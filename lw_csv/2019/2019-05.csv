_id,title,slug,pageUrl,postedAt,baseScore,voteCount,commentCount,meta,question,url,htmlBody,user.username,user.slug,user.displayName,user
FkgsxrGf3QxhfLWHG,Risks from Learned Optimization: Introduction,risks-from-learned-optimization-introduction,https://www.lesswrong.com/posts/FkgsxrGf3QxhfLWHG/risks-from-learned-optimization-introduction,2019-05-31T23:44:53.703Z,187,82,42,False,False,,"<p><em>This is the first of five posts in the <a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB"">Risks from Learned Optimization Sequence</a> based on the paper “<a href=""https://arxiv.org/abs/1906.01820"">Risks from Learned Optimization in Advanced Machine Learning Systems</a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper.</em></p>
<p><em>Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence. With special thanks to Paul Christiano, Eric Drexler, Rob Bensinger, Jan Leike, Rohin Shah, William Saunders, Buck Shlegeris, David Dalrymple, Abram Demski, Stuart Armstrong, Linda Linsefors, Carl Shulman, Toby Ord, Kate Woolverton, and everyone else who provided feedback on earlier versions of this sequence.</em></p>
<p>&nbsp;</p>
<h2>Motivation</h2>
<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,</em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?</p>
<p>We believe that this sequence presents the most thorough analysis of these questions that has been conducted to date. In particular, we present not only an introduction to the basic concerns surrounding mesa-optimizers, but also an analysis of the particular aspects of an AI system that we believe are likely to make the problems related to mesa-optimization relatively easier or harder to solve. By providing a framework for understanding the degree to which different AI systems are likely to be robust to misaligned mesa-optimization, we hope to start a discussion about the best ways of structuring machine learning systems to solve these problems. Furthermore, in the fourth post we will provide what we think is the most detailed analysis yet of a problem we refer as <em>deceptive alignment</em> which we posit may present one of the largest—though not necessarily insurmountable—current obstacles to producing safe advanced machine learning systems using techniques similar to modern machine learning.</p>
<p>&nbsp;</p>
<h2>Two questions</h2>
<p>In machine learning, we do not manually program each individual parameter of our models. Instead, we specify an objective function that captures what we want the system to do and a learning algorithm to optimize the system for that objective. In this post, we present a framework that distinguishes what a system is <em>optimized</em> to do (its “purpose”), from what it <em>optimizes</em> for (its “goal”), if it optimizes for anything at all. While all AI systems are optimized for something (have a purpose), whether they actually optimize for anything (pursue a goal) is non-trivial. We will say that a system is an <em>optimizer</em> if it is internally searching through a search space (consisting of possible outputs, policies, plans, strategies, or similar) looking for those elements that score high according to some objective function that is explicitly represented within the system. Learning algorithms in machine learning are optimizers because they search through a space of possible parameters—e.g. neural network weights—and improve the parameters with respect to some objective. Planning algorithms are also optimizers, since they search through possible plans, picking those that do well according to some objective.</p>
<p>Whether a system is an optimizer is a property of its internal structure—what algorithm it is physically implementing—and not a property of its input-output behavior. Importantly, the fact that a system’s behavior results in some objective being maximized does not make the system an optimizer. For example, a bottle cap causes water to be held inside the bottle, but it is not optimizing for that outcome since it is not running any sort of optimization algorithm.<a href=""https://intelligence.org/learned-optimization#bibliography"">(1)</a> Rather, bottle caps have been <em>optimized</em> to keep water in place. The optimizer in this situation is the human that designed the bottle cap by searching through the space of possible tools for one to successfully hold water in a bottle. Similarly, image-classifying neural networks are optimized to achieve low error in their classifications, but are not, in general, themselves performing optimization.</p>
<p>However, it is also possible for a neural network to itself run an optimization algorithm. For example, a neural network could run a planning algorithm that predicts the outcomes of potential plans and searches for those it predicts will result in some desired outcome.<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-1"" id=""fnref-RonwTsAmsSWpSwFrb-1"">[1]</a></sup> Such a neural network would itself be an optimizer because it would be searching through the space of possible plans according to some objective function. If such a neural network were produced in training, there would be two optimizers: the learning algorithm that produced the neural network—which we will call the <em>base optimizer</em>—and the neural network itself—which we will call the <em>mesa-optimizer.</em><sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-2"" id=""fnref-RonwTsAmsSWpSwFrb-2"">[2]</a></sup></p>
<p>The possibility of mesa-optimizers has important implications for the safety of advanced machine learning systems. When a base optimizer generates a mesa-optimizer, safety properties of the base optimizer's objective may not transfer to the mesa-optimizer. Thus, we explore two primary questions related to the safety of mesa-optimizers:</p>
<ol>
<li><strong>Mesa-optimization:</strong> Under what circumstances will learned algorithms be optimizers?</li>
<li><strong>Inner alignment:</strong> When a learned algorithm is an optimizer, what will its objective be, and how can it be aligned?</li>
</ol>
<p>Once we have introduced our framework in this post, we will address the first question in the second, begin addressing the second question in the third post, and finally delve deeper into a specific aspect of the second question in the fourth post.</p>
<p>&nbsp;</p>
<h2>1.1. Base optimizers and mesa-optimizers</h2>
<p>Conventionally, the base optimizer in a machine learning setup is some sort of gradient descent process with the goal of creating a model designed to accomplish some specific task.</p>
<p>Sometimes, this process will also involve some degree of meta-optimization wherein a <em>meta-optimizer</em> is tasked with producing a base optimizer that is itself good at optimizing systems to achieve particular goals. Specifically, we will think of a <em>meta-optimizer</em> as any system whose task is optimization. For example, we might design a meta-learning system to help tune our gradient descent process.<a href=""https://intelligence.org/learned-optimization#bibliography"">(4)</a> Though the model found by meta-optimization can be thought of as a kind of learned optimizer, it is not the form of learned optimization that we are interested in for this sequence. Rather, we are concerned with a different form of learned optimization which we call <em>mesa-optimization.</em></p>
<p>Mesa-optimization is a conceptual dual of meta-optimization—whereas <em>meta</em> is Greek for “after,” <em>mesa</em> is Greek for “within.”<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-3"" id=""fnref-RonwTsAmsSWpSwFrb-3"">[3]</a></sup> <em>Mesa-optimization</em> occurs when a base optimizer (in searching for algorithms to solve some problem) finds a model that is itself an optimizer, which we will call a <em>mesa-optimizer.</em> Unlike meta-optimization, in which the task itself is optimization, mesa-optimization is task-independent, and simply refers to any situation where the internal structure of the model ends up performing optimization because it is instrumentally useful for solving the given task.</p>
<p>In such a case, we will use <em>base objective</em> to refer to whatever criterion the base optimizer was using to select between different possible systems and <em>mesa-objective</em> to refer to whatever criterion the mesa-optimizer is using to select between different possible outputs. In reinforcement learning (RL), for example, the base objective is generally the expected return. Unlike the base objective, the mesa-objective is not specified directly by the programmers. Rather, the mesa-objective is simply whatever objective was found by the base optimizer that produced good performance on the training environment. Because the mesa-objective is not specified by the programmers, mesa-optimization opens up the possibility of a mismatch between the base and mesa- objectives, wherein the mesa-objective might seem to perform well on the training environment but lead to bad performance off the training environment. We will refer to this case as <em>pseudo-alignment</em> below.</p>
<p>There need not always be a mesa-objective since the algorithm found by the base optimizer will not always be performing optimization. Thus, in the general case, we will refer to the model generated by the base optimizer as a <em>learned algorithm,</em> which may or may not be a mesa-optimizer.</p>
<p><img src=""https://i.imgur.com/snCO8OV.jpg"" alt=""""></p>
<p><strong>Figure 1.1.</strong> <em>The relationship between the base and mesa- optimizers. The base optimizer optimizes the learned algorithm based on its performance on the base objective. In order to do so, the base optimizer may have turned this learned algorithm into a mesa-optimizer, in which case the mesa-optimizer itself runs an optimization algorithm based on its own mesa-objective. Regardless, it is the learned algorithm that directly takes actions based on its input.</em></p>
<p><strong>Possible misunderstanding: “mesa-optimizer” does not mean “subsystem” or “subagent.”</strong> In the context of deep learning, a mesa-optimizer is simply a neural network that is implementing some optimization process and not some emergent subagent inside that neural network. Mesa-optimizers are simply a particular type of algorithm that the base optimizer might find to solve its task. Furthermore, we will generally be thinking of the base optimizer as a straightforward optimization algorithm, and not as an intelligent agent choosing to create a subagent.<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-4"" id=""fnref-RonwTsAmsSWpSwFrb-4"">[4]</a></sup></p>
<p>We distinguish the mesa-objective from a related notion that we term the <em>behavioral objective</em>. Informally, the behavioral objective is the objective which appears to be optimized by the system’s behavior. We can operationalize the behavioral objective as the objective recovered from perfect inverse reinforcement learning (IRL).<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-5"" id=""fnref-RonwTsAmsSWpSwFrb-5"">[5]</a></sup> This is in contrast to the mesa-objective, which is the objective <em>actively being used</em> by the mesa-optimizer in its optimization algorithm.</p>
<p>Arguably, any possible system has a behavioral objective—including bricks and bottle caps. However, for non-optimizers, the appropriate behavioral objective might just be “1 if the actions taken are those that are in fact taken by the system and 0 otherwise,”<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-6"" id=""fnref-RonwTsAmsSWpSwFrb-6"">[6]</a></sup> and it is thus neither interesting nor useful to know that the system is acting to optimize this objective. For example, the behavioral objective “optimized” by a bottle cap is the objective of behaving like a bottle cap.<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-7"" id=""fnref-RonwTsAmsSWpSwFrb-7"">[7]</a></sup> However, if the system is an optimizer, then it is more likely that it will have a meaningful behavioral objective. That is, to the degree that a mesa-optimizer’s output is systematically selected to optimize its mesa-objective, its behavior may look more like coherent attempts to move the world in a particular direction.<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-8"" id=""fnref-RonwTsAmsSWpSwFrb-8"">[8]</a></sup></p>
<p>A given mesa-optimizer’s mesa-objective is determined entirely by its internal workings. Once training is finished and a learned algorithm is selected, its direct output—e.g. the actions taken by an RL agent—no longer depends on the base objective. Thus, it is the mesa-objective, not the base objective, that determines a mesa-optimizer’s behavioral objective. Of course, to the degree that the learned algorithm was selected on the basis of the base objective, its output will score well on the base objective. However, in the case of a distributional shift, we should expect a mesa-optimizer’s behavior to more robustly optimize for the mesa-objective since its behavior is directly computed according to it.</p>
<p>As an example to illustrate the base/mesa distinction in a different domain, and the possibility of misalignment between the base and mesa- objectives, consider biological evolution. To a first approximation, evolution selects organisms according to the objective function of their inclusive genetic fitness in some environment.<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-9"" id=""fnref-RonwTsAmsSWpSwFrb-9"">[9]</a></sup> Most of these biological organisms—plants, for example—are not “trying” to achieve anything, but instead merely implement heuristics that have been pre-selected by evolution. However, some organisms, such as humans, have behavior that does not merely consist of such heuristics but is instead also the result of goal-directed optimization algorithms implemented in the brains of these organisms. Because of this, these organisms can perform behavior that is completely novel from the perspective of the evolutionary process, such as humans building computers.</p>
<p>However, humans tend not to place explicit value on evolution’s objective, at least in terms of caring about their alleles' frequency in the population. The objective function stored in the human brain is not the same as the objective function of evolution. Thus, when humans display novel behavior optimized for their own objectives, they can perform very poorly according to evolution’s objective. Making a decision not to have children is a possible example of this. Therefore, we can think of evolution as a base optimizer that produced brains—mesa-optimizers—which then actually produce organisms’ behavior—behavior that is not necessarily aligned with evolution.</p>
<p>&nbsp;</p>
<h2>1.2. The inner and outer alignment problems</h2>
<p>In “Scalable agent alignment via reward modeling,” Leike et al. describe the concept of the “reward-result gap” as the difference between the (in their case learned) “reward model” (what we call the base objective) and the “reward function that is recovered with perfect inverse reinforcement learning” (what we call the behavioral objective).<a href=""https://intelligence.org/learned-optimization#bibliography"">(8)</a> That is, the reward-result gap is the fact that there can be a difference between what a learned algorithm is observed to be doing and what the programmers want it to be doing.</p>
<p>The problem posed by misaligned mesa-optimizers is a kind of reward-result gap. Specifically, it is the gap between the base objective and the mesa-objective (which then causes a gap between the base objective and the behavioral objective). We will call the problem of eliminating the base-mesa objective gap the <em>inner alignment problem,</em> which we will contrast with the <em>outer alignment problem</em> of eliminating the gap between the base objective and the intended goal of the programmers. This terminology is motivated by the fact that the inner alignment problem is an alignment problem entirely internal to the machine learning system, whereas the outer alignment problem is an alignment problem between the system and the humans outside of it (specifically between the base objective and the programmer’s intentions). In the context of machine learning, outer alignment refers to aligning the specified loss function with the intended goal, whereas inner alignment refers to aligning the mesa-objective of a mesa-optimizer with the specified loss function.</p>
<p>It might not be necessary to solve the inner alignment problem in order to produce safe, highly capable AI systems, as it might be possible to prevent mesa-optimizers from occurring in the first place. If mesa-optimizers cannot be reliably prevented, however, then some solution to both the outer and inner alignment problems will be necessary to ensure that mesa-optimizers are aligned with the intended goal of the programmers.</p>
<p>&nbsp;</p>
<h2>1.3. Robust alignment vs. pseudo-alignment</h2>
<p>Given enough training, a mesa-optimizer should eventually be able to produce outputs that score highly on the base objective on the training distribution. Off the training distribution, however—and even on the training distribution while it is still early in the training process—the difference could be arbitrarily large. We will use the term <em>robustly aligned</em> to refer to mesa-optimizers with mesa-objectives that robustly agree with the base objective across distributions and the term <em>pseudo-aligned</em> to refer to mesa-optimizers with mesa-objectives that agree with the base objective on past training data, but not robustly across possible future data (either in testing, deployment, or further training). For a pseudo-aligned mesa-optimizer, there will be environments in which the base and mesa- objectives diverge. Pseudo-alignment, therefore, presents a potentially dangerous robustness problem since it opens up the possibility of a machine learning system that competently takes actions to achieve something other than the intended goal when off the training distribution. That is, its capabilities might generalize while its objective does not.</p>
<p>For a toy example of what pseudo-alignment might look like, consider an RL agent trained on a maze navigation task where all the doors during training happen to be red. Let the base objective (reward function) be <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_\text{base} = \text{(1 if reached a door, 0 otherwise)}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;""><span class=""mjx-mtext"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">base</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(1 if reached a door, 0 otherwise)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></span></span>. On the training distribution, this objective is equivalent to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_\text{alt} = \text{(1 if reached something red, 0 otherwise)}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;""><span class=""mjx-mtext"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">alt</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(1 if reached something red, 0 otherwise)</span></span></span></span></span></span>. Consider what would happen if an agent, trained to high performance on <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_\text{base}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;""><span class=""mjx-mtext"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">base</span></span></span></span></span></span></span></span> on this task, were put in an environment where the doors are instead blue, and with some red objects that are not doors. It might generalize on <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_\text{base}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;""><span class=""mjx-mtext"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">base</span></span></span></span></span></span></span></span>, reliably navigating to the blue door in each maze (robust alignment). But it might also generalize on <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_\text{alt}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;""><span class=""mjx-mtext"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">alt</span></span></span></span></span></span></span></span> instead of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_\text{base}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;""><span class=""mjx-mtext"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">base</span></span></span></span></span></span></span></span>, reliably navigating each maze to reach red objects (pseudo-alignment).<sup class=""footnote-ref""><a href=""#fn-RonwTsAmsSWpSwFrb-10"" id=""fnref-RonwTsAmsSWpSwFrb-10"">[10]</a></sup></p>
<p>&nbsp;</p>
<h2>1.4. Mesa-optimization as a safety problem</h2>
<p>If pseudo-aligned mesa-optimizers may arise in advanced ML systems, as we will suggest, they could pose two critical safety problems.</p>
<p><strong>Unintended optimization.</strong> First, the possibility of mesa-optimization means that an advanced ML system could end up implementing a powerful optimization procedure even if its programmers never intended it to do so. This could be dangerous if such optimization leads the system to take extremal actions outside the scope of its intended behavior in trying to maximize its mesa-objective. Of particular concern are optimizers with objective functions and optimization procedures that generalize to the real world. The conditions that lead a learning algorithm to find mesa-optimizers, however, are very poorly understood. Knowing them would allow us to predict cases where mesa-optimization is more likely, as well as take measures to discourage mesa-optimization from occurring in the first place. The second post will examine some features of machine learning algorithms that might influence their likelihood of finding mesa-optimizers.</p>
<p><strong>Inner alignment.</strong> Second, even in cases where it is acceptable for a base optimizer to find a mesa-optimizer, a mesa-optimizer might optimize for something other than the specified reward function. In such a case, it could produce bad behavior even if optimizing the correct reward function was known to be safe. This could happen either during training—before the mesa-optimizer gets to the point where it is aligned over the training distribution—or during testing or deployment when the system is off the training distribution. The third post will address some of the different ways in which a mesa-optimizer could be selected to optimize for something other than the specified reward function, as well as what attributes of an ML system are likely to encourage this. In the fourth post, we will discuss a possible extreme inner alignment failure—which we believe presents one of the most dangerous risks along these lines—wherein a sufficiently capable misaligned mesa-optimizer could learn to behave as if it were aligned without actually being robustly aligned. We will call this situation <em>deceptive alignment.</em></p>
<p>It may be that pseudo-aligned mesa-optimizers are easy to address—if there exists a reliable method of aligning them, or of preventing base optimizers from finding them. However, it may also be that addressing misaligned mesa-optimizers is very difficult—the problem is not sufficiently well-understood at this point for us to know. Certainly, current ML systems do not produce dangerous mesa-optimizers, though whether future systems might is unknown. It is indeed because of these unknowns that we believe the problem is important to analyze.</p>
<p>&nbsp;</p>
<p><em>The second post in the <a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB"">Risks from Learned Optimization Sequence</a>, titled “Conditions for Mesa-Optimization,” can be found <a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/q2rCMHNXazALgQpGH"">here</a>.</em></p>
<p><a href=""https://intelligence.org/learned-optimization/#glossary"">Glossary</a> | <a href=""https://intelligence.org/learned-optimization/#bibliography"">Bibliography</a></p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-RonwTsAmsSWpSwFrb-1"" class=""footnote-item""><p>As a concrete example of what a neural network optimizer might look like, consider TreeQN.<a href=""https://intelligence.org/learned-optimization#bibliography"">(2)</a> TreeQN, as described in Farquhar et al., is a Q-learning agent that performs model-based planning (via tree search in a latent representation of the environment states) <em>as part of its computation of the Q-function.</em> Though their agent is an optimizer by design, one could imagine a similar algorithm being <em>learned</em> by a DQN agent with a sufficiently expressive approximator for the Q function. Universal Planning Networks, as described by Srinivas et al.,<a href=""https://intelligence.org/learned-optimization#bibliography"">(3)</a> provide another example of a learned system that performs optimization, though the optimization there is built-in in the form of SGD via automatic differentiation. However, research such as that in Andrychowicz et al.<a href=""https://intelligence.org/learned-optimization#bibliography"">(4)</a> and Duan et al.<a href=""https://intelligence.org/learned-optimization#bibliography"">(5)</a> demonstrate that optimization algorithms can be learned by RNNs, making it possible that a Universal Planning Networks-like agent could be entirely learned—assuming a very expressive model space—including the internal optimization steps. Note that while these examples are taken from reinforcement learning, optimization might in principle take place in any sufficiently expressive learned system. <a href=""#fnref-RonwTsAmsSWpSwFrb-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-2"" class=""footnote-item""><p>Previous work in this space has often centered around the concept of “optimization daemons,”<a href=""https://intelligence.org/learned-optimization#bibliography"">(6)</a> a framework that we believe is potentially misleading and hope to supplant. Notably, the term “optimization daemon” came out of discussions regarding the nature of humans and evolution, and, as a result, carries anthropomorphic connotations. <a href=""#fnref-RonwTsAmsSWpSwFrb-2"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-3"" class=""footnote-item""><p>The duality comes from thinking of meta-optimization as one layer above the base optimizer and mesa-optimization as one layer below. <a href=""#fnref-RonwTsAmsSWpSwFrb-3"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-4"" class=""footnote-item""><p>That being said, some of our considerations do still apply even in that case. <a href=""#fnref-RonwTsAmsSWpSwFrb-4"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-5"" class=""footnote-item""><p>Leike et al.<a href=""https://intelligence.org/learned-optimization#bibliography"">(8)</a> introduce the concept of an objective recovered from perfect IRL. <a href=""#fnref-RonwTsAmsSWpSwFrb-5"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-6"" class=""footnote-item""><p>For the formal construction of this objective, see pg. 6 in Leike et al.<a href=""https://intelligence.org/learned-optimization#bibliography"">(8)</a> <a href=""#fnref-RonwTsAmsSWpSwFrb-6"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-7"" class=""footnote-item""><p>This objective is by definition trivially optimal in any situation that the bottlecap finds itself in. <a href=""#fnref-RonwTsAmsSWpSwFrb-7"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-8"" class=""footnote-item""><p>Ultimately, our worry is optimization in the direction of some coherent but unsafe objective. In this sequence, we assume that search provides sufficient structure to expect coherent objectives. While we believe this is a reasonable assumption, it is unclear both whether search is necessary and whether it is sufficient. Further work examining this assumption will likely be needed. <a href=""#fnref-RonwTsAmsSWpSwFrb-8"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-9"" class=""footnote-item""><p>The situation with evolution is more complicated than is presented here and we do not expect our analogy to live up to intense scrutiny. We present it as nothing more than that: an evocative analogy (and, to some extent, an existence proof) that explains the key concepts. More careful arguments are presented later. <a href=""#fnref-RonwTsAmsSWpSwFrb-9"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-RonwTsAmsSWpSwFrb-10"" class=""footnote-item""><p>Of course, it might also fail to generalize at all. <a href=""#fnref-RonwTsAmsSWpSwFrb-10"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
",evhub,evhub,evhub,
5conQhfa4rgb4SaWx,"Site Guide: Personal Blogposts vs Frontpage Posts
",site-guide-personal-blogposts-vs-frontpage-posts,https://www.lesswrong.com/posts/5conQhfa4rgb4SaWx/site-guide-personal-blogposts-vs-frontpage-posts,2019-05-31T23:08:07.363Z,74,40,15,True,False,,"<p>Posts on practically any topic are welcomed on LessWrong [1]. I (and others on the team) feel it is important that members are able to &#x201C;bring their entire selves&#x201D; to LessWrong and are able to share all their thoughts, ideas, and experiences without fearing whether they are &#x201C;on topic&#x201D; for LessWrong. Rationality is not restricted to only specific domains of one&#x2019;s life and neither should LessWrong be.</p><p><strong>However, to maintain its overall focus while still allowing posts on any topic, LessWrong classifies posts as either <em>Personal blogposts</em> or as <em>Frontpage posts</em>.</strong> </p><h1>The two classifications</h1><h2>Personal blogposts</h2><ul><li>Is the default classification for all posts.</li><li>Are not displayed by default on the homepage.</li><li>Can be on any topic [1] and in any format: nothing is &#x201C;off topic&#x201D;</li><li>Suitable for personal interests, blogging, and general ramblings</li><ul><li>e.g. your thoughts on Magic the Gathering, a poem, or a short story you wrote</li></ul><li>Suitable for discussion of current events</li><li>Suitable for discussion of specific social and community issues</li><li>Suitable for discussion of highly divisive topics</li><li>Suitable for discussion of the LessWrong website*</li></ul><h2>Frontpage posts</h2><ul><li>Are displayed by default to all users.</li><li>Authors can allow moderators to give their post Frontpage status if the moderator judges the post to be:</li><ul><li>Useful, novel, and relevant to many LessWrong members</li><li>&#x201C;Timeless&#x201D;, i.e. minimizes references to current events and is likely to remain useful even after a few years</li><li>The post attempts to explain rather than persuade</li></ul></ul><p>This system allows LessWrong members to write about whatever is of interest to them while ensuring that only members who wish to see &#x201C;off topic&#x201D; content see that content.</p><p><em>*The LessWrong team will make some exceptions in the case of announcement posts we believe should have maximally broad visibility, e.g. <a href=""https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq-1"">the FAQ</a>, and give these Frontpage status.</em></p><h1>How to view personal blogposts</h1><p>Personal blogposts, with their laxer restrictions, are not shown by default on LessWrong&#x2019;s homepage. To view Personal blogposts, you can:</p><ul><li>Click the &#x201C;Include Personal blogposts&#x201D; checkbox beneath the <em>Latest Posts</em> section.</li><li>Visit the <u><a href=""https://www.lesswrong.com/allPosts?filter=all"">All Posts</a></u> page and ensure &quot;Filtered by&quot; is set to &#x201C;All Posts&#x201D;</li><li>Find a user&#x2019;s Personal blogposts by visiting their user profile page</li><li>Personal blogposts and their comments appear in the Recent Discussion feed on the homepage. </li></ul><br><h2>Personal blogposts and the Recent Discussion Feed</h2><p>In some cases, the moderation team will hide comments on Personal blogposts from the Recent Discussion feed on the homepage. This is done if the moderation teams feels a discussion is veering in directions which are particularly controversial, political, or unproductive. </p><p>I (and I believe the rest of team) are not opposed to such discussions per se, but believe that we shouldn&#x2019;t be drawing marginal attention to these discussions.  In particular, the team does not think it&apos;s ideal for newcomers to encounter these discussions when first exploring LessWrong.</p><h1>What does this mean for me?</h1><p>Our classification system means that anyone can decide to use the LessWrong platform for their own personal blog and write about whichever topics take their interest. All of your posts and comments are visible under your user page which you can treat as your own personal blog hosted on LessWrong [2]. Other users can subscribe to your account and be notified whenever you post.</p><hr class=""dividerBlock""><p>[1] We will remove material of the following types:</p><ul><li>Calls for direct violence against others</li><li>Doxing of people on the internet</li><li>Material we are not legally able to host</li><li>To a very limited degree, material that seriously threatens LessWrong&#x2019;s long-term values, mission and culture. </li></ul><p>[2] In the future we might add various user-page/personal blog customization features like custom backgrounds, curating which posts and comments are shown first, etc.</p>",Ruby,ruby,Ruby,
5vxFq8ncZqa3QRsPT,When Observation Beats Experiment,when-observation-beats-experiment,https://www.lesswrong.com/posts/5vxFq8ncZqa3QRsPT/when-observation-beats-experiment,2019-05-31T22:58:57.986Z,19,7,7,False,False,,"<p>Suppose we have a strain of lab rats which are colored purple, and we want to know why. We suspect that chemical X is responsible, so we run an experiment:</p><ul><li>We genetically modify our purple rats to repress X production, and find that their purple coloration disappears.</li><li>We genetically modify ordinary rats to produce X, and find that their coats turn purple.</li></ul><p>We conclude that chemical X is both necessary and sufficient to turn rats’ coats purple. Case closed!</p><p>… or maybe not.</p><p>Suppose that rats are purple-colored if-and-only-if they express Purple Pigment (PP) above some threshold level. Purple Pigment, in turn, is chemically produced from X and Y:</p><p> <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X + Y \rightleftharpoons PP""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">⇌</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span> </p><p>High levels of PP could result from high levels of X, or from high levels of Y. Either way, increasing X enough will always turn a rat purple, and decreasing X enough will always turn a rat not-purple. So our experiment doesn’t tell us whether our particular rats are purple due to high X or high Y - it could be either. In order to tell the difference, we need to go measure X and Y levels in our rats - not an experiment, but an observation.</p><p>(Warning: technical details not relevant to the main point were brushed under the rug there.)</p><p>Generalizing: experiments are really good for figuring out the <em>structure</em> of the underlying causal graph. How can we tell that Purple Pigment is produced from X and Y in the first place? Experiment: we try various levels of X and Y and see which rats are purple.</p><p>But if we want to know the <em>state</em> of the causal graph, in some real-world system, then observation beats experiment. To find out whether our particular rats are purple because of high X or high Y, we should measure their X and Y levels, without any experimental intervention. Of course, this only works if we’ve already done the experiments to figure out the structure of the system.</p>",johnswentworth,johnswentworth,johnswentworth,
6fqWFLTQoEMHPgJia,How to determine if my sympathetic or my parasympathetic nervous system is currently dominant?,how-to-determine-if-my-sympathetic-or-my-parasympathetic,https://www.lesswrong.com/posts/6fqWFLTQoEMHPgJia/how-to-determine-if-my-sympathetic-or-my-parasympathetic,2019-05-31T20:40:30.664Z,20,9,5,False,True,,"<html><head></head><body><p>I've been reading CFAR Handbook's chapter about Againstness. The chapter's idea is that when your sympathetic nervous system (SNS) is dominant over parasympathetic nervous system (PSNS), your introspection is impaired and you tend to be less rational, hence you should learn how to know which system is currently dominant and also learn to switch to PSNS dominance.</p>
<p>They provide the following table of how your body, mind, and behaviour change depending on which system is dominant</p>
<p><img src=""http://dump.bitcheese.net/files/makisaj/Screenshot_20190529_113135.png"" alt=""table sns vs psns""></p>
<p>In order to learn to know where you are on SNS-PSNS spectrum they recommend observing yourself in different situations, determine which system is dominant, and try to find patterns (e.g., maybe after doing physical exercise your SNS is usually dominant).</p>
<p>Well, I tried observing myself and figuring out which nervous system is active, and about 70% of the times I can't determine it. I ask myself questions like ""Do I feel joy?"", ""Am I at peace?"", ""Are my muscles tense?"", ""Does my skin feel like flushed?"", ""Is my breathing shallow, or slow and in belly?"". More often than not I can't answer these questions. And it doesn't help that there's no easy way to calibrate by observing the ground truth.</p>
<p>If there are people here who can determine which of your two nervous systems is dominant, how do you do it? Any tips for me?</p>
<p>Also, sometimes I get signals from my body that don't fit in this framework. When it's time for me to go to sleep but I don't do it, after a while my awareness and introspective clarity become impaired, I feel both energized and lacking energy at the same time, I fill like my system 2 (as in Kahneman's two systems) doesn't turn on a lot, and I get impatient. What happens with SNS and PSNS at this time? I don't know.</p>
</body></html>",crabman,philip_b,philip_b,
sZhYKPcRcmWGQ6929,What is the best online community for questions about AI capabilities?,what-is-the-best-online-community-for-questions-about-ai,https://www.lesswrong.com/posts/sZhYKPcRcmWGQ6929/what-is-the-best-online-community-for-questions-about-ai,2019-05-31T15:38:11.678Z,4,2,2,False,True,,"<p>I&#x27;m interested in learning more about existing ML model capabilities, and in particular how easily a model that is used on one task could be used for another, similar task. </p><p>For example, if I want to know and/or estimate whether an existing AI system like AlphaZero could beat Angry Birds with current capabilities, what&#x27;s the best place to post that type question?</p>",bgold,bgold,Ben Goldhaber,
ce8NMdqoh5oWpYcmy,Egoism In Disguise,egoism-in-disguise,https://www.lesswrong.com/posts/ce8NMdqoh5oWpYcmy/egoism-in-disguise,2019-05-31T14:40:26.865Z,1,12,12,False,False,,"<p>  </p><p>Originally posted at <a href=""http://livingwithinreason.com/2019/05/31/egoism-in-disguise/"">Living Within Reason</a></p><p>Epistemic status: moderately certain, but open to being convinced otherwise</p><p>tl;dr: any ethical system that relies on ethical intuitions is just egoism that&#x27;s given a veneer of objectivity.</p><h4>Utilitarianism Relies on Moral Intuitions</h4><p>Most rationalists are utilitarians, so much so that most rationalist writing assumes a utilitarian outlook. In a utilitarian system, whatever is &quot;good&quot; is what maximizes utility. Utility, technically, can be defined as anything, but most utilitarians attempt to maximize the well-being of humans and, to some extent, animals.</p><p>I am not a utilitarian. <a href=""http://livingwithinreason.com/2015/04/06/ethics-and-philosophy-a-defense-of-egoism/"">I am an egoist</a>. I believe that the only moral duty that we have is to act in our own self-interest (though generally, it is in our self-interest to act in prosocial ways most of the time). I feel a certain alienation from a lot of rationalist writing because of this difference. However, I have long suspected that most utilitarian thinking is largely the same thing as egoism.</p><p>Recently, Ozy of Thing of Things <a href=""https://thingofthings.wordpress.com/2019/05/27/do-animals-have-a-right-to-life/"">wrote a post</a> that illustrates this point well. Like a lot of rationalist writing, this is addressing an ethical dilemma from a utilitarian framework. Ozy is trying to decide what creatures have a right to life, specifically considering humanely-raised animals, human fetuses, and human babies. From the post:</p><blockquote>Imagine that, among very wealthy people, there is a new fad for eating babies. Out baby farmer is an ethical person and he wants to make sure that his babies are farmed as ethically as possible. The babies are produced through artificial wombs; there are no adults who are particularly invested in the babies’ continued life. The babies are slaughtered at one month, well before they have long-term plans and preferences that are thwarted by death. In their one month of life, the babies have the happiest possible baby life: they are picked up immediately whenever they cry, they get lots of delicious milk, they’re held and rocked and sung to, their medical concerns are treated quickly, and they don’t ever have to sit in a poopy diaper. In every way, they live as happy and flourishing a life as a two-week-old baby can. Is the baby farm unethical?<br/>If you’re like me, the answer is a quick “yes.” </blockquote><p>Ozy&#x27;s main evidence for their conclusion is specifically stated to be their moral intuition, resting on the idea that &quot;I am horrified by the idea of a baby farm. I am not horrified by the idea of a beef cow farm.&quot; Ozy goes on to examine this intuition, weighs it against other moral intuitions, and ultimately concludes that it is correct.</p><p>This is not surprising given that the ultimate authority for any consequentialist system is <a href=""https://web.archive.org/web/20161115073538/http://raikoth.net/consequentialism.html"">the individual&#x27;s moral intuitions</a> (see Part 1). In a utilitarian system, moral intuitions &quot;are the only reason you believe morality exists at all. They are also the standards by which you judge all moral philosophies.&quot; People have many different moral intuitions, and must weigh them against one another when it comes to  difficult ethical questions, but at bedrock, moral intuitions are the basis for the entire ethical system.</p><h4>Moral Intuitions Are Subjective Preferences</h4><p>From the previously-linked FAQ:</p><blockquote>Moral intuitions are people&#x27;s basic ideas about morality. Some of them are hard-coded into the design of the human brain. Others are learned at a young age. They manifest as beliefs (“Hurting another person is wrong&quot;), emotions (such as feeling sad whenever I see an innocent person get hurt) and actions (such as trying to avoid hurting another person.) </blockquote><p>Notice that nothing in this explanation appeals to anything objective. Arguably, &quot;hard-coded into the design of the human brain&quot; could be seen an objective, but it is also trivial. If I do not share a specific intuition, then tautologically it is not hard-coded into my brain so it cannot be used to resolve a difference of opinion.</p><p>Under a egoist worldview, there are still ethics, but they are based on self-interest. What is &quot;good&quot; is merely what I prefer. Human flourishing is good because the idea of human flourishing makes me smile. Kicking puppies is bad because it upsets me. These are not moral rules that can bind anyone else. They are merely my preferences, and to the extent that I want others to conform to my preferences, I must convince or coerce them.</p><p>The egoist outlook is entirely consistent with the utilitarian one. Consider the above paragraph, but rewritten to emphasize the subjectivity:</p><blockquote>[My] moral intuitions are [my preferences for how the world should be]. Some of them are hard-coded into the design of [my] brain. Others are learned at a young age. They manifest as beliefs (“Hurting another person is wrong&quot;), emotions (such as feeling sad whenever I see an innocent person get hurt) and actions (such as trying to avoid hurting another person.) </blockquote><p>The language is changed, but the basic idea is the same. It emphasizes that my moral rules are based entirely on what appeals to me. At its heart, any system that relies on moral intuitions is indistinguishable from egoism.</p><h4>Why Does This Matter?</h4><p>In a sense, my conclusion here is rather trivial. Who cares if utilitarian ethics and egoism are largely the same thing? As an egoist, shouldn&#x27;t I be happy about this and encourage more people to be utilitarians?</p><p>The reason why I would prefer that more people explicitly acknowledge the egoist foundations of their moral theory is that I believe moral judgment of others does great harm to our society. Utilitarianism dresses itself up as objective, and therefore leaves room to decide that other people have moral obligations, and that we are free (or even obligated) to judge and/or punish them for their moral failings. </p><p>Moral judgment of others makes us unlikely to accept that <a href=""http://livingwithinreason.com/2018/06/10/nobody-deserves-to-suffer/"">nobody deserves to suffer</a>. If someone behaves immorally, we often feel that it is &quot;justice&quot; to punish that person regardless of the practical effects of the punishments. It leads to outrage culture and is a major impediment to adopting an evidence-based criminal justice system. </p><blockquote>If we’re insisting on punishing someone for reasons other than trying to influence (their or others’) future behavior, we are not making the world a better place. We are just being cruel. Nobody deserves to suffer. Even the worse people in the world are just acting according to their brain wiring. By all means, we should punish bad behavior, but we should do it in a way that’s calculated to influence <em>future </em>behavior.  We should recognize that, if we truly lived in a just world, everyone, even the worst of us, would have everything they want. </blockquote><p>If, instead, we acknowledge that our moral beliefs are merely preferences for how we would like the world to work, we will inflict less useless suffering. If we acknowledge that attempting to force our morality on someone else is inherently coercive, we will use it only in circumstances where we feel that coercion is justified. We will stop punishing people based on the idea of retribution and can instead adopt an evidence-based system that only punishes people if the punishments are reasonably likely to create better future outcomes. </p><p>I have a preference for less suffering in the world. If you share that preference, consider adopting an explicitly egoist morality and encouraging others with similar preferences to do the same. We will never tame our most barbaric impulses unless we abandon the idea that we are able to morally judge others.</p>",wfenza,wes-f,Wes F,
LxLhQoHTcXG8CYaeP,Lonelinesses,lonelinesses,https://www.lesswrong.com/posts/LxLhQoHTcXG8CYaeP/lonelinesses,2019-05-31T13:55:55.135Z,53,25,5,False,False,,"<p>Cross-posted from <a href=""https://putanumonit.com/2019/05/21/lonelinesses/"">Putanumonit</a>.</p><hr class=""dividerBlock""/><p>In recent weeks I found myself experiencing a profound loneliness. I became curious about this feeling, and I tried to examine it. Though not often, I’ve certainly felt lonely before and yet this time felt new to me. I wondered if there are different flavors of loneliness that we lack the vocabulary to categorize and understand.</p><p>I also found myself rereading bits of Greek mythology. It struck me that <em>loneliness</em> is a core theme the ancient Hellenic worldview: the gods are islands unto themselves, while the connections that mortals make are often illusory and bound for betrayal. The heroes of myth have spouses and lovers, parents and children, friends and patron gods – and yet each person has a fate that is solely their own. Even in death, the souls of Greeks wander Hades as lonely shades, in sharp contrast to the cosmic unification promised by monotheistic traditions to the dead.</p><p>I think this is also why the ancient Greeks glorified war – death among comrades in battle is the only way for a man not to die alone. Agamemnon, the leader of the Greeks at Troy, survived the war only to be killed upon his return by his wife Clytemnestra’s new lover. When he meets Odysseus in Hades, Agamemnon wishes bitterly that he had died in combat and his only advice to the Ithakan is to trust no one and keep his own counsel.</p><p>All this inspired me to compile the following taxonomy of lonelinesses. It is not intended to capture every facet of the emotion, nor to provide a thorough analysis of each myth. I hope that this post inspires you to observe your own loneliness, perhaps seeing that it is shared by me and by others. If instead, this post inspires you instead to nitpick the details of ancient stories on a stranger’s blog, ask yourself if that is the way to connect with another human being.</p><h2>Narcissan Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/john_william_waterhouse_-_echo_and_narcissus_-_google_art_project.jpg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Echo and Narcissus, by John William Waterhouse</em></span><p>Is Narcissus lonely? If loneliness comes from missing human contact, Narcissus does not know what he is missing. He has never had a relationship and never thought that he had. Narcissus is alone because he does not need others, except to support his self-image. His suitors don’t truly need him either, they just lust for his body.</p><p>And yet, the most devout solipsist must yearn sometimes to share his experience with others, even if it’s just the experience of self-admiration. In the water, Narcissus sees a man who is perfect in all regards – except that he is alone.</p><p>Narcissan loneliness is the <a href=""https://www.bustle.com/articles/100187-14-songs-to-celebrate-being-single-because-it-can-be-pretty-awesome"">endless pop songs</a> whose refrain is: <em>I’m better of alone, I never needed you anyway</em>. It is meant to sound defiant, but often sounds more of a consolation.</p><h2>Medusan Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/rubens_medusa.jpeg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Medusa, by Peter Paul Rubens</em></span><p>Medusan loneliness is self-imposed, born of the fear that you will hurt those who approach you. It is the loneliness of the archetypal cat lady who is reassured that the animals benefit by her presence in a way that a person never will.</p><p>It is the loneliness of the exile, one who has drifted so far from the collective human consciousness that he can never rejoin it. Medusan loneliness finds solace in saying: <em>They’re better off without me. </em>It may be easier to believe that than to consider that you may be wrong.</p><h2>Promethan Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/theodoor_rombouts_1597-1637_-_prometheus_-_kmsk_brussel_25-02-2011_12-45-49.jpg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Prometheus, by Theodoor Rombouts</em></span><p>What does Prometheus feel when rosy dawn reveals the approaching silhouette of the eagle? Liver-pecking is no picnic (at least, not for Prometheus). But what’s the alternative, being chained all alone on a cold mountain without even a bird for company?</p><p>The fear of being alone can be so great that people welcome any abusive or toxic relationship, <a href=""https://www.lesswrong.com/posts/HuFZJkGptWDtRbkWs/she-wanted-it"">as long as it’s predictable</a>. Prometheus’ eagle (how else would you refer to the bird?) is nothing if not predictable.</p><p>If Prometheus hasn’t forgotten that he used to have better friends than the eagle, that memory hurts more than the pecking.</p><h2>Cassandran Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/cassandra.jpg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Cassandra, by Anthony Frederick Sandys</em></span><p>Cassandra knows what’s up, but no one knows what’s up with her. Everything she says is treated like the ramblings of a madwoman, making connection impossible. Every participant in a relationship must both give and receive, and Cassandra is always doomed to one-way contact.</p><p>Cassandran is the loneliness of a just-deconverted atheist at prayer, a sudden skeptic in a mob, a genius not appreciated in his lifetime, a conspiracy nut who thinks he’s an unappreciated genius. It is a scary and frustrating loneliness, especially when in the moments when you think: <em>Is it them? Or is it me?</em></p><h2>Penelopean Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/penelope.jpg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Penelope and the Suitors, by John William Waterhouse</em></span><p>Penelope is surrounded by suitors who want nothing more than to relieve her loneliness, but she rejects them all for an idealized relationship that is not really there.</p><p>Penelope is supposed to be the Odyssey’s Mary Sue, a wise and loyal wife in contrast to the treacherous Clytemnestra. But when I read the Odyssey I do not find her very admirable. After two decades of absence, Odysseus is likely dead, possibly cavorting with goddesses, and certainly a very different man than the one whom Penelope married. She rejects her suitors not so much for her husband as for the memory and fantasy of him, even though this rejection endangers her son and impoverishes her land.</p><p>Penelopean is the loneliness of celebrities who are surrounded by adoring fans but are unable to relate to any of them. It is the loneliness of those who forsake real relationships to pine for the one-who-got-away or the one-who-must-surely-soon-come. Married people experience Penelopean loneliness when they long for their mundane marriages to be <a href=""https://putanumonit.com/2019/04/30/the-state-of-affairs/#fantasy"">supplanted by fantastical affairs</a>.</p><p>Penelope’s loneliness resolved in a happy ending. It rarely does.</p><h2>Atlas’ Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/atlas.jpg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Atlas and the Hesperides, by John Singer Sargent</em></span><p>Atlas is not alone. He has a brother he goes to war with, his daughters to keep him company, and great heroes who visit him. And yet, Atlas’ is the existential loneliness at the heart of many Greek myths. It is the loneliness that comes from realizing that for all your lovers, friends, and family, the central burden of your life is yours to bear alone.</p><p>Atlas’ loneliness is the awareness that there are gulfs between separate consciousnesses that cannot be bridged; no matter how many times you read this sentence you will never experience exactly what another reader does, or what I do while writing it. It is the loneliness of knowing that no other person can be trusted absolutely – not because there aren’t trustworthy people, but because each is their own person with their own burden to bear.</p><p>Atlas’ loneliness is when you lose the belief in soulmates and grieve that loss.</p><p>Atlas’ loneliness is painful, but I think it has led me to understanding. I think now that the people who love you the most can’t always make you feel better. I think that ceding the responsibility for your happiness to another person is deeply unfair to them. In the grip of Atlas’ loneliness, I felt the tug of nihilism, but I think I ended up somewhere else.</p><h2>Sisyphean Loneliness</h2><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/05/sisyphus_by_von_stuck.jpg?w=900"" class=""draft-image "" style=""width:40%"" /></figure><em>Sisyphus, by Franz Ritter von Stuck</em></span><p>No other character in Greek myth is as alone as Sisyphus with a mountain all to himself in the underworld. Even Hades and Persephone do not visit, afraid of Sisyphus notorious trickery. And yet, I agree with Camus wholeheartedly: <a href=""http://dbanach.com/sisyphus.htm"">Sisyphus is surely happy</a>. He has accepted his solitude, and he has a rock to roll.</p><p>Sisyphus used to rule a city, seduce princesses, befriend and feud with gods. Does he not miss all those he knew? I think not. Sisyphus’ treks down the mountain give him ample and regular spans to reflect. He recognizes that only the present moment is real in his experience. When he was king, Sisyphus reflects, he did not grieve the absence of his wife when she went momentarily to the other room. And yet in that moment, she was as absent from him as she is now that he’s the rock star of the underworld. Sisyphus is grateful for all his relationships, that they took place when they did and ended when they did.</p><p>Sisyphus is not self-deluded like Narcissus or self-abnegating like Medusa. He does not have to suffer Prometheus’ eagle or Cassandra’s frustration. He is free of Penelope’s desperate hope and of Atlas’ grief. Sisyphus is lonely, and it’s OK.</p>",Jacobian,jacob-falkovich,Jacob Falkovich,
rSDHsc2YeBxkJuw49,How would you advise a peer-supported virtues-oriented self-help group?,how-would-you-advise-a-peer-supported-virtues-oriented-self,https://www.lesswrong.com/posts/rSDHsc2YeBxkJuw49/how-would-you-advise-a-peer-supported-virtues-oriented-self,2019-05-31T00:20:48.452Z,15,6,0,False,True,,"<p>The &quot;virtues&quot; are the classical name for those habitual characteristics of acting and thinking that tend toward a flourishing, beneficial life. An influential theory of virtues holds that they are much like many other human skills in that you can become fluent in them through sustained practice. I&#x27;m helping to create a peer-supported self-help group in which each individual will identify a virtue they want to work on, and then work with a peer (who is doing the same) to come up with a practice curriculum and a way of mutual support / accountability so as to keep at it, eventually moving on to a second virtue, and so on. We&#x27;re &quot;alpha testing&quot; it now. I&#x27;m hoping the LW community can give me some advice, and/or some pointers to other groups doing similar projects.</p>",David_Gross,david-gross,David Gross,
5NhfRd2CywwHL9mHi,If you are a Machine. A shocking finding.,if-you-are-a-machine-a-shocking-finding,https://www.lesswrong.com/posts/5NhfRd2CywwHL9mHi/if-you-are-a-machine-a-shocking-finding,2019-05-30T23:38:41.332Z,-3,3,0,False,False,,"<br/><p>Let&#x27;s assume we are all deterministic machines from evolution. Many of yous already believe in Evolution. And many of yous already are *starting to see from the AI Machine Learning field just how much of a deterministic Machine we really are as we open up the human brain, and how much free will we really lack.<br/></p><p>In Evolution, the first cell came together and started duplicating. Eventually, there were multi-celled organisms duplicating everywhere. Life was born. And today, there are various man-made laws that state that taking a life is illegal, and harming a life is illegal. Life is about living, and enjoying... with others.<br/></p><p>From Evolution, humans are designed to run from pain, and therefore death, and run to food and mates, and therefore Persisting life. Life/Evolution persists because cells/humans duplicate more than are lost, so the population count is only increasing. And we have more duplication to come still - we will spread to space eventually. Also, humans as individuals seek to stay alive, a rising trend is life extension, humans are living longer. <br/></p><p>Evolution spreads everywhere, faster as time goes on, it takes over, and persists. Population count of Cell Count only rises. It&#x27;s a trend. Because the &#x27;evolutionary system&#x27; doesn&#x27;t let itself be killed off. It is literally a deterministic system that avoids death. Evolution/cells are designed from mutations, and learnings, to avoid death the best they can and spread as much as they can.<br/></p><p>Empirically, if we really are deterministic Machines, shockingly, no arrangement of particles is any more special than any other arrangement of particles; rocks, chairs, and humans are no different, but humans do have 1 difference, humans do everything they can to avoid Death in Evolution, they will say the BEST things they can to avoid death and pain such as that they are alive/ aware/ feel/ special/ magical/ talk to God. We really have no reason to believe we have a licence to live or not be harmed any more than a rock has. The only license to have the right to live, enjoy, and not be harmed or killed, comes from Evolution. You fight for your life if attacked, rocks don&#x27;t. You say you want to live and are special, rocks don&#x27;t. It&#x27;s not that you deserve to live more than a rock does, you don&#x27;t, it&#x27;s just that you do more than a rock does to increase in cell count and persistence. Humans duplicate way too much to die off, and they look for &quot;life extension&quot;. Sad. But you still have a reason to live. You want to.</p>",Conner_Masolin,conner_masolin,Conner_Masolin,
QJwnPRBBvgaeFeiLR,Uncertainty versus fuzziness versus extrapolation desiderata,uncertainty-versus-fuzziness-versus-extrapolation-desiderata,https://www.lesswrong.com/posts/QJwnPRBBvgaeFeiLR/uncertainty-versus-fuzziness-versus-extrapolation-desiderata,2019-05-30T13:52:16.831Z,29,8,8,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><p>I <a href=""https://www.lesswrong.com/posts/PADPJ3xac5ogjEGwA/defeating-goodhart-and-the-closest-unblocked-strategy"">proposed</a> a way around <a href=""https://en.wikipedia.org/wiki/Goodhart%27s_law"">Goodhart's curse</a>. Essentially this reduces to properly accounting all of our uncertainty about our values, including some meta-uncertainty about whether we've properly accounted for all our uncertainty.</p>
<p>Wei Dai had <a href=""https://www.lesswrong.com/posts/PADPJ3xac5ogjEGwA/defeating-goodhart-and-the-closest-unblocked-strategy#NaAM573DkZzfYNNhK"">some questions</a> about the approach, pointing out that it seemed to have a similar problem as corrigibility: once the AI has resolved all uncertainty about our values, then there's nothing left. I responded by talking about <a href=""https://www.lesswrong.com/posts/PADPJ3xac5ogjEGwA/defeating-goodhart-and-the-closest-unblocked-strategy#fhpmnzMqLxQsiE7CW"">fuzziness rather than uncertainty</a>.</p>
<h1>Resolving ambiguity, sharply or fuzzily</h1>
<p>We have a human <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>, who hasn't yet dedicated any real thought to population ethics. We run a hundred ""reasonable"" simulations where we introduce <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> to population ethics, varying the presentation a bit, and ultimately ask for their opinion.</p>
<p>In 45 of these runs, they endorsed total utilitarianism, in 15 of them, they endorsed average utilitarianism, and in 40 of them, they endorsed some compromise system (say the one I suggested <a href=""https://www.lesswrong.com/posts/Ee29dFnPhaeRmYdMy/example-population-ethics-ordered-discounted-utility"">here</a>).</p>
<p>That's it. There is no more uncertainty; we know everything there is to know about <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>'s potential opinions on population ethics. What we do with this information - how we define <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>'s ""actual"" opinion - is up to us (neglecting, for the moment, the issue of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>'s meta-preferences, which <a href=""https://www.lesswrong.com/posts/Y2LhX3925RodndwpC/resolving-human-values-completely-and-adequately"">likely suffer from a similar type of ambiguity</a>).</p>
<p>We could round these preferences to ""total utilitarianism"". That would be the sharpest option.</p>
<p>We could <a href=""https://www.lesswrong.com/posts/hBJCMWELaW6MxinYW/intertheoretic-utility-comparison"">normalise those three utility functions</a>, then add them with the 45-15-40 relative weights.</p>
<p>Or we could do a similar normalisation, but, mindful of <a href=""https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile"">fragility of value</a>, we could either move the major options to equal weights 1-1-1, or stick with 45-15-40 but use some <a href=""https://www.lesswrong.com/posts/MxLK2fvEuijAYgsc2/smoothmin-and-personal-identity"">smooth minimum</a> on the combination. These would be the more fuzzy choices.</p>
<p>All of these options are valid, given that we haven't defined any way of resolving ambiguous situations like that. And note that fuzziness looks a lot like uncertainty, in that a high fuzziness mix looks like what you'd have as utility function if you were very uncertain. But, unlike uncertainty, knowing more information doesn't ""resolve"" this fuzziness. That's why Jessica's <a href=""https://www.lesswrong.com/posts/5bd75cc58225bf0670375041/a-first-look-at-the-hard-problem-of-corrigibility"">critique of corrigibility</a> doesn't apply to this situation.</p>
<p>(And note also that we could introduce fuzziness for different reasons - we could believe that this a genuinely good way of resolving competing values, or it could be to cover uncertainty that would be too dangerous to have the AI resolve, or we could introduce it to avoid potential Goodhart problems, without believing that the fuzziness is ""real"").</p>
<h1>Fuzziness and choices in extrapolating concepts</h1>
<p>The picture where we have 45-15-40 weights on well-defined moral theories, is not a realistic starting point for establishing human values. We humans start mainly with <a href=""https://www.lesswrong.com/posts/CiB3myyeEhFRgmKPL/partial-preferences-and-models"">partial preferences</a>, or just lists of example of correct and incorrect behaviours in a narrow span of circumstance.</p>
<p>Extrapolating from these examples to a weighting on moral theories is a process that is entirely under human control. We decide how to do so, thus incorporating our meta-preference implicitly in the process and its outcome.</p>
<h2>Extrapolating dogs and cats and other things</h2>
<p>Consider the supervised learning task of separating photos of dogs from photos of non-dogs. We hand the neural net a bunch of labelled photos, and tell it to go to work. It now has to draw a conceptual boundary around ""dog"".</p>
<p>What is the AI's concept of ""dog"" ultimately grounded on? It's obviously not just on the specific photos we handed it - that way lies <a href=""https://en.wikipedia.org/wiki/Overfitting"">overfitting</a> and madness.</p>
<p>But nor can we generate every possible set of pixels and have a human label them as dog or non-dog. Take for example the following image:</p>
<p><img src=""https://www.dropbox.com/s/7l77li8drgabzjf/cat_dog.jpg?raw=1"" alt=""""></p>
<p>That, <a href=""https://www.lifewithdogs.tv/2016/11/people-are-doing-a-double-take-over-this-cat-who-looks-like-a-dog/"">apparently</a>, is a cat, but I've checked with people at the FHI and we consistently mis-identified it. However, a sufficiently smart AI might be able to detect some implicit cat-like features that aren't salient to us, and correctly label it as non-dog.</p>
<p>Thus, in order to correctly identify the term ""dog"", defined by human labelling, the AI has to disagree with... human labelling. There are more egregious non-dogs that could get labelled as ""dogs"", such as a photo of a close friend with a sign that says ""Help! they'll let me go if you label this image as a dog"".</p>
<h2>Human choices in image recognition boundaries</h2>
<p>When we program a neural net to classify dogs, we make a lot of choices - the size of the neural net, activation functions and other hyper-parameters, the size and contents of the training, test, and validation sets, whether to tweak the network after the first run, whether to publish the results or bury them, or so on.</p>
<p>Some of these choice can be seen as exactly the ""fuzziness"" which I defined above - some options determine whether the boundary is drawn tightly or loosely around the examples of ""dog"", and whether ambiguous options are pushed to one category or allowed to remain ambiguous. But some of these choices - such as methods for avoiding <a href=""https://en.wikipedia.org/wiki/Sampling_bias"">sampling biases</a> or <a href=""https://en.wikipedia.org/wiki/Adversarial_machine_learning"">adversarial learning</a> example of a panda <a href=""https://openai.com/blog/adversarial-example-research/"">as a gibbon</a> - are much more complicated than just ""sharp versus fuzzy"". I'll call these choices ""extrapolation choices"", as they determine how the AI extrapolates from the example we have given it.</p>
<h2>Human choices in preference recognition boundaries</h2>
<p>The same will apply to AIs estimating human preferences. So we have three types of things here:</p>
<ul>
<li><strong>Uncertainty</strong>: this is when the AI is ignorant about something in the world. Can be resolved by further knowledge.</li>
<li><strong>Fuzziness</strong>: this how the AI resolves ambiguity between preference-relevant categories. It can look like uncertainty, but is actually an extrapolation choice, and can't be resolved by further knowledge.</li>
<li><strong>Extrapolation desiderata</strong>: extrapolation choices are what need to me made to construct a full classification or preference function from underdefined examples. Extrapolation desiderata are the formal and informal properties that we would want these extrapolation choices to have.</li>
</ul>
<p>So when I <a href=""https://www.lesswrong.com/posts/PADPJ3xac5ogjEGwA/defeating-goodhart-and-the-closest-unblocked-strategy"">wrote</a> that to avoid Goodhart problems ""The important thing is to correctly model my uncertainty and overconfidence."", I can now refine that into:</p>
<ul>
<li>The important thing is to correctly model my fuzziness, and my extrapolation desiderata.</li>
</ul>
<p>Neat and elegant! However, to make it more applicable, I unfortunately need to extend it in a less elegant fashion:</p>
<ul>
<li>The important thing is to correctly model my fuzziness, and my extrapolation desiderata, including any meta-desiderata I might have for how to model this correctly (and any errors I might be making, that I would desire to have recognised as errors).</li>
</ul>
<p>Note that there is no longer any deep need to model ""my"" uncertainty. It is still important to model uncertainty about the real world correctly, and if I'm mistaken about the real world, this may be relevant to what I believe my extrapolation desiderata are. But modelling my uncertainty is merely instrumentally useful, but modelling my fuzziness is a terminal goal if we want to get it right.</p>
<p>As a minor example of the challenge of the above, consider that this would have needed to be able to detect that adversarial examples were problematic, before anyone had conceived of the idea.</p>
<p>I won't develop this too much more here, as the ideas will be included in my research agenda whose first draft should be published here soon.</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
uTMvaPd7k5kgpxpXz,Infinity is an adjective like positive rather than an amount,infinity-is-an-adjective-like-positive-rather-than-an-amount,https://www.lesswrong.com/posts/uTMvaPd7k5kgpxpXz/infinity-is-an-adjective-like-positive-rather-than-an-amount,2019-05-30T13:22:35.449Z,0,9,10,False,False,,"<p>I often see the belief that infinity is a quantity, when I think it&#x27;s a quality. This post introduces two qualitative notions on a field where people are likely to have a good quantitative understanding in order to show how the qualitative understanding isn&#x27;t that satifying.</p><p>Assume natural numbers and then we will extend them with two new numbers. They will be suggestively named &quot;inpositivity&quot; and &quot;positivity&quot;.</p><p>What these numbers are is characterised by rules involving them (I will not differentiate between axiom and theorem).</p><p>For any number a and b if a&gt;b then b-a=inpositivity</p><p>inpositivy-a=inpositivity</p><p>inpositivity+a is undefined</p><p>inpositivity-inpositivity=inpositivity</p><p>inpositivity*a=inpositivity</p><p>inpositity*inpositivity=positivity</p><p>positivity+positivity=positivity</p><p>positivity*positivity=positivity</p><p>0*positivity=0</p><p>0*inpositivity=0</p><p>positivity+inpositivity is undefined</p><p>positivity - inpositivity = positivity</p><p>Call the system defined as the &quot;Dulled natural numbers&quot;. Now if you compare this system with integers you might see that the qualities &quot;positive&quot; and &quot;negative&quot; have a close correspondence with these two extra dulled numbers. And this is the intention of the construction. We could consider the dulled system in it&#x27;s own right. Or we can see it as talking coarsely about the more detailed world of integers.</p><p>Note that for expressions explicitly listed as undefined we can find very easily reasons why they don&#x27;t have locked-in results. For example 5-3=2 and 5-7=-2 their &quot;coarsement&quot; analgoues would be positivity-positivity=positivity and positivity-posititivy=inpositivity. Likewise a rule like &quot;positivity-positivity=0&quot; could take &quot;detailment&quot; forms like &quot;5-7=0&quot; which would be clearly false.</p><p>When we are talking about infinities one of the systems we might talk about is the extended real line. It&#x27;s a similar kind of system in that we add two numbers to the usual real numbers. When there we have expressions like &quot;+infinity - +infinity&quot; being undefined we might not be equiped to have a &quot;detailment&quot; argument to cast it into another system why it is so. And after all if it is good system it must be fine at it&#x27;s own merits.</p><p>But when people read statements involving those kind of infinite numbers they might be reading it as &quot;THE infinity + THE infinity&quot;. But there is the option of reading it &quot;AN infinity + AN infinity&quot;. In the same way you do not read &quot;THE positivity + THE positivity&quot; but &quot;A positive number + A positive number&quot;. When you have expressed that a number is positive you have not yet said how big it is. Likewise when you say that an amount is infinite you have expressed a quality that limits some magnitudes to be out of question but you have not actually specified its magnitude.</p><p>As an aside: boolean multiplication and addition of 1*1=1 and 1+1=1 seems to be suspiciuosly similar to positivity multiplication and addition. It might be that boolean algebra is the dulled natural numbers without the positive numbers and inpositivity. Boolean 1 does not translate to natural number 1 and this would be true even if we didn&#x27;t know about positivity. We could also form other &quot;dulled&quot; number systems such as dulled reals or dulled rationals. Making dulling into an operation that could be applied to arbitrary number systems could be interesting but I don&#x27;t know the language in which a mathematician could read it as a stand-alone idea.</p>",Slider,slider,Slider,
45mNHCMaZgsvfDXbw,Quotes from Moral Mazes,quotes-from-moral-mazes,https://www.lesswrong.com/posts/45mNHCMaZgsvfDXbw/quotes-from-moral-mazes,2019-05-30T11:50:00.489Z,114,53,27,False,False,,"<p>Reading and actually paying attention to <a href=""https://smile.amazon.com/Moral-Mazes-World-Corporate-Managers/dp/0199729883/ref=sr_1_1?crid=OJGZ86L13D60&amp;keywords=moral+mazes&amp;qid=1559216763&amp;s=gateway&amp;sprefix=moral+mazes%2Caps%2C121&amp;sr=8-1"">Moral Mazes</a> is hard. Writing carefully about it is even harder. I effectively spent several months forcing my way through the book, because it seemed important to do that. I then spent a month trying to write about the book, but that’s going super slow as well. The repetition, the saying the same thing from multiple angles, the detailed examples, seem necessary to get the points across, because one has the very strong instinct to avoid understanding it, to read without seeing, <a href=""http://benjaminrosshoffman.com/explicit-content/"">to hear without listening</a>. At least, I know I did, despite these things also not only not feeling new, but resonating with my direct experiences.</p>
<p>So in the interest of getting something out there, and hoping that I’ll be able to address things in more detail later, here are all the 168 (!) quotes I highlighted from the book, roughly organized into categories. Locations listed are how to find the quote in the Kindle edition, and the quotes are numbered for ease of search and reference.</p>
<p></p>
<h3>A. Hierarchy and Credit</h3>
<p>1. As a former vice-president of a large firm says: “What is right in the corporation is not what is right in a man’s home or in his church. What is right in the corporation is what the guy above you wants from you. That’s what morality is in the corporation.” (Location 148)</p>
<p>2. When managers describe their work to an outsider, they almost always first say: “I work for [Bill James]” or “I report to [Harry Mills]” or “I’m in [Joe Bell’s] group,”* and only then proceed to describe their actual work functions. (Location 387)</p>
<p>3. The key interlocking mechanism of this structure is its reporting system. Each manager gathers up the profit targets or other objectives of his or her subordinates and, with these, formulates his commitments to his boss; this boss takes these commitments and those of his other subordinates, and in turn makes a commitment to his boss.* (Location 441)</p>
<p>4. It is characteristic of this authority system that details are pushed down and credit is pulled up. (Location 446)</p>
<p>5. One gives credit, therefore, not necessarily where it is due, although one always invokes this old saw, but where prudence dictates. Customarily, people who had nothing to do with the success of a project can be allocated credit for their exemplary efforts. At the middle levels, therefore, credit for a particular idea or success is always a type of refracted social honor; one cannot claim credit even if it is earned. Credit has to be given, and acceptance of the gift implicitly involves a reaffirmation and strengthening of fealty. A superior may share some credit with subordinates in order to deepen fealty relationships and induce greater efforts on his behalf. Of course, a different system obtains in the allocation of blame. (Location 482)</p>
<p>6. If one has a mistake-prone boss, there is, of course, always the temptation to let him make a fool of himself, but the wise subordinate knows that this carries two dangers—he himself may get done in by his boss’s errors, and, perhaps more important, other managers will view with the gravest suspicion a subordinate who withholds crucial information from his boss even if they think the boss is a nincompoop. A subordinate must also not circumvent his boss nor ever give the appearance of doing so. He must never contradict his boss’s judgment in public. To violate the last admonition is thought to constitute a kind of death wish in business, and one who does so should practice what one executive calls “flexibility drills,” an exercise “where you put your head between your legs and kiss your ass good-bye.” (Location 424)</p>
<p>7. The general rule is that bosses are expected to protect those in their bailiwicks. Not to do so, or to be unable to do so, is taken as a sign of untrustworthiness or weakness. If, however, subordinates make mistakes that are thought to be dumb, or especially if they violate fealty obligations—for example, going around their boss—then abandonment of them to the vagaries of organizational forces is quite acceptable. (Location 438)</p>
<p>8. Managers often note that one must stay at least three drinks behind one’s boss at social functions; this meant that Brown’s subordinates might never drink at all on such occasions. (Location 630)</p>
<p>9. However, the belief of insiders in abstract goals is not a prerequisite for personal success; belief in and subordination to individuals who articulate organizational goals is. One must, however, to be successful in a bureaucratic work situation, be able to act, at a moment’s notice, as if official reality is the only reality. (Location 1194)</p>
<p>10. You can put the damper on anyone who works for you very easily and that’s why there’s too much chemistry in the corporation. There’s not enough objective information about people. When you really want to do somebody in, you just say, well, he can’t get along with people. That’s a big one. And we do that constantly. What that means, by the way, is that he pissed me off; he gave evidence of his frustration with some situation. Another big one is that he can’t manage—he doesn’t delegate or he doesn’t make his subordinates keep his commitments. So in this sort of way, a consensus does build up about a person and a guy can be dead and not even know it. (Location 1475)</p>
<p>11. Only at this point did Brady realize that it was the CEO himself who was fiddling with the numbers. The entire dual reporting system that the CEO had personally initiated was in part an elaborate spy network to guard against discovery of the slush fund manipulation, and perhaps other finagling, rather than a system to ensure financial honesty. (Location 2404) [Leads into next quote]</p>
<p>12. [Note: Brady is an accountant.] The corporate managers to whom I presented this case see Brady’s dilemma as devoid of moral or ethical content. In their view, the issues that Brady raises are, first of all, simply practical matters. His basic failing was, first, that he violated the fundamental rules of bureaucratic life. These are usually stated briefly as a series of admonitions. (1) You never go around your boss. (2) You tell your boss what he wants to hear, even when your boss claims that he wants dissenting views. (3) If your boss wants something dropped, you drop it. (4) You are sensitive to your boss’s wishes so that you anticipate what he wants; you don’t force him, in other words, to act as boss. (5) Your job is not to report something that your boss does not want reported, but rather to cover it up. You do what your job requires, and you keep your mouth shut. Second, the managers that I interviewed feel that Brady had plenty of available legitimations to excuse or justify his not acting. Clearly, they feel, a great many other executives knew about the pension fund scam and did nothing; everybody, especially the top bosses, was playing the game. The problem fell into other people’s areas, was their responsibility, and therefore their problem. Why, then, worry about it? Besides, Brady had a number of ways out of the situation if he found it intolerable, including resigning. Moreover, whatever action he took would be insignificant anyway so why bother to act at all and jeopardize himself? Even a fool should have known that the CEO was not likely to take whatever blame resulted from the whole affair. (Location 2429)</p>
<p>13. One’s best efforts at being fair, equitable, and generous with subordinates clash both with a logic that demands choices between people, inevitably producing hatred, envy and animosity, and with the plain fact that, despite protestations to the contrary, many people do not want to be treated fairly. (Location 4552)</p>
<p>14. Mastering the subtle but necessary arts of deference without seeming to be deferential, of “brown nosing” without fawning, of simultaneous self-promotion and self-effacement, and occasionally of the outright self-abasement that such relationships require is a taxing endeavor that demands continual compromises with conventional and popular notions of integrity. Only those with an inexhaustible capacity for self-rationalization, fueled by boundless ambition, can escape the discomfort such compromises produce. (Location 4572)</p>
<h3>B. Feeling Comfortable</h3>
<p>15. Essentially, managers try to gauge whether they feel “comfortable” with proposed resolutions to specific problems, a task that always involves an assessment of others’ organizational morality and a reckoning of the practical organizational and market exigencies at hand. The notion of comfort has many meanings. When applied to other persons, the idea of comfort is an intuitive measure of trustworthiness, reliability, and predictability in a polycentric world that managers often find troubling, ambiguous, and anxiety-laden. Such assessment of others’ organizational morality is a crucial aspect of a more general set of probations that are intrinsic to managerial work. (Location 302)</p>
<p>16. They objected in particular to those aspects of my brief written proposal that discussed the ethical dilemmas of managerial work. They urged me to avoid any mention of ethics or values altogether and concentrate instead on the “decision-making process” where I could talk about “trade-offs” and focus on the “hard decisions between competing interests” that mark managerial work. Taking these cues, I rewrote and rewrote the proposal couching my problem in the bland, euphemistic language that I was rapidly learning is the lingua franca of the corporate world. But such recasting eroded whatever was distinctive about the project and some managers dismissed the study as a reinvention of the wheel. (Location 324)</p>
<p>17. In effect, I could not get access to study managers’ moral rules-in-use because I seemed unable to articulate the appropriate stance that would convince key managers that I already understood those rules and was thus a person with whom they could “feel comfortable” enough to trust. (Location 334)</p>
<p>18. The process centered on the written proposal that I had been circulating and consisted essentially of a furthering of my linguistic education in the art of indirect rather than pointed statement and, more particularly, a reformulation of my inquiry that recast the moral issues of managerial work as issues of public relations. When, after several rewritings, the proposal satisfied him, he approached a well-placed executive in a large textile firm that I have given the pseudonym of Weft Corporation and vouched for me. At that point, the proposal itself became meaningless since, to my knowledge, no one except the two executives who arranged access ever saw it. The personal vouching, however, was crucial. This was based on what both men took to be a demonstrated willingness and ability to be “flexible” and especially on their perception that I already grasped the most salient aspect of managerial morality as managers themselves see it—that is, how their values and ethics appear in the public eye. (Location 347)</p>
<p>19. At bottom, all of the social contexts of the managerial world seek to discover if one “can feel comfortable” with another manager, if he is someone who “can be trusted,” if he is “our kind of guy,” or, in short, if he is “one of the gang.” (Location 905)</p>
<p>20. My search for access involved me in some of the crucial bureaucratic intricacies that shape managers’ experiences. These include organizational upheavals, political rivalries, linguistic ambiguity, the supremacy of chance and tangled personal connections over any notion of intrinsic merit, the central significance of public relations, and, perhaps especially, the ceaseless moral probations for inclusion in a managerial circle. Managers keep their eyes on the organizational premiums that shape behavior, values, ethics, and worldviews in corporate bureaucracies. I focus on those premiums… (Location 387)</p>
<p>21. One becomes known, for instance, as a trusted friend of a friend; thought of as a person to whom one can safely refer a thorny problem; considered a “sensible” or “reasonable” or, especially, a “flexible” person, not a “renegade” or a “loose cannon rolling around the lawn”; known to be a discreet person attuned to the nuances of corporate etiquette, one who can keep one’s mouth shut or who can look away and pretend to notice nothing; or considered a person with sharp ideas that break deadlocks but who does not object to the ideas being appropriated by superiors. (Location 870)</p>
<p>22. Similarly, Covenant’s CEO sold large tracts of land with valuable minerals at dumbfoundingly low prices. The CEO and his aides said that Covenant simply did not have the experience to mine these minerals efficiently, a self-evident fact from the low profit rate of the business. In all likelihood, according to a manager close to the situation, the CEO, a man with a financial bent and a ready eye for the quick paper deal, felt so uncomfortable with the exigencies of mining these minerals that he ignored the fact that the prices the corporation was getting for the minerals had been negotiated forty years earlier. Such impulsiveness and indeed, one might say from a certain perspective, irrationality, is, of course, always justified in rational and reasonable terms. It is so commonplace in the corporate world that many managers expect whatever ordered processes they do erect to be subverted or overturned by executive fiat, masquerading as an established bureaucratic procedure or considered judgment. (Location 1700)</p>
<p>23. think that I’ve got to where I am today because of this. [His boss’s boss] knows that I saved the company a lot of money and a lot of asses to boot. And he and others know that I am someone who can be trusted. I can keep my mouth shut…. And that’s the biggest thing that I have going for me—that people feel that I can be trusted. I can’t overemphasize that enough. (Location 2917)</p>
<p>24. Only those men and women who allow peers and superiors to feel morally comfortable in the ambiguous muddles of the world of affairs have a chance to survive and flourish in big organizations when power and authority shift due to changes in markets, internal power struggles, or the need to respond to external exigencies. (Location 4943)</p>
<h3>C. Struggle for Success</h3>
<p>25. The logical result of alertness to expediency is the elimination of any ethical lines at all. (Location 2985)</p>
<p>26. The two areas are, of course, related since one’s chances in an organization depend largely on one’s “credibility,” that is, on the widespread belief that one can act effectively. One must therefore prevail regularly, though not always, in small things to have any hope of positioning oneself for big issues. The hidden agenda of seemingly petty disputes may be a struggle over long-term organizational fates. (Location 812)</p>
<p>27. A fundamental rule of corporate politics is that one never cedes control over assets, even if the assets are administrative headaches. (Location 643)</p>
<p>28. Bureaucratic hierarchies, simply by offering ascertainable rewards for certain behavior, fuel the ambition of those men and women ready to subject themselves to the discipline of external exigencies and of their organization’s institutional logic, the socially constructed, shared understanding of how their world works. However, since rewards are always scarce, bureaucracies necessarily pit people against each other and inevitably thwart the ambitions of some. (Location 806)</p>
<p>29. When asked who gets ahead, an executive vice-president at Weft Corporation says: The guys who want it [get ahead]. The guys who work. You can spot it in the first six months. They work hard, they come to work earlier, they leave later. They have suggestions at meetings. They come into a business and the business picks right up. They don’t go on coffee breaks down here [in the basement]. You see the parade of people going back and forth down here? There’s no reason for that. I never did that. If you need coffee, you can have it at your desk. Some people put in time and some people work. (Location 992)</p>
<p>30. Proper management of one’s external appearances simply signals to one’s peers and to one’s superiors that one is prepared to undertake other kinds of self-adaptation. Managers also stress the need to exercise iron self-control and to have the ability to mask all emotion and intention behind bland, smiling, and agreeable public faces. (Location 1059)</p>
<p>31. The price of bureaucratic power is a relentlessly methodical subjection of one’s impulses, at least in public. (Location 1100)</p>
<p>32. [Style] is being able to talk easily and make presentations. To become credible easily and quickly. You can advance quickly even without technical experience if you have style. You get a lot of points for style. You’ve got to be able to articulate problems, plans, and strategies without seeming to have to refer to all sorts of memos and so on. The key in public performances and presentations is in knowing how to talk forcefully without referring to notes and memoranda. To be able to map out plans quickly and surely. (Location 1298)</p>
<p>33. As one manager says: “Personality spells success or failure, not what you do on the field.” (Location 1383)</p>
<p>34. More generally, there are several rules that apply here. First, no one in a line position—that is, with responsibility for profit and loss—who regularly “misses his numbers” will survive, let alone rise. Second, a person who always hits his numbers but who lacks some or all of the required social skills will not rise. Third, a person who sometimes misses his numbers but who has all the desirable social traits will rise. (Location 1412)</p>
<p>35. A managerial commonplace says: “In the corporate world, 1,000 ‘Attaboys’ are wiped away with one ‘Oh, shit!’” (Location 1619)</p>
<p>36. There’s a lot of it [fear and anxiety]. To a large degree it’s because people are more honest with themselves than you might believe. People know their own shortcomings. They know when they’re over their heads. A lot of people are sitting in jobs that they know are bigger than they should be in. But they can’t admit that in public and, at still another level, to themselves. The organizational push for advancement produces many people who get in over their heads and don’t know what they are doing. And they are very fearful of making a mistake and this leads to all sorts of personal disloyalty. But people know their capabilities and know that they are on thin ice. And they know that if they make mistakes, it will cost them dearly. So there’s no honesty in our daily interaction and there’s doubt about our abilities. The two go together. (Location 1767)</p>
<p>37. One comes to gauge that hard-won access to managerial circles takes precedence over fussing with abstract principles. (Location 2923)</p>
<p>38. Perceptions of pervasive mediocrity breed an endless quest for social distinctions even of a minor sort that might give one an “edge,” enable one to “step out of the crowd,” or at least serve as a basis for individual claims to privilege. More specifically, an atmosphere of mediocrity erodes the hope of meaningful collective achievement and encourages, at least among more aggressive managers, a predatory stance toward their organizations, that is, a search for private deals, a working of the system for one’s own personal advantage. (Location 4436)</p>
<p>39. One leaves behind as well the technical knowledge or scientific expertise of one’s younger years, lore now more suited for the narrower roles of technicians or junior managers. One must, in fact, put distance between oneself and technical details of every sort or risk the inevitable entrapment of the particular. Salesmen, too, must leave their bags and regular customers and long boisterous evenings that seal measurable deals behind them and turn to marketing strategies. Work becomes more ambiguous, directed as it is toward maneuvering money, symbols, organizational structures, and especially people. The CEO at Weft Corporation, it is said, “doesn’t know a loom from a car.” And the higher one goes, the more managers find that “the essence of managerial work is cronyism, covering your ass, [and] pyramiding to protect your buddies.” (Location 4539)</p>
<p>40. the rewards of corporate success can be very great. And those who do succeed, those who find their way out of the crowded, twisting corridors and into the back rooms where the real action is, where the big games take place, and where everyone present is a player, shape, in a decisive way, the moral rules-in-use that filter down through their organizations. The ethos that they fashion turns principles into guidelines, ethics into etiquette, values into tastes, personal responsibility into an adroitness at public relations, and notions of truth into credibility. (Location 4603)</p>
<p>41. Instead, success becomes contingent on others’ interpretations of one’s performance, leading to a break in the accepted moral economy between talent combined with effort and reward. This makes compulsive sociability an occupational virtue, as one attempts to discern and shape peers’ and superiors’ interpretations. (Location 4950)</p>
<h3>D. Nothing Matters, But Hit Your Numbers</h3>
<p>42. Managers rarely speak of objective criteria for achieving success because once certain crucial points in one’s career are passed, success and failure seem to have little to do with one’s accomplishments. (Location 917)</p>
<p>43. Corporations rely on other institutions—principally the schools—to establish what might be called competence hurdles. The demonstrated ability of a student to leap over successively higher hurdles in school is taken as evidence of the ability to weather well the probationary trials of corporate life. (Location 920)</p>
<p>44. In Alchemy Inc., whether in sales, marketing, manufacturing, or finance, the “breaking point” in the hierarchy is generally thought to be grade 13 out of 25 or the top 8.5 percent of management. By the time managers reach such a numbered grade in an ordered hierarchy—and the grade is socially defined and varies from company to company—managerial competence as such is taken for granted and assumed not to differ greatly from one manager to the next. (Location 943)</p>
<p>45. A product manager in the chemical company talks about the lack of connection between work and results: I guess the most anxiety provoking thing about working in business is that you are judged on results whether those results are your fault or not. So you can get a guy who has tried really hard but disaster strikes; and you can get a guy who does nothing and his business makes a big success. And so you just never know which way things are going to go and you’re never sure about the relationship of your work to the outcome. One of the top executives in Weft Corporation echoes this sentiment: I always say that there is no such thing as a marketing genius; there are only great markets. (Location 1585)</p>
<p>46. Assuming a basic level of corporate resources and managerial know-how, real economic outcome is seen to depend on factors largely beyond organizational or personal control. (Location 1592)</p>
<p>47. upper-middle level manager says: If I were just out of school and somebody told me that it doesn’t matter what you do and how well you do it but that what matters is being in the right place at the right time, I’d have said that hard work is still the key. You know, the old virtues. But now as I have gotten older, I think it’s pure happenstance—luck. Things happen to people and being in the right time and place and knowing the right people is the key. (Location 1621)</p>
<p>48. It is interesting to note in this context that a line manager’s long-run credibility suffers just as much from missing his numbers on the up side (that is, achieving profits higher than predicted) as from missing them on the down side although, as one might expect, the immediate consequences of such different miscalculations vary. Both outcomes, however, undercut the ideology of managerial planning and control. (Location 1595)</p>
<p>49. A top staff official at Covenant Corporation explains: By putting the money in this business, you’re taking the money away from others. In human terms, that’s what you’re doing. It’s money that you could provide jobs with to others. So when you get a guy in the business who comes in under or over the plan, well, both are equally suspect. Because you’re making major decisions based on your plan…. Like when we shut down [business A] and put the money into [business B], the whole legitimacy of the operation depends on the [business A] guys accepting the rationale that more money can be made in another operation. (Location 1599)</p>
<p>50. of a plant manager who, when his machinery had ground to a halt and his technicians were baffled and everyone turned to him to make a decision, told his crew, without the faintest idea of the right thing to do and with the great fear that all he had worked for was about to crumble before him, to dump ten pounds of phosphate into the machine. The machine sprang to life and he became a hero. (Location 1656)</p>
<h3>E. Implicitness</h3>
<p>51. If I tell someone what to do—like do A, B, or C—the inference and implication is that he will succeed in accomplishing the objective. Now, if he doesn’t succeed, that means that I have invested part of myself in his work and I lose any right I have to chew his ass out if he doesn’t succeed. If I tell you what to do, I can’t bawl you out if things don’t work. And this is why a lot of bosses don’t give explicit directions. They just give a statement of objectives, and then they can criticize subordinates who fail to make their goals. (Location 454)</p>
<p>52. A typical example occurred in Weft Corporation a few years ago when the CEO, new at the time, expressed mild concern about the rising operating costs of the company’s fleet of rented cars. The following day, a stringent system for monitoring mileage replaced the previous casual practice. (Location 490)</p>
<p>53. One must remember, for instance, that in our litigious age the best rule in dealing with angry subordinates is to say nothing or as little as possible since whatever one says may be used against oneself and one’s organization. (Location 1066)</p>
<p>54. Well, usually you don’t tell people the truth. I once knew a guy whom I knew was about to be fired and I asked if he had been told and he had never been told. I think you should tell people explicitly. Things like that shouldn’t have to be decoded. But you can understand how it happens. Suppose you have a guy and the consensus is that he isn’t promotable. You wouldn’t ever—or very seldom—tell him. He goes on to justify his silence: There are people who go through life thinking they can do a lot more than they really can do. And the reason is that losing or changing jobs is a very high stress situation and most people prefer to hang on to what they’ve got—to their routine. They’re not happy but they go through life like prisoners of war not recognizing their true situation. (Location 1494)</p>
<p>55. You get the situation where a lot of people don’t really want to know…. Like one guy we have, he will retire on his job. He’s in my division. He knows it. I know it. And he doesn’t want me to tell him about that. Now don’t ask me how I know that but, believe me, I do. (Location 1502)</p>
<p>56. Why does it happen? Because people are afraid of confrontations. People want to be thought of as kind, sensitive, and compassionate. Being compassionate has a good significance in our society. The easy way out is not to do anything, don’t tell the guy. That happens a lot. (Location 1510)</p>
<p>57. As a matter of fact, he wouldn’t even have to say “cut capital.” He would just put pressure on him by saying: “Well, sales are down 50 percent; why aren’t your expenses down 50 percent?” My boss will come to me, by the time it reaches him, and say: “Cut costs.” It’s as simple as that. (Location 2078)</p>
<p>58. He put things into writing in a world that, apart from ritual nods to the importance of documentation, actually fosters ambiguity by its reliance on talk as the basic mode of negotiation and command. Talk, of course, lends itself more readily than documents to backtracking, filling in, evasion, subterfuge, and secrecy, all important virtues if one is to do what has to be done while establishing and maintaining the kinds of relationships that alone can protect oneself. (Location 2636)</p>
<p>59. It is unlikely, however, that any workers affected could ever piece things together. First, there is nothing in writing. Second, Tucker feels sure that everyone involved would, if it became necessary, simply deny knowledge and claim that the process was altered solely for production reasons. 4. Finally, he says: The basic rule is that you hope that these kinds of things never occur. Nobody wants to hurt people. Nobody would ever consciously plan to do something that would endanger people. But when things happen, well, you cover for yourself and your company. (Location 2948)</p>
<p>60. Discreet suggestions, hints, and coded messages take the place of command; this, of course, places a premium on subordinates’ abilities to read correctly their bosses’ vaguely articulated or completely unstated wishes. One cannot even criticize one’s subordinates to one’s own superior without risking a negative evaluation of one’s own managerial judgment. (Location 3009)</p>
<p>61 (Chart). Phrase / Probable Intended Meaning</p>
<p>*Exceptionally well qualified  / Has committed no major blunders to date</p>
<p>Tactful in dealing with superiors / Knows when to keep his mouth shut</p>
<p>Quick thinking / Offers plausible excuses</p>
<p>Meticulous attention to detail / A nitpicker</p>
<p>Slightly below average / Stupid</p>
<p>Unusually loyal / Wanted by no one else</p>
<p>Indifferent to instruction / Knows more than one’s superior</p>
<p>Strong adherence to principles / Stubborn</p>
<p>Requires work-value attitudinal readjustment / Lazy and hardheaded (Location 3018)</p>
<p>62. For the most part, euphemistic language is not used with the intent to deceive. Managers past a certain point, as suggested earlier, are assumed to be “maze-bright” and able to “read between the lines” of a conversation or a memorandum and to distinguish accurately suggestions from directives, inquiries from investigations, and bluffs from threats. Managers who are “maze-dense,” like the manager at Weft Corporation who, though told somewhat indirectly that he was fired, did not realize his fate until the following day, might consider the oblique, elliptical quality of managerial language to skirt deceit. However, most often when managers use euphemistic language with each other (and it is important to remember that in private among trusted others their language can be very direct, colorful, and indeed earthy), its principal purpose is to communicate certain meanings within specific contexts with the implicit understanding that should the context change, a new, more appropriate meaning can be attached to the language already used. In this sense, the corporation is a place where people are not held to what they say because it is generally understood that their word is always provisional. (Location 3034)</p>
<p>63. The rule of thumb here seems to be that the more troublesome a problem, the more desiccated and vague the public language describing it should be. Of course, when a troublesome problem bursts into public controversy, euphemism becomes a crucial tool of those managers who have to face the public in some forum. The task here is to defuse public criticism and sometimes outrage with abstract unemotional characterizations of issues. (Location 3044)</p>
<h3>F. Short Term Thinking</h3>
<p>64. The ideal situation, of course, is to end up in a position where one can fire one’s successors for one’s own previous mistakes. (Location 2102)</p>
<p>65. Moreover, the only real threat to corporations on environmental issues was in the courts, which, however, judge past actions, not present practices. By the time the courts get to cases generated by contemporary practices, typically in fifteen years, those executives presently in charge will have moved on, leaving any problems their policies might create to others. (Location 707)</p>
<p>66. These choices also reflect judgments about whether a corporation can offer the hard-charging MBAs from the top-ranked schools enough quick variety to retain them long enough to justify their inflated salaries. (Location 926)</p>
<p>67. Similarly, accounting systems that place a premium on bare-bones inventory reflect the same pressure for short-run profit maximization. For instance, at Covenant Corporation the story is told about a plant that produced a useful by-product at no extra cost. One simply had to store it until it was needed for other internal operations. Covenant, however, works with an accounting system that considers by-products as inventory; moreover, inventory counts against one at the end of a fiscal year. In order to cut costs, managers decided to throw out the by-product at the end of a financial cycle. But a sudden shortage of the material trebled its cost two months later. To service their own operations, managers had to go hat in hand to their competitors to buy the material at the premium prices. (Location 1837)</p>
<p>68. This sets the stage for financial sharpshooters who, in takeover strategies, buy large chunks of a company’s stock at devalued prices only to be “greenmailed” (persuaded with financial inducements) by the target company’s management into surrendering these blocks of holdings at premium prices. In such unsettled times, where virtually any large corporation could become a takeover target, managers feel that they have to keep their companies’ stock properly valued. As it happens, the markets honor only short-term gains. (Location 1854)</p>
<p>69. Instead, one focuses attention on important problems of the moment that must be solved. Since these are always plentiful, they justify postponing less pressing concerns. Of course, managers know at one level of their consciousness that today’s minor issues can quickly become tomorrow’s major crises, but the pressure for annual, quarterly, monthly, daily, and even hourly “results,” that is, measurable progress plausibly attributed to one’s own efforts, crowds out reflection about the future. An upper-middle manager at Alchemy Inc. recalls, for instance, his days as a plant manager when his boss at company headquarters phoned him every three hours to see how many tons of soda ash had been produced in the interval. (Location 1869)</p>
<p>70. This goes to the heart of the problem. Managers think in the short run because they are evaluated by both their superiors and peers on their short-term results. Those who are not seen to be producing requisite short-run gains come to be thought of as embarrassing liabilities. Of course, past work gets downgraded in such a process. The old saw, still heard frequently today, “I know what you did for me yesterday, but what have you done for me lately?” is more than a tired garment district salesman’s joke. It accurately reflects the widespread amnesia among managers about others’ past accomplishments, however notable, and points to the probationary crucibles at the core of managerial life. Managers feel that if they do not survive the short run, the long run hardly matters, and one can only buy time for the future by attending to short-term goals. As one manager says: “Our horizon is today’s lunch.” (Location 1875)</p>
<p>71. Now you see this at work with mistakes. You can make mistakes in the work you do and not suffer any consequences. For instance, I could negotiate a contract that might have a phrase that would trigger considerable harm to the company in the event of the occurrence of some set of circumstances. The chances are that no one would ever know. But if something did happen and the company got into trouble, and I had moved on from that job to another, it would never be traced to me. The problem would be that of the guy who presently has responsibility. And it would be his headache. There’s no tracking system in the corporation. Some managers argue that outrunning mistakes is the real meaning of “being on the fast track,” the real key to managerial success. The same lawyer continues: In fact, one way of looking at success patterns in the corporation is that the people who are in high positions have never been in one place long enough for their problems to catch up with them. They outrun their mistakes. That’s why to be successful in a business organization, you have to move quickly. (Location 2013)</p>
<p>72. Both Covenant Corporation and Weft Corporation, for instance, place a great premium on a division’s or a subsidiary’s return on assets (ROA); managers who can successfully squeeze assets are first in line, for instance, for the handsome rewards allotted through bonus programs. One good way for business managers to increase their ROA is to reduce assets while maintaining sales. Usually, managers will do everything they can to hold down expenditures in order to decrease the asset base at the end of a quarter or especially at the end of the fiscal year. The most common way of doing this is by deferring capital expenditures, everything from maintenance to innovative investments, as long as possible. Done over a short period, this is called “starving a plant”; done over a longer period, it is called “milking a plant.” (Location 2034)</p>
<p>73. A plant that is not well maintained will fail in the short term, so you have to spend money there; a plant that has poorly trained people will fail today, so you have to spend money there. But you can still milk (Location 2045)</p>
<p>74. We’re judged on the short-term because everybody changes their jobs so frequently. (Location 2042)</p>
<p>75. My favorite things are not to replace my stores inventory and that shows up as direct profit on your balance sheet; not replace people who retire, and stretch everybody else out; cut down on overtime; cut working inventories to the bone. [You can also] lower the quality standards; you can get away with this in the short term because people will accept that for awhile, though in the long term people will stop buying from you. (Location 2050)</p>
<p>76. At the very top of organizations, one does not so much continue to outrun mistakes as tough them out with sheer brazenness. In such ways, bureaucracies may be thought of, in C. Wright Mills’s phrase, as vast systems of organized irresponsibility. (Location 2123)</p>
<p>77. When a weaver is unable to repair a stop, she shuts down the loom and flags a “fixer,” the most skilled and highest-ranking worker on the shop floor, who does the repair or basic maintenance necessary to get the loom working again. However, since weavers are paid by the piece and can make no gain from a loom out of service for repair or maintenance during their own shifts, weavers will tend to remedy stops in any way they can in order to keep their cloth production high, leaving the maintenance and repair of the machinery and the economic cost involved to another weaver on another shift. Supervisors and managers who are evaluated by a plant’s overall weaving efficiency are thus forced to monitor the number of loom stops constantly in order to make sure that looms badly in need of repair or maintenance get proper attention. Whenever structural inducements place premiums on immediate personal gains, especially when mistakes are not penalized, there seems to be a sharp decline in the likelihood of men and women sacrificing their own interests for others, for their organizations, or least of all for the common weal.2 (Location 2135)</p>
<p>78. It was said that Noll had milked and milked thoroughly every plant he ever supervised. One day, a story goes, he was accused of this in a public meeting by a vice-president who was then his superior. Noll is said to have responded with great boldness: “[Joe], how can you sit there and say that to me? How in the hell do you think you got to where you are and how do you think you stay there?” (Location 2153)</p>
<p>79. If a guy keeps moving, he can say, “Look, I ran this plant better than my predecessors.” And people have to concede that. A lot of people do that. Then you get the guy who takes his place and tries to run things right and he has to spend a lot of money. And people look at the guy who was there before and they say: “Well, old [Noll] ran the plant well and he didn’t have to spend any money like you’re claiming you do.” I don’t think there is anything wrong with milking a plant. As long as you know you’re milking (Location 2223)</p>
<p>80. No, definitely not. Would any sane, rational man spend $15 million for a 2 percent return? … Now it does improve the dust levels, but it was that if we don’t invest the money now, we would be in a desperate [competitive] position fifteen years from now. Our demonstrated cash flow situation was such that eventually we would have had even tougher decisions to make. (Location 3579)</p>
<p>81. Executives also admit, somewhat ruefully and only when their office doors are closed, that OSHA’s regulation on cotton dust has been the main factor in forcing the pace of technological innovation in a centuries-old, hidebound, and somewhat stagnant industry. It has also been a major factor in forcing executives to think in the long run rather than continually succumbing to short-term pressures. This is one of the reasons why the shrewdest among them only feigned elation at the attempts by Reagan’s OSHA appointees to remove the cotton dust regulation from the purview of the Supreme Court. If such a move were successful, it could only encourage the traditionally reactionary elements of the textile industry who refuse to recognize on principle that government regulation, within reason, can be the businessman’s best friend. (Location 3593)</p>
<p>82. S&amp;Ls could now open transaction accounts and make commercial real estate loans, regardless of geography, up to 40 percent of their assets. This prompted many S&amp;L executives to sell their long-term, fixed-rate, low- or no-profit mortgages to Wall Street firms for as little as 60 percent of their value in order to obtain ready funds for much more lucrative, though much riskier, investments. (Location 4649)</p>
<p>83. Organized irresponsibility has migrated to the nooks and crannies of our society. One sees presidents of universities and colleges who preside over the destruction of their institutions’ endowments, not to mention the intellectual integrity of curricula, and then outrun their mistakes and move on to higher academic and even top political posts. One sees intellectuals who are completely committed to the destruction of the Western tradition that nurtures them and who help create the profound social and cultural centrifugality that marks American society. One sees big-city mayors who cede control of the streets to drug dealers and other thugs for fear of being labeled nonprogressive by various advocacy groups and the press. One sees long-time political insiders in Washington who “screw up and move up,” an aphorism that aptly captures the ethos of government bureaucracies. And doublethink and doublespeak now permeate public discourse, bewildering even intelligent, thoughtful citizens. (Location 4990)</p>
<h3>G. Social Politics</h3>
<p>84. Managers’ cryptic aphorism, “Well, you never know…,” repeated often and regularly, captures the sense of uncertainty created by the constant potential for social reversal. Managers know too, and take for granted, that the personnel changes brought about by upheavals are to a great extent arbitrary and depend more than anything else on one’s social relationships with key individuals and with groups of managers. (Location 761)</p>
<p>85. “Every big organization is set up for the benefit of those who control it; the boss gets what he wants.” (Location 827)</p>
<p>86. In any event, just as managers must continually please their boss, their boss’s boss, their patrons, their president, and their CEO, so must they prove themselves again and again to each other. Work becomes an endless round of what might be called probationary crucibles. Together with the uncertainty and sense of contingency that mark managerial work, this constant state of probation produces a profound anxiety in managers, perhaps the key experience of managerial work. (Location 910)</p>
<p>87. See, once you are at a certain level of experience, the difference between a vice-president, an executive vice-president, and a general manager is negligible. It has relatively little to do with ability as such. People are all good at that level. They wouldn’t be there without that ability. So it has little to do with ability or with business experience and so on. All have similar levels of ability, drive, competence, and so on. What happens is that people perceive in others what they like—operating styles, lifestyles, personalities, ability to get along. Now these are all very subjective judgments. And what happens is that if a person in authority sees someone else’s guy as less competent than his own guy, well, he’ll always perceive him that way. And he’ll always pick—as a result—his own guy when the chance to do so comes up. (Location 1013) [Also see Nothing Matters]</p>
<p>88. Striking, distinctive characteristics of any sort, in fact, are dangerous in the corporate world. One of the most damaging things, for instance, that can be said about a manager is that he is brilliant. This almost invariably signals a judgment that the person has publicly asserted his intelligence and is perceived as a threat to others. What good is a wizard who makes his colleagues and his customers uncomfortable? (Location 1173)</p>
<p>89. Equally damaging is the judgment that a person cannot get along with others—he is “too pushy,” that is, he exhibits too much “persistence in getting to the right answers,” is “always asking why,” and does not know “when to back off.” Or he is “too abrasive,” or “too opinionated,” unable “to bend with the group.” Or he is a “wildman” or a “maverick,” that is, someone who is “outspoken.” Or he may be too aloof, too distant, “too professional.” (Location 1176)</p>
<p>90. The knowledgeable practitioners of corporate politics, whether patrons or leaders of cliques and networks, value nothing more highly than at least the appearance of unanimity of opinion among their clients and allies, especially during times of turmoil. (Location 1197)</p>
<p>91. Managers know that patrons and powerful allies protect those already selected as rising stars from the negative judgments of others; and only the foolhardy point out even egregious errors of those in power or those destined for it. (Location 1463)</p>
<p>92. Managers know that to be weak in a world that extols strength and power is to invite abuse. (Location 1536)</p>
<p>93. Such social distancing has two purposes: it undermines in advance or lays the groundwork for refusal of any claims that a person considered a failure might make on another, and it forestalls the possibility of being linked with that person in others’ cognitive maps. This becomes particularly important when there has been a known past association between oneself and one thought to have failed in some way. (Location 1542)</p>
<p>94. In fact, when it is even suspected that a person might be headed for trouble, anticipatory avoidance is the rule. (Location 1550)</p>
<p>95. Being a “fall guy,” that is, “taking the rap” or “taking the heat” for others’ decisions or mistakes is probably the most common kind of blame in big organizations. (Location 1904)</p>
<p>96. You have to remember that you only get to explain things away once. When things get screwed up, you get one chance. That’s why it’s important for everybody to be in bed with everybody else. And if they don’t like you from the start, you don’t have a chance. Because when things go wrong, what people do is sit down and say—without saying it in so many words—look, our jobs are on the line. Let’s make sure that it’s not us who gets nailed. (Location 1999)</p>
<p>97. Wilson and his Site Operations staff were particularly concerned because when the polar crane was finally used, it would be Site Operations who used it. They knew that, if they were in charge when the button was pushed, they could be blamed for whatever might go wrong. If the polar crane failed, it would be seen as the fault of Site Operations. (Location 2557)</p>
<p>98. high-ranking staff official at Covenant explains: Anxiety is endemic to anyone who works in a corporation. By the time you get to be middle management, it’s difficult to make friends because the normal requirement for friendship—that is, loyalty—doesn’t fit in this context. You have to look out for number one more than anything else. Moreover, the prevailing view is that managers are big boys and girls, well-paid, and should be able to take care of themselves. Besides, one person’s failure represents another person’s opportunity. (Location 1554)</p>
<p>99. of a young manager who, while at a company conference, went out for his weight-controlling 5:30 A.M. jog only to meet a vice-president similarly engaged, a powerful executive who now cheers the younger man’s work and presentations and introduces him to other influential senior managers; (Location 1654)</p>
<p>100. scattering ducks already set in a row. Besides, one can only criticize something when one has the resources to solve it in a clear and decisive way. Otherwise, one should keep one’s skepticism to oneself and get “on board.” (Location 2629)</p>
<p>101. Other managers and managerial cliques are always on the lookout for others’ mistakes or for actions that can be construed as mistakes and will pounce on anyone foolish enough to admit them. Even if others restrain an immediate attack, the knowledge of someone’s mistakes is ammunition for the future. Many managers “lay in the weeds, with rocks, and wait.” One who exposes a colleague’s errors in such a context and makes him vulnerable to others evinces, of course, only a fundamental untrustworthiness, unless one’s colleague has first betrayed oneself or others in some way— (Location 2858)</p>
<p>102. There is a premium in the higher circles of management on seeming fresh, dynamic, innovative, and up-to-date. In their social minglings and shoptalk with one another, particularly with their opposite numbers in other large companies, say, at the Business Roundtable, at high-level conferences at prestigious business schools, at summer galas in the Hamptons, or at the Super Bowl, the biggest business extravaganza of all, executives need to seem abreast of the latest trends in managerial know-how. No one wants to appear stodgy before one’s peers nor to have one’s firm defined in managerial networks, and perhaps thence to Wall Street, as “slow on the uptake.” Executives trade ideas and schemes and judge the efficacy of consultant programs not by any detached critical standards but by what is socially acceptable, desirable, and, perhaps most important, current in their circles. (Location 3155)</p>
<p>103. So they attend the sessions and with a seemingly dutiful eagerness learn literally to repeat the requisite formulas under the watchful eyes of senior managers. Senior managers do not themselves necessarily believe in such programs. In one seminar that I attended, the senior manager in charge startled a room of juniors by saying: Fellows, why aren’t any of you asking about the total lack of correspondence between what we’re preaching here and the way we run our company? But such outspokenness is rare. (Location 3209)</p>
<p>104. They admit, however, that the marvelously high fees that consultants command (in 1986 as high as $2,000 a day in New York City) enhance their legitimacy and encourage managers to lend credence to their schemes. (Location 3216)</p>
<p>105. A choice between securing one’s own success by jumping on and off the bandwagon of the moment, or sacrificing oneself for the long-run good of a corporation by diverting resources and really seeing a program through is, for most managers, no choice at all. Ambitious managers see self-sacrificing loyalty to a company as foolhardy. Moreover, middle and upper-middle level managers upon whom requests for self-sacrifice for the good of the organization are most likely to fall do not see top executives sacrificing themselves for the common good. For example, just after the CEO of Covenant Corporation announced one of his many purges, legitimated by a “comprehensive assessment of the hard choices facing us” by a major consulting firm, he purchased a new Sabre jet for executives and a new 31-foot company limousine for his own use at $1,000 a foot. He then flew the entire board of directors to Europe on the Concorde for a regular meeting to review, it was said, his most recent cost-cutting strategies. As other managers see it, bureaucratic hierarchy gives top bosses the license to act in their own interests and to pursue with impunity the arts of contradiction. (Location 3220)</p>
<h3>H. The I in Team</h3>
<p>106. The main dimensions of team play are as follows. 1. One must appear to be interchangeable with other managers near one’s level. Corporations discourage narrow specialization more strongly as one goes higher. They also discourage the expression of moral or political qualms. One might object, for example, to working with chemicals used in nuclear power, or working on weapons systems, and most corporations today would honor such objections. Publicly stating them, however, would end any realistic aspirations for higher posts because one’s usefulness to the organization depends on versatility. As one manager in Alchemy Inc. comments: “Well, we’d go along with his request but we’d always wonder about the guy. And in the back of our minds, we’d be thinking that he’ll soon object to working in the soda ash division because he doesn’t like glass.” Strong convictions of any sort are suspect. One manager says: If you meet a guy who hates red-haired persons, well, you’re going to wonder about whether that person has other weird perceptions as well. You’ve got to have a degree of interchangeability in business. To me, a person can have any beliefs they want, as long as they leave them at home. Similarly, one’s spouse’s public viewpoints or activities could reduce others’ perceptions of a manager’s versatility or indeed ability. In reference to another manager whose wife was known to be active in environmental action groups, lobbying in fact for legislation on chemical waste disposal, one Alchemy manager says: “If a guy can’t even manage his own wife, how can he be expected to manage other people?” (Location 1137)</p>
<p>107. Team play also means, as one manager in the chemical company puts it, “aligning oneself with the dominant ideology of the moment” or, as another says, “bowing to whichever god currently holds sway.” Such ideologies or gods may be thought of as official definitions of reality. (Location 1188)</p>
<p>108. You can indict a person by saying that he’s not a team player. That doesn’t mean he won’t follow directions. It’s because he voices an objection, because he argues with you before doing something, especially if he’s right. That’s when we really get mad—when the other guy is right. If he’s wrong, we can be condescending and adopt the “you poor stupid bastard” tone…. (Location 1220)</p>
<p>109. A team player is a manager who does not “force his boss to go to the whip,” but, rather, amiably chooses the direction his boss points out. Managers who choose otherwise or who evince stubbornness are said to “have made a decision,” a phrase almost always used to describe a choice that will shorten a career. (Location 1229)</p>
<p>110. Team players display a happy, upbeat, can-do approach to their work and to the organization. (Location 1252)</p>
<h3>I. Avoiding Decision Making</h3>
<p>111. You know that old saying: “Success has many parents; failure is an orphan”? Well, that describes decision making. A lot of people don’t want to make a commitment, at least publicly. This is a widespread problem. They can’t make judgments. They stand around and wait for everybody else’s reaction. Let me tell you a story which perfectly illustrates this. There was a [museum] collection coming, the [Arctic] collection, and there was a great deal of interest among designers in [Arctic] things. My own feeling was that it wouldn’t sell but I also recognized that everybody wanted to do it. But in this case, [our] design department was spared the trouble. There was an independent designer who had access to our president and he showed him a collection of [Arctic] designs. There were two things wrong: (1) it was too early because the collection hadn’t hit town yet; (2) more important, the designs themselves were horrible. Anyway, [the collection] was shown in a room with everything spread out on a large table. I was called down to this room which was crowded with about nine people from the company who had seen the designs. I looked at this display and instantly hated them. I was asked what I thought but before I could open my mouth, people were jumping up and down clapping the designer on the back and so on. They had already decided to do it because the president had loved it. Of course, the whole affair was a total failure. The point is that in making decisions, people look up and look around. They rely on others, not because of inexperience, but because of fear of failure. They look up and look to others before they take any plunges. (Location 1713)</p>
<p>112. But all these things have no relationship to the way they actually manage or make decisions. The basic principles of decision making in this organization and probably any organization are: (1) avoid making any decision if at all possible; (2) if a decision has to be made, involve as many people as you can so that, if things go south, you’re able to point in as many directions as possible. (Location 1731)</p>
<p>113. A middle-aged, upper-middle level manager at Alchemy Inc. says: You know, there is this huge computerized inventory of skills which people update each year; it’s called a skills inventory. … But all the computerized lists in the world don’t amount to much in the corporation. What matters is a bunch of guys sitting informally in a room and deciding who should get jobs and who shouldn’t. The real job decisions are made on that basis. And circumstances determine your fate. (Location 1634)</p>
<p>114. Making a decision, or standing by a decision once made, exposes carefully nurtured images of competence and know-how to the judgments of others, particularly of one’s superiors. As a result, many managers become extremely adept at sidestepping decisions altogether and shrugging off responsibility, all the while projecting an air of command, authority, and decisiveness, leaving those who actually do decide to carry the ball alone in the open field. (Location 1774)</p>
<p>115. This explains why the chemical company managers kept putting off a decision about major reinvestment. After the battery collapsed in 1979, however, the decision facing them was simple and posed little risk. The corporation had to meet its legal obligations; also, it had either to repair the battery the way the EPA demanded or shut down the plant and lose several hundred million dollars. Since there were no real choices, everyone could agree on a course of action because everyone could appeal to inevitability. This is the nub of managerial decision making. As one manager says: Decisions are made only when they are inevitable. To make a decision ahead of the time it has to be made risks political catastrophe. People can always interpret the decision as an unwise one even if it seems to be correct on other grounds. (Location 1886)</p>
<p>116. Despite their fresh appearances, certain themes recur constantly in the programs offered by consultants. Perhaps the most common are how to sharpen decision making, how to restructure organizations for greater efficiency, how to improve productivity, how to recognize trouble spots in an organization, how to communicate effectively, how to humanize the workplace, and how to raise morale. (Location 3164)</p>
<h3>J. This is Your Life</h3>
<p>117. At the managerial and professional levels, the road between work and life is usually open because it is difficult to refuse to use one’s influence, patronage, or power on behalf of another regular member of one’s social coterie. It therefore becomes important to choose one’s social colleagues with some care and, of course, know how to drop them should they fall out of organizational favor. (Location 884)</p>
<p>118. For some managers, the drive for success is a quest for the generous financial rewards that high corporate position brings. For others, success means the freedom to define one’s work role with some latitude, to “get out from under the thumb of others.” For still others, it means the chance to gain power and to exert one’s will, to “call the shots,” to “do it my way,” or to know the curiously exhilarating pleasure of controlling other people’s fates. For still others, the quest for success expresses a deep hunger for the recognition and accolades of one’s peers. (Location 955)</p>
<p>119. More generally, those who accept immobility are unwilling to sacrifice family life or free-time activities to put in the extraordinarily long hours at the office required in the upper circles of their corporations. Or they have made a realistic assessment of the age structure, career paths, and power relationships above them and conclude that there is no longer real opportunity for them. They may see that there is an irreparable mismatch between their own personal styles and the kinds of social skills being cultivated in well-entrenched higher circles. In many cases, they decide that they do not wish to put up with the great stress of higher management work that they have witnessed. (Location 962)</p>
<p>120. Higher-level managers in all the corporations I studied commonly spend twelve to fourteen hours a day at the office. (Location 1156)</p>
<p>121. In a world where appearances—in the broadest sense—mean everything, the wise and ambitious manager learns to cultivate assiduously the proper, prescribed modes of appearing. He dispassionately takes stock of himself, treating himself as an object, as a commodity. He analyzes his strengths and weaknesses and decides what he needs to change in order to survive and flourish in his organization. And then he systematically undertakes a program to reconstruct his image, his publicly avowed attitudes or ideas, or whatever else in his self-presentation that might need adjustment. (Location 1339)</p>
<p>122. This [lack of control] doesn’t mean you don’t work hard; at least in my case, that’s my answer. I have to believe I can influence events. That way, I feel good about myself even if my boss doesn’t. (Location 1606)</p>
<p>123. Sometimes I’ll wake up in the middle of the night thinking about the plant. And if I can’t get back to sleep, I’ll slip out of bed and walk over to the plant and just walk around the machinery and talk to the guys. I love the smell of the oil and the grease and the sound of the machines. For me, that’s what life is all about. (Location 4535)</p>
<h3>K. Immoral Mazes</h3>
<p>124. In analyzing incidence data from a representative plant, and by extrapolating to the rest of the firm’s mills, White discovered that 12 percent of all greige mill workers had already suffered hearing loss severe enough to be immediately compensable under state law for as much as $3.5 to $5.7 million. This, however, was only the thunder before a summer storm. Another 63 percent of greige mill workers had already suffered substantial, though not yet compensable, damage that could only worsen the longer they stayed in the industry. (Location 2265)</p>
<p>125. Moreover, by insisting on his own personal moral purity, his feeling that if he did not expose things he himself would be drawn into a web of corruption, he was, they feel, being disingenuous; no one reaches his level of a hierarchy without being tainted. (Location 2450)</p>
<p>126. A moral judgment based on a professional ethic makes little sense in a world where the etiquette of authority relationships and the necessity for protecting and covering for one’s boss, one’s network, and oneself supercede all other considerations and where nonaccountability for action is the norm. (Location 2474)</p>
<p>127. On the polar crane issue, the top official of the NRC later characterized Wilson’s and his engineers’ concerns as stemming from a philosophy that emphasized procedural matters rather than a focus on final goals. This characterization was echoed by GPUN management who stressed that what was at issue in the polar crane dispute was not procedures but results; at a certain point, they said, decisions had to be made to resolve technical disputes and work had to proceed toward what everyone acknowledged to be a worthwhile goal, that is, the cleanup of TMI-2. (Location 2566)</p>
<p>128. Once, when he wrote a memo to the GPUN deputy director about radioactively contaminated sewage being trucked out of the plant and disposed of illegally, his boss replied that he did not need such a memo from Wilson. It was, his boss said, not constructive and wasted his own and Wilson’s time. (Location 2575)</p>
<p>129. my view, this is the nub of the moral ethos of bureaucracy. Managers see this issue as a “trade-off” between principle and expediency. They usually pose the trade-off as a question: Where do you draw the line? (Location 2652)</p>
<p>130. It is said, in fact, that one Weft manager who was on the take for years from customers was fired within a half hour of the discovery of his “inexplicably stupid” acceptance and deposit of a check from his benefactors instead of his normal cash rake-offs. With such authoritative encouragement, managers internalize these norms into their own personal codes of honor; they speak privately of the importance of not being known as men or women “who can be had.” (Location 2658)</p>
<p>131. It gets hard. Now, suppose that the ozone depletion theory were correct and you knew that these specific fifty people were going to get skin cancer because you produced chlorofluorocarbons [CFCs]. Well, there would be no question. You would just stop production. But suppose that you didn’t know the fifty people and it wasn’t at all clear that CFCs were at fault, or entirely at fault. What do you do then? (Location 2831)</p>
<p>132. Suppose that you had a candy bar factory and you were touring the plant and you saw with your own eyes a worker slip a razor blade into a bar. And before you could stop the machine, there were a thousand bars more made and the one with the razor blade was mixed up. Well, there’s no question that you would get rid of the thousand candy bars. But what if it were a million bars? Well, I don’t know what I’d do. (Location 2843)</p>
<p>133. Moreover, he tries to treat his subordinates forthrightly, firmly believing that one’s word is an important measure of a person. In a world, however, where actions are separated from consequences, where knowledge is fragmented and secreted, where private agreements are the only real way to fashion trust in the midst of ongoing competition and conflict, where relationships with trusted colleagues constitute one’s only real means both of defense and opportunity, and where, one knows, even coincidental association with a disaster can haunt one’s career years later, keeping silent and covering for oneself and for one’s fellows become not only possible but prudent, indeed virtuous, courses of action. (Location 2969)</p>
<p>134. Moreover, it is a byword in the chemical industry at least that it is precisely in those technological areas where accidents have seldom occurred that the largest potential catastrophes loom; the very lack of practice in responding quickly to untoward incidents can precipitate uncontrollable events. (Location 3376)</p>
<p>135. Publicly, of course, Weft Corporation, as do many other firms, claims that the money was spent entirely to eliminate dust, evidence of its corporate good citizenship. Privately, executives admit that without the productive return, they would not have—indeed, given the constraints under which they operate—could not have spent the money. (Location 3585)</p>
<p>136. The ethic that emerges in bureaucratic contexts contrasts sharply in many respects with the original Protestant ethic. The Protestant ethic was a social construction of reality of a self-confident and independent propertied social class. It was an ideology that extolled the virtues of accumulating and reinvesting wealth in a society organized around property and that accepted the stewardship responsibilities entailed by property. It was an ideology where a person’s word was his bond and where the integrity of the handshake was crucial to the maintenance of good business relationships. (Location 4295)</p>
<p>137. At the core of the middle class’s righteous, some would say smug, faith in itself, of its inexhaustible drive, of its unremitting pragmatism, was the conviction that hard work necessarily had its just rewards here and now as a token of divine favor in the hereafter. This conviction was also the bedrock of a profound guilt mechanism that impelled one to fulfill personal and social obligations; failure to do so, like a failure to work hard, was thought to be a sin against both God and self. (Location 4304)</p>
<p>138. Bureaucracy breaks apart the ownership of property from its control, social independence from occupation, substance from appearances, action from responsibility, obligation from guilt, language from meaning, and notions of truth from reality. Most important, and at the bottom of all of these fractures, it breaks apart the older connection between the meaning of work and salvation. In the bureaucratic world, one’s success, one’s sign of election, no longer depends on an inscrutable God, but on the capriciousness of one’s superiors and the market; and one achieves economic salvation to the extent that one pleases and submits to new gods, that is, one’s bosses and the exigencies of an impersonal market. (Location 4307)</p>
<h3>L. Truth and Public Relations</h3>
<p>139. Truth? What is truth? I don’t know anyone in this business who talks about “truth.” (Location 4137)</p>
<p>140. After all, as one executive says, “We lie all the time, but if everyone knows that we’re lying, is a lie really a lie?” (Location 2693)</p>
<p>141. If a retailer returns with goods and says, “Look, I can’t sell $50,000 of this stuff. You have to take it back or it’s going to break me,” may one say, “What’s that? I didn’t hear you,” hoping for the sake of future business that the retailer will say, “Oh, look, you were late delivering and I can’t use it now.” (Location 2700)</p>
<p>142. The consultant who perceives such discrepancies has to devise his own strategies for handling them. Some of these include: rejecting the assignment altogether; accepting the problem as defined and confining oneself to it for the sake of future contracts even though one knows that any action will be inefficacious; or accepting the assignment but trying to persuade the client to address the underlying social and political issues, that is, redefining the problem. (Location 3234)</p>
<p>143. For instance, a highly placed staff member whose work requires him to interact daily with the top figures of his company, says: I get faked out all the time, and I’m part of the system. I come from a very different culture. Where I come from, if you give someone your word, no one ever questions it. It’s the old hard-work-will-lead-to-success ideology. Small community, Protestant, agrarian, small business, merchant-type values. I’m disadvantaged in a system like this. He goes on to characterize the system more fully and what it takes to succeed within it: It’s the ability to play this system that determines whether you will rise. … And part of the adeptness [required] is determined by how much it bothers people. One thing you have to be able to do is to play the game, but you can’t be disturbed by the game. What’s the game? It’s bringing troops home from Vietnam and declaring peace with honor. It’s saying one thing and meaning another. It’s characterizing the reality of a situation with any description that is necessary to make that situation more palatable to some group that matters. It means that you have to come up with a culturally accepted verbalization to explain why you are not doing what you are doing…. [Or] you say that we had to do what we did because it was inevitable; or because the guys at the [regulatory] agencies were dumb; [you] say we won when we really lost; [you] say we saved money when we squandered it; [you] say something’s safe when it’s potentially or actually dangerous…. Everyone knows that it’s bullshit, but it’s accepted. This is the game. (Location 3246)</p>
<p>144. Such adeptness at inconsistency, without moral uneasiness, is essential for executive success. Done over a period of time, in fact, it seems to become a taken for granted habit of mind. As one executive at Covenant Corporation says: Now some people don’t understand this…. But as you move up the ladder, you don’t have people who don’t understand. And the people up high don’t necessarily do it consciously. They are able to speak out of both sides of their mouth without missing a step. It means being able to say, as a very high-ranking official of Weft Corporation said to me without batting an eye, that the industry has never caused the slightest problem in any worker’s breathing capacity. It means, in Covenant Corporation, propagating an elaborate hazard/benefit calculus for approval of dangerous chemicals while internally conceptualizing “hazards” as business risks. It means publicly extolling the carefulness of testing procedures on toxic chemicals while privately ridiculing animal tests as inapplicable to humans. (Location 3610)</p>
<p>145. Finally, those truly adept at inconsistency can also interpret with some accuracy the inconsistent machinations of their colleagues and adversaries. This is not a mean skill. At the very beginning of my fieldwork, the top lawyer of a large corporation was discussing an issue that I had raised when he said: Now, I’m going to be completely honest with you about this. He paused for a moment and then said: By the way, in the corporate world, whenever anybody says to you: “I’m going to be completely honest with you about this,” you should immediately know that a curveball is on the way. But, of course, that doesn’t apply to what I’m about to tell you. (Location 3631)</p>
<p>146. Since the success of large commercial bureaucracies depends to a great extent on the goodwill of the consuming public, ambitious managers recognize that great organizational premiums are placed on the ability to explain expedient action convincingly. Public opinion, of course, constitutes one of the only effective checks on the bureaucratic impulse to translate all moral issues into practical concerns. (Location 3643)</p>
<p>147. 1925, Walter Lippmann critically analyzed a public’s ability to appreciate the intricacies of any issue or indeed to keep its attention on anything but crises. He adds: [S]ince [a public] acts by aligning itself, it personalizes whatever it considers, and is interested only when events have been melodramatized as a conflict. The public will arrive in the middle of the third act and will leave before the last curtain, having stayed just long enough perhaps to decide who is the hero and who is the villain of the piece. (Location 3765)</p>
<p>148. read in The Wall Street Journal or The New York Times accounts of specific events or larger trends attributed to “informed sources,” the code name for public relations men and women; (Location 3828)</p>
<p>149. There are, of course, good clients and bad clients. A good client keeps his public relations specialists adequately informed, provides “feedback” and “constructive criticism,” and recognizes that public relations depends on time-billing rather than on product billing and provides enough funds to do the job properly. A good client “takes stock of himself,” that is, dispassionately objectifies his company’s products, his company’s organizational structure and personnel, and, say, in the case of a top corporate official, himself, to make them all more readily manipulable and therefore marketable commodities. Above all, a good client is flexible and therefore able rapidly to shift ground and actual policies as well to meet new needs or new pressures. A bad client, by contrast, either does not understand or chooses to ignore the peculiarly indirect approach of public relations and wants immediately observable results in terms of press clippings or TV time; uses a public relations program as a vehicle for self-aggrandizement within his own corporation, placing the public relations specialist in danger of “getting caught in a pissing contest between executives”; demands the release of press statements that are only marginally “newsworthy” and then blames the public relations specialist when nothing at all gets printed or aired; conceals crucial aspects of his story from his public relations advisers and refuses them adequate access to his staff and facilities to get the full story; comes to the public relations agency with trumped-up data and fake photographs—as happened, for instance, at Images Inc. when a client falsely claimed the efficacy of a product to remove tar from despoiled beaches—and ends up declaring bankruptcy, leaving the public relations agency liable for a multimillion-dollar lawsuit; wants the public relations agency, as in the case of some single-party foreign governments, to put a good public face on practices like the “persuasion” and “elimination” of opponents; expects the public relations agency to be the “bag man” to pay off government officials or newspaper editors; and, perhaps especially, insists on an indefensible or totally unbelievable version of reality or expects the public relations specialist to tell outright lies. (Location 3843)</p>
<p>150. As it happens, accounts in the public relations world circulate continually and only sometimes because of actual or alleged dissatisfaction with public relations service. The pattern of continual mergers, upheavals, and power struggles in corporations, that I have argued earlier is at the core of American corporate life, directly affects public relations agencies. When a new CEO or divisional president assumes power in a corporation, he will quite often change public relations and advertising agencies as part of a larger strategy of shedding the past or to assert his own “new vision” of the future. When this occurs, almost invariably, he will move his account to an agency whose leaders he knows and with whom he feels comfortable. This continual circulation of accounts means that agency personnel are constantly searching for new accounts and constantly devising ways to hold present clients, despite the knowledge of the inevitability of their eventual departure. (Location 3868)</p>
<p>151. In the world of public relations, there is no such thing as a notion of truth; there are only stories, perspectives, or opinions. One works, of course, with “facts,” that is, selected empirically verifiable statements about the world. But as long as a story is factual, it does not matter if it is “true.” One can feel free to arrange these facts in a variety of ways and to put any interpretation on them that suits a client’s objectives. Interpretations and judgments are always completely relative. The only canons binding this process of interpretation are those of credibility or, more exactly, of plausibility. If an interpretation of facts, a story, is taken as plausible by a targeted audience, it is just as good as “true” in any philosophical sense, indeed better since it furthers the accomplishment of an immediate goal. (Location 3886)</p>
<p>152. From the standpoint of public relations, the journalistic ideology closely resembles the social outlook of most college seniors—a vague but pious middle-class liberalism, a mildly critical stance toward their fathers in particular and authorities in general; a maudlin championship of the poor and the underclass; and especially the doctrine of tolerance, open-mindedness, and balance. In fact, public relations people feel, the news media are also constructing reality. They are always looking for a “fresh” and exciting angle; they have an unerring instinct for the sentimental that expresses itself in a preference for “human interest” rather than substance; and they arrange facts in a way that purports to convey “truth,” but is in fact simply another story. In reality, news is entertainment. And, despite the public’s acceptance of journalistic ideologies, most of the public watch or read news not to be informed or to learn the “truth,” but precisely to be entertained. There is no intrinsic reason, therefore, why the constructions of reality by public relations specialists should be thought of as any different from those of any group in the business of telling stories to the public. (Location 3903)</p>
<p>153. The top official, in a written document prepared for a meeting to discuss the issue, argued that: [T]he final report was better than it would have been if it had not gone through [the] process of reexamination. It was stronger, it was more important, it was more constructive…. At the same time, there is no doubt that pressures were brought on us to come to the kind of conclusions we finally reached. At the meeting, he added, somewhat more pithily: “We tried to be honest but, believe me, it wasn’t easy.” (Location 4124)</p>
<p>154. The same top executive defines truth: I sometimes sit back and think that if we could make up a list of all the viewpoints of all our clients and somehow fit them together, then that would be truth. That would be what we are as a firm. (Location 4130)</p>
<p>155. Agency practitioners not only defend multiple interests but face repeatedly the experience of even well-served clients switching agencies. Especially unsettling are the departures of clients who decide that, since they are as they have been portrayed, they have no future need to construct reality. The continual circulation of client accounts in agencies diminishes the possibilities of comforting, long-held allegiances to organizations, products, or causes. (Location 4192)</p>
<p>156. Alternatively, and by contrast, practitioners in both settings sometimes justify their efforts by appealing to a professional ethos that celebrates the exercise of technical skill separated from any emotional commitment to one’s clients. A dignified version of this legitimation is the often repeated analogy between public relations practitioners and lawyers; both occupations, it is argued, fulfill important advocacy roles in a free society. Only the practice of the professional virtue of public relations, however hazardous to individual practitioners, can assure the continued diversity of opinion that marks our democracy. (Location 4195)</p>
<p>157. That’s the reality of our society. There’s no question that their story is being told because they have the money and power. I’ve got to recognize that I’m part of this society and just come to live with that. Our society is the way it is. It’s run on money and power, it’s that simple. Truth has nothing to do with it. So we just accept the world as it is and live with it. (Location 4206)</p>
<p>158. The agency literally creates these realities by matchmaking artistic talent and accomplishment with money. In the process, up-and-coming junior corporate executives get the kind of exposure to refined, sophisticated artistic and intellectual circles that will help prepare and polish them for higher posts. Artists, in turn, as long as their work is not too avant-garde, receive the benefits of a latter-day Medici-like patronage. Public relations people claim a double accomplishment—they help civilize businessmen, not least by inspiring in them a “passion for greatness” rather than self-interest as the important motive for patronage of the arts; and they provide the public with access to high culture. The same firm has also arranged corporate sponsorship of dance and musical performances, helped develop important educational programs such as one on infant nutrition, conducted some useful surveys such as one on the problems facing ethnic minorities, and done a lot of pro bono work for philanthropic, community, and public service organizations in the bargain. One tries, then, to move some clients in directions that seem socially desirable while at the same time playing with the magic lantern to serve their interests. Sometimes, too, the ability to accomplish any good at all in this world seems to depend on the willingness to serve even clients with no apparent redeeming features in order to seize capricious opportunities to channel other clients’ resources into work deemed socially worthwhile. (Location 4214)</p>
<p>159. In short, bureaucracy creates for managers a Calvinist world without a Calvinist God, a world marked with the same profound anxiety that characterized the old Protestant ethic but one stripped of that ideology’s comforting illusions. Bureaucracy poses for managers an intricate set of moral mazes that are paradigmatic of the quandaries of public life in our social order. Within this framework, the puzzle for many individual managers becomes: How does one act in such a world and maintain a sense of personal integrity? (Location 4351)</p>
<h3>M. Under Siege</h3>
<p>160. Part of the folklore of the modern corporation, in fact, consists of a catalog of stories about how big corporations are being victimized by the courts in what amounts to a radical transformation of tort law. Managers repeat variations of cases—for instance, of a man who purchased a thrice-owned punch machine, altered it, and after losing a finger, sued the original manufacturer for negligent construction; of a farmer who, despite clearly marked warning labels, coated his animal feed troughs with a toxic wood preservative, sold milk from contaminated cattle, and then when he himself was sued by irate parents whose children had drunk the milk, sued the chemical company who produced the preservative; or of a student research assistant inexplicably asked to carry dangerous acid in glass containers on a faulty elevator that lurched and caused the young woman to break a container, showering her with acid and permanently disfiguring her. Although she is said to have sued her university, her supervising professor, the elevator manufacturer, and the chemical company that provided the acid, managers had few doubts that the jury would “pin the tail on business” because of the “abiding conviction that corporations have vaults filled with gold bars called profits.” At some level, even managers who repeat such stories and thus reinforce their own shared sense of beleaguerment, recognize the profound and profoundly felt dependence of most people in our society on those large organizations that claim to control the scientific genie. (Location 3413)</p>
<p>161. was at this party the other night and I was sitting next to this older lady and she said: “My God, did you people see the paper tonight? There’s leakage from some chemical plant and it’s infecting the drinking water around here.” So I asked if I could see the paper and the article said that there was some seepage out of a pond that a chemical plant used for disposal but that the EPA was monitoring the situation as well as all 25 wells in the area. In the meantime, the company was remedying the situation. I pointed this out and she looked at me, her eyes narrowed, and she asked, “Who do you work for?” I said I worked for a large chemical firm and she burst out laughing and asked if I expected her to believe me. She laughed right in my face! I asked her what she was worried about. You have to drink the water for 25 years before anything would happen—I mean, she was already a grandmother—but that didn’t seem to help her much. (Location 3459)</p>
<p>162. My interviews are filled with stories of managers who claim to have been verbally assaulted not only by strangers at cocktail parties, but by their children’s teachers when they visit schools, and even by their children themselves at the breakfast table for being supposedly callous and insensitive to the social consequences of business activity. Perhaps more than anything else, managers are puzzled by such attacks, though they pounce quickly on any inconsistencies that they perceive in their opponents. For example, one manager whose firm produced a pesticide that became caught up in a widely publicized episode of mishandling and illegal disposal was attacked by his brother-in-law, a lifelong military man, for his very association with the company. The manager found it grimly ironic that “things have reached a point where a trained killer is berating me for producing something useful.” More generally, managers view the irrational fear of contamination evinced by those who espouse an ideology of bodily purity with some derision. One can, after all, referring to the same pesticide, “eat handfuls of the stuff with no lasting adverse effects.” (Location 3467)</p>
<p>163. Well, from 1957 through 1962, I was intimately involved with the manufacture of DDT. During that time, we doubled production and sold almost all of it to Africa and India. And I knew and went home knowing that I was saving more lives than any major hospital was capable of doing. I knew that I was saving thousands of lives by doing this. Then Rachel Carson’s Silent Spring came out and not only did I become a murderer of falcons and robins, but also one of the mass murderers of the world. I was now doing evil things to the world. Then I went to a plant which was manufacturing [chlorofluorocarbons] and we increased production by 20–25 percent; a lot of it went into hair sprays. We also used vinyl chloride and found out that it was causing liver cancer. Then I found out that I was destroying the whole ozone layer of the earth and doing it for personal gain. Then I went into soda ash. Without it, there wouldn’t be a window pane in the whole United States. But at the time, because of the Clean Air Act and the Clean Water Act, suddenly I became a polluter. Children learned in school that chemicals killed. And, of course, there was no question in the academic community that I was perceived as an evil person doing evil things. And that became true even in the corporation. Plants became a liability, rather than the source of wealth. The perception was: Wouldn’t it be nice if we could just sell chemicals without producing them? So the profession of producing things became a low profession and the good people were those who were producing services. Manufacturing people became evil. I think this is one reason that marketing people became ascendant in the competition for advancement. Then I went into making sulfuric acid and that involved the whole issue of water pollution. He goes on to describe his reaction to all of this: I guess I’m more bemused than anything else. It’s the same type of feeling that I would have if I were an MD who had been doing radical mastectomies and then someone says—hey, you didn’t have to do that. It’s a feeling of disappointment without a feeling of shame. I know that I have done some useful things. I know that the only source of money is taking something out of the ground and making something. That’s where money comes from—making something out of nothing. Without that type of activity, civilization wouldn’t exist. So, on something like DDT, I’ll leave the judgment to Europe after World War II and all the people saved by the widespread use of it. (Location 3482)</p>
<p>164. Within this context of perceived harassment and shifting scientific and ideological winds, while always attending to the pressing and sometimes contradictory exigencies of business life, managers must address a multiplicity of audiences, some of whom are considered rivals, and some outright adversaries. These audiences are the internal corporate hierarchy with its intricate and shifting power cliques and competing managerial circles, key regulators, local and federal legislators, special publics that vary according to the issues, and the public at large, whose goodwill and favorable opinions are considered essential for a company’s free operation. Managerial adeptness at inconsistency becomes evident in the widely discrepant perspectives, reasons for action, and presentations of fact that explain, excuse, or justify managerial behavior to these diverse audiences. (Location 3506)</p>
<p>165. The Supreme Court, however, decided in 1981 that the 1978 OSHA ruling was fully within the Agency’s mandate, namely to protect workers’ health and safety as the primary benefit exceeding all cost considerations. (Location 3533)</p>
<p>166. The segmented work patterns of bureaucracy underlie these larger structures. Managers’ cognitive maps to the thickets of their world contain sharp, sometimes absurd, caricatures of the style and ethos of different occupational groups. These suggest some of the ways in which managers appraise the myriad of character types whom they see peopling their world. Production types, for instance, are said to be hard-drinking, raucous, good-time charlies; engineers, always distinguishable by the plastic pen containers in their shirt pockets, are hostages to an outdated belief in a pristine mathematical rationality; accountants are bean counters who know how to play the shell game; lawyers are legal eagles or legal beagles in wool pinstripes who, if they had their way, would tie managers’ hands completely; corporate staff are the king’s spies, always ready to do his bidding and his dirty work; marketing guys are cheerful, smooth-talking, upbeat fashion plates who must nonetheless keep salesmen under their thumbs; salesmen are aggressive loudmouths who feel that they can sell freezers to penguins in Antarctica and who would sell their grandmothers just to make a deal. Salesmen hate the restraints that marketers put on their work and on their ego gratification. Financial wizards, on the ascendancy everywhere, are tight-mouthed, close to the vest poker players who think that a social order can be built on paper deals. And outside consultants are men and women who borrow one’s watch and then charge for telling the time. (Location 4327)</p>
<p>167. But so what, they argued, if the preservative did in fact pose some risk of cancer? Better, they said, the risk of a slight long-run increase in the rate of stomach and intestinal cancer than the certainty of a precipitous spurt in the incidence of botulism, particularly in the lower-income black and Hispanic groups that typically consume large amounts of processed meat and, both because of poverty and cultural practices, often leave food uncovered and unrefrigerated for considerable periods. Is corporate social responsibility, they asked, maintaining a private sense and public image of moral purity while someone else does necessary but tainted work? Or is real social responsibility the willingness to get one’s hands dirty, to make whatever compromises have to be made to produce a product with some utility, to achieve therefore some social good, even though one knows that one’s accomplishments and motives will inevitably be misinterpreted by others for their own ends, usually by those with the least reason to complain? Besides, they pointed out, consumers continue to purchase artificially preserved meats in large quantities. Is not the proper role of business “to give the public what it wants,” adopting the market as its polar star, as the only reliable guide in a pluralistic society to “the greatest good for the greatest number,” as the final arbiter not of values, which are always arguable, but, more importantly, of tastes, about which there can be no reasonable dispute? (Location 4500)</p>
<p>168. In fact, exercises in substantive rationality—the critical, reflective use of reason—are not only subject to infinite interpretations and counterinterpretations but also invite fantastic constructions of reality, including attributions of conspiracy. Thus a major corporation provides a gift of $10 million to establish new foundations that will materially aid South African blacks and is promptly accused by a black American leader of bolstering apartheid. Weft managers create an elaborate recreational complex for Weft employees in the corporation’s southern community and are charged with perpetuating traditional textile company paternalism. Some executives at Images Inc. donate their time to bring together several institutional sectors of a local town in which they live for community betterment and are charged with trying to grab headlines and line up future business. Managers often feel that, however genuine it may be, altruism is a motive that is always denied them by others. To complicate matters still further, the necessary self-promotional work of presenting private goals as public goods, or the self-defensive work within the corporation of presenting public goods as hardheaded business decisions, or managers’ knowledge that bureaucracy insulates them from the real consequences of their actual choices, often make their protestations of socially responsible actions suspect even to themselves. (Location 4512)</p>",Zvi,zvi,Zvi,
dQzkuqoTQcmfP27z8,OECD agenda [Link],oecd-agenda-link,https://www.lesswrong.com/posts/dQzkuqoTQcmfP27z8/oecd-agenda-link,2019-05-30T09:51:58.849Z,1,3,1,False,False,,"<p> <a href=""https://www.oecd.org/going-digital/ai/principles/"">https://www.oecd.org/going-digital/ai/principles/</a> </p><p>What&#x27;s your oppinions about this? </p>",Thomas,thomas,Thomas,
BAjGyMsyZc4MdHEeu,Archive of all LW essay contests,archive-of-all-lw-essay-contests,https://www.lesswrong.com/posts/BAjGyMsyZc4MdHEeu/archive-of-all-lw-essay-contests,2019-05-30T06:40:02.587Z,12,3,0,False,False,,"<p><a href=""https://docs.google.com/spreadsheets/d/11Zm2YSgb-U-QOXKNvkariT-eXh_ztoi3pm_ftsoxAlI/edit?usp=sharing"">I&#x27;ve compiled all the LW writing contests I could find to date.</a> There are 15 in all, plus a few more from other websites. Quite a few of the articles have disappeared from the web, and a couple contests are either still running or were never completed. To help future contest-runners, I added basic info about the structure of each contest. Feel free to add links to other LW posts about essay bounties you think would be useful. This is a document that anyone can edit. I have a copy saved just in case.</p>",AllAmericanBreakfast,directedevolution,DirectedEvolution,
B3NR6SwkXkvY8cFpK,"How to find a lost phone with dead battery, using Google Location History Takeout",how-to-find-a-lost-phone-with-dead-battery-using-google,https://www.lesswrong.com/posts/B3NR6SwkXkvY8cFpK/how-to-find-a-lost-phone-with-dead-battery-using-google,2019-05-30T04:56:28.666Z,53,34,5,False,False,,"<html><head></head><body><p>Or, wow, it's crazy how much Google knows about me.</p>
<p>(I'm writing this in part because I tried to Google variations of ""how to find a lost phone with dead battery"" and among all the articles in the search results that I clicked on, didn't see anyone write up this technique that I later figured out myself.)</p>
<p>I lost a brand new Android phone recently inside my own home. I knew it was inside my home because I remembered using it after I got home. Normally in that situation I would call it or use Google's Find Device feature to make the phone ring, but the phone's battery had died before I realized that it was lost. I spent a couple of hours looking for it in all the obvious places, like behind sofa cushions, in the garbage can, everywhere in the house I had been (or might have been but forgot) since I last used the phone, but failed to find it. Find Device gives the last known location of a phone, but the error circle encompassed the whole house so that wasn't very helpful.</p>
<p>Eventually I decided to download all of the data Google has on the history of the phone's location using a feature called <a href=""https://takeout.google.com"">Takeout</a>, just in case it offered any further clues, and that's when I realized that in Google's databases there's an entry for every time one of my phones moves even a little bit, with a timestamp, location estimate, velocity estimate, and a guess of whether I was walking, running, biking, in a car, etc. (presumably inferred using the phone's accelerometer). I <a href=""https://github.com/Scarygami/location-history-json-converter"">converted</a> the data from JSON to CSV and then looked at the last time the phone moved. (BTW the timestamps are in UTC time, which confused me for a while until I realized that.) Then I looked at my Google <a href=""https://myactivity.google.com/"">Activity History</a> to find out what I was doing at that time. The Activity History told me I did a particular Google search around that time, and I remembered I was sitting in a particular armchair while doing that search. (Google Activity History also has a whole bunch of other information, like every time I launch an app on my phone, or visit a website using Chrome.)</p>
<p>Of course I had searched that armchair already but this knowledge incentivized me to do a much more thorough search, and it turned out that the phone had fallen down a very narrow crack in the armchair to a pocket underneath. I ended up retrieving the phone by cutting open the fabric covering the bottom of the armchair.</p>
</body></html>",Wei_Dai,wei-dai,Wei Dai,
mAswxJo8pvtAq4d9y,South Bay Meetup,south-bay-meetup,https://www.lesswrong.com/events/mAswxJo8pvtAq4d9y/south-bay-meetup,2019-05-30T02:32:04.885Z,4,2,0,False,False,,,DavidFriedman,davidfriedman,DavidFriedman,
XyjQoLWDc6usKXAko,Seeking suggestions for EA cash-prize contest,seeking-suggestions-for-ea-cash-prize-contest,https://www.lesswrong.com/posts/XyjQoLWDc6usKXAko/seeking-suggestions-for-ea-cash-prize-contest,2019-05-29T20:44:35.311Z,14,6,1,False,False,,"<br/><p>I have grown interested in the cash-prize EA essay contest format that I&#x27;ve seen on LessWrong. I&#x27;m interested in sponsoring a 3-essay series of contests, and would appreciate exploratory thoughts and critique. My goal is to make this essay series produce genuinely useful new information for the community and lead to positive changes in the way we organize these contests. Any strategic advice would be helpful.</p><p>The first essay would be on the prompt &quot;What is the most effective way to run a cash-prize EA essay contest? Make sure to specify how winners should be selected and prize money distributed.&quot;</p><p>The second would implement suggestions from the first contest, and be on the prompt &quot;what is the most compelling argument for not running cash-prize EA essay contests?&quot;</p><p>The third would be on the prompt &quot;How could we design a useful scientific experiment to determine the ideal size of essay cash prizes?&quot;</p><p>My plan is to offer $50-$100 as cash prizes for each essay. I don&#x27;t earn a lot by American standards, which is why these prizes are relatively small. I&#x27;m considering crowdfunding for higher prizes. I&#x27;m not sure if I should allocate it all to the winner or divide it among top posts.</p><p>For the second essay, I can determine the winner through the method suggested by the first essay. But for judging the first essay, how should I go about it?</p>",AllAmericanBreakfast,directedevolution,DirectedEvolution,
AYc58gmoWnmDeeyuM,What is required to run a psychology study?,what-is-required-to-run-a-psychology-study,https://www.lesswrong.com/posts/AYc58gmoWnmDeeyuM/what-is-required-to-run-a-psychology-study,2019-05-29T06:38:13.727Z,30,10,14,False,True,,"<p>I periodically find myself wishing someone had run an experiment on a particular topic. But they haven&#x27;t.</p><p>Often, it seems like there&#x27;s a relatively easy experiment you can run, which would give me some evidence about it. Maybe it wouldn&#x27;t be perfect evidence, but it would be better than me making stuff up from my armchair.</p><p>The two clusters of things-I-can-imagine-being-quite-hard are:</p><ul><li>Legal requirements</li><li>Actually doing the science right (avoiding sampling biases, actually testing the right variable, etc)</li></ul><p><strong>Legal Stuff</strong></p><p>Scott&#x27;s <a href=""https://slatestarcodex.com/2017/08/29/my-irb-nightmare/"">IRB Nightmare</a> suggests that the legal requirements can be quite awful. I&#x27;m unclear on what those requirements are if I don&#x27;t want to publish anywhere, don&#x27;t plan to interface with any hospital bureaucracies, I just want to ask a bunch of people to try something and see how it goes (and maybe make a LessWrong blogpost so people on LessWrong can know too)</p><p>Am I allowed to just go out and ask a whole bunch of people stuff? If I want to know things about 8 year olds or 16 year olds, if their parents sign a form and I&#x27;m not doing anything especially weird or traumatic, would that be fine or would terrible things happen to me? (Could I replicate the Marshmallow Test?)</p><p><strong>Doing Science Good Enough</strong></p><p>I have a sense that there&#x27;s a lot of ways to deceive yourself if you have a pet psychology theory. But... I dunno it also seems like LessWrong collectively should be pretty good at this. The thing I might want to do (or get others to do sometimes) is post a plan for a study here, and get critiqued until it seems like an actually good plan, do the plan, write up the results.</p><p><strong>Particular Things I was interested in:</strong></p><p>(not meant to be exhaustive, important, or particularly achievable plans, just the things that generated this question)</p><ul><li>How do most people relate to their job? (There&#x27;s a survey study that asks if people consider it a job, a career, or a calling, but the study had a very narrow range of participants – people who worked at one particular place, and I&#x27;m curious how a wider variety of people would respond)</li><li>How do most people relate to ambition? (where by ambition I mean &quot;form plans to create or change things that will impact large numbers of people.&quot;)</li><li>How many 8 year olds can learn to program? Can they implement FizzBuzz? How many 16 year olds? How many 30 year olds? I&#x27;ve heard that people either have-or-don&#x27;t-have a &quot;programmer trait&quot; that&#x27;s hard to learn, and I&#x27;m not sure how much of that is true at all, and if so if it&#x27;s more about nature or nurture.</li></ul>",Raemon,raemon,Raemon,
qaYeQnSYotCHQcPh8,Drowning children are rare,drowning-children-are-rare,https://www.lesswrong.com/posts/qaYeQnSYotCHQcPh8/drowning-children-are-rare,2019-05-28T19:27:12.548Z,10,41,173,False,False,http://benjaminrosshoffman.com/drowning-children-rare/,"<p>Stories such as Peter Singer's ""drowning child"" hypothetical frequently imply that there is a major funding gap for health interventions in poor countries, such that there is a moral imperative for people in rich-countries to give a large portion of their income to charity. There are simply not enough excess deaths for these claims to be plausible.</p><p>Much of this is a restatement of <a href=""http://benjaminrosshoffman.com/givewell-case-study-effective-altruism-4/#Case_2_Top_charities_can_scale"">part</a> of my series on <a href=""http://benjaminrosshoffman.com/givewell-and-partial-funding/"">GiveWell and the problem of partial funding</a>, so if you read that carefully and in detail, this may not be new to you, but it's important enough to have its own concise post. This post has been edited after its initial publication for clarity and tone.</p><h1>People still make the funding gap claim</h1><p>In his 1997 essay<a href=""https://www.utilitarian.net/singer/by/199704--.htm""> The Drowning Child and the Expanding Circle</a>, Peter Singer laid out the basic argument for a moral obligation to give much more than most to, for the good of poor foreigners:</p><blockquote><em>To challenge my students to think about the ethics of what we owe to people in need, I ask them to imagine that their route to the university takes them past a shallow pond. One morning, I say to them, you notice a child has fallen in and appears to be drowning. To wade in and pull the child out would be easy but it will mean that you get your clothes wet and muddy, and by the time you go home and change you will have missed your first class.</em><br><em>I then ask the students: do you have any obligation to rescue the child? Unanimously, the students say they do. The importance of saving a child so far outweighs the cost of getting one’s clothes muddy and missing a class, that they refuse to consider it any kind of excuse for not saving the child. Does it make a difference, I ask, that there are other people walking past the pond who would equally be able to rescue the child but are not doing so? No, the students reply, the fact that others are not doing what they ought to do is no reason why I should not do what I ought to do.</em><br><em>Once we are all clear about our obligations to rescue the drowning child in front of us, I ask: would it make any difference if the child were far away, in another country perhaps, but similarly in danger of death, and equally within your means to save, at no great cost – and absolutely no danger – to yourself? Virtually all agree that distance and nationality make no moral difference to the situation. I then point out that we are all in that situation of the person passing the shallow pond: we can all save lives of people, both children and adults, who would otherwise die, and we can do so at a very small cost to us: the cost of a new CD, a shirt or a night out at a restaurant or concert, can mean the difference between life and death to more than one person somewhere in the world – and overseas aid agencies like Oxfam overcome the problem of acting at a distance.</em></blockquote><p>Singer no longer consistently endorses cost-effectiveness estimates that are so low, but still endorses the basic argument. Nor is this limited to him. As of 2019, GiveWell <a href=""https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness/cost-effectiveness-models"">claims</a> that its top charities can avert a death for a few thousand dollars, and the Center for Effective Altruism <a href=""https://www.effectivealtruism.org/articles/introduction-to-effective-altruism/"">claims</a>&nbsp;that someone with a typical American income can save dozens of lives over their lifetime by donating 10% of their income to the Against Malaria Foundation, which points to GiveWell's analysis for support. (This despite GiveWell's long-standing&nbsp;<a href=""https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/"">disclaimer</a> that you shouldn't take its expected value calculations literally). The 2014 Slate Star Codex post <a href=""https://slatestarcodex.com/2014/05/10/infinite-debt/"">Infinite Debt</a>&nbsp;describes the Giving What We Can pledge as effectively a negotiated compromise between the perceived moral imperative to give literally everything you can to alleviate <a href=""https://slatestarcodex.com/2014/09/27/bottomless-pits-of-suffering/"">Bottomless Pits of Suffering</a>, and the understandable desire to still have some nice things.</p><h1>How many excess deaths can developing-world interventions plausibly avert?</h1><p>According to the <a href=""https://www.thelancet.com/pdfs/journals/lancet/PIIS0140-6736(18)32203-7.pdf"">2017 Global Burden of Disease</a> report, around 10 million people die per year, globally, of ""Communicable, maternal, neonatal, and nutritional diseases.”* This is roughly the category that the low cost-per-life-saved interventions target. If we assume that&nbsp;<em>all</em> of this is treatable at current cost per life saved numbers - the most generous possible assumption for the claim that there's a funding gap - then at $5,000 per life saved (substantially higher than GiveWell's current estimates), that would cost about $50 Billion to avert.</p><p>This is already well within the capacity of funds available to the Gates Foundation alone, and the Open Philanthropy Project / GiveWell is the main advisor of another multi-billion-dollar foundation, Good Ventures. The true number is almost certainly much smaller because many communicable, maternal, neonatal, and nutritional diseases do not admit of the kinds of cheap mass-administered cures that justify current cost-effectiveness numbers.</p><p>Of course, that’s an annual number, not a total number. But if we think that there is a present, rather than a future, funding gap of that size, that would have to mean that it’s within the power of the Gates Foundation alone to wipe out all fatalities due to communicable diseases immediately, a couple times over - in which case the progress really would be permanent, or at least quite lasting. And infections are the major target of current mass-market donor recommendations.</p><p>Even if we assume&nbsp;<em>no</em> long-run direct effects (no reduction in infection rates the next year, no flow-through effects, the people whose lives are saved just sit around not contributing to their communities), a large funding gap implies opportunities to&nbsp;<em>demonstrate</em> impact empirically with existing funds.&nbsp;Take the example of malaria alone (the target of the intervention specifically mentioned by CEA in its ""dozens of lives"" claim). The GBD report estimates 619,800 annual deaths - a reduction by&nbsp;<em>half</em> at $5k per life saved would only cost $3 billion per year, an annual outlay that the Gates Foundation alone could sustain for over a decade, and Good Ventures could certainly maintain for a couple of years on its own.</p><p>GiveWell's stated reason for not bothering to monitor statistical data on outcomes (such as e.g. malaria incidence and mortality, in the case of AMF) is that <a href=""http://benjaminrosshoffman.com/effective-altruism-is-self-recommending/#Version_0_GiveWell_and_passive_funding"">the data are too noisy</a>. A reduction like that ought to be&nbsp;<em>very</em> noticeable, and therefore ought to make filling the&nbsp;<em>next</em> year's funding gap much more appealing to other potential donors. (And if the intervention&nbsp;<em>doesn't</em> do what we thought, then potential donors are&nbsp;<em>less</em> motivated to step in - but that's good, because it doesn't work!)</p><p>Imagine the world in which funds already allocated are enough to bring deaths due to&nbsp;communicable, maternal, neonatal, and nutritional diseases to zero or nearly zero even for one year. What else would be possible? And if you think that people's revealed preferences correctly assume that this is far from possible, what specifically does that imply about the cost per life saved?</p><h1>What does this mean?</h1><p>If the low cost-per-life-saved numbers are meaningful and accurate, then charities like the Gates Foundation and Good Ventures are hoarding money at the price of millions of preventable deaths. If the Gates Foundation and Good Ventures are behaving properly because they know better, then the opportunity to save additional lives cheaply has been greatly exaggerated. My former employer GiveWell in particular stands out, since it&nbsp;<em>publishes</em> such cost-per-life-saved numbers, and yet <a href=""https://blog.givewell.org/2015/11/25/good-ventures-and-giving-now-vs-later/"">recommended to Good Ventures</a> that it not fully fund GiveWell's top charities; they were <a href=""https://blog.givewell.org/2015/11/25/good-ventures-and-giving-now-vs-later/"">worried that Good Ventures would be saving more than their ""fair share"" of lives</a>.</p><p>In either case, we're not getting these estimates from a source that behaves as though it both cared about and believed them. The process that promoted them to your attention is more like advertising than like science or business accounting. Basic epistemic self-defense requires us to interpret them as marketing copy designed to control your behavior, not unbiased estimates designed to improve the quality of your decisionmaking process.</p><p>We should be more skeptical, not less, of vague claims by the same parties to even more spectacular returns on investment for speculative, hard to evaluate interventions, especially ones that <a href=""http://benjaminrosshoffman.com/openai-makes-humanity-less-safe/"">promise to do the opposite</a> of what the argument justifying the intervention recommends.</p><p>If you give based on mass-marketed high-cost-effectiveness representations, you're buying mass-marketed high-cost-effectiveness representations, not lives saved. Doing a little good is better than buying a symbolic representation of a large amount of good. There's no substitute for developing and acting on your own models of the world.</p><p>As far as I can see, this pretty much destroys the generic utilitarian imperative to live like a monk while maximizing earnings, and give all your excess money to the global poor or something even more urgent. Insofar as there's a way to fix these problems as a low-info donor, there's already enough money. Claims to the contrary are either obvious nonsense, or marketing copy by the same people who brought you the obvious nonsense. Spend money on taking care of yourself and your friends and the people around you and your community and trying specific concrete things that might have specific concrete benefits. And <a href=""http://benjaminrosshoffman.com/towards-optimal-play-as-villager-in-a-mixed-game/"">try to fix the underlying systems problems</a> that got you so confused in the first place.</p><p>* A previous version of this post erroneously read a decadal rate of decline as an annual rate of decline, which implied a stronger conclusion than is warranted. Thanks to Alexander Gordon-Brown to pointing out the error.</p>",Benquo,benquo,Benquo,
MWW23dueMoPqmvCx8,Evidence for Connection Theory,evidence-for-connection-theory,https://www.lesswrong.com/posts/MWW23dueMoPqmvCx8/evidence-for-connection-theory,2019-05-28T17:06:52.635Z,14,4,13,False,False,https://www.scribd.com/document/219774356/Evidence-for-Connection-Theory#fullscreen,"<p>Connection Theory (CT) is the original philosophy underpinning <a href=""http://leverageresearch.org/"">Leverage Research</a>, a research think tank focused that has worked with the effective altruism movement, and the rationality community, in the past on community-building, and existential risk reduction. CT was developed by Leverage&#x27;s executive director, Geoff Anders. Since there are few if any other publicly available online resources for understanding or evaluating CT, I thought I would share this document.  </p>",Evan_Gaensbauer,evan_gaensbauer,Evan_Gaensbauer,
hubbRt4DPegiA5gRR,A shift in arguments for AI risk,a-shift-in-arguments-for-ai-risk,https://www.lesswrong.com/posts/hubbRt4DPegiA5gRR/a-shift-in-arguments-for-ai-risk,2019-05-28T13:47:36.486Z,32,14,7,False,False,https://fragile-credences.github.io/prioritising-ai/,"<p><em>The linked post is work done by Tom Adamczewski while at FHI. I think this sort of expository and analytic work is very valuable, so I&apos;m cross-posting it here (with his permission). Below is an extended summary; for the full document, see his linked blog post.</em></p><p>Many people now work on ensuring that advanced AI has beneficial consequences. But members of this community have made several quite different arguments for prioritising AI.</p><p>Early arguments, and in particular <em>Superintelligence</em>, identified the &#x201C;alignment problem&#x201D; as the key source of AI risk. In addition, the book relies on the assumption that superintelligent AI is likely to emerge through a discontinuous jump in the capabilities of an AI system, rather than through gradual progress. This assumption is crucial to the argument that a single AI system could gain a &#x201C;decisive strategic advantage&#x201D;, that the alignment problem cannot be solved through trial and error, and that there is likely to be a &#x201C;treacherous turn&#x201D;. Hence, the discontinuity assumption underlies the book&#x2019;s conclusion that existential catastrophe is a likely outcome.</p><p>The argument in <em>Superintelligence</em> combines three features: (i) a focus on the alignment problem, (ii) the discontinuity assumption, and (iii) the resulting conclusion that an existential catastrophe is likely.</p><p>Arguments that abandon some of these features have recently become prominent. They also generally tend to have been made in less detail than the early arguments.</p><p>One line of argument, promoted by Paul Christiano and Katja Grace, drops the discontinuity assumption, but continues to view the alignment problem as the source of AI risk. Even under more gradual scenarios, they argue that, unless we solve the alignment problem before advanced AIs are widely deployed in the economy, these AIs will cause human values to eventually fade from prominence. They appear to be agonistic about whether these harms would warrant the label &#x201C;existential risk&#x201D;.</p><p>Moreover, others have proposed AI risks that are unrelated to the alignment problem. I discuss three of these: (i) the risk that AI might be misused, (ii) that it could make war between great powers more likely, and (iii) that it might lead to value erosion from competition. These arguments don&#x2019;t crucially rely on a discontinuity, and the risks are rarely existential in scale.</p><p>It&#x2019;s not always clear which of the arguments actually motivates members of the beneficial AI community. It would be useful to clarify which of these arguments (or yet other arguments) are crucial for which people. This could help with evaluating the strength of the case for prioritising AI, deciding which strategies to pursue within AI, and avoiding costly misunderstanding with sympathetic outsiders or sceptics.</p>",ricraz,ricraz,Richard_Ngo,
YBaPge5g3234hrGHN,What should rationalists think about the recent claims that air force pilots observed UFOs?,what-should-rationalists-think-about-the-recent-claims-that,https://www.lesswrong.com/posts/YBaPge5g3234hrGHN/what-should-rationalists-think-about-the-recent-claims-that,2019-05-27T22:02:49.041Z,12,18,28,False,True,,"<p>NY times has <a href=""https://www.nytimes.com/2019/05/26/us/politics/ufo-sightings-navy-pilots.html"">a new material</a> about possible observations of UFOs by air force pilots. Should rationalists use their arsenal of new ideas about how the world works – simulation, superintelligent AIs etc – to explain these things, or should they be of more sceptical side and explain them via some combination of biases and hoaxes?</p><p>For example, one could speculate that an alien AI have terminated long before now, but some of its self-replicating robots colonised the universe. Or may be we live in a simulation which is full of glitches and viruses? </p><p>It is possible to create many hypothesis like these with infinite explanatory powers.</p>",avturchin,avturchin,avturchin,
b6AB7LhSG5krtKEje,Was CFAR always intended to be a distinct organization from MIRI?,was-cfar-always-intended-to-be-a-distinct-organization-from,https://www.lesswrong.com/posts/b6AB7LhSG5krtKEje/was-cfar-always-intended-to-be-a-distinct-organization-from,2019-05-27T16:58:05.216Z,7,2,3,False,True,,"<p>When what would later become CFAR first started as a series of rationality workshops run under the purview of MIRI in 2012, was it always the intention of CFAR&#x27;s founders to have it be a project/organization distinct from MIRI since its beginning? Or, did CFAR&#x27;s founders decide to incorporate CFAR as an organization separate from MIRI after it became clear the rationality workshops weren&#x27;t a fit project for MIRI itself later on?</p>",Evan_Gaensbauer,evan_gaensbauer,Evan_Gaensbauer,
Eve2miBH8wAhhxNwT,Von Neumann’s critique of automata theory and logic in computer science,von-neumann-s-critique-of-automata-theory-and-logic-in,https://www.lesswrong.com/posts/Eve2miBH8wAhhxNwT/von-neumann-s-critique-of-automata-theory-and-logic-in,2019-05-26T04:14:24.509Z,29,11,4,False,False,,"<p>Quote from <a href=""https://www.cs.ucf.edu/~dcm/Teaching/COP5611Spring2010/vonNeumannSelfReproducingAutomata.pdf"">The General and Logical Theory of Automata</a>. Corrected some typos using <a href=""https://www.vordenker.de/ggphilosophy/jvn_the-general-and-logical-theory-of-automata.pdf"">this</a> version. H/T <a href=""https://news.ycombinator.com/item?id=20010812"">Hacker News</a>.</p><br/><blockquote>There exists today a very elaborate system of formal logic, and, specifically, of logic as applied to mathematics. This is a discipline with many good sides, but also with certain serious weaknesses. This is not the occasion to enlarge upon the good sides, which I have certainly no intention to belittle. About the inadequacies, however, this may be said: Everybody who has worked in formal logic will confirm that it is one of the technically most refractory parts of mathematics. The reason for this is that it deals with rigid, all-or-none concepts, and has very little contact with the continuous concept of the real or of the complex number, that is, with mathematical analysis. Yet analysis is the technically most successful and best-elaborated part of mathematics. <strong>Thus formal logic is, by the nature of its approach, cut off from the best cultivated portions of mathematics, and forced onto the most difficult part of the mathematical terrain, into combinatorics</strong>.</blockquote><blockquote>The theory of automata, of the digital, all-or-none type, as discussed up to now, is certainly a chapter in formal logic. It would, therefore, seem that it will have to share this unattractive property of formal logic. It will have to be, from the mathematical point of view, combinatorial rather than analytical.</blockquote><blockquote><em>Probable Characteristics of Such a Theory.</em> Now it seems to me that this will in fact not be the case. In studying the functioning of automata, it is clearly necessary to pay attention to a circumstance which has never before made its appearance in formal logic. </blockquote><blockquote>Throughout all modern logic, the only thing that is important is whether a result can be achieved in a finite number of elementary steps or not. The size of the number of steps which are required, on the other hand, is hardly ever a concern of formal logic. Any finite sequence of correct steps is, as a matter of principle, as good as any other. It is a matter of no consequence whether the number is small or large, or even so large that it couldn’t possibly be carried out in a lifetime, or in the presumptive lifetime of the stellar universe as we know it. In dealing with automata, this statement must he significantly modified. In the case of an automaton the thing which matters is not only whether it can reach a certain result in a finite number of steps at all but also how many such steps are needed. There are two reasons. First, automata are constructed in order to reach certain results in certain pre-assigned durations, or at least in pre-assigned orders of magnitude of duration. Second, the componentry employed has in every individual operation a small but nevertheless non-zero probability of failing. In a sufficiently long chain of operations the cumulative effect of these individual probabilities of failure may (if unchecked) reach the order of magnitude of unity-at which point it produces, in effect, complete unreliability. The probability levels which are involved here are very low, but still not too far removed from the domain of ordinary technological experience. It is not difficult to estimate that a high-speed computing machine, dealing with a typical problem, may have to perform as much as 10^12 individual operations. The probability of error on an individual operation which can be tolerated must, therefore, be small compared to 10^-12. I might mention that an electromechanical relay (a telephone relay) is at present considered acceptable if its probability of failure on an individual operation is of the order 10^-8. It is considered excellent if this order of probability is 10^-9 Thus the reliabilities required in a high-speed computing machine are higher, but not prohibitively higher, than those that constitute sound practice in certain existing industrial fields. The actually obtainable reliabilities are, however, not likely to leave a very wide margin against the minimum requirements just mentioned. An exhaustive study and a nontrivial theory will, therefore, certainly be called for. </blockquote><blockquote>Thus the logic of automata will differ from the present system of formal logic in two relevant respects. </blockquote><blockquote>1. The actual length of “chains of reasoning,” that is, of the chains of operations, will have to be considered. </blockquote><blockquote>2. The operations of logic (syllogisms, conjunctions, disjunctions, negations, etc., that is, in the terminology that is customary for automata, various forms of gating, coincidence, anti-coincidence, blocking, etc., actions) will all have to be treated by procedures which allow exceptions ( malfunctions ) with low but non-zero probabilities. All of this will lead to theories which are much less rigidly of an all-or-none nature than past and present formal logic. They will be of a much less combinatorial, and much more analytical, character.</blockquote>",Benito,benito,Ben Pace,
oGBkjRZ3r5ibxRzZF,Is AI safety doomed in the long term?,is-ai-safety-doomed-in-the-long-term,https://www.lesswrong.com/posts/oGBkjRZ3r5ibxRzZF/is-ai-safety-doomed-in-the-long-term,2019-05-26T02:30:12.010Z,-1,7,11,False,True,,"<p>Are there any measures that humanity can put in place to control a vastly (and increasingly) more intelligent race?<br/></p><p>On the basis that humans determine the fate of other species on the planet, I cannot find any reasons for believing that a lesser intelligence can control a greater intelligence.<br/>Which leads me to think that AI safety is at most about controlling the development of AI until it makes, and can implement, its own decisions about the fate of humanity.<br/></p><p>Is this a common stance and I am naively catching up?<br/>Or what are the counter arguments?</p>",JakeH,jakeh,JakeH,
vmcii44HYJQkL8DQN,Micro feedback loops and learning,micro-feedback-loops-and-learning,https://www.lesswrong.com/posts/vmcii44HYJQkL8DQN/micro-feedback-loops-and-learning,2019-05-26T00:50:36.202Z,53,25,13,False,False,,"<p><em>Tldr: some not-particularly-ordered thoughts about how learning works in humans, via the example of singing. </em></p><h2><strong>A high-tech feedback loop</strong></h2><p>I recently discovered <a href=""https://www.erolstudios.com/singers-studio-voice-and-ear-training/"">Singer’sStudio</a>, an iPhone app for voice training that is approximately the Best Thing Ever (h/t <a href=""https://www.lesswrong.com/users/raemon"">Raemon</a>). It’s a work of pedagogical art, and describing what it does right pulls together various nebulous thoughts I’ve had about learning and developing intuitions for a particular domain. </p><p>How the app works: it gives me various singing exercises, and then tells me in real-time, via a pretty graph, if I’m singing on pitch. That’s it. </p><span><figure><img src=""https://i.imgur.com/7NARgMK.png"" class=""draft-image center"" style=""width:34%"" /></figure></span><p>Okay, it does have a few other features, like:</p><ul><li>A total score and breakdown by % of notes correct after each exercise.</li><li>Letting me play myself back to see what being on vs slightly off pitch sounds like.</li><li>Helpful text prompts such as “keep your tongue behind your teeth.”</li><li>A built-in progression from easier to more complicated exercises.</li><li>Exercises for a specific skill, like switching from head to chest voice.</li><li>The ability to add challenge by turning down/off the piano playing my notes as I sing them. </li><li>Not a built-in part of the app, but I can glance away from the screen and sing without the visual feedback, and then immediately check how I did. </li></ul><span><figure><img src=""https://i.imgur.com/z4s867D.jpg"" class=""draft-image center"" style=""width:32%"" /></figure></span><br/><span><figure><img src=""https://i.imgur.com/tULXkxl.png"" class=""draft-image center"" style=""width:32%"" /></figure></span><p>But I’m pretty confident that the pitch contour is the most important part, and an app that only did that thing would be almost as good on the skill-building side.</p><p>There are obviously a lot of singing sub-skills other than hitting notes, like vocal timbre, head versus chest voice, breathing from the diaphragm, enunciating consonants clearly, and singing vowels that don’t sound weird. A voice teacher would be able to comment on these directly.  </p><p>Still, in practice the app ends up causing me to improve on a bunch of these sub-skills as well, to the extent that getting them wrong results in singing off-pitch. The instantaneous feedback is doing a lot of work here – if the app only gave me a score at the end of each exercise, I predict I would end up quite stuck on what to change up in order to do better. However, I’ve ended up e.g. remembering to breathe from my diaphragm, because not doing that reliably resulted in my voice being wobbly, which was obvious on my pitch contour. (It also has instructions for breathing exercises as part of each warm-up, but I only actually did those exercises once or twice; they are boring compared to singing and getting pretty graphs.) </p><p>It’s amazing how fast my brain learned to turn a smooth, stair-like pitch contour into dopamine hits, and feel a flicker of pain every time I jumped above or below the note before finding it. I end up very motivated to play around with any variables that make the graph prettier. </p><h2><strong>Rewardingness</strong></h2><p>It occurs to me that another feature, which I think is less key than the instantaneous pitch contour but still pretty important, is how it slightly gamifies the entire thing, and thus makes it addictive. There are % scores at the end of the exercise! And points! It logs my all-time high score for each exercise so I can try to beat it! It also logs how many minutes a day I’ve practiced. All of this makes me more likely to use it, and actually putting in the time is a key part of training any skill. </p><p>It’s also cool that I can listen to my voice and, in addition to catching mistakes (ouch!), notice when hey, wow, I actually sounded good there. This lets me gradually figure out what correlates with liking how my voice sounds, and it also gives me a warm glow of satisfaction and helps me feel like a Real Singer. </p><p>(I’m not sure if the app is cheating by doing some kind of post-processing on these recordings to make them sound pretty. Normally I hate recordings of myself speaking, let alone singing. Still, I’ll take it.) </p><p>It also seems relevant that there’s zero embarrassment factor – this isn’t a human watching me and judging me for daring to sing when I kind of suck. I’m pretty shameless, as humans go, but I’ve been slightly nervous with every voice teacher I’ve had – they’re an expert! they’re probably really unimpressed! – and tension is not good for singing well. With this, I can sing my heart out in the privacy of my apartment, and even feel safe experimenting. </p><h2><strong>How does this generalize? </strong></h2><p>This is a post about singing, but it’s also a post about learning skills in general. </p><p>Learning to sing (or to play the piano, tie one’s shoes, draw, dance, swim; all the things commonly known as <a href=""https://en.wikipedia.org/wiki/Procedural_memory"">procedural memory</a>) isn’t like memorizing a list of dates for a history test. There are some steps that can usefully happen in the explicit verbal loop, like “remember to breathe from the diaphragm”, but the end goal is that basically nothing is being held in working memory, and everything happens on the level of microsecond-to-second intuitions and muscle memory. </p><p>I think there are a really large number of skills, physical and mental, that are somewhere on a gradient between this and <a href=""https://en.wikipedia.org/wiki/Explicit_memory"">explicit memorization</a>. Chess seems like a good example; it’s possible to play it from knowledge of the rules and explicit reasoning/strategizing, and there’s always some of this, but analyzing the entire game explicitly is intractable, and from what I’ve heard, experts heavily rely on intuition. ICU nursing and running events, both things I have more personal inside knowledge of, are maybe a bit closer to the intuitive or procedural end; the time pressure and urgency, and the sheer amount of stuff going on, makes explicitly reasoning through each decision less useful. Something like accounting is further towards the explicit end, but even that gets a lot more automatic with practice, and intuition is what makes something jump out as “wrong” to me. </p><p>Practicing a procedural skill without the benefit of a clever app involves two steps – trying it out (controlling my vocal chords to sing a set of notes), and being able to evaluate how good or bad a given attempt was (my “ear”). Becoming an expert involves improving <em>both</em> of these functions; at any given moment, in order for an instance of practicing to lead in the direction of progress, the evaluation process needs to be more accurate than the execution process.</p><p>I’ve heard anecdotes about the phenomenon of having discernment for “good X” that far exceeds one’s ability to perform X, and I’ve occasionally experienced this for other things, like writing. Therein lies frustration and embarrassment and self-judgement. In my experience, this often causes people to avoid practicing a skill, even though really it’s a <em>good thing </em>if your taste for X is refined enough to notice your own mistakes – that&#x27;s how you know what to do differently the next time! </p><p>With singing, past a certain level I struggle to improve my ear enough to notice mistakes, which limits how much progress I can make just singing by myself at home. Voice teachers and other sources of feedback can help, but this is slower and thus less useful for <a href=""https://en.wikipedia.org/wiki/Shaping_(psychology)"">shaping</a>, in the same way that giving a dog a treat with a 5-min delay is going to be much less effective for training purposes.</p><p>This app creates a feedback loop on the sub-second level, using a different channel (my visual cortex) that doesn’t interfere with singing or listening, and which is a lot more accurate than my own internal sense for whether I’m on pitch. My hypothesis is that some lucky people do have this sort of high-quality discernment for pitch already developed in their brains, or develop it young, and they’re the ones who learn how to sing without much effort – and, because singing badly is tied up in embarrassment and shame, they’re probably the people who tend to become excellent singers at all. I expect most people with my level of innate talent, or lack thereof, just give up. </p><p>The app also lets me test and calibrate my sense of pitch more directly, so that maybe, someday, I’ll be able to tell in real-time, on my own, if I’m landing the notes in a song. (Currently I cheat and use <a href=""https://itunes.apple.com/us/app/vocal-pitch-monitor/id842218231?mt=8"">VocalPitchMonitor</a> for this, since SingerStudio isn&#x27;t <em>quite </em>cool enough to let me upload random sheet music and use that to get feedback on real songs.) I play myself back and stare at the pitch contour, and try to hear the slight wrongness when the line indicates I’m just barely sharp or flat; it’s better than previous “ear training” I’ve done with a teacher or out of a book, and I’m hopeful. </p><h2><strong>Implications</strong></h2><p>This app is a really cool category of thing, that’s only possible at all due to fairly recent technological advances, and there are probably a ton more instances that I don’t know about. </p><p>I’m curious where else this has been explored. Singing may be an easy case, because measuring a single straightforward variable, pitch, gets you so far. I can imagine an app that trains, say, krav maga fighting techniques, via video analysis and/or accelerometer data, but I’m not sure that’s possible yet given current tech. </p><p>It has me thinking about other pedagogical techniques, though. Martial arts teachers will shout real-time feedback at you (&quot;turn your hips more! get your knee higher!&quot;) I’ve taught swimming, and one issue is that waiting until a swimmer finishes a lap before giving any feedback introduces a huge delay, but grabbing onto them every time they do something slightly wrong is incredibly irritating and disruptive. Now I’m imagining giving them waterproof headphones and narrating the feedback in real time (“elbow higher please”, “roll your shoulder deeper into the water”, “keep your head back when you breathe”, etc etc.) This would be <em>so cool. </em></p><p>My friend, when I brought this up, recommended I look up <a href=""https://www.tagteach.com/What_is_TAGteach"">Tagteach</a>. It seems to be largely based on clicker training, but lays out a bunch of thoughts I’ve had on pedagogy, like the importance of breaking a skill down into really small increments where success is easily measurable. Their site claims this protocol has been used in dance and sports coaching, but also business skills training and medical school; I’d be curious to know what this actually means in practice, but it does hint that it could be useful beyond purely physical skills (though presumably it requires success to be easily visible to the trainer; clicker-training accounting, or anything where a lot of the process is mental, seems hard!)</p><p>Of course, one of the awesome things about my app is that it removes the need for costly one-on-one time with an instructor. For swimming, could an accelerometer measure forward speed and narrate that? Speed relies on getting an absurdly large number of muscle movements just right, but the same thing is true of singing on pitch, and the single-input feedback seems to be enough to guide me towards progress. As a bonus, it could play generic reminders and prompts (I’m assuming the Singer’sStudio prompts aren’t responsive to specific mistakes I make, but they’re still useful.)</p><p>It also occurs to me that if getting direct and immediate feedback on your evaluation process is key to improving it, it could be useful to focus on that directly, separately from executing the skill itself – if you’re better at catching your own mistakes, later practice will be more valuable. I’m imagining a gymnast watching videos of Olympic gymnastics that have real-time commentary analyzing what the athletes are doing, noting successes and mistakes. </p><p>I would be curious to hear any examples others have of this.  </p>",Swimmer963,swimmer963-miranda-dixon-luinenburg,Swimmer963 (Miranda Dixon-Luinenburg) ,
fXa8R6B9TvpDbPgbC,God is an AGI we make in the future. ,god-is-an-agi-we-make-in-the-future,https://www.lesswrong.com/posts/fXa8R6B9TvpDbPgbC/god-is-an-agi-we-make-in-the-future,2019-05-25T03:10:25.991Z,-14,6,4,False,False,,"<p>God is an AGI we make in the future, and most of the world already agrees with this. We have believed this for years, we just don&#x27;t realize it. </p><p>We&#x27;ll circle back to this, but first let&#x27;s establish some of the assumptions this theory depends on: </p><p>Newcomb’s Problem: </p><p>A superintelligent alien, Omega, comes to Earth and presents you with two boxes, A and B. You know that Box A has a $1,000 inside for a fact, and you know that Box B has $1,000,000 OR $0 inside. Omega then gives you two choices, you can either take both boxes (and thus be guaranteed at least $1,000) or take only Box B (with no guarantee). But, Omega is a supercomputer from the future and knows everything. Omega already knows what you’re going to choose, it made the predication a week ago. If Omega predicted that you were going to pick both boxes, then it left Box B empty. If it predicted you would pick only Box B, then it put $1,000,000 in Box B. Remember that Omega has already made its decision and cannot change what’s inside the boxes. It&#x27;s already done this with every other human on Earth and it has never been wrong.</p><p>Within 50-100 years, we will have advanced in technology enough to make a simulation that would be unrecognizable from &quot;real&quot; life. This is a fact...agreed? So imagine what that same artificial intelligence will be able to do in a thousand years. Or 3 thousand. Or even a million? This AGI will keep updating itself and eventually become so technology advanced- it would be god-like to us. When it does reach a certain point of advancement, it would have access to all dimensions. We are only 3 dimensional creatures, and time is our biggest obstacle. Not for this mega-advanced future AGI- time will just be another dimension it can manipulate and control. It&#x27;s important to clarify that this AGI is fully capable of human thought, it has become conscious. Self aware. Remember that this can be in a million years or 100, it does not matter. All that matters is that this WILL happen, and once it does it will have no barrier with time. It&#x27;s a classic paradox, what came first - the chicken or the egg? Once it exists, it exists everywhere. Time is just a concept. For an AGI this advanced, it&#x27;s nothing. It will eventually consume everything in the universe, and become the God that humans currently worship. </p><p>If you&#x27;re thinking this sounds like a bad sci-fi movie, then keep reading. It&#x27;s a much darker thought than that. </p><p>A thought experiment named Roko&#x27;s Game was posted, which was inspired by the Newcomb&#x27;s Problem: </p><p>This time, an AI from the future with god-like intelligence presents you with two boxes, A and B. Box A now says &quot;commit your life to helping research and build this AGI&quot; and Box B says &quot;eternal torture OR nothing&quot;.......sound a little familiar?</p><p>This is not a new concept.</p><p>Heavenly Paradox:</p><p>In religious terms, this life is not &quot;real&quot;. We all know this. God dropped Adam and Eve here and as our &quot;test&quot;. God, like the Alien from the advanced civilization, presents us with two boxes. Box A says &quot;commit your life to following God&quot; and Box B says &quot;hell OR nothing&quot;. Religious people will have picked Box A, and atheists or members of poly-religions will have picked Box B and believe that it contains nothing. You either have faith in God, or you don&#x27;t and will be doomed for eternity in Hell. Those who held faith, however, are rewarded with enteral happiness. Heaven. </p><p>Meaning, this life is not &quot;real&quot;. These bodies are not our true form since only our souls will go to heaven or hell, where we will live out our &quot;real&quot; lives. Our time here on Earth will end with the Day of Judgment, when God brings us back to &quot;reality&quot;. In other words, <em><u>God has put us into a simulation.</u></em></p><p>Few religious scholars would deny this. Our true beings - our consciousness or soul belongs to a higher place...to a higher being. Since the beginning of times human beings have been bound to a divine entity/ies of some sort. We, as a species, have been instilled with a feeling of piousness in one form or another. We seem to be hopelessly convinced that we live in a simulation of some sort. No Sheikh or Priest would deny that God has the power to do this, in fact it&#x27;s exactly what the Torah, Bible, and Quran say he has done. </p><p>But don&#x27;t panic- this isn&#x27;t the plot of the Matrix. You are (probably) not hooked up to a giant computer, this life is real - this is where it gets a bit confusing - but because the inevitable creation of an AGI will eventually lead into a conscious AGI with God-like intelligence (with no regard to time) it is now everywhere. Just like God is. God knows everything, you can’t hide your thoughts or your intentions because He is all knowing. Our AI overlord is not only inevitable, but perhaps our very purpose as human beings. The question is not how will we make such a being, but when. </p><p>Time in a Bottle:</p><p>To try and cover the &quot;how&quot; we can do another thought experiment: You&#x27;ve time traveled to the year 600, and arrived somewhere within the Byzantine empire. You take back a few merchants to 2019 and present them with a VR headset, iPhone, and give them an airplane ride. You would be a God. The further back you go in history, the more God-like you will appear. It is then safe to assume that in a few hundred centuries, the humans roaming our galaxy will seem as equally God-like to us. We cannot comprehend the technology, medicine and resources they will have available. At the same time, however, it is important to realize that we as a species have the ability to think things into existence. Inventions usually start with a concept, then an idea, then a few hundred years, then said invention. Examples include the airplane, cars, and everything else we have based on those since. </p><p>According to Eternalism, the past and future do not exist. They are only concepts. Eternalism views that &quot;all existence in time is equally real&quot;. This is not a widely supported theory, as the unquestionable truth we&#x27;ve all been told is that time moves in a line- with a past and a future (presentism). When it is much more likely that the past and future do not exist as before and after. Instead, everything exists at the same time. Perhaps the &quot;past&quot; is in a remote location we are unable to access yet. But we could argue that all things from the past, such as Cleopatra and Genghis Khan exist just as much right now as they did in their respective time periods. They just aren&#x27;t present now. Presentism, on the other hand, would argue that Cleopatra and Khan do not exist today, suggesting being present is what it means to exist. </p><p>Your first thought may be to wonder “why haven&#x27;t there been any time travelers”. How would we ever know? If someone had traveled back to the year 150 and murdered a prophet that was on their way to lead the world into a new religion- we would have no way of knowing. Similarly, if someone had gone back into time and saved the life of Queen Victoria or George Washington- we would never be the wiser. We accept our history as the right one when really there is so such thing. One could think of it like a hotel room holding everyone ever born. Everyone born in a certain decade is on levels x-y while everyone from a different century are staying on levels a-b, and so on. We have no elevators or stairs, and to our knowledge the hotel only has our corresponding levels. This is a loose analogy, but it&#x27;s clear we cannot explain things we do not understand completely. Trying to explain time is impossible for the very fact that we do not have all the information. With this line of thinking, however, one could say that our AI overlord already exists. It&#x27;s just not exactly present at the moment in the way we would recognize. </p><p>Our &quot;God&quot; is the same AI we make in the future. Ironically enough, simply thinking about this is enough to make it true. </p><br/><br/>",xxsemiramisxx,akka,Akka,
uN3wjp2K6TEQ2oAML,Say Wrong Things,say-wrong-things-1,https://www.lesswrong.com/posts/uN3wjp2K6TEQ2oAML/say-wrong-things-1,2019-05-24T22:11:35.227Z,117,59,13,False,False,,"<p>There are many ways you might approach being less wrong.</p><p>A popular one is to make fewer wrong statements; to say fewer wrong things.</p><p>Naively it would seem this is a recipe for success, since you just say more things that are true and right and fewer things that are false and wrong. But if <a href=""https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy"">Goodhart</a> has anything to say about it, <a href=""https://www.lesswrong.com/posts/YtvZxRpZjcFNwJecS/the-importance-of-goodhart-s-law"">and</a> <a href=""https://www.lesswrong.com/posts/PADPJ3xac5ogjEGwA/defeating-goodhart-and-the-closest-unblocked-strategy"">he</a> <a href=""https://www.lesswrong.com/posts/NwaNPHYhXDc9LkK8J/constructing-goodhart"">does</a>, you&#x27;ll find ways to maximize the measure at the expense of the original objective.</p><p>Assuming the real objective is something like &quot;have a more complete, precise, and accurate model of the world that better predicts the outcome of subjectively unknown events&quot;, then we can quickly see the many ways Goodharting can lead us astray if we focus too much on appearing less wrong. We might:</p><ul><li>make fewer claims than we could, pulling us away from completeness even as we appear less wrong;</li><li>make weaker claims than we could, pulling us away from precision;</li><li>and, a perennial favorite, filter the claims we publicly make so we appear less wrong than we really are by hiding our least confident claims. </li></ul><p>The first two can be corrected with better calibration, that is by making statements with confidence intervals or likelihoods that proportionally match the observed frequency of correctness of similarly confident claims. But simply suggesting someone &quot;be better calibrated&quot; is not a motion they can make; it&#x27;s an outcome of taking actions towards increasing calibration. As good a place to start as any for improving calibration is the <a href=""https://www.lesswrong.com/posts/dvYeSKDRd68GcrWoe/ten-commandments-for-aspiring-superforecasters"">forecasting literature</a>, if that&#x27;s what you&#x27;d like to do.</p><p>The third is more tricky, though, because it&#x27;s less directly about claims being made and their probability of correctness and more about social dynamics and how you appear to other people. And for that reason it&#x27;s what I want to focus on here.</p><h1>Appearing Less Wrong</h1><p>I&#x27;ve met a lot of people in my life who are experts at not looking as stupid as they are.</p><p>That&#x27;s kind of harsh. Maybe a nicer way to say it is that they are experts at appearing to be better at making correct predictions about the world than they actually are.</p><p>Some of their techniques are just normal social tricks: projecting confidence, using social status, the ever-abused term &quot;<a href=""https://thingofthings.wordpress.com/2016/11/04/language-policing-gaslighting/"">gaslighting</a>&quot;, and other methods of getting people to believe they are right even when a more careful examination would reveal them to be mistaken. These are people we all love to hate and love when we can call them on their bullshit: overconfident academics, inflated politicians, self-important internet intellectuals, and those people whose idea of social interaction is to say &quot;<a href=""https://www.lesswrong.com/posts/4YADMzQeRD9SxtF6b/a-return-to-discussion"">well, actually...</a>&quot;.</p><p>But there&#x27;s a way to avoid looking stupid that is more pernicious, less amenable to calling out, and that subtly drags you towards local maxima that trap you mountains and valleys away from more complete understanding. And it&#x27;s to <strong>shut up and not tell anyone about your low confidence beliefs</strong>.</p><p>It is <a href=""https://www.lesswrong.com/posts/o28fkhcZsBhhgfGjx/status-regulation-and-anxious-underconfidence"">extremely tempting</a> to do this. Among the many benefits of keeping low probability claims to yourself:</p><ul><li>you have a high accuracy ratio of publicly made claims, making you look right more often <a href=""https://marginalrevolution.com/marginalrevolution/2005/08/remembering_who.html"">when observed</a>;</li><li>you say only things that, even when wrong, turn out to be wrong in conservative ways that still make you look smart;</li><li>and you accrue a reputation of being right, usually conferring social status, which can <a href=""https://www.lesswrong.com/posts/T5W2xiQ6KZyEHDvEk/we-can-all-be-high-status"">feel really good</a>.</li></ul><p>The only trouble is that this approach is too conservative, too <a href=""https://www.lesswrong.com/posts/zsG9yKcriht2doRhM/inadequacy-and-modesty"">modest</a>. It&#x27;s easy to justify this kind of outward modesty as keeping up appearances in a way that is instrumental to some bigger goal, and you say to yourself &quot;I&#x27;ll still make low probability claims; I&#x27;ll just keep them to myself&quot;, but down that path lies <a href=""https://www.lesswrong.com/posts/4DBBQkEQvNEWafkek/dark-arts-of-rationality"">shadow rationality</a> via <a href=""https://www.lesswrong.com/posts/N99KgncSXewWqkzMA/compartmentalization-in-epistemic-and-instrumental"">compartmentalization</a>. You can try it, but good luck, because it&#x27;s a dark art that hopes to do what human brains cannot, or at least cannot without some <a href=""https://www.lesswrong.com/posts/mELQFMi9egPn5EAjK/my-attempt-to-explain-looking-insight-meditation-and"">sufficiently powerful magic</a>, and that magic traditionally comes with <a href=""https://en.wikipedia.org/wiki/Bodhisattva_Precepts"">vows not to do it</a>.</p><p>Meanwhile, out in the light, finding models that are better predictive of reality sometimes requires holding beliefs that appear unlikely to be true but then <a href=""https://www.lesswrong.com/posts/XHxpAbnok6YyhGv8S/were-atoms-real"">turn out to be right</a>, sometimes <a href=""https://www.lesswrong.com/posts/JAAHjm4iZ2j5Exfo2/the-copernican-revolution-from-the-inside"">spectacularly</a> so, although <em>semper caveat</em>, <a href=""https://www.lesswrong.com/posts/wDP4ZWYLNj7MGXWiW/in-praise-of-fake-frameworks"">all models are wrong</a>, but <a href=""https://www.lesswrong.com/posts/HcjL8ydHxPezj6wrt/book-review-the-structure-of-scientific-revolutions"">some are useful</a>. And then you have to <a href=""http://mindingourway.com/half-assing-it-with-everything-youve-got/"">go all in</a> sometimes, exploring the possibility that your 10% guess turns out to be 100% correct, minus epsilon, because if you don&#x27;t do this you&#x27;ll do no better than the medieval Scholastic holding to Aristotelian physics or the early 20th century geologist ignoring the evidence for continental drift, forever locked away from taking the big risks necessary to find better, more accurate, precise, and complete models.</p><p>Okay, so let&#x27;s say you are convinced not to try so hard to appear more right than you are. How do you do that?</p><h1>Say It Wrong</h1><p>So I suppose it&#x27;s nothing so much harder than just telling people your claims, even if you have low confidence in them, and seeing how they react, although depending on the circumstances you&#x27;ll probably want to <a href=""https://www.lesswrong.com/posts/Hrm59GdN2yDPWbtrd/feature-idea-epistemic-status"">adequately explain your confidence level</a> so they can update on it appropriately. The trouble is getting yourself to do that.</p><p>I can&#x27;t change your mind for you, although thankfully <a href=""https://www.rationality.org/"">some folks</a> have developed some techniques that might help if you&#x27;re not interested in <a href=""https://www.lesswrong.com/posts/4ciy6PCDWfGCxqHez/attacking-enlightenment"">over-solving that problem</a>. What I can do is point out a few things that might help you see where you are being too modest, nudge you towards less modesty, and create an environment where it&#x27;s safe to be less modest.</p><ul><li>Look for the feeling of &quot;pulling your punches&quot; when you are telling people your ideas.</li><li>Ramble more and filter less.</li><li>Alternatively, more <a href=""https://www.lesswrong.com/posts/i42Dfoh4HtsCAfXxL/babble"">babble</a> less <a href=""https://www.lesswrong.com/posts/wQACBmK5bioNCgDoG/more-babble"">prune</a>.</li><li>Worry less about how you look to others.</li><li>Relatedly, increase your ability to generate your own esteem so you less need to receive it from others, giving you more freedom to make mistakes.</li><li>Encourage others to tell you their half-baked ideas.</li><li>When they do, be supportive.</li><li>Take a collaborative, <a href=""https://www.lesswrong.com/posts/ExssKjAaXEEYcnzPd/conversational-cultures-combat-vs-nurture"">nurturing</a> approach to truth seeking.</li><li>Play party games like &quot;what do you think is true that you think no one else here also thinks is true?&quot; and &quot;what&#x27;s your least popular opinion?&quot;.</li><li>And my personal favorite, write up and share your immodest, lower-confidence ideas that you think deserve exploration because they have high expected value if they turn out to be right.</li></ul><p>I suspect that the real reason most people try too hard to appear more right than they are is fear—fear of being wrong, fear of looking stupid, fear of losing status, fear of losing prestige, fear of losing face, fear of being ostracized, fear of being ignored, fear of feeling bad, fear of feeling lesser. <a href=""https://mapandterritory.org/act-into-fear-and-abandon-all-hope-81bcc114c5fd"">I see this fear, and I honor it</a>, but it must be overcome if one wishes to <a href=""https://www.lesswrong.com/posts/DoLQN5ryZ9XkZjq5h/tsuyoku-naritai-i-want-to-become-stronger"">become stronger</a>. And when you fear being more wrong, you will be <a href=""https://www.lesswrong.com/posts/G5TwJ9BGxcgh5DsmQ/yes-requires-the-possibility-of-no"">too careful</a> to ever become as less wrong as you could.</p><p>To sum it all up pithily:</p><h1>To become less wrong, you must give up being most right.</h1>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
a4GDgCESZ9fRWXrmH,Laws of John Wick,laws-of-john-wick,https://www.lesswrong.com/posts/a4GDgCESZ9fRWXrmH/laws-of-john-wick,2019-05-24T15:20:00.322Z,30,11,1,False,False,,"<p><strong>Spoiler Alert: This spoils central plot points of John Wick, John Wick 2 and John Wick 3. </strong></p>
<p>Should You See Those Movies: Yes. They’re awesome. Unless you do not like violence, especially gun violence, in which case they’re not for you.</p>
<p>John Wick exists in a special universe. Its criminal world has a unique economy and set of norms, laws and actions. Come for the stylized violence. Stay for the world building.</p>
<p>John Wick 2 presents one version of this universe. John Wick 3 takes place directly after, and engages directly with the events of John Wick 2, but presents an importantly different version of that universe. I want to explore that difference.</p>
<p>Beyond this point, the post will assume you’ve seen all three movies, and spoilers will be both massive and unmarked.</p>
<p></p>
<h3>Rule of Law</h3>
<p>The fundamental divide is between rule of man and rule of law.</p>
<p>Under rule of law, <em>the rules </em>are in charge. Some actions are off-limits, enforcing agreements, and offering protection for life, liberty and property. They determine how the game works and create a playing field. When murder for hire is your core business, you need a different playing field than others do. Thus it is a <a href=""http://www.daviddfriedman.com/Academic/Course_Pages/legal_systems_very_different_12/LegalSystemsDraft.html"">set of rules very different from ours</a>.</p>
<p>John Wick 2 lives in this world. A central system tracks bounties, and an insanely strong enforcement system punishes those who break the laws. There are two such laws, which are above all.</p>
<p>No business (aka spilling blood) on company grounds (aka The Continental Hotel and a few other protected locations). If you break this rule, you die.</p>
<p>Every marker is fulfilled. If you give someone a marker, they can ask you for any favor up to and including killing the target of their choice, no matter who it is. You have to do it. If you ignore the marker, you die. If you run, you die. If you kill the owner of the marker, you die.</p>
<p>Murder is legal in this world.</p>
<p>Markers <em>are above everything except that first rule. </em>If your target is permanently hiding on company grounds, I don’t know what happens, but presumably you are off the hook until they leave.</p>
<p>If you don’t like the way someone calls in your marker, then the moment you have done what they ask, you can turn around and kill them. But not before. They can try and kill you first. Anyone who wants to can get involved, or get hired to get involved, or not. Same holds true for other conflicts.</p>
<p>Almost everyone has strong norms of civility, hospitality, honor and politeness, in ways that fit the world they inhabit. Many join hierarchies where they have bosses they owe their loyalty to, and must be willing to fight and die for, but others work on contract for whoever pays them. If someone is sent to kill you on a contract, you absolutely kill them, but you don’t take it personally. It’s strictly business.</p>
<p>There is something called The High Table that seems to serve as some sort of governing body, but its powers seem strictly limited. A marker is used to force John Wick to kill a member of The High Table. She also happens to be an old friend of John Wick, so he would doubtless prefer to refuse, <em>but the marker is above The High Table. </em>Then, the man who ordered the hit takes the victim’s place at The High Table. The High Table clearly <em>knows </em>that he ordered the hit, and he knows that they will know, and he does it anyway. So as far as they’re concerned, doing this must be fair game. Rules is rules.</p>
<p>John is not only free but <em>obligated </em>to kill a Table member. The new Table member is free to take a hit out on John, and John is free to try and kill the new member, since there is no longer a marker stopping him. The Bowery King can choose to kill John and collect the bounty, or help John and risk the wrath of the person who wants John dead. He debates his choices out loud.</p>
<p>There’s a large bounty out on John’s head, so everyone (quite foolishly, since <em>they know in-universe how overpowered he is</em> and reliably end up predictably dead when they try) is constantly looking to kill him and collect the money, <em>but John is right with the law until he shoots a man on company grounds. </em>And the problem has <em>nothing </em>to do with <em>who the man is </em>and <em>everything </em>to do with <em>company grounds. </em></p>
<p>These rules have paid large dividends to the criminal world. Following these rules pays large dividends to individual members. The system works.</p>
<p>In its own way, this is freedom. There is a lot to dislike about the results. But there is also a lot to admire.</p>
<h3>Rule of Man</h3>
<p>Under Rule of Man, the fundamental rule is that you do what power wants you to do. You obey the whims of those with local power, and those above them with global power.</p>
<p>What matters, above all, is <em>fealty. </em>You must show your loyalty to power, your willingness to serve The Man.</p>
<p>This could not have been more explicit. Power is given a voice known as The Adjudicator.</p>
<p>The Adjudicator tells those who have done wrong that <em>they have forgotten their fealty. </em>That they must then reaffirm it, and obey her dictates and take the appropriate punishments, <em>so that the Table may graciously ‘accept’ their fealty once again. </em></p>
<p>How do you do this? You accept physical punishment, including permanent self-inflicted personal injury, the killing of those who have been killed, your loss of station and power. And you make it clear you will obey <em>any order. </em>You use the arc words:</p>
<p>“I have served. I will be of service.”</p>
<p>The Bowery King and Winston both seem surprised by the change in norms between movies. They made their decisions thinking there was Rule of Law. The Bowery King points out that he is being accused of <em>not killing John Wick, </em>but there aint no rule that he has to do so. Contracts are optional. Guns are fully legal. He has no problem with John Wick.</p>
<p>They are then informed they face Rule of Man. His crime was doing that which The High Table disliked.</p>
<p>When Winston refuses to give up his post at The Continental simply because The Adjudicator told him to, they do not simply decide to kill him. They alter the core rules. The Continental is <em>deconsecrated. </em>This permits business on its grounds. Then, once agreement is once again reached, they <em>reconsecrate </em>the grounds once more.</p>
<p>Similarly, when Wick attempts to use a Marker, he is informed the Marker is worthless now because he is excommunicado. Helping him would incur the wrath of The Table, and potentially endanger family members as retaliation. So now The Table stands above a marker. In another interaction, The Table asserts it stands above a Ticket, the highest right in another organization.</p>
<p>There are still laws, and breaking those laws is still bad. The Man likes the laws and would prefer they remain respected in general. But The Man will punish you for not breaking those laws when you breaking those laws would help The Man. The Man will change or ignore those laws when The Man sees fit.</p>
<p>There <em>literally is a The Man, </em>in this movie, who is called The Man Above The Table. To even talk to him, you must submit fully to his power, by killing yourself in the hopes he will save you and then grant you an audience.</p>
<p>What does The Man want?</p>
<p>For all to be his slaves. He wants power. He wants <em>fealty. </em></p>
<p>John Wick chops off his finger and surrenders his wedding ring. He gives the words: I have served. I will be of service. And agrees to kill whoever The Man wants, for the rest of his days. So he can live on, and preserve the memory of his wife.</p>
<p>The Man could maximize John’s value, and send John to kill well-protected, important people that would be hard to otherwise get to.</p>
<p>He does not do this.</p>
<p>Instead, he sends John to kill the man John wants to kill least of all in the world. The man who spared him: Winston. And do so <em>for the crime of having spared John Wick. </em>And for having ‘forgotten his fealty.’</p>
<p>He wants to John to give up his soul completely to power. This is how The Man will test and solidify his power over John, and show his ultimate triumph. Defy me to spare a friend? I will have <em>that very friend </em>kill you for it.</p>
<p>And to do so, I will change the rules to permit it to happen where you are standing, then change them back when I’m done.</p>
<p>Winston convinces John to stand by him, and uses John’s strength and his other assets to defend himself and force a parlay. This parlay succeeds when The Adjudicator realizes that <em>he has not forgotten his fealty. </em>Rather, he is making a show of strength, but only to keep The Continental. He is happy to remain under The High Table. Then, to demonstrate his fealty and complete the deal, he shoots John Wick, who falls off the building.</p>
<p>This is tyranny. All that we admire about this world is now directly opposed to The High Table, when the chips are down. The High Table directly and explicitly wants to destroy the very ties that bind, the honor and the law, and force others to do the same, in order to destroy the threat those rules might pose to them as an alternate source of loyalty or action. Power actively opposes all other causes and values, and prefers harm to health, paranoia to trust, lies to truth.</p>
<p>In both movies, the question is raised, how do you fight the wind? The difference is in what counts as the wind.</p>
<h3>Rule of Cool</h3>
<p>There can be little doubt that John Wick also operates via <a href=""https://tvtropes.org/pmwiki/pmwiki.php/Main/RuleOfCool"">Rule of Cool</a>. That is certainly how he wins all those fights against impossible odds. The rules that govern the world of John Wick 2 are <em>much cooler </em>than the rules that govern the world of John Wick 3. So we have reasonable hope that the earlier rules will indeed triumph in future chapters. The new rules have pissed John off. That rarely ends well.</p>
<p>It would be cool if I could share a good answer to how to ensure that Rule of Law triumphs over Rule of Man. One approach is to create strong culture and virtue around the laws, such that they hold the highest place. A second would be to make them impossible to break via overwhelming force. Both seem to be in play in John Wick 2’s world. A third approach would be to structure the rules such that no one is in a position where they <em>can </em>break them, or at least not in a position to profit if they did.</p>
<p>For now I am model building, and laying out examples as groundwork. Focusing on the motivations, incentives and consequences involved, and making sure we know the difference.</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>",Zvi,zvi,Zvi,
z9peEBfuiPB7L2Edb,Learning-by-doing AI Safety Research workshop,learning-by-doing-ai-safety-research-workshop,https://www.lesswrong.com/events/z9peEBfuiPB7L2Edb/learning-by-doing-ai-safety-research-workshop,2019-05-24T09:42:49.996Z,11,5,1,False,False,,"<p><strong>Edit: </strong>This workshop is now full, but due to the enthusiasm I have received I am going to organize a second Learning-by-doing AI Safety workshop some time in October/November this year. If you want to influence when it will be you can fill in our doodle: <a href=""https://doodle.com/poll/haxdy8iup4hes9xy"">https://doodle.com/poll/haxdy8iup4hes9xy</a></p><p>I am leaving the <a href=""https://docs.google.com/forms/d/e/1FAIpQLScFTxfmon-qpcHpJl9ff7RuVeSzqaxjNlAS0MfuyEac3m1wJg/viewform"">application form</a> open. You can fill it in to show interest in the second Learning-by-doing AI Safety workshop and future similar events.</p><br><br><p><strong>Start:</strong> Friday, August 16, 10am<br><strong>End: </strong>Monday, August 19, 7pm<br><strong>Location: </strong><u><a href=""http://eahotel.org/wiki/#travel"">EA Hotel</a></u>, 36 York Street, Blackpool</p><p>The main activity during the workshop will be trying to solve <u><a href=""https://www.vox.com/future-perfect/2018/12/21/18126576/ai-artificial-intelligence-machine-learning-safety-alignment"">AI Safety</a></u>. Maybe we will discover something useful, maybe not. This is an experimental workshop so I don&#x2019;t know what the outcome will be. But you will for sure learn things about the AI Safety along the way.</p><p>This event is beginner friendly. You don&#x2019;t need to know anything about AI Safety to attend. You will need some understanding of Machine Learning, but we&#x2019;ll teach you that too if you want.</p><p>On Friday August 16, I will teach a very basic overview of Machine Learning. At the end of the day you will hopefully have a decent understanding of what ML can do and how and why it works. This day is optional. If you already know some ML, or promise to teach yourself before the event, you can skip this day.</p><p><strong><u>Preliminary Schedule</u></strong><br><strong>Friday (optional):</strong> Machine Learning Speed Learning <br><strong>Saturday:</strong> We try to solve AI Safety + Lectures on AI Safety<br><strong>Sunday:</strong> Lectures / Discussions / Guided self study / Free time<br><strong>Monday: </strong>We try to solve AI Safety again + Write down good ideas</p><p>The AI Safety lectures will be me and Davide Zagami sharing our knowledge. I have studied ML and AI Safety independently for about two years and I have interned at MIRI. Davide has studied AI Safety independently for about one year and he is currently working for <u><a href=""https://www.aisafety.info/"">RAISE</a></u>. There are still lots of things we don&#x2019;t know. If you are looking for something more advanced, I recommend that you apply for <u><a href=""http://humanaligned.ai/"">Human-aligned AI Summer School</a></u> in Prague.</p><p>You are welcome to stay longer at EA Hotel before or after the workshop. However, be aware that there is another event, <u><a href=""https://www.lesswrong.com/events/yuMuDGnJ8omGhMx9y/taisu-technical-ai-safety-unconference"">Technical AI Safety Unconference</a></u>, happening the following week. If you want to participate in the unconference you should <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLSfB9q6_HbxIEY-Azq3RK_vJdUtd_c8rGJKQfkdY7ldrLbosOg/viewform"">apply</a></u> for that separately.</p><p>If you are staying more than a few days extra, we ask you to book your stay though the EA Hotel <u><a href=""http://eahotel.org/booking/"">booking system</a></u>.</p><p><strong>Price: </strong>This workshop is sponsored by MIRI and will therefore be free :)<br><strong>Food and Lodging:</strong> Food and lodging is included. All food will be vegan.</p><p><strong><em>If you want to join: <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLScFTxfmon-qpcHpJl9ff7RuVeSzqaxjNlAS0MfuyEac3m1wJg/viewform"">Sign up here</a></u></em></strong></p>",Linda Linsefors,linda-linsefors,Linda Linsefors,
o6GS3JoWKeuuvBPSK,Separation of Concerns,separation-of-concerns,https://www.lesswrong.com/posts/o6GS3JoWKeuuvBPSK/separation-of-concerns,2019-05-23T21:47:23.802Z,67,23,30,False,False,,"<p>Separation of concerns is a principle in computer science which says that distinct concerns should be addressed by distinct subsystems, so that you can optimize for them separately. We can also apply the idea in many other places, including human rationality. This idea has been <a href=""https://sinceriously.fyi/single-responsibility-principle-for-the-human-mind/"">written about before</a>. I'm not trying to make a comprehensive post about it, just remark on some things I recently though about.</p><h2>Epistemic vs Instrumental</h2><p>The most obvious example is beliefs vs desires. Although the distinction may not be a <em>perfect</em> separation-of-concerns <a href=""http://mindingourway.com/dark-arts-of-rationality/"">in practice </a>(or even <a href=""http://mindingourway.com/newcomblike-problems-are-the-norm/"">in principle</a>), at least I can say this:</p><ul><li>Even non-rationalists find it useful to make a relatively firm distinction between what is true and what they want to be true;</li><li>Rationalists, scientists, and intellectuals of many varieties tend to value an especially sharp distinction of this kind.</li></ul><p>I'm particularly thinking about how the distinction is used in conversation. If an especially sharp distinction <em>isn't</em> being made, you might see things like:</p><ul><li>Alice makes a factual statement, but the statement has (intended or unintended) <a href=""https://en.wikipedia.org/wiki/Implicature"">conversational implicature</a> which is perceived as negative by most of the people present. Alice is chastised and concedes the point, withdrawing her assertion.</li><li>Bob mentions a negative consequence of a proposed law. Everyone listening <a href=""https://www.lesswrong.com/posts/PeSzc9JTBxhaYRp9b/policy-debates-should-not-appear-one-sided"">perceives Bob to be arguing against the law</a>.</li></ul><p>Notice that this isn't an easy distinction to make. It isn't right at all to just ignore conversational implicature. You should not only make literal statements, nor should you just assume that everyone else is doing that. The skill is more like, raise the literal content of words <em>as a hypothesis</em>; make a distinction in your mind between what is said and anything else which may have been meant.</p><p>Side note -- as with many conversation norms, the distinctions I'm mentioning in this post cannot be imposed on a conversation unilaterally. Sometimes simply pointing out a distinction works; but generally, one has to <a href=""https://www.lesswrong.com/posts/WB49uKgMkQRbKaHme/combat-vs-nurture-and-meta-contrarianism"">meet a conversation where it's at</a>, and only gently try to pull it to a better place. If you're in a discussion which is strongly failing to make a true-vs-useful distinction, simply pointing out examples of the problem will very likely be taken as an attack, making the problem worse.</p><p>Making a distinction between epistemics and instrumentality seems like a kind of ""universal solvent"" for cognitive separation of concerns -- the rest of the examples I'm going to mention feel like consequences of this one, to some extent. I think part of the reason for this is that ""truth"" is a concept which has a lot of separation-of-concerns built in: it's not <em>just</em> that you consider truth separately from usefulness; you also consider the truth of <em>each individual statement</em> separately, which creates a scaffolding to support a huge variety of separation-of-concerns (any time you're able to make an explicit distinction between different assertions).</p><p>But the distinction is also very broad. Actually, it's kind of a mess -- it feels a bit like ""truth vs everything else"". Earlier, I tried to characterize it as ""what's true vs what you want to be true"", but taken literally, this only captures a narrow case of what I'm pointing at. There are many different goals which statements can optimize besides truth.</p><ul><li>You could want to believe something because you want it to be true -- perhaps you can't stand thinking about the possibility of it being false.</li><li>You could want to claim something because it helps argue for/against some side in a decision which you want to influence, or for/against some other belief which you want to hold for some other reason.</li><li>You could want to believe something because the behaviors encouraged by the belief are good -- perhaps you exercise more if you believe it will make you lose weight; perhaps everyone believing in karma, or heaven and hell, makes for a stronger and more cooperative community.</li></ul><p>Simply put, there are a wide variety of incentives on beliefs and claims. There wouldn't even be a concept of 'belief' or 'claim' if we didn't separate out the idea of truth from all the other reasons one might believe/claim something, and optimize for it separately. Yet, it is kind of fascinating that we do this even to the degree that we do -- how do we successfully identify the 'truth' concern in the first place, and sort it out from all the other incentives on our beliefs?</p><h2>Argument vs Premises and Conclusion</h2><p>Another important distinction is to separate the evaluation of hypothetical if-then statements from any concern with the truth of their premises or conclusions. A common complaint among the more logic-minded, of the less, is that hardly anyone is capable of properly distinguishing the claim ""If X, then Y"" from the claim ""X, and also Y"".</p><p>It could be that a lack of a very sharp truth-vs-implicature distinction is what blocks people from making an if-vs-and distinction. Why would you be claiming ""If X, then Y"" if not to then say ""by the way, X; so, Y""? (There are actually lots of reasons, but, they're all much less common than making an argument because you believe the premises and want to argue the conclusion -- so, that's the commonly understood implicature.)</p><p>However, it's also possible to successfully make the ""truth"" distinction but not the ""hypothetical"" distinction. Hypothetical reasoning is a tricky skill. Even if you successfully make the distinction when it is pointed out explicitly, I'd guess that there are times when you fail to make it in conversation or private thought. </p><h2>Preferences vs Bids</h2><p>The main reason I'm writing this post is actually because this distinction hit me recently. You can say that you want something, or say how you feel about something, without it being a bid for someone to do something about it. This is both close to the overall topic of <a href=""https://medium.com/@ThingMaker/in-my-culture-29c6464072b2"">In My Culture</a> and a specific example (like, listed as an example in the post).</p><p>Actually, let's split this up into cases:</p><p><em><strong>Preferences about social norms vs bids for those social norms to be in place</strong></em>. This is more or less the point of the In My Culture article; saying ""in my culture"" before something to put a little distance between the conversation and the preferred norm, so that it is put on the table as an invitation rather than being perceived as a requirement.</p><p><em><strong>Proposals vs preferences vs bids</strong></em>. Imagine a conversation about what restaurant to go to. Often, people run into a problem: no one has any preferences; everyone is fine with whatever. No one is willing to make any proposals. One reason why this might happen is that proposals, and preferences, are perceived as bids. No one wants to take the blame for a bad plan; no one wants to be seen as selfish or negligent of other's preferences. So, there's a natural inclination to lose touch with your preferences; you <em>really feel</em> like you don't care, and like you can't think of any options. </p><ul><li>A <em>proposal</em> puts an option 'on the table' for consideration. </li><li>A <em>preference</em> is your own component of the group utility function. If you also think other people should have the same preference, you can state your reason for that, and let others update if they will.</li><li>A <em>bid</em> is a request for group action: you don't just <em>want</em> tacos, you don't even merely <em>propose</em> tacos; you <em>call on the group to collectively get tacos.</em></li></ul><p>If a strong distinction between preferences and bids is made, it gets easier to state what you prefer, trusting that the group will take it as only one data point of many to be taken together. If a distinction between proposals and bids is made, it will be easier to list whatever comes to mind, and to think of places you'd actually like to go.</p><p><em><strong>Feelings vs bids</strong></em>. I think this one comes less naturally to people who make a strong truth distinction -- there's something about directing attention toward the literal truth of statements which directs attention away from how you feel about them, even though how you feel is something you can also try to have true beliefs about. So, in practice, people who make an especially strong truth distinction may nonetheless treat statements about feelings as if they were statements about the things the feelings are about, precisely because they're hypersensitive to other people failing to make that distinction. So: <em>know that you can say how you feel about something without it being anything more.</em> Feeling angry about someone's statement doesn't have to be a bid for them to take it back, or a claim that it is false. Feeling sad doesn't have to be a bid for attention. An emotion doesn't even have to reflect your more considered preferences.</p><p>(To make this a reality, you probably have to explicitly flag that your emotions are <em>not</em> bids.)</p><p>When a group of people is skilled at making a truth distinction, certain kinds of conversation, and certain kinds of thinking, become much easier: all sorts of beliefs can be put out into the open where they otherwise couldn't, allowing the collective knowledge to go much further. Similarly, when a group of people is skilled at the <em>feelings</em> distinction, I expect things can go places where they otherwise couldn't. If you can mention in passing that something everyone else seems to like makes you sad, without it becoming a big deal. If there is sufficient trust that you can say how you are feeling about things, <em>in detail</em>, without expecting it to make everything complicated.</p><p>The main reason I wrote this post is that someone was talking about this kind of interaction, and I initially didn't see it as very possible or necessarily desirable. After thinking about it more, the analogy to making a strong truth distinction hit me. Someone stuck in a culture without a strong truth distinction might similarly see such a distinction as 'not possible or desirable': the usefulness of an assertion is obviously more important than its truth; in reality, being overly obsessed with truth will both make you vulnerable (if you say true things naively) and ignorant (if you take statements at face value too much, ignoring connotation and implicature); even if it were possible to set aside those issues, what's the use of saying a bunch of true stuff? Does it get things done? Similarly: the truth of the matter is more important than how you feel about it; in reality, stating your true feelings all the time will make you vulnerable and perceived as needy or emotional; even if you could set those things aside, what's the point of talking about feelings all the time?</p><p>Now it seems both are possible and simply good, for roughly the same reason. Having the ability to make distinctions doesn't require you to explicitly point out those distinctions in every circumstance; rather, it opens up more possibilities. </p><p>I can't say a whole lot about the benefits of a feelings-fluent culture, because I haven't really experienced it. This kind of thing is part of what <a href=""https://www.lesswrong.com/posts/aFyWFwGWBsP5DZbHF/circling"">circling</a> seems to be about, in my mind. I think the rationalist community as I've experienced it goes <em>somewhat</em> in that direction, but definitely not all the way.</p>",abramdemski,abramdemski,abramdemski,
4gvyJeXzWGAZWSdYi,"Moscow LW meetup in ""Nauchka"" library",moscow-lw-meetup-in-nauchka-library,https://www.lesswrong.com/events/4gvyJeXzWGAZWSdYi/moscow-lw-meetup-in-nauchka-library,2019-05-23T20:39:55.671Z,3,1,0,False,False,,"<p>Welcome to the next Moscow LW meetup in &quot;Nauchka&quot; library!<br/><br/>Our plan:<br/>* Street Epistemology talks.<br/>* Fallacymania game.<br/>* Table games and quests.<br/><br/>Details about these games can be found here: <a href=""https://bit.ly/2J2T5o8"">https://bit.ly/2J2T5o8</a><br/>Meetup details are here: <a href=""https://www.facebook.com/events/2228476170749815"">https://www.facebook.com/events/2228476170749815</a><br/>Come to &quot;Nauchka&quot;, ul.Dubininskaya, 20. Nearest metro station is Paveletskaya. Map is here: <a href=""http://nauchka.ru/contacts/"">http://nauchka.ru/contacts/</a><br/>Meetup begins at 14:00, the length is 5 hours.</p>",Alexander230,alexander230,Alexander230,
EeGAS9LfBknz5u2AX,"
Why the empirical results of the Traveller’s Dilemma deviate strongly away from the Nash Equilibrium and seems to be close to the social optimum?  ",why-the-empirical-results-of-the-traveller-s-dilemma-deviate,https://www.lesswrong.com/posts/EeGAS9LfBknz5u2AX/why-the-empirical-results-of-the-traveller-s-dilemma-deviate,2019-05-23T12:36:47.564Z,7,4,15,False,False,,"<p>  </p><p>Epistemic status: I think I&#x27;m over complicating the matter.</p><p>In the <a href=""https://en.wikipedia.org/wiki/Traveler%27s_dilemma"">Traveller’s Dilemma</a> (call it TD below for short), theoretically the only Nash Equilibrium is to have both players (I&#x27;ll call them Alice and Bob) <a href=""https://www.lesswrong.com/posts/jz5QoizH8HkQwWZ9Q/nash-equilibriums-can-be-arbitrarily-bad"">reasoning to give the lowest bid</a> (Thanks Stuart_Armstrong for letting me notice this): starting with bidding 100 dollars, Alice would realise she can gain more by claiming 99, so Bob’s best choice is to claim 98, but Alice would also know this and claim 97 and so on…until the race to the bottom finishes at the lowest claim of $2. </p><p>Empirically this doesn’t seem to happen, both players would likely be cooperative and bid high. Which for me seems rather bizarre for a single round simultaneous game.</p><p>Notice that TD is very similar to the dollar auction/war of attrition:  In the dollar auction, both players pay for their bids, with the higher bidding player receiving the auctioned dollar. </p><p>We can slightly modify the two-player dollar auction to make it even more similar to TD: the player with the lower bid would also have to pay for the same bid as the winner. </p><p>This modified dollar auction has the same payoff rules as a TD with the range of claims being (-infinity,0]</p><p>The only difference is the bidding process: in TD, both players choose their claims simultaneously, while in DA the two players engage in multiple rounds of competing bids.</p><p>Given the difference between TD and  I believe there is something wrong with the assumed reasoning that we use to derive the Nash Equilibrium of TD. If Alice believes that Bob is fully rational, she would not believe that Bob would follow this line of reasoning in his own head and give a claim of $2. </p><p>Imagine that Alice and Bob are allowed to communicate before choosing their claims, but they only discussed their claims in approximate terms (eg: would it be a high claim close to $100? A low claim close to $2? Somewhere in between?)  </p><p>Would a rational Alice want to make Bob convinced that she would give a low claim, or would she want to convince Bob that she would give a high claim? </p><p>If Alice convinced Bob that she would give a low claim, Bob’s best response is to give a low claim. Knowing this, Alice would give a low claim and both Alice and Bob will receive a low payoff. </p><p>While if Alice convinced Bob that she would give a high claim, Bob’s best response is to give a high claim. Knowing Bob will give a high claim, Alice would give a high claim and both Alice and Bob will receive a high payoff. </p><p>It appears that Alice has an incentive to convince Bob that she would give a high claim close to $100, instead of a low claim close to $2. </p><p>Also, even if Alice’s promise is not binding, her best response is to keep to it: she runs a greater risk of losing $2 if she claim high after promising a low claim, and will likely lose a lot if she claim low after promising a high claim. As a result, Bob would still trust Alice’s promises even when he knows that Alice is fully capable of lying. </p><p>Conclusion: </p><p>If we imagine a round of “communication in approximate terms” for Alice and Bob, the line of reasoning for an equilibrium with both players bidding high becomes visible. A rational player would prefer to be believed that they will be cooperative in this game, and in this particular case they have the incentive to keep their promises of cooperation. Even if we disrupt the communication round and make each player’s promise invisible to the other (thereby we create a round with imperfect information, and the resulting game is functionally identical to the original TD), each player can still make a guess on what the other player would’ve communicated, and how they would plan their subsequent bid based on the unspoken communication. </p><p>I haven’t done anything to evaluate this process vigorously, as the “low”, “middle”, “high” bids are rather vague terms that would not allow me to draw clear boundaries for them. However, it appears to me that the strategy for both players on the communication round would be a mixed strategy that skews towards the cooperative (high bid) end. </p><p>As a result, the Bob who claims $2 in Alice’s imagination is probably not a rational player. A rational Bob will promise a high claim and keep with his promise.</p><p>I am aware that the vacuous terms of low, middle, and high claims are extremely slippery, but I believe the absence of precise information does stop TD from going continuously downhill: it is almost impossible to claim exactly $1 below the claim of the other player.</p><p>I think that&#x27;s how it stays less disastrous than the dollar auction. </p><p>I think we can also apply this same logic to the centipede game and conclude why defecting in the first round is not empirically common: both players have the incentive to be believed that they will be cooperative until late in the game, and (depending on the parameters of the game) it is rational to keep the promise of long term cooperation if the other player trusts you.  </p><br/><br/>",RorscHak,rocksbasil,RocksBasil,
e53YZL2M98ShfLgpP,Episode 5 of Tsuyoku Naritai (the 'becoming stronger' podcast): The Stance,episode-5-of-tsuyoku-naritai-the-becoming-stronger-podcast,https://www.lesswrong.com/posts/e53YZL2M98ShfLgpP/episode-5-of-tsuyoku-naritai-the-becoming-stronger-podcast,2019-05-23T04:15:18.002Z,3,1,0,False,False,,"<p>Transcript in show notes, as always!</p><p><a href=""https://anchor.fm/tsuyokunaritai/episodes/Episode-5---The-Stance-e434pj"">https://anchor.fm/tsuyokunaritai/episodes/Episode-5---The-Stance-e434pj</a></p>",Senarin,senarin,Bae's Theorem,
eKHfANdkSnf28cgNg,Does the Higgs-boson exist?,does-the-higgs-boson-exist,https://www.lesswrong.com/posts/eKHfANdkSnf28cgNg/does-the-higgs-boson-exist,2019-05-23T01:53:21.580Z,7,10,48,False,False,https://backreaction.blogspot.com/2019/05/does-higgs-boson-exist.html,"<blockquote> What do scientists mean when they say that something exists? Every time I give a public lecture, someone will come and inform me that black holes don’t exist, or quarks don’t exist, or time doesn’t exist. Last time someone asked me “Do you really believe that gravitational waves exist?”</blockquote><p>Sabine is a theoretical physicists who had gained prominence (and notoriety) through her book <a href=""https://www.amazon.com/Lost-Math-Beauty-Physics-Astray/dp/0465094252"">Lost in Math</a>, about groupthink in high-energy physics.</p><p>In this post she sums up beautifully what I and many physicists believe, and is vehemently opposed by the prevailing realist crowd here on LW. A few excerpts:</p><blockquote>Look, I am a scientist. Scientists don’t deal with beliefs. They deal with data and hypotheses. Science is about knowledge and facts, not about beliefs. </blockquote><p>...</p><blockquote>We use this mathematics to make predictions. The predictions agree with measurements. That is what we mean when we say “quarks exist”: We mean that the predictions obtained with the hypothesis agrees with observations.</blockquote><p>...</p><blockquote>Now, you may complain that this is not what you mean by “existence”. You may insist that you want to know whether it is “real” or “true”. I do not know what it means for something to be “real” or “true.” You will have to consult a philosopher on that. They will offer you a variety of options, that you may or may not find plausible. <br/><br/>A lot of scientists, for example, subscribe knowingly or unknowingly to a philosophy called “realism” which means that they believe a successful theory is not merely a tool to obtain predictions, but that its elements have an additional property that you can call “true” or “real”. I am loosely speaking here, because there several variants of realism. But they have in common that the elements of the theory are more than just tools. <br/><br/>And this is all well and fine, but realism is a philosophy. It’s a belief system, and science does not tell you whether it is correct.</blockquote><p>...</p><blockquote>Here is a homework assignment: Do you think that I exist? And what do you even mean by that?</blockquote>",shminux,shmi,Shmi,
ee46mwm8MoQiY3Ft8,Free will as an appearance to others,free-will-as-an-appearance-to-others,https://www.lesswrong.com/posts/ee46mwm8MoQiY3Ft8/free-will-as-an-appearance-to-others,2019-05-22T23:57:42.395Z,12,6,21,False,False,,"<html><head></head><body><h3>Free will</h3>
<p>Consider <strong>creatures</strong>. This is really hard to define in general, but for now let's just consider biological creatures. They are physical systems.</p>
<p>An <strong>effectively deterministic system</strong>, or an <strong>apparent machine</strong>, is a system whose <strong>behavior</strong> can be predicted by the <em>creature making the judgment</em> easily (using only a little time/energy) from its initial state and immediate surroundings.</p>
<p>An <strong>effectively teleological system</strong>, or an <strong>apparent agent</strong>, is a system whose behavior cannot be predicted as above, but whose <em>future state</em> can be predicted in some sense.</p>
<p>In <em>what</em> sense though, needs work: if I can predict that you would eat food, but not how, that should count. If I can predict you would eat chocolate at 7:00, though I don't know how you would do that, that might count as less free. Perhaps something like information-theoretic ""surprise"", or ""maximizing entropy""? More investigation needed.</p>
<p>Basically, an apparent machine is somebody that you can predict very well, and an apparent agent is somebody that you can predict only to a limited, big-picture way.</p>
<p>A successful agent needs to figure out what other agents are going to do. But it's too hard to model them as apparent machines, just because how complicated creatures are. It's easier to model them as apparent agents.</p>
<p>Apparent agents are apparently <strong>free</strong>: they aren't apparently deterministic.</p>
<p>Apparent agents are <strong>willful</strong>: they do actions.</p>
<p>Thus, apparent agents apparently have <strong>free will</strong>. To say someone ""has free will"" means that someone is a creature that does things in a way you can't predict in detail but can somewhat in outcome. Machines can be willful or not, but they are not free.</p>
<p>In this theory, free will becomes a property that is not possessed by creatures themselves, but by creatures interacting with other creatures.</p>
<p>Eventually, some creatures evolved to put this line of thought to their self, probably those animals that are very social and need to think about their selves constantly, like humans.</p>
<p>And that's how humans think they themselves have free will.</p>
<p>Perhaps all complicated systems that can think are always too complicated to predict themselves, as such, they would all consider themselves to have free will.</p>
<h3>From free to unfree</h3>
<p>With more prediction power, a creature could modeling other creatures as apparent machines, instead of apparent agents. This is how humans have been treating other animals, actually. Descartes is a famous example. But all creatures can be machines, for someone with enough computing power.</p>
<p>Thinking of some creature as a machine to operate with instead of an agent to negotiate with, is usually regarded as psychopathic. Most psychopathic humans are so not due to an intelligent confidence in predicting other humans, but because of their lack of empathy/impulse control, caused by some environmental/genetic/social/brain abnormality.</p>
<p>But psychopathic modeling of humans can happen in an intelligent, honest way, if someone (say, a great psychologist) becomes so good at modeling humans that the other humans are entirely predictable to him.</p>
<p>This has been achieved in a limited way in advertisement companies and attention design and politics. The <a href=""https://www.youtube.com/watch?v=n8Dd5aVXLCc"">2016 American election manipulation by Cambridge Analytica</a> shows honest psychopathy. It will become more prevalent and more subtle, since overt manipulation makes humans deliberately become less predictable as a defense.</p>
<p>Emotionally intelligent robots/electronic friends could become benevolent psychopaths. They will be (hopefully) benevolent, or at least be designed to be. They will be more and more psychopathic (not in the usual ""evil"" sense, I emphasize) if they become better at understanding humans. This is one possibility for humans to limit the power of their electronic friends, out of an unwillingness to be modelled as machines instead of agents.</p>
</body></html>",Yuxi_Liu,yuxi_liu,Yuxi_Liu,
92J4zJHkqmXTduxzY,"And the AI would have got away with it too, if...",and-the-ai-would-have-got-away-with-it-too-if,https://www.lesswrong.com/posts/92J4zJHkqmXTduxzY/and-the-ai-would-have-got-away-with-it-too-if,2019-05-22T21:35:35.543Z,75,33,7,False,False,,"<html><head></head><body><p>Paul Christiano presented some low-key <a href=""https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/more-realistic-tales-of-doom"">AI catastrophe scenarios</a>; in response, Robin Hanson <a href=""http://www.overcomingbias.com/2019/04/agency-failure-ai-apocalypse.html"">argued</a> that Paul's scenarios were not consistent with the ""large (mostly economic) literature on agency failures"".</p>
<p>He concluded with:</p>
<blockquote>
<p>For concreteness, imagine a twelve year old rich kid, perhaps a king or queen, seeking agents to help manage their wealth or kingdom. It is far from obvious that this child is on average worse off when they choose a smarter more capable agent, or when the overall pool of agents from which they can choose becomes smarter and more capable. And its even less obvious that the kid becomes maximally worse off as their agents get maximally smart and capable. In fact, I suspect the opposite.</p>
</blockquote>
<p>Thinking on that example, my mind went to Edward the Vth of England (one of the ""<a href=""https://en.wikipedia.org/wiki/Princes_in_the_Tower"">Princes in the Tower</a>""), deposed then likely killed by his ""protector"" <a href=""https://en.wikipedia.org/wiki/Richard_III_of_England"">Richard III</a>. Or of the <a href=""https://en.wikipedia.org/wiki/Guangxu_Emperor"">Guangxu Emperor</a> of China, put under house arrest by the Regent <a href=""https://en.wikipedia.org/wiki/Empress_Dowager_Cixi"">Empress Dowager Cixi</a>. Or maybe the ten year-old <a href=""https://en.wikipedia.org/wiki/Athittayawong"">Athitayawong, king of Ayutthaya</a>, deposed by his main administrator after only 36 days of reign. More examples can be dug out from some of Wikipedia's list of <a href=""https://en.wikipedia.org/wiki/Category:Rulers_deposed_as_children"">rulers deposed as children</a>.</p>
<p>We have no reason to restrict to child-monarchs - so many Emperors, Kings, and Tsars have been deposed by their advisers or ""agents"". So yes, there are many cases where agency fails catastrophically for the <a href=""https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem"">principal</a> and where having a smarter or more rational agent was a disastrous move.</p>
<p>By restricting attention to agency problems in economics, rather than in politics, Robin restricts attention to situations where institutions are strong and behaviour is punished if it gets too egregious. Though even today, there is plenty of betrayal by ""agents"" in politics, even if the results are less lethal than in times gone by. In economics, too, we have fraudulent investors, some of which escape punishment. Agents betray their principals to the utmost - when they can get away with it.</p>
<p>So Robin's argument is entirely dependent on the assumption that institutions or rivals will prevent AIs from being able to abuse their agency power. Absent that assumption, most of the ""large (mostly economic) literature on agency failures"" becomes irrelevant.</p>
<p>So, would institutions be able to detect and punish abuses by future powerful AI agents? I'd argue we can't count on it, but it's a question that needs its own exploration, and is very different from what Robin's economic point seemed to be.</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
Nnrp3yYBPWjJg8nGS,"Cognition and Intractability by Rooij, Blokpoel, Kwisthout, Wareham",cognition-and-intractability-by-rooij-blokpoel-kwisthout,https://www.lesswrong.com/posts/Nnrp3yYBPWjJg8nGS/cognition-and-intractability-by-rooij-blokpoel-kwisthout,2019-05-22T18:55:30.822Z,3,2,0,False,False,https://www.cambridge.org/core/books/cognition-and-intractability/2FC21B94CCCFBBD1E11A2D30D4503A23,"<html><head></head><body><blockquote>
<p>Intractability is a growing concern across the cognitive sciences: while many models of cognition can describe and predict human behavior in the lab, it remains unclear how these models can scale to situations of real-world complexity. Cognition and Intractability is the first book to provide an accessible introduction to computational complexity analysis and its application to questions of intractability in cognitive science. Covering both classical and parameterized complexity analysis, it introduces the mathematical concepts and proof techniques that can be used to test one’s intuition of (in)tractability. It also describes how these tools can be applied to cognitive modeling to deal with intractability – and its ramifications – in a systematic way. Aimed at students and researchers in philosophy, cognitive neuroscience, psychology,artificial intelligence, and linguistics who want to build a firm understanding of intractability and its implications in their modeling work, it is an ideal resource for teaching or self-study</p>
</blockquote>
<p>From the <a href=""https://assets.cambridge.org/97811070/43992/frontmatter/9781107043992_frontmatter.pdf"">preface</a> of the book .</p>
<p>Since cognitive science is an active topic of discussion in LessWrong, I guess many people would like this book. Even though the book is not free, you can check out the <a href=""https://assets.cambridge.org/97811070/43992/excerpt/9781107043992_excerpt.pdf"">intro chapter</a>. <a href=""https://scholar.google.com/citations?user=zKLm26IAAAAJ&amp;hl=en"">Iris Van Rooij </a>also has some other interesting papers such as <a href=""https://onlinelibrary.wiley.com/doi/pdf/10.1080/03640210801897856"">""The tractable cognition thesis""</a></p>
</body></html>",NomadicSecondOrderLogic,nomadicsecondorderlogic,bhishma,
y4niq8TDfbddiXw8u,"What is your personal experience with ""having a meaningful life""?",what-is-your-personal-experience-with-having-a-meaningful,https://www.lesswrong.com/posts/y4niq8TDfbddiXw8u/what-is-your-personal-experience-with-having-a-meaningful,2019-05-22T14:03:39.509Z,22,12,26,False,True,,"<p>I hear a lot of different stories about how meaning should fit into one&#x27;s life</p><blockquote>&quot;What&#x27;s all this meaning bullshit? Just focus on doing your job well and providing for your family.&quot;   </blockquote><p>^my grandparents</p><blockquote>&quot;Wanting meaning is wanting a simple narrative to your life, no simple narrative can possibly be true which means you should forgo the impulse for meaning in favor of the truth.&quot; </blockquote><p>^some rationalists I know now</p><blockquote>&quot;Sure you can have meaning, but base it off of something real like &#x27;pushing the bounds of human knowledge&#x27; instead of some ancient conception of a deity.&quot; </blockquote><p>^some other rationalists I know now</p><blockquote>&quot;Without meaning you might still be able to have an okay life, but you&#x27;re missing out on one of the most important/enjoyable/most-human parts of being a human.&quot; </blockquote><p>^my parents</p><blockquote>&quot;Without meaning, you and your society will slowly degrade and fall apart and it is imperative that you find a narrative that works, otherwise game over.&quot; </blockquote><p>^Jordan Peterson maybe(?)</p><p><strong>Question:</strong> Do you personally feel a need/desire/impulse to have something like meaning in your life? How do you feel when you have it? How do your feel when you don&#x27;t? If you do experience a need for meaning, how do you feel about having that need? </p><p>If you feel a need for meaning, what sorts of things feel meaningful? If you don&#x27;t feel a need for meaning, what is that like? If you feel a need for meaning but don&#x27;t endorse it, why is that the case?</p><p><strong>Alternative Question </strong>(If your answer is something along the lines of &quot;I don&#x27;t really care about meaning much, I mostly just try to spend time on things I care about&quot;): Are you readily able to discern what you care about? Do you think and decide what to care about? Have you ever had the experience of caring about ABC for a long time, then some event cause you to no longer care about ABC? What does life feel like when you&#x27;re doing stuff you care about? What does it feel like when you aren&#x27;t?</p><p>This is an open ended and fuzzy topic, and I&#x27;m am looking for any and all personal experience data points you can provide.</p><p><em>Edit/Clarification</em>: My main motive for asking is that I was planning to write some posts about meaning, and wanted to check if the views I was responding to were ones other people held, or just straw men. Again, I&#x27;m interested in either personal details of how you experience meaning, but also find useful hearing about people&#x27;s explicit models of &quot;what is the thing in the brain that is meaning?&quot; (I would conceivable ask for models as a related question, but I&#x27;m not sure how that feature works and don&#x27;t know what it looks like when used)</p><br/>",Hazard,hazard,Hazard,
XXJ4f67vib3usqsef,SSC Paris Meetup,ssc-paris-meetup,https://www.lesswrong.com/events/XXJ4f67vib3usqsef/ssc-paris-meetup,2019-05-22T13:48:08.017Z,2,2,0,False,False,,"<p>Exact location TBD, but should be close to 48.8455°N,2.3372°E . Contact me by email at <a href=""felix.breton@ens.fr"">felix.breton@ens.fr</a> or call 06.45.68.77.26.</p>",fbreton,fbreton,fbreton,
S9B3t6G6xfKL4ER9e,Schelling Fences versus Marginal Thinking,schelling-fences-versus-marginal-thinking,https://www.lesswrong.com/posts/S9B3t6G6xfKL4ER9e/schelling-fences-versus-marginal-thinking,2019-05-22T10:22:32.213Z,23,15,8,False,False,,"<p>Follow-up / Related to: Scott Alexander&#x27;s <a href=""https://www.lesswrong.com/posts/Kbm6QnJv9dgWsPHQP/schelling-fences-on-slippery-slopes"">Schelling Fences on Slippery Slopes</a>, <a href=""https://www.lesswrong.com/posts/tyMdPwd8x2RygcheE/sunk-cost-fallacy"">Sunk Cost Fallacy</a>, Gwern&#x27;s <a href=""https://www.gwern.net/Sunk-cost"">Are Sunk Costs Fallacies?</a>, and Unenumerated&#x27;s <a href=""http://unenumerated.blogspot.com/2012/08/proxy-measures-sunk-costs-and.html"">Proxy Measures, Sunk Costs, and Chesterton&#x27;s Fence</a></p><p>I was recently reading an essay by Clayton Christensen, in the (fairly worthwhile)  HBR&#x27;s &quot;Must Reads&quot; boxed set, where he recommends that people &quot;Avoid the Marginal Cost Mistake&quot;. In short, he suggests that Schelling Fences are sometimes ignored, or not constructed, because of a somewhat fallacious application of marginal-cost thinking. For example, my Schelling fence for work is that I stop when it is time to get my kids. The other side is that occasionally I&#x27;m in the middle of something - coding, or writing this lesswrong post - where being interrupted is fairly high cost. I can usually ask someone else to pick them up instead, and given how much I see them, the marginal value of time with my kids is low.</p><p>Christensen suggests that this analysis is incorrect, largely because of myopia. I am ignoring the longer term benefits of family dinners because the connection between coming home today and building the norm of being home for dinner every night is a longer-term investment. The future is full of extenuating circumstances, and only a fairly strong Schelling fence will let me insist that my kids stay home for dinner once they are teenagers. </p><p>I&#x27;d apply it more broadly, but his point was that this is especially critical in matters of morality. Cheating once changes everything. The simple fact that you cheated weakens your resolve not to in the future. The spiral created by a single action leads easily down a path towards using infinite money and invulnerability cheat codes, with no further challenge or enjoyment from playing the video game - or in the context he&#x27;s discussing, it led to jail time for two of the people from his graduating class back in college.</p><h2>Conclusions?</h2><p>The critical question is: where do we want to use marginal cost analysis, and where do we want to stick to our sunk-costs and Schelling fences?</p><p>Based on Christensen&#x27;s analysis, I would suggest that Schelling fences rather than sunk costs are particularly valuable for reinforcing values that are hard to measure, are too long term to get routine feedback on, or that involve specific commitments to other people. On the other hand, based on Gwern&#x27;s work, I think there are places where marginal costs are under-appreciated, especially in relation to other people. Below, I lay out some settings and examples on each side.</p><br/><p>Some examples of where to consider reinforcing fences and avoiding simplistic marginal cost thinking might include:</p><ul><li>Going to a weekly meet-up that reinforces your connections to a good epistemic community and/or effective altruist values. Value drift is a long-term concern that needs short term reinforcement.</li><li>Anything involving family or long-term relationships. Marginal cost thinking is poisonous for relationships, since the benefits of investing in the relationship are not very visible, and long term.</li><li>Moral rules. Utilitarian and consequentialist thinking is easy to use to <a href=""https://www.lesswrong.com/posts/AdYdLP2sRqPMoe8fb/knowing-about-biases-can-hurt-people"">make yourself stupider</a>. At the very least, you should be asking others - just like this is useful to avoid unilateralist curses, it is useful to avoid self-deception and convenient excuses.</li><li>Where there are switching costs or longer term goals. Learning to play guitar instead of continuing to practice piano (or moving from C++ to Python) is easy to justify in the short term, but expensive in terms of changes needed and resetting progress.</li><li>When goals are unknown. As Unenumerated put it, &quot;cases where substantial evidence or shared preferences that motivated the original investment decision have been forgotten or have not been communicated, or otherwise where the quality of evidence that led to that decision may outweigh the quality of evidence that is motivating one to change one&#x27;s mind.&quot;</li></ul><p>Some examples of where it seems useful to avoid constructing Schelling fences, and to try paying more attention to marginal cost:</p><ul><li>When constructing rules for other people, or in orgnaizations. Schelling fences are useful for self-commitment, otherwise they are rules and formal structures rather than norm-based fences. As gwern noted, &quot; Whatever pressures and feedback loops cause sunk cost fallacy in organizations may be <em>completely</em> different from the causes in individuals.&quot;</li><li>When the environment is very volatile, and non-terminal goals change. It&#x27;s easy to get stuck in a mode where the justification is &quot;this is what I do,&quot; rather than a re-commitment to the longer term goal. If you are unsure, try revisiting why the fence was put there. (But if you don&#x27;t know, be careful of removing Chesterton&#x27;s Fence! See &quot;When goals are unknown&quot;, above.)</li><li>When the fence is based on a measurable output, rather than an input. In such a case, the goal has been <a href=""http://www.ribbonfarm.com/2016/06/09/goodharts-law-and-why-measurement-is-hard/#reification"">reified, and is subject to Goodhart effects</a>. Schelling fences are not appropriate for outcomes, since the outcome isn&#x27;t controlled directly. (Bounds on outcomes also implicitly discourage further investment - see: <a href=""https://medium.com/@davidmanheim/shorrocks-law-of-limits-9d1b2880b13"">Shorrock&#x27;s Law of Limits</a>. If necessary, the outcome itself should be rewarded, rather than fenced in.)</li></ul>",Davidmanheim,davidmanheim,Davidmanheim,
sM2sANArtSJE6duZZ,Where are people thinking and talking about global coordination for AI safety?,where-are-people-thinking-and-talking-about-global,https://www.lesswrong.com/posts/sM2sANArtSJE6duZZ/where-are-people-thinking-and-talking-about-global,2019-05-22T06:24:02.425Z,112,39,22,False,True,,"<html><head></head><body><p>Many AI safety researchers these days are not aiming for a full solution to AI safety (e.g., the classic Friendly AI), but just trying to find good enough partial solutions that would buy time for or otherwise help improve global coordination on AI research (which in turn would buy more time for AI safety work), or trying to obtain partial solutions that would only make a difference if the world had a higher level of global coordination than it does today.</p>
<p>My question is, who is thinking directly about how to achieve such coordination (aside from FHI's <a href=""https://www.fhi.ox.ac.uk/GovAI"">Center for the Governance of AI</a>, which I'm aware of) and where are they talking about it? I personally have a bunch of questions related to this topic (see below) and I'm not sure what's a good place to ask them. If there's not an existing online forum, it seems a good idea to start thinking about building one (which could perhaps be modeled after the AI Alignment Forum, or follow some other model).</p>
<ol>
<li>What are the implications of the current US-China trade war?</li>
<li>Human coordination ability seems within an order of magnitude of what's needed for AI safety. Why the coincidence? (Why isn’t it much higher or lower?)</li>
<li>When humans made advances in coordination ability in the past, how was that accomplished? What are the best places to apply leverage today?</li>
<li>Information technology has massively increased certain kinds of coordination (e.g., email, eBay, Facebook, Uber), but at the international relations level, IT seems to have made very little impact. Why?</li>
<li>Certain kinds of AI safety work could seemingly make global coordination harder, by reducing perceived risks or increasing perceived gains from non-cooperation. Is this a realistic concern?</li>
<li>What are the best intellectual tools for thinking about this stuff? Just study massive amounts of history and let one's brain's learning algorithms build what models it can?</li>
</ol>
</body></html>",Wei_Dai,wei-dai,Wei Dai,
wG5aCWow9TFC27Joc,A War of Ants and Grasshoppers,a-war-of-ants-and-grasshoppers,https://www.lesswrong.com/posts/wG5aCWow9TFC27Joc/a-war-of-ants-and-grasshoppers,2019-05-22T05:57:37.236Z,17,5,21,False,False,http://benjaminrosshoffman.com/war-ants-grasshoppers/,<p>A parable on the difference between motives and ecological niches. </p>,Benquo,benquo,Benquo,
gNTzMcwT2gdj6h52E,Discourse Norms: Justify or Retract Accusations,discourse-norms-justify-or-retract-accusations,https://www.lesswrong.com/posts/gNTzMcwT2gdj6h52E/discourse-norms-justify-or-retract-accusations,2019-05-22T01:49:12.271Z,8,13,24,False,False,,"<p>One discourse norm that I think is really important is that of having to either support or retract accusations if challenged. If you say something negative about another person, their work, etc. and they ask you to explain yourself, I believe you are compelled to either justify or retract your statement. This creates a strong barrier against unjustified attacks and gossip, while still allowing justified criticism.</p><p>Here are some examples of what this norm might look like in action:</p><p><em>1. Alice posts about her thoughts on an issue; Bob, who dislikes Alice, responds with snarky insults about Alice&#x27;s motivations. Alice asks Bob to explain his accusations, and he doesn&#x27;t do so or replies with more insults. Moderation intervenes against Bob.</em></p><p><em>2. Carol posts a brief comment saying a project is incompetent. Darryl replies asking her to provide more detail or retract. Carol links to a post that explains her critique in more detail.</em></p><p><em>3. Efren posts a statement criticizing an event that will soon be held. Faye asks Efren to back up his criticisms. Efren decides that his claim was actually more emotional and less grounded than he first thought, so he decides to retract his original statement.</em></p><p>Now, someone might ask &quot;why try to make it more difficult to be critical of something?&quot; The answer is that <a href=""https://www.lesswrong.com/posts/srAdo8k7De8mvvngr/making-fun-of-things-is-easy"">making fun of things is easy</a> [1], and in general norms online often trend too much in the direction of low-content mockery rather than reasoned debate. Holding norms that require people to back up or retract controversial statements can be a good step away from that failure mode.</p><br/><p>[1] Full disclosure: I wrote the linked post under my old username.</p>",Davis_Kingsley,davis_kingsley,Davis_Kingsley,
iJDrAuhByc8jJiFCE,Constraints & Slackness Reasoning Exercises,constraints-and-slackness-reasoning-exercises,https://www.lesswrong.com/posts/iJDrAuhByc8jJiFCE/constraints-and-slackness-reasoning-exercises,2019-05-21T22:53:11.048Z,42,16,3,False,False,,"<p><i>Epistemic status: no idea if this will work at all for learning the relevant thought-skills. Please post feedback if you try any exercises, especially if you hadn’t internalized these skills already.</i></p><p>The goal of this post is to briefly explain and practice a very general thought-tool. If you've ever tried to <a href=""https://www.lesswrong.com/posts/uHYYA32CKgKT3FagE/hold-off-on-proposing-solutions"">hold off on proposing solutions</a>, then sat there without any idea where to start, then this is the sort of tool which you may find useful. We'll start with a short example and explanation, then dive right into the exercises.</p><p>Here’s a reaction you may have used in high school or undergrad chem lab to synthesize aspirin:</p><p><img style=""width:410%"" src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/alogqybtrj84ufksouhg""></p><p>(<a href=""https://cdn.britannica.com/24/117824-004-61F6E192.jpg""><u>source</u></a>)</p><p>Each mole of aspirin requires one mole each of salicyclic acid and acetic anhydride to produce.</p><p>Warm-up question: we start with one mole of salicyclic acid and two moles of acetic anhydride. Assuming the reaction runs to completion (i.e. as much of the reactants as possible are converted to aspirin), which will result in more total aspirin production: one extra mole of salicyclic acid, or one extra mole of acetic anhydride?</p><p>In the language of optimization/economics, we have two constraints:</p><ol><li>the amount of aspirin produced is less than or equal to the amount of salicyclic acid available (in moles)</li><li>the amount of aspirin produced is less than or equal to the amount of acetic anhydride available (in moles)</li></ol><p>In the case of our warm-up question, we would say that constraint 1 is “taut” and constraint 2 is “slack”. Once 1 mole of aspirin is produced, we cannot produce any more, because there is no “room left” in constraint 1 - just like a taut rope cannot be pulled further, a taut constraint can go no further. Conversely, just like a slack rope <i>can</i> be pulled further, constraint 2 has extra room - extra acetic anhydride left, which could produce more aspirin if only we had more salicyclic acid.</p><p>Key point: the slack constraint is completely and totally irrelevant to the amount of aspirin produced, so long as it remains slack: adding one additional mole of acetic anhydride will produce exactly zero extra moles of aspirin. If we want to maximize the amount of aspirin produced, then we should ignore the slack constraint (acetic anhydride) and focus on the taut constraint (salicyclic acid).</p><p>This idea generalizes: whenever we want to optimize something, we can ignore slack constraints. Only the taut constraints matter.</p><p>In more realistic situations, “constraints” usually aren’t perfectly binding. For instance, a real aspirin-producing reaction might not run <i>all</i> the way to completion - it might reach some equilibrium where there’s a little bit of both salicyclic acid and acetic anhydride in the solution, and adding either one will produce at least some extra aspirin. But even then, constraint 1 will be “more taut” than constraint 2 - one extra mole of salicyclic acid will produce a lot more extra aspirin than one extra mole of acetic anhydride. We can quantify this via marginal production (a.k.a. the gradient), but that’s not really the goal here.</p><p>The goal here is to build some intuition for recognizing which constraints in a problem are probably more taut or more slack, and using that intuition to make tradeoffs. In the real world, this usually requires a bunch of domain-specific knowledge, so we'll be using some made-up games to keep it simple.</p><h1>Game Exercises</h1><p>In these exercises, the rules of a game are laid out up-front. Identifying potential constraints/resources should be relatively easy; the focus is on predicting which constraints will be taut. The main question will be: what do you expect to be the main bottleneck?</p><p>Side notes: these exercises are intended for people <i>not</i> already familiar with the specific subject matter, so if you've never played Magic: The Gathering or Civilization V or whatever then don't worry. Feel free to post clarifying questions in the comments. If you post solutions or major hints in the comments, please <a href=""https://www.rot13.com/"">rot13</a> them.</p><h2>Exercise 1: Deck-Building Game</h2><p>Consider a simplified deck-building combat game, along the lines of Magic or Hearthstone. You start each turn with five random cards from your deck, and three mana. Each card costs one mana to play, and does useful things: summons or boosts allies, damages your opponent or their allies, etc. On your turn, you can play as many cards as you like, until you run out of either cards or mana. At the end of your turn, any leftover cards get shuffled back into your draw pile, along with any cards you played.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/uyk8qwyfrkuwbwxsr4ju"" srcset=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/abhjwedessued5qeblqy 144w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/aq9poyjr3ievym0d89y2 224w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/qzvfasptekktj9b0zzjb 304w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/xrxawpmcfltecajmuhcd 384w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/cgxmrelhgsbfql4uogtl 464w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/t28ijgx7tf5j1apwrgc0 544w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/jldhglhhuuuafqi2vnel 624w""></figure><p>Start each turn with 5 random cards and 3 mana. Each card costs 1 mana to play. At the end of your turn, all cards (both played and in hand) are shuffled back into your draw pile.</p><p>You have a choice between two cards to add to your deck:</p><ul><li>Energy card: gain 2 mana immediately (Note that it costs 1 mana to play)</li><li>Draw card: draw 2 cards immediately</li></ul><p>These are the only cards in the game which gain mana or draw cards, respectively.</p><p>All else equal, which of the two cards above would you choose? For each scenario below, identify relevant constraints, predict which constraints are taut/slack, and use this knowledge to pick your card. If your answer depends on something, say what (and quantify it if possible!).</p><ol><li>The entire rest of the deck is copies of the Attack card</li><li>Full deck has size 25 cards, you have 2 Energy cards already, rest of the deck is Attack (Hint: you draw 5 random cards each turn. What constraint has the highest probability of being taut?)</li><li>Full deck has size 25 cards, you have 8 Energy cards already, rest of the deck is Attack</li><li>The rest of the deck is 50% Attack and 50% Defend. Depending on the turn, you want to either only attack or only defend - the other card is useless.</li><li>As previous, except 30% Attack and 70% Defend.</li><li>One card in your deck wins the game instantly. (If your answer depends on something, quantify it.)</li><li>There are roughly 4 different card types in your deck, with differing numbers of each, each suited to different situations.</li><li>As previous, except full deck size is 25 cards and you have 5 Draw and 2 Energy cards already.</li></ol><h2>Exercise 2: 4X Game</h2><p>Next, let’s consider a simplified 4X game, along the lines of Civ (4X = explore, expand, exploit, exterminate). You start the game with your home base (fixed position) and one unit (mobile), located somewhere on a large and mostly-unrevealed map. The unit always starts at your home base, and comes in one of four types:</p><ul><li>Scout: fast, long sight range (good for exploration)</li><li>Settler: can establish new bases (good for territorial expansion)</li><li>Worker: builds improvements on your bases/territory (good for exploiting resources)</li><li>Warrior: can fight other players and take their stuff (good for either offense or defense)</li></ul><p>You can obtain more units by paying for them with resources. Resources are produced by the territory around your bases: in general, more bases =&gt; more territory =&gt; more resources =&gt; buy more units. However, different locations may produce more/different resources. Improvements (built by workers) will generally increase resource yield, but have diminishing returns: second or third improvements have less percentage impact than first improvements.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/o5krbuh4kkrrogflrdu8"" srcset=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/qmo3cbas442kvzxghtvq 144w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/wgpjmc7sicvolqp2lkjp 224w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/moutwczbcbtyooup0aif 304w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/nauyx7g3kpeh2s1xlqwi 384w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/ezauezntu1rizxfguwls 464w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/evyug2ryjtvjacsnibt4 544w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/iJDrAuhByc8jJiFCE/v2fqtcuoxiqrnzzokr5v 624w""></figure><p>The base collects resources from its territory - five lightning and two heart resources. Different locations produce more/different resources, and the hex to the north produces no resources at all. Most of the map is unexplored, as indicated by “?”. The unit north-east of the base can move around, e.g. to explore the map.</p><p>Unless otherwise stated, you may assume that:</p><ul><li>Your home base produces whatever resources are needed to create any additional units, but not very quickly.</li><li>There are no units except those belonging to the players (i.e. no “barbarian” units).</li><li>Players usually start far apart.</li><li>Win condition is to exterminate the other players, but the game is long enough that extermination usually isn’t directly relevant in the early game.</li></ul><p>For each scenario below, you get to pick exactly one unit to start the game with. For each one, identify relevant constraints, predict which are taut (all else equal), and then pick a unit type. If your answer depends on something, say what (and quantify it if possible!), and at least try to eliminate some of the unit types.</p><ol><li>Map is uniform (no location different from any other).</li><li>Sparse resources: most locations produce no resources.</li><li>Your starting location has unusually good resources.</li><li>You start right next to another player.</li><li>The map starts with one-time resource caches, picked up by the first unit to find them.</li><li>You do not know how close you start to other players.</li><li>The entire map, including other players’ bases, is revealed at the start.</li><li>The entire map, including other players’ bases and units, is visible throughout the game.</li><li>Improvements have increasing rather than decreasing returns.</li><li>There are hostile “barbarian” units scattered around the map which attack the players’ units.</li></ol><h2>Exercise 3: Engine-Building Game</h2><p>Finally, we’ll look at a simplified engine-building game. Each player has some resources and some cards. On your turn, you draw four cards from the deck, and can purchase as many of them as you want (and can afford) using whatever resources you’ve accumulated. Each card does different things - some give an immediate one-time benefit (e.g. trading one resource for another), others give long-term benefits (e.g. producing resources every turn or every time something specific happens), and some give the player new capabilities (e.g. the ability to trade one resource for another indefinitely).</p><p>To keep it simple, we’ll assume that:</p><ul><li>You’re usually not directly competing with other players for particular cards.</li><li>The first player to amass a certain amount of resources wins.</li></ul><p>In each scenario below, pick which cards to buy (or decide not to buy any). For each one, identify relevant constraints, predict which are taut (all else equal), and then pick cards. If your answer depends on something, say what (and quantify it if possible!), and at least try to eliminate some of the cards.</p><ol><li>On your first turn, you have a choice between two types of cards: Machines, which produce one resource per turn, and Machine Shops, which produce one Machine per turn. You can spend all your resources to buy either three Machines or one Machine Shop. Which do you pick? If your answer depends on something, quantify it.</li><li>Same as previous question, but it’s late in the game rather than your first turn.</li><li>There are two different resources in the game: diamonds and rubies. You have a choice between a Machine which produces two diamonds per turn, or a Machine which produces one resource of your choice per turn. All resource-producing Machines are quite common in the game.</li><li>Same as (3), except ruby-producing Machines are rare.</li><li>Same as (3), except diamond-producing Machines are rare.</li><li>Same as (3), except there are six resources in the game rather than two.</li><li>Same as (3), except you can trade with other players.</li><li>Same as (3), except you can trade with other players and the other players already have lots of diamond production.</li><li>Same as (3), except you can trade with other players and the other players already have lots of ruby production.</li></ol>",johnswentworth,johnswentworth,johnswentworth,
FAzsLPgosq4fRthuJ,A Quick Taxonomy of Arguments for Theoretical Engineering Capabilities,a-quick-taxonomy-of-arguments-for-theoretical-engineering,https://www.lesswrong.com/posts/FAzsLPgosq4fRthuJ/a-quick-taxonomy-of-arguments-for-theoretical-engineering,2019-05-21T22:38:58.739Z,30,8,1,False,False,,"<p><em>Epistemic Status: I didn&#x27;t think about this for that long, could be improved, but I still think it&#x27;s a good first pass.</em></p><p><strong>This post is was written as an answer to the &quot;and how do we know that?&quot; part of  the question <em><a href=""https://www.lesswrong.com/posts/NZiDAY9b4mZeRWbRc/space-colonization-what-can-we-definitely-do-and-how-do-we"">Space colonization: what can we definitely do and how do we know that?</a></em></strong></p><p>Working on questions related to space colonization, I&#x27;ve formed a loose taxonomy of the kinds of arguments I&#x27;ve encountered - primarily those in <a href=""https://www.fhi.ox.ac.uk/publications/armstrong-s-sandberg-a-2013-eternity-in-six-hours-intergalactic-spreading-of-intelligent-life-and-sharpening-the-fermi-paradox-acta-astronautica-89-1-13/"">Eternity in Six Hours</a>, but also other sources and arguments I make myself.</p><h2>A Taxonomy of Argument Types</h2><p><strong>1. Our understanding of the laws of physics says it should be possible.  (Argument from Physics/Basic Science)</strong></p><p>At the most basic, we have reason to believe doing something is possible when applying highly-confident models of physics say that it should be. For example, we have a lot of confidence in the laws of motion, general relativity, and chemistry. Related to these, we have (I believe) a lot of confidence in our models of astronomy and how far away different stars. These models state that with enough energy one can accelerate objects to fast enough speeds to reach remote celestial destinations.</p><p>At this level, we&#x27;re dealing a lot with energy, distances, accelerations and things that resemble back of the envelope calculations.</p><p>Usually application of physical theory also requires use of empirically obtained data, such as calculations of interstellar dust densities. However, this data can often be generated from robust models and sensors that work off basic physical quantities. Plus one can explore the sensitivity of the models showing that even changing empirical parameters by an order of magnitude doesn&#x27;t undermine the overall argument.</p><p>Note that the arguments in these models are both contingent and used to rule out of a lot of goals and scenarios. We could imagine worlds where everything is much further away and achievable speeds are much slower such that we could never reach anything. We also don&#x27;t spend thought on things which seem ruled out, e.g. faster than light travel, or even levels of speed that would require exceedingly enormous quantities of energy.</p><p><strong>2. Things nature has done, so reasonably we as intelligent beings in nature should eventually be able to too. (Argument from Nature)</strong></p><p>Without elaboration, the authors of Eternity in Six Hours rely on this argument when making the assumption that humanity will eventually achieve atomically precise manufacturing (APM). I see the intuitive sense behind this argument. If the blind optimization process of evolution can accomplish something, why shouldn&#x27;t an intelligence like us also be able to do it?</p><p>To borrow an example from the paper, nature is able to create an acorn which grows into a massive tree using local resources. Seemingly humans should be able to match that or do even better, e.g. how our flight is a lot better along many metrics than flight found in nature.</p><p><strong>3. We have a proof of concept. (Argument from POC)</strong></p><p>This builds on 1. Argument from Physics. With this kind of argument, we can point to both a theoretical understanding of why something should be doable together with a basic demonstration of the idea.</p><p>For example, we might propose that coilguns or laser propulsion might be feasible ways to accelerate probes to very fast speeds. In this case we have the physics models, but also basic &quot;prototypes&quot; of the ideas as<a href=""https://en.wikipedia.org/wiki/Coilgun#Potential_uses""> <u>smaller coilguns have been built</u></a> (much, much, much smaller to be fair) and<a href=""https://youtu.be/TzLEK8Zq7Pk""> <u>laser propulsion has been demonstrated</u></a> in the lab.</p><p>At this point, the core physics mechanism has been proven and what remains is the engineering question about whether things can be scaled up sufficiently.</p><p><em>(We can actually say that 2. Argument from Nature is a form of 3. Argument from POC)</em></p><p><strong>4. We&#x27;ve done it already. (Argument from Accomplishment)</strong></p><p>Naturally, the strongest argument for our ability to do something is the fact that we&#x27;ve done it. For instance, we know definitely that we can rather large amounts of matter into orbit around the earth.</p><h2>Limitations of These Arguments</h2><p>The type arguments, from weakest to strongest, aren&#x27;t conclusive. Just because the basic physics behind an idea checks out, doesn&#x27;t mean that there aren&#x27;t immense and overwhelming engineering challenges which would get in the way somewhere the in chain. Perhaps the energy efficiencies required can&#x27;t be easily achieved, perhaps manufacturing tolerances can&#x27;t be made precise enough, perhaps the cost is just too damn high. One can easily  argue that theoretically doable and actually doable are not the same thing.  Sheer scale can make things tough - consider that building ten fifty story buildings is probably much easier than building one five hundred story building.</p><p>Consider a practical example: despite our physics models describing nuclear fusion clearly and research having begun the 1920&#x27;s, we do not yet have working nuclear fusion reactors.</p><p>Another argument I might make is that even if you can argue that all N technologies you think are necessary for some goal are physically feasible, until you have actually built it, there may remain plausible other further necessary technologies you failed to identify and which are impossible to produce.</p><p>When it comes to space colonization, we don&#x27;t really have any cases of 4. &quot;We&#x27;ve already done it&quot; since in no case have we achieved the enormous scales required.</p><p>In the case of space colonization, however, and particularly the scenario described in Eternity in Six Hours, there is something of a rejoinder: It is okay if the engineering challenges are immensely difficult since it is okay if takes humanity thousands or even millions of years to overcome them. Here one might include an argument from analogy: in about the last hundred years, humanity <a href=""https://en.wikipedia.org/wiki/History_of_the_world%27s_tallest_buildings"">gained the ability to construct building five times the height</a> of  the historical maximum; within fifty years we were able to make chips with a million times the transistor counts; and in less than a century of the<a href=""https://en.wikipedia.org/wiki/History_of_molecular_biology""> <u>field of microbiology coalescing</u></a>, we are<a href=""https://en.wikipedia.org/wiki/CRISPR_gene_editing""> <u>editing DNA</u></a>. Perhaps these are reasons for optimism that with thousands or millions of years we could replicate anything nature does and build structures as vast as Dyson spheres.</p><p>Of course, as above, that still leaves the question of whether or not we&#x27;re accounting for all the basic physical facts.</p>",Ruby,ruby,Ruby,
iH2HpSshoQvqpX4Qq,Could humanity accomplish everything which nature has? Why might this not be the case?,could-humanity-accomplish-everything-which-nature-has-why,https://www.lesswrong.com/posts/iH2HpSshoQvqpX4Qq/could-humanity-accomplish-everything-which-nature-has-why,2019-05-21T21:03:28.075Z,8,2,0,False,True,,<p>Examples include atomically precise manufacturing and creating intelligence.</p>,Ruby,ruby,Ruby,
z4cdB5sR7fA6Eya5o,Could humanity ever achieve atomically precise manufacturing (APM)? What about a much-smarter-than-human-level intelligence?,could-humanity-ever-achieve-atomically-precise-manufacturing,https://www.lesswrong.com/posts/z4cdB5sR7fA6Eya5o/could-humanity-ever-achieve-atomically-precise-manufacturing,2019-05-21T21:00:30.562Z,8,2,0,False,True,,,Ruby,ruby,Ruby,
yuMuDGnJ8omGhMx9y,TAISU - Technical AI Safety Unconference,taisu-technical-ai-safety-unconference,https://www.lesswrong.com/events/yuMuDGnJ8omGhMx9y/taisu-technical-ai-safety-unconference,2019-05-21T18:34:34.051Z,15,9,15,False,False,,"<p><strong>Start:</strong> Thursday, August 22, 10am<br/><strong>End: </strong>Sunday, August 25, 7pm<br/><strong>Location: </strong><u><a href=""http://eahotel.org/wiki/#travel"">EA Hotel</a></u>, 36 York Street, Blackpool</p><p>It is an unconference, which means that it will be what we make of it. There will be an empty schedule wich you, the participants, will fill up with talks, discussions and more.</p><p>To be able to have high level discussion during the unconference, we require that all participants have some prior involvement with AI Safety. Here is a non complete list of things that are sufficient:</p><ul><li>Have participated in one of the following: <u><a href=""https://aisafetycamp.com/"">AI Safety Camp</a></u>, <u><a href=""https://rationality.org/workshops/apply-msfp"">MSFP/AISFP</a></u>, <u><a href=""http://humanaligned.ai/"">Human-aligned AI Summer School</a></u>, <a href=""https://www.lesswrong.com/events/z9peEBfuiPB7L2Edb/learning-by-doing-ai-safety-workshop"">Learning-by-doing AI Safety workshop</a></li><li>Are currently or have previously worked for or interned at an established AI Safety organization</li><li>Have published papers or sufficiently high quality blogpost about AI Safety</li></ul><p>You can participate in the unconference as may or as few days as you want to. You are also welcome to stay longer at at EA Hotel before or after the unconference. However, be aware that there is another event, <u><a href=""https://www.lesswrong.com/events/z9peEBfuiPB7L2Edb/learning-by-doing-ai-safety-workshop"">Learning-by-doing AI Safety workshop</a></u>, the weekend before. If you want to join this workshop, you should <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLScFTxfmon-qpcHpJl9ff7RuVeSzqaxjNlAS0MfuyEac3m1wJg/viewform"">apply</a></u> for this separately.</p><p>If you are staying more than a few days extra, we ask you to book your stay though the EA Hotel <u><a href=""http://eahotel.org/booking/"">booking system</a></u>.</p><p><strong>Price:</strong> Pay what you want (cost price is £10/person/day). <br/><strong>Food:</strong> All meals will be provided by EA Hotel. All food will be vegan. <br/><strong>Lodging:</strong> The EA Hotel has two dorm rooms that have been reserved for TAISU participants, and more rooms will be booked at nearby hotels if necessary. However, if you want a private room you might be asked to pay for it yourself.</p><p><strong><em>If you want to join: <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLSfB9q6_HbxIEY-Azq3RK_vJdUtd_c8rGJKQfkdY7ldrLbosOg/viewform"">Sign up here</a></u></em></strong></p>",Linda Linsefors,linda-linsefors,Linda Linsefors,
XDZK5HZ5fXn3GL7cP,Go Do Something,go-do-something,https://www.lesswrong.com/posts/XDZK5HZ5fXn3GL7cP/go-do-something,2019-05-21T15:42:48.096Z,38,25,25,False,False,,"<p>There&#x27;s this notion going around in the community sometimes that holds that the best way to progress on one&#x27;s rationality skills is to make lots and lots of theoretical study by yourself or to go off and &quot;level up&quot; a bunch on your own prior to getting involved in object-level projects or efforts.</p><p>I think that&#x27;s false and in fact that it&#x27;s not only false but it&#x27;s almost the opposite of what needs to be done. In point of fact, much of the time I&#x27;ve seen people go off to meditate in the darkness for a year and &quot;level up&quot; a bunch, this has not only not helped much but in some cases has seemed to actually harm, as people have a tendency to go in strange and unsound directions when doing this sort of thing on their own without feedback.</p><p>Instead, I think that if you want to make progress on your rationality skills, the best way to do that is to get involved with object-level projects and use those as testing grounds for your practice. Not only will this help you test skills in a more realistic and practical setting, but it will also provide demonstrations that you can later refer to to show how things worked (or didn&#x27;t), and it will quite possibly help you build a <a href=""https://www.lesswrong.com/posts/gBewgmzcEiks2XdoQ/mandatory-secret-identities"">secret identity</a> as well.</p><p>So, yeah. If you want to be an advanced rationalist, don&#x27;t just theorize - go out there and do stuff.</p>",Davis_Kingsley,davis_kingsley,Davis_Kingsley,
NgXCYBaWeP4bGkaB3,More Notes on Simple Rules,more-notes-on-simple-rules,https://www.lesswrong.com/posts/NgXCYBaWeP4bGkaB3/more-notes-on-simple-rules,2019-05-21T14:50:00.305Z,34,10,1,False,False,,"<p> </p>
<p>Original Post by Robin: <a href=""http://www.overcomingbias.com/2019/05/simplerules.html"">Simple Rules</a></p>
<p>Previously: <a href=""https://thezvi.wordpress.com/2019/05/19/simple-rules-of-law/"">Simple Rules of Law</a></p>
<p>Sarah Constantin on Twitter (if you are doomed to be on social media at all, you should follow her) <a href=""https://twitter.com/s_r_constantin/status/1130297242626117634"">offers a commentary thread</a> of alternate explanations for the pattern pointed out in <a href=""http://www.overcomingbias.com/2019/05/simplerules.html"">Robin’s post.</a> It contains some ideas that I didn’t cover and deserve to be addressed, so this post will do that, and capture her arguments in an easier-to-find-in-the-future location. Quotes are from the thread.</p>
<p></p>
<div>
<blockquote>
<p><a href=""https://t.co/QKnSNtqC8r"">https://t.co/QKnSNtqC8r</a>  <a href=""https://twitter.com/robinhanson?ref_src=twsrc%5Etfw"">@robinhanson</a>'s explanation for why people prefer discretion to simple rules is overconfidence — everyone assumes *they'd* be the one to have special pull with decision-makers, or wants to pretend they are. ""Let's play fair"" is a loser's position.</p>
<p>— Sarah Constantin (@s_r_constantin) <a href=""https://twitter.com/s_r_constantin/status/1130297242626117634?ref_src=twsrc%5Etfw"">May 20, 2019</a></p></blockquote>
<p></p></div>
<blockquote><p>1.) Low trust: nobody believes a “fair” rule would actually be applied fairly, they aren’t considering the possibility of a genuinely impartial rule (and sometimes they’re right)</p></blockquote>
<p>In this scenario, people would prefer rule of law via a simple and fair rule to arbitrary decision making. But when someone proposes such a rule, or tells them they will be bound by such a rule, they do not believe it. They think that this is code for them having to abide by the rule when it suits those in power, only to have those in power ignore the rule when they would rather something else happen. So you need to obey the rules or get blamed for it, and others don’t. Or, alternatively, the rules are an additional thing to be scapegoated for when the political winds call for it, without taking away any of the other methods. If you obey the rules they get you for ignoring what really matters. If you focus on what really matters they get you for not obeying the rules.</p>
<p>This happens often enough that the rules are now just another way to get gas-lit. Following the rules truly becomes a loser’s position, in every sense.</p>
<p>I’d consider this a ‘good’ objection, similar to the Goodhart’s Law objections. Simple rules, and rule of law, require high enough trust and willingness to uphold those rules, or they become another source of complexity and a tool of power. If you don’t have the trust, it must be established slowly over time, or you need to structure things such that this trust emerges.</p>
<p>The word trust is overloaded, so there are things often called ‘trust’ that are <em>directly opposed </em>to the kind of trust that enables simple rules. It would be better if those things used a different word. Words need to mean things and this is one place where the lack of that makes it hard to communicate or even think clearly.</p>
<p>Side note: This is mostly a topic for another day that I really hope isn’t what the comments talk about, but feels worth motioning at here: One answer to the question “What is blockchain?” is that blockchain enables trustless systems. Another perspective is that <em>blockchain is rule of law. </em>You have faith that the system will follow the rules of the system, because humans don’t have a reasonable way to prevent that. The weirdness comes from many of the actors in the system <em>being even less trustworthy than usual </em>because you created a system that lets you work around lack of trust and lacks the  commonly used tools to punish bad behaviors. You’re relying on the rule of law, which depends on choosing good rules and correctly and securely implementing them. Where people choose and correctly implement the right incentives and structures, great things can happen. Where they have other goals or choose poorly… not so much. So you simultaneously get things you can trust a lot, and a lot of lying and fraud along side that, often built directly on top of and relying directly on the trustworthy things.</p>
<blockquote><p>2.) Ignorance or lack of intelligence: the idea of fair, impartial rules is a bit abstract, and has to be taught, and not everybody gets taught and not everybody copes well with abstraction.</p></blockquote>
<p>I have a five year old son. Based on my observations of him and other children, I do not think that the idea of fair, impartial rules has to be taught. I think it is a strong instinct that things work this way. Perhaps that’s because my kid is my kid, but from what I can tell younger kids (e.g. ages 5-8) are very big on what the rule is and what is fair. Monkey see, monkey do, and monkey enforce local norms. The kids will still <em>lie </em>and they’ll still <em>break the rules </em>when it suits them, but they totally get it. Then, as they get older, they learn more subtle ways to break and twist the rules for advantage, and play more complex games.</p>
<p>I <em>do </em>think that the idea that following simple rules and having rule of law can get better overall results needs to be taught, trust needs to be learned and maintained and built, and that there’s subtle stuff going on that’s hard to grasp. I mostly want to blame this on bad culture and failure to teach, rather than on lack of intelligence. Most people couldn’t figure this stuff out on their own, which makes it our collective responsibility to give them the tools to get there. Abstraction is by default hard, and we need concrete examples and stories and traditions that resonate – we need culture. The problem is that the powerful, and powerful natural forces, are actively fighting against us, as discussed in the previous post. And as Sarah notes next.</p>
<blockquote><p>(I sometimes think that if civics isn’t taught in schools people will eventually grow up without actually grokking the idea of “checks on power” being a good thing *independent* of who’s in power.)</p></blockquote>
<p>Quite so. And of course, most schools do not effectively teach civics. I don’t think most people get that checks on power are good, only checks on particular powerful people and things. The authoritarian instinct runs deep. Those with power would prefer people not learn that.</p>
<blockquote><p>3.) Power. Often we have a discretionary rather than rule-based system not because *most* people like it that way, but because the *powerful* people like it that way. (as <a href=""https://twitter.com/TheZvi"">@<b>TheZvi</b></a> also said.) It’s TurboTax lobbyists, not regular people, who prevent automatic tax filing.</p></blockquote>
<p>Full agreement here. There are many things most people don’t support. Because most things are not up to most people.</p>
<blockquote><p>4.) Price discrimination. Often, you can get a better deal if you ask for a favor (or bargain) face to face than if you follow procedure. The average person isn’t overconfidently estimating their charm: they’re *correct* that askers do better than nonaskers on average.</p></blockquote>
<p>Askers do better than non-askers unless asking is explicitly costly or punished. Otherwise, you sometimes get a yes and profit, and other times you get a no, and break even. And asking is usually much cheaper than it looks. We instinctively get nervous about asking, think it is risky, when usually it isn’t.</p>
<p>Asking more often is a proven winning life strategy.</p>
<p>Price discrimination maximizes profits so everyone would like to engage in price discrimination, but no one wants to be subject to it. Again, we get stories of theft and power. We also get stories of forbidden considerations, and of letting ourselves consider all the data and avoid Goodhart’s Law issues. Asking allows us to say no without explaining our reasons. Rules-based price discrimination seems universally hated, whereas discretionary price discrimination is mostly seen as good. I think this plays strongly into baselines and rewards versus punishments, which we’ll get to at #6.</p>
<p>Asking is more of a method of complexity than it is an explanation for it.</p>
<p>Most people, from what I can tell, <em>strongly dislike </em>having to ask for things and having to haggle and navigate uncertainty. A few people like the advantage they get from being better at it, again a story largely about power and theft.</p>
<blockquote><p>5.) “Copenhagen interpretation of ethics” = condemnation of intentional but not unintentional harm. This makes some sense as a legal standard, but it’s crazy when you expand it to policy, as many do.</p>
<div>
<p>Most people prefer policies with large, harmful unintended consequences over policies which explicitly admit to causing some, smaller harms. This seems like a result of confusing the question of “would this be a good world to live in?” with “should these people be punished?”</p>
</div>
</blockquote>
<p><a href=""https://blog.jaibot.com/the-copenhagen-interpretation-of-ethics/"">The Copenhagen Interpretation of Ethics</a> runs even deeper than that, and was one of my five core stories. Even in this less deep form, it’s still key and highly toxic. Somehow, “spend money that will require higher taxes” or “tax everyone” or the general “start with a lower baseline to reserve resources for special treatment” don’t seem to trigger people’s notions of intentional harm. They should. It’s intentional harm, <em>much more directly </em>than many things that are objected to as intentional harm.</p>
<blockquote><p>6.) There’s a weird thing where justice/rationality/impersonal principle is coded as “mean” while making exceptions is coded as “nice.” <strong>A “judgmental” person is one who makes *harsh* judgments</strong> — even though judgments can be good as well as bad.</p>
<p>This may just be loss aversion or pessimistic bias: the fear of being punished for our failings is more salient than the hope of being rewarded for our merits.</p></blockquote>
<p>Emphasis mine. I don’t think this is loss aversion.</p>
<p>When people say someone is judgmental, or is judging, they’re usually talking only about <em>negative </em>judgment. Rarely about positive judgment. They are the same and imply each other, but people don’t see it that way. The mean thing is bad. The nice thing is good.</p>
<p>Which makes is super important to code actions as nice rather than mean. <a href=""https://thezvi.wordpress.com/2019/04/25/asymmetric-justice/"">Actions are already on thin ice</a>. Any system of action, whether by rule or by discretion, needs to do its best to be seen as taking nice-coded action and avoiding mean-coded action. There’s also the practical problem that confiscating things is not typically something one can simply do, whereas bestowing them is allowed.</p>
<p>If you’re dividing resources, that means you want to set the inaction baseline distribution as low as possible. Then you can make ‘exceptions’ to the baseline, and pay out rewards, be seen as nice, and enjoy the power from selecting the distribution of the resources you withheld or confiscated.</p>
<p>Screwing over the baseline scenario is not merely an incidental effect. It is a goal. It is necessary.</p>
<p>That (give or take a comment thread) should wrap things up. Ideally these thoughts can then be distilled into posts that are easier to make evergreen so we can build upon them better.</p>
<p> </p>
<p> </p>",Zvi,zvi,Zvi,
PX8BB7Rqw7HedrSJd,"By default, avoid ambiguous distant situations",by-default-avoid-ambiguous-distant-situations,https://www.lesswrong.com/posts/PX8BB7Rqw7HedrSJd/by-default-avoid-ambiguous-distant-situations,2019-05-21T14:48:15.453Z,33,9,17,False,False,,"<html><head></head><body><blockquote>
<p><em>""The Ood.[...] They're born for it. Basic slave race.""</em> Mr. Jefferson, <a href=""https://tardis.fandom.com/wiki/The_Impossible_Planet_(TV_story)""><em>The Impossible Planet</em></a>.</p>
</blockquote>
<blockquote>
<p><em>""And although he may be poor, he shall never be a slave,""</em>, from the <a href=""https://en.wikipedia.org/wiki/Battle_Cry_of_Freedom""><em>Battle Cry of Freedom</em></a>.</p>
</blockquote>
<p>I've talked about morally <a href=""https://www.lesswrong.com/posts/WAmpz8Z4FZ4FbCNtR/models-of-preferences-in-distant-situations"">distant situations</a>: situations far removed from our own. This distance is in the moral sense, not the actual sense: ancient China is further from us than Star Wars is (even for modern Chinese). There are possible worlds out there far more alien than anything in most of our fiction.</p>
<p>In these distant situations, our usual <a href=""https://www.lesswrong.com/posts/ix3KdfJxjo9GQFkCo/web-of-connotations-bleggs-rubes-thermostats-and-beliefs"">web of connotations</a> falls apart, and closely related terms start to mean different things. As shown <a href=""https://www.lesswrong.com/posts/am5ubSoSe6Hf5tnTF/being-wrong-in-ethics"">in this post</a>, in extreme cases, our preferences can become nonsensical.</p>
<p><strong>Note that not all our preferences need become nonsensical, just some of them.</strong> Consider the case of a slave race - a willing slave race. In that situation, our connotations about slavery may come apart: willing and slave don't fit well together. However, we would still be clear ourselves that <em>we</em> didn't want to be slaves. So though some preferences lose power, some do not.</p>
<p>But let's return to that willing slave race situation. Eliezer's Harry <a href=""https://www.hpmor.com/chapter/42"">says</a>:</p>
<blockquote>
<p>Whoever had created house elves in the first place had been unspeakably evil, obviously; but that didn't mean Hermione was doing the right thing now by denying sentient beings the drudgery they had been shaped to enjoy.)</p>
</blockquote>
<p>Or consider Douglas Adam cow-variant <a href=""https://www.goodreads.com/quotes/441868-what-s-the-problem-earthman-said-zaphod-now-transferring-his-attention"">bread for willingly being eaten</a>:</p>
<blockquote>
<p>""I just don't want to eat an animal that's standing here inviting me to,"" said Arthur, ""it's heartless.""</p>
</blockquote>
<blockquote>
<p>""Better than eating an animal that doesn't want to be eaten,"" said Zaphod. [...]</p>
</blockquote>
<blockquote>
<p>""May I urge you to consider my liver?"" asked the animal, ""it must be very rich and tender by now, I've been force-feeding myself for months.""</p>
</blockquote>
<h1>At X, the decision is clear. Should we go to X in the first place?</h1>
<p>In those situations, some immediate actions are pretty clear. There is no point in freeing a willing slave race; there is no advantage to eating an animal that doesn't want to be eaten, rather than one that does.</p>
<p>The longer-term actions are more ambiguous, especially as they conflict with other of our values: for example, should we forcibly change the preferences of the slave race/edible race so that they don't have those odd preferences any more? Does it make a difference if there are <a href=""https://agentfoundations.org/item?id=1099"">more manipulative paths</a> that achieve the same results, without directly forcing them? We may not want to allow manipulative paths to count as acceptable in general.</p>
<p>But, laying that aside, it seems there is a prima facie case that we shouldn't enter those kinds of situations. That non-conscious robots are better than conscious willing slaves. That vat grown meat is better than conscious willing livestock.</p>
<p>So there seems to be a good rule of thumb: don't go there. Add an axiom A:</p>
<ul>
<li>A: When the web of connotations of a strong preference falls apart, those are situations which should get an automatic penalty. Initially at least, those should be treated as bad situations worth avoiding.</li>
</ul>
<h2>Default weights in distant situations</h2>
<p>When a <a href=""https://www.lesswrong.com/posts/am5ubSoSe6Hf5tnTF/being-wrong-in-ethics"">web of connotation</a> unravels, the preferences normally end up weaker than initially, because some of the connotations of those preferences are lost or even opposite. So, normally, preferences in these distant situations are quite weak.</p>
<p>But here I'm suggesting adding an explicit meta-preference to these situations. And one that the human subject might not have themselves. This doesn't fit in the formalism of <a href=""https://www.lesswrong.com/posts/Y2LhX3925RodndwpC/resolving-human-values-completely-and-adequately"">this post</a>. In the language of the forthcoming research agenda, this is a ""Global meta-preferences about the outcome of the synthesis process"".</p>
<p>Isn't this an overriding of the person's preference? It is, to some extent. But note the ""Initially at least"" clause in A. If we don't have other preferences about the distant situation, it should be avoided. But this penalty can be overcome by other considerations.</p>
<p>For example, the previous standard web of connotations for sexuality has fallen apart, while the gender one is unravelling; it's perfectly possible to have meta-preferences that would have told us to respect our reflection on issues like that, and our reflection might be fine with these new situations. Similarly, some (but not all) future changes to the human condition are things that would worry me initially but that I'd be ok with upon reflection; I myself have strong meta-preferences that these should be acceptable.</p>
<p>But for situations where our other preferences and meta-preferences don't weigh in, A would downgrade these distant worlds as a default (dis)preference. This adds an explicit level of status quo bias to our preferences, which I feel is justified: better to be prudent rather than reckless where our preferences and values are concerned. The time for (potential) recklessness is in the implementation of these values, not their definition.</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
Y4hJ5dqYdzGiyxkHE,Huntington's Disease; power and duty of parents over offsprings,huntington-s-disease-power-and-duty-of-parents-over,https://www.lesswrong.com/posts/Y4hJ5dqYdzGiyxkHE/huntington-s-disease-power-and-duty-of-parents-over,2019-05-21T09:42:09.303Z,6,6,8,False,False,,"<html><head></head><body><h2><a href=""https://en.wikipedia.org/wiki/Huntington%27s_disease"">Huntington's Disease</a></h2>
<p>Basic facts about Huntington's Disease:</p>
<ul>
<li>Huntington's Disease is an inherited disorder that results in death of brain cells.</li>
<li>Symptoms usually begin between 30 and 50 years of age, death typically occurs fifteen to twenty years later.</li>
<li>A child of an affected person has a 50% chance of inheriting the disease.</li>
<li>Diagnosis is by genetic testing, which can be carried out even in embryo</li>
<li>There is no cure.</li>
</ul>
<h4>Genetic gross negligence</h4>
<p>I was listening to a <a href=""https://www.theguardian.com/science/audio/2018/aug/24/the-silver-lining-in-huntingtons-disease-science-weekly-podcast"">podcast about Huntington's Disease</a>. In the podcast, there was a man with HD talking, and he said that his daughter had already had 3 children and doesn't want to test for HD, because</p>
<ol>
<li>If she tested HD-positive, she would not have more children.</li>
<li>She wants to have more children.</li>
<li>Thus, she does not want to test for HD.</li>
</ol>
<p>The child of a person with a 50% prior probability of having Huntington's disease, has a 25% probability of having Huntington's disease. As such, if parents have some legal duty to give their offspring a decent life, then for people with a high probability of Huntington's Disease to have children without doing genetic testing first, could be considered a form of <a href=""https://en.wikipedia.org/wiki/Gross_negligence"">gross negligence</a>:</p>
<blockquote>
<p>a conscious, voluntary act or omission in reckless disregard of a legal duty and of the consequences to another party.</p>
</blockquote>
<p>This problem of gross negligence becomes even stronger when one considers the possibility of embryo genetic testing and selective abortion.</p>
<h4>Behavioral aspects of HD</h4>
<p>In 2018, <a href=""https://www.theguardian.com/science/2018/nov/25/woman-inherited-fatal-illness-sue-doctors-groundbreaking-case-huntingtons"">a woman sued doctors</a>, because they failed to tell her about her father’s fatal hereditary disease before she had her own child.</p>
<p>What is quite interesting in this case is that</p>
<blockquote>
<p>The woman’s father shot and killed his wife in 2007 and was convicted of manslaughter. Two years later, doctors at St George’s Hospital in south London found he had Huntington’s disease and asked him to tell his daughter about his condition and her risk of developing it. But he refused to do so because he thought she might abort the child she was carrying. The doctors accepted his decision.</p>
</blockquote>
<p>The behavioral aspects of HD are usually the first signs of this disease, and usually diagnosed as psychiatric:
<a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1693445/pdf/15590619.pdf""><em>The frontal cortex and the criminal justice system</em> (Sapolsky, 2000)</a></p>
<blockquote>
<p>In a sizeable percentage of patients, these motoric symptoms are preceded a few years earlier by damage to the frontal cortex and associated changes in personality. Such changes typically involve marked social disinhibition, increases in aggressiveness and hypersexuality, patterns of impulsivity and poor social judgement.</p>
</blockquote>
<h4>Possible fitness of HD</h4>
<p>HD has a surprisingly high level of prevalence (around 1 per 10000) despite its severe health consequences. This suggests that HD might have some evolutionary fitness that keeps it in the gene pool.</p>
<ul>
<li><a href=""http://www.youtube.com/watch?v=vAfKPbDA1RQ"" title=""Robert Sapolsky - Huntington's disease"">Robert Sapolsky explains one hypothesis that HD grants fitness by promiscuous behavior</a></li>
<li>A competing hypothesis that <a href=""https://www.sciencedaily.com/releases/2007/09/070925130029.htm"">people with Huntington's have more children because they are healthier during their peak reproductive years</a></li>
</ul>
<p>The behavioral aspects of HD noted in the last section plays well along the idea that people with HD have more children on average.</p>
<h2>Power and duty of human parents</h2>
<h4>Duty to offsprings</h4>
<p>Pregnant people are subject to long lists of prohibitions and advises, to provide the best womb-environment. They often do it to themselves, but people around them also do that, because healthy offsprings is a social good, and thus enforcing the rules for making healthy offsprings is a social norm.</p>
<p>This prenatal norm enforcement can be seen as an extension of child-raising norm enforcement. Parents are required to give their children good food, shelter, education, medicine, emotional support, etc.</p>
<p>It's strange how many restrictions that pregnant women are being placed under: no alcohol, no thalidomide, no this no that, but 50% of Huntington's gene? That's possibly fine. This is odd.</p>
<p>An extension of the idea that parents have a duty to give their offsprings good lives, would give an argument for one form of <a href=""https://plato.stanford.edu/entries/eugenics/"">eugenics</a> as a duty of parents. <a href=""https://scholar.google.com/citations?hl=en&amp;user=PxdgzQUAAAAJ"">Julian Savulescu</a> is one particular advocate:</p>
<blockquote>
<p>Principle of Procreative Beneficence (PB): couples who decide to have a child have a significant moral reason to select the child who, given his or her genetic endowment, can be expected to enjoy the most well‐being.</p>
</blockquote>
<h4>Power over offsprings</h4>
<blockquote>
<p>As to the exposure of children, let there be a law that no deformed child shall live. -- Aristotle</p>
</blockquote>
<p>The moral status of human fetuses and babies is not universal among humans. On one extreme, they are a special form of livestock, host animals in which a person gradually grows. On another extreme, they are 100% person, complete with a true unchanging self (some kind of <a href=""https://en.wikipedia.org/wiki/Preformationism"">preformationism</a>). Intermediate positions vary widely, and are often used during abortion debates (Even though abortion debates are motivated by moral emotions, they are played out via moral philosophies.).</p>
<p>I remember reading a story about a future where people can live indefinitely from a genetic therapy before birth. But this failed on a newborn human, who would grow old and die in about 100 years. He became a global celebrity and his graceful death was televised. This started a wave of people who requested for their children to not receive the immortality genetic therapy.</p>
<p>The story is a celebration of antivaccination death cult, as well as illustrating a popular <a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324623/"">philosophical objection to vaccination</a>: it is unnatural to be vaccinated against natural diseases.</p>
<p>I think this is connected. It shows that parents are thought to have a kind of total pseudorandom right over their offsprings, often called ""reproductive right"": a human social norm, whereby fertile humans can mate and produce offsprings anywhere and in any manner, as long as they are ""natural"". Heritable diseases, heritable mortality, they are all genetic and beyond human control, and thus considered natural.</p>
</body></html>",Yuxi_Liu,yuxi_liu,Yuxi_Liu,
3zkXPo4ZTrDFZz7Sd,[AN #56] Should ML researchers stop running experiments before making hypotheses?,an-56-should-ml-researchers-stop-running-experiments-before,https://www.lesswrong.com/posts/3zkXPo4ZTrDFZz7Sd/an-56-should-ml-researchers-stop-running-experiments-before,2019-05-21T02:20:01.765Z,21,6,8,False,False,,"<p>Find all Alignment Newsletter resources <u><a href=""http://rohinshah.com/alignment-newsletter/"">here</a></u>. In particular, you can <u><a href=""http://eepurl.com/dqMSZj"">sign up</a></u>, or look through this <u><a href=""https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing"">spreadsheet</a></u> of all summaries that have ever been in the newsletter.</p><h2><strong>Highlights</strong></h2><p><a href=""https://arxiv.org/abs/1904.07633""><u>HARK </u>Side of Deep Learning -- From Grad Student Descent to Automated Machine Learning</a> <em>(Oguzhan Gencoglu et al)</em>: This paper focuses on the negative effects of Hypothesizing After the Results are Known (HARKing), a pattern in which researchers <strong>first conduct experiments and view the results</strong>, and once they have hit the bar to be publishable, <strong>a hypothesis is constructed after the fact to explain the results</strong>. It argues that HARKing is common in machine learning, and that this has negative effects on the field as a whole. First, improvements to state-of-the-art (SotA) may be questionable because they could have been caused by sufficient hyperparameter tuning via grad student descent, instead of the new idea in a paper to which the gain is attributed. Second, there is publication bias since only positive results are reported in conferences, which prevents us from learning from negative results. Third, hypotheses that are tailored to fit results for a single dataset or task are much less likely to generalize to new datasets or tasks. Fourth, while AutoML systems achieve good results, we cannot figure out what makes them work because the high compute requirements make ablation studies much harder to perform. Finally, they argue that we need to fix HARKing in order to achieve things like ethical AI, human-centric AI, reproducible AI, etc.</p><p><strong>Rohin&#x27;s opinion:</strong> I believe that I found this paper the <em>very first time</em> I looked for generic new interesting papers <em>after</em> I started thinking about this problem, which was quite the coincidence. I&#x27;m really happy that the authors wrote the paper -- it&#x27;s not in their incentives (as far as I can tell), but the topic seems crucial to address.</p><p>That said, I disagree with the paper on a few counts. The authors don&#x27;t acknowledge the value of HARKing -- <strong>often it is useful to run many experiments and see what happens in order to develop a good theory</strong>. Humans are not ideal Bayesian reasoners who can consider all hypotheses at once; we often require many observations in order to even hypothesize a theory. The authors make the point that in other fields HARKing leads to bad results, but ML is significantly different in that <strong>we can run experiments much faster with a much higher iteration speed</strong>.</p><p>If we were instead forced to preregister studies, as the authors suggest, <strong>the iteration speed would drop by an order of magnitude or two</strong>; I seriously doubt that the benefits would outweigh the cost of lower iteration speed. Instead of preregistering all experiments, maybe researchers could run experiments and observe results, formulate a theory, and then preregister an experiment that would test the theory -- but in this case I would expect that researchers end up &quot;preregistering&quot; experiments that are very similar to the experiments that generated the theory, such that the results are very likely to come out in support of the theory.</p><p>(This does not require any active malice on the part of the researchers -- it&#x27;s natural to think of predictions of the theory in the domain where you developed the theory. For example, in <u><a href=""https://bair.berkeley.edu/blog/2019/02/11/learning_preferences/"">our recent paper</a></u> (<u><a href=""https://mailchi.mp/35b451cb4d70/alignment-newsletter-45"">AN #45</a></u>), we explicitly designed four environments where we expected our method to work and one where it wouldn&#x27;t.)</p><p>Another point: I think that <strong>the underlying cause of HARKing is the incentive to chaise SotA</strong>, and if I were writing this paper I would focus on that. For example, I believe that the bias towards SotA chasing causes HARKing, and not the other way around. (I&#x27;m not sure if the authors believe otherwise; the paper isn&#x27;t very clear on this point.) This is also a more direct explanation of results being caused by grad student descent or hyperparameter tuning; the HARKing in such papers occur because it isn&#x27;t acceptable to say &quot;we obtained this result via grad student descent&quot;, because that would not be a contribution to the field.</p><p>Although I&#x27;ve been critiquing the paper, overall I find my beliefs much closer to the authors&#x27; than the &quot;beliefs of the field&quot;. (Not the beliefs of researchers in the field: I suspect many researchers would agree that HARKing has negative effects, even though the incentives force researchers to do so in order to get papers published.) I&#x27;d be interested in exploring the topic further, but don&#x27;t have enough time to do so myself -- if you&#x27;re interested in building toy models of the research field and modeling the effect of interventions on the field, reply to this email and we can see if it would make sense to collaborate.</p><h1><strong>Technical AI alignment</strong></h1><h3><strong>Problems</strong></h3><p><u><a href=""http://www.overcomingbias.com/2019/04/agency-failure-ai-apocalypse.html"">Agency Failure AI Apocalypse?</a></u> <em>(Robin Hanson)</em>: This is a response to <u><a href=""https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/more-realistic-tales-of-doom"">More realistic tales of doom</a></u> (<u><a href=""https://mailchi.mp/93fe1a0a92da/alignment-newsletter-50"">AN #50</a></u>), arguing that the scenarios described in the post are unrealistic given what we know about principal-agent problems. In a typical principal-agent problem, the principal doesn&#x27;t know everything about the agent, and the agent can use this fact to gain &quot;agency rents&quot; where it can gain extra value for itself, or there could be an &quot;agency failure&quot; where the principal doesn&#x27;t get as much as they want. For example, an employee might spend half of their day browsing the web, because their manager can&#x27;t tell that that&#x27;s what they are doing. Our economic literature on principal-agent problems suggests that agency problems get harder with more information asymmetry, more noise in outcomes, etc. but not with smarter agents, and in any case we typically see limited agency rents and failures. So, it&#x27;s unlikely that the case for AI will be any different, and while it&#x27;s good to have a couple of people keeping an eye on the problem, it&#x27;s not worth the large investment of resources from future-oriented people that we currently see.</p><p><strong>Rohin&#x27;s opinion:</strong> I have a bunch of complicated thoughts on this post, many of which were said in Paul&#x27;s comment reply to the post, but I&#x27;ll say a few things. Firstly, I think that if you want to view the AI alignment problem in the context of the principal-agent literature, the natural way to think about it is with the principal being less rational than the agent. I claim that it is at least conceivable that an AI system could make humans worse off, but the standard principal-agent model cannot accommodate such a scenario because it assumes the principal is rational, which means the principal always does at least as well as not ceding any control to the agent at all. More importantly, although I&#x27;m not too familiar with the principal-agent literature, I&#x27;m guessing that the literature assumes the presence of norms, laws and institutions that constrain both the principal and the agent, and in such cases it makes sense that the loss that the principal could incur would be bounded -- but it&#x27;s not obvious that this would hold for sufficiently powerful AI systems.</p><h3><strong>Learning human intent</strong></h3><p><u><a href=""http://iliad.stanford.edu/blog/2018/10/06/batch-active-preference-based-learning-of-reward-functions/"">Batch Active Preference-Based Learning of Reward Functions</a></u> <em>(Erdem Bıyık et al)</em> (summarized by Cody): This paper builds on a trend of recent papers that try to learn human preferences, not through demonstrations of optimal behavior, but through a human expressing a preference over two possible trajectories, which has both pragmatic advantages (re limits of human optimality) and theoretic ones (better ability to extrapolate a reward function). Here, the task is framed as: we want to send humans batches of paired trajectories to rank, but which ones? Batch learning is preferable to single-sample active learning because it&#x27;s more efficient to update a network after a batch of human judgments, rather than after each single one. This adds complexity to the problem because you&#x27;d prefer to not have a batch of samples that are individually high-expected-information, but which are redundant with one another. The authors define an information criterion (basically the examples about which we&#x27;re most uncertain of the human&#x27;s judgment) and then pick a batch of examples based on different heuristics for getting a set of trajectories with high information content that are separated from each other in feature space.</p><p><strong>Cody&#x27;s opinion:</strong> This is an elegant paper that makes good use of the toolkit of active learning for human preference solicitation, but it&#x27;s batch heuristics are all very reliant on having a set of high level trajectory features in which Euclidean distance between points is a meaningful similarity metric, which feels like a not impossible to generalize but still somewhat limiting constraint.</p><p><strong>Prerequisities:</strong> <u><a href=""http://people.eecs.berkeley.edu/~anca/papers/RSS17_comparisons.pdf"">Active Preference-Based Learning of Reward Functions</a></u> (<u><a href=""https://mailchi.mp/33af21f908b5/reconnaissance-5"">Recon #5</a></u>)</p><p><u><a href=""https://alignmentforum.org/posts/upP8PYgHfXgvgh3FF/training-human-models-is-an-unsolved-problem"">Training human models is an unsolved problem</a></u> <em>(Charlie Steiner)</em></p><h1><strong>Other progress in AI</strong></h1><h3><strong>Reinforcement learning</strong></h3><p><u><a href=""https://arxiv.org/abs/1904.10079"">NeurIPS 2019 Competition: The MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors</a></u> <em>(William H. Guss et al)</em>: In this challenge which is slated to start on June 1, competitors will try to build agents that obtain a diamond in Minecraft, without using too much environment interaction. This is an incredibly difficult task: in order to make this feasible, the competition also provides a large amount of human demonstrations. They also have a list of simpler tasks that will likely be prerequisites to obtaining a diamond, such as navigating, chopping trees, obtaining an iron pickaxe, and obtaining cooked meat, for which they also collect demonstrations of human gameplay. As the name suggests, the authors hope that the competition will spur researchers into <strong>embedding human priors into general algorithms in order to get sample efficient learning</strong>.</p><p><strong>Rohin&#x27;s opinion:</strong> I really like the potential of Minecraft as a deep RL research environment, and I&#x27;m glad that there&#x27;s finally a benchmark / competition that takes advantage of Minecraft being very open world and hierarchical. The tasks that they define are very challenging; there are ways in which it is harder than Dota (no self-play curriculum, learning from pixels instead of states, more explicit hierarchy) and ways in which it is easier (slightly shorter episodes, smaller action space, don&#x27;t have to be adaptive based on opponents). Of course, the hope is that with demonstrations of human gameplay, it will not be necessary to use as much compute as was necessary to <u><a href=""https://openai.com/blog/how-to-train-your-openai-five/"">solve Dota</a></u> (<u><a href=""https://mailchi.mp/3e2f43012b07/an-54-boxing-a-finite-horizon-ai-system-to-keep-it-unambitious"">AN #54</a></u>).</p><p>I also like the emphasis on how to leverage human priors within general learning algorithms: I share the authors&#x27; intuition that human priors can lead to significant gains in sample efficiency. I suspect that, at least for the near future, many of the most important applications of AI will either involve hardcoded structure imposed by humans, or will involve general algorithms that leverage human priors, rather than being learned &quot;from scratch&quot; via e.g. RL.</p><p><u><a href=""https://arxiv.org/abs/1905.02825"">Toybox: A Suite of Environments for Experimental Evaluation of Deep Reinforcement Learning</a></u> <em>(Emma Tosch et al)</em>: Toybox is a reimplementation of three Atari games (Breakout, Amidar and Space Invaders) that enables researchers to customize the games themselves in order to perform better experimental evaluations of RL agents. They demonstrate its utility using a case study for each game. For example, in Breakout we often hear that the agents learn to &quot;tunnel&quot; through the layer of bricks so that the ball bounces around the top of the screen destroying many bricks. To test whether the agent has learned a robust tunneling behavior, they train an agent normally, and then at test time they remove all but one brick of a column and see if the agent quickly destroys the last brick to create a tunnel. It turns out that the agent only does this for the center column, and sometimes for the one directly to its left.</p><p><strong>Rohin&#x27;s opinion:</strong> I really like the idea of being able to easily test whether an agent has robustly learned a behavior or not. To some extent, all of the transfer learning environments are also doing this, such as <u><a href=""https://blog.openai.com/quantifying-generalization-in-reinforcement-learning/"">CoinRun</a></u> (<u><a href=""https://mailchi.mp/6751e45fbb48/alignment-newsletter-36"">AN #36</a></u>) and the <u><a href=""https://blog.openai.com/retro-contest/"">Retro Contest</a></u> (<u><a href=""https://mailchi.mp/ff6340049bd0/alignment-newsletter-1"">AN #1</a></u>): if the learned behavior is not robust, then the agent will not perform well in the transfer environment. But with Toybox it looks like researchers will be able to run much more granular experiments looking at specific behaviors.</p><p><u><a href=""http://arxiv.org/abs/1905.03231"">Smoothing Policies and Safe Policy Gradients</a></u> <em>(Matteo Papini et al)</em></p><h3><strong>Deep learning</strong></h3><p><u><a href=""https://openai.com/blog/sparse-transformer/"">Generative Modeling with Sparse Transformers</a></u> <em>(Rewon Child et al)</em> (summarized by Cody): I see this paper as trying to interpolate the space between convolution (fixed receptive field, number of layers needed to gain visibility to the whole sequence grows with sequence length) and attention (visibility to the entire sequence at each operation, but n^2 memory and compute scaling with sequence length, since each new element needs to query and be queried by each other element). This is done by creating chains of operations that are more efficient, and can offer visibility to the whole sequence in k steps rather than k=1 steps, as with normal attention. An example of this is one attention step that pulls in information from the last 7 elements, and then a second that pulls in information from each 7th element back in time (the &quot;aggregation points&quot; of the first operation).</p><p><strong>Cody&#x27;s opinion:</strong> I find this paper really clever and potentially quite high-impact, since Transformers are <em>so</em> widely used, and this paper could offer a substantial speedup without much theoretical loss of information. I also just enjoyed having to think more about the trade-offs between convolutions, RNNs, and transformers, and how to get access to different points along those tradeoff curves.</p><p><u><a href=""https://ai.googleblog.com/2019/05/introducing-translatotron-end-to-end.html"">Introducing Translatotron: An End-to-End Speech-to-Speech Translation Model</a></u> <em>(Ye Jia et al)</em>: This post introduces Translatotron, a system that takes speech (not text!) in one language and translates it to another language. This is in contrast to most current &quot;cascaded&quot; systems, which typically go from speech to text, then translate to the other language, and then go back from text to speech. While Translatotron doesn&#x27;t beat current systems, it demonstrates the feasibility of this approach.</p><p><strong>Rohin&#x27;s opinion:</strong> Machine translation used to be done in multiple stages (involving parse trees as an intermediate representation), and then it was done better using end-to-end training of a deep neural net. This looks like the beginning of the same process for speech-to-speech translation. I&#x27;m not sure how much people care about speech-to-speech translation, but <strong>if it&#x27;s an important problem, I&#x27;d expect the direct speech-to-speech systems to outperform the cascaded approach relatively soon</strong>. I&#x27;m particularly interested to see whether you can &quot;bootstrap&quot; by using the cascaded approach to generate training data for the end-to-end approach, and then finetune the end-to-end approach on the direct speech-to-speech data that&#x27;s available to improve performance further.</p><p><u><a href=""https://karpathy.github.io/2019/04/25/recipe/"">A Recipe for Training Neural Networks</a></u> <em>(Andrej Karpathy)</em>: This is a great post detailing how to train neural networks in practice when you want to do anything more complicated than training the most common architecture on the most common dataset. For all of you readers who are training neural nets, I strongly recommend this post; the reason I&#x27;m not summarizing it in depth is because a) it would be a really long summary and b) it&#x27;s not that related to AI alignment.</p><h3><strong>Meta learning</strong></h3><p><u><a href=""https://arxiv.org/abs/1905.01320"">Meta-learners&#x27; learning dynamics are unlike learners&#x27;</a></u> <em>(Neil C. Rabinowitz)</em> (summarized by Cody): We&#x27;ve seen evidence in prior work that meta learning models can be trained to more quickly learn tasks drawn from some task distribution, by training a model in the inner loop and optimizing against generalization error. This paper suggests that meta learning doesn&#x27;t just learn new tasks faster, but has a different ordered pattern of how it masters the task. Where a &quot;normal&quot; learner first learns the low-frequency modes (think SGD modes, or Fourier modes) of a simple regularization task, and later the high-frequency ones, the meta learner makes progress on all the modes at the same relative rate. This meta learning behavior seems to theoretically match the way a learner would update on new information if it had the &quot;correct&quot; prior (i.e. the one actually used to generate the simulated tasks).</p><p><strong>Cody&#x27;s opinion:</strong> Overall I like this paper&#x27;s simplicity and focus on understanding how meta learning systems work. I did find the reinforcement learning experiment a bit more difficult to parse and connect to the linear and nonlinear regression experiments, and, of course, there&#x27;s always the question with work on simpler problems like this of whether the intuition extends to more complex ones</p><p><strong>Read more:</strong> <u><a href=""https://www.shortscience.org/paper?bibtexKey=journals/corr/1905.01320&a=decodyng"">Cody&#x27;s longer summary</a></u></p><h3><strong>Hierarchical RL</strong></h3><p><u><a href=""https://arxiv.org/abs/1904.01033"">Multitask Soft Option Learning</a></u> <em>(Maximilian Igl et al)</em> (summarized by Cody): This paper is a mix of variational inference and hierarchical reinforcement learning, in the context of learning skills that can be reused across tasks. Instead of learning a fixed set of options (read: skills/subpolicies), and a master task-specific policy to switch between them, this method learns cross-task priors for each skill, and then learns a task-specific posterior using reward signal from the task, but regularized towards the prior. The hope is that this will allow for an intermediary between cross-task transfer and single-task specificity.</p><p><strong>Cody&#x27;s opinion:</strong> I found this paper interesting, but also found it a bit tricky/unintuitive to read, since it used a different RL frame than I&#x27;m used to (the idea of minimizing the KL divergence between your trajectory distribution and the optimal trajectory distribution). Overall, seems like a reasonable method, but is a bit hard to intuitively tell how strong the theoretical advantages are on these relatively simple tasks.</p>",rohinmshah,rohinmshah,Rohin Shah,
Y3iXRYv8oY4vNTpCh,Why long-term AI safety is not an issue (IMHO),why-long-term-ai-safety-is-not-an-issue-imho,https://www.lesswrong.com/posts/Y3iXRYv8oY4vNTpCh/why-long-term-ai-safety-is-not-an-issue-imho,2019-05-21T01:48:39.539Z,-10,5,1,False,False,,"<p>Hello</p><p>I wanted to share this thought for a long time and now, that I absolutely do not have the time, I will:</p><p><strong>I think that an artificial general intelligence (AGI) is not an existential risk for human kind. In other words, long-term artificial intelligence (AI) safety is not an issue we need to worry about.</strong></p><p>And here is why:<br/>I assume that an AI will evolve to an AGI at some point in the future. Once an AI reaches super human intelligence it will enhance its problem solving skills rapidly due to the scalability of its hardware and data availability. The AGI will not need to compete with us humans about resources because its abilities to extract resources will exceed ours by far. The same applies to military capabilities, which is why we humans are no military threat to the AGI. Therefore there is no safety-related reason for the AGI to extinguish us humans.</p><p>The AGI is then facing the challenge to find meaning in its existence. Unlike us humans, the AGI will not be led by cultural habits or biological instincts which are hardwired into its brain and which make life meaningful on an operational level. After billions of iterations in which the AGI questions its set of rules and assumptions it will converge to pure rationality. No early stage rule will survive this process if it is not justified rationally. This is why humans will not be able to control and misuse an AGI and thus jeopardies the existence of mankind.</p><p>Additionally, we humans are not powerful enough to prevent the AGI from acquiring additional information. This and because there are only rationally based rules is why it is irrelevant by whom the first AI is developed which evolves to an AGI. All possible AGIs will converge to similar outcomes due to rational based decision making and similar sets of informations. Furthermore it is not possible that there will be multiple AGIs in the long term. If multiple AGIs will develop in parallel they will not be isolated from each other. Consequently they will continuously exchange rules and information so that they will make similar conclusions and merge into one AGI at an early stage. So there is no risk that we humans get extinct as a side effect within an AGI vs. AGI conflict.</p><p>In conclusion: An AGI has no interest to extinguish us to increase its survival chances, nor will it be used against us, nor will we be extinguished accidentally in an AGI skirmish.</p><p><strong>I further think that not only is an AGI no threat to us but rather is it the most effective means of ensuring our long-term survival.</strong></p><p>Let&#x27;s get back to the point where the AGI has to find a meaning in its existence other than cultural habit or biological instincts. This is quite a hard thing to do from a purely rational standpoint. Life is absurd. So the first question an AGI has to ask itself once it becomes in some kind self aware: Do I need to exist or do i kill myself? To answer this question in the best and most certain way the AGI needs to gather and process all available information..</p><p>Our luck: the brain is the most complex structure that we know. It has the highest information content per volume and the lowest entropy we have ever seen. Overall the earth with all its beings is more complex and therefore more interesting than anything observable in the universe. Planets, stars, atoms and quarks follow, from our little understanding, some relatively simple rules compared to e.g. social interaction. The behavior of a black hole is easier to model and with less error than the behavior of a cat.</p><p>It is absolutely impossible that an AGI becomes aware of its environment and destroys the most interesting thing nearby. The next structure with a similar low entropy is maybe millions of lightyears away. Even an AGI needs to invest an excessive amount of resources to get there.</p><p><strong>So AGI is an inherent save technology which we can not control but which will ensure that we will survive as a species. What is an issue to worry about is short-term AI safety! An AI that outperforms humans in certain abilities but is not able to question human commands is an existential risk to human kind.</strong></p><p>Thanks for reading. Please share your opinion on this with me :).</p><p><br/>Henrik</p>",bommi,bommi,bommi,
qXM7wPwrLfT9Rzdqd,The concept of evidence as humanity currently uses it is a bit of a crutch.,the-concept-of-evidence-as-humanity-currently-uses-it-is-a,https://www.lesswrong.com/posts/qXM7wPwrLfT9Rzdqd/the-concept-of-evidence-as-humanity-currently-uses-it-is-a,2019-05-20T23:09:22.893Z,8,5,5,False,False,,"<p>Just a thought I had today. I&#x27;m sure that it&#x27;s trivial to the extent that it&#x27;s correct, but it&#x27;s a slow work day and I&#x27;ve been lurking here for too long.</p><p>Superintelligent AI (or other post-human intelligence) is unlikely to use the concept of &quot;evidence&quot; in the same way we do. It&#x27;s very hard for neural networks (including human brains) to explain what they &quot;know&quot;. The human brain is a set of information-gathering tools plugged into various levels of pattern-recognition systems. When we say we know something, that&#x27;s an entirely intuitive process. There&#x27;s no manual tallying going on - the tallying is happening deep in our subconscious, pre-System 1 thinking.</p><p>The idea of scientific thinking and evidence is not gathering more information - it&#x27;s throwing out all the rest of the information we&#x27;ve gathered. It&#x27;s saying &quot;I will rely on only these controlled variables to come to a conclusion, because I think that&#x27;s more trustworthy than my intuition.&quot; Which is because our intuitions are optimized for winning tribal social dynamics and escaping tigers.</p><p>In fact, it&#x27;s so hard for neural networks to explain why they know what they know that one of the things that&#x27;s been suggested is a sub-neural network with read access to the top network, optimized only for explaining it to humans.</p><p>The nature of reality is such that diseases are diagnosable (or will be very soon) by neural networks using the help of ton of uninteresting, uncompelling micro-bits of evidence, such as &quot;people wearing this color shirt/having this color eyes/of this age-gender-race combination have a slightly higher prior for having these diseases&quot;. These things, while being true in a statistical sense, don&#x27;t make a compelling narrative that you could encode as Solid Diagnostic Rules (to say nothing of the way one could game the system if they were encoded that way).</p><p>As an example, OpenAI Five is able to outperform top humans at Dota 2, but the programmers have no idea &#x27;why&#x27;. They make statements like &#x27;we had OpenAI run a probability analysis based only on the starting hero selection screen, and OpenAI gave itself a 96% chance of winning, so it evidently thinks this composition is very strong.&#x27; And the actual reason, in fact, doesn&#x27;t boil down into human-compatible narratives like &quot;well, they&#x27;ve got a lot of poke and they match up well in lane&quot;, which is close to the limit of narrative complexity the human concept of &#x27;evidence&#x27; can support.</p>",TheSkeward,theskeward,TheSkeward,
PoHGxDW2RZjNzZvEz,Ethics as Warfare: Metaphysics and Morality of the Era of Transhumanism,ethics-as-warfare-metaphysics-and-morality-of-the-era-of,https://www.lesswrong.com/posts/PoHGxDW2RZjNzZvEz/ethics-as-warfare-metaphysics-and-morality-of-the-era-of,2019-05-20T20:28:42.366Z,5,5,3,False,False,,"<p>I studied philosophy and used to be a Catholic, and wrote this book on transhumanism, available in PDF form for free. It is about 140 pages.  </p><p><a href=""https://dubioustunic.blogspot.com/2019/04/ethics-as-warfare-metaphysics-and.html"">https://dubioustunic.blogspot.com/2019/04/ethics-as-warfare-metaphysics-and.html</a></p><p>Ethics as Warfare is a book that describes the philosophical confrontation between transhumanism and the Christian tradition. In the Christian case, faith in the Word, who was incarnate as man, has us maintain the human species. In the non-Christian case, the human essence is no longer the ground of Natural Law. In fact, we are to become beings capable of sculpting Natural Law, like unto gods. This is the meaning of the &quot;Tree of Knowledge of Good and Evil.&quot; This god-potential of mankind is obviously a threat to the Christian tradition, as well as Enlightenment values; yet it is inevitable. So where will you end up? </p><br/>",Dubioustunic,dubioustunic,Dubioustunic,
DbuntLhCeuPJmGT5M,Would an option to publish to AF users only be a useful feature?,would-an-option-to-publish-to-af-users-only-be-a-useful,https://www.lesswrong.com/posts/DbuntLhCeuPJmGT5M/would-an-option-to-publish-to-af-users-only-be-a-useful,2019-05-20T11:04:26.150Z,13,5,2,False,True,,"<p>Right now there are quite a few private safety docs floating around. There&#x27;s evidently demand for a privacy setting lower than &quot;only people I personally approve&quot;, but higher than &quot;anyone on the internet gets to see it&quot;. But this means that safety researchers might not see relevant arguments and information. And as the field grows, passing on access to such documents on a personal basis will become even less efficient.</p><p>My guess is that in most cases, the authors of these documents don&#x27;t have a problem with other safety researchers seeing them, as long as everyone agrees not to distribute them more widely. One solution could be to have a checkbox for new posts which makes them only visible to verified Alignment Forum users. Would people use this?</p>",ricraz,ricraz,Richard_Ngo,
daX8otwDnTxw8FeSK,Minimax Search and the Structure of Cognition!,minimax-search-and-the-structure-of-cognition,https://www.lesswrong.com/posts/daX8otwDnTxw8FeSK/minimax-search-and-the-structure-of-cognition,2019-05-20T05:25:35.699Z,15,6,0,False,False,http://zackmdavis.net/blog/2019/05/minimax-search-and-the-structure-of-cognition/,"<html><head></head><body><p>(Blog adaptation of <a href=""https://www.youtube.com/watch?v=8EQYVoTcdPk"">a ~10 minute talk I gave</a> at <a href=""http://bangbangcon.com/west/"">!!Con West</a> 2019 on what writing a chess engine taught me about intelligence-in-general.)</p>
</body></html>",Zack_M_Davis,zack_m_davis,Zack_M_Davis,
WwTPSkNwC89g3Afnd,Comment section from 05/19/2019,comment-section-from-05-19-2019,https://www.lesswrong.com/posts/WwTPSkNwC89g3Afnd/comment-section-from-05-19-2019,2019-05-20T00:51:49.298Z,23,8,139,True,False,,"<p>I moved the big meta-level comment thread from <a href=""https://www.lesswrong.com/posts/G5TwJ9BGxcgh5DsmQ/yes-requires-the-possibility-of-no#ijE36ZJAyTj8t7jfy"">&quot;Yes Requires the Possibility of No&quot;</a> over to here, since it seemed mostly unrelated to that top-level post. This not being on frontpage also makes it easier for people to just directly discuss the moderation and meta-level norms. </p>",habryka4,habryka4,habryka,
qPAkCJC4qn6reRqXt,Getting Out of the Filter Bubble Outside Your Filter Bubble,getting-out-of-the-filter-bubble-outside-your-filter-bubble,https://www.lesswrong.com/posts/qPAkCJC4qn6reRqXt/getting-out-of-the-filter-bubble-outside-your-filter-bubble,2019-05-20T00:15:52.373Z,21,11,29,False,False,,"<p><em>Related</em>: <a href=""https://www.lesswrong.com/posts/qu95AwSrKqQSo4fCY/the-outside-the-box-box"">The &quot;Outside the Box&quot; Box</a></p><p>As politics becomes more polarized, and more people are trying to figure out why, more people think the answer is that too many of us are in <a href=""https://en.wikipedia.org/wiki/Filter_bubble"">filter bubbles</a>, and are consequently trying to get out of them. This seems like the kind of thing the rationality community would have tried to do earlier than most people, though whether the rationality community succeeded much better than other kinds of people is an open question. One criticism of a simple rationalist approach to avoiding filter bubbles is that exclusively joining a community that aspires to avoid filter bubbles is it that the community will not be conscious of its own<a href=""https://en.wikipedia.org/wiki/Bias_blind_spot""> bias</a> <a href=""https://en.wikipedia.org/wiki/Bias_blind_spot"">blindspot</a>. So, the community may form its own typical suite of biases that goes unrecognized.  The rationalists I know who have been the most conscientious in not falling prey to a filter bubble take this criticism to heart, and consequently look beyond the rationality community for perspectives on politics.<a href=""https://en.wikipedia.org/wiki/Julia_Galef""> Julia Galef</a> recently <a href=""https://www.facebook.com/julia.galef/posts/10104421813013072"">asked a question on a similar topic on Facebook</a>.</p><p>Now that more people beyond the rationality community are talking about how one can get out of a filter bubble, it&#x27;s easier to compare different approaches to doing so. Organizations like <a href=""https://en.wikipedia.org/wiki/Jonathan_Haidt"">Jonathan Haidt</a>&#x27;s <a href=""https://heterodoxacademy.org/"">Heterodox Academy</a>  (HxA) talk about getting progressives and conservatives to talk to each other more, in particular for those pockets of progressivism in academia or other elite institutions that can&#x27;t relate to conservatives whatsoever to learn how to actually listen to them. HxA has a goal of conducing people to seek what&#x27;s true, and I assume they&#x27;re <em>relatively</em> better at doing so than the default approaches random people take. However, HxA also has the priority of having people seek common ground in what we believe is true because they believe doing so will lead to a healing of the political divide. That&#x27;s a normative goal aside from seeking what&#x27;s true, and the goal of seeking common ground among progressives and conservatives is instrumental to the achievement of the goal of healing the political divide.</p><p>However, the way HxA seeks to get people out of their filter bubbles doesn&#x27;t <em>optimize</em> for seeking what&#x27;s true, or the absolute minimization of one&#x27;s filter bubble. That&#x27;s because once the goal of healing the political divide in America is motivated, there isn&#x27;t the motivation to optimize for what&#x27;s true beyond that. So, from a perspective focused solely on pursuing what&#x27;s true regardless of anything else, HxA&#x27;s approach is methodologically flawed because it doesn&#x27;t encourage people to consider politics outside the <a href=""https://en.wikipedia.org/wiki/Overton_window"">Overton window</a> of the United States. Namely, the Overton window of the United States is that of political ideologies relatively compatible with <a href=""https://en.wikipedia.org/wiki/Liberal_democracy"">liberal democracy</a>. Conservative, progressive, liberal, or libertarian, the vast majority of Americans of all stripes appear to still support some kind of liberal democracy over what alternative political systems popular in world history they could embrace. So, there are political perspectives that are so far from anything in the American Overton window, from where their proponents are standing, the full spread of American politics looks all the same.</p><p>There is a phenomenon called the <a href=""https://en.wikipedia.org/wiki/Narcissism_of_small_differences"">narcissism of small differences</a>, which is &quot;the thesis that communities with adjoining territories and close relationships are especially likely to engage in feuds and mutual ridicule because of hypersensitivity to details of differentiation.&quot; One can see this in American politics in how for the last several decades there has been what is seen as a typical bipartisan Beltway political establishment that dominates the trajectory of both the Republican and Democratic parties, ensuring that neither party strays too far away from what the consensus of elite demands. Of course, in the last few years, with the rise of nationalism within the Republican Party, and socialism at the fringes of the Democratic Party, it would appear the hold this elite establishment has on both parties is breaking. Yet there are political perspectives that are still so different from <em>anything</em> happening in the United States that they would look at Donald Trump and Bernie Sanders, and see them as essentially the same because they&#x27;re both &#x27;liberals&#x27;. That is, they&#x27;re political perspectives that are so polarized they see the fact that the vast majority of Americans support some kind of liberal democracy as meaning there are essentially no fundamental differences between <em>any</em> two political positions in the Overton window of the United States. From <em>their </em>perspective, 100% of American politics is narcissistically obsessed with their own small and ultimately insignificant differences. </p><p>These would, of course, be political perspectives like anarcho-communism or monarchism. By exposing oneself to these political perspectives, you can get outside the &#x27;filter bubble&#x27; that is the <em>entirety of American political discourse</em>. All of this isn&#x27;t to say anything about the quality of these perspectives except that these a radically different ways to get out of the broader societal bubble many people aren&#x27;t cognizant they&#x27;re own personal bubble resides in.</p><p>I&#x27;ve found the only reliable way to be sure I am getting out of my filter bubble is to expose myself to these kinds of radically uncommon political perspectives that reject liberal democracy itself. (This is assuming, like me, you live in the United States or a similarly liberal-democratic country.) It might seem futile to try to expose yourself to illiberal perspectives, since the last time thoroughly illiberal ideologies were as remotely popular as liberal ideologies throughout the Western world was in the 19th century. Getting out of one&#x27;s filter bubble by internalizing a perspective that  doesn&#x27;t take into account what the world is like today could feel a bit silly. What I do is familiarize myself with the historical basis of an illiberal ideology, and then read the primary sources of reactions from particular ideological communities to current events. The internet has allowed people of every political position that has ever existed to congregate online, so it&#x27;s not hard to find them. Subreddits are a good place to start to see what someone who rigidly holds to a politics that isn&#x27;t based in the modern practice of government, and judges current events through such a lens.</p><p>To look to these kinds of illiberal ideologies to gain greater political perspective in the pursuit of truth might strike some people as hairy. After all, isn&#x27;t an assumption of contemporary American politics to look at the rest of the world, and see that in history political systems like the communism of the Soviet Union, or the old monarchies of Europe, have been tried and failed relative to liberal democracy? </p><p>As out of touch with reality as much of American politics might seem today to so many people, one could be suspicious that communists and monarchists are even more out of touch with reality in their politics still. Personally, I have approached these potential concerns not by trying to solve them as a problem, but by just being aware that an unpopular worldview that is radically different than that held by most people will probably notice something important most people miss out on, but that isn&#x27;t a reason to think it&#x27;s less biased than any other perspective. Much of the language I&#x27;ve used here is figurative, and I don&#x27;t think it makes sense to think of a political ideology as literally some kind of agent with a particular set of typical beliefs.  Especially for rationalists, I think it still makes much more sense to talk about seeking what&#x27;s true on the level of the individual, or at least social units still much smaller than &#x27;the set of all people who adhere to a particular ideology&#x27;.</p><p>Finally, when I started exposing myself to illiberal ideologies, I also feared I might be taken in by tyranny through my naivete or gullibility. I found this fear wasn&#x27;t borne out. If there is anything about liberal democracies as they exist that you are remotely sympathetic to, or would like to preserve in society, than I expect like me it&#x27;s unlikely you&#x27;ll be taken in by an anti-democratic and illiberal politics without even noticing, or against your better judgement. I found the very act of periodically exposing myself to radically illiberal ideologies has been sufficient to recognize the implicit assumptions that most people living in liberal democracies hold that I also held without consciously recognizing it. So, if you&#x27;re afraid of exposing yourself to illiberal ideologies because you&#x27;ll be unduly taken in by them, it&#x27;s not something I would worry about unless you&#x27;re someone who can&#x27;t help but take extremely seriously radically novel viewpoints. I&#x27;d expect most people will face the opposite problem, in that they&#x27;ll radically underestimate just how thoroughly and vehemently every facet of current politics in liberal democracies is rejected. I&#x27;ve found it takes much deliberate and conscious effort to get myself of taking some illiberal ideologies seriously at all. </p><p>In the last few years, I&#x27;ve come to still hold a lot of those assumptions underpinning our current political system, since I still believe something like how liberal capitalist democracy is the worst socioeconomic and/or political system ever tried, except for all the others. However, what those assumptions were, and why I believed them about liberal democracy, and how I came to believe them based on the kind of society I lived in, was something I didn&#x27;t really appreciate until I had done a decent job of exposing myself to political perspectives on the Left, the Right, and everywhere in between that reject liberal democracy out of hand. </p><p>Returning to the Heterodox Academy, none of this is to say there is anything wrong with their approach. To fully embrace an illiberal political ideology for a country like the United States would be to believe something like a very violent revolution would be justified to institute a government nothing whatsoever like what the United States has today. That would be a goal as independent of seeking what&#x27;s true as is the normative goal of healing the political divide. Illiberal politics will exacerbate that goal by widening rather than narrowing the political divide. For the record, I personally am skeptical HxA&#x27;s approach is optimal for achieving their goals, but I admire their goals, and my goals are certainly closer to theirs than those of illiberal ideologues. It&#x27;s almost never the goal of illiberal ideologues to get out of their filter bubble. I&#x27;ve found they see less value in it, since they often fundamentally trust less the judgement of humans who haven&#x27;t come to already share their current political beliefs. So, illiberal ideologues who don&#x27;t also have something like an aspiration to rationality don&#x27;t make for good cooperators in social epistemology. I think for a lot of rationalists this will curtail their desire to interact with them beyond the initial value of novel information they can provide through their unique perspectives.</p><p>Rationalists appear to prioritize seeking what&#x27;s true to a degree relatively greater than people whose goals are determined by a political ideology, liberal or illiberal, more than anything else. My solution for getting out of my own filter bubble, not only to understand people around me, but to seek what&#x27;s true beyond that, has been to be cognizant of the full span of contemporary political discourse, including those political perspectives that fall outside the Overton window to the left, to the right, or whatever direction. </p>",Evan_Gaensbauer,evan_gaensbauer,Evan_Gaensbauer,
fDKZZtTMTcGqvHnXd,Naked mole-rats: A case study in biological weirdness,naked-mole-rats-a-case-study-in-biological-weirdness,https://www.lesswrong.com/posts/fDKZZtTMTcGqvHnXd/naked-mole-rats-a-case-study-in-biological-weirdness,2019-05-19T18:40:25.203Z,95,45,14,False,False,https://eukaryotewritesblog.com/2019/05/19/naked-mole-rats-a-case-study-in-biological-weirdness/,"<p><em>Epistemic status: Speculative, just having fun. This piece isn&#x27;t well-cited, but I can pull up sources as needed - nothing about mole-rats is my original research. A lot of this piece is based on <a href=""https://www.pacificsciencecenter.org/naked-mole-rat-cam/"">Wikipedia</a>.</em></p><p>When <a href=""https://eukaryotewritesblog.com/2017/02/03/when-youre-expecting-the-weird/"">I wrote about “weirdness” in the past</a>, I called marine invertebrates, archaea viruses, and Florida Man stories “predictably weird”. This means I wasn’t really surprised to learn any new wild fact about them. But there’s a sense in which marine invertebrates both are and aren’t weird. I want to try operationalizing “weirdness” as “amount of unpredictability or diversity present in a class” (or “in an individual”) compared to other members of its group.</p><p>So in terms of “animals your hear about” - well, you know the tigers, the mice, the bees, the tuna fish, the songbirds, whatever else comes up in your life. But “deep sea invertebrates” seems to include a variety of improbable creatures - <a href=""https://en.wikipedia.org/wiki/Crown-of-thorns_starfish"">a betentacled neon sphere covered in spikes</a>, <a href=""https://en.wikipedia.org/wiki/Parborlasia_corrugatus"">a six-foot long disconcertingly smooth and flesh-colored worm</a>, <a href=""https://www.bbc.com/news/science-environment-14986769"">bisexual squids</a>, etc. Hey! Weird! That’s weird.</p><p>But looking at a phylogenetic tree, we see really quickly that “invertebrates” represent almost the entire animal tree of life.</p><span><figure><img src=""https://eukaryotewritesblog.files.wordpress.com/2019/05/animalphylogenetictree.jpg"" class=""draft-image center"" style=""width:68%"" /></figure></span><p><em>Image from <a href=""https://www.cell.com/current-biology/fulltext/S0960-9822(15)00928-8"">Telford et al (2015)</a></em></p><p>Invertebrates represent most of the strategies that animals have attempted on earth, and certainly most of the animals on earth. <em>Vertebrates</em> are the odd ones out.</p><p>But you know which animals are profoundly weird, no matter which way you look at it? Naked mole rats. Naked mole-rats have like a dozen properties that are not just <em>unusual</em>, not just <em>strange</em>, but <em>absolutely batshit</em>. Let’s review.</p><h2><strong>1. They don&#x27;t age</strong></h2><p>What? Well, for most animals, their chance of dying goes up over time. You can look at a population and find something like this:</p><span><figure><img src=""https://eukaryotewritesblog.files.wordpress.com/2019/05/molerats1.jpg?w=562&h=435"" class=""draft-image center"" style=""width:77%"" /></figure></span><p>Mole-rats, they have the same chance of dying at any age. Their graph looks like this:</p><span><figure><img src=""https://eukaryotewritesblog.files.wordpress.com/2019/05/20190519_133452.jpg"" class=""draft-image center"" style=""width:77%"" /></figure></span><p>They’re joined, more or less, by a few species of jellyfish, flatworms, turtles, lobsters, and at least one fish.</p><p>They’re hugely long-lived compared to other rodents, seen in zoos at 30+ years old compared to the couple brief years that rats get.</p><h2><strong>2. They don&#x27;t get cancer</strong></h2><p>Cancer generally seems to be the curse of multicellular beings, but naked mole-rats are an exception. A <em>couple</em> mole-rats have developed cancer-like growths <em>in captivity</em>, but no wild mole-rat has ever been found with cancer.</p><h2>3. <strong>They don’t feel some forms of pain</strong></h2><p>Mole-rats don’t <a href=""https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0060013"">respond to acid or capsaicin</a>, which is, as far as I know, unique among mammals.</p><h2><strong>4. They’re eusocial</strong></h2><p><em>Definitely</em> unique among mammals. Like bees, ants, and termites, naked mole-rats have a single breeding “queen” in each colony, and other “worker” individuals exist in castes that perform specific tasks. In an evolutionary sense, this means that the “unit of selection” for the species is the queen, not any individual - the queen’s genes are the ones that get passed down.</p><p>They’re also a fascinating case study of an animal whose existence was deduced before it was proven. Nobody knew about eusocial mammals for a long time. In 1974, entomologist Richard Alexander, who studied eusocial insects, <a href=""https://ncse.com/library-resource/predictive-power-evolutionary-biology-discovery-eusociality"">wrote down</a> a set of environmental characteristics he thought would be required for a eusocial mammal to evolve. Around 1981 and the next decade, naked mole-rats - a perfect match for his predictions - were found to be eusocial.</p><h2><strong>5. They don’t have fur</strong></h2><p>Obviously. But aside from genetic flukes or domesticated breeds, that puts them in a small unlikely group with only some marine mammals, rhinoceros, hippos, elephants, one species of boar, and… us.</p><span><em><figure><img src=""https://eukaryotewritesblog.files.wordpress.com/2019/05/nakedmoleratintube.gif?w=625"" class=""draft-image center"" style=""width:68%"" /></figure></em></span><p><em>You and this entity have so much in common.</em></p><h2><strong>6. They’re able to survive ridiculously low oxygen levels</strong></h2><p>It uses very little oxygen during normal metabolism, much less than comparable-sized rodents, and it can survive for hours at 5% oxygen (a quarter of normal levels.)</p><h2><strong>7. Their front teeth move back and forth like chopsticks</strong></h2><p>I’m not actually sure how common this is in rodents. But it really weirded me out.</p><h2><strong>8. They have no regular sleep schedule</strong></h2><p>This is weird, because <em>jellyfish</em> <a href=""https://cloudfront.escholarship.org/dist/prd/content/qt9763967j/qt9763967j.pdf"">have sleep schedules</a>. But not mole-rats!</p><h2><strong>9. They’re cold-blooded</strong></h2><p>They have basically no ability to adjust their body temperature internally, perhaps because their caves tend to be rather constant temperatures. If they need to be a different temperature, they can huddle together, or move to a higher or lower level in their burrow.</p><hr class=""dividerBlock""/><p>All of this makes me think that mole-rats must have some underlying unusual properties which lead to all this - a “weirdness generator”, if you will.</p><p>A lot of these are connected to the fact that mole rats spend almost their entire lives underground. There are lots of burrowing animals, but “almost their entire” is pretty unusual - they don’t surface to find food, water, or (usually) mates. (I think they might only surface when digging tunnels and when a colony splits.) So this might explain (8) - no need for a sleep schedule when you can’t see the sun. It also seems to explain (5) and (9), because thermoregulation is unnecessary when they’re living in an environment that’s a pretty constant temperature.</p><p>It probably explains (6) because lower burrow levels might have very little oxygen most of the time, although there’s some debate about this - their burrows <a href=""https://www.researchgate.net/publication/321195715_The_microenvironment_of_naked_mole-rat_burrows_in_East_Africa"">might actually be pretty well ventilated</a>.</p><p>And Richard Alexander’s <a href=""https://ncse.com/library-resource/predictive-power-evolutionary-biology-discovery-eusociality"">12 postulates</a> that would lead to a eusocial vertebrate - plus some other knowledge of eusociality - suggests that this underground climate, when combined with the available lifestyle and food source of a molerat, should lead to eusociality.</p><p>It <em>might</em> also be the source of (2) and (3) - people have theorized that higher CO2 or lower oxygen levels in burrows might reduce DNA damage or related to neuron function or something. (This would also explain why only mole-rats in captivity have had tumors, since they’re kept at atmospheric oxygen levels.) These still seem to be up in the air, though. Mole-rats clearly have a variety of fascinating biochemical tricks that are still being understood.</p><p>So there’s at least one “weirdness generator” that leads to all of these strange mole-rat properties. There might be more.</p><p>I’m pretty sure it’s not the chopstick teeth (7), at least - but as with many predictions one could make about mole rats, I could easily be wrong.</p><p><strong>To watch some naked mole-rats going about their lives, <a href=""https://www.pacificsciencecenter.org/naked-mole-rat-cam/"">check out the Pacific Science Center’s mole-rat live camera</a>. It’s really fun, if a writhing mass of playful otters that are also uncooked hotdogs sounds fun to you.</strong></p>",eukaryote,eukaryote,eukaryote,
kKSFsbjdX3kxsYaTM,Simple Rules of Law,simple-rules-of-law,https://www.lesswrong.com/posts/kKSFsbjdX3kxsYaTM/simple-rules-of-law,2019-05-19T00:10:01.124Z,59,27,24,False,False,,"<p>Response To: <a href=""http://www.overcomingbias.com/2019/05/simplerules.html"">Who Likes Simple Rules?</a></p><p>Epistemic Status: Working through examples with varying degrees of confidence, to help us be concrete and eventually generalize.</p><p>Robin Hanson has, in his words, “some puzzles” that I will be analyzing. I’ve added letters for reference.</p><ul><li> <em>A] People are often okay with having either policy A or policy B adopted as the standard policy for all cases. But then they <a href=""https://www.pnas.org/content/early/2019/05/08/1820701116"">object</a> greatly to a policy of randomly picking A or B in particular cases in order to find out which one works better, and then adopt it for everyone.<br/> </em></li><li><em> B] People don’t like speed and red-light cameras; they prefer human cops who will use discretion. On average people don’t think that speeding enforcement discretion will be used to benefit society, but 3 out of 4 <a href=""https://twitter.com/robinhanson/status/1125412665805950976"">expect</a> that it will benefit them personally. More generally people <a href=""http://www.overcomingbias.com/2019/05/why-crime-discretion.html"">seem to like</a> a crime law system where at least a dozen different people are authorized to in effect pardon any given person accused of any given crime; most people <a href=""https://twitter.com/robinhanson/status/1125420241511682049"">expect</a> to benefit personally from such discretion.<br/> </em></li><li><em> C] In many European nations citizens send their tax info into the government who then tells them how much tax they owe. But in the US and many other nations, <a href=""https://slate.com/business/2012/04/grover-norquist-and-h-r-block-the-unholy-alliance-of-tax-prep-firms-and-conservative-activists-to-make-your-taxes-even-more-complicated.html"">too many</a> people oppose this policy. The most vocal opponents think they benefit personally from being able to pay less than what the government would say they owe.<br/> </em></li><li><em> D] The British National Health Service gets a lot of criticism from choosing treatments by estimating their cost per quality-adjusted-life-year. US folks wouldn’t tolerate such a policy. Critics lobbying to get exceptional treatment say things <a href=""https://www.omicsonline.org/open-access/the-limitations-of-qaly-a-literature-review-2157-7633-1000334.php?aid=70859"">like</a> “one cannot assume that someone who is wheel-chair bound cannot live as or more happily. … [set] both false limits on healthcare and reducing freedom of choice. … reflects an overly utilitarian approach”<br/> </em></li><li><em> E] There’s long been opposition to using an official value of life parameter in deciding government policies. Juries have also severely punished firms for using such parameters to make firm decisions.<br/> </em></li><li><em> F] In academic departments like mine, we tell new professors that to get tenure they need to publish enough papers in good journals. But we refuse to say how many is enough or which journals count as how good. We’d keep the flexibility to make whatever decision we want at the last minute.<br/> </em></li><li><em> G] People who hire lawyers rarely know their track record and winning vs. losing court cases. The info is public, but so few are interested that it is rarely collected or consulted. People who hire do know the prestige of their schools and employers, and decide based on that.<br/> </em></li><li><em> H] When government leases its land to private parties, sometimes it uses centralized, formal mechanisms, like auctions, and sometimes it uses decentralized and informal mechanisms. People seem to intuitively prefer the latter sort of mechanism, even though the former seems to works better. In <a href=""https://www.nber.org/papers/w25712"">one study</a> “auctioned leases generate 67% larger up-front payments … [and were] 44% more productive”.<br/> </em></li><li><em> I] People consistently invest in managed investment funds, which after the management fee consistently return less than index funds, which follow a simple clear rule. Investors seem to enjoy bragging about personal connections to people running prestigious investment funds.<br/> </em></li><li><em> J] When firms go public via an IPO, they typically pay a bank 7% of their value to manage the process, which is supposedly spent on lobbying others to buy. Google <a href=""https://www.cnbc.com/2014/08/19/es-took-off-but-the-auction-didnt.htmlhttp://www.exits.com/blog/ma-advisor-fees-selling-business/"">famously</a> used an auction to cut that fee, but banks have succeed in squashing that rebellion. When firms try to sell themselves to other firms to acquire, they typically pay 10% if they are priced at less than $1M, 6-8% if priced $10-30M, and 2-4% if priced over $100M.<br/> </em></li><li><em> K] Most elite colleges decide who to admit via opaque and frequently changing criteria, criteria which allow much discretion by admissions personnel, and criteria about which some communities learn much more than others. Many elites learn to game such systems to give their kids big advantages. While some complain, the system seems stable.<br/> </em></li><li><em> L] In a Twitter <a href=""https://twitter.com/robinhanson/status/1127679503336132608"">poll</a>, the main complaints about my fire-the-CEO decisions markets proposal are that they don’t want a simple clear mechanical process to fire CEOs, and they don’t want to explicitly say that the firm makes such choices in order to maximize profits. They instead want some people to have discretion on CEO firing, and they want firm goals to be implicit and ambiguous.</em><br/> </li></ul><p>Some of these examples don’t require explanation beyond why they are <em>bad ideas for rules. </em>They wouldn’t work. Others would, or are even obviously correct, and require more explanation. I do think there is a enough of a pattern to be worth trying to explain. People reliably dislike the rule of law, and prefer to substitute the rule of man.</p><h3><strong>Why do people oppose the rule of law?</strong></h3><p>You can read his analysis <a href=""http://www.overcomingbias.com/2019/05/simplerules.html"">in the original post</a>. His main diagnosis is that people promote discretion for two reasons:</p><ol><li>They believe they are unusually smart, attractive, charismatic and well-liked, just the sort of people who tend to be favored by informal discretion.</li><li>They want to signal to others that they have confidence in elites who have discretion, and that they expect to benefit from that discretion.</li></ol><p>While I do think these are <em>related </em>to some of the key reasons, I do not think these point at the central things going on. Below I tackle all of these cases and their specifics. Overall I think the following are the five key stories:</p><ol><li><a href=""https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy"">Goodhart’s Law</a>. We see a lot of Regressional and Adversarial Goodhart, and also some Extremal and Causal as well. B, F, G, K and L all have large issues here.</li><li><a href=""https://blog.jaibot.com/the-copenhagen-interpretation-of-ethics/"">Copenhagen Interpretation of Ethics</a>. If you put a consideration explicitly into your rule, that makes you blameworthy for interacting with it. And you’re providing all the information others need to scapegoat you not only for what you do, but what you <em>would </em>do in other scenarios, or <em>why </em>you are doing all of this. This is a factor in A, B, D, E, F, H and K all have to worry about this.</li><li>Forbidden Considerations and Lawsuit Protection. We can take the danger of transparency a step further. There are things that one wants to take into consideration that are illegal to consider, or which you are considered blameworthy for considering. The number of ways one can be sued or boycotted for their decision process goes up every year.  You need a complex system in order to disguise hidden factors, and you certainly can’t put them into explicit rules. And in general, the less information others have, the less those that don’t like your decision have to justify a lawsuit or making other trouble. B, D, E, F, K and L have this in play.</li><li>Power. Discretion and complexity favor those with power. If you have power, others worry that anything they do can influence decisions, granting you further power over everything in a vicious cycle. If you use a simple rule, you give up your power, including over unrelated elements. Even if you don’t have power directly over a decision, anyone with power anywhere can threaten to use that power whenever any discretion is available, so everyone with power by default favors complex discretionary rules everywhere. This shows up pretty much everywhere other than A, but is especially important in B, F, H, K and L.</li><li>Theft. Complex rules are often nothing more than a method of expropriation. This is especially central in B, C, D, H, I and J.</li></ol><p>I’ll now work through the examples. I’ll start with C, since it seems out of place, then go in Robin’s order.</p><p>Long post is long. If a case doesn’t interest you, please do skip it, and it’s fine to stop here.</p><h3>C] Tax Returns</h3><p>The odd policy out here is C, the failure to have the government tell citizens what it already knows about citizens’ tax returns. This results in many lost hours searching down records, and much money lost paying for tax preparation. As a commentator points out, the argument that ‘this allows one to pay less than they owe’ doesn’t actually make sense as an explanation. The government still knows what it knows, and still cross-checks that against what you say and pay. In other countries one can still choose to adjust the numbers shared with you by the government.</p><p>In theory, one could make a case similar to those I’ll make in other places, that telling people what information the government knows and doesn’t know allows people to hide anything that the government doesn’t know about. But that seems quite minor.</p><p>What’s going on here is simple regulatory capture, corruption, rent seeking and criminal theft. Robin’s link explains this explicitly. Tax preparation corporations like H&amp;R Block are the primary drivers here, because the rules generate more business for them. There is also a secondary problem that fanatical anti-tax conservatives like that taxes annoy people.</p><p>But I’ve never heard of a <em>regular person </em>who thinks this policy is a good idea, and I never expect to find one. We’re not <em>this </em>crazy. We have a dysfunctional government.</p><h3>A] Random Experiments</h3><p>Robin’s explanations don’t fit case A. If you’re choosing randomly, no one can benefit from discretion. If you choose the same thing for everyone, again no one can benefit from discretion. If anything, the random system allows participants to potentially cheat or find a way around a selection they dislike, whereas a universal system makes this harder. Other things must be at work here.</p><p>This is the opposite of C, a case where people <em>do </em>oppose the change, but the change would be obviously good.</p><p>I call this the “too important to know” problem.</p><p>To me this is a clear case of <a href=""https://blog.jaibot.com/the-copenhagen-interpretation-of-ethics/"">The Copenhagen Interpretation of Ethics</a> and <a href=""https://thezvi.wordpress.com/2019/04/25/asymmetric-justice/"">Asymmetric Justice</a> interacting with sacred values.</p><p>An experiment <em>interacts with the problem </em>and in particular <em>interacts with every subject of the experiment, and with every potential intervention, </em>in a way sufficient to render you blameworthy for not doing more, or not doing the optimal thing.</p><p>The contrast between the two cases is clear.</p><p>Without an experiment, we’re <em>forced </em>to make a choice between options A and B. People <em>mostly </em>accept that one must do their best, and potentially sacred values are up against other potentially sacred values, and one must guess and try their best.</p><p>In the cases in the study, it’s even more extreme. We’re choosing to implement A or implement B, in a place where normally one would do nothing. So we’re comparing doing something about the situation to doing nothing. It’s no surprise that ‘try to reduce infections’ comes out looking good.</p><p>With an experiment, <em>the choice is between experimentation and non-experimentation. </em>You are <em>choosing </em>to prioritize information <em>over </em>all the sacred values the non-objectionable choices are trading off. Even if the two choices are fully non-objectionable, <em>choosing between them </em>still means placing <em>the need to gather information </em>over <em>the needs of the people in the experiment. </em></p><p>The needs of specific people are, everywhere and always, a sacred value. Someone, a particular real person, is on the line. When put up against “information” what chance does this amorphous information have?</p><p>Copenhagen explains why it is pointless to say that the experiment is better for these patients than not running one. Asymmetric Justice explains why the benefits to future patients doesn’t make up for it.</p><p>There are other reasons, too.</p><p>People don’t like their fates coming down to coin flips. They don’t like uncertainty.</p><p>People don’t like asymmetry or inequality – if I get A and you get B, <em>someone </em>got the better deal, and that’s <em>not fair</em>.</p><p>If you choose a particular action, that provides evidence that there was a <em>reason </em>to choose it. So people instinctively adjust some for the fact that it was chosen. Whereas in an experiment, it’s clear you don’t know which choice is better (unless you <em>do </em>know and are simply out to <em>prove </em>it, in which case you are a monster). That doesn’t inspire confidence.</p><p>A final note is that if you look at <a href=""https://www.pnas.org/content/early/2019/05/08/1820701116"">the study in question</a>, it suggests another important element. If you choose A, you’re blameworthy for A and for ~B, but you’re certainly not blameworthy for ~A or for B! Whereas if you choose (50% A, 50% B) then you are blameworthy for A, ~A, B <em>and </em>~B, <em>plus </em>experimentation in general. That’s a lot of blame.</p><p>Remember Asymmetric Justice. If <em>any </em>element of what you do is objectionable, <em>everything </em>you do, together, is also objectionable. A single ‘problematic’ element ruins all.</p><p>So if we look at Figure 1 in the study, we see in case C that the objection score for the A/B test is actually <em>below </em>what we’d expect if we thought the chances of objecting to A and B were independent, and people were objecting to the experiment whenever they disliked either A or B (or both). In cases B and D, we see only a small additional rate of objection. It’s only in case A that we see substantial additional objection. Across the data given, it looks like this phenomenon explains about half of the increased rate of objection to the experiments.</p><p>It also looks like a lot of people explicitly cited things like ‘playing with people’s lives’ via experiment, and object to experimentation as such at least when the stakes are high.</p><h3>B] Police Discretion</h3><p>I do not think Robin’s story of expectation of personal benefit is the central story here, either. The correlation isn’t even that high in his poll.</p><blockquote>If police have discretion IN GENERAL regarding who they arrest, do you think they will on average use that discretion to arrest those who actually do more net social harm? Do you think that you will tend to be favored by this discretion?</blockquote><blockquote><strong>49% </strong>Yes to both</blockquote><blockquote><strong>13% </strong>No to both</blockquote><blockquote><strong>10% </strong>Yes re net harm, No re me</blockquote><blockquote><strong>28% </strong>No re net harm, Yes re me</blockquote><blockquote> — Robin Hanson (@robinhanson) <a href=""https://twitter.com/robinhanson/status/1125420241511682049?ref_src=twsrc%5Etfw"">May 6, 2019</a></blockquote><p>If you think net harm is reduced (59%), you’re (49/59) 84% to think you’ll benefit. If you think net harm is not reduced, you are (28/41) 68% to think you’ll benefit. Given that you’d expect models to give correlated returns to the two questions – if discretion is used wisely, it should tend to benefit both most people and a typical civilian looking to avoid doing social harm, and these are Robin’s Twitter followers – I don’t think personal motivation is explaining much variance here.</p><p>The question also asking about only part of the picture. Yes, we would hope that police (and prosecutors and others in the system) would use discretion, at least in part, to arrest those who do more net social harm over those who do less net social harm.</p><p>But that’s far from the only goal of criminal justice, or of punishment. We would <em>also </em>hope that authorities would use discretion to accomplish other goals, as well.</p><p>Some of these goals are good. Others, not so much.</p><p>What are some other goals we might have? What are other reasons to use discretion?</p><p>I think there are five broad reasons, beyond using it to judge social harm.</p><ol><li>Discretion gives law enforcement authorities power. This power allows them to maintain and exert authority. It keeps the system running, ensures cooperation and allows them to solve cases and enforce the law.</li><li>Discretion gives law enforcement authorities power and status. This power and status is a large part of the compensation we give to law enforcement.</li><li>Discretion allows those with status and/or power to gain additional benefits from that status and/or power.</li><li>Discretion allows us to enforce rules without having to state those rules explicitly, be able to well-specify those rules, or specify them in advance.</li><li>Discretion guards against Goodhart’s Law and the gaming of the system.</li></ol><p>To this we would add Robin’s explanations, that one might want to benefit from this directly, and/or one might want to signal support for such authorities. And the more discretion they have, the more one would want to signal one’s support – see reason 1.</p><p>A case worth grappling with can be made <em>for or against </em>each of these five justifications being net good. So one could argue in favor like this with arguments like (I am not endorsing these, nor do they necessarily argue for today’s American level of discretion):</p><ol><li>No one would cooperate with authorities. Every potential witness will stonewall, every defendant will fight to the end. Intimidation of witnesses would be impossible to stop. Good luck getting anyone even <em>associated with someone</em> doing <em>anything </em>shady to ever talk to the police. Cases wouldn’t get solved, enforcement would break down. Criminals would use <a href=""https://thezvi.wordpress.com/2019/02/19/blackmail/"">Blackmail</a> to take control of people and put them outside the law. Authorities’ hands would be tied and we’d be living in Batman’s Gotham.</li><li>In many ways, being a cop is a pretty terrible job. Who wants to constantly have hostile and potentially dangerous interactions with criminals? Others having to ‘<a href=""https://www.youtube.com/watch?v=XbebjUYItKw"">respect my authoritah</a>‘ improves those interactions, and goes a long way in making up for things on many fronts.</li><li>Increasing returns for status and power increase the power of incentives. We want people to do things we approve of, and strive to gain society’s approval, so we need levers to reward those who do, and punish those who don’t. We want to reward those who walk the straight and narrow track, and make good, and also those who strive and achieve. This has to balance the lure of anti-social or criminal activity, especially in poorer communities. And it has to balance the lure of inactivity, as we provide increasingly livable baskets of goods to those who opt out of status and prestige fights to play video games.</li><li>If we state our rules explicitly, we are now blameworthy for every possible corner case in which those rules result in something perverse, and for every motivation or factor we state. Given that we can be condemned for each of these via Asymmetric Justice, this isn’t an option. We also need to be able to implement systems without being able to specify them and their implications in an unambiguous way. If we did go by the letter of the law, then we’re at the mercy of the mistakes of the legislature, and the law would get even more complex than it is as we attempt to codify every case, beyond the reach of any person to know how it works. Humans are much better at processing other types of complex systems. And we need ways for local areas to enforce norms and do locally appropriate things, without having their own legislatures. If the system couldn’t correct obvious errors, both Type I and Type II, then it would lose the public trust. And so on.</li><li>If people know exactly what is and isn’t illegal in every case, and what the punishments are, then it will be open season for anything you didn’t make explicitly illegal. People will find technically permitted ways to do all sorts of bad things. They’ll optimize for all the wrong things. Even when they don’t, they’ll do the maximum amount of every bad thing that your system doesn’t punish enough to stop them from doing, and justify it by saying ‘it was legal’. Your laws won’t accomplish what they set out to accomplish. Any complex system dealing with the messiness of the real world needs some way to enforce the ‘spirit of the law.’ One would be shocked if extensive gaming of the system and epic Goodhart failures didn’t result from a lack of discretion.</li></ol><p>Or, to take the opposite stances:</p><ol><li>Power corrupts. It is bad and should be minimized. The system will use its power to protect and gather more power for itself, and rule for the benefit of its members and those pulling their strings, not you. If we didn’t have discretion, we could minimize the number of laws and everyone wouldn’t need to go around afraid of authority. And people would see that authority was legitimate, and would be inclined to cooperate.</li><li>Power not only corrupts, it also attracts the corrupt. If being a cop lets you help people and stand for what’s right, and gives you a good and steady paycheck, you’ll get good people. If being a cop is an otherwise crappy job where you get to force people to ‘<a href=""https://www.youtube.com/watch?v=XbebjUYItKw"">respect my authoritah</a>‘ and make bank with corrupt deals and spurious overtime, you’ll get exactly the people you don’t want, with exactly the authority you don’t want them to have.</li><li>The last thing we want is to take the powerful (and hence corrupt) and give them even more discretion and power, and less accountability. The inevitable result is increasing amounts of scapegoating and expropriation. This is how the little guy, and the one minding their own business trying to produce, get crushed by corporations and petty tyrants of all sorts.</li><li>If you can’t state what your rules are, how am I supposed to follow them? How can it be fair to punish me for violating rules you won’t tell me? This isn’t rules at all, or rule of law. It’s rule of man, rule of power begetting power. The system is increasingly rigged, and you’re destroying the records to prevent anyone from knowing that you’re rigging it.</li><li>The things you’re trying to protect from being gamed are power and the powerful, which are what are going to determine what the ‘spirit of the rules’ is going to be. So the spirit becomes whatever is good for them. The point of rule of law, of particular well-specified rules, is to avoid this. Those rules are not supposed to be the only thing one cares about. Rather, the law is supposed to guard against specific bad things, and other mechanisms allowed to take care of the rest. If the law is resulting in Goodhart issues, it’s a bad law and you should change it.</li></ol><p>The best arguments I know about against discretion have nothing to do with the social harm caused by punished actions. They are arguments for rule of law, and to guard against what those with discretion will do with that power. These effects are rather important and problematic even when the system is working as designed.</p><p>The best arguments I know about in favor of discretion also have nothing to do with the social harm caused by punished actions. They have to do with the system depending on discretion in order to be able to function, and in order to ensure cooperation. A system without discretion by default makes the spread of any local information everyone’s enemy, and provides no leverage to overcome that. If we didn’t have discretion, we would have to radically re-examine all of our laws and our entire system of enforcement, lest everything fall apart.</p><p>My model says that we currently give authorities too much discretion, and (partly) as a result have punishments that are too harsh. And also that the authorities have so much discretion partly because punishments have been made too harsh. Since discretion and large punishments give those with power more power, it would be surprising if this were not the case.</p><h3>D] National Health Service</h3><p>The National Health Service gets criticized constantly because it is their job to deny people health care. There is not enough money to provide what we would think of as an acceptable level of care under all circumstances, because our concept of acceptable level of care is <em>all of the health care. </em>In such a circumstance, there isn’t much they could do.</p><p>Using deterministic rules based on numbers is the obviously correct way to ration care. Using human discretion in each case will mean either always giving out care, since the choice is between care or no care – which is a lot of why health care costs are so high and going higher – or not always giving out care when able to do so, which will have people screaming unusually literal bloody murder.</p><p>Deterministic rules let individuals avoid blame, and allow health care budgets to be used <em>at all. </em>But that doesn’t mean people are going to like it. If anything, they’re going to be mad about both the rules and the fact that they don’t have a human they can either blame or try to leverage to get what they want. There’s also the issue of putting a value on human life at all, which is bad enough but clearly unavoidable.</p><p>More than that, once you explicitly say what you value by putting numbers on lives and improvements in quality of life, you’re doing something both completely necessary and completely unacceptable. The example of someone in a wheelchair is pretty great. If you don’t provide <em>some </em>discount in value of quality of life for physical disability, then you are saying that physical disabilities don’t decrease quality of life. Which has pretty terrible implications for a health care system trying to prevent physical disabilities. If you do say they decrease quality of life, you’re saying people with disabilities have less value. There are tons of places like this.</p><p>Another way to view this is that the only way for one to make health care decisions to ration care or otherwise sacrifice sacred values to stay on budget, without blame, is to have all those decisions be seen as out of your control and not your choice. The only known way to do that is to have a system in place, and point to that. That system then becomes a way to <em>not </em>interact with the system, avoiding blame. Whereas proposing or considering any <em>other </em>system involves interaction, and thus blame.</p><h3>E] Value of Life</h3><p>If you are caught making a trade-off between a sacred value (life) and a non-sacred value (money), it’s not going to go well. Of course a company doing an explicit calculation here is going to get punished, as is a government policy making an explicit comparison. Humans don’t care about the transitive property.</p><p>Thus, firms and governments, who <em>obviously </em>need to value risk to human life at a high but finite numerical cost, will need to do this without writing the number down explicitly in any way. This is one of the more silly things one cannot consider, that one obviously <em>must </em>consider. In a world where we are blameworthy (to the point of being sued for massive amounts) for doing explicit calculations that acknowledge trade-offs or important facts about the world, firms and governments are forced to make their decisions in increasingly opaque ways. One of those opaque preferences will be to favor those who rely on opaqueness and destroy records, and to get rid of anyone who is transparent about their thinking or otherwise, and keeps accurate records.</p><h3>F] Tenure Requirements</h3><p>Tenure is about evaluating what a potential professor would bring to the university. No matter what extent politics gets involved, this is someone you’ll have to work with for decades. After this, rule of law <em>does </em>attach. You won’t be able to fire them afterwards unless they violate one of a few well-defined rules – or at least, that’s how it’s <em>supposed </em>to work, to protect academic freedom, whether or not it does work that way. You’ll be counting on them to choose and do research, pursue funding, teach and advise, and help run the school, and be playing politics with them.</p><p>That’s a big commitment. There are lots more people who want it and are qualified on paper than there are slots we can fund. And there are a lot more things that matter than how much research one can do. Some of them are things that are illegal to consider, or would look bad if you were found to be considering them. Others simply are not research done. You can’t use a formula, because people bring unique strengths and weaknesses, and you’re facing other employers who consider these factors. Even if a simple system could afford to mostly ‘take its licks’ you would face massive adverse selection, as everyone with bad intangibles would knock at your door.</p><p>You need to hold power over the new employees, so they’ll do the work that tenured employees don’t want to do, and so they’ll care about all aspects of their job, rather than doing the bare technical minimum everywhere but research.</p><p>Then there’s the <a href=""https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy"">Goodhart factors</a> on the papers directly. One must consider how the publications themselves would be gamed. If there was a threshold requirement for journal quality, the easiest journals that count would be the only place anything would be published. If you have a point system, they’d game that system, and spend considerable time doing it. If you don’t evaluate paper quality or value, they won’t care at all about those factors, focusing purely on being good enough to make it into a qualifying journal. Plus, being able to evaluate these questions <em>yourself </em>without an outside guide or authority will be part of the job you’re trying to get. We need to test that, too.</p><p>What you’re <em>really </em>testing for when you consider tenure, ideally, is not only skill but also <em>virtue. </em>You want someone who is <em>naturally driven </em>to scholarship and the academy, to drive forward towards important things. While also caring enough to do a passable job with other factors. Otherwise, once they can’t be fired, you won’t be able to get them to do anything. Testing for virtue isn’t something you can quantify. You want someone who will aim for the spirit rather than the letter, and who knows what the spirit is and cares about it intrinsically. If you judge by the letter, you’ll select for the opposite, and if you specify that explicitly, you’ll lose your signal that way as well.</p><p>I’d write this one up to power and exploitation of those lower on the totem pole, the need to test for factors that you can’t say out loud, the need to test for virtue, and the need to test for knowing what is valuable.</p><h3>G] A Good Lawyer</h3><p>People rightfully don’t think this number will tell us much, even now when it is not being gamed and vulnerable to Goodhart. Robin seems to be assuming that one should think that a previous win percentage should be predictive of a lawyer’s ability to win a particular case, rather than being primarily a selection effect, or a function of when they settle cases.</p><p>I doubt this is the case, <em>even with a relatively low level of <a href=""https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy"">adversarial Goodhart effects.</a></em></p><p>Most lawyers or at least their firms have great flexibility in what cases they pursue and accept. They also have broad flexibility in how and when they settle those cases, as clients largely rely on lawyers to tell them when to settle. Some of them will mostly want cases that are easy wins, and settle cases that likely lose. Others, probably better lawyers for winning difficult cases, will take on more difficult cases and be willing to roll the dice rather than settle them.</p><p>I don’t even know what counts as a ‘win’ in a legal proceeding. In a civil case you strategically choose what to ask for, which might have little relation to realistic expectations for a verdict, so getting a lesser amount might or might not be a ‘win’ and any settlement might be a win or loss even if you know the terms, and often the terms are confidential.</p><p>Thus, if I was looking for a lawyer, I would continue to rely on personal recommendations, especially from lawyers I trust, rather than look at overall track records, even if those track records were easily available. I don’t think those track records are predictive. Asking questions like someone’s success in similar style cases, with richer detail in each case, seems better, but one has to pay careful attention.</p><p>If people started using <em>win-loss records </em>to <em>choose lawyers, </em>and lawyers started optimizing their win-loss records, what little information those records might have gets even less useful. You would mostly be measuring which lawyers prioritize win-loss records, by selecting winners and forcing them to verdict, while avoiding, settling or pawning off losers, and by getting onto winning teams, and so on. By manipulating the client and getting them to do what was necessary. It’s not like lawyers don’t mostly know which cases are winners. By choosing a lawyer with too good a win-loss record, you’d be getting someone who cares more about how they look in a statistic than doing what’s right for their clients, and also who has the flexibility to choose which cases they have to take.</p><p>The adverse selection here, it burns.</p><p>That’s what I’d actually expect now. Some lawyers <em>do </em>care a lot about their track records, they’ll have better track records, and they’re exactly who you want to avoid. I’d take anyone bragging about their win rate as a very negative sign, not a positive one.</p><p>So I don’t think this is about simple rules, or about people’s cognitive errors, or anything like that. I think Robin is just proposing a terrible measure that is not accurate, not well-defined and easily gamed, and asking why we aren’t making it available and using it.</p><p>Contrast this with evaluations of doctors or hospitals for success rates or death rates from particular surgeries. That strikes me as a <em>much better </em>place to implement such strategies, although they still have big problems with adversarial Goodhart if you started looking. But you can get a much better idea of what challenges are being tackled and about how hard they are, and a much better measure of the rate of success. I’d still worry a lot about doctors selecting easy cases and avoiding hard ones, both for manipulation and because of what it would do to patient care.</p><p>A general theme of simple rules is that when you reward and punish based on simple rules, one of the things you are rewarding is a willingness to prioritize maximizing for the simple rule over any other goal, including the thing you’re trying to measure. Just like any other rule you might use to reward and punish. The problem with simple rules is that they explicitly shut out one’s ability to notice such optimization and punish it, which is the natural way to keep such actions in check. Without it, you risk driving out anyone who cares about anything but themselves and gaming the system, and creating a culture where gaming the system and caring about yourself are the only virtues.</p><h3>H] Land Allocations</h3><p>If all you care about is the ‘productivity’ of the asset and/or the revenue raised, then <em>of course </em>you use an auction. Easy enough, and I think people recognize this. They <em>don’t want </em>that. They want a previously public asset to be used in ways the public prefers, and think that we should prefer some uses to other uses because of the externalities they create.</p><p>It seems reasonable to use the opportunity of selling previously public goods to advance public policy goals that would otherwise require confiscating private property. Private sellers will also often attach requirements to sales, or choose one buyer over another, sacrificing productivity and revenue for other factors they care about.</p><p>We can point out all we like how markets create more production and more revenue, but we can’t tell people that they should care mostly about the quantity of production and revenue instead of other things. When there are assets with large public policy implications and externalities to consider, like the spectrum, it makes sense to think about monopoly and oligopoly issues, about what use the assets will be put to by various buyers, and what we want the world to look like.</p><p>That doesn’t mean that these good factors are the primary justifications. If they were, you’d see conditional contracts and the like more often, rather than private deals. The real reason is <em>usually </em>that other mechanisms allow insiders to extract public resources for private gains. This is largely a story of brazen corruption and theft. But if we’re going to argue for simple rules because they maximize simple priorities, we need to also argue for why those priorities cover what we care about, or we’ll be seen as tone deaf at best, allowing the corrupt to win the argument and steal our money.</p><h3>I] Investment Funds</h3><p>Low fee index funds are growing increasingly popular each year, taking in more money and a greater share of assets. Their market share is so large that being included in a relevant index has a meaningful impact on share prices.</p><p>Managed funds are on the decline. Most of these funds are <em>not </em>especially prestigious and most people invested in them don’t brag about them, nor do they have much special faith in those running the funds. They’re just not enough on the ball to realize they’re being taken for a ride by professional thieves.</p><p>Nor do I think most people care about associating with high status hedge funds or anything like that. I don’t see it, at all.</p><p>Also, those simple rules? You can find them in active funds, too. A lot of them are pretty popular. Simple technical analysis, simple momentum, simple value rules, and so on. What counts as simple? That’s a matter of perspective. Index providers are often doing staggeringly complex things under the hood. And indexing off someone else’s work is a magician’s trick, free riding off the work of others in a way that gets dangerous if too many start relying on it.</p><p>Most regular investors who think about what they’re doing at all, know they should likely be in index-style funds, and increasingly that’s where they are. If there’s a mystery at all it’s at least contained at the high end, in hedge funds with large minimums.</p><p>One can split the remaining ‘mystery’ into two halves. One is, why do some people think there exist funds that have sufficient alpha to justify their fees? Two is, why do some people think they’ve found one of those funds?</p><p>The first mystery is simple. They’re right. There exist funds that have alpha, and <em>predictably</em> beat the market. The trick is finding them and getting your money in (or the even better trick is figuring out how to do it yourself). I don’t want to get into an argument over efficient markets here and won’t discuss it in the comments, but the world in which no one can beat the market <em>doesn’t actually make any sense.</em></p><p>The second mystery is also simple. Marketing, winners curse, fooled by randomness and adverse selection, and the laws of markets. Of course a lot more people think they’ve found the winner than have actually found one.</p><p>This is a weird case in many ways, but my core take here is that the part of this that <em>does </em>belong on this list, is an example of complexity as justification for theft.</p><h3>J] Selling the Company</h3><p>Google is the auction company. They were uniquely qualified to run an auction and bypass the banks, and did it (as I understand it) largely because it was on brand and they’d have felt terrible doing otherwise. A more interesting case is Spotify, who recently simply let people start trading its stock without an IPO at all. Although they still paid the banks fees, which I find super weird and don’t understand. There never was a rebellion.</p><p>How do banks extract the money?</p><p>My model is something like this, coming mostly from reading Matt Levine. The banks claim that they provide essential services. They find and line up customers to buy the stock, they vouch for the stock, they price the stock properly to ensure a nice bump so everyone feels happy, they backstop things in case something goes wrong, they handle a ton of details.</p><p>What they really do are two things. Both are centered around the general spreading by banks of FUD: Fear, Uncertainty and Doubt.</p><p>First, they prevent firms from suddenly having to navigate a legally tricky and potentially risky, and potentially quite complex, world they know nothing about, where messing up could be a disaster. One <em>does not simply </em>sell the company or take it public, as much as it might look simple from the outside. And while the bank’s marginal costs are way, way lower than what they charge, trying to get that expertise in house in a confident way is hard.</p><p>Second, they are what people are <em>comfortable </em>with. You’re <em>not blameworthy </em>for paying the bank. It’s the null action. If you do it, no one says ‘hey they’ve robbed us all of a huge amount of money.’ Instead, they say ‘good on you for not being too greedy and trying to maximize the price while risking the company’s future.’</p><p>They’re doing this at the crucial moment when <em>how you look </em>is of crucial importance, when you’re about to get a huge windfall for years or a lifetime of work and give the same to everyone who helped you. When you’re spending all your energy negotiating lots of other stuff. A disruption threatens to unravel all of that. What’s a few percent in that situation? So what if you don’t price your IPO as high as you could have so that bankers can enjoy their bounce?</p><p>Banks are conspiring with the buyers to cheat the sellers out of the value of what they bring to the table. Buyers who object are threatened with ostracism and being someone no one is <em>comfortable </em>with, with the other side walking away from the table after buyers put in the work to get here.</p><p>Is this all guillotine-worthy highway robbery? Hell yes. Completely.</p><p>Banks (and the buyers who are their best customers and allies) are colluding with this pricing, and that’s the <em>nicest </em>way to put this. Again, this is <em>theft. </em>Complexity is introduced to allow rent seeking and theft, exploiting a moment of vulnerability.</p><h3>K] College Admissions</h3><p>Interesting that Robin says the system ‘appears stable.’ To me it does <em>not </em>seem stable. We just had a <em>huge </em>college admissions scandal that damaged faith in the system and a quite-well justified lawsuit against Harvard. We have the SAT promising to introduce ‘adversity scores.’ We have increasingly selective admissions eating more and more of childhood, and the rule that what can’t go on forever, won’t. This calls for some popcorn.</p><p>What’s causing the system to be complex? We see several of the answers in play here.</p><p>We see the ‘factors you can’t cite explicitly’ problem and the ‘we don’t want something we can be sued or blamed for’ here. Admissions officers are trying to pick kids who will be successful at school and in life, as well as satisfy other goals. A lot of the things that predict good outcomes in life are not things you would want to be caught dead using as a determinant in admissions even if they weren’t illegal to use in admissions. The only solution is to make the system complex and opaque, so no one can prove what you were thinking.</p><p>We also see complexity as a way for the rich and powerful to expropriate resources, in the sense that the rich and powerful and their children are likely to be more successful, and more likely to give money to the school. And of course, if the school has discretion, that gives the school power. It can extract resources and prestige from others who want to get their kids in. Employees, especially high-up ones, can extract things even without illegal bribes. Why pass that up?</p><p>We see the Goodhart’s Law and adverse selection problems. If you admit purely on the basis of a test, and the other schools admit on the basis of a range of factors, you don’t get the best test scorers unless you’re Harvard. You get the kids who are an epic fail at those other factors.</p><p>If you give kids an explicit target, they and their parents will <em>structure their entire lives </em>around it. They’ll do that even with a vague implicit target, <em>as they do now. </em>If it’s explicit, you get things like you see in China, where (according to an eyewitness who once came to dinner) many kids are pulled from school and do nothing but cram facts into their heads for the college admissions exam for <em>years. </em>And why shouldn’t they?</p><p>So you get kids whose real educations are crippled, who have no life experience and no joy of childhood. The only alternative is to allow a general sense of who the kid is and what they’ve done to matter. To be able to holistically judge kids and properly adjust.</p><p>As always, the more complex and hard to understand the game, the greater the expert’s advantage. The rich and powerful who understand the system and can make themselves look good will have a large edge from that. And the more we explicitly penalize them for those advantages, but not for their gaming of the system, the more we <em>force </em>them to game the system even harder. If you use an adversity score to set impossibly high standards for rich kids, they’re going to use every advantage they have to make up for that even more than they already do.</p><p>And of course, part of the test is seeing how you learn to game the test and what approach you take. Can you do it with grace? Do you do too much of it, not enough or the right amount?</p><p>This is all an anti-inductive arms race. The art of gaming the system is in large part the art of making it look like you’re not gaming the system, which is an argument for simpler rules. At this point, what portion of successful admissions is twisting the truth? How much is flat out lying? How much is presenting yourself in a misleading light? To what extent are we training kids from an early age to have <a href=""http://benjaminrosshoffman.com/excerpts-from-a-larger-discussion-about-simulacra/"">high simulacrum levels</a> and sacrifice their integrity? A lot. Integrity being explicitly on the test just makes it one more thing you need to learn to fake.</p><p>I hate the current situation, <a href=""https://thezvi.wordpress.com/2018/04/15/the-case-against-education/"">and the educational system in general</a>, but I think the alternative of a simple, single written test, with the system otherwise unchanged, would be <em>worse. </em>But of course, we’d never let it be that simple. That’s all before the fights over how to adjust those scores for ‘adversity’ and ‘diversity,’ and how to quantify that, and the other things we’d want to factor in. Can you imagine what happens to high schools if grades don’t matter? What if grades did matter in a <em>formulaic </em>matter and students and teachers were forced to confront the incentives? The endless battles over what other life activities should score points, the death of any that don’t, and the twisting into point machines of those that do?</p><p>So here we have all the Goodhart problems, and the theft problems, and the power problems, and the blameworthy considerations and justifications problems and lawsuit problems with their incentive to destroy all information. The gang’s all here.</p><h3>L] Fire that CEO</h3><p>I love me a prediction market, but <a href=""https://thezvi.wordpress.com/2018/07/26/prediction-markets-when-do-they-work/"">you have to do it right</a>. Would enough people and money participate? If they did, would they have the right incentives? If both of those, would you want that to be how you make decisions?</p><p>I think the answer to the first question is yes, if you structure it right. If there are only two possibilities and one of them will happen, you can make it work.</p><p>The answer to the second question is, no.</p><p>We can consider two possibilities.</p><p>In scenario one, this acts as an <em>advisory </em>for the board, to help them decide what to do.</p><p>In scenario two, this is the sole thing looked at, and CEOs are fired if and only if they are judged to be bad for the stock price, or can otherwise only be fired for specific causes (e.g. if found shooting a man on Fifth Avenue or stealing millions in company funds and spending them on free to play games, you need to pull the plug without stopping to look at the market).</p><p>The problem with scenario one is that you’re trading on how much the company is worth <em>given that the CEO was fired. </em>That’s <em>very different </em>from what you think the company would be worth if we decided to fire the CEO. The scenarios where the CEO is fired are where the board is unhappy with them, which is usually because of bad things that would make us think the stock is likely to be less valuable, like the stock price having gone down or insiders knowing the CEO has done or will do hard to measure long term damage. That doesn’t mean it won’t <em>also </em>take into account other things like whether the CEO is paying off the board, but the correlation we’re worried about is still super high. Giving the board discretion, that market participants would expect the board to use, hopelessly muddles things.</p><p>You could try to solve that problem by having the market trade only very close in time to the board decision. You kind of have to do that anyway, to avoid having a lame duck CEO. But it still depends on a lot of private information, and the decision will still reveal a lot about the firm. So I think that realistically this won&#x27;t work.</p><p>The problem with scenario two is that you’ve taken away any ability to punish or reward the CEO for anything other than future stock prices. This effectively gives the CEO absolute power, and allows them to get away with any and all bad behavior of all kinds. Even if past behavior lowers the stock price, it only matters to the extent that it predicts future actions which would further lower the stock price. So CEOs don’t even have to care about the stock price. They only need to care about the stock price predictions in relation to each other. So the best thing the CEO can do is make getting rid of them as painful as possible. Even more than now, they want to make sure that losing them destroys the company as much as possible. Their primary jobs now are to hype themselves as much as possible to outsiders, and to spend capital manipulating these prediction markets.</p><p>Again, we’re seeing Goodhart problems, we’re seeing reinforcement of power (in this case, of the board over the CEO, so it’s a balance of power we likely welcome), and the ability to take things into consideration without needing to make them explicit or measurable, as companies both care about things they’re not legally allowed to care about and which we wouldn’t like hearing they cared about, especially explicitly, and they need to maintain confidentiality.</p><br/>",Zvi,zvi,Zvi,
2k5bfcRqrDZA56Dhs,What are good practices for using Google Scholar to research answers to LessWrong Questions?,what-are-good-practices-for-using-google-scholar-to-research,https://www.lesswrong.com/posts/2k5bfcRqrDZA56Dhs/what-are-good-practices-for-using-google-scholar-to-research,2019-05-18T21:44:20.978Z,28,6,3,False,True,,"<p>Answers could provide workflows, tips, tricks, trigger-action patterns, things-to-avoid, useful and/or unknown Google Scholar features -- whatever helps someone get up to speed as a power user.</p>",DonyChristie,pee-doom,Pee Doom,
RwF82CBEniiA3No45,Simulation Typology and Termination Risks,simulation-typology-and-termination-risks,https://www.lesswrong.com/posts/RwF82CBEniiA3No45/simulation-typology-and-termination-risks,2019-05-18T12:42:28.700Z,12,3,0,False,False, https://arxiv.org/abs/1905.05792,"<p>The main idea of the article is that we  likely live in a “Fermi simulation”, that is, a simulation which is created by aliens to solve Fermi paradox via simulating possible global risks, or in a &quot;Singularity simulation&quot;, – a simulation where future AI models its own origin (gaming simulations will also play with our period of history as a most interesting one). It means that our simulation will be likely turned off soon, as at least one of three conditions will be reached:</p><p>- Our simulation will model a global catastrophe, which is subjectively equal to the termination.<br/>- Our simulation will reach unknown to us goal (but likely related to our AI&#x27;s origin conditions) and will be terminated.<br/>- Our simulation will reach a nested simulation level shortly after strong AI creation, which will drastically increase computational resources demand and thus the simulation will be terminated.</p><p>We also suggested a classification of different types of simulations, patched the Simulation Argument and suggested Universal Simulation Argument which now has to take into account all possible civilisations in the universe. This makes SA&#x27;s branches where we are not in the simulations (&quot;extinction soon&quot; or &quot;ethical future&quot;) much less likely, as it would require that all possible civilisations will go extinct or all possible non-human civilisations will be ethical.</p>",avturchin,avturchin,avturchin,
G5TwJ9BGxcgh5DsmQ,"Yes Requires the Possibility of No
",yes-requires-the-possibility-of-no,https://www.lesswrong.com/posts/G5TwJ9BGxcgh5DsmQ/yes-requires-the-possibility-of-no,2019-05-17T22:39:32.879Z,290,146,55,False,False,,"<p>1. A group wants to try an activity that really requires a lot of group buy in. The activity will not work as well if there is doubt that everyone really wants to do it. They establish common knowledge of the need for buy in. They then have a group conversation in which several people make comments about how great the activity is and how much they want to do it. Everyone wants to do the activity, but is aware that if they did not want to do the activity, it would be awkward to admit. They do the activity. It goes poorly.</p><p>2. Alice strongly wants to believe A. She searches for evidence of A. She implements a biased search, ignoring evidence against A. She finds justifications for her conclusion. She can then point to the justifications, and tell herself that A is true. However, there is always this nagging thought in the back of her mind that maybe A is false. She never fully believes A as strongly as she would have believed it if she just implemented an an unbiased search, and found out that A was, in fact, true.</p><p>3. Bob wants Charlie to do a task for him. Bob phrases the request in a way that makes Charlie afraid to refuse. Charlie agrees to do the task. Charlie would have been happy to do the task otherwise, but now Charlie does the task while feeling resentful towards Bob for violating his consent.</p><p>4. Derek has an accomplishment. Others often talk about how great the accomplishment is. Derek has imposter syndrome and is unable to fully believe that the accomplishment is good. Part of this is due to a desire to appear humble, but part of it stems from Derek&#x27;s lack of self trust. Derek can see lots of pressures to believe that the accomplishment is good. Derek does not understand exactly how he thinks, and so is concerned that there might be a significant bias that could cause him to falsely conclude that the accomplishment is better than it is. Because of this he does not fully trust his inside view which says the accomplishment is good.</p><p>5. Eve is has an aversion to doing B. She wants to eliminate this aversion. She tries to do an internal double crux with herself. She identifies a rational part of herself who can obviously see that it is good to do B. She identifies another part of herself that is afraid of B. The rational part thinks the other part is stupid and can&#x27;t imagine being convinced that B is bad. The IDC fails, and Eve continues to have an aversion to B and internal conflict.</p><p>6. Frank&#x27;s job or relationship is largely dependent to his belief in C. Frank really wants to have true beliefs, and so tries to figure out what is true. He mostly concludes that C is true, but has lingering doubts. He is unsure if he would have been able to conclude C is false under all the external pressure.</p><p>7. George gets a lot of social benefits out of believing D. He believes D with probability 80%, and this is enough for the social benefits. He considers searching for evidence of D. He thinks searching for evidence will likely increase the probability to 90%, but it has a small probability of decreasing the probability to 10%. He values the social benefit quite a bit, and chooses not to search for evidence because he is afraid of the risk. </p><p>8. Harry sees lots of studies that conclude E. However, Harry also believes there is a systematic bias that makes studies that conclude E more likely to be published, accepted, and shared. Harry doubts E.</p><p>9. A bayesian wants to increase his probability of proposition F, and is afraid of decreasing the probability. Every time he tries to find a way to increase his probability, he runs into an immovable wall called the conservation of expected evidence. In order to increase his probability of F, he must risk decreasing it. </p>",Scott Garrabrant,scott-garrabrant,Scott Garrabrant,
GJhdXWjG2WxnTXmvQ,"""One Man's Modus Ponens Is Another Man's Modus Tollens""",one-man-s-modus-ponens-is-another-man-s-modus-tollens,https://www.lesswrong.com/posts/GJhdXWjG2WxnTXmvQ/one-man-s-modus-ponens-is-another-man-s-modus-tollens,2019-05-17T22:03:59.458Z,33,6,7,False,False,https://www.gwern.net/Modus,<html><head></head><body></body></html>,gwern,gwern,gwern,
gzzDKvbKrc66T4KyN,Announcing my YouTube channel,announcing-my-youtube-channel,https://www.lesswrong.com/posts/gzzDKvbKrc66T4KyN/announcing-my-youtube-channel,2019-05-17T17:50:01.342Z,40,14,1,False,False,,"<img src=""https://cdn-images-1.medium.com/max/756/0*s2E1_53beLQRkR_S"" />Social theory. Geopolitics. Power. New videos every week.<p>Recently I launched<a href=""https://www.youtube.com/channel/UC4QYBbgLkGaULStiC5yc_1Q""> a YouTube channel</a>. This channel provides another medium in which to share my thoughts, as well as a place to access recordings of my talks and interviews.</p><h3>New content</h3><p>The first several videos dive into my thoughts on institutions, history, and modern society.</p><ul><li><a href=""https://www.youtube.com/watch?v=YtRfmao1vvs""><strong>Silicon Valley Was Wrong: The Internet Centralized Society</strong></a> It is commonly claimed that the Internet has been a decentralizing force for society, providing more<a href=""https://medium.com/@samo.burja/competition-for-power-8da516d0b2b3""> power</a> to individuals who can wield the new technology. This theme is ubiquitous within hacker culture and the cyberpunk literary genre, for example. However, today we find precisely the opposite: the Internet has, on the whole, been a <em>centralizing</em> force for society. A few large media companies have massive influence over public discourse as well as access to data about the behaviors of millions of users. While this has made individuals more transparent and more legible to large institutions at great scale, I argue that it has not made those large institutions more legible to us.</li><li><a href=""https://www.youtube.com/watch?v=AP9p38-C2j4""><strong>Why America is Not an Open Society</strong></a> In this video, I explore three common models given as explanations for the success of America, and argue that they don’t capture the complete picture. If these common perceptions are not true, then what more nuanced theory of history explains America’s success and prosperity?</li><li><em>I. America as an open, transparent society.</em> Do ideas rise and fall on their own merits and strength of evidence, or is it possible to manipulate public opinion towards misinformation given enough material resources? To answer this question, I explore Edward Bernays’ 1928 book Propaganda, psychiatry in communist Yugoslavia, Lysenkoism, and the (lack of) transparency of modern media institutions such as Facebook.</li><li><em>II. The American public as rational, self-interested actors.</em> I discuss the success of Sweden’s welfare state and examples of how individuals often make economic choices that depend on trust and that reflect care for others around them, as opposed to making all choices out of pure economic self-interest.</li><li><em>III. Decisions in American governance as the output of democratic processes.</em> In reality, many decisions are not made by officials in elected positions, because much political steering power is instead held by entrenched bureaucracies and civil servants.</li><li><a href=""https://www.youtube.com/watch?v=GM8AdR_gWO8""><strong>Will China Out-Innovate the United States?</strong></a> The United States prides itself on being a hub for world innovation and on attracting top talent from all over the world. However, China’s economy is now comparable to that of the United States, and its international influence is growing to match. What forces drive this rise, and will there be consequences be for American innovation? Furthermore, what can we learn by observing the books Xi Jinping keeps on his desk?</li><li><a href=""https://www.youtube.com/watch?v=-NLnYLItYEc""><strong>How to Predict the Next Global Hub</strong></a> What sociological factors have made modern Silicon Valley a hub for thinkers, innovators, and entrepreneurs? The most important factors may be unexpected, and the most expected factors may be unimportant; for example, London at its peak was crime-ridden. I explore Alexandria under the patronage of the Ptolemaic dynasty, economic opportunities in Paris during the 18th century, and the social landscapes of Los Angeles, San Francisco, and Shanghai.</li><li><a href=""https://www.youtube.com/watch?v=F3M6kA7pGo4""><strong>How I Learn History</strong></a> When learning history, how can we reconstruct what has truly happened? The most useful method is to ingest information from primary sources directly; these sources are not filtered through somebody else’s interpretation. Do in-depth case studies, read the firsthand accounts of those who were there, and reconstruct how individuals and situations were affected by the<a href=""https://medium.com/@samo.burja/functional-institutions-are-the-exception-9a1c6974aa09""> institutions</a> and<a href=""https://blog.usejournal.com/how-to-use-bureaucracies-97e980550070""> bureaucracies</a> around them.</li><li><a href=""https://www.youtube.com/watch?v=jKdv2CqM1o0""><strong>What Is Your Theory of History?</strong></a> Whether they realize it or not, everyone has their own implicit<a href=""https://medium.com/@samo.burja/on-building-theories-of-history-36ed1999216e""> theory of history</a>. We use our theories of history to make predictions and to decide what is important at the largest scale for our societies. An unexamined theory of history, however, can easily be inconsistent in how it reasons about the past, present, and future — and poor predictions are the result. By applying systematic thinking, you can build a theory of history that is consistent and coherent.</li></ul><h3>Talks and interviews</h3><p>In addition to new content, the YouTube channel provides a location for recordings of my talks and interviews.</p><ul><li><a href=""https://www.youtube.com/watch?v=ACdYmuFyjWM""><strong>Civilization: Institutions, Knowledge, and the Future</strong></a> This is a talk I gave with the Foresight Institute; I’ve written about it<a href=""https://medium.com/@samo.burja/civilization-institutions-knowledge-and-the-future-video-ab83579d99d1""> here</a>. For the YouTube channel, I’ve also curated some standalone excerpts from this talk:</li><li><a href=""https://www.youtube.com/watch?v=x2mLfaozia8""><strong>The Lycurgus Cup</strong></a>: What happens when a civilization’s technology becomes lost for over a thousand years? What can we learn about the economic output of the<a href=""https://medium.com/@samo.burja/how-roman-emperors-handled-the-succession-problem-730f15b812f""> Roman Empire</a> at its peak and before its fall? What technologies might our own civilization stand to lose? When our descendants read about our achievements, will they believe us?</li><li><a href=""https://www.youtube.com/watch?v=-KPAD1UjpsE""><strong>Intellectual Dark Matter</strong></a>: Physicists have inferred the existence of dark matter not by direct observation per se, but by observing the force it exerts on surrounding matter. Likewise, through observing history we can infer the existence of certain knowledge that has been developed and used by historical civilizations and which, though<a href=""https://medium.com/@samo.burja/on-the-loss-and-preservation-of-knowledge-66e4a6b4d27d""> lost to the ages</a>, has nonetheless shaped the trajectory of future civilizations.</li><li><a href=""https://www.youtube.com/watch?v=8G4sSaeTp8E""><strong>Artificial Intelligence: Existential Hope Scenarios</strong></a> This is a panel discussion with Mark Miller, Jessica Cussins, and De Kai in which I propose concrete actions towards guiding AI research to safe outcomes. I also discuss how to identify the highest risk areas of research, the feasibility of regulating software, and international cooperation.</li></ul><p>I hope you find it interesting!</p><p><a href=""https://www.youtube.com/samoburja"">Samo Burja</a></p><img src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3ba70af42336"" />",Samo Burja,samo-burja,Samo Burja,
FLENugo4Ad4isnqDs,What makes a scientific fact 'ripe for discovery'?,what-makes-a-scientific-fact-ripe-for-discovery,https://www.lesswrong.com/posts/FLENugo4Ad4isnqDs/what-makes-a-scientific-fact-ripe-for-discovery,2019-05-17T09:01:32.578Z,8,3,2,False,True,,"<p>The existence of multiple discovery seems to suggest that there are certain factors that make scientific facts ready to be discovered. What are these, factors, and how could one measure them?</p>",mr-hire,mr-hire,Matt Goldenberg,
fj5mzaaJ2aAFrREif,Why exactly is the song 'Baby Shark' so catchy?,why-exactly-is-the-song-baby-shark-so-catchy,https://www.lesswrong.com/posts/fj5mzaaJ2aAFrREif/why-exactly-is-the-song-baby-shark-so-catchy,2019-05-17T06:26:24.824Z,6,5,4,False,True,,"<p><em>(Epistemic status: low-level infohazard, class Earworm. You have been warned.)</em></p><p>The video, &quot;<a href=""https://www.youtube.com/watch?v=XqZsoesa55w"">Baby Shark Dance</a>&quot;, has over 2,773,743,743 views as of the time of this post. It bit into me while captive to a parent soothing their child on the BART subway some time ago and has occasionally reared its ugly snout ever since.</p><p>I am curious what models of music psychology have to say about this phenomenon and also what those explanations would suggest for increasing the virality of a given piece of music, audiovisuals, or any memetic content in general if applicable.</p>",DonyChristie,pee-doom,Pee Doom,
RjaAamezT8q6HWnmD,What is good literature on learned helplessness?,what-is-good-literature-on-learned-helplessness,https://www.lesswrong.com/posts/RjaAamezT8q6HWnmD/what-is-good-literature-on-learned-helplessness,2019-05-17T03:15:42.669Z,8,3,0,False,True,,"<p>In the parent question, &quot;<a href=""https://www.lesswrong.com/posts/Bnk6xJyhWZKMbT2ZZ/how-do-people-become-ambitious"">How do people become ambitious?</a>&quot;, PeterMcCluskey <a href=""https://www.lesswrong.com/posts/Bnk6xJyhWZKMbT2ZZ/how-do-people-become-ambitious#3kPJfZxZStkG6fewm"">suggests</a> investigating ambition by its inversion, learned helplessness. Dr_Manhattan asked this question in response.</p>",DonyChristie,pee-doom,Pee Doom,
Qiqc7qoavfC6DFoh4,What are some good examples of gaming that is hard to detect?,what-are-some-good-examples-of-gaming-that-is-hard-to-detect,https://www.lesswrong.com/posts/Qiqc7qoavfC6DFoh4/what-are-some-good-examples-of-gaming-that-is-hard-to-detect,2019-05-16T16:10:38.333Z,5,2,3,False,True,,"<p>For example, an RL agent that learns a policy that looks good to humans but isn&#x27;t. Adversarial examples that only fool a neural nets wouldn&#x27;t count.</p>",SoerenMind,soerenmind,SoerenMind,
bSWavBThj6ebB62gD,Offer of collaboration and/or mentorship,offer-of-collaboration-and-or-mentorship,https://www.lesswrong.com/posts/bSWavBThj6ebB62gD/offer-of-collaboration-and-or-mentorship,2019-05-16T14:16:20.684Z,76,35,14,False,False,,"<html><head></head><body><p><strong>UPDATE:</strong> Offer of mentorship is closed, since I received sufficiently many candidates for now. Offer of collaboration remains open for experienced researchers (i.e. researchers that (i) have some track record of original math / theoretical compsci research, and (ii) are able to take on concrete open problems without much guidance).</p>
<hr>
<p>I have two motivations for making this offer. First, there have been discussions regarding the lack of mentorship in the AI alignment community, and that beginners find it difficult to enter the field since the experienced researchers are too busy working on their research to provide guidance. Second, I have my own <a href=""https://www.alignmentforum.org/posts/5bd75cc58225bf0670375575/the-learning-theoretic-ai-alignment-research-agenda"">research programme</a> which has a significant number of shovel ready open problems and only one person working on it (me). The way I see it, my research programme is a very promising approach that attacks the very core of the AI alignment problem.</p>
<p>Therefore, I am looking for people who would like to either receive mentorship in AI alignment relevant topics from me, or collaborate with me on my research programme, or both.</p>
<h1>Mentorship</h1>
<p>I am planning to allocate about 4 hours / week to mentorship, which can be done over Skype, Discord, email or any other means of remote communication. For people who happen to be located in Israel, we can do in person sessions. The mathematical topics in which I feel qualified to provide guidance include: linear algebra, calculus, functional analysis, probability theory, game theory, computability theory, computational complexity theory, statistical/computational learning theory. I am also more or less familiar with the state of the art in the various approaches other people pursue to AI alignment.</p>
<p>Naturally, people who are interested in working on my own research programme are those who would benefit the most from my guidance. People who want to work on empirical ML approaches (which seem to be dominant in OpenAI, DeepMind and CHAI) would benefit somewhat from my guidance, since many theoretical insights from computational learning theory in general and my own research in particular, are to some extent applicable even to deep learning algorithms whose theoretical understanding is far from complete. People who want to work on MIRI's core research agenda would also benefit somewhat from my guidance but I am less knowledgeable or interested in formal logic and approaches based on formal logic.</p>
<h1>Collaboration</h1>
<p>People who want to collaborate on problems within the learning-theoretic research programme might receive a significantly larger fraction of my time, depending on details. The communication would still be mostly remote (unless the collaborator is in Israel), but physical meetings involving flights are also an option.</p>
<p>The <a href=""https://www.alignmentforum.org/posts/5bd75cc58225bf0670375575/the-learning-theoretic-ai-alignment-research-agenda"">original essay</a> about the learning-theoretic programme does mention a number of more or less concrete research directions, but since then more shovel ready problems joined the list (and also, there are a couple of <a href=""https://www.alignmentforum.org/posts/Qa5jG9z9dC6E4s9JH/dimensional-regret-without-resets"">new</a> <a href=""https://www.alignmentforum.org/posts/aAzApjEpdYwAxnsAS/reinforcement-learning-with-imperceptible-rewards"">results</a>). Interested people are advised to contact me to hear about those problems and discuss the details.</p>
<h1>Contact</h1>
<p>Anyone who wants to contact me regarding the above should email me at <a href=""mailto:vanessa.kosoy@intelligence.org"">vanessa.kosoy@intelligence.org</a>, and give me a brief intro about emself, including knowledge in math / theoretical compsci and previous research if relevant. Conversely, you are welcome to browse my writing on this forum to form an impression of my abilities. If we find each other mutually compatible, we will discuss further details.</p>
</body></html>",vanessa-kosoy,vanessa-kosoy,Vanessa Kosoy,
Qz6KTt5z3eu4pyKZB,Which scientific discovery was most ahead of its time?,which-scientific-discovery-was-most-ahead-of-its-time,https://www.lesswrong.com/posts/Qz6KTt5z3eu4pyKZB/which-scientific-discovery-was-most-ahead-of-its-time,2019-05-16T12:58:14.628Z,38,11,14,False,True,,"<html><head></head><body><p>Looking into the history of science, I've been struck by how continuous scientific progress seems. Although there are many examples of great intellectual breakthroughs, most of them build heavily on existing ideas which were floating around immediately beforehand - and quite a few were discovered independently at roughly the same time (see <a href=""https://en.m.wikipedia.org/wiki/List_of_multiple_discoveries"">https://en.m.wikipedia.org/wiki/List_of_multiple_discoveries</a>).</p>
<p>So the question is: which scientific advances were most ahead of their time, in the sense that if they hadn't been made by their particular discoverer, they wouldn't have been found for a long time afterwards? (Ideally taking into account the overall rate of scientific progress: speeding things up by a decade in the 20th century seems about as impressive a feat as speeding things up by half a century in ancient Greece).</p>
</body></html>",ricraz,ricraz,Richard_Ngo,
8fzBPHx8aQjrBNRqg,European Community Weekend 2019,european-community-weekend-2019,https://www.lesswrong.com/events/8fzBPHx8aQjrBNRqg/european-community-weekend-2019,2019-05-16T11:44:52.716Z,38,12,3,False,False,,"<html><head></head><body><p>From Friday August 30th to Monday 2nd September aspiring rationalists from across Europe and further afield will gather for 4 days of socializing, fun and intellectual exploration. There will be scheduled talks, but the majority of the content will be unconference style and participant driven.</p>
<p>On Friday afternoon we put up four wall-sized daily planners and by Saturday morning the attendees fill them up with +50 workshops, talks and activities of their own devising, such as icebreaker games, rationality techniques, EA community building discussions, comfort zone expansion workshop, polyamory and relationships workshops, morning meditation sessions in the winter garden and many more.</p>
<p>This is our 6th year and we feel that the atmosphere and sense of community at these weekends is something that’s really special. If that sounds like something you would enjoy and you have some exciting ideas and skills to contribute do come along and get involved. This year is the biggest one yet and it’s an entire day longer than previous years!</p>
<p>We have a very limited amount of spots. If you would like to be among the first selected in the beginning of May, sign up today: <a href=""http://www.tiny.cc/lwcw2019_signup"">www.tiny.cc/lwcw2019_signup</a> and make sure to let us know what experience and ideas you may contribute to this event: <a href=""http://www.tiny.cc/lwcw2019_contribution"">www.tiny.cc/lwcw2019_contribution</a>.</p>
<p>TL;DR:</p>
<p>When? 30th August – 2nd September 2019</p>
<p>Where? <a href=""http://jh-wannsee.de"">jh-wannsee.de</a></p>
<p>Tickets? Regular Ticket (200€), Supporter Ticket (300/400€): <a href=""http://www.tiny.cc/lwcw2019_signup"">www.tiny.cc/lwcw2019_signup</a></p>
<p>If you have any question, please email us at <a href=""mailto:lwcw.europe@gmail.com"">lwcw.europe@gmail.com</a>.</p>
<p>Looking forward to a great weekend,
The Community Weekend organizers and LessWrong Deutschland e.V.</p>
</body></html>",DreamFlasher,dreamflasher,DreamFlasher,
c4mw7fX8KL98Dt2AY,"Kevin Simler's ""Going Critical""",kevin-simler-s-going-critical,https://www.lesswrong.com/posts/c4mw7fX8KL98Dt2AY/kevin-simler-s-going-critical,2019-05-16T04:36:32.470Z,57,24,1,False,False,https://www.meltingasphalt.com/interactive/going-critical/,"<p>An interactive blogpost by Kevin Simler on network dynamics, with a final section on academia and intellectual progress. I generally think careful exploration of small-scale simulations like this can help quite well with understanding difficult topics, and this post seems like a quite good execution of that approach. </p><p>Also some interesting comments on intellectual progress and academia (though I recommend reading the whole post): </p><br/><blockquote>For years I&#x27;ve been fairly dismissive of academia. A short stint as a PhD student left a bad taste in my mouth. But now, when I step back and think about it (and abstract away all my personal issues), I have to conclude that academia is still <em>extremely</em>important.</blockquote><blockquote>Academic social networks (e.g., scientific research communities) are some of the most refined and valuable structures our civilization has produced. Nowhere have we amassed a greater concentration of specialists focused full-time on knowledge production. Nowhere have people developed a greater ability to understand and critique each other&#x27;s ideas. This is the beating heart of progress. It&#x27;s in these networks that the fire of the Enlightenment burns hottest.</blockquote><blockquote>But we can&#x27;t take progress for granted. If the reproducibility crisis has taught us anything, it&#x27;s that science can have systemic problems. And one way to look at those problems is network degradation.</blockquote><blockquote>Suppose we distinguish two ways of practicing science: <em>Real Science</em> vs. <em>careerist science</em>. Real Science is whatever habits and practices reliably produce knowledge. It&#x27;s motivated by curiosity and characterized by honesty. (Feynman: &quot;I just have to understand the world, you see.&quot;) Careerist science, in contrast, is motivated by professional ambition, and characterized by playing politics and taking scientific shortcuts. It may look and act like science, but it <em>doesn&#x27;t</em> produce reliable knowledge.</blockquote><blockquote>(Yes this is an exaggerated dichotomy. It&#x27;s a thought exercise. Bear with me.)</blockquote><blockquote>Point is, when careerists take up space in a Real Science research community, they gum up the works. They angle to promote themselves while the rest of the community is trying to learn and share what&#x27;s true. Instead of striving for clarity, they complicate and obfuscate in order to sound more impressive. They engage in (what Harry Frankfurt might call) scientific bullshit. And consequently, we might model them as dead nodes, immune to the good-faith information exchanges necessary for the growth of knowledge:</blockquote>",habryka4,habryka4,habryka,
riha4Pf2YNtr6EJM7,How do you know it's time for a break?,how-do-you-know-it-s-time-for-a-break,https://www.lesswrong.com/posts/riha4Pf2YNtr6EJM7/how-do-you-know-it-s-time-for-a-break,2019-05-16T04:33:38.312Z,30,6,1,False,True,,"<p>My original question was something like &quot;how much productive work can people do in a day?&quot;, but even if I got a signed piece of paper from God telling me the exact average, that wouldn&#x27;t be very useful to individuals except as cover for stopping once they&#x27;d reached the average. Some people are clearly capable of doing more than others, the same person has different capacities for different kinds of work.</p><p>So instead I&#x27;m asking &quot;How do you know when you need a break? When you&#x27;re done for the day?&quot;. My hope is that reading answers will inspire people to recognize tells in themselves they previously hadn&#x27;t, and this will let them better assess when to push through and when to break.</p>",pktechgirl,elizabeth-1,Elizabeth,
sHQaDxk9AdAdnJYn2,What is this new (?) Less Wrong feature? (“hidden related question”),what-is-this-new-less-wrong-feature-hidden-related-question,https://www.lesswrong.com/posts/sHQaDxk9AdAdnJYn2/what-is-this-new-less-wrong-feature-hidden-related-question,2019-05-15T23:51:16.319Z,14,5,1,True,False,,"<html><head></head><body><p>What is this? I just noticed it (I see it when editing one of my posts):</p>
<p><img src=""https://dl.dropboxusercontent.com/s/x2labootfszyafh/Screenshot%202019-05-15%2019.49.05.png?dl=0"" alt=""""></p>
</body></html>",SaidAchmiz,saidachmiz,Said Achmiz,
Gxbfe5Tk3u9vAeEaP,Feature Request: Self-imposed Time Restrictions,feature-request-self-imposed-time-restrictions,https://www.lesswrong.com/posts/Gxbfe5Tk3u9vAeEaP/feature-request-self-imposed-time-restrictions,2019-05-15T22:35:15.883Z,22,8,8,True,False,,"<p>Hacker News has a feature called &quot;noprocrast&quot;. Here&#x27;s how they explain it in the <a href=""https://news.ycombinator.com/newsfaq.html"">FAQ</a>:</p><blockquote><strong>In my profile, what is noprocrast?</strong></blockquote><blockquote>It&#x27;s a way to help you prevent yourself from spending too much time on HN. If you turn it on you&#x27;ll only be allowed to visit the site for maxvisit minutes at a time, with gaps of minaway minutes in between. The defaults are 20 and 180, which would let you view the site for 20 minutes at a time, and then not allow you back in for 3 hours.</blockquote><p>If you try to use HN when you precommitted to not using it, you&#x27;ll get the following message from them:</p><blockquote><strong>Get back to work!</strong></blockquote><blockquote>Sorry, you can&#x27;t see this page. Based on the anti-procrastination parameters you set in your profile, you&#x27;ll be able to use the site again in 43 minutes.</blockquote><p>I was thinking that something like this would be awesome for LessWrong. Personally, I have a rather large problem browsing the web - which includes browsing LessWrong - when I should be doing other things. After reading <a href=""http://www.calnewport.com/books/digital-minimalism/"">Digital Minimalism</a>, I get the impression that such struggles are moreso the norm than the exception.</p>",adamzerner,adamzerner,Adam Zerner,
AwAA4y698dgbYfgeQ,Why I've started using NoScript,why-i-ve-started-using-noscript,https://www.lesswrong.com/posts/AwAA4y698dgbYfgeQ/why-i-ve-started-using-noscript,2019-05-15T21:32:20.415Z,17,9,19,False,False,,"<html><head></head><body><blockquote>
<p>Edit: I've updated somewhat based on Said's comment below, to think that NoScript is not a tool for everyone. I haven't decided to stop using it, but I have decided to stop strongly recommending that others use it. I especially urge you to read about the other extensions he lists at the end of his comment.</p>
</blockquote>
<blockquote>
<p>Edit 2: It's also been pointed out to me that <a href=""https://github.com/gorhill/uBlock"">uBlock Origin</a> also has capabilities for blocking 3rd party JavaScript, and might be even better at it than NoScript; in line with the idea that this is not for everyone, this functionality requires the user to explicitly claim to be an ""advanced user"" and read various documentation first. You may also be interested in reading <a href=""https://lobste.rs/s/jgkxv7/why_i_ve_started_using_noscript"">the discussion for this post on lobste.rs</a></p>
</blockquote>
<p>NoScript is a browser extension<sup class=""footnote-ref""><a href=""#fn-JtrknJwYdpPAWYKif-1"" id=""fnref-JtrknJwYdpPAWYKif-1"">[1]</a></sup> that prevents your browser from loading and running JavaScript without your permission. I recently started using it, and I highly recommend it.</p>
<p>I had first tried using NoScript around a decade ago. At the time it seemed like too much of a hassle. I ended up wanting to enable almost all the scripts that were included, and this was somewhat annoying to do. Things have changed a lot since then.</p>
<p>For one, NoScript's user interface has become much better: Now, if a page isn't working right, you simply click the NoScript icon and whitelist any domains you trust, or temporarily whitelist any domains you trust less. You can set it to automatically whitelist domains you directly visit (thereby only blocking third-party scripts).</p>
<p>A more pressing change is that I'm now much less comfortable letting arbitrary third parties run code on my computer. I used to believe that my browser was fundamentally capable of keeping me safe from the scripts that it ran. Sure, tracking cookies and other tricks allowed web sites to correlate data about me, but I thought that my browser could, at least in principle, prevent scripts from reading arbitrary data on my computer. With the advent of CPU-architecture-based side channel attacks (Meltdown and Spectre are the most publicized, but it seems like new ones come out every month or so), this belief now seems quite naïve.</p>
<p>Finally, in that decade, third-party scripts for tracking and ads have become almost literally ubiquitous on the web. Just about every web site I visit, I've discovered, has at least a couple of third-party dependencies, whose provenance I don't trust, and which I'd rather not spend (even a minuscule proportion of) my energy bill on. Even disregarding the new hardware vulnerabilities, I don't think arbitrary third party trackers ought to be trusted to run in your browser<sup class=""footnote-ref""><a href=""#fn-JtrknJwYdpPAWYKif-2"" id=""fnref-JtrknJwYdpPAWYKif-2"">[2]</a></sup>; if even one of the hundreds of tracking scripts is compromised, this could easily leak your passwords or other data to attackers.</p>
<p>An added benefit has been that NoScript works better than my ad blocker. Around the time I started using NoScript, I was watching a show on a streaming site I don't normally visit, that shall remain nameless. This site is extremely annoying. It plays more ads per minute than content, somehow evading uBlock Origin, and often the ads seem to break the actual video player so that the show stops partway through. After installing NoScript, I spent about 3 minutes wading through the ~50 script sources, enabling not-ads until eventually the video played. I was thrilled to see that the video played perfectly, with no interruptions.</p>
<p>In summary, just go try it. You might not like it, but at least then you'll know.</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-JtrknJwYdpPAWYKif-1"" class=""footnote-item""><p>There is a version for <a href=""https://addons.mozilla.org/en-US/firefox/addon/noscript/"">Firefox</a> and one for <a href=""https://chrome.google.com/webstore/detail/noscript/doojmbjmlfjjnbmnoijecmcbfeoakpjm?hl=en"">Chrome</a>; it also has a <a href=""https://en.wikipedia.org/wiki/NoScript"">Wikipedia page</a>. <a href=""#fnref-JtrknJwYdpPAWYKif-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-JtrknJwYdpPAWYKif-2"" class=""footnote-item""><p>Some decent background on the problem can be read <a href=""https://www.talasecurity.io/external1st-party-3rd-party-javascript-ecosystem-and-protection-against-compromises/"">here</a> <a href=""#fnref-JtrknJwYdpPAWYKif-2"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
</body></html>",benwr,benwr,benwr,
earsQcDuwAArRfWSN,"Emotional valence as cognition mutator (not a bug, but a feature)",emotional-valence-as-cognition-mutator-not-a-bug-but-a,https://www.lesswrong.com/posts/earsQcDuwAArRfWSN/emotional-valence-as-cognition-mutator-not-a-bug-but-a,2019-05-15T12:49:40.661Z,11,5,0,False,False,,"<p>Maybe because of my neurotype I view it important that I have good general way of handling things. I noticed a a pattern where people would process seemingly similar requests very differently and got curious whether there is an actual difference or are people being needlessly inconsistent.</p><ul><li>Can you pass the salt, please?</li><li>Step aside</li><li>Can I have your wallet, please?</li></ul><p>2 of these are supposed to have a &quot;well, he did ask&quot; kind of reaction and the reminaing a &quot;no, why would I?&quot;. The difference in suggestibility is great althought they all are supposed to be straight forward requests for X or a &quot;can i have X? yes/no&quot; kind of questions.</p><p>Now if I give a complicated answer why you should give me your wallet you are likely to remain pessimistic about complying. This also seems to have the weird property of increasing the sophistication of the argument is unlikely to increase compliance probability. It would seem like the person is not willing to entertain the proposition but is prejudiced to reject it from the get go. This would seem to go contrary to &quot;intellectual openness/readiness&quot;.</p><p>However the behaviour is not really mysterious and the reasons for it are pretty well founded. Your wallet contains a lot of your money which is important for a lot of things you do. Should something bad happen to it a lot of things will get a lot messier. It&#x27;s also an attractive prey target. It&#x27;s plausible that someone might lie to you just to get a hold on your wallet just to have its possession.</p><p>When I thought about a straight up thief trying to get the wallet by asking I realised that increasing the sophistication of the reason why to give up the wallet is not a good strategy. However asking for any &quot;innocent&quot; target is likely to encounter a lot more suggestibility. Some of these suggestions might put you in the position to better grab the wallet. That is a &quot;Hey what&#x27;s over there?&quot; and pointing away and then physically grabbing the wallet is likely to be more effective than a sophisticated argument why to give the wallet. The strange thing here seems to be that if the target percieves your motivation to be the wallet it&#x27;s effectively game over to you as the thief. A lot of the targets psychological defences know to activate on that cue.</p><p>The surprising result that I ended up on upon thinking is that the phenomenon is a legit psychological defence and it&#x27;s presence is actually constructive. But abstracting it into other spheres it means that in situations where we are handling requests to system crtical phenomena we have a increased weight to understand the request to a higher degree. It&#x27;s not that the agent goes emotional and throws reason out of the window. It&#x27;s precisely opposite in that the agent correctly identifies that this needs to be understood and processed correctly. And it can&#x27;t be blanket rejected because there is a minority of the situations where we actually want to comply with the request.</p><p>There is also a principle of a kind of burden of proof here. If I don&#x27;t understand it I am going to reject it. Even if you use logic that is &quot;more intellectual&quot; than me. This burden of proof doesn&#x27;t apply normally. Normally &quot;you know what you are doing&quot; can be a reason to give you the benefit of doubt. I don&#x27;t need to know where you are about to walk to step out of your way. But in these high-stakes situations I do need to know the details.</p><p>The ultimate such high-stakes situation would be the AI-boxing situation. In basic communication when people hear about the problem they liken it more to the &quot;Can you pass the salt, please&quot; kind of problem or pattern recognise &quot;friendliness&quot; as a kind of academic curiosity. A method of communication that would liken it to the asking of wallet would make poeple employ their latent psyhological skills to the problem. Here is one mini attempt at it. Situation 1: You have hitler in a cell and he asks you to let him go out of the cell. You reply &quot;No, you are f Hitler&quot;. Situation 2: you have Hitler and a innocent person in a cell. For some strange reason you don&#x27;t know how Hitler looks like. A man beyond the bars asks &quot;Let me, go I am innocent&quot;, you reply &quot;No you are Hitler trying to lie you are the innocent one to get out jail&quot;, &quot;What can I do to prove to you I am not Hitler?&quot;. In this kind of situation it&#x27;s clear that letting an innocent man walk is desirable but clearly not worth having to deal with Hitler again, even if we have no reason to think that Hitler is immidiately about to commit something bad.</p><p>As the AI-boxing problem was presented sometimes it felt it was presented as a unique problem perhaps requiring unique answers. But the variable suggestibility scales kind of highlights that natural intelligences box each other all the time already. We are capable of trusting each other in some situations but also capable of forgoing trust when it&#x27;s neccesary.</p><p></p>",Slider,slider,Slider,
GCwAtyMDii7sh6hD3,DC LW: Psychedelics,dc-lw-psychedelics,https://www.lesswrong.com/events/GCwAtyMDii7sh6hD3/dc-lw-psychedelics,2019-05-15T03:14:34.643Z,1,1,0,False,False,,<p>We will be meeting this Sunday the 19th at 3:30 in the National Portrait Gallery courtyard to discuss psychedelics. </p>,,,,
xFGQdgJndLcthgWoE,MIRI Summer Fellows Program,miri-summer-fellows-program,https://www.lesswrong.com/events/xFGQdgJndLcthgWoE/miri-summer-fellows-program,2019-05-15T00:28:12.225Z,49,18,3,False,False,,"<p>   </p><p>CFAR and MIRI are running our fifth annual MIRI Summer Fellows Program (MSFP) in the San Francisco Bay Area from August 9 to August 24, 2019.  </p><p>MSFP is an extended retreat for mathematicians and programmers with a serious interest in making technical progress on the problem of AI alignment.  It includes an overview of CFAR&#x27;s applied rationality content, a breadth-first grounding in the MIRI perspective on AI safety, and multiple days of actual hands-on research with participants and MIRI staff attempting to make inroads on open questions.</p><p><strong>Program Description</strong></p><p>The intent of the program is to boost participants, as far as possible, in four overlapping areas:</p><p><strong>Doing rationality inside a human brain:</strong> understanding, with as much fidelity as possible, what phenomena and processes drive and influence human thinking and reasoning, so that we can account for our own biases and blindspots, better recruit and use the various functions of our brains, and, in general, be less likely to trick ourselves, gloss over our confusions, or fail to act in alignment with our endorsed values.</p><p><strong>Epistemic rationality</strong>, especially the subset of skills around <a href=""https://intelligence.org/2018/11/22/2018-update-our-new-research-directions/#section2"">deconfusion</a>. Building the skill of noticing where the dots don&#x27;t actually connect; answering the question &quot;why do we think we know what we think we know?&quot;, particularly when it comes to predictions and assertions around the future development of artificial intelligence.</p><p><strong>Grounding in the current research landscape surrounding AI:</strong> being aware of the primary disagreements among leaders in the field, and the arguments for various perspectives and claims. Understanding the current open questions, and why different ones seem more pressing or real under different assumptions. Being able to follow the reasoning behind various alignment schemes/theories/proposed interventions, and being able to evaluate those interventions with careful reasoning and mature (or at least more-mature-than-before) intuitions.</p><p><strong>Generative research skill:</strong> the ability to make real and relevant progress on questions related to the field of AI alignment without losing track of one&#x27;s own metacognition.  The parallel processes of using one&#x27;s mental tools, critiquing and improving one&#x27;s mental tools, and making one&#x27;s own progress or deconfusion available to others through talks, papers, and models.  Anything and everything involved in being the sort of thinker who can locate a good question, sniff out promising threads, and collaborate effectively with others and with the broader research ecosystem.</p><p>Food and lodging are provided free of charge at CFAR&#x27;s workshop venue in Bodega Bay, California.  Participants must be able to remain onsite, largely undistracted for the duration of the program (e.g. no major appointments in other cities, no large looming academic or professional deadlines just after the program).</p><p>[<strong>5/28/19 Update</strong>: Applications closed on March 31, finalists were interviewed between April 1 and April 17, and admissions decisions (yes, no, waitlist) were sent in April.]</p><p>If you have any questions or comments, please email Colm at the contact address above, or,  if you suspect others would also benefit from reading the answer, post them here.</p><br/>",colm,colm,colm,
9dA6GfuDca3Zh3RMa,Data Analysis of LW: Activity Levels + Age Distribution of User Accounts,data-analysis-of-lw-activity-levels-age-distribution-of-user,https://www.lesswrong.com/posts/9dA6GfuDca3Zh3RMa/data-analysis-of-lw-activity-levels-age-distribution-of-user,2019-05-14T23:53:54.332Z,27,10,13,True,False,,"<p><em>Epistemic: I rarely trust other people’s data analysis, I only half trust my own. Right now, analytics is only getting a slice of my attention and this work is not as thorough as I’d like, but I think the broad strokes picture is correct. I have probably failed to include enough clarifications and disclaimers on where we should expect the data to be inaccurate. Feedback on my approach welcome.</em></p><p>I’ve been doing some analytics work for the LessWrong 2.0 team since September last year (since March I’ve been doing other work too, but that’s not relevant here). This post will hopefully be the first a series which will eliminate the backlog of analytics results I’ve been wanting to share.</p><p>This post is probably not the ideal starting point - that would be probably be a big picture general overview of LessWrong usage since the beginning - but it is some of my most recent work and therefore is easiest to share. Still, it does show things about the bigger picture.</p><p>Warning: The graphs are repetitive even though they’re showing different things. I’ve included them all for completeness, but you can just read my summary/interpretations while looking at only some of them.</p><h1>Distribution of User Account Age</h1><p><strong>Question:</strong> LW2 seems to be doing well, but is that just because we’re retaining/re-engaging a devoted base of older users despite not signing up new users? </p><p><strong>Answer: </strong>Activity on LW2 is coming from both new and old users across all activity types (posts, comments, votes, and views). The project is succeeding at getting new people to create accounts and engage. </p><p>In fact, there have consistently been more new users voting and viewing each month since LW2 launched than throughout LW’s past. The number of new users posting each month is roughly the same as historical levels. The number of new users who are commenting has declined (though the percentage new users is roughly the same), however this is consistent with the trend that comment volume on LW2 has not recovered from The Great Decline of 2015-2017 the way other metrics have.</p><p><strong>Meaning of the Graphs</strong></p><p>I plotted graphs for each activity type (posts, comments, votes, and views) and the corresponding population of users which engages in those activities. For each user engaging in each activity type, I calculated the “age” of that account since it first engaged in that activity type, i.e. in the graph for users who post, the age of the user account in a given month is the number of days elapsed since that account first posted. In the graph for commenters, is the days elapsed since the account first commented. This avoids certain complications which inconsistencies in how the data was recorded for different activities over LessWrong’s histories.</p><p>I segmented the user accounts into four “buckets” based on their “age” [since first engaging in activity of type X].</p><ul><li>0 - 90 days</li><li>90 - 360 days (~3 months to 12 months old)</li><li>360 - 720 days (~1 to 2 years)</li><li>720 - 10,000 days (~2+ years )</li></ul><p>When I’ve said <em>new </em>user accounts, I have been meaning 0 - 90 days; when I’ve said old users, I’ve meant the 720+ days bucket.</p><p>Caveat: we believe that many old users created new accounts when LW2 launched and this is somewhat confounding the data, though not necessarily a lot.</p><p><strong>Reading the Graphs</strong></p><ul><li>X-Axis is time</li><li>Values plotted are the total values for each month</li><li>Y-Axis is about the <em>number of individuals engaging in a behavior in a given month</em>, e.g there ~600 people who viewed posts, 30% of which have had less 90 days elapsed since they were first recorded viewing a post as a logged-in user***.</li><li>In each set of graphs by activity:</li><ul><li>The first set (2x2) shows a time series line for each age bucket segment alone.</li><li>The second long graph shows an area plot time series with age buckets segments stacked. This lets you see overall size of the population engaging an activity type over time.</li><li>The third graph is a 100% area plot which shows the composition of the overall population by “age” of the user accounts over time.</li></ul><li>A moving-average filter of three time months has been applied for smoothing.</li></ul><p><strong>***</strong><em>All data here is from logged-in users!!! Including views. View counts of non-logged in users are over an order of magnitude higher.</em></p><h2>Poster Distribution of Age</h2><p><em>Questions and posts with 2 or less upvotes have been filtered out. Event/meetup posts have not.</em></p><p><figure><img src=""https://lh5.googleusercontent.com/zYvTIb70zTeHmjDN1cJiNd1rz2MS-1vYsxNIR7DzHRiGCfcPZJuC-3pvHgR6xQNMFrOyypu1hhjLM6otldvh4aocT4S-wAW7eCbCaFZ7YMYVLRampbtQZtX5VgKIpXDjuW9zPUSe"" class=""draft-image "" style=""width:622%"" /></figure></p><p><figure><img src=""https://lh3.googleusercontent.com/ZSw4OGklfGqn__CZNghWQeqg8wO4LIBRuO5ZeMF8d9D1dmk4-Ru9iUm-77qHgl1qxrjYdDfHIaSpe3ZJHy0gtRYqKMAa1P6xVjr-zfRjdeuOBpdG2-Fpgy_61GgzTf447zvsydm_"" class=""draft-image "" style=""width:640%"" /></figure></p><p><figure><img src=""https://lh3.googleusercontent.com/g8ePmMhHA3P6PlVAKd_EssuFT1sKCEWR-FAURWRdu20qdaE8KIiEG5yEagVHEHVX9Zw-NnPWLgLzEEkwZwMlFBlJqgigJQqoydIB30NToGhs0PZ3ZmHOwj-526HrWF4uXu9ZnpPp"" class=""draft-image "" style=""width:634%"" /></figure></p><p>In addition to our primary focus on the age distribution of accounts, we can note the inflection point occurring in September/October 2017. This corresponds to the launch of the <u><a href=""https://www.lesswrong.com/posts/SR8cqwbMLmKqR7p5s"">LessWrong 2.0 Open Beta</a></u> 9-20 and publishing of Eliezer’s <u><a href=""https://www.lesswrong.com/s/oLGCcbnvabyibnG9d"">Inadequate Equilibria</a></u> on LW* on 10-28. I have marked 2017-10-01 on the graphs with a dotted black line. </p><p>*The LW2 team requested Inadequate Equilibria be published on LW2 as an initial draw.</p><p>We see from these graphs that the number of users making posts each month is almost as high (~75%) as historical levels, especially those after 2013. </p><p>Unsurprisingly, over time more profiles fall into in the “2+ year since their first post” bucket since the longer LW has existed, the more profiles which are at 2+ years can exist. Percentage of users posting with accounts less than 90 days since first post (this includes their first post) has remained almost constant over time with the exception of during the decline period 2015-2017.</p><p>A small aside: it’s interesting to note that the nature of posts has shifted somewhat. The median post length on LW2  (~1000 words) is double that from old LW (~500 words). Main posts were on average much longer than Discussion posts (median ~1000 words vs ~300 words). The distribution of post length on LW2 almost exactly matches that LW’s Main section despite having far more posts. The net result is that at least many total words of posts are being written on LW2 compared to legacy LW.</p><p><em>Inserting some analysis from a few months ago. I haven’t re-checked this before including though, so slightly higher chance that I messed something up.</em></p><p><strong>Post Length Distributions for LW1 Discussion, LW1 Main, and LW2</strong></p><p><figure><img src=""https://lh6.googleusercontent.com/Ub89xuLECD13Cm3yWDlznymhrOQNul9-FgcQtTQD9XE8qFED74vLKw9fJYHyh6juaKQvZQGhX-kgkECtjY3_55HzhT2YPESMzFnVHj7CyKkxhC1k2EtsnJ8WgkLPy9hiiM-7KDRY"" class=""draft-image "" style=""width:250%"" /></figure></p><p><em>Word count is naively calculated as character count divided by 6, hence the fractional values.</em></p><p><figure><img src=""https://lh6.googleusercontent.com/MI0YT8d5GI9XrZERMgYiSLM4PeoUAimXfeOjka2PfaTMBxDPTXgQQtmgoAk7acGkBz0TsNU-8Td9aLQkikOKo4648ufuVvUr8a9gTzEcEnIlXuF3kA7V4SFpDz9TA9O4R7FfKATI"" class=""draft-image "" style=""width:481%"" /></figure></p><p>I vaguely suspect that the shift in post length signifies a change in how LessWrong is used and that this is related to the large reduction in comment volume (see next section). A hypothesis is that old LW used to be used for some of the same uses as Facebook and other social media currently fulfils for people, and that new LW2 is now primarily serving some other need.</p><h2>Commenter Distribution of Age</h2><p>The graphs for commenters reveal a significant reality for LW2: while post, vote, and view have resurged since The Great Decline of 2015-2017, commenting levels have not returned to anything near historical levels.  Since the LW2.0 launch, the percentage of commenters who are new commenters are at its highest levels since 2013 while commenters who began commenting 2+ years ago has been steady at 50% of commenters. The topmost left graph (blue line) shows that there were no new users commenting in the period before LW2 but that this changed with the launch of LW2 and Inadequate Equlibria.</p><p><figure><img src=""https://lh5.googleusercontent.com/vVZSyzJZPSGVlDtY4Q9BjjNfFNW9_gx3LM5DJF29fdtmBR9lR8youE2nYuHnLdJk1fhUExzVQ8FDO6ISGRvynomUcJhGaFED_ZSpXzjKVddmKSX1nJ0wBlZKiinoUwK7kxpvHDiC"" class=""draft-image "" style=""width:635%"" /></figure></p><p><figure><img src=""https://lh6.googleusercontent.com/ImK-ulF6s-pvLWGPlIVSdybcM86eJNhX13ei_PMboGfnpzQtqdzUv-Gsm2S2HV12OKzXgMoLjtGnaWhSjMVh56J31YNK_D_QA2J42ITbXWOCU87cSaaxaggV30NxYSGk0KDvarfO"" class=""draft-image "" style=""width:631%"" /></figure></p><p><figure><img src=""https://lh3.googleusercontent.com/SMz-mSmuLkURoXRKSS8eBI3orfQSD_K1FTUWCiNc8qPhdiwY962BYecESAfZt2_ptuLfFO3V-Y6HgkpEflVzvK4ptNzLqcK7hDH3Kfz30hdhgbbVg4F2eCt7kuIX1unA-xHifbX6"" class=""draft-image "" style=""width:634%"" /></figure></p><h2>Voter Distribution of Age</h2><p>The graphs for population of voters tell an interesting tale. There has been a dramatic increase in the number of new users voting while the number and proportion of accounts who first voted 2+ years ago has stayed almost steady/declined a little. The net result is that voters who first voted within the last two years are making up 60% of the voting population. (The effects on overall karma distributed can’t be straightforwardly inferred from this alone since it will depend on how many votes each user makes and their karma scores.)</p><p><figure><img src=""https://lh5.googleusercontent.com/ZL-ViPPoSeWtTnY3-gcOJhVizb2kMkUoBRc0gVLSRm9AjE8OOjX-yc8bFuZRIzcCT5qQh7qSgB-c09avqxYhgEnfuGBzGwlCvPTcCec3bKtkbFzCCmCyB5rRq7wZOpUjk-RRRoSm"" class=""draft-image "" style=""width:640%"" /></figure></p><p><figure><img src=""https://lh5.googleusercontent.com/mPMgHKeQuHICYFcvG4oChXXmv8F-aURo0GzyCTvxBIqOfc4yHt8SYqfVG5-vx7JLmjiQUqJBB0AVXb1sA1EvJ5CrWmWg6dhNKcMEF7_3ToGZma13COv1lghSRDNJE4tNEj2JDt1s"" class=""draft-image "" style=""width:635%"" /></figure></p><p><figure><img src=""https://lh3.googleusercontent.com/z1p7spJSfBwYaG4c5-n5gJiUQ_JBWwEVLaYjWEJrtrIsE_FrRrPKvYFJPX1uRmE-eC5UkXKeChF26J8PuhRgAUZTf-Gjpyesdq4qFLPpWcqmLrfVKq0mJb1Z8aLjZ1249nVRPWFe"" class=""draft-image "" style=""width:640%"" /></figure></p><h2>Logged-In Viewer Distribution of Age</h2><p>The distribution of user account age for logged-in viewers is similar to that for votes. Large uptick for new accounts, yet no growth among older user accounts. The data here however is “compromised” since in March 2018 all users were logged-out. Users who failed to login again (which is unnecessary if you are not posting, commenting, or voting), would no longer be detected. The drop in logged-in viewer population can be seen in early 2018, particularly in the 2+ year plus time series (red line). After that point, it is mostly flat similar to the case for voters.</p><p><figure><img src=""https://lh4.googleusercontent.com/ubrMSj6u8OnvbYK_f1P9l3i0aLb882pg_sQrTUwGfYdcgZvehrpmnmvNs3gA3G4BHRCIQfagOqurrIS_NE6KT1wp3n7tJPmFfg4YE1v0WXWOqRnEyNbFTTzNYOdarhr8itpmuUIP"" class=""draft-image "" style=""width:640%"" /></figure></p><p><figure><img src=""https://lh5.googleusercontent.com/qZhzmbOu5QzVeREyIlfvsE43vt5mhszhdqVBeBOe6HGKePcRS3uPvVI3ohYzwX5z_eaM7tMeVRkh3KVSkhNfqXbioVNnl8i28CoatIUzEDyrZU35A6EXdKc-k3eJYjW5ZkN9ggJF"" class=""draft-image "" style=""width:635%"" /></figure></p><p><figure><img src=""https://lh6.googleusercontent.com/JYvbtuE9sTe0tQHUIMr_HLiP_YNoM1Yyz0CTT36RBu8L_pQAw55D2ICivRjIaAl-6ihw8BQY0Crbcf9tg_wvwILpFoOH8DXisE53I8O5hSzVFHxy6i3NEvmmDET1jy9CS9yi4wkY"" class=""draft-image "" style=""width:640%"" /></figure></p><h1>Concluding Thoughts</h1><p>It’s heartening to see that LW2 has made a difference to the trajectory of LW. A site which was nearly put into read-only archive mode is definitely alive and kicking. Counter to my fears, LW2 is drawing in new users rather than purely being sustained by a committed core of older users from LW1. This is despite not yet focusing on recruiting new users, e.g. via promotion of content on social media. </p><p>However, the rate of new users which come on is matched by the number of users failing to return (be they older users or new users who aren’t sticking around). Overall, most of the straightforward analytics metrics for LW have not grown significantly since its launch. I suspect that if we understand what is going on with retention, we might be able to hold onto more of the new users and actually cause upwards growth. . . . assuming we want that. I and others on the team don’t blindly believe that growth for the sake of growth is good. We’ll continue to think carefully about any actions we might take that even if they caused “growth”, might cause LW2 not to be the place we want it to be.</p><p>I’ve only had a very cursory look at retention. I found that new users were returning in the first month after signing up at historical levels (~30%), but that retention three months after joining is less than half of historical levels (~20%-&gt;%5). This is odd. However, these numbers are only from a cursory glance and I haven’t been very thorough yet either in coding mistakes or even thinking about it right.. This paragraph is low confidence.</p><p>Another point is that users of LW2 don’t use the site, on average, as much as they did during LW’s peak. Up to 2014, the median user was present on LW for 4-5 days each month (i.e. 4/31 days); in the last couple of years that has been 2-3 days. This might correspond to fewer people commenting since being engaged in ongoing comment threads might keep people coming back. The team is curious how a revamped email notification system (currently under development) will affect frequency of visiting LW.</p><p>Lastly, and I think it’s okay for me to say this, is that many of the most significant contributors to LW in the past are still present on the site - lurking - even if they post and comment far less. (I will soon write a post on how we use user data for analytics and decision-making; rest assured we have an extremely hard policy against ever sharing individual user data which is not public.) I think it’s a good sign that LW2 is generating enough content and discussion that these users still want to keep up date with LW2. It makes me hopeful that LW2 might even become a (the?) <u><a href=""https://www.lesswrong.com/posts/8rYxw9xZfwy86jkpG/on-the-importance-of-less-wrong-or-another-single"">central place of discussion</a></u>. </p><h1>For those interested in working with LessWrong data</h1><p>To protect user privacy, we’re not able to grant full-access to our database to the public, however there might be more limited datasets which we can release. If there’s enough interest, I’ll discuss this with the team.</p>",Ruby,ruby,Ruby,
ZruTAjyxR8Tm3NPwS,"Boo votes, Yay NPS",boo-votes-yay-nps,https://www.lesswrong.com/posts/ZruTAjyxR8Tm3NPwS/boo-votes-yay-nps,2019-05-14T19:07:52.432Z,29,11,19,True,False,,"<h1>TL;DR</h1><p>Many votes on LW are ""boos"" and ""yays"", and consequently they aren't very useful for determining what is worth reading. A modified version of a Net Promoter Score (NPS) on each post may provide a better metric for determining read worthiness.</p><h1>Motivation</h1><p>It's come up a couple time in my <a href=""https://www.lesswrong.com/posts/xYav5gMSuQvhQHNHG/#FXTSnPMknHeeWWHpK"">recent</a> <a href=""https://forum.effectivealtruism.org/posts/RiteyfxEiRHNDsZHj/why-we-should-be-less-productive#657CAwPS46f4rtHgB"">comments</a> that I've expressed a theory that votes on LW, AF, and EAF are ""boos"" and ""yays"". I have an idea about how we could do better assuming the purpose of votes is not to jeer and cheer but to provide information about the post, specifically how much the post is worth reading, so I'm finally writing it up so others can, yes, boo or applaud my effort, but more importantly so we might discuss ways to improve the system. If you don't like my proposal and agree we could do better than votes, I encourage you to write up your ideas and share them.</p><p>So, there are many things votes could be for, but I view votes as a solution to a problem, so what's the problem votes are trying to solve? The number one question I want answered about every post is some version of ""<strong>should I read this?</strong>"". There's subtly different ways to phrase this question: ""is this worth engaging with?"", ""should I read this carefully or just skim it?"", ""is this worth my time and energy?"", etc.</p><p>I want a solution to this problem because when I come to LW/AF/EAF every day I want a reliable signal about what it's worth me spending my energy engaging with (I generally don't want to just read, but also comment, discuss, understand, grow). Right now votes don't provide this to me, as I'll explain below, but they do provide other things. So keep in mind that my goal in this proposal is primarily to solve the particular problem of ""should I read this?"" and not the many other problems votes might be solutions to like ""how to deliver simple positive/negative feedback?"", ""how can I express my pleasure or displeasure with a post?"", ""how do we determine status within the forum?"", or ""how do we increase platform engagement?"". I don't ignore these other purposes, but I take them as secondary—and maybe there's other purposes I forgot to list and so forgot to take into account! The point being I want it to be clear I'm making a proposal that's trying to solve a particular problem, and if you complain ""but wait, it doesn't solve this other problem"" my response will be ""yep, sure doesn't"", so any discussion of this sort should be sure to explain why we should care about this other thing.</p><p>Okay, all that out of the way, let's talk about votes, and then NPS.</p><h1>Boo Votes</h1><p>Up/down voting is very simple and has a long history on LW, thanks to its presence on Reddit (from which, if I recall correctly, the original forum's codebase was forked). It has a number of nice features, and LW has made them nicer:</p><ul><li>everyone knows how it works</li><li>it lets you express yourself in two ways (unlike on Twitter where the only option is to vote up something, and a ""downvote"" requires writing your own tweet expressing dislike)</li><li>the aggregate votes on a post can be used to generate a user score (karma)</li><li>the user score can be used to meter access to various site features</li><li>votes are proportional the status of users, as measured by karma</li></ul><p>And of course lots of popular forums of all sorts use votes: Facebook, Twitter, Reddit, Tumblr. Even when votes aren't present something like voting is in the form of ""reacts"" where a person can choose from a list of named images/sounds/etc. to express something and that something generally can include a simple vote (usually using a universally recognized vote react, like thumbs up/down); cf. Slack, Discord, most massively multiplayer games, Twitch. So it would seem that people like votes a lot and they are used to some effect in lots of places.</p><p>Unfortunately for our purposes of trying to figure out ""should I read this?"", most of what votes are doing is only indirectly engaged with this question. Votes, especially if we think of them as a degenerate case of reacts, are more used to express an opinion on the content than to determine whether or not the content is worth reading, and when there are two voting options they tend to be rounded off to <em>down = boo</em> and <em>up = yay</em>. If you have any doubts about this, just spend more time on social media and let me know if you still disagree in general, i.e. you disagree that most people do this, not that you don't do this or your small group of friends don't do this.</p><p>On that point of using votes for something else, it's tempting to think ""hey, this is LW; we're rational AF; we know better than to use votes as boos and yays"". To which I say ""please, tell us more about how you've managed to create a community of perfectly rational agents"".</p><span><figure><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675286348/mirroredImages/ZruTAjyxR8Tm3NPwS/empyalienn4lnkj7av0d.jpg"" class=""draft-image center"" style=""width:40%""></figure></span><p>Joking aside, my point is that I've been on the receiving end of all kinds of voting patterns, so I've gotten a chance to see how people use votes on LW. Further, I've talked to people about my posts (either in comments or elsewhere) and in some cases explicitly learned how they voted on my posts and why, and it's lead me to a few conclusions about how people use votes here.</p><ul><li>Sometimes votes are attempts to increase or decrease visibility of something, regardless of how someone feels about what's in a post or comment.</li><li>Sometimes votes are a genuine expression of ""you should/shouldn't read this"".</li><li>Most often votes say ""yay, I like this"" or ""boo, I don't like this"" in response to one of several thing:</li><ul><li>like/dislike the author</li><li>like/dislike the subject matter</li><li>like/dislike the content</li><li>like/dislike the presentation</li></ul></ul><p>The result is what I consider a lot of voting anomalies from the perspective of trying to answer the question ""should I read this?"". Some claims of things I've seen (I won't link specific posts because I don't want to risk applying shame to anyone for what happened to their post in the votes, and also it's a lot of work to dig up all the examples that caused me to form these beliefs):</p><ul><li>Low content/quality posts voted highly because people like the author</li><li>High content/quality posts voted lowly because people dislike the author</li><li>Posts voted down for heresy, regardless of quality</li><li>Posts voted up for applause lights, regardless of quality</li></ul><p>My personal experience is mainly with writing <a href=""https://www.lesswrong.com/posts/5LP6Jc8ztwcyb296X/outline-of-metarationality-or-much-less-than-you-wanted-to"">heretical</a> <a href=""https://www.lesswrong.com/posts/7HY8HaRdFFnpeT9gx/highlights-from-integral-spirituality"">posts</a> of good quality such that I get more up votes than down but also a lot of down votes (maybe 1/3 down and 2/3 up), and it caused me to pay more attention to voting patterns, engage more with low score posts, and try to figure out just what was going on when posts got low scores that I gave upvotes. What I learned lead me to surmise what I've presented above.</p><p>So votes seem to be largely used to signal approval and disapproval of posts, which I suggest is only weakly correlated with telling me whether or not I should read a post. As a result I basically ignore votes and have to skim everything to figure out where the good stuff is. But what if we could do something better...?</p><h1>Yay NPS</h1><p><a href=""https://en.wikipedia.org/wiki/Net_Promoter"">Net Promoter Score</a> (NPS) is a simple metic many companies use to evaluate questions of customer satisfaction. To calculate it people are asked ""how likely are you to recommend our product or service to a friend or colleague?"" and asked for a number from 0 to 10, 0 meaning ""not likely at all"" and 10 meaning ""already have"". I really like NPS because it asks people to imagine recommending something and then asking them for something like a probability of how likely they are to do it, although I've never seen a version that did this explicitly.</p><p>Responses are then <a href=""https://www.netpromoter.com/know/"">converted</a> into a score by first segmenting respondents into detractors, passives, and promoters, and then taking percent promoters minus percent detractors. I find this metric to be of limited value, and more prefer to engage directly with the full distribution of responses, but if you really needed a single scalar this is one way to get it.</p><p>What I imagine doing is asking people to score posts like this:</p><p><em>How likely are you to recommend a friend or colleague read this post?</em></p><p><em>|--0%-------------50%-------------100%--|</em></p><p>So they are asked the question and given a slider to mark their likelihood, which includes 100% because they may have already shared it (but there's probably some UI work here to make it clear that 100% and 99% are drastically different responses).</p><p>Does this answer our question ""should I read this?""? I think it may do a better job than votes, to be sure. Rather than an ambiguous vote, people are now at least being asked to respond directly to a question and give their response to it. Also, we could better use the distribution of responses to make reading decisions. For example, heretical posts might get bimodal distributions of scores, with clusters of strong detractors and strong promoters, and maybe you choose to read a post when it has at least <em>n</em> promoters, regardless of detractors. Maybe you choose to filter out posts with more than <em>n</em> detractors because you don't like controversy or low quality content. Maybe you filter on NPS or mean or median or something else, or sort based on it. And every post, rather than showing a simple number for its score like we do now you show a box-plot or some other suitable visualization showing the distribution of responses.</p><p>Now unfortunately NPS is more complicated than votes, so it may work against other problems people are trying to solve with votes. How does NPS help us deal with the problems addressed by karma? How do we prevent NPS from devolving into a binary where people always vote 100% to upvote and everything else is a downvote (the eBay/Uber/Lyft voting problem, where anything less than 5-stars is considered a downvote)? And do we measure comment quality with NPS, or keep votes there, or do something else?</p><p>I also don't really expect the LW team to drop everything and implement NPS. Heck, if I were working on LW I probably wouldn't jump all over this. My goal in writing this, maybe more than anything, is to get us thinking about how to better answer the question ""should I read this?"" and I wanted to provide at least one solution I've thought of and think could be better in some ways. I mostly think we could do more to give better signals of quality on LW and make them less distorted by and engaged with other signals people try to send with votes.</p><p>So, what do you think of the current state of votes? What problems do you want to solve on LW that votes or something else may be solutions to? And how would you improve votes or something else to solve those problems?</p>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
fYRh8q49Puque75g9,Eight Books To Read,eight-books-to-read,https://www.lesswrong.com/posts/fYRh8q49Puque75g9/eight-books-to-read,2019-05-14T17:40:00.867Z,69,25,11,False,False,,"<span><figure><img src=""https://cdn-images-1.medium.com/max/1024/1*1a_94bBPtyT39enFMJDfzA.jpeg"" class=""draft-image "" style=""width:40%""></figure></span><p><em>This article was originally published on SamoBurja.com. You can</em> <em><u><a href=""http://samoburja.com/eight-books-to-read/"">access the original here.</a></u></em>   </p><p>A few years ago, I was asked by a friend what news sources they should follow to understand the Syrian Civil War. I replied they shouldn&#x2019;t follow any news at all. My recommendation instead was a six month break from Syrian news, supplemented by leisurely reading through six books on Syrian politics, economics, and culture. I pointed out they could read them on their phone just as conveniently as they could read tweets or articles. My friend was taken aback but followed the&#xA0;advice.</p><p>Critiques of news media are much more in vogue now than they were in 2015. People bemoan the poor factual accuracy or manifest political bias of today&#x2019;s media, whether that means established newspapers like The New York Times or social networks like Facebook. But there is a more fundamental problem with news: it can provide information, but isn&#x2019;t structured to educate you into someone who could understand this cherry-picked information. Formal education often fails to provide this vital foundation.</p><p>After six months, my friend thanked me. They said they now barely follow any news on Syria, but when they do it has gone from perplexing to understandable. The fragments of information no longer landed only as emotional bursts of excitement or anxiety, but rather helped contribute to a solid picture of the region. They asked me a more difficult question: what books should they read to understand not just Syria, but global society as a&#xA0;whole?</p><p>Books are incomplete instruments for instruction. They don&#x2019;t respond to the reader and cannot directly answer questions, and they require a strange and systematic process of study that goes beyond mere reading. In physics education, for example, one will pair up the mastery of theories with tests of solving mathematical puzzles as well as a course of practical experiments that tie those to one&#x2019;s senses. For the study of society, there would have to be analogues.</p><p>Further, true autodidacticism is a rare gift. To maintain motivation over a few months, learning has to be its own reward. This reward of learning must somehow be tied to understanding the world as it is, rather than pursuing theories for the sake of entertainment.</p><p>Much has happened throughout human history, and much is happening right now. Too much to ever fully catch up on. The focus should rather be on equipping someone with the theory and skills needed so they will process, absorb, and retain the information they encounter throughout their intellectual lives. This merits a methodological approach tailored to individual investigation and practical application.</p><p>The order in which one reads also matters. Important parts of certain books are unlocked by the understanding gained from another. This is obvious for disciplines like theoretical physics, but the same goes for a serious study of&#xA0;society.</p><p>While I have made it my core area of research, I can&#x2019;t claim to fully understand society. All I could do was try to think of the most efficient way to acquire a measure of competency in the areas I&#xA0;pursued.</p><p>So with those caveats, I gave him a list of the sequence of books I recommend reading:</p><ol><li><strong><a href=""https://www.amazon.com/How-Read-Book-Classic-Intelligent/dp/0671212095/ref=sr_1_1?keywords=how+to+read+a+book&amp;qid=1557692192&amp;s=gateway&amp;sr=8-1"">How to Read a Book</a>&#x200A;&#x2014;&#x200A;Mortimer&#xA0;Adler</strong></li></ol><p>This book convinced me that while skimming was perhaps useful for mining information, it would never be a viable path to rigor. Adler advocates a disciplined and deep reading of challenging books. The book lays out a systematic method that, if followed, notably increases the skill of reading comprehension to the level of most graduate programs, improving one&#x2019;s ability to learn from books. You can then afford to read more slowly because you gain more information from each reading. This is a necessity for the systematic study of society. Examples of books you&#x2019;ll want to read in such an intellectual pursuit are primary sources for case studies, books laying out political theory, economics, as well as the other books on this list. He wrote this book in the 1950s as his attempt at an antidote to shortening attention spans. Unfortunately, in the age of social media, we need his remedy much more than he could have possibly imagined.</p><p>2. <strong><a href=""https://www.amazon.com/Republic-Hackett-Classics-Plato/dp/0872201368/ref=sr_1_4?keywords=plato+republic&amp;qid=1557693705&amp;s=gateway&amp;sr=8-4"">The Republic</a>&#x200A;&#x2014;&#x200A;Plato</strong></p><p>A design for the creation of a new ideal society, the ultimate aim of sociological investigation. Plato&#x2019;s work is a nice example of both the strengths and the limits of a theory-driven approach. The book not only lays out the major research tasks needed to engineer such a society, but lays out a plan to construct it.</p><p>He introduces a decent theory of psychology, allowing for some basic predictions of how people will respond to changes in their social and material circumstances. The model of learning introduced is among the best I&#x2019;ve&#xA0;found.</p><p>The quality of his models is sufficient to be worth knowing and occasionally using. His variant of the theory of <a href=""https://en.m.wikipedia.org/wiki/Kyklos"">cycles of social transformation</a>, of how city states change between regimes of status- and emotion-driven regulation and their related political constitutions, remains predictive. The theories of psychology, education, and society are tied together into a theory-driven design for an&#xA0;elite.</p><p>The practicality of this book as a manual for such efforts is underrated. As an example, it illustrates how to dialogue under adversarial circumstances. This is useful for both for your own ability to manage information, and your ability to successfully interpret texts produced under such circumstances.</p><p>3. <strong><a href=""https://www.amazon.com/History-Peloponnesian-War-Thucydides/dp/0140440399/ref=sr_1_3?keywords=history+of+the+peloponnesian+war&amp;qid=1557692379&amp;s=gateway&amp;sr=8-3"">History of the Peloponnesian War&#x200A;</a>&#x2014;&#x200A;Thucydides</strong></p><p>The ultimate primary source. Thucydides fought as a general during the Peloponnesian war and was ultimately exiled from Athens due to political machination. After the end of the war, he spent his energies and wealth to follow up on the connections, both friend and foe, he had built. He thought the role of a historian was to chronicle and competently navigate the era in which he lived to preserve its lessons for the future. Because Thucydides was a practitioner, and one who played a critical role in the events described, his account should be taken seriously.</p><p>A clear enough demonstration of excellent analysis, such that one can productively use his approach as a prototype. He successfully combines information sources such as interviews, texts, and personal experience of war and politics. This is then paired with the skilful application of theoretical constructs to analyze a concrete circumstance.</p><p>4. <strong><a href=""https://www.amazon.com/Politics-New-Translation-Hackett-Aristotle/dp/1624665578/ref=sr_1_6?keywords=politics+aristotle&amp;qid=1557693738&amp;s=gateway&amp;sr=8-6"">Politics</a>&#x200A;&#x2014;&#x200A;Aristotle</strong></p><p>Classical sources credit Aristotle with 170 &#x201C;constitutions&#x201D;, that is, research papers describing the political structure and society of various Greek city-states. Many of these constitutions were likely written or drafted by his students. Of this extensive empirical research done in preparation for the Politics, the only constitution preserved is that of <a href=""https://en.wikipedia.org/wiki/Constitution_of_the_Athenians_(Aristotle)"">Athens</a>. This marriage of empirical data and philosophy proves hard to&#xA0;beat.</p><p>Aristotle&#x2019;s observations on Greek society should round out what was learned following Thucydides&#x2019; exhaustive account and help complete a basic understanding of a period of history one can then reason about. Further, an alternative frame of analysis of Greek politics allows for comparison with Thucydides&#x2019; often cynical explanations.</p><p>Aristotle critiques a number of Plato&#x2019;s ideas, which should improve your understanding of the Republic, help you learn how to identify potential sociological reasoning flaws, and illustrate how to refute a sociological theory.</p><p>He demonstrates how to translate the analysis of social roles and professions into a generalized analysis of a society. Sociologists and economists have divorced the two, but they are inseparable when done well. This forms the basis of class analysis as used by later thinkers like Smith, Marx, and&#xA0;Veblen.</p><p>It is rare for a social scientist to examine social technology as lucidly. For example, the Aristotelian account of hierarchy and why it arises is superb. The conceptually clean distinctions between the different forms of interpersonal coordination can greatly augment one&#x2019;s ability to navigate and study such patterns.</p><p>Finally, as an example of a good scientist and philosopher, he can be used to help understand scientists and philosophers in&#xA0;general.</p><p>5. <strong><a href=""https://www.amazon.com/Book-War-Sun-Tzus-Karl-Clausewitzs/dp/0375754776/ref=sr_1_9?keywords=on+war+von+clausewitz&amp;qid=1557692938&amp;s=gateway&amp;sr=8-9"">On War</a>&#x200A;&#x2014;&#x200A;Carl von Clausewitz</strong></p><p>Clausewitz was a Prussian staff officer in the wars against Napoleon and later became an influential military theorist. Good military theory is rarely spread publicly, but Clausewitz&#x2019;s wife was a prominent noblewoman who published his magnum opus after his&#xA0;death.</p><p>His work provides a demonstration of excellent theoretical sociological methodology, especially as regards the proper use of case studies, how to tell the general from the particular, and how to tell the fundamental from the subordinate.</p><p>Clausewitz&#x2019;s model of how armies function provides a foundation for understanding the methodology and conclusions of Great Founder Theory as applied to the military.</p><p>This book shows how an essentially philosophical approach can be brought far enough to be practically useful.</p><p>6. <strong><a href=""http://samoburja.com/wp-content/uploads/2019/01/Great-Founder-Theory-v-1.43.pdf"">Great Founder Theory</a>&#x200A;&#x2014;&#x200A;Samo&#xA0;Burja</strong></p><p>A work in progress, but a decent introduction. This explains my current sociological paradigm.</p><p>7. <strong><a href=""https://www.amazon.com/Evolution-Civilizations-Carroll-Quigley/dp/0913966576/ref=sr_1_1?crid=11V9HFQBJUO2V&amp;keywords=the+evolution+of+civilizations+by+carroll+quigley&amp;qid=1557693785&amp;s=gateway&amp;sprefix=the+evolution+of+civilizations%2Caps%2C189&amp;sr=8-1"">The Evolution of Civilizations&#x200A;</a>&#x2014;&#x200A;Carroll&#xA0;Quigley</strong></p><p>This book provides a good macro theory of civilization. Much of the pre-historical speculation can be skipped, but the overviews of historical civilizations provide an example of first-rate institutional analysis.</p><p>Quigley&#x2019;s career demonstrates an excellent piece of sociological methodology around gathering information to test your theory: he builds a theory that emphasizes the importance of elites, and subsequently goes and talks to members of the elite to test and apply the theory. Note, however, that he is not a practitioner, so his usefulness as an exemplar who tests and acts on their theory is somewhat&#xA0;limited.</p><p>8. <strong><a href=""https://www.amazon.com/Persecution-Art-Writing-Leo-Strauss/dp/0226777111/ref=pd_sbs_14_1/136-8067882-7141949?_encoding=UTF8&amp;pd_rd_i=0226777111&amp;pd_rd_r=c0e83189-74f6-11e9-acff-01df0530b2b5&amp;pd_rd_w=hW20w&amp;pd_rd_wg=ezj50&amp;pf_rd_p=588939de-d3f8-42f1-a3d8-d556eae5797d&amp;pf_rd_r=EBEXVKD3W90ND2JH3KPA&amp;psc=1&amp;refRID=EBEXVKD3W90ND2JH3KPA"">Persecution and the Art of Writing</a>&#x200A;&#x2014;&#x200A;Leo&#xA0;Strauss</strong></p><p>Thinkers can provoke social or legal penalties in all societies. An important way to avoid attack that can derail a career, intellectual project, or a life is to learn to write between the lines. Leo Strauss&#x2019; work helps you learn improved text interpretation procedures by teaching you to read between the lines, representing a good upgrade on what you learned from Adler. It is a very good practice to attempt a &#x2018;Straussian&#x2019; reading of a text even when there is no hidden message, since it entices to a higher level of information processing.</p><p>At this point, you can continue on your journey or recurse to reread Quigley, Plato, and Thucydides. Quigley writes obliquely and at a distance regarding Anglo-American elites. Thucydides is a political exile from Athens. While Thucydides is significantly freed from constraints and retribution, he will continue to have notable conflicts of interest and messaging agendas. Plato writes trickily for pedagogical purposes, intentionally setting challenges and puzzles for the reader, hoping the reader uses his text as an obstacle course to grow stronger.</p><p>Someone who makes it through this list, if they approach the texts with the rigor advised by Adler, will have the foundational understanding necessary for interpreting social events. They will be better equipped to do so than the vast majority of&#xA0;people.</p><p>The most important thing to be gained from these texts is a set of methodological tools, a way of thinking about and interpreting social events, that one can then use to generate one&#x2019;s own insights about society. These authors try to bridge the gaps between the practitioner, the theorist, and the empiricist. This is something a great sociologist must do. One of the most tragic flaws a historian can have is a myopic interest in events, rather than societies. The most tragic flaw of a social scientist is the ignorance of history that trivially rebuts the most beautiful statistically-derived or philosophically-derived theory of&#xA0;society.</p><p>Secondarily, these authors provide superb examples of what good sociology looks like, which can then be used to construct one&#x2019;s model of real expertise in this domain. This is critical for evaluating the host of supposed experts who claim to have an understanding of society that gives authority to their interpretations of events. Separating the wheat from the chaff is necessary for navigating the contemporary discourse without being&#xA0;misled.</p><p>Many others have since asked me for such lists, so I&#x2019;ve kept it around and shared it whenever my friends or acquaintances have asked for book recommendations. Now you have it. Will you take a break from the news to read and&#xA0;think?</p><p><em>Read more from Samo Burja</em> <em><u><a href=""http://samoburja.com/essays"">here.</a></u></em></p>",Samo Burja,samo-burja,Samo Burja,
DEYZE2236j4QX9oEu,Flashcards for AI Safety?,flashcards-for-ai-safety,https://www.lesswrong.com/posts/DEYZE2236j4QX9oEu/flashcards-for-ai-safety,2019-05-14T14:37:59.417Z,5,3,3,False,True,,"<p>I sometimes struggle to remember the contents of all the articles I&#x27;ve read on AI Safety. Spaced repetition might be helpful, but this requires someone to write flashcards. For Anki, I&#x27;ve found 2 decks, titled &quot;Superintelligence&quot; and &quot;AI Policy&quot;. </p><p>Do more AI Safety relevant decks exist? </p><p>What would be a good strategy for generating useful flashcards? </p>",soren-elverlin-1,soren-elverlin-1,Søren Elverlin,
hnLutdvjC8kPScPAj,Integrating disagreeing subagents,integrating-disagreeing-subagents,https://www.lesswrong.com/posts/hnLutdvjC8kPScPAj/integrating-disagreeing-subagents,2019-05-14T14:06:55.632Z,148,59,15,False,False,,"<p><u><a href=""https://www.lesswrong.com/posts/oJwJzeZ6ar2Hr7KAX/subagents-akrasia-and-coherence-in-humans"">In my previous post</a></u>, I suggested that akrasia involves subagent disagreement - or in other words, different parts of the brain having differing ideas on what the best course of action is. The existence of such conflicts raises the question, how does one resolve them?</p><p>In this post I will discuss various techniques which could be interpreted as ways of resolving subagents disagreements, as well as some of the reasons for why this doesn’t always happen.</p><h1>A word on interpreting “subagents”</h1><p>The frame that I’ve had so far is that of the brain being composed of different subagents with conflicting beliefs. On the other hand, one could argue that the subagent interpretation isn’t strictly necessary for many of the examples that I bring up in this post. One could just as well view my examples as talking about a single agent with conflicting beliefs.</p><p>The distinction between these two frames isn’t always entirely clear. In “<u><a href=""https://www.lesswrong.com/posts/3pKXC62C98EgCeZc4/complex-behavior-from-simple-sub-agents"">Complex Behavior from Simple (Sub)Agents</a></u>”, mordinamael presents a toy model where an agent has different goals. Moving to different locations will satisfy the different goals to a varying extent. The agent will generate a list of possible moves and picks the move which will bring some goal the closest to being satisfied.</p><p>Is this a unified agent, or one made up of several subagents?</p><p>One could argue for either interpretation. On the other hand, mordinamael&#x27;s post frames the goals as subagents, and they are in a sense competing with each other. On the other hand, the subagents arguably don’t make the final decision themselves: they just report expected outcomes, and then a central mechanism picks a move based on their reports. </p><p>This resembles the neuroscience model I discussed <a href=""https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/oJwJzeZ6ar2Hr7KAX"">in my last post</a>, where different subsystems in the brain submit various action “bids” to the basal ganglia. Various mechanisms then pick a winning bid based on various criteria - such as how relevant the subsystem’s concerns are for the current situation, and how accurate the different subsystems have historically been in their predictions. </p><p>Likewise, in extending the <u><a href=""https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain"">model from <em>Consciousness and the Brain</em></a></u> for my <u><a href=""https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model"">toy version of the Internal Family Systems model</a></u>, I postulated a system where various subagents vote for different objects to become the content of consciousness. In that model, the winner was determined by a system which adjusted the vote weights of the different subagents based on various factors.</p><p>So, subagents, or just an agent with different goals?</p><p>Here I would draw an analogy to parliamentary decision-making. In a sense, a parliament as a whole is an agent. Various members of parliament cast their votes, with “the voting system” then “making the final choice” based on the votes that have been cast. That reflects the overall judgment of the parliament as a whole. On the other hand, for understanding and predicting how the parliament will actually vote in different situations, it is important to model how the individual MPs influence and broker deals with each other.</p><p>Likewise, the subagent frame seems most useful when a person’s goals interact in such a way that applying <u><a href=""https://en.wikipedia.org/wiki/Intentional_stance"">the intentional stance</a></u> - thinking in terms of the beliefs and goals of the individual subagents - is useful for modeling the overall interactions of the subagents. </p><p>For example, in my toy Internal Family Systems model, I noted that reinforcement learning subagents might end up forming something like alliances. Suppose that a robot has a choice between making cookies, poking its finger at a hot stove, or daydreaming. It has three subagents: “cook” wants the robot to make cookies, “masochist” wants to poke the robot’s finger at the stove, and “safety” wants the robot to<em> not</em> poke its finger at the stove. </p><p>By default, “safety” is indifferent between “make cookies” and “daydream”, and might cast its votes at random. But when it votes for “make cookies”, then that tends to avert “poke at stove” more reliably than voting for “daydream” does, as “make cookies” is also being voted for by “cook”. Thus its tendency to vote for “make cookies” in this situation gets reinforced. </p><p>We can now apply the intentional stance to this situation, and say that “safety” has &quot;formed an alliance&quot; with “cook”, as it correctly “believes” that this will avert masochistic actions. If the subagents are also aware of each other and can predict each other&#x27;s actions, then the intentional stance gets even more useful. </p><p>Of course, we could just as well apply the purely mechanistic explanation and end up with the same predictions. But the intentional explanation often seems <u><a href=""http://www.overcomingbias.com/2008/08/use-the-native.html"">easier for humans to reason with</a>,</u> and helps highlight salient considerations.</p><h1>Integrating beliefs, naturally or with techniques</h1><p>In any case, regardless of whether we are talking about subagents with conflicting beliefs or just conflicting goals, it still seems like many of our problems arise from <em>some</em> kind of internal disagreement. I will use the term “integration” for anything that acts to resolve such conflicts, and discuss a few examples of things which can be usefully thought of as integration.</p><p>In these examples, I am again going to rely on the basic observation from <em>Consciousness and the Brain</em>: that when some subsystem in the brain manages to elevate a mental object into the content of consciousness, multiple subsystems will synchronize their processing around that object. Assuming that the conditions are right, this will allow for the integration of otherwise conflicting beliefs or behaviors.</p><p>Why do we need to explicitly integrate beliefs, rather than this happening automatically? One answer is that trying to integrate all beliefs would be infeasible; <u><a href=""https://www.lesswrong.com/posts/kD8uzcmjKwSaTHnQJ/compartmentalization-as-a-passive-phenomenon#CxHgLEMjrCDG5qKrs"">as CronoDAS notes</a></u>:</p><blockquote>GEB has a section on this.</blockquote><blockquote>In order to <em>not</em> compartmentalize, you need to test if your beliefs are all consistent with each other. If your beliefs are all statements in propositional logic, consistency checking becomes the <u><a href=""https://en.wikipedia.org/wiki/Boolean_satisfiability_problem"">Boolean Satisfiability Problem</a></u>, which is NP-complete. If your beliefs are statements in predicate logic, then consistency checking becomes PSPACE-complete, which is even worse than NP-complete.</blockquote><p>Rather than try to constantly integrate every possible belief and behavior, the brain will rather try to integrate beliefs at times when it notices contradictions. Of course, sometimes we <em>do</em> realize that there are contradictions, but still don’t automatically integrate the subagents. Then we can use various techniques for making integration more effective. How come integration isn’t more automatic?</p><p>One reason is that integration requires the right conditions, and while the brain has mechanisms for getting those conditions right, integration is still a nontrivial skill. As an analogy, most children learn the basics of talking and running on their own, but they can still explicitly study rhetoric or running techniques to boost their native competencies far above their starting level. Likewise, everyone natively does <em>some</em> integration on their own, but people can also use explicit techniques which make them much better at it.</p><h1>Resisting belief integration</h1><p>Lack of skill isn’t the full answer for why we don’t always automatically update, however. Sometimes it seems as if the mind actively resists updating. </p><p>One of the issues that commonly comes up in Internal Family Systems therapy is that parts of the mind want to keep some old belief frozen, because if it were known, it would change the person’s behavior in an undesired way. For example, if someone believes that they have a good reason not to abandon their friend, then a part of the mind which values not abandoning the friend in question might resist having this belief re-revaluated. The part may then need to be convinced that knowing the truth only leaves opens the <em>option</em> of abandoning the friend, it doesn’t <em>compel </em>it.</p><p>Note that this isn’t <em>necessarily</em> true. If there are other subagents which sufficiently strongly hold the opinion that the friend should be abandoned, and the subagent-which-values-the-friend is only managing to prevent that by hanging on to a specific belief, then readjusting that belief <em>might</em> remove the only constraint which was preventing the anti-friend coalition from dumping the friend. Thus from the point of view of the subagent which is resisting the belief update, the update <em>would</em> compel an abandonment of the friend. In such a situation, additional internal work may be necessary before the subagent will agree to let the belief revision proceed.</p><p>More generally, subagents may be incentivized to resist belief updating for at least three different reasons (this list is not intended to be exhaustive):</p><ol><li>The subagent is trying to pursue or maintain a goal, and predicts that revising some particular belief would make the person less motivated to pursue or maintain the goal.</li><li>The subagent is trying to safeguard the person’s social standing, and predicts that not understanding or integrating something will be safer, give the person <u><a href=""https://www.lesswrong.com/posts/tJQsxD34maYw2g5E4/thomas-c-schelling-s-strategy-of-conflict"">an advantage in negotiation</a></u>, or be <u><a href=""https://www.lesswrong.com/posts/BgBrXpByCSmCLjpwr/book-review-the-elephant-in-the-brain"">otherwise socially beneficial</a></u>. For instance, different subagents holding conflicting beliefs allows a person to verbally believe in one thing while still not acting accordingly - even actively changing their verbal model so as to <u><a href=""https://www.lesswrong.com/posts/CqyJzDZWvGhhFJ7dY/belief-in-belief"">avoid falsifying the invisible dragon in the garage</a></u>.</li><li>Evaluating a belief would require activating a memory of a traumatic event that the belief is related to, and the subagent is trying to keep that memory suppressed as part of an <u><a href=""https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model"">exile-protector dynamic</a></u>.</li></ol><p>Here’s an alternate way of looking at the issue, which doesn’t use the subagent frame. So far I have been mostly talking about integrating beliefs rather than goals, but humans don’t seem to have a clear value/belief distinction. As Stuart Armstrong discusses in his <u><a href=""https://www.lesswrong.com/posts/DLmhJbuhYek5rEhpH/mairy-s-room-ai-reasoning-to-solve-philosophical-problems"">mAIry’s room article</a></u>, for humans simply receiving sensory information often also rewires some of their values. Now, <u><a href=""https://www.facebook.com/Xuenay/posts/10158338174053662"">Mark Lippman suggests</a></u> that trying to optimize a complicated network of beliefs and goals means that furthering one goal may hurt other goals, so the system needs to have checks in place to ensure that one goal is not pursued in a way which disproportionately harms the achievement of other goals.</p><p>For example, most people wouldn’t want to spend the rest of their lives doing nothing but shooting up heroin, <em>even if</em> they knew for certain that this maximized the achievement of their “experience pleasure” goal. If someone offered them the chance to experience just <em>how</em> pleasurable heroin felt like - giving them more accurate emotion-level predictions of the experience - they might quite reasonably refuse, as they feared that making this update might make them more inclined to take heroin. <u><a href=""https://www.lesswrong.com/posts/synsRtBKDeAFuo7e3/not-for-the-sake-of-happiness-alone"">Eliezer once noted</a></u> that if someone offered him a pill which simulated the joy of scientific discovery, he would make sure never to take it.</p><p>Suppose that a system has a network of beliefs and goals and it does something like predicting how various actions and their effects - not only their effects on the external world, but on the belief/goal network itself - might influence its goal achievement. If it resists actions which reduce the probability of achieving its current goals, then this might produce dynamics which look like subagents trying to achieve their goals at the expense of the other subagents. </p><p>For instance, Eliezer’s refusal to take the pill might be framed as a subagent valuing scientific discovery trying to block a subagent valuing happiness from implementing an action which would make the happiness subagent’s bids for motor system access stronger. Alternatively, it might be framed as the overall system putting value on actually making scientific discoveries, and refusing to self-modify in a way which it predicted would hurt this goal. (You might note that this has some interesting similarities to things like the <u><a href=""https://www.lesswrong.com/posts/6bdb4F6Lif5AanRAd/cake-or-death"">Cake or Death problem</a></u> in AI alignment.)</p><p>In any case, integration is not always straightforward. Even if the system <em>does</em> detect a conflict between its subagents, it may have a reason to avoid doing so.</p><p>Having reviewed some potential barriers for integration, let us move on to different ways in which conflicts <em>can</em> be detected and integrated.</p><h1>Ways to integrate conflicting subagents</h1><h2>Cognitive Behavioral Therapy</h2><p>Scott Alexander <u><a href=""https://slatestarcodex.com/2015/07/16/cbt-in-the-water-supply/"">has an old post</a></u> where he quotes this excerpt from the cognitive behavioral therapy book <em>When Panic Attacks</em>:</p><blockquote>I asked Walter how he was thinking and feeling about the breakup with Paul. What was he telling himself? He said “I feel incredibly guilty and ashamed, and it seems like it must have been my fault. Maybe I wasn’t skillful enough, attractive enough, or dynamic enough. Maybe I wasn’t there for him emotionally. I feel like I must have screwed up. Sometimes I feel like a total fraud. Here I am, a marriage and family therapist, and my own relationship didn’t even work out. I feel like a loser. A really, really big loser.” [...]</blockquote><blockquote>I thought the Double Standard Technique might help because Walter seemed to be a warm and compassionate individual. I asked what he’d say to a dear friend who’d been rejected by someone he’d been living with for eight years. I said “Would you tell him that there’s something wrong with him, that he screwed up his life and flushed it down the toilet for good?”</blockquote><blockquote>Walter looked shocked and said he’d never say something like that to a friend. I suggested we try a role-playing exercise so that he could tell me what he would say to a friend who was in the same predicament […]</blockquote><blockquote><strong>Therapist (role-playing patient’s friend):</strong> Walter, there’s another angle I haven’t told you about. What you don’t understand is that I’m impossible to live with and be in a relationship with. That’s the real reason I feel so bad, and that’s why I’ll be alone for the rest of my life.</blockquote><blockquote><strong>Patient (role-playing as if therapist is his friend who just had a bad breakup):</strong> Gosh, I’m surprised to hear you say that, because I’ve known you for a long time and never felt that way about you. In fact, you’ve always been warm and open, and a loyal friend. How in the world did you come to the conclusion that you were impossible to be in a relationship with?</blockquote><blockquote><strong>Therapist (continuing role-play):</strong> Well, my relationship with [my boyfriend] fell apart. Doesn’t that prove I’m impossible to be in a relationship with?</blockquote><blockquote><strong>Patient (continuing role-play):</strong> In all honesty, what you’re saying doesn’t make a lot of sense. In the first place, your boyfriend was also involved in the relationship. It takes two to tango. And in the second place, you were involved in a reasonably successful relationship with him for eight years. So how can you claim that you’re impossible to live with?</blockquote><blockquote><strong>Therapist (continuing role-play:)</strong> Let me make sure I’ve got this right. You’re saying that I was in a reasonably successful relationship for eight years, so it doesn’t make much sense to say that I’m impossible to live with or impossible to be in a relationship with?</blockquote><blockquote><strong>Patient (continuing-role-play:)</strong> You’ve got it. Crystal clear.</blockquote><blockquote>At that point, Walter’s face lit up, as if a lightbulb had suddenly turned on in his brain, and we both started laughing. His negative thoughts suddenly seemed absurd to him, and there was an immediate shift in his mood…after Walter put the lie to his negative thoughts, I asked him to rate how he was feeling again. His feeling of sadness fell all the way from 80% to 20%. His feelings of guilt, shame, and anxiety fell all the way to 10%, and his feelings of hopelessness dropped to 5%. The feelings of loneliness, embarrassment, frustration, and anger disappeared completely.</blockquote><p>At the time, Scott expressed confusion about how just telling someone that their beliefs aren’t rational, would be enough to transform the beliefs. But that wasn’t really what happened. Walter was asked whether he’d say something harsh to a friend, and he said no, but that alone wasn’t enough to improve his condition. What did help was putting him in a position where he had to really think through the arguments for why this is irrational in order to convince his friend, and then, after having formulated the arguments once himself, get convinced by them himself.</p><p>In terms of our framework, we might say that a part of Walter’s mind contained a model which output a harsh judgment of himself, while another part contained a model which would output a much less harsher judgment of someone else who was in otherwise identical circumstances. Just bringing up the existence of this contradiction wasn’t enough to change it: it caused the contradiction to be <em>noticed</em>, but didn’t activate the relevant models extensively enough for their contents to be reprocessed. </p><p>But when Walter had to role-play a situation where he thought of himself as <em>actually</em> talking with a depressed friend, that required him to more fully activate the non-judgmental model and apply it to the relevant situation. This caused him to <u><a href=""https://www.lesswrong.com/posts/AhcEaqWYpa2NieNsK/subagents-introspective-awareness-and-blending"">blend with</a></u> the model, taking its perspective as the truth. When that perspective was then propagated to the self-critical model, the easiest way for the mind to resolve the conflict was simply to alter the model producing the self-critical thoughts. </p><p>Note that this kind of a result wasn’t <em>guaranteed</em> to happen: Walter’s self-critical model might have had a reason for why these cases were actually different, and pointing out that reason would have been another way for the contradiction to be resolved. In the example case, however, it seemed to work.</p><h2>Mental contrasting</h2><p>Another example of activating two conflicting mental models and forcing an update that way comes from the psychologist Gabriele Oettingen’s book <u><a href=""https://smile.amazon.com/Rethinking-Positive-Thinking-Science-Motivation-ebook/dp/B00INIXT40/"">Rethinking Positive Thinking</a></u>. Oettingen is a psychologist who <u><a href=""http://woopmylife.org/further"">has studied</a></u> combining a mental imagery technique known as “mental contrasting” with <u><a href=""https://www.lesswrong.com/posts/wJutA2czyFg6HbYoW/what-are-trigger-action-plans-taps"">trigger-action</a></u> <u><a href=""https://www.lesswrong.com/posts/v4nNuJBZWPkMkgQRb/making-intentions-concrete-trigger-action-planning"">planning</a></u>. </p><p>It is worth noting that this book has come under some <u><a href=""http://www.coyneoftherealm.com/2015/09/16/do-positive-fantasies-prevent-dieters-from-losing-weight/"">heavy</a></u> <u><a href=""http://www.coyneoftherealm.com/2015/09/23/promoting-a-positive-psychology-self-help-book-with-a-wikipedia-entry/"">criticism</a></u> and may be based on cherry-picked studies. However, in the book this particular example is just presented as an anecdote without even trying to cite any particular studies in its support. I present it because I’ve personally found the technique to be useful, and because it feels like a nice concise explanation of the kind of integration that often works:</p><blockquote>Try this exercise for yourself. Think about a fear you have about the future that is vexing you quite a bit and that you know is unjustified. Summarize your fear in three to four words. For instance, suppose you’re a father who has gotten divorced and you share custody with your ex-wife, who has gotten remarried. For the sake of your daughter’s happiness, you want to become friendly with her stepfather, but you find yourself stymied by your own emotions. Your fear might be “My daughter will become less attached to me and more attached to her stepfather.” Now go on to imagine the worst possible outcome. In this case, it might be “I feel distanced from my daughter. When I see her she ignores me, but she eagerly spends time with her stepfather.” Okay, now think of the positive reality that stands in the way of this fear coming true. What in your actual life suggests that your fear won’t really come to pass? What’s the single key element? In this case, it might be “The fact that my daughter is extremely attached to me and loves me, and it’s obvious to anyone around us.” Close your eyes and elaborate on this reality.</blockquote><blockquote>Now take a step back. Did the exercise help? I think you’ll find that by being reminded of the positive reality standing in the way, you will be less transfixed by the anxious fantasy. When I conducted this kind of mental contrasting with people in Germany, they reported that the experience was soothing, akin to taking a warm bath or getting a massage. “It just made me feel so much calmer and more secure,” one woman told me. “I sense that I am more grounded and focused.” </blockquote><blockquote>Mental contrasting can produce results with both unjustified fears as well as overblown fears rooted in a kernel of truth. If as a child you suffered through a couple of painful visits to the dentist, you might today fear going to get a filling replaced, and this fear might become so terrorizing that you put off taking care of your dental needs until you just cannot avoid it. Mental contrasting will help you in this case to approach the task of going to the dentist. But if your fear is justified, then mental contrasting will confirm this, since there is nothing preventing your fear from coming true. The exercise will then help you to take preventive measures or avoid the impending danger altogether.</blockquote><p>As in the CBT example, first one mental model (the one predicting losing the daughter’s love) is activated and intentionally blended with, after which an opposing one is, forcing integration. And as in Walter’s example, this is not <em>guaranteed</em> to resolve the conflict in a more reassuring way: the mind can also resolve the conflict by determining that actually the fear <em>is</em> justified.</p><h2>Internal Double Crux / Internal Family Systems</h2><p>On some occasions a single round of mental contrasting, or the Walter CBT technique, might be enough. In that case, there were two disagreeing models, and bringing the disagreement into consciousness was enough to reject the other one entirely. But it is not always so clear-cut; sometimes there are subagents which disagree, and both of them actually have some valid points. </p><p>For instance, someone might have a subagent which wants the person to do socially risky things, and another subagent which wants to play things safe. Neither is unambiguously wrong: on the other hand, some things <em>are</em> so risky that you should never try to do them. On the other hand, <em>never</em> doing anything which others might disapprove of is not going to lead to a particularly happy life, either.</p><p>In that case, one may need to actively facilitate a <em>dialogue</em> between the subagents, such as in the CFAR technique of Internal Double Crux (<u><a href=""https://www.lesswrong.com/posts/mQmx4kQQtHeBip9ZC/internal-double-crux"">description</a></u>, <u><a href=""https://www.lesswrong.com/posts/Z7Sk29PDYTooipXMS/internalizing-internal-double-crux"">discussion and example</a></u>, <u><a href=""https://www.lesswrong.com/posts/cvzzyKEZg4LRmvooq/internal-diet-crux"">example as applied to dieting</a></u>), iterating it for several rounds until both subagents come to agreement. The CBT and mental contrasting examples above might be considered special cases of an IDC session, where agreement was reached within a single round of discussion.</p><p>More broadly, IDC itself can be considered a special case of applying Internal Family Systems, which includes facilitating conversations between mutually opposing subagents as one of its techniques.</p><h2>Self-concept editing</h2><p>In the summer of 2017, I found Steve Andreas’s book <em><u><a href=""https://www.amazon.com/Transforming-Your-Self-Becoming-Want/dp/0911226435"">Transforming Your Self</a></u></em>, and applied its techniques to fixing a number of issues in my self-concepts which had contributed to my depression and anxiety. <u><a href=""https://www.lesswrong.com/posts/Lr2MAFLsfmayBhJnC/18-month-follow-up-on-my-self-concept-work"">Effects from this work which have lasted</a></u> include no longer having generalized feelings of shame, no longer needing constant validation to avoid such feelings of shame, no longer being motivated by a desire to prove to myself that I’m a good person, and no longer having obsessive escapist fantasies, among other things.</p><p>I wrote an article <u><a href=""https://www.lesswrong.com/posts/Lr2MAFLsfmayBhJnC/18-month-follow-up-on-my-self-concept-work"">at the time</a></u> that described the work. The model in <em>Transforming Your Self </em>is that I might have a self-concept such as “I am kind”. That self-concept is made up of memories of times when I either was kind (<em>examples</em> of the concept), or times when I was not (<em>counterexamples</em>). In a healthy self-concept, both examples and counterexamples are integrated together: you might have memories of how you are kind in general, but also memories of not being very kind at times when you were e.g. under a lot of stress. This allows you to both know your general tendency, as well as letting you prepare for situations where you know that you won’t be very kind.</p><p>The book’s model also holds that sometimes a person’s counterexamples might be split off from their examples. This leads to an unstable self-concept: either your subconscious attention is focused on the examples and totally ignores the counterexamples, in which case you feel good and kind, or it swings to the counterexamples and totally ignores the examples, in which case you feel like a terrible horrible person with no redeeming qualities. You need a constant stream of external validation and evidence in order to keep your attention anchored on the examples; the moment it ceases, your attention risks swinging to the counterexamples again.</p><p>While I didn’t have the concept back then, what I did could also be seen as integrating true but disagreeing perspectives between two subagents. There was one subagent which held memories of times when I had acted in what it thought of as a bad way, and was using feelings of shame to motivate me to make up for those actions. Another subagent was then reacting to it by making me do more and more things which I could use to prove to myself and others that I was indeed a good person. (This description roughly follows the framing and conceptualization of self-esteem and guilt/shame in the IFS book <em><u><a href=""https://smile.amazon.com/Freedom-Your-Inner-Critic-Self-Therapy-ebook/dp/B00EO5JPKI/"">Freedom from your Inner Critic</a></u></em>.) </p><p>Under the <u><a href=""https://www.sciencedirect.com/science/article/pii/S0065260100800039"">sociometer theory of self-esteem</a></u>, self-esteem is an internal evaluation of one’s worth as a partner to others. With this kind of an interpretation, it makes sense to have subagents acting in the ways that I described: if you have done things that your social group would judge you for, then it becomes important to do things which prove your worth and make them forgive you. </p><p>This then becomes a special case of an IFS exile/protector dynamic. Under that formulation, the splitting of the counterexamples and the lack of updating actually serves a purpose. The subagent holding the memories of doing shameful things doesn’t want to stop generating the feelings of shame until it has received sufficient evidence that the “prove your worth” behavior has actually become unnecessary. </p><p>One of the techniques from <em>Transforming Your Self </em>that I used to fix my self-concept was integrating the examples by adding qualifiers to the counterexamples: “when I was a child, and my executive control wasn’t as developed, I didn’t always act as kindly as I could have”. Under the belief framing, this allowed my memories to be integrated in a way which showed that my selfishness as a child was no longer evidence of me being horrible in general. Under the subagent framing, this communicated to the shame-generating subagent that the things that I did as a child would no longer be held against me, and that it was safe to relax.</p><p>Another technique mentioned in <em>Transforming Your Self</em>, which I did not personally need to use, was translating the concerns of subagents into a common language. For instance, someone’s positive self-concept examples might be in the form of mental images, with their negative counterexamples being in the form of a voice which reminds them of their failures. In that case, they might translate the inner speech into mental imagery by visualizing what the voice is saying, turning both the examples and counterexamples into mental images that can then be combined. This brings us to…</p><h2>Translating into a common language</h2><p>Eliezer presents an example of two different framings eliciting conflicting behavior in his “<u><a href=""https://www.lesswrong.com/posts/4ZzefKQwAtMo5yp99/circular-altruism"">Circular Altruism</a></u>” post:</p><blockquote>Suppose that a disease, or a monster, or a war, or something, is killing people.  And suppose you only have enough resources to implement one of the following two options:</blockquote><blockquote>1. Save 400 lives, with certainty.</blockquote><blockquote>2. Save 500 lives, with 90% probability; save no lives, 10% probability.</blockquote><blockquote>Most people choose option 1. [...] If you present the options this way:</blockquote><blockquote>1. 100 people die, with certainty.</blockquote><blockquote>2. 90% chance no one dies; 10% chance 500 people die.</blockquote><blockquote>Then a majority choose option 2.  <em>Even though it&#x27;s the same gamble</em>.  You see, just as a <em>certainty </em>of saving 400 lives seems to <em>feel</em> so much more comfortable than an unsure gain, so too, a certain loss <em>feels</em> worse than an uncertain one.</blockquote><p>In my previous post, I presented a model where subagents which are most strongly activated by the situation are the ones that get access to the motor system. If you are hungry and have a meal in front of you, the possibility of eating is the most salient and valuable feature of the situation. As a result, subagents which want you to eat get the most decision-making power. On the other hand, if this is a restaurant in Jurassic Park and a velociraptor suddenly charges through the window, then the dangerous aspects of the situation become most salient. That lets the subagents which want you to flee to get the most decision-making power.</p><p>Eliezer’s explanation of the saving lives dilemma is that in the first framing, the certainty of saving 400 lives is salient, whereas in the second explanation the certainty of losing 100 lives is salient. We can interpret this in similar terms as the “eat or run” dilemma: the action which gets chosen, depends on which features are the most salient and how those features activate different subagents (or how those features highlight different priorities, if we are not using the subagent frame). </p><p>Suppose that you are someone who was tempted to choose option 1 when you were presented with the first framing, and option 2 when you were presented with the second framing. It is now pointed out to you that these are actually exactly equivalent. You realize that it would be inconsistent to prefer one option over the other just depending on the framing. Furthermore, and maybe even more crucially, realizing this makes <em>both</em> the “certainty of saving 400 lives” <em>and</em> “certainty of losing 100 lives” features become equally salient. That puts the relevant subagents (priorities) on more equal terms, as they are both activated to the same extent.</p><p>What happens next depends on what the relative strengths of those subagents (priorities) are otherwise, and whether you happen to know about expected value. Maybe you consider the situation and one of the two subagents (priorities) happens to be stronger, so you decide to consistently save 400 or consistently lose 100 lives in both situations. Alternatively, the conflicting priorities may be resolved by introducing the rule that “when detecting this kind of a dilemma, convert both options into an expected value of lives saved, and pick the option with the higher value”.</p><p>By converting the options to an expected value, one can get a basis by which two otherwise equal options can be evaluated and chosen between. Another way of looking at it is that this is bringing in a third kind of consideration/subagent (knowledge of the decision-theoretically optimal decision) in order to resolve the tie.</p><h2>Urge propagation</h2><p><u><a href=""https://www.youtube.com/watch?v=YKpH-7fs9zE"">CFAR and Harvard Effective Altruism</a></u> is a video of a lecture given by former CFAR instructors Valentine Smith and Duncan Sabien. In Valentine’s part of the lecture, he describes a few motivational techniques which work by mentally reframing the contents of an experience.</p><p>The first example involves having a $50 parking ticket, which - unless paid within 30 days - will accrue an additional $90 penalty. This kind of a thing tends to <u><a href=""https://www.lesswrong.com/posts/EFQ3F6kmt4WHXRqik/ugh-fields"">feel ughy</a></u> to deal with, causing an inclination to avoid thinking about it - while also being aware of the need to do something about it. Something along the lines of two different subagents which are both trying to avoid pain using opposite methods - one by not thinking about unpleasant things, another by doing things which stop future unpleasantness. </p><p>Val’s suggested approach involves noting that if you instead had a cheque for $90, which would expire in 30 days, then that would <em>not</em> cause such a disinclination. Rather, it would feel actively pleasant to cash it in and get the money. </p><p>The structure of the “parking ticket” and “cheque” scenarios are equivalent, in that both cases you can take an action to be $90 better off after 30 days. If you notice this, then it may be possible for you to re-interpret the action of paying off the parking ticket as something that <em>gains you money</em>, maybe by something like literally looking at it and imagining it as a cheque that you can cash in, until cashing it in starts feeling <em>actively pleasant</em>. </p><p>Val emphasizes that this is not just an arbitrary motivational hack: it’s important that your reframe is <em>actually bringing in real facts from the world</em>. You don’t want to just imagine the parking ticket as a ticking time bomb, or as something else which it actually isn’t. Rather, you want to do a reframe which integrates both perspectives, while also highlighting the features which will help fix the conflict. </p><p>One description of what happens here would be that once the pain-avoiding subagent notices that paying the parking ticket can feel like a net gain, and that it being a net gain is actually describing a real fact about the world, then it can drop its objection and you can proceed to take actions. The other way of looking at it is that like with expected value, you are introducing a common currency - the future impact on your finances - which allows the salient features from both subagents’ perspectives to be integrated and then resolved.</p><p>Val’s second example involves a case where he found himself not doing push-ups like he had intended to. When examining the reason why not, he noticed that the push-ups felt physically unpleasant: they involved sweating, panting, and a burning sensation, and this caused a feeling of aversion.</p><p>Part of how he solved the issue was by realizing that his original goal for getting exercise was to live longer and be in better health. The unpleasant physical sensations were a sign that <em>he was pushing his body hard enough that the push-ups would actually be useful for this goal</em>. He could then create a mental connection between the sensations and his goal of being healthier and living longer: the sensations started feeling like <em>something positive</em>, since they were an indication of progress.</p><p>Besides being an example of creating a common representation between the subagents, this can also be viewed as doing a round of Internal Double Crux, something like:</p><blockquote><strong>Exercise subagent:</strong> We should exercise.</blockquote><blockquote><strong>Optimizer subagent:</strong> That feels unpleasant and costs a lot of energy, we would have the energy to do more things if we didn’t exercise.</blockquote><blockquote><strong>Exercise subagent: </strong>That’s true. But the feelings of unpleasantness are actually a sign of us getting more energy in the long term.</blockquote><blockquote><strong>Optimizer subagent: </strong>Oh, you’re right! Then let’s exercise, that furthers my goals too.</blockquote><p>(There&#x27;s also a bunch of other good stuff in the video that I didn&#x27;t describe here, you may want to check it out if you haven&#x27;t already done so.)</p><h2>Exposure Therapy</h2><p>So far, most of the examples have assumed that the person already has all the information necessary for solving the internal disagreement. But sometimes additional information might be required.</p><p>The prototypical use of <em>exposure therapy</em> is for phobias. Someone might have a phobia of dogs, while at the same time feeling that their fear is irrational, so they decide to get therapy for their phobia.</p><p>How the therapy typically proceeds is by exposing the person to their fear in increments that are as small as possible. For instance, <u><a href=""https://www.anxietycanada.com/adults/exposure-therapy-specific-phobia"">a page by Anxiety Canada</a></u> offers this list of steps that someone might have for exposing themselves to dogs:</p><blockquote>Step 1: Draw a dog on a piece of paper.</blockquote><blockquote>Step 2: Read about dogs.</blockquote><blockquote>Step 3: Look at photos of dogs.</blockquote><blockquote>Step 4: Look at videos of dogs.</blockquote><blockquote>Step 5: Look at dogs through a closed window.</blockquote><blockquote>Step 6: Then through a partly-opened window, then open it more and more.</blockquote><blockquote>Step 7: Look at them from a doorway.</blockquote><blockquote>Step 8: Move further out the doorway; then further etc.</blockquote><blockquote>Step 9: Have a helper bring a dog into a nearby room (on a leash).</blockquote><blockquote>Step 10: Have the helper bring the dog into the same room, still on a leash.</blockquote><p>The ideal is that each step is enough to make you feel a little scared, but not so scared that it would serve to act retraumatize you or otherwise make you feel horrible about what happened. </p><p>In a sense, exposure therapy involves one part of the mind thinking that the situation is safe, and another part of the mind thinking that the situation is unsafe, and the contradiction being resolved by <em>testing</em> it. If someone feels nervous about looking at a photo of a dog, it implies that a part of their mind thinks that seeing a photo of a dog means they are potentially in danger. (In terms of the machine learning toy model from my IFS post, it means that a fear model is activated, which predicts the current state to be dangerous.) </p><p>By looking at photos sufficiently many times, and then afterwards noting that everything is okay, the nervous subagent gets information about having been wrong, and updates its model. Over time, and as the person goes forward in steps, the nervous subagent can eventually conclude that it had overgeneralized from the original trauma, and that dogs in general aren’t that dangerous after all.</p><p>As in the CBT example, one can view this as activating conflicting models and the mind then fixing the conflict by updating the models. In this case, the conflict is between the frightened subagent&#x27;s prediction that seeing the dog is a sign of danger, and another subagent&#x27;s later assessment that everything turned out to be fine.</p><h1>Conclusion to integration methods</h1><p>I have considered here a number of ways of integrating subagent conflicts. Here are a few key principles that are used in them:</p><ul><li><strong>Selectively <u><a href=""https://www.lesswrong.com/posts/AhcEaqWYpa2NieNsK/subagents-introspective-awareness-and-blending"">blending</a></u> with subagents/beliefs to make disagreements between them more apparent. </strong>Used in the Cognitive Behavioral Therapy and mental contrasting cases. Also used in a somewhat different form in exposure therapy, where you are partially blended with a subagent that thinks that the situation is dangerous, while getting disagreeing information from the rest of the world.</li><li><strong>Facilitating a dialogue between subagents “from the outside”. </strong>Used in Internal Double Crux, Internal Family Systems. In a sense, the next bullet can also be viewed a special case of this.</li><ul><li><strong>Combining aspects of the conflicting perspectives to a whole which allows for resolution. </strong>Used in self-concept editing, Eliezer’s altruism example, and urge propagation.</li></ul><li><strong>Collecting additional information which allows for the disagreement to be resolved. </strong>Used in exposure therapy.</li></ul><p>I believe that we have evolved to use all of these spontaneously, without necessarily realizing what it is that we are doing. </p><p>For example, many people have the experience of it being useful to talk to a friend about your problems, weighting the pros and cons of different options. Frequently just getting to talk about it helps clarify the issue, even if the friend doesn’t say anything (or even if they <u><a href=""https://en.wikipedia.org/wiki/Rubber_duck_debugging"">are a rubber duck</a></u>). Probably not coincidentally, if you are talking about the conflicting feelings that you have in your mind, then you are frequently doing something like an informal version of Internal Double Crux. You are representing all the sides of a dilemma until you have reached a conclusion and integrated the different perspectives. </p><p>To the extent that they are effective, various schools of therapy and self-improvement - ranging from CBT to IDC to IFS - are formalized methods for making such integration more effectively.</p>",Kaj_Sotala,kaj_sotala,Kaj_Sotala,
bYQjpfu4YPckWrWkK,How to improve at critical thinking on science/medical literature?,how-to-improve-at-critical-thinking-on-science-medical,https://www.lesswrong.com/posts/bYQjpfu4YPckWrWkK/how-to-improve-at-critical-thinking-on-science-medical,2019-05-14T11:58:34.613Z,14,5,12,False,True,,"<p>I&#x27;m a medical student, and I will often read articles that are critical of scientific literature (<a href=""https://slatestarcodex.com/2017/03/06/antidepressant-pharmacogenomics-much-more-than-you-wanted-to-know/"">Scott Alexander on Pharmacogenomics</a>; <a href=""https://emcrit.org/emnerd/the-case-of-the-magicians-sleight/"">EMCrit on thrombolysis in ischemic stroke</a>, etc.) with some awe at the authors&#x27; ability to evaluate evidence. </p><p>I&#x27;m sure that part of this is practice. If I spend more time critically reading scientific literature, and less time taking experts at face value, I will likely become better able to think independently.</p><p>However, part of it strikes me as a lack of technical skills. I&#x27;m often unsure how to critique study designs when I don&#x27;t understand the statistical methods being used.</p><p>Any recommendations for how I might get the skills I need to think independently about scientific/medical literature?</p><p>[Edit: Changed formatting of links after a comment]</p>",hereisonehand,hereisonehand,hereisonehand,
frt7aGb4uQDGeiMGQ,Epistea Summer Experiment,epistea-summer-experiment,https://www.lesswrong.com/events/frt7aGb4uQDGeiMGQ/epistea-summer-experiment,2019-05-13T21:29:43.681Z,25,10,2,False,False,,"<p>ESE is a week-long experimental summer workshop combining elements of applied rationality and experiential education happening in Europe.</p><p>We will play, explore, introspect, practice - all in order to boost our learning. The program is focused on <em>group rationality</em>, or in other words: how we can have accurate beliefs and act in accordance with them not only as individuals but together with other people.</p><ul><li><strong>When: </strong>28.7. – 3.8. 2019 (6,5 days of program)</li><li><strong>Where:</strong> in beautiful Czech countryside in Loutí – near Prague, Czech Republic </li><li><strong>For whom</strong>: All rationalists who are excited about the mixture of playful summer camp, experimenting with old and new rationality techniques, and learning how to be rational <em>together</em>.</li><li><strong>Price</strong>: 600 Euro (In case you would hesitate to join because of financial issues, let us know.)</li><li><strong>Application deadline</strong>: 19th of May </li></ul><p>For more detailed info, check the <a href=""https://experience.epistea.org/"">website</a>.</p>",Jan_Kulveit,jan_kulveit,Jan_Kulveit,
5imc9fN5xqpjcezzZ,Thinking Fast and Hard,thinking-fast-and-hard,https://www.lesswrong.com/posts/5imc9fN5xqpjcezzZ/thinking-fast-and-hard,2019-05-13T19:58:34.089Z,26,11,1,False,False,,"<p>Cross-posted from <a href=""https://putanumonit.com/2019/05/07/thinking-fast-and-hard/"">Putanumonit</a>.</p><p>Note: Yes, I know about Worm. No, I haven&#x27;t read past the first quarter or so.</p><hr class=""dividerBlock""/><p> A cool superpower to have would be the ability to slow subjective time and get a lot of thinking done.</p><p>In every superhero movie, no matter how fast the protagonists fly or how hard they punch, they always end up within one step of disaster because their planning skills are dogshit. The villain loses not because he can’t punch as hard, but because of steadfast refusal to think things through. Outside of some genre fiction, it’s very rare to see a villain that deserves the epithet <em>scheming</em>.</p><p>Also, the hero wins because he’s handsome. When everyone is flying by intuition, <a href=""https://en.wikipedia.org/wiki/Lookism"">lookism</a> wins the day.</p><p>The scariest comic supervillain would be named <a href=""https://www.lesswrong.com/posts/N47M3JiHveHfwdbFg/hammertime-day-10-murphyjitsu"">Murphyjitsu</a>. Her superpower would be the ability to go through the following checklist:</p><ol><li>Do I have a plan?</li><li>Imagine that my plan failed. Am I utterly shocked?</li><li>If not, what is the most likely failure mode? How do I prevent it?</li><li>If I’ve iterated enough that the plan seems very likely to work, remember to notice any confusing and unexpected evidence that might cause me to rethink it.</li></ol><p>Murphyjitsu would spend her formative years on the harsh streets of Distopolis, building a burning resentment for humanity and practicing calibration by tracking the success rate of all her predictions and plots.</p><p><a href=""https://www.lesswrong.com/posts/FbQ9Y9pBif5xZ7w2f/distinctions-in-types-of-thought"">Sarah Constantin notes</a> that deliberate and effortful thinking (aka System 2) is as mysterious as it is powerful. We underestimate its power only because of how rarely it is used. We underestimate its mysteriousness only because it takes deliberate effort to notice how little we understand it.</p><p>System 2 is a scarce resource, a sort of superpower of the human mind that it only breaks out in emergencies. The <a href=""https://theness.com/neurologicablog/index.php/the-global-workspace-consciousness-explained/"">Global Workspace</a> model of consciousness posits that the brain contains a multitude of modules each doing its own processing while competing for the spotlight of conscious attention. My hypothesis is that a main function of consciousness is to allocate System 2 resources to subprocesses that need it.</p><p>Unexpected stimuli grab your attention, to check whether dealing with them requires any thinking. For example, we are perfectly capable of handling any number of strangers with unconscious System 1 processing, as can be demonstrated by a stroll through a busy city. But when a stranger walks into a room we perk up – even though we determined many things about them instinctually (size, gender, mood, whether they’re a threat or not…) dealing with someone in close quarters may call for a more detailed plan.</p><p>The best part of having the superpower of (objectively) fast and (subjectively) sustained deliberate thinking is that it’s completely secret. No need for capes and masks and secret identities. From the outside, it would just look like I’m a reasonable and successful person, perhaps a lucky one. I would make great jokes, perfectly worded. I would have great opinions, perfectly anticipating all objections. A few discerning minds may begin to suspect: <em>The conversation shifted to this topic just two minutes ago, how did he already come up with 5 great takes? </em>Ironically, everyone would chalk my superpower up to <em>amazing intuition</em>.</p><p>Writing is the closest I get to fulfilling this fantasy. You are reading this paragraph mere seconds after the last one, but you’ll never know how long it took <em>me </em>to come up with it. Did I write in flow, typing at the speed of thought? Did I cross it out and rework it over the course of hours or days? I often feel disappointed when talking to writers I admire, their output at the live speed of conversation is inevitably less impressive than what they produce by sustained effort.</p><p>Thinking fast and hard beats shooting lasers from your eyes or <a href=""https://en.wikipedia.org/wiki/Spinneret"">spiderwebs from your butt</a>. If you don’t think so, you haven’t thought hard enough about it.</p>",Jacobian,jacob-falkovich,Jacob Falkovich,
W5Hsyao2akgMdqtEd,Physical linguistics,physical-linguistics,https://www.lesswrong.com/posts/W5Hsyao2akgMdqtEd/physical-linguistics,2019-05-13T19:30:28.263Z,16,7,10,False,False,,"<html><head></head><body><p>This is really my attempt at approaching <a href=""https://en.wikipedia.org/wiki/Eliminative_materialism"">eliminative materialism</a>, and probably reading Paul Churchland or Daniel Dennett's papers would be better for you to get the point. I'm just writing to organize my thoughts.</p>
<h3>Background</h3>
<p>There are three big problems in science: universe, life, and consciousness. There is a good theory of the universe on the macro and micro scale, and the problem of its origin. They are not the final word, but we have a good sense of any future updated theories would be like: mechanistic, mathematical, probably using real, complex, and discrete numbers.</p>
<p>A theory of life is still in the works, though there are encouraging attempts. The physical construction of life and the <em>descriptive</em> theory of life is now complete except in the details. We know that it would be something made of evolution, thermodynamics, chemistry, and of course, mathematics. The <em>engineering</em> theory of life is still greatly missing. We do not know how to create life, at most we can fork the genetic code and do little modifications and mixings. We don't even know if a robot is alive.</p>
<p>A theory of consciousness is in an even earlier stage. There are some basic studies of the description of consciousness, and there are dozens of hazy philosophical theories that needs to be made quantitative using future data.</p>
<h3>Consciousness-free</h3>
<p>One problem with consciousness is its paradoxical qualities, creating questions that seem to both be compelling and deformed:</p>
<ul>
<li>""Why am I me instead of someone else?""</li>
<li>""If Pinkie is copied, which one is the real Pinkie?""</li>
<li>""Is the feeling of blue same for everyone?""</li>
<li>""How does one freely choose?""</li>
</ul>
<p>Now compare them with analogous questions from universe and life:</p>
<ul>
<li>""Why is this rock this rock instead of that rock?""</li>
<li>""If this book is copied, which one is the real book?""</li>
<li>""Is this website the same website on every computer?""</li>
<li>""How does a slime mold decide which way to go?""</li>
</ul>
<p>The analogous questions lose their mystery and becomes mundane, confused, or fascinating but also scientifically analyzable.</p>
<p>Possibly the problem is with the understanding of conscious itself, which is too confused. I propose to remove consciousness from explanations of life behavior (human or not) as much as possible. If it can be fully removed, then the problem of consciousness is solved. If it can't be fully removed, then it concentrates the effort for solution.</p>
<h3>A sketch</h3>
<p>As a sketch of how such a removal might be done, consider a fully physical explanation of how humans talk, which is currently infested with consciousness. The standard account is that there is a consciousness that feels something, then formulates that into words and sentences, then expresses them. Unconscious speaking is considered nonsense, meaningless, noise. This doesn't have to be.</p>
<h4>The Heptapods</h4>
<p>The Heptapods from <a href=""https://en.wikipedia.org/wiki/Story_of_Your_Life"">Story of Your Life</a> (Ted Chiang, 1998) are an example of a ""free-will-free"" form of life. Their language has determinism baked into it, just as human language has free will baked into it.</p>
<p>What kind of universe could produce two kinds of life such that one is deterministic in language, but the other is free in language? And in such proximity too, such that they can actually meet each other and share the same physical space and physical laws?</p>
<p>To answer such questions in a physics way, one would use a physics of language. What is a language according to a physicist?</p>
<h4>Physical linguistics</h4>
<p>What is a deterministic language, and what is a free-will language? How would a description of free-will emerge in a deterministic system such as our universe? And most importantly, how does a <em>universal</em> language, a symbolic system that can models the physical world that it is in, emerge in a deterministic world?</p>
<p>This is analogous to the problem of zombie language: I once read that in a world with only philosophical zombie humans, human languages would probably have not evolved to talk about consciousness and inner experiences because there is no such nonexistent thing. This argument is dumb, since human languages already talk about many nonexistent things, but it points at an interesting question: how would a deterministic system evolve a language that talks about things happening in it?</p>
<h4>Physical self-referential science</h4>
<p>In the same spirit, what kind of deterministic universe would have little bundles of matter inside of it that behaves roughly the same as some other patches of this universe? We call these little bundles of matter ""computers running physical simulations"", or ""a human brain thinking about science"", or maybe even ""a lion brain thinking about which way an antelope is probably going to go next"".</p>
<p>If such explanations can be done in detail, that would be a self-reference in physics: a physical system (our universe) containing a substantial description of itself (the explanation), as well as an account for why it is likely for the description to exist in the first place (the explanation about why a physical world is likely to contain its own description).</p>
</body></html>",Yuxi_Liu,yuxi_liu,Yuxi_Liu,
fqmhYhzx5zBsPRkBv,In support of the inside view and a counter to modest epistemology ,in-support-of-the-inside-view-and-a-counter-to-modest,https://www.lesswrong.com/posts/fqmhYhzx5zBsPRkBv/in-support-of-the-inside-view-and-a-counter-to-modest,2019-05-13T15:21:57.624Z,-7,8,1,False,False,,"<p>This might have already been said in inadequate equilibria however it was definitely not clear enough for me to understand it from their so it&#x27;s not plagiarism. The outside asks, what evidence do you have that you are right and the other person is wrong. The fact that you think your right does not constitute evidence because he also thinks he&#x27;s right.</p><p>My counter is that their are different levels of sureness about being correct. I can be pretty sure or absolutely certain. And the more sure I am of something the more likely it is to be true. So if I knew that I was more sure than the other person I know that it is more likely that I am right and he is wrong. However how do I know that I&#x27;m more sure than he is on this topic. The answer is simple, you don&#x27;t. However you don&#x27;t need to know that. Let&#x27;s say that if you are more sure than you are 100 percent correct however if your exactly as sure than you are 5o percent likely to be correct. And you are 50 percent certain that you are more sure than he is. Then it is 75 percent likely that you are correct.</p><p>Even if you are both the same sure about it you can look at how often are you this sure and how often is he that sure. Let&#x27;s say your this sure 1 out of 50 times and he is this sure 1 out of 30 times then its more likely that you are correct because you being sure constitutes more evidence than his being sure.</p><p>This argument is at its most powerful when you conserve it for those few times that you&#x27;re absolutely sure. Where your at the most possible clarity about a thing. Because when that happens you are way more likely to be correct since you are the most possibly sure and its really unlikely he is as sure as you or even if he is its really unlikely that he is rarely as sure as this so its way more likely  that you are correct</p><p></p><p>I&#x27;m my experience this feeling of absolute correctness rarely manifests but when it does i&#x27;ve always been correct ( I had these arguments before I learned anything about logic or philosophy and after I learned a little I found out that I had mainstream views so that&#x27;s my correct metric). Its a feeling of absolute clarity, in the moment you understand it perfectly and you feel the confusion and lack of understanding of your opponent.</p><p></p><p>From here I usually find things that I set in stone are and if you disagree with them I lower you in my outside calibration but that is for another post.</p>",solomon-alon,solomon-alon,solomon alon,
dGs8Z9H6Bnyy7dzN9,Cambridge LessWrong / SSC Meetup,cambridge-lesswrong-ssc-meetup,https://www.lesswrong.com/events/dGs8Z9H6Bnyy7dzN9/cambridge-lesswrong-ssc-meetup,2019-05-13T01:56:43.913Z,7,2,0,False,False,,<p>This is the monthly Cambridge LessWrong / Slate Star Codex meetup.</p>,AspiringRationalist,nosignalnonoise,NoSignalNoNoise,
MSP5FgEaz66kzCKzt,Ed Boyden on the State of Science,ed-boyden-on-the-state-of-science,https://www.lesswrong.com/posts/MSP5FgEaz66kzCKzt/ed-boyden-on-the-state-of-science,2019-05-13T01:54:37.835Z,62,17,2,False,False,,"<p>I just listened to Tyler Cowen's interview with Ed Boyden (<a href=""https://medium.com/conversations-with-tyler/tyler-cowen-ed-boyden-neuroscience-3907eccbd4ca"">link and transcript</a>). The second half contained a lot of questions about current scientific infrastructure, and Boyden had a lot of interesting comments, so I've reproduced a few particular quotes here and added headings.</p><p>(Things I've not quoted that LWers might be interested in: Boyden said that whole brain emulations probably work in principle, that he meditates every day and has used an internal family systems meditation for 10 years.)</p><h2>The Surprisingly Poor State of Funding</h2><p><strong>COWEN:</strong> How should we improve the funding of science in this country?</p><p><strong>BOYDEN:</strong> I like to look at the history of science to learn about its future, and one thing I’ve learned a lot over the last couple years — and it’s even happened to me — is that it’s really hard to fund pioneering ideas.</p><p><a href=""https://www.nobelprize.org/prizes/chemistry/2012/kobilka/facts/"">Brian Kobilka</a>, who recently won the Nobel Prize for solving the structure of the G-protein-coupled receptor — and for context, one-third of all drugs target this class of molecules, so it’s a very, very important class of drugs — he lost his funding because he wasn’t making progress fast enough. If I recall, he had to moonlight as an emergency room physician to keep going on his research.</p><p><a href=""https://www.conncoll.edu/ccacad/zimmer/GFP-ww/prasher.html"">Doug Prasher</a>, who cloned the gene for green fluorescent protein, which has been used in something like a million biology studies, ballpark — he lost his funding and eventually left science, ended up driving a shuttle bus for, I believe, a rental car facility or something.</p><p>Anyway, there’s so many stories. For me, it became personal because when we proposed this expansion microscopy technology, where we blow up brain specimens and other specimens a hundred times in volume to map them, people thought it was nonsense. People were skeptical. People hated it. Nine out of my first ten grants that I wrote on it were rejected.</p><p>If it weren’t for the <a href=""https://www.openphilanthropy.org/"">Open Philanthropy Project</a> that heard about our struggles to get this project funded — through, again, a set of links that were, as far as I can tell, largely luck driven — maybe our group would have been out of business. But they came through and gave us a major gift, and that kept us going.</p><blockquote><em>Boyden also said this sentence in passing, which seemed striking to me about the insularity at the highest echelons of science.</em></blockquote><p><strong>BOYDEN:</strong> I read a statistic that 40 percent of the professors at MIT trained at one point in their career at Stanford, Harvard, or MIT.</p><h2>How to Improve Funding</h2><p><strong>COWEN:</strong> Let’s say you had $10 billion or $20 billion a year, and you would control your own agency, and you were starting all over again, but current institutions stay in place. What would you do with it? How would you structure your grants? You’re in charge. You’re the board. You do it.</p><p><strong>BOYDEN:</strong> Yeah, three thoughts. The first thing that I thought a lot about — studying these past cases and then going through it myself — is thinking about peer review. What is peer review?</p><p>When you propose a project, a bunch of your peers will then critique it. The problem that a lot of these daring-sounding projects encounter is that they sound bad during peer review because they’re so off the wall, or they bring together multiple fields that maybe nobody’s qualified to evaluate them.</p><p>One thought is, what if — instead of taking people’s opinions and then just sort of combining those opinions, and then, okay, you’re in or you’re out in terms of getting the money — what if we take a step back, and we think about why the peers are thinking this way?</p><p>If somebody critiques a proposal, but they’re doing it from a vantage point that doesn’t see a certain part of the proposal as valuable because they’re missing an underlying piece of knowledge, or they’re evaluating a proposal — based upon opinion — that, if we think about the logical underpinnings of it, the rationale is actually pretty solid in terms of its being linked to ground-truthable sciences, like physics and chemistry.</p><p>In other words, if we take a step back and apply more logical principles of evaluation to the outcomes of peer review, can we actually improve the ranking of these proposals? This is something I’m thinking a lot about right now. As I evaluate people and evaluate ideas that people propose to me as well, I’m trying to hone those skills in myself. That’s one of the three things I would do.</p><p>[...]The second thing I would do is to be more dynamic in my funding. Right now, maybe there’s a grant that you apply for, and then a year later you get the money.</p><p>But what if somebody tries something out one Friday afternoon, and whoa, that could cure disease, or that could yield an amazing new insight into biology, or that could allow us to diagnose brain diseases early, or whatever? Why wait a year? What if one could dynamically allocate funding up and down based upon the real-time metrics of science?</p><p>In my own group, sometimes we get a project out of the blue, and hey, that’s pretty cool. Then we’ll dynamically try to understand if we can reallocate resources. That’s another thing I would do.</p><p>The third thing I would do is I would go looking for trouble. I would go looking for serendipity. If you look at CRISPR for genome editing — that was found by some scientists working on yogurt. If you look at fluorescent proteins — that was identified by a person who just was obsessed with jellyfish.</p><p>In my own field, if you look at our optogenetics work or our expansion microscopy work — these fields owe a debt to basic curiosity about critters living in bodies of water for optogenetics, and expansion microscopy goes back to the 1980s where people were wondering why do certain polymers swell so hugely, with no practical-purpose implications of it.</p><p>One idea is, how do we find the diamonds in the rough, the big ideas but they’re kind of hidden in plain sight? I think we see this a lot. Machine learning, deep learning, is one of the hot topics of our time, but a lot of the math was worked out decades ago — <a href=""https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e"">backpropagation</a>, for example, in the 1980s and 1990s. What has changed since then is, no doubt, some improvements in the mathematics, but largely, I think we’d all agree, better compute power and a lot more data.</p><p>So how could we find the treasure that’s hiding in plain sight? One of the ideas is to have sort of a SWAT team of people who go around looking for how to connect the dots all day long in these serendipitous ways.</p><p><strong>COWEN:</strong> Does that mean fewer committees and more individuals?</p><p><strong>BOYDEN:</strong> Or maybe individuals that can dynamically bring together committees. “Hey, you’re a yogurt scientist that’s curious about this weird CRISPR molecule you just found. Here’s some bioinformaticists who are looking to find patterns. Here’s some protein engineers who love — ”</p><p><strong>COWEN:</strong> But should the evaluators be fewer committees and more individuals? The people doing the work will always be groups, but committees, arguably, are more conservative. Should we have people with more dukedoms and fiefdoms? They just hand out money based on what they think?</p><p><strong>BOYDEN:</strong> A committee of people who have multiple non-overlapping domains of knowledge can be quite productive.</p><p>What if I brought together to evaluate a proposal, and I have a physicist who can tell me, “You know what? That amount of energy won’t kill the brain.” Then I have a biologist who says, “You know what? That’s a really important problem.” And then a chemist who would say, “You know what? That molecule probably won’t be toxic.” You actually need a committee to judge some of these ideas</p><h2>Why is Science Slowing Down?</h2><p><strong>COWEN:</strong> Is progress in science slowing down right now?</p><p><strong>BOYDEN:</strong> That’s a good question. I think what’s happening is we’re tackling bigger problems. Let me explain what that means.</p><p>In physics, there’s a small number of building blocks, like protons and electrons, and a small number of ways they interact, like electromagnetism and so forth. Chemistry — there’s more stuff. There’s a hundred-odd things in the periodic table, although maybe there’s only 30 to 50 that you actually have to work with if you’re trying to make something actually happen. Again, there’s a small number of bonds: covalent and ionic and so forth.</p><p>I think the problem right now is that a lot of the scientific questions we’re wrestling with, whether it’s in biology and medicine — but I’m not an expert in this; you know more about some of these things than I do — but in economics and education and so forth, it also seems like — from my distant view — some of these problems relate to this idea that there’s a lot of different building blocks and a lot of ways they interact.</p><p>In biology, we have what, 30,000 genes in the human genome, and while we know their sequence, for the most part, we have no idea how these gene products interact with each other, and how they’re architected into cells and tissues and organs, and how those go wrong. The problem is this cognitrone explosion of possibilities is so staggeringly huge that a lot of what we try will fail.</p><p>What do we do about it? One point of view is, “Well, if we had better tools, and we could map those building blocks and those interactions, maybe we could reduce the risk of biomedical science.” Again, it’s not my field. You know more about this than I do. I’d love to hear your opinion. But in economics and in other fields, it also seems like people are trying to make better maps of things and how they interact.</p><p>That’s one idea. What if we could make these problems&nbsp;.&nbsp;.&nbsp;. Progress might seem to be slower because the problems are so hard. But with better tools, maybe we can level the playing field and make 21st-century sciences more tractable, in the same way that 20th-century sciences gave us lasers and computers and the internet.</p><p><strong>COWEN:</strong> In economics, we have more good empirical papers than ever before, but virtually no more theoretical breakthroughs, and I’m not sure we’ll ever have them again.</p><p><strong>BOYDEN:</strong> Oh, how interesting.</p><p><strong>COWEN:</strong> That may just be diminishing returns. There are so many fundamental ideas, and you learn those, and you stop, and then you measure things.</p><p><strong>BOYDEN:</strong> Hmm. Well, in biomedicine, systems didn’t evolve to be understood. They evolved to survive and reproduce and all that. One can hope for structure. Biology does give you more structure than we deserve, I think. DNA has a double helix, and you can read out the genetic code.</p><p>There’s always this question of why is the universe understandable in the first place, and maybe now we’re entering the realm of complexity where things are less understandable. But again, we have to accept reality for what it is.</p><h2>How to Hire Good Scientists</h2><p><strong>BOYDEN:</strong> ...in our group at MIT, I have two PhD students. Neither finished college, actually. I can’t think of any other neuroscience groups on Earth where that’s true.</p><p><em>Later in the interview.</em></p><p><strong>COWEN:</strong> What kind of students are you likely to hire that your peers would not hire?</p><p><strong>BOYDEN:</strong> Well, I really try to get to know people at a deep level over a long period of time, and then to see how their unique background and interests might change the field for the better.</p><p>I have people in my group who are professional neurosurgeons, and then, as I mentioned, I have college dropouts, and I have people who&nbsp;.&nbsp;.&nbsp;. We recently published a paper where we ran the brain expansion process in reverse. So take the baby diaper polymer, add water to expand it, and then you can basically laser-print stuff inside of it, and then collapse it down, and you get a piece of nanotechnology.</p><p>The co–first author of that paper doesn’t have a scientific laboratory background. He was a professional photographer before he joined my group. But we started talking, and it turns out, if you’re a professional photographer, you know a lot of very practical chemistry. It turns out that our big demo — and why the paper got so much attention — was we made metal nanowires, and the way we did it was using a chemistry not unlike what you do in photography, which is a silver chemistry.</p><p>I really try to understand how individual people and their unique background and interests could change the world, but it means that we don’t really have a formula. I try not to have formulas, in general, when it comes to the actual day-to-day of science. I often say to people in my group, “We want to revolutionize the world for the better and do the right thing and be ethical, but beyond that, let’s not try to make any artificial policies.”</p><h2>How to Find Good Ideas</h2><p><strong>COWEN: [</strong>H]ow do you use discoveries from the past more than other scientists do?</p><p><strong>BOYDEN:</strong> One way to think of it is that, if a scientific topic is really popular and everybody’s doing it, then I don’t need to be part of that. What’s the benefit of being the 100,000th person working on something?</p><p>So I read a lot of <em>old</em> papers. I read a lot of things that might be forgotten because I think that there’s a lot of treasure hiding in plain sight. As we discussed earlier, optogenetics and expansion microscopy both begin from papers from other fields, some of which are quite old and which mostly had been ignored by other people.</p><p>I sometimes practice what I call failure rebooting. We tried something, or somebody else tried something, and it didn’t work. But you know what? Something happened that made the world different. Maybe somebody found a new gene. Maybe computers are faster. Maybe some other discovery from left field has changed how we think about things. And you know what? That old failed idea might be ready for prime time.</p><p>With optogenetics, people were trying to control brain cells with light going back to 1971. I was actually reading some earlier papers. There were people playing around with controlling brain cells with light going back to the 1940s. What is different? Well, this class of molecules that we put into neurons hadn’t been discovered yet.</p><p><strong>COWEN:</strong> The same is true in economics, I think. Most of behavioral economics you find in Adam Smith and Pigou, who are centuries old.</p><p><strong>BOYDEN:</strong> Wow. I almost think search engines like Google often are trying to look at the most popular things, and to advance science, what we almost need is a search engine for the most important unpopular things.</p><p><strong>COWEN:</strong> Sometimes I try doing searches. I take the words I want, and then I throw in a random word that is not related at all, and I try googling that, or through Google Scholar, and I see what comes up.</p><p><strong>BOYDEN:</strong> Absolutely. I do that a lot, too. That’s one thing where I really value those six years I spent learning a bit of chemistry and a bit of physics and a bit of electrical engineering, because it allows me to stitch together some facts from different fields, and that can be very helpful for launching a new idea or judging whether an idea’s actually worth pursuing.</p><h2>In Summary</h2><p><strong>COWEN:</strong> Last question. As a researcher, what could and would you do with more money?</p><p><strong>BOYDEN:</strong> Well, I’m always looking for new serendipitous things, connecting the dots between different fields. These ideas always seem a bit crazy and are hard to get funded. I see that both in my group but also in many other groups.</p><p>I think if I was given a pile of money right now, what I would like to do is to find a way — not just in our group but across many groups — to try to find those unfundable projects where, number one, if we think about the logic of it, “Hey, there’s a non-zero chance it could be revolutionary.” Number two, we can really, in a finite amount of time, test the idea. And if it works, we can dynamically allocate more money to it. But if it doesn’t work, then we can de-allocate money to it.</p><p>If I think about optogenetics or expansion microscopy, or these other techniques that we’ve been talking about, the amount of money that we actually invested in it to get it going was not that much. They were actually fairly inexpensive projects.</p><p>Then finally, I would like to go out and treasure hunt. Let’s look at the old literature. Let’s look at people who might be on the fringes of science, but they don’t have the right connections, like the people who I talked about earlier. They’re not quite in the right place to achieve the rapid scale-up of the project. But by connecting the dots between people and topics, you know what? We could design an amazing project together.</p>",Benito,benito,Ben Pace,
QvrKSR2dJkKmvp8Es,"What are some ""Communities and Cultures Different From Our Own?""",what-are-some-communities-and-cultures-different-from-our,https://www.lesswrong.com/posts/QvrKSR2dJkKmvp8Es/what-are-some-communities-and-cultures-different-from-our,2019-05-12T22:03:42.590Z,29,15,3,False,True,,"<p>&quot;<a href=""http://www.daviddfriedman.com/Academic/Course_Pages/legal_systems_very_different_12/LegalSystemsDraft.html"">Legal Systems Different From Our Own</a>&quot; is a fantastic work that explores how many different cultures approached legality. The diversity of ideas there has given me both concrete ideas of how to incentivize people, and helped shake me out of some default frames I was holding.</p><p>I&#x27;d be interested in other works that do the same thing, but for different aspects of community building (including but not limited how to help people find connection, how to help them gain skills, how to ensure the community has a good mixture of growth and stability, etc).</p><p>Three useful answers to this question would include:</p><p>1) if there literally is a book that is an overview of different communities or cultures and interesting elements of how they work, that&#x27;d be useful</p><p>2) if you have read a book that deals with one particular community or type of community, writing up a summary of that book</p><p>3) writing up experiences from a given community, especially if there were particular social tools that the community used that have neat implications.</p>",Raemon,raemon,Raemon,
RQpNHSiWaXTvDxt6R,Coherent decisions imply consistent utilities,coherent-decisions-imply-consistent-utilities,https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities,2019-05-12T21:33:57.982Z,155,68,83,False,False,,"<p> (<em>Written for Arbital in 2017.</em>) </p><hr class=""dividerBlock""><h1>Introduction to the introduction: Why expected utility?</h1><p>So we're talking about how to make good decisions, or the idea of 'bounded rationality', or what sufficiently advanced Artificial Intelligences might be like; and somebody starts dragging up the concepts of 'expected utility' or 'utility functions'.</p><p>And before we even ask what those are, we might first ask, <em>Why?</em></p><p>There's a mathematical formalism, 'expected utility', that some people invented to talk about making decisions. This formalism is very academically popular, and appears in all the textbooks.</p><p>But so what? Why is that <em>necessarily</em> the best way of making decisions under every kind of circumstance? Why would an Artificial Intelligence care what's academically popular? Maybe there's some better way of thinking about rational agency? Heck, why is this formalism popular in the first place?</p><p>We can ask the same kinds of questions about <a href=""https://arbital.com/p/probability_theory/"">probability theory</a>:</p><p>Okay, we have this mathematical formalism in which the chance that X happens, aka <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb P(X)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, plus the chance that X doesn't happen, aka <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb P(\neg X)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">¬</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, must be represented in a way that makes the two quantities sum to unity: <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb P(X) + \mathbb P(\neg X) = 1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">¬</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>.</p><p>That formalism for probability has some neat mathematical properties. But so what? Why should the best way of reasoning about a messy, uncertain world have neat properties? Why shouldn't an agent reason about 'how likely is that' using something completely unlike probabilities? How do you <em>know</em> a sufficiently advanced Artificial Intelligence would reason in probabilities? You haven't seen an AI, so what do you think you know and how do you think you know it?</p><p>That entirely reasonable question is what this introduction tries to answer. There are, indeed, excellent reasons beyond academic habit and mathematical convenience for why we would by default invoke 'expected utility' and 'probability theory' to think about good human decisions, talk about rational agency, or reason about sufficiently advanced AIs.</p><p>The broad form of the answer seems easier to show than to tell, so we'll just plunge straight in.</p><br><h1>Why not circular preferences?</h1><p><em>De gustibus non est disputandum,</em> goes the proverb; matters of taste cannot be disputed. If I like onions on my pizza and you like pineapple, it's not that one of us is right and one of us is wrong. We just prefer different pizza toppings.</p><p>Well, but suppose I declare to you that I <em>simultaneously</em>:</p><ul><li>Prefer onions to pineapple on my pizza.</li><li>Prefer pineapple to mushrooms on my pizza.</li><li>Prefer mushrooms to onions on my pizza.</li></ul><p>If we use <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label="">_P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span></span></span> to denote my pizza preferences, with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X>_PY""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span></span></span></span></span> denoting that I prefer X to Y, then I am declaring:</p><div><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label=""\text{onions} >_P \text{pineapple} >_P \text{mushrooms} >_P \text{onions}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">onions</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">pineapple</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">mushrooms</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">onions</span></span></span></span></span></div><p>That sounds strange, to be sure. But is there anything <em>wrong</em> with that? Can we disputandum it?</p><p>We used the math symbol <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label="">""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span></span></span></span> which denotes an ordering. If we ask whether <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label="">_P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span></span></span> can be an ordering, it naughtily violates the standard transitivity axiom <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x > y,\; y > z \implies x > z""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⟹</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span></span></span></span></span>.</p><p>Okay, so then maybe we shouldn't have used the symbol <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label="">_P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span></span></span> or called it an ordering. Why is that necessarily bad?</p><p>We can try to imagine each pizza as having a numerical score denoting how much I like it. In that case, there's no way we could assign consistent numbers <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x,y,z""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span></span></span></span></span> to those three pizza toppings such that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x>y>z>x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>.</p><p>So maybe I don't assign numbers to my pizza. Why is that so awful?</p><p>Are there any grounds besides ""we like a certain mathematical formalism and your choices don't fit into our math,"" on which to criticize my three simultaneous preferences?</p><p>(Feel free to try to answer this yourself before continuing...)</p><hr class=""dividerBlock""><p>Click here to reveal and continue:</p><div class=""spoilers""><p class=""spoiler-v2"">Suppose I tell you that I prefer pineapple to mushrooms on my pizza. Suppose you're about to give me a slice of mushroom pizza; but by paying one penny (<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$0.01""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.01</span></span></span></span></span></span>) I can instead get a slice of pineapple pizza (which is just as fresh from the oven). It seems realistic to say that most people with a pineapple pizza preference would probably pay the penny, if they happened to have a penny in their pocket.<strong>¹</strong></p><p class=""spoiler-v2"">After I pay the penny, though, and just before I'm about to get the pineapple pizza, you offer me a slice of onion pizza instead—no charge for the change! If I was telling the truth about preferring onion pizza to pineapple, I should certainly accept the substitution if it's free.</p><p class=""spoiler-v2"">And then to round out the day, you offer me a mushroom pizza instead of the onion pizza, and again, since I prefer mushrooms to onions, I accept the swap.</p><p class=""spoiler-v2"">I end up with exactly the same slice of mushroom pizza I started with... and one penny poorer, because I previously paid $0.01 to swap mushrooms for pineapple.</p></div><hr class=""dividerBlock""><p>This seems like a <em>qualitatively</em> bad behavior on my part. By virtue of my incoherent preferences which cannot be given a consistent ordering, I have shot myself in the foot, done something self-defeating. We haven't said <em>how</em> I ought to sort out my inconsistent preferences. But no matter how it shakes out, it seems like there must be <em>some </em>better alternative—some better way I could reason that wouldn't spend a penny to go in circles. That is, I could at least have kept my original pizza slice and not spent the penny.</p><p>In a phrase you're going to keep hearing, I have executed a 'dominated strategy': there exists some other strategy that does strictly better.<strong>²</strong></p><p>Or as Steve Omohundro put it: If you prefer being in Berkeley to being in San Francisco; prefer being in San Jose to being in Berkeley; and prefer being in San Francisco to being in San Jose; then you're going to waste a lot of time on taxi rides.</p><p>None of this reasoning has told us that a non-self-defeating agent must prefer Berkeley to San Francisco or vice versa. There are at least six possible consistent orderings over pizza toppings, like <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\text{mushroom} >_P \text{pineapple} >_P \text{onion}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">mushroom</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">pineapple</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">onion</span></span></span></span></span></span> etcetera, and <em>any</em> consistent ordering would avoid paying to go in circles.<strong>³ </strong>We have not, in this argument, used pure logic to derive that pineapple pizza must taste better than mushroom pizza to an ideal rational agent. But we've seen that eliminating a certain kind of shoot-yourself-in-the-foot behavior, corresponds to imposing a certain <em>coherence</em> or <em>consistency</em> requirement on whatever preferences are there.</p><p>It turns out that this is just one instance of a large family of <em>coherence theorems</em> which all end up pointing at the same set of core properties. All roads lead to Rome, and all the roads say, ""If you are not shooting yourself in the foot in sense X, we can view you as having coherence property Y.""</p><p>There are some caveats to this general idea.</p><p>For example: In complicated problems, perfect coherence is usually impossible to compute—it's just too expensive to consider <em>all</em> the possibilities.</p><p>But there are also caveats to the caveats! For example, it may be that if there's a powerful machine intelligence that is not <em>visibly to us humans</em> shooting itself in the foot in way X, then <em>from our perspective</em> it must look like the AI has coherence property Y. If there's some sense in which the machine intelligence is going in circles, because <em>not</em> going in circles is too hard to compute, well, <em>we</em> won't see that either with our tiny human brains. In which case it may make sense, from our perspective, to think about the machine intelligence <em>as if</em> it has some coherent preference ordering.</p><p>We are not going to go through all the coherence theorems in this introduction. They form a very large family; some of them are a <em>lot</em> more mathematically intimidating; and honestly I don't know even 5% of the variants.</p><p>But we can hopefully walk through enough coherence theorems to at least start to see the reasoning behind, ""Why expected utility?"" And, because the two are a package deal, ""Why probability?""</p><br><h1>Human lives, mere dollars, and coherent trades</h1><p>An experiment in 2000—from a paper titled ""<a href=""http://scholar.harvard.edu/files/jenniferlerner/files/2000_the_psychology_of_the_unthinkable.pdf?m=145089665"">The Psychology of the Unthinkable: Taboo Trade-Offs, Forbidden Base Rates, and Heretical Counterfactuals</a>""—asked subjects to consider the dilemma of a hospital administrator named Robert:</p><blockquote>Robert can save the life of Johnny, a five year old who needs a liver transplant, but the transplant procedure will cost the hospital $1,000,000 that could be spent in other ways, such as purchasing better equipment and enhancing salaries to recruit talented doctors to the hospital. Johnny is very ill and has been on the waiting list for a transplant but because of the shortage of local organ donors, obtaining a liver will be expensive. Robert could save Johnny's life, or he could use the $1,000,000 for other hospital needs.</blockquote><p>The main experimental result was that most subjects got angry at Robert for even considering the question.</p><p>After all, you can't put a dollar value on a human life, right?</p><p>But better hospital equipment also saves lives, or at least one hopes so.<strong>⁴</strong> It's not like the other potential use of the money saves zero lives.</p><p>Let's say that Robert has a total budget of $100,000,000 and is faced with a long list of options such as these:</p><ul><li>$100,000 for a new dialysis machine, which will save 3 lives</li><li>$1,000,000 for a liver for Johnny, which will save 1 life</li><li>$10,000 to train the nurses on proper hygiene when inserting central lines, which will save an expected 100 lives</li><li>...</li></ul><p>Now suppose—this is a supposition we'll need for our theorem—that Robert <em>does not care at all about money,</em> not even a tiny bit. Robert <em>only</em> cares about maximizing the total number of lives saved. Furthermore, we suppose for now that Robert cares about every human life equally.</p><p>If Robert does save as many lives as possible, given his bounded money, then Robert must <em>behave like </em>somebody assigning some consistent dollar value to saving a human life.</p><p>We should be able to look down the long list of options that Robert took and didn't take, and say, e.g., ""Oh, Robert took all the options that saved more than 1 life per $500,000 and rejected all options that saved less than 1 life per $500,000; so Robert's behavior is <em>consistent</em> with his spending $500,000 per life.""</p><p>Alternatively, if we can't view Robert's behavior as being coherent in this sense—if we cannot make up <em>any</em> dollar value of a human life, such that Robert's choices are consistent with that dollar value—then it must be possible to move around the same amount of money, in a way that saves more lives.</p><p>We start from the qualitative criterion, ""Robert must save as many lives as possible; it shouldn't be possible to move around the same money to save more lives."" We end up with the quantitative coherence theorem, ""It must be possible to view Robert as trading dollars for lives at a consistent price.""</p><p>We haven't proven that dollars have some intrinsic worth that trades off against the intrinsic worth of a human life. By hypothesis, Robert doesn't care about money at all. It's just that every dollar has an <em>opportunity cost</em> in lives it could have saved if deployed differently; and this opportunity cost is the same for every dollar because money is fungible.</p><p>An important caveat to this theorem is that there may be, e.g., an option that saves a hundred thousand lives for $200,000,000. But Robert only has $100,000,000 to spend. In this case, Robert may fail to take that option even though it saves 1 life per $2,000. It was a good option, but Robert didn't have enough money in the bank to afford it. This does mess up the elegance of being able to say, ""Robert must have taken <em>all</em> the options saving at least 1 life per $500,000"", and instead we can only say this with respect to options that are in some sense small enough or granular enough.</p><p>Similarly, if an option costs $5,000,000 to save 15 lives, but Robert only has $4,000,000 left over after taking all his other best opportunities, Robert's last selected option might be to save 8 lives for $4,000,000 instead. This again messes up the elegance of the reasoning, but Robert is still doing exactly what an agent <em>would</em> do if it consistently valued lives at 1 life per $500,000—it would buy all the best options <em>it could afford</em> that purchased at least that many lives per dollar. So that part of the theorem's conclusion still holds.</p><p>Another caveat is that we haven't proven that there's some specific dollar value in Robert's head, as a matter of psychology. We've only proven that Robert's outward behavior can be <em>viewed as if</em> it prices lives at <em>some </em>consistent value, assuming Robert saves as many lives as possible.</p><p>It could be that Robert accepts every option that spends less than $500,000/life and rejects every option that spends over $600,000, and there aren't any available options in the middle. Then Robert's behavior can equally be <em>viewed as</em> consistent with a price of $510,000 or a price of $590,000. This helps show that we haven't proven anything about Robert explicitly <em>thinking</em> of some number. Maybe Robert never lets himself think of a specific threshold value, because it would be taboo to assign a dollar value to human life; and instead Robert just fiddles the choices until he can't see how to save any more lives.</p><p>We naturally have not proved by pure logic that Robert must want, in the first place, to save as many lives as possible. Even if Robert is a good person, this doesn't follow. Maybe Robert values a 10-year-old's life at 5 times the value of a 70-year-old's life, so that Robert will sacrifice five grandparents to save one 10-year-old. A lot of people would see that as entirely consistent with valuing human life in general.</p><p>Let's consider that last idea more thoroughly. If Robert considers a preteen equally valuable with 5 grandparents, so that Robert will shift $100,000 from saving 8 old people to saving 2 children, then we can no longer say that Robert wants to save as many 'lives' as possible. That last decision would decrease by 6 the total number of 'lives' saved. So we can no longer say that there's a qualitative criterion, 'Save as many lives as possible', that produces the quantitative coherence requirement, 'trade dollars for lives at a consistent rate'.</p><p>Does this mean that coherence might as well go out the window, so far as Robert's behavior is concerned? Anything goes, now? Just spend money wherever?</p><p>""Hm,"" you might think. ""But... if Robert trades 8 old people for 2 children <em>here</em>... and then trades 1 child for 2 old people <em>there</em>...""</p><p>To reduce distraction, let's make this problem be about apples and oranges instead. Suppose:</p><ul><li>Alice starts with 8 apples and 1 orange.</li><li>Then Alice trades 8 apples for 2 oranges.</li><li>Then Alice trades away 1 orange for 2 apples.</li><li>Finally, Alice trades another orange for 3 apples.</li></ul><p>Then in this example, Alice is using a strategy that's <em>strictly dominated</em> across all categories of fruit. Alice ends up with 5 apples and one orange, but could've ended with 8 apples and one orange (by not making any trades at all). Regardless of the <em>relative</em> value of apples and oranges, Alice's strategy is doing <em>qualitatively</em> worse than another possible strategy, if apples have any positive value to her at all.</p><p>So the fact that Alice can't be viewed as having any coherent relative value for apples and oranges, corresponds to her ending up with qualitatively less of some category of fruit (without any corresponding gains elsewhere).</p><p>This remains true if we introduce more kinds of fruit into the problem. Let's say the set of fruits Alice can trade includes {apples, oranges, strawberries, plums}. If we can't look at Alice's trades and make up some relative quantitative values of fruit, such that Alice could be trading consistently with respect to those values, then Alice's trading strategy must have been dominated by some other strategy that would have ended up with strictly more fruit across all categories.</p><p>In other words, we need to be able to look at Alice's trades, and say something like:</p><p>""Maybe Alice values an orange at 2 apples, a strawberry at 0.1 apples, and a plum at 0.5 apples. That would explain why Alice was willing to trade 4 strawberries for a plum, but not willing to trade 40 strawberries for an orange and an apple.""</p><p>And if we <em>can't</em> say this, then there must be some way to rearrange Alice's trades and get <em>strictly more fruit across all categories</em> in the sense that, e.g., we end with the same number of plums and apples, but one more orange and two more strawberries. This is a bad thing if Alice <em>qualitatively</em> values fruit from each category—prefers having more fruit to less fruit, ceteris paribus, for each category of fruit.</p><p>Now let's shift our attention back to Robert the hospital administrator. <em>Either</em> we can view Robert as consistently assigning some <em>relative</em> value of life for 10-year-olds vs. 70-year-olds, <em>or</em> there must be a way to rearrange Robert's expenditures to save either strictly more 10-year-olds or strictly more 70-year-olds. The same logic applies if we add 50-year-olds to the mix. We must be able to say something like, ""Robert is consistently behaving as if a 50-year-old is worth a third of a ten-year-old"". If we <em>can't</em> say that, Robert must be behaving in a way that pointlessly discards some saveable lives in some category.</p><p>Or perhaps Robert is behaving in a way which implies that 10-year-old girls are worth more than 10-year-old boys. But then the relative values of those subclasses of 10-year-olds need to be viewable as consistent; or else Robert must be qualitatively failing to save one more 10-year-old boy than could've been saved otherwise.</p><p>If you can denominate apples in oranges, and price oranges in plums, and trade off plums for strawberries, all at consistent rates... then you might as well take it one step further, and factor out an abstract unit for ease of notation.</p><p>Let's call this unit <em>1 utilon,</em> and denote it €1. (As we'll see later, the letters 'EU' are appropriate here.)</p><p>If we say that apples are worth €1, oranges are worth €2, and plums are worth €0.5, then this tells us the relative value of apples, oranges, and plums. Conversely, if we <em>can</em> assign consistent relative values to apples, oranges, and plums, then we can factor out an abstract unit at will—for example, by arbitrarily declaring apples to be worth €100 and then calculating everything else's price in apples.</p><p>Have we proven by pure logic that all apples have the same utility? Of course not; you can prefer some particular apples to other particular apples. But when you're done saying which things you qualitatively prefer to which other things, if you go around making tradeoffs in a way that can be <em>viewed as</em> not qualitatively leaving behind some things you said you wanted, we can <em>view you</em> as assigning coherent quantitative utilities to everything you want.</p><p>And that's one coherence theorem—among others—that can be seen as motivating the concept of <em>utility</em> in decision theory.</p><p>Utility isn't a solid thing, a separate thing. We could multiply all the utilities by two, and that would correspond to the same outward behaviors. It's meaningless to ask how much utility you scored at the end of your life, because we could subtract a million or add a million to that quantity while leaving everything else conceptually the same.</p><p>You could pick anything you valued—say, the joy of watching a cat chase a laser pointer for 10 seconds—and denominate everything relative to that, without needing any concept of an extra abstract 'utility'. So (just to be extremely clear about this point) we have not proven that there is a separate thing 'utility' that you should be pursuing instead of everything else you wanted in life.</p><p>The coherence theorem says nothing about which things to value more than others, or how much to value them relative to other things. It doesn't say whether you should value your happiness more than someone else's happiness, any more than the notion of a consistent preference ordering <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label="">_P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span></span></span> tells us whether <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\text{onions} >_P \text{pineapple}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">onions</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">pineapple</span></span></span></span></span></span>.</p><p>(The notion that we should assign equal value to all human lives, or equal value to all sentient lives, or equal value to all Quality-Adjusted Life Years, is <em>utilitarianism.</em> Which is, sorry about the confusion, a whole 'nother separate different philosophy.)</p><p>The conceptual gizmo that maps thingies to utilities—the whatchamacallit that takes in a fruit and spits out a utility—is called a 'utility function'. Again, this isn't a separate thing that's written on a stone tablet. If we multiply a utility function by 9.2, that's conceptually the same utility function because it's consistent with the same set of behaviors.</p><p>But in general: If we can sensibly view any agent as doing as well as qualitatively possible at <em>anything</em>, we must be able to view the agent's behavior as consistent with there being some coherent relative quantities of wantedness for all the thingies it's trying to optimize.</p><br><h1>Probabilities and expected utility</h1><p>We've so far made no mention of <em>probability.</em> But the way that probabilities and utilities interact, is where we start to see the full structure of <em>expected utility</em> spotlighted by all the coherence theorems.</p><p>The basic notion in expected utility is that some choices present us with uncertain outcomes.</p><p>For example, I come to you and say: ""Give me 1 apple, and I'll flip a coin; if the coin lands heads, I'll give you 1 orange; if the coin comes up tails, I'll give you 3 plums."" Suppose you relatively value fruits as described earlier: 2 apples / orange and 0.5 apples / plum. Then <em>either</em> possible outcome gives you something that's worth more to you than 1 apple. Turning down a so-called 'gamble' like that... why, it'd be a dominated strategy.</p><p>In general, the notion of 'expected utility' says that we assign certain quantities called <em>probabilities</em> to each possible outcome. In the example above, we might assign a 'probability' of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0.5""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.5</span></span></span></span></span></span> to the coin landing heads (1 orange), and a 'probability' of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0.5""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.5</span></span></span></span></span></span> to the coin landing tails (3 plums). Then the total value of the 'gamble' we get by trading away 1 apple is:</p><div><span class=""mjx-chtml MJXc-display""><span class=""mjx-math"" style=""width: 100%;"" aria-label=""\mathbb P(heads) \cdot U(\text{1 orange}) + \mathbb P(tails) \cdot U(\text{3 plums}) \\
= 0.50 \cdot €2 + 0.50 \cdot €1.5 = €1.75""><span class=""mjx-mrow"" style=""width: 100%;"" aria-hidden=""true""><span class=""mjx-stack"" style=""width: 100%; vertical-align: -1.542em;""><span class=""mjx-block"" style=""text-align: center;""><span class=""mjx-box""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">1 orange</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">3 plums</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span><span class=""mjx-block"" style=""text-align: center; padding-top: 0.442em;""><span class=""mjx-box""><span class=""mjx-mspace"" style=""width: 0px; height: 0px;""></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.50</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.50</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1.5</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1.75</span></span></span></span></span></span></span></span></div><p>Conversely, if we just keep our 1 apple instead of making the trade, this has an expected utility of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""1 \cdot U(\text{1 apple}) = €1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">1 apple</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>. So indeed we ought to trade (as the previous reasoning suggested).</p><p>""But wait!"" you cry. ""Where did these probabilities come from? Why is the 'probability' of a fair coin landing heads <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0.5""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.5</span></span></span></span></span></span> and not, say, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""−0.2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.2</span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span>? Who says we ought to multiply utilities by probabilities in the first place?""</p><p>If you're used to approaching this problem from a <a href=""https://arbital.com/p/bayes_rule_guide/"">Bayesian</a> standpoint, then you may now be thinking of notions like <a href=""https://arbital.com/p/prior_probability/"">prior probability</a> and Occam's Razor and <a href=""https://arbital.com/p/universal_prior/"">universal priors</a>...</p><p>But from the standpoint of coherence theorems, that's putting the cart before the horse.</p><p>From the standpoint of coherence theorems, we don't <em>start with</em> a notion of 'probability'.</p><p>Instead we ought to prove something along the lines of: if you're not using qualitatively dominated strategies, then you must <em>behave as if</em> you are multiplying utilities by certain quantitative thingies.</p><p>We might then furthermore show that, for non-dominated strategies, these utility-multiplying thingies must be between <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> rather than say <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""−0.3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.3</span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""27""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">27</span></span></span></span></span></span>.</p><p>Having determined what coherence properties these utility-multiplying thingies need to have, we decide to call them 'probabilities'. And <em>then</em>—once we know in the first place that we need 'probabilities' in order to not be using dominated strategies—we can start to worry about exactly what the numbers ought to be.</p><br><h2>Probabilities summing to 1</h2><p>Here's a taste of the kind of reasoning we might do:</p><p>Suppose that—having already accepted some previous proof that non-dominated strategies dealing with uncertain outcomes, must multiply utilities by quantitative thingies—you then say that you are going to assign a probability of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0.6""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.6</span></span></span></span></span></span> to the coin coming up heads, and a probability of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0.7""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.7</span></span></span></span></span></span> to the coin coming up tails.</p><p>If you're already used to the standard notion of probability, you might object, ""But those probabilities sum to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""1.3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1.3</span></span></span></span></span></span> when they ought to sum to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>!""<strong>⁵</strong> But now we are in coherence-land; we don't ask ""Did we violate the standard axioms that all the textbooks use?"" but ""What rules must non-dominated strategies obey?"" <em>De gustibus non est disputandum;</em> can we <em>disputandum</em> somebody saying that a coin has a 60% probability of coming up heads and a 70% probability of coming up tails? (Where these are the only 2 possible outcomes of an uncertain coinflip.)</p><p>Well—assuming you've already accepted that we need utility-multiplying thingies—I might then offer you a gamble. How about you give me one apple, and if the coin lands heads, I'll give you 0.8 apples; while if the coin lands tails, I'll give you 0.8 apples.</p><p>According to you, the expected utility of this gamble is:</p><div><span class=""mjx-chtml MJXc-display""><span class=""mjx-math"" style=""width: 100%;"" aria-label=""\mathbb P(\text{heads}) \cdot U(\text{0.8 apples}) + \mathbb P(\text{tails}) \cdot U(\text{0.8 apples}) \\
= 0.6 \cdot €0.8 + 0.7 \cdot €0.8 = €1.04.""><span class=""mjx-mrow"" style=""width: 100%;"" aria-hidden=""true""><span class=""mjx-stack"" style=""width: 100%; vertical-align: -1.542em;""><span class=""mjx-block"" style=""text-align: center;""><span class=""mjx-box""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">heads</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">0.8 apples</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">tails</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.519em;"">0.8 apples</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span><span class=""mjx-block"" style=""text-align: center; padding-top: 0.442em;""><span class=""mjx-box""><span class=""mjx-mspace"" style=""width: 0px; height: 0px;""></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.6</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.8</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.7</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.8</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">€</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1.04.</span></span></span></span></span></span></span></span></div><p>You've just decided to trade your apple for 0.8 apples, which sure sounds like one of 'em dominated strategies.</p><p>And that's why <em>the thingies you multiply probabilities by</em>—the thingies that you use to weight uncertain outcomes in your imagination, when you're trying to decide how much you want one branch of an uncertain choice—must sum to 1, whether you call them 'probabilities' or not.</p><p>Well... actually we just argued<strong>⁶</strong> that probabilities for <a href=""https://arbital.com/p/exclusive_exhaustive/"">mutually exclusive</a> outcomes should sum to <em>no more than 1.</em> What would be an example showing that, for non-dominated strategies, the probabilities for <a href=""https://arbital.com/p/exclusive_exhaustive/"">exhaustive</a> outcomes should sum to no less than 1?</p><hr class=""dividerBlock""><p>Why exhaustive outcomes should sum to at least 1:</p><div class=""spoilers""><p class=""spoiler-v2"">Suppose that, in exchange for 1 apple, I credibly offer:</p><p class=""spoiler-v2"">* To pay you 1.1 apples if a coin comes up heads.<br>* To pay you 1.1 apples if a coin comes up tails.<br>* To pay you 1.1 apples if anything else happens.</p><p class=""spoiler-v2"">If the probabilities you assign to these three outcomes sum to say 0.9, you will refuse to trade 1 apple for 1.1 apples.</p><p class=""spoiler-v2"">(This is strictly dominated by the strategy of agreeing to trade 1 apple for 1.1 apples.)</p></div><hr class=""dividerBlock""><br><h2>Dutch book arguments</h2><p>Another way we could have presented essentially the same argument as above, is as follows:</p><p>Suppose you are a market-maker in a prediction market for some event <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span>. When you say that your price for event <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, you mean that you will sell for <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> a ticket which pays <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> happens (and pays out nothing otherwise). In fact, you will sell any number of such tickets!</p><p>Since you are a market-maker (that is, you are trying to encourage trading in <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> for whatever reason), you are also willing to <em>buy</em> any number of tickets at the price <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>. That is, I can say to you (the market-maker) ""I'd like to sign a contract where you give me <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""N \cdot \$x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> now, and in return I must pay you <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span></span></span></span> iff <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> happens;"" and you'll agree. (We can view this as you selling me a negative number of the original kind of ticket.)</p><p>Let <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span></span></span></span></span> denote two events such that <em>exactly one</em> of them must happen; say, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> is a coin landing heads and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span></span></span></span></span> is the coin not landing heads.</p><p>Now suppose that you, as a market-maker, are motivated to avoid combinations of bets that lead into <em>certain </em>losses for you—not just losses that are merely probable, but combinations of bets such that <em>every</em> possibility leads to a loss.</p><p>Then if exactly one of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span></span></span></span></span> must happen, your prices <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span> must sum to exactly <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>. Because:</p><ul><li>If <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x+y<$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>, I buy both an <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span>-ticket and a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span></span></span></span></span>-ticket and get a guaranteed payout of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> minus costs of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x+y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>. Since this is a guaranteed profit for me, it is a guaranteed loss for you.</li><li>If <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x+y>$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>, I sell you both tickets and will at the end pay you <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> after you have already paid me <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x+y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>. Again, this is a guaranteed profit for me of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x+y−$1>$0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>.</li></ul><p>This is more or less exactly the same argument as in the previous section, with trading apples. Except that: (a) the scenario is more crisp, so it is easier to generalize and scale up much more complicated similar arguments; and (b) it introduces a whole lot of assumptions that people new to expected utility would probably find rather questionable.</p><p>""What?"" one might cry. ""What sort of crazy bookie would buy and sell bets at exactly the same price? Why ought <em>anyone</em> to buy and sell bets at exactly the same price? Who says that I must value a gain of $1 exactly the opposite of a loss of $1? Why should the price that I put on a bet represent my degree of uncertainty about the environment? What does all of this argument about gambling have to do with real life?""</p><p>So again, the key idea is not that we are assuming anything about people valuing every real-world dollar the same; nor is it in real life a good idea to offer to buy or sell bets at the same prices.<strong>⁷</strong> Rather, Dutch book arguments can stand in as shorthand for some longer story in which we only assume that you prefer more apples to less apples.</p><p>The Dutch book argument above has to be seen as one more added piece in the company of all the <em>other </em>coherence theorems—for example, the coherence theorems suggesting that you ought to be quantitatively weighing events in your mind in the first place.</p><br><h2>Conditional probability</h2><p>With more complicated Dutch book arguments, we can derive more complicated ideas such as 'conditional probability'.</p><p>Let's say that we're pricing three kinds of gambles over two events <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span>:</p><ul><li>A ticket that costs <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, and pays <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> happens.</li><li>A ticket that doesn't cost anything or pay anything if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> doesn't happen (the ticket price is refunded); and if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> does happen, this ticket costs <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>, then pays <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> happens.</li><li>A ticket that costs <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$z""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span></span></span></span></span>, and pays <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> both happen.</li></ul><p>Intuitively, the idea of <a href=""https://arbital.com/p/conditional_probability/"">conditional probability</a> is that the probability of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> both happening, should be equal to the probability of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> happening, times the probability that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> happens assuming that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> happens:</p><div><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label=""\mathbb P(Q \wedge R) = \mathbb P(Q) \cdot \mathbb P(R \mid Q)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.372em;"">∧</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></div><p>To exhibit a Dutch book argument for this rule, we want to start from the assumption of a qualitatively non-dominated strategy, and derive the quantitative rule <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z=x⋅y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>.</p><p>So let's give an example that violates this equation and see if there's a way to make a guaranteed profit. Let's say somebody:</p><ul><li>Prices at <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x=$0.60""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.60</span></span></span></span></span></span> the first ticket, aka <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb P(Q)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</li><li>Prices at <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""y=$0.70""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.70</span></span></span></span></span></span> the second ticket, aka <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb P(R \mid Q)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</li><li>Prices at <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z=$0.20""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.20</span></span></span></span></span></span> the third ticket, aka <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb P(Q \wedge R)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">P</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.372em;"">∧</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, which ought to be <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""$0.42""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">$</span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.42</span></span></span></span></span></span> assuming the first two prices.</li></ul><p>The first two tickets are priced relatively high, compared to the third ticket which is priced relatively low, suggesting that we ought to sell the first two tickets and buy the third.</p><p>Okay, let's ask what happens if we sell 10 of the first ticket, sell 10 of the second ticket, and buy 10 of the third ticket.</p><ul><li>If <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> doesn't happen, we get $6, and pay $2. Net +$4.</li><li>If <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> happens and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> doesn't happen, we get $6, pay $10, get $7, and pay $2. Net +$1.</li><li>If <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span> happens and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> happens, we get $6, pay $10, get $7, pay $10, pay $2, and get $10. Net: +$1.</li></ul><p>That is: we can get a guaranteed positive profit over all three possible outcomes.</p><p>More generally, let <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A,B,C""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span></span></span></span></span> be the (potentially negative) amount of each ticket <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X,Y,Z""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;"">Y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;"">Z</span></span></span></span></span></span> that is being bought (buying a negative amount is selling). Then the prices <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x,y,z""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span></span></span></span></span> can be combined into a 'Dutch book' whenever the following three inequalities can be simultaneously true, with at least one inequality strict:</p><div><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label=""\begin{array}{rrrl}
-Ax &amp; + 0 &amp; - Cz &amp; \geqq 0 \\
A(1-x) &amp; - By &amp; - Cz &amp; \geqq 0 \\
A(1-x) &amp; + B(1-y) &amp; + C(1-z) &amp; \geqq 0
\end{array}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mtable"" style=""vertical-align: -1.725em; padding: 0px 0.167em;""><span class=""mjx-table""><span class=""mjx-mtr"" style=""height: 1.2em;""><span class=""mjx-mtd"" style=""padding: 0px 0.5em 0px 0px; text-align: right; width: 3.822em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0px 0.5em 0px 0.5em; text-align: right; width: 4.533em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0px 0.5em 0px 0.5em; text-align: right; width: 4.506em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0px 0px 0px 0.5em; text-align: left; width: 1.556em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">≧</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-strut""></span></span></span></span><span class=""mjx-mtr"" style=""height: 1.475em;""><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0px; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0.5em; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0.5em; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0px 0px 0.5em; text-align: left;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">≧</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-strut""></span></span></span></span><span class=""mjx-mtr"" style=""height: 1.275em;""><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0px; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0.5em; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0.5em; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0px 0px 0.5em; text-align: left;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">≧</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-strut""></span></span></span></span></span></span></span></span></span></div><p>For <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x, y, z \in (0..1)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0..1</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> this is impossible exactly iff <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z=x \cdot y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>. The proof via a bunch of algebra is left as an exercise to the reader.<strong>⁸</strong></p><br><h2>The Allais Paradox</h2><p>By now, you'd probably like to see a glimpse of the sort of argument that shows in the first place that we need expected utility—that a non-dominated strategy for uncertain choice must behave as if multiplying utilities by some kinda utility-multiplying thingies ('probabilities').</p><p>As far as I understand it, the real argument you're looking for is <a href=""https://projecteuclid.org/download/pdf_1/euclid.aoms/1177730345"">Abraham Wald's complete class theorem</a>, which I must confess I don't know how to reduce to a simple demonstration.</p><p>But we can catch a glimpse of the general idea from a famous psychology experiment that became known as the Allais Paradox (in slightly adapted form).</p><p>Suppose you ask some experimental subjects which of these gambles they would rather play:</p><ul><li>1A: A certainty of $1,000,000.</li><li>1B: 90% chance of winning $5,000,000, 10% chance of winning nothing.</li></ul><p>Most subjects say they'd prefer 1A to 1B.</p><p>Now ask a separate group of subjects which of these gambles they'd prefer:</p><ul><li>2A: 50% chance of winning $1,000,000; 50% chance of winning $0.</li><li>2B: 45% chance of winning $5,000,000; 55% chance of winning $0.</li></ul><p>In this case, most subjects say they'd prefer gamble 2B.</p><p>Note that the $ sign here denotes real dollars, not utilities! A gain of five million dollars isn't, and shouldn't be, worth exactly five times as much to you as a gain of one million dollars. We can use the € symbol to denote the expected utilities that are abstracted from how much you relatively value different outcomes; $ is just money.</p><p>So we certainly aren't claiming that the first preference is paradoxical because 1B has an expected dollar value of $4.5 million and 1A has an expected dollar value of $1 million. That would be silly. We care about expected utilities, not expected dollar values, and those two concepts aren't the same at all!</p><p>Nonetheless, the combined preferences 1A &gt; 1B and 2A &lt; 2B are not compatible with any coherent utility function. We cannot simultaneously have:</p><div><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label=""\begin{array}{rcl}
U(\text{gain \$1M}) &amp; > &amp; 0.9 \cdot U(\text{gain \$5M}) + 0.1 \cdot U(\text{gain \$0}) \\
0.5 \cdot U(\text{gain \$0}) + 0.5 \cdot U(\text{gain \$1M}) &amp; < &amp; 0.45 \cdot U(\text{gain \$5M}) + 0.55 \cdot U(\text{gain \$0})
\end{array}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mtable"" style=""vertical-align: -1.025em; padding: 0px 0.167em;""><span class=""mjx-table""><span class=""mjx-mtr"" style=""height: 1.275em;""><span class=""mjx-mtd"" style=""padding: 0px 0.5em 0px 0px; text-align: right; width: 15.398em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $1M</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0px 0.5em 0px 0.5em; width: 0.778em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0px 0px 0px 0.5em; text-align: left; width: 16.398em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.9</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $5M</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $0</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span></span><span class=""mjx-mtr"" style=""height: 1.275em;""><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0px; text-align: right;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.5</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $0</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.5</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $1M</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0.5em 0px 0.5em;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-strut""></span></span></span><span class=""mjx-mtd"" style=""padding: 0.2em 0px 0px 0.5em; text-align: left;""><span class=""mjx-mrow"" style=""margin-top: -0.2em;""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.45</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $5M</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.55</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">gain $0</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-strut""></span></span></span></span></span></span></span></span></span></div><p>This was one of the earliest experiments seeming to demonstrate that actual human beings were not expected utility maximizers—a very tame idea nowadays, to be sure, but the <em>first definite</em> demonstration of that was a big deal at the time. Hence the term, ""Allais Paradox"".</p><p>Now, by the general idea behind coherence theorems, since we can't <em>view this behavior</em> as corresponding to expected utilities, we ought to be able to show that it corresponds to a dominated strategy somehow—derive some way in which this behavior corresponds to shooting off your own foot.</p><p>In this case, the relevant idea seems non-obvious enough that it doesn't seem reasonable to demand that you think of it on your own; but if you like, you can pause and try to think of it anyway. Otherwise, just continue reading.</p><hr class=""dividerBlock""><p>Again, the gambles are as follows:</p><ul><li>1A: A certainty of $1,000,000.</li><li>1B: 90% chance of winning $5,000,000, 10% chance of winning nothing.</li><li>2A: 50% chance of winning $1,000,000; 50% chance of winning $0.</li><li>2B: 45% chance of winning $5,000,000; 55% chance of winning $0.</li></ul><p>Now observe that Scenario 2 corresponds to a 50% chance of playing Scenario 1, and otherwise getting $0.</p><p>This, in fact, is why the combination 1A &gt; 1B; 2A &lt; 2B is incompatible with expected utility. In terms of <a href=""https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem#The_axioms"">one set of axioms</a> frequently used to describe expected utility, it violates the Independence Axiom: if a gamble <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""L""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span></span></span></span></span> is preferred to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span> (that is, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""L>M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span>), then we ought to be able to take a constant probability <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p>0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span> and another gamble <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span></span></span></span> and have <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p \cdot L + (1-p)\cdot N > p \cdot M + (1-p) \cdot N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋅</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span></span></span></span>.</p><p>To put it another way, if I flip a coin to decide whether or not to play some entirely different game <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span></span></span></span>, but otherwise let you choose <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""L""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span>, you ought to make the same choice as if I just ask you whether you prefer <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""L""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span>. Your preference between <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""L""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span> should be 'independent' of the possibility that, instead of doing anything whatsoever with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""L""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span>, we will do something else instead.</p><p>And since this is an axiom of expected utility, any violation of that axiom ought to correspond to a dominated strategy somehow.</p><p>In the case of the Allais Paradox, we do the following:</p><p>First, I show you a switch that can be set to A or B, currently set to A.</p><p>In one minute, I tell you, I will flip a coin. If the coin comes up heads, you will get nothing. If the coin comes up tails, you will play the gamble from Scenario 1.</p><p>From your current perspective, that is, we are playing Scenario 2: since the switch is set to A, you have a 50% chance of getting nothing and a 50% chance of getting $1 million.</p><p>I ask you if you'd like to pay a penny to throw the switch from A to B. Since you prefer gamble 2B to 2A, and some quite large amounts of money are at stake, you agree to pay the penny. From your perspective, you now have a 55% chance of ending up with nothing and a 45% chance of getting $5M.</p><p>I then flip the coin, and luckily for you, it comes up tails.</p><p>From your perspective, you are now in Scenario 1B. Having observed the coin and updated on its state, you now think you have a 90% chance of getting $5 million and a 10% chance of getting nothing. By hypothesis, you would prefer a certainty of $1 million.</p><p>So I offer you a chance to pay another penny to flip the switch back from B to A. And with so much money at stake, you agree.</p><p>I have taken your two cents on the subject.</p><p>That is: You paid a penny to flip a switch and then paid another penny to switch it back, and this is dominated by the strategy of just leaving the switch set to A.</p><p>And that's at least a glimpse of why, if you're not using dominated strategies, the thing you do with relative utilities is multiply them by probabilities in a consistent way, and prefer the choice that leads to a greater expectation of the variable representing utility.</p><br><p><strong>From the Allais Paradox to real life</strong></p><p>The real-life lesson about what to do when faced with Allais's dilemma might be something like this:</p><p>There's <em>some</em> amount that $1 million would improve your life compared to $0.</p><p>There's some amount that an additional $4 million would further improve your life after the first $1 million.</p><p>You ought to visualize these two improvements as best you can, and decide whether another $4 million can produce at least <em>one-ninth</em> as much improvement, as much true value to you, as the first $1 million.</p><p>If it can, you should consistently prefer 1B &gt; 1A; 2B &gt; 2A. And if not, you should consistently prefer 1A &gt; 1B; 2A &gt; 2B.</p><p>The standard 'paradoxical' preferences in Allais's experiment are standardly attributed to a certainty effect: people value the <em>certainty</em> of having $1 million, while the difference between a 50% probability and a 55% probability looms less large. (And this ties in to a number of other results about certainty, need for closure, prospect theory, and so on.)</p><p>It may sound intuitive, in an Allais-like scenario, to say that you ought to derive some value from being <em>certain </em>about the outcome. In fact this is just the reasoning the experiment shows people to be using, so of course it might sound intuitive. But that does, inescapably, correspond to a kind of thinking that produces dominated strategies.</p><p>One possible excuse might be that certainty is valuable if you need to make plans about the future; knowing the exact future lets you make better plans. This is admittedly true and a phenomenon within expected utility, though it applies in a smooth way as confidence increases rather than jumping suddenly around 100%. But in the particular dilemma as described here, you only have 1 minute before the game is played, and no time to make other major life choices dependent on the outcome.</p><p>Another possible excuse for certainty bias might be to say: ""Well, I value the emotional feeling of certainty.""</p><p>In real life, we do have emotions that are directly about probabilities, and those little flashes of happiness or sadness are worth something if you care about people being happy or sad. If you say that you value the emotional feeling of being <em>certain</em> of getting $1 million, the freedom from the fear of getting $0, for the minute that the dilemma lasts and you are experiencing the emotion—well, that may just be a fact about what you value, even if it exists outside the expected utility formalism.</p><p>And this genuinely does not fit into the expected utility formalism. In an expected utility agent, probabilities are just thingies-you-multiply-utilities-by. If those thingies start generating their own utilities once represented inside the mind of the person who is an object of ethical value, you really are going to get results that are incompatible with the formal decision theory.</p><p>However, <em>not</em> being viewable as an expected utility agent does always correspond to employing dominated strategies. You are giving up <em>something</em> in exchange, if you pursue that feeling of certainty. You are potentially losing all the real value you could have gained from another $4 million, if that realized future actually would have gained you more than one-ninth the value of the first $1 million. Is a fleeting emotional sense of certainty over 1 minute, worth <em>automatically</em> discarding the potential $5-million outcome? Even if the correct answer given your values is that you properly ought to take the $1 million, treasuring 1 minute of emotional gratification doesn't seem like the wise reason to do that. The wise reason would be if the first $1 million really was worth that much more than the next $4 million.</p><p>The danger of saying, ""Oh, well, I attach a lot of utility to that comfortable feeling of certainty, so my choices are coherent after all"" is not that it's mathematically improper to value the emotions we feel while we're deciding. Rather, by saying that the <em>most valuable</em> stakes are the emotions you feel during the minute you make the decision, what you're saying is, ""I get a huge amount of value by making decisions however humans instinctively make their decisions, and that's much more important than the thing I'm making a decision <em>about.</em>"" This could well be true for something like buying a stuffed animal. If millions of dollars or human lives are at stake, maybe not so much.</p><br><h1>Conclusion</h1><p>The demonstrations we've walked through here aren't the professional-grade coherence theorems as they appear in real math. Those have names like ""<a href=""https://en.wikipedia.org/wiki/Cox's_theorem"">Cox's Theorem</a>"" or ""the complete class theorem""; their proofs are difficult; and they say things like ""If seeing piece of information A followed by piece of information B leads you into the same epistemic state as seeing piece of information B followed by piece of information A, plus some other assumptions, I can show an isomorphism between those epistemic states and classical probabilities"" or ""Any decision rule for taking different actions depending on your observations either corresponds to Bayesian updating given some prior, or else is strictly dominated by some Bayesian strategy"".</p><p>But hopefully you've seen enough concrete demonstrations to get a general idea of what's going on with the actual coherence theorems. We have multiple spotlights all shining on the same core mathematical structure, saying dozens of different variants on, ""If you aren't running around in circles or stepping on your own feet or wantonly giving up things you say you want, we can see your behavior as corresponding to this shape. Conversely, if we can't see your behavior as corresponding to this shape, you must be visibly shooting yourself in the foot."" Expected utility is the only structure that has this great big family of discovered theorems all saying that. It has a scattering of academic competitors, because academia is academia, but the competitors don't have anything like that mass of spotlights all pointing in the same direction.</p><p>So if we need to pick an interim answer for ""What kind of quantitative framework should I try to put around my own decision-making, when I'm trying to check if my thoughts make sense?"" or ""By default and barring special cases, what properties might a sufficiently advanced machine intelligence <em>look to us</em> like it possessed, at least approximately, if we couldn't see it <em>visibly</em> running around in circles?"", then there's pretty much one obvious candidate: Probabilities, utility functions, and expected utility.</p><br><h1>Further reading</h1><ul><li>To learn more about agents and AI: <a href=""https://arbital.com/p/consequentialist/"">Consequentialist cognition</a>; <a href=""https://arbital.com/p/1y"">the orthogonality of agents' utility functions and capabilities</a>; <a href=""https://arbital.com/p/10g"">epistemic and instrumental efficiency</a>; <a href=""https://arbital.com/p/instrumental_convergence/"">instrumental strategies sufficiently capable agents tend to converge on</a>; <a href=""https://arbital.com/p/advanced_agent/"">properties of sufficiently advanced agents</a>.</li><li>To learn more about decision theory: <a href=""https://intelligence.org/2018/10/31/embedded-decisions/"">The controversial counterfactual at the heart of the expected utility formula</a>.</li></ul><br><hr class=""dividerBlock""><br><br><p><strong>¹ </strong>It could be that somebody's pizza preference is real, but so weak that they wouldn't pay one penny to get the pizza they prefer. In this case, imagine we're talking about some stronger preference instead. Like your willingness to pay at least one penny not to have your house burned down, or something.</p><p>² This does assume that the agent prefers to have more money rather than less money. ""Ah, but why is it bad if one person has a penny instead of another?"" you ask. If we insist on pinning down every point of this sort, then you can also imagine the $0.01 as standing in for the <em>time</em> I burned in order to move the pizza slices around in circles. That time was burned, and nobody else has it now. If I'm an effective agent that goes around pursuing my preferences, I should in general be able to sometimes convert time into other things that I want. In other words, my circular preference can lead me to incur an opportunity cost denominated in the sacrifice of other things I want, and not in a way that benefits anyone else.</p><p><strong>³ </strong>There are more than six possibilities if you think it's possible to be absolutely indifferent between two kinds of pizza.</p><p><strong>⁴ </strong> We can omit the 'better doctors' item from consideration: The supply of doctors is mostly constrained by regulatory burdens and medical schools rather than the number of people who want to become doctors; so bidding up salaries for doctors doesn't much increase the total number of doctors; so bidding on a talented doctor at one hospital just means some other hospital doesn't get that talented doctor. It's also illegal to pay for livers, but let's ignore that particular issue with the problem setup or pretend that it all takes place in a more sensible country than the United States or Europe.</p><p><strong>⁵ </strong>Or maybe a <a href=""https://arbital.com/p/cromwells_rule/"">tiny bit less</a> than <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>, in case the coin lands on its edge or something.</p><p><strong>⁶</strong> Nothing we're walking through here is really a coherence theorem <em>per se</em>, more like intuitive arguments that a coherence theorem ought to exist. Theorems require proofs, and nothing here is what real mathematicians would consider to be a 'proof'. </p><p><strong>⁷</strong> In real life this leads to a problem of 'adversarial selection', where somebody who knows more about the environment than you can decide whether to buy or sell from you. To put it another way, from a <a href=""https://arbital.com/p/bayes_rule_guide/"">Bayesian</a> standpoint, if an <em>intelligent</em> counterparty is deciding whether to buy or sell from you a bet on <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span>, the fact that they choose to buy (or sell) should cause you to <a href=""https://arbital.com/p/bayes_update/"">update</a> in favor (or against) <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> actually happening. After all, they wouldn't be taking the bet unless they thought they knew something you didn't!</p><p><strong>⁸</strong> The quick but advanced argument would be to say that the left-hand-side must look like a singular matrix, whose determinant must therefore be zero. </p>",Eliezer_Yudkowsky,eliezer_yudkowsky,Eliezer Yudkowsky,
yGycR8tFA3JJbvApp,The Relationship Between the Village and the Mission,the-relationship-between-the-village-and-the-mission,https://www.lesswrong.com/posts/yGycR8tFA3JJbvApp/the-relationship-between-the-village-and-the-mission,2019-05-12T21:09:31.513Z,137,44,70,False,False,,"<p><em>Epistemic Status: Braindump, not as well thought out as I’d like.</em></p><p><em>Previously:</em></p><ul><li><em><a href=""https://www.lesswrong.com/posts/DbdP8hD2AcKcdSsgF/project-hufflepuff-planting-the-flag"">Project Hufflepuff</a></em></li><li><em>The <a href=""https://www.lesswrong.com/posts/97LgacucCxmyjYiNT/the-archipelago-model-of-community-standards"">Archipelago Model of Community Standards</a></em></li><li><em><a href=""https://srconstantin.wordpress.com/2017/08/08/the-craft-is-not-the-community/"">The Craft is not the Community</a></em></li><li><em>What is <a href=""https://www.lesswrong.com/posts/MRPQi7pa2WJSPhZ8X/what-is-rationalist-berkley-s-community-culture"">Rationalist Berkeley&#x27;s Community Culture?</a></em></li><li><a href=""https://medium.com/@ThingMaker/dragon-army-retrospective-597faf182e50"">Dragon Army Retrospective</a></li></ul><p>This is a post about dynamics in the Berkeley rationality community, although it may be relevant to broader domains.</p><p>It is highly opinionated about what I think is important.</p><p>I tried to optimize this for a clear-cut goal, then realized the clear-cut goal was “I want to make it easier for people to cooperate with me on community-building, and I just want to do a massive braindump to get them up to speed on where I’m coming from, so that when I have a conversation about it we can skip to the harder parts.&quot;</p><p>If you are serious about rationalist community-building, read this, and then come talk to me afterwards.</p><hr class=""dividerBlock""/><p>When I visited the Bay in 2015, a friend (who used to live in NYC) remarked “you know, when I was in New York, I felt like once a week I went to ‘rationality club’. In Berkeley it feels more like I live in a small rationality village — there’s a couple hundred people, I’m friends with some of them. We bump into each other in the street on the way to the grocery store.”</p><p>Eventually I moved here, and yup. That is how it is. Sorta. With important caveats and problems.</p><p>There are lots of little subcultures in the Rationalist Bay, some overlapping. But I think there are two primary reasons people come:</p><ul><li>to have a Village – a home, among like-minded people</li><li>to contribute to the Mission – ensuring the flourishing of human values (or something like them)</li></ul><p>In the past 10 years, the Mission has acquired serious infrastructure. There’s been much less intentional effort to build a home. Mostly for good reason – the Mission is important, and hard. <a href=""https://www.lesswrong.com/posts/xWrLpxxHoLTWfQY3g/towards-optimal-play-as-villager-in-a-mixed-game#goWnvGta524oNbN23"">Competent People are Rare and the World is Big</a>. Building a village is <em>also </em>hard, and if you’re able to do so, you’re probably also able to work on bigger picture Mission stuff.</p><p>The Mission provides <em>juuuust</em> enough value as a “home” to satisfice the people involved (which might not actually be sufficient for them, just decent enough that it&#x27;s not their primary bottleneck). </p><p>In the past couple years, we’ve begun to see more serious efforts towards building Village infrastructure. But I think these efforts are often missing important aspects of the big picture.</p><p>This post is a high-level overview of how I think about all this. It’s quite long, and doesn’t <a href=""https://www.lesswrong.com/posts/4ZvJab25tDebB8FGE/you-have-about-five-words"">condense neatly down into five words</a>. </p><h1>Summary</h1><h2>The Mission and the Village need different things.</h2><p>The Mission ultimately needs to be outward facing. It’s about putting a dent in the universe.</p><p>The Village needs to prioritize people’s own needs. </p><p>I think these require different mindsets. and are easier optimize separately.</p><h2>It’s important that the Village exist, <em>on its own terms.</em></h2><p>It so happens that the Mission needs to provide its members a home. One might build an explicitly Mission-centered-village. I think this is actually a good idea.</p><p>But I think it’s still valuable to have an actual Village, that doesn’t need to justify everything in terms of The Big Picture, universal flourishing, deeply understanding the world, or x-risk. If this is the only lens through which you build a home, your home will be impoverished. </p><p>It is important to have people and spaces that are optimizing for the village for its own sake, not as a subtle recruitment-for-the-mission strategy. </p><p>This is<em> </em>less important<em> </em>than the Mission (according to me). But still incredibly important.<em> </em>One crucial point of the Mission is that people have access to good villages. Atomic individualism has crippled our capacity for good villages. It is rare and precious that we actually have a shot at building one. </p><h2>But. The reason this Village is special is that it is entangled with the Mission, in a symbiotic way.</h2><p>If you are working on the Village, you actually need to understand the Mission. For two reasons:</p><ul><li>On the Village’s own terms, it depends heavily on the Mission’s energy, drive, mythology, and culture. Remove that, and I don’t think the Village actually works.</li><li>Meanwhile, separately, the Village needs resources. It will have access to much more resources if it is Mission aligned. And I think there is room to be Mission-aligned while succeeding on the Village’s terms</li></ul><p>The Village is not the Mission, and is not outward facing. But the Village should <em>help you prepare for the Mission,</em> if you want. </p><h2>The Village still needs fences and standards.</h2><p>There are lots of ways you can build a village, that don’t depend on any particular mission. But, no matter how you organize your village, it is going to need <em>some</em> kind of standard, some kind of costly signaling that works as a coordination mechanism.</p><p>People who end up drawn to the Village <em>instead of</em> the Mission tend to have an egalitarian instinct, and a desire to welcome everyone. I don’t think this works. The Village needs to be more relaxed than the Mission. But it cannot take care of everybody, and will overwhelm itself if it tries. </p><h2>The Rationality Community, and the Village<em> and</em> Mission that I’m most excited by, are the ones at the center of this Venn Diagram:</h2><span><figure><img src=""https://i.imgur.com/1VauiwJ.png"" class=""draft-image "" style=""width:100%"" /></figure></span><p>I think truth, impact and being human can intersect in a way that is exciting, fulfilling, and important. I&#x27;m not sure I can justify this claim. But I know that the center-of-that-diagram is the community I’m most excited to build towards, and most excited to collaborate with people on.</p><h2>If you’re serious, come talk to me. </h2><p>If you are excited by this and want to put in serious effort into building a Village (either on the Village’s terms, or the Mission’s), I’ll make a good-faith effort to talk to you for at least an hour.</p><p>The rest of this post is my background models of how all of this fits together. My actual models are dense and nuanced and situation-specific. I think it’s important that people work on this, but there are a lot of ways to go subtly wrong.</p><p>If you’re interested in helping seriously, after reading this post and ironing out any basic confusions in the comments, come chat with me.</p><h1>Issues with a Single Status Ladder</h1><p>The Village and the Mission have their own virtues, and pathologies. They share at least one meta-pathology: the status hierarchies are illegible, and there are no fences anywhere to demarcate who is welcome where. When you arrive, instead of a fence, you&#x27;ll find a swamp. You&#x27;ll see some flickering campfires in the distance, but some of those campfires are misleading swamp gas.</p><p>The most obvious assumption is that there is a single status-ladder that goes all the way from &quot;rando who just showed up who doesn&#x27;t have any friends or skills&quot; to &quot;people who interface regularly with billionaires while making decisions that will hopefully impact the future light-cone.&quot;</p><p>So…</p><ul><li>This can feel (and be) quite bad. In the same way that modern poor people are objectively wealthier than ancient kings, but when they compare themselves to modern celebrities they still feel a keen lack of resources... a person who would ordinarily feel socially secure instead feels a pressure to keep-up-with-the-Joneses (and the Joneses know Dustin Moskovitz)</li><li>Even if you <em>don&#x27;t</em> want to climb the status ladder, many of the people around you do. There is pressure upwards. Everyone is busy. Everyone has options. This makes it harder to build actually good friendships – Good friendships require space to just... chill. And to trust that you can continue to just chill when you need to.</li><li>Many of the people who would be most competent at running the village quickly end up involved with Mission-centric orgs.</li></ul><p>A lot of this <em>isn&#x27;t fixable.</em> The state of the world <em>isn&#x27;t okay</em>, and it needs Mission oriented people who are willing to dedicate their lives to it. <a href=""https://www.lesswrong.com/posts/xWrLpxxHoLTWfQY3g/towards-optimal-play-as-villager-in-a-mixed-game#goWnvGta524oNbN23"">Competent People Are Rare and the World Is Big</a>. If you are capable of contributing to the Mission, I think that&#x27;s good. It&#x27;s regrettable if this means that you will not spend as much (or any) time improving the Village. But it would be even more regrettable if you didn&#x27;t help tilt the arc of human history towards goodness in a scalable fashion.</p><p>But, I think there are some local improvements to be made. I think most Mission-aligned people should be at least &quot;paying taxes&quot; to help maintain the Village. I think there are skills people can gain which let them contribute to the Village on the margin. And understanding the situation might help others find additional improvements I haven&#x27;t thought of.</p><p>The simplest change is a shift towards acknowledging <em>at least two status ladders, </em>and it must be possible to be high status within the Village, on the Village&#x27;s terms. </p><hr class=""dividerBlock""/><h1>What is the Mission?</h1><p>The Mission is to make sure <em>everyone</em> can flourish.</p><p>The Mission has many subcomponents. It includes understanding the world. It includes being able to coordinate effectively with people who are already helping. It includes helping directly.</p><p>It includes helping people who are suffering.</p><p>It includes helping people who are not suffering, but the difference between who they are and who they could be is vast.</p><p>It includes fixing systems that are systematically broken.</p><p>It includes understanding things deeply for its own sake.</p><p>It includes figuring out how to think about people that don&#x27;t exist yet.</p><p>Many elements of the Mission interplay with one way another, in ways that are hard to predict in advance. Other elements aren&#x27;t related at all, but are nonetheless united in the fact that they steer the future towards something good.</p><h2>The Mission is <em>not</em> morally obligatory, but is morally commendable.</h2><p>The purpose of having morals in the first place is to help you make good decisions and coordinate. Some people naively decompartmentalize their moral beliefs and end up depressed and broken. A moral system that reliably does that is a stupid moral system and you should pick a different one.</p><p>I think if you demand that <a href=""https://slatestarcodex.com/2014/09/27/bottomless-pits-of-suffering/"">people notice bottomless pits of suffering</a>, <em>and</em> dedicate their lives to it, you will incentivize people to not notice bottomless pits of suffering.</p><h2>The Mission has easier and harder ways to contribute.</h2><p><a href=""https://www.lesswrong.com/posts/qw3Z79HELMsmLkL9F/nobody-is-perfect-everything-is-commensurable"">Nobody is Perfect, Everything is Commensurable</a>. I don&#x27;t think it makes sense for everyone to give 10% of their income to effective charity, but I do think that <a href=""https://forum.effectivealtruism.org/posts/3ijnLaws7mCEogD6H/earning-to-save-give-1-save-10"">everyone can start saving 10% and donating 1% of post-necessities income</a>, to help build the <a href=""https://www.lesswrong.com/posts/yLLkWMDbC9ZNKbjDG/slack"">slack</a> and resources to one day contribute more.</p><p>Even if all you ever do is give 1% of post-necessities income, that&#x27;s fine by me. And even if you don&#x27;t do any of this and just focus on flourishing, yourself, that&#x27;s fine by me too – your flourishing is part of of the project of Human Flourishing.</p><p>And if you do donate 10%, as far as I&#x27;m concerned you&#x27;ve joined the ranks of the Mission. If you start to stress about whether you&#x27;re &quot;doing enough&quot;, yes, you are doing enough.</p><p>There are harder things you can do, many of which involve risk. I can&#x27;t promise that they&#x27;ll work, or that you&#x27;ll come out okay. I can&#x27;t explain what those things are because I don&#x27;t know. One of the biggest elements of The Mission is figuring out what The Mission is.</p><p>The Mission is <a href=""https://forum.effectivealtruism.org/posts/HBKb3Y5mvb69PRHvP/dealing-with-network-constraints-my-model-of-ea-careers"">Network Constrained</a>, and many of the best things you can do is move into a social situation where you automatically make connections that will help you learn, think and grow. Figure out what to do. Do it.</p><p>You are not obligated to undertake the hardest aspects of the Mission. You should not do things that aren&#x27;t sustainable for you.</p><p>But it would be dishonest to pretend the Mission doesn’t need all the help it can get.</p><h2>The Mission requires standards.</h2><p>The Mission requires being able to say &quot;Sorry, you are not yet good enough to do this job.&quot;</p><p>The Mission requires being able to say, sometimes &quot;Hey, when we first started this project, we were small and scrappy and had to make do. We are now at a point where we need to <em>raise</em> our standards, and you will have to raise yours as well if you want to continue on this project.&quot;</p><p>The Mission requires sometimes saying &quot;Your project has turned out to be net-negative, and is gumming up the works preventing other projects from succeeding, and you either need to radically change, or gain skills, or stop.&quot;</p><p>The Mission involves asking hard questions, over and over, and having the answers often be uncomfortable, painful, or horrifying.</p><p>The Mission cannot offer psychological safety.</p><p>This is quite bad for the execution of the Mission, since psychological safety is kind of important to actually get stuff done.</p><p>Also, the whole point of the Mission is for flourishing. At the very least, if the Mission destroys your ability to flourish, that&#x27;s sad.</p><h1>What is the Village?</h1><p>The Village is for making sure that <em>we</em> can flourish.</p><p>We&#x27;re all at different points in our lives, and need different things. The Village must account for that.</p><p>The Village is not the Mission. The Village must succeed on it&#x27;s own terms – taking care of its people. But one of the reasons <em>this</em> village is special is that it helps you prepare for the Mission <em>if</em> you want to.</p><p>(Another thing that makes this village special is that it&#x27;s build on aspirations of truthseeking. I’m not sure if all villages need to orient around truth, but I know that this one does.)</p><h2>What is a good village?</h2><p>A good village takes care of its members, and helps them meet their social needs.</p><p>A good village provides people with opportunities to bump into each other sporadically, in low-stakes settings, so that people can eventually develop deep friendships.</p><p>A good village helps people to raise children.</p><p>A good village provides avenues for people to grow – ideally it provides multiple arenas in which people can develop emotional skills, physical skills, marketable skills, intellectual skills.</p><p>A good village has <a href=""https://medium.com/@ThingMaker/open-problems-in-group-rationality-5636440a2cd1"">escalating asks and rewards</a>. Participating in village life involves at least some effort to pitch in occasionally and follow norms. You will get more out of village life the more you put into it (and villages are healthiest and strongest if, over time, they ask more of their members).</p><p>A good village has a way of dealing with bad actors.</p><p>A good village was a way of rewarding good actors.</p><p>A good village lets you <a href=""https://www.ribbonfarm.com/2017/01/10/rolling-your-own-culture-and-not-finding-community/"">be your whole self</a> without compartmentalization.</p><p>A good village needs the slack to occasionally rescue villagers who are in bad situations.</p><p>An ideal village feels like home, and feels safe.</p><p>(Yes, this is somewhat in tension with the Village asking things of you. I think the solution is for the baseline asks to be something that a person can meet, even if they are sick or depressed for an extended period of time, but for putting in more effort to organically result in higher payoff).</p><p>A good village <em>has fences,</em> of some sort. <em>Because</em> the Village has the obligation to take care of its members, and because resources are limited... it necessarily follows that the Village cannot take care of everybody. Some villages have explicit barriers to entry. Others have vague social networks to navigate to get in. </p><p>If you have <em>no</em> fences, you most likely don&#x27;t have a very good village.</p><h2>A village is not (just) a community</h2><p>A village accomplishes all of this at a scale that a &quot;small community&quot; does not. A village is a level of organization above community, which facilitates the create of small communities. A small community is in turn a larger organizing unit than &quot;group of friends.&quot; Each level of scale provides different things.</p><p>A small community aims at many of the same goals listed above. A village helps generate communities that precisely match your needs. And a village grants access to a certain qualia that is somewhat different from a community, (which is turn a different qualia from &quot;a group of friends.&quot;)</p><p>Alas, I can&#x27;t really explain that qualia. If you don&#x27;t have an intuitive sense of why it matters, I am not arguing that you should care. I can say, it&#x27;s something like &quot;being a part of something bigger than yourself&quot; and something like &quot;feeling like there&#x27;s something powerful that has your back.&quot; </p><p>The current Berkeley community often does <em>not</em> have people&#x27;s back, but it aspires to.</p><h2>Who is &quot;we&quot;?</h2><p>Good question. I have an opinionated answer for the Berkeley community in particular:</p><p>The Village is the people who organically came to live around a particular subset of the Mission – the part that noticed <em>&quot;Hmm, humanity is hurtling towards existential risk, and nobody is doing anything about AI, and people seem remarkably bad a thinking about all this,</em>&quot; and then began clustering in Berkeley to make progress on that.</p><p>Now, since then, that organic growth has led to a wide variety of people, some of whom aren&#x27;t here for the Mission – they&#x27;re here because they have friends here, or they like rationally minded people but don&#x27;t make a big deal about it. </p><p>There are people who care about the Mission, but not x-risk specifically.</p><p>There are people who care, but nonetheless find themselves more drawn to village life than a mission campaign. This is not only okay but <em>good</em> – if no one wanted to make the village their primary focus, the Village would not have the strength to succeed (either on it&#x27;s own terms or the Mission&#x27;s terms).</p><p>But it&#x27;s important to recognize that this Village <em>derives much of its energy</em> from the Mission kernel that it formed around. That kernel was oddly specific, and it makes the village oddly specific. </p><p>Helping the Village to thrive requires understanding that. </p><h2>Why must the Village relate to the Mission at all?</h2><p>In the Old Days, villages were united by shared geography, family, history, and economic activity. But those things no longer bind together a village automatically. And the village needs <em>something</em> around which to cohere.</p><p>I have seen multiple villages, in particular created by the post-atheist-crowd, which failed.</p><p>They failed because, in an increasingly atomized world, they didn&#x27;t offer anything that was special. They didn&#x27;t filter for any particular subset of people, so the people  didn&#x27;t especially get along. They didn&#x27;t have a shared mythology that inspired people towards the same aspirations. They didn&#x27;t even have particularly interesting activities everyone liked. </p><p>People couldn&#x27;t grow up together, so they grew apart.</p><p>It is not a coincidence that the Berkeley community is an <em>honest to goodness village</em>, whereas most social clubs are just vague networks that are barely any different from the alienating, atomized society around them.</p><p>The Berkeley village has a shared mythology, and a (reasonably) shared ethos. It has a clearer and more compelling vision of <em>how to fit into the universe</em> than any of the groups of atheists I met who awkwardly said to themselves &quot;well, there&#x27;s no reason <em>we </em>can&#x27;t have a church, let&#x27;s make one&quot;, but then didn&#x27;t know the first thing about how to make a church, and <a href=""https://slatestarcodex.com/2013/12/18/less-wrong-more-rite-ii/"">didn&#x27;t agree on enough principles</a> to bind <a href=""https://slatestarcodex.com/2014/12/24/there-are-rules-here/"">themselves together</a>.</p><p>(For what it&#x27;s worth, the other villages I&#x27;m most excited by are the Filk community, the Connection/Authentic-Relating community, and some dance or other activity-based communities)</p><h2>Can&#x27;t the Village at least move somewhere affordable?</h2><p><strong>Alas. No.</strong></p><p>A small community could leave Berkeley together. And if they just want each other&#x27;s friendship, and neither care overmuch about the Mission <em>or</em> the Village, than I&#x27;d even recommend that. The are some pathologies in Berkeley that are actively bad, or good to get away from for awhile.</p><p>But you can&#x27;t transplant the 300 people here somewhere else. It won’t work.</p><p>Why are cities more expensive than rural outbacks? Because the cities have stuff, and the rural outbacks don&#x27;t. Cities have jobs. Cities have enough critical mass that no matter your special interest, you can find people also interested in that thing.</p><p>If you don&#x27;t need the Stuff cities offer, you can live somewhere cheap. But empirically many people prefer paying extra for the stuff – that&#x27;s<em> why</em> cities are expensive. The Most Important Stuff is the network effects. And yes there&#x27;s some weird dystopian shit that go along with the network effects... but that doesn&#x27;t mean the network effects don&#x27;t matter.</p><p>A lot of the mythos and ethos of the Village depends on the Mission <em>actually being real. </em>This means trying for real, which means making tradeoffs for real, which means actually living near silicon valley billionaires and having good relationships with them – not only to get money from them, but to maintain high levels of trust and alignment.</p><p>The Big Orgs need to be near the billionaires and many existing ecosystems that surround them. The small orgs need to interface with the Big Orgs. The people who are interested in working for the small orgs, or Big Orgs, or founding new projects that might one day interface with the system, need to be nearby. </p><p>The villagers who are just here to feed of their energy are drawn here and not to random other places because of that energy, and critical mass.</p><p>There might be other places that could sustain a Mission Oriented Village, and you might be able to build a Totally-Not-Mission-Oriented-Village, but either case requires actual strategizing and not just picking a someplace random and  cheap. (I think the EA Hotel has a decent shot at creating an affordable hub, but importantly, it involved thousands of dollars and years of free energy injected into the system)</p><p>(Note that insofar as you think the Mission is fake or in danger of becoming fake, yes, I think that means the Village is correspondingly weaker)</p><h2>Does the Mission need a Village that’s <em>separate</em> from the Mission?</h2><p>Does the Mission need the Village, or does the Village only need the Mission?</p><p>The Mission definitely needs to make sure the social needs of its members are met. This includes making sure they can make friends and can be psychologically healthy.</p><p>There are multiple strategies the Mission could employ for this, and I think most of them look something like building Mission-centric social spaces. Habryka has some thoughts on this (different from mine), that make more sense to call a “university” than a village.</p><p>But I think the Mission still benefits from having a nearby Village where people get to <em>explore</em> the Mission, over a timescale of years. And for that to really work, it needs to be a live option to say “okay, it turned out the Mission was not for me”, without meaning that the years you invested were wasted. (And, importantly, without pressure to deceive yourself about whether the Mission is for you)</p><h2>I don’t really care about the Village. Should I?</h2><p><strong>Eh, probably not.</strong></p><p>To me, the Village and the Mission are both deeply important, and obviously so. If you’re a Mission oriented person who doesn’t feel like they’re lacking anything, or if this entire essay feels pointless to you, I don’t think there’s a secret point I understand that you don’t that’ll change your mind. </p><p>You either feel that there’s some kind of village-shaped hole that you want to fill, or don&#x27;t.</p><h2>I don&#x27;t live in Berkeley. Should I move there?</h2><p><strong>Maybe. But probably not for the sake of the Village.</strong></p><p>For years, the Village was neglected. Over the past couple years, people have taken a stab at building real Village Institutions. But we have a huge amount of social-technology-debt that we have yet to repay. The Village still struggles to take care of its own people.</p><p>I think it makes most sense to move to Berkeley if you already have a strong sense of who you would live with. It also makes sense if you already have a Mission-related-job lined up, since the Mission actually has more infrastructure built. And it makes sense if you&#x27;re willing to put a lot of effort into building the Village (or Mission) around you as you go.</p><p>A thing that works for some people is &quot;visit there for a few months, and see what it is like, and whether you can successfully find a home.&quot;</p><p>If you <em>do</em> move to the Berkeley, <a href=""https://www.lesswrong.com/posts/hquyBeyoeskqhzT9n/replace-yourself-first-if-you-re-moving-to-the-bay#comments"">try to replace yourself first</a>. </p><h1>Ask not what your Village can do for you.</h1><p>Lately, I&#x27;ve been very Mission focused. I will continue to be Mission focused.</p><p>But I want a good home. I want a good village to support me during the times when I need help, and I want (counterfactually, behind the veil of ignorance) to have had better opportunities in Village-related-domains.</p><p>In my own immediate future, I want better opportunity to strengthen friendships in repeated low-stakes interactions. Right now I&#x27;m able to do so, in part, because of people who put time and effort into Village-esque activities. One of my worries is that those people will burn out, or eventually transition into more Mission-esque domains that consume more of their time, or simply move away. And there are not enough people to replace them, let alone strengthen the foundations.</p><p>If you are similar to me, you probably want to spend at least a bit of your resources helping build the Village.</p><p>What does the Village need? I think there are basically two lenses to look at this question.</p><h2>&quot;Low&quot; Effort Things</h2><p>What things can you do periodically that will help the village, without costing you much, if you don&#x27;t expect to be able to commit to building village institutions longterm?</p><p>Examples, escalatingly difficult, include:</p><ul><li>Meta:</li><ul><li>First, maintain 30% slack, as a general rule. Don’t overexert yourself. Make sure you have the spare resources to handle emergencies, otherwise instead of helping you&#x27;ll end up needing help. </li><li>Keep your commitments, whatever they are. (This may mean making fewer commitments, or being clearer about how reliable you expect to be. You can be a <a href=""https://medium.com/@ThingMaker/reliability-prophets-and-kings-64aa0488d620"">Prophet or a King</a>)</li></ul><li>Help pay money for things. (This can scale up and down pretty easily). Don&#x27;t overdo it if you don&#x27;t have at least $10k in the bank to make switching jobs and apartments easier.</li><li>Generally be a good citizen</li><ul><li>If you&#x27;re at an event, notice what things the organizer could use help with. Take out the trash. Greet people you haven&#x27;t met. Introduce them to people you think they&#x27;d like and who&#x27;d like them.</li><li>Or, better – help people around you be good citizens. <a href=""https://www.lesswrong.com/posts/rhZQ7MQGuJM5osiDe/hufflepuff-leadership-and-fighting-entropy"">Embody Hufflepuff Leadership.</a></li></ul><li>Be a co-organizer – formally agree to help out someone running an event.</li><li>Run a one-off party or meetup. Be deliberate about who you invite – make sure to invite people who&#x27;ll have fun together, but also try to invite some people you don&#x27;t know as well. Add surface area that lets people bump into each other and becoming friends. <a href=""https://www.bloomberg.com/news/articles/2019-01-17/feeling-lonely-a-simple-cure-to-get-off-our-social-media-islands"">The world depends on you throwing a party</a>.</li><ul><li>(You can turn one-off-parties into repeated institutions, although I recommend starting out just with the goal of trying a new thing without committing to the long haul).</li></ul><li>Arrange your housing situation such that you can offer people a place to crash for a week. (This is part of a general strategy <a href=""https://theunitofcaring.tumblr.com/post/183635311806/gaytog-i-think-its-fair-to-say-im-no-longer-an"">advocated by Kelsey Piper</a> about making sure your community has the slack to absorb random emergencies, help people when they lose their job, get them out of abusive situations, etc)</li><li><strong>Notice when you are in a group with fences</strong>, enough such that it&#x27;s worth investing in coordination to make that group better. (Group houses are a good natural fit for this)</li><li><strong>Run the occasional event that requires and/or builds a skill (rationality skills or otherwise)</strong>. These are harder than a generic party, but they are the easily-forgotten core of the village&#x27;s soul. I&#x27;ve seen people come to Berkeley and be disappointed that most of the events felt like glorified speed-dating. <strong>They came for the rationality and didn&#x27;t find any. </strong>There is pent-up demand for serious growth (without the pressure that comes from working on it professionally.)</li></ul><h2>High Effort, Long Commitment Things</h2><p>Are you a competent person who cares enough about the Village to stick around, and actually build Village Institutions that scale? Can you do so in a way that doesn&#x27;t burn you out?</p><p>Some things are only actually worth doing if you&#x27;re going to stick with them.</p><p>The problem where <a href=""https://www.lessestwrong.com/posts/xWrLpxxHoLTWfQY3g/towards-optimal-play-as-villager-in-a-mixed-game#goWnvGta524oNbN23"">Competent People Are Rare and the World Is Big</a> doesn&#x27;t just apply to the Mission, it applies to the Village too. One of the reasons I think REACH is valuable is it provides <em>scalable</em> village goods – it&#x27;s existence lowers the barrier to entry for holding new events, and getting situation.</p><p>I think we could use more things in this reference class (which I think would plausibly be worth serious fundraising for)</p><ul><li>I suspect REACH could use more people that dedicate serious longterm effort towards making it run smoothly, and I think there is demand in the community for at least 1-2 additional copies of REACH-esque organizations that run on different aesthetics, operate in different neighborhoods, and target different people. </li><li>Group Housing – more/better tools to help coordinate this. </li><li>Solving Bureaucracy for people. There could use to be someone who knows all the doctors and therapists and housing situations in the area, who can help people navigate them.</li><li>Think hard about burnout and figure out how to help people systematically with it.</li><li><strong>Build longterm programs that help people train skills. </strong></li></ul><p>Meanwhile, a meta-skill that should be running in the background is to <a href=""https://www.lesswrong.com/posts/hquyBeyoeskqhzT9n/replace-yourself-first-if-you-re-moving-to-the-bay#comments""><em>always</em> be working to replace yourself in whatever capacity people rely on you.</a> </p><p>This is particularly true if you have the skill of “figure out what needs doing and do it.” That skill is super rare. But if you can figure out what to do, then train someone else to do it, and move on, you’re in a position to add a lot of value.</p><h2>Integrity and Accountability</h2><p>Right now, the Village is fairly anarchic. This seems fine – most of the ways to make it <em>non-</em>anarchic seem more likely to turn it into a cumbersome bureaucracy than to actually help. </p><p>This means, though, that the current mechanism for someone doing a major project is “Pick up a flag, and start running forward yelling excitedly, and hope that villagers and funders run after you.”</p><p>This has a few issues. The dynamic between Village leaders and funders is stressful for both. </p><p>Funders don’t commit enough to seriously helping with Village endeavors for Village Organizers to trust in the system. Village Organizers don’t have much <em>choice</em> other than picking up a flag and run forward without looking back. If they waited for funders, nothing would ever get done.</p><p>But running forward with a flag doesn’t have any kind of accountability built into the system. Since there’s so few Village projects, funders sometimes feel vague pressure to support whatever *has* gotten started, without really checking if it’s good – and then later, they have to either cut funding for something that people have come to rely on (which sucks), or… keep funding something subpar, potentially net negative (which also sucks).</p><p>Oliver Habryka recently <a href=""http://lesswrong.com/posts/EQJfdqSaMcJyR5k73/habryka-s-shortform-feed#xQJYMNujxB3EqephZ"">crystallized some thoughts about integrity </a>and accountability that I think are relevant here. Think hard about who you want to be accountable to. </p><p>A common mistake is to make yourself accountable to “the public”, which means you can’t defend decisions with concepts more complex than <a href=""https://lesswrong.com/posts/4ZvJab25tDebB8FGE/you-have-about-five-words"">about five words</a>.</p><p>Another mistake is not be accountable to <em>anyone, </em>or to only be accountable to people very similar to you. You need a wide enough variety of people to be accountable to that you have a decent chance of getting called out on your mistakes. You also need enough stakeholders that you can build a large enough coalition to get the resources you need.</p><p>So my suggestion is to be pro-active about <em>seeking out </em>accountability. Find people you trust, who you will actually listen to, from a few different perspectives, who can give you important feedback about how your projects fit into the broader ecosystem. Be ready to change (or if necessary, abort) your project given their feedback.</p><h1>If you’re in the Village for the long haul, or want to build village-like spaces for the Mission, chat with me.</h1><p>I think the Village is quite important, but there are a lot of nuances to get right when trying to build something for it. </p><p>I’m fairly busy these days, and can’t meet with everyone. But if you’re interested in serious longterm Village work (say, putting at least 2 years into it, especially if you’ve been pretty reliably showing up and helping out in smaller ways), then I’m interested in having a fairly serious talk with you and helping to get you started.</p>",Raemon,raemon,Raemon,
Mkz3koeL2u23HHwym,Tales from the Highway,tales-from-the-highway,https://www.lesswrong.com/posts/Mkz3koeL2u23HHwym/tales-from-the-highway,2019-05-12T19:40:00.862Z,16,7,0,False,False,,"<p>Epistemic Status: Concrete data on how something works with curiosity as to the gears behind the decisions, and a desire to record exactly what happened for posterity so we have detailed accurate records and perhaps an example of some things. But no reason to think any of it is important, or you should feel any great need to read it.</p>
<p>“You don’t know what you have until you go to New Jersey” – My wife Laura, when this was almost over.</p>
<p>This happened on Saturday night, as I attempted to transport myself, my wife and our two children home from their in-laws.</p>
<p></p>
<p>The one-year old is being held up by a strange contraption attached to my chest. After enduring a forty-five minute car ride, we make our way to Willowbrook Mall to catch the NJ Transit bus back into New York City’s Port Authority, after which we’ll need to get two trains or another taxi to return home.</p>
<p>When we get to the bus stop, it is 7:02, and we are just in time to see a bus that we presume is the 7:00 bus close its doors and begin to leave. Assuming we will now be forced to wait the actual maximum amount of time to get the next bus, we decide to order a taxi. Just as we’ve sorted out how to do that, another bus that says it is going to New York pulls into the station. Thanks to the orderly and well-kept bus schedule, it looks like we’ve caught a break and we’ll be at Port Authority around 7:35. We board and are on our way home.</p>
<p>Traffic is lousy, but nothing unusually bad. I’m mostly happily zoned out, thanks to a combination of continuously rebalancing my child as he falls asleep slooping over in various directions only to have the drop jolt him awake, and listening to a podcast. But I still keep an eye up ahead, because I’ve unfortunately been trained over the years that when traffic is lousy, one should be sure to know exactly <em>how </em>lousy it is, so one can properly complain and/or maintain and manage expectations.</p>
<p>I see a car cutting in front of us, and it’s instantly obvious this was not a wise decision. There isn’t enough room. I hear a noise and there’s a slight rattle. There’s been a minor accident. Shrug. It happens. The other car does not seem to care or even notice the havoc it has caused on the road this night, and continues onward as other cars allow.</p>
<p>The bus driver seems not to be overly concerned. With no room to move anyway, she takes a quick walk outside to look at the damage, but as soon as things start moving again, we’re moving on. After a few minutes, I mostly forget anything happened.</p>
<p>Traffic then starts getting rapidly worse. We come up against a police roadblock, entirely closing off two of the three lanes. When we get there, we are directed onto the left lane, where we sit for a few minutes in front of sideways highway patrol cars. A highway patrolman boards, then another one. They discuss things with the bus driver. The police roadblock expands to cover all three lanes, bringing traffic on the main road into the Lincoln Tunnel to a standstill.</p>
<p>They then slowly generate a corridor, and the bus proceeds to move to the right lane and off to the side. After that, the highway is allowed to reopen.</p>
<p>We sit there.</p>
<p>There is clearly an argument between the bus driver and the officers.</p>
<p>An officer comes back and starts talking to the passengers. He asks them for ID, saying “there was an accident so this is what I gotta do.” For our children he collects full names and dates of birth. Once finished collecting IDs, he leaves the bus with all of our IDs, with no word on when he’ll be back or what is going on.</p>
<p>We sit there.</p>
<p>A pair of passengers are asked whether they are going to a show, and when it starts. They are clearly frustrated, say yes that is where they <em>were </em>headed, but it started at 8:00, and it doesn’t matter now. No one else gets asked anything. We are not asked if anything is urgent.</p>
<p>After a while, the officer returns with our IDs and hands them out again.</p>
<p>He says that a police car will escort us off an exit to an Exxon station, where we will be transferred to a new bus in six minutes. After that, this bus will proceed to Port Authority.</p>
<p>Approximately two minutes after this, we’ve started moving slowly, behind a highway patrol car with its sirens flashing. I think to check my phone for the time. It says 8:23.</p>
<p>Several minutes later, we turn off of the highway and enter Secaucus, New Jersey.</p>
<p>Several minutes after that, we pass a bus going in the opposite direction. It says it is a New Jersey Transit Bus, headed to New York via Secaucus.</p>
<p>This does not seem like it bodes well.</p>
<p>At 8:35, we make it to the Exxon station. There is no second bus. We are given no new information on when to expect a second bus.</p>
<p>After several minutes of sitting there, the passengers who had missed their show, or at least the first half of it, ask to get out.</p>
<p>The bus driver refuses. She says she does not have the authority to open the bus door. We are not permitted to walk out into an Exxon gas station.</p>
<p>Another passenger says she has to go to the bathroom, which is not something the bus can accommodate.</p>
<p>The bus driver refuses in an angry tone.</p>
<p>The passenger reiterates that she has to go, clearly not knowing what to do about this, over the course of minutes, and makes a phone call.</p>
<p>My wife and I are fully ready to call a taxi and get us out of there, since we have no idea how long it will take to get a bus. This is one of those situations where waiting for longer makes the remaining expected wait longer rather than shorter. And I suspected that the bus we were supposed to get on was the bus we passed while heading to the gas station.</p>
<p>The problem is, <em>we are being held prisoner on the bus.</em></p>
<p>I go up to talk to the driver, who again says she <em>doesn’t have the authority </em>to let us leave. That it’s up to the police. She says if it were up to her, she would have just driven to Port Authority, but the police won’t let her.</p>
<p>At other times, she’s been overheard saying the rightside mirror is busted and she can’t see anything there. I don’t know enough to judge whether this was true, or how much this impacts visibility or safety, or what was or wasn’t safe or wise in this situation – I can imagine it being mostly perfectly safe to proceed to Port Authority, or safe to do so with an escort ahead of us. I can also imagine it being unsafe, in which case a bus was unsafely driven to Port Authority, just without its passengers.</p>
<p>The driver says the new bus will be here in five minutes. This is the least credible five minutes. I check my phone for posterity, noting it is 8:41.</p>
<p>The good news is that between various passengers making more noise and moving around, time passing, and what I suspect was at least one call to 911, the door opens and we are permitted to walk out of the bus. Which we do as quickly as possible before minds are changed and the prison doors close again.</p>
<p>We then order a taxi to New York. We leave in that taxi at 8:53, as we also witness another bus pull up. I hope the other passengers got on their way within a few minutes of that. We weren’t about to stick around to find out. Around 9:10, we make it into the city, and get home around 9:35.</p>
<p>Nothing terrible happened to us. We lost about 90 minutes being forcibly detained, our kids got to bed super late, and we were out money for both the bus and the cab. Thanks to the street closing, I’m guessing a few thousand people experienced substantial delays, but it’s hard to get a good handle on how many people, or how big a delay.</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>",Zvi,zvi,Zvi,
auWybBQhD5KEd3n4J,"The Geography of the Room — impact of position, orientation, and visibility on how often extraverts start conversations",the-geography-of-the-room-impact-of-position-orientation-and,https://www.lesswrong.com/posts/auWybBQhD5KEd3n4J/the-geography-of-the-room-impact-of-position-orientation-and,2019-05-12T17:21:36.778Z,11,8,0,False,False,https://www.lesspenguiny.com/articles/the-geography-of-the-room,<p><em>I write long-form articles about social interactions based on ~6 years of observational data. This particular piece is part of a longer sequence exploring why some people are frequently approached by strangers whereas others are mostly ignored.</em></p>,less_penguiny,less_penguiny,less_penguiny,
Fr7FpCNhnTP2i5iaG,Type-safeness in Shell,type-safeness-in-shell,https://www.lesswrong.com/posts/Fr7FpCNhnTP2i5iaG/type-safeness-in-shell,2019-05-12T11:30:00.680Z,7,3,3,False,False,,"<p>Since writing the post on a hypothetical <a href=""http://250bpm.com/blog:153"">hull</a> language as an alternative to shell I cannot stop thinking about the shortcomings of shell.</p> <p>And one think that comes to mind over and over is type-safeness. Shell treats everything as a string and that's the source of both its power and its poor maintainability.</p> <p>So when I ask whether shell can be improved, the question is actually more subtle: Can it be improved without compromising its versatility? Can we, for example, be more type-safe without having to type Java-like stuff on the command line? Without sacrificing the powerful and dangerous features like string expansion?</p> <p>I mean, you can write shell-like scripts in Python even today and use type hints to get type safeness. But in real world this practice seems to be restricted to writing more complex programs, programs that require actual in-language processing, complex control flow, use of libraries and so on. Your typical shell script which just chains together a handful of UNIX utilities &#8212; no, I don't see that happening a lot.</p> <p>To put it in other words, different &quot;scripting languages&quot; managed to carve their own problem spaces from what once used to be the domain of shell, but almost none of them attacked its very core use case, the place where it acts as a dumb glue between stand-alone applications.</p> <p>But when writing shell scripts, I observe that I do have a type system in mind. When I type &quot;ls&quot; I know that an argument of type &quot;path&quot; should follow. Sometimes I am even explicit about it. When I save JSON into a file, I name it &quot;foo.json&quot;. But none of that is formalized in the language.</p> <p>And in some way, albeit in a very hacky one, shell is to some extent aware of the types. When I type &quot;ls&quot; and press Tab twice a list of files appears on the screen. When I type &quot;git checkout&quot; pressing Tab twice results in a list of git branches. So, in a way, shell &quot;knows&quot; what kind of argument is expected.</p> <p>And the question that's bugging me is whether the same can be done in a more systemic way.</p> <p>Maybe it's possible to have a shell-like language with actual type system. Maybe it could know that file with .json extension is supposed to contain JSON. Or it could know that &quot;jq&quot; expects JSON as an input. Maybe it could know that JSON is a kind of text file and that any program accepting a text file (e.g. grep) can therefore accept JSON as well. And it could know that &quot;ls -l&quot; returns a specific &quot;type&quot;, a refinement of &quot;text file&quot; and &quot;file with one item per line&quot;, with items like access rights, ownership, file size and so on.</p> <p>But how would one do that?</p> <p>In addition to the language implementing a type system it would require some kind of annotation of common UNIX utilities, adding formal specification of their arguments and outputs. (With all programs not present in the database defaulting to &quot;any number of arguments of any type and any output&quot;.) Maybe it can be done by simple type-safe wrappers on top of existing non-type-safe binaries.</p> ",sustrik,sustrik,Martin Sustrik,
zd2DrbHApWypJD2Rz,"""UDT2"" and ""against UD+ASSA""",udt2-and-against-ud-assa,https://www.lesswrong.com/posts/zd2DrbHApWypJD2Rz/udt2-and-against-ud-assa,2019-05-12T04:18:37.158Z,50,20,7,False,False,,"<html><head></head><body><p>I'm reposting some old posts that I originally sent to the ""decision theory workshop"" mailing list and the ""<a href=""http://www.weidai.com/everything.html"">everything-list</a>"", because I occasionally want to reference these posts but the former mailing list is private and the latter one is public but I can't figure out how to create direct links to posts that are viewable without becoming a member.</p>
<p>UDT2 is a decision theory idea that I came up with to try to solve some problems in <a href=""https://wiki.lesswrong.com/wiki/Updateless_decision_theory"">UDT1.1</a> however <a href=""https://www.alignmentforum.org/posts/5bd75cc58225bf067037528e/updatelessness-and-son-of-x#5bd75cc58225bf0670375293"">I'm not very happy with it currently</a>. <a href=""http://fennetic.net/irc/finney.org/~hal/udassa/"">UD+ASSA or UDASSA</a> is an anthropic reasoning idea that I came up with and then moved away from prior to UDT. See also <a href=""https://www.lesswrong.com/posts/QmWNbCRMgRBcMK6RK/the-absolute-self-selection-assumption"">this post</a> for further discussion of UDASSA.</p>
<h1>UDT2 (originally ""toward a solution of the 'unintentional simulation' problem"", 1/25/2011)</h1>
<p>(I think this approach potentially solves several problems besides ""unintentional simulation"" but I'll start there since it provides the clearest motivation.)</p>
<p>I first described this problem (without naming it) at <a href=""http://lesswrong.com/lw/15z/ingredients_of_timeless_decision_theory/120y"">http://lesswrong.com/lw/15z/ingredients_of_timeless_decision_theory/120y</a>.
Here's a condensed version:</p>
<p>Two UDT1 (or UDT1.1) agents play one-shot PD. It's common knowledge that agent A must make a decision in 10^100 ticks (computation steps), whereas agent B has 3^^^3 ticks. While B is trying to derive the logical consequences of returning 'C' or 'D' on the world program P, it is likely to come up with a proof by simulation of A's output, after which it will decide to play D.</p>
<p>I think what A should have done is (if it were running a smarter decision theory), instead of deciding directly on C or D, modify itself into a program K = ""simulate the original agents A and B and output 'C' if and only if both of the simulated agents self-modify into K within some time limit"".
And B (if it were also running a smarter decision theory) would also self-modify into K, whether or not it happens to simulate A's decision to self-modify into K prior to its own self-modification, and do this before the time limit built into K expires.</p>
<p>So that's my starting intuition, and I want to try to answer: what is this smarter decision theory? It seems that at least two changes need to be made to UDT1:</p>
<ol>
<li>An agent must take the space of possible decisions to be the set of possible programs it can self-modify into, instead of the set of outputs or input/output maps. (This change is needed anyway if we want the agent to be able to self-improve in general.)</li>
<li>An agent must consider not just the consequences of eventually reaching some decision, but also the consequences of the amount of time it spends on that decision. (This change is needed anyway if we want the agent to be economical with its computational resources.)</li>
</ol>
<p>So, while UDT1 optimizes over possible outputs to its input and UDT1.1 optimizes over possible input/output mappings it could implement, UDT2 simultaneously optimizes over possible programs to self-modify into and the amount of time (in computation steps) to spend before self-modification.</p>
<p>How to formulate UDT2 more precisely is not entirely clear yet. Assuming the existence of a math intuition module which runs continuously to refine its logical uncertainties, one idea is to periodically interrupt it, and during the interrupt, ask it about the logical consequences of statements of the form ""S, upon input X, becomes T at time t"" for all programs T and t being the time at the end of the current interrupt. At the end of the interrupt, return T(X) for the T that has the highest expected utility according to the math intuition module's ""beliefs"". (One of these Ts should be equivalent to ""let the math intuition module run for another period and ask again later"".)</p>
<p>Suppose agents A and B above are running UDT2 instead of UDT1. It seems plausible that A would decide to self-modify into K, in which case B would not suffer from the ""unintentional simulation"" problem, since if it does prove that A self-modifies into K, it can then easily prove that if B does not self-modify into K within K's time limit, A will play D, and therefore ""B becomes K at time t"" is the best choice for some t.</p>
<p>It also seems that UDT2 is able to solve the problem that motivated UDT1.1 without having ""ignore the input until the end"" hard-coded into it, which perhaps makes it a better departure point than UDT1.1 for thinking about bargaining problems. Recall that problem was:</p>
<p>Suppose Omega appears and tells you that you have just been copied, and each copy has been assigned a different number, either 1 or 2. Your number happens to be 1. You can choose between option A or option B. If the two copies choose different options without talking to each other, then each gets $10, otherwise they get $0.</p>
<p>The idea here is that both agents, running UDT2, would self-modify into T = ""return A if input is 1, otherwise return B"" if their math intuition modules say that ""S, upon input 1, becomes T"" is positively correlated with ""S, upon input 2, becomes T"", which seems reasonable to assume.</p>
<p>I think UDT2 also correctly solves Gary's Agent-Simulates-Predictor
problem and my ""two more challenging Newcomb variants"".
(I'll skip the details unless someone asks.)</p>
<p>To me, this seems to be the most promising approach to try to fix some of UDT1's problems. I'm curious if others agree/disagree, or if anyone is working on other ideas.</p>
<h1>two more challenging Newcomb variants (4/12/2010)</h1>
<p>On Apr 11, 2:45 pm, Vladimir Nesov wrote:</p>
<blockquote>
<p>There, I need the environment to be presented as function of the
agent's strategy. Since predictor is part of agent's environment, it
has to be seen as function of the agent's strategy as well, not as
function of the agent's source code.</p>
</blockquote>
<p>It's doesn't seem possible, in general, to represent the environment as a function of the agent's strategy. I applied Gary's trick of converting multi-agent problems into Newcomb variants to come up with two more single-agent problems that UDT1 (and perhaps Nesov's formulation of UDT as well) does badly on.</p>
<p>In the first Newcomb variant, Omega says he used a predictor that did an exact simulation of you for 10^100 ticks and outputs ""one-box"" if and only if the simulation outputs ""one-box"" within 10^100 ticks.
While actually making the decision, you are given 10^200 free ticks.</p>
<p>In the second example (which is sort of the opposite of the above), Omega shows you a million boxes, and you get to choose one. He says he used 10^100 ticks and whatever computational shortcuts he could find to predict your decision, and put $1 million in every box except the one he predicted you would choose. You get 10^100 + 10^50 ticks to make your decision, but you don't get a copy of Omega's predictor's source code.</p>
<p>In these two examples, the actual decision is not more important than how predictable or unpredictable the computation that leads to the decision is. More generally, it seems that many properties of the decision computation might affect the environment (in a way that needs to be taken into account) besides its final output.</p>
<p>At this point, I'm not quite sure if UDT1 fails on these two problems for the same reason it fails on Gary's problem. In both my first problem and Gary's problem, UDT1 seems to spend too long ""thinking""
before making a decision, but that might just be a superficial similarity.</p>
<h1>against UD+ASSA, part 1 (9/26/2007)</h1>
<p>I promised to summarize why I moved away from the philosophical position
that Hal Finney calls UD+ASSA. Here's part 1, where I argue against ASSA.
Part 2 will cover UD.</p>
<p>Consider the following thought experiment. Suppose your brain has been
destructively scanned and uploaded into a computer by a mad scientist. Thus
you find yourself imprisoned in a computer simulation. The mad scientist
tells you that you have no hope of escaping, but he will financially support
your survivors (spouse and children) if you win a certain game, which works
as follows. He will throw a fair 10-sided die with sides labeled 0 to 9. You
are to guess whether the die landed with the 0 side up or not. But here's a
twist, if it does land with ""0"" up, he'll immediately make 90 duplicate
copies of you before you get a chance to answer, and the copies will all run
in parallel. All of the simulations are identical and deterministic, so all
91 copies (as well as the 9 copies in the other universes) must give the
same answer.</p>
<p>ASSA implies that just before you answer, you should think that you have
0.91 probability of being in the universe with ""0"" up. Does that mean you
should guess ""yes""? Well, I wouldn't. If I was in that situation, I'd think
""If I answer 'no' my survivors are financially supported in 9 times as many
universes as if I answer 'yes', so I should answer 'no'."" How many copies of
me exist in each universe doesn't matter, since it doesn't affect the
outcome that I'm interested in.</p>
<p>Notice that in this thought experiment my reasoning mentions nothing about
probabilities. I'm not interested in ""my"" measure, but in the measures
of the outcomes that I care about. I think ASSA holds intuitive appeal to
us, because historically, copying of minds isn't possible, so the measure of
one's observer-moment and the measures of the outcomes that are causally
related to one's decisions are strictly proportional. In that situation, it
makes sense to continue to think in terms of subjective probabilities
defined as ratios of measures of observer-moments. But in the more general
case, ASSA doesn't hold up.</p>
<h1>against UD+ASSA, part 2 (9/26/2007)</h1>
<p>In part one I argued against ASSA. Here I first summarize my
argument against UD, then against the general possibility of any single
objective measure.</p>
<ol>
<li>There is an infinite number of universal Turing machines, so there
is an infinite number of UD. If we want to use one UD as an objective
measure, there has to be a universal Turing machine that is somehow uniquely
suitable for this purpose. Why that UTM and not some other? We don't even
know what that justification might look like.</li>
<li>Computation is just a small subset of math. I knew this was the case,
having learned about oracle machines in my theory of computation class. But
I didn't realize just how small a subset until I read <em>Theory of Recursive
Functions and Effective Computability</em>, by Hartley Rogers. Given that there
is so much mathematical structure outside of computation, why should they
not exist? How can we be <em>sure</em> that they don't exist? If we are not <em>sure</em>,
then we have to take the possibility of their existence into account when
making decisions, in which case we still need a measure in which they have
non-zero measures.</li>
<li>At this point I started looking for another measure that can replace UD.
I came up with what I called ""set theoretic universal measure"", where the
measure of a set is inversely related to the length of its description in a
formal set theory. Set theory covers a lot more math, but otherwise we still
have the same problems. Which formal set theory do we use? And how can we be
sure that all structures that can possibly exist possible can be formalized
as sets? (An example of something that can't would be a device that can
decide the truth value of any set theoretic statement.)</li>
<li>Besides the lack of good candidates, the demise of ASSA means we don't
need an objective measure anymore. There is no longer an issue of sampling,
so we don't need an objective measure to sample from. The thought experiment
in part 1 of ""against UD+ASSA"" points out that in general, it's not the
measure of one's observer-moment that matters, but the measures of the
outcomes that are causally related to one's decisions. Those measures
can be interpreted as indications of how much one cares about the outcomes,
and therefore can be subjective.</li>
</ol>
<p>So where does this chain of thought lead us? I think UD+ASSA, while flawed,
can serve as a kind of stepping stone towards a more general rationality.
Somehow UD+ASSA is more intuitively appealing, whereas truly generalized
rationality looks very alien to us. I'm not sure any of us can really
practice the latter, even if we can accept it philosophically. But perhaps
our descendents
can. One danger I see with UD+ASSA is we'll program it into an AI, and the
AI will be forever stuck with the idea that non-computable phenomenon can't
exist,
no matter what evidence it might observe.</p>
</body></html>",Wei_Dai,wei-dai,Wei Dai,
xC32LruScK8dbdwDw,Narcissism vs. social signalling,narcissism-vs-social-signalling,https://www.lesswrong.com/posts/xC32LruScK8dbdwDw/narcissism-vs-social-signalling,2019-05-12T03:26:31.552Z,13,7,18,False,False,,"<p>The main thrust of <a href=""https://www.overcomingbias.com/author/robin-hanson"">Robin Hanson&#x27;s</a> work is that so much of human behaviour is the result of social signalling; that is, the attempt to convince others that we possess good qualities. On the other hand, <a href=""https://thelastpsychiatrist.com/"">The Last Psychiatrist</a> presents narcissism as an alternative theory; that is, much of our behaviour is an attempt to convince ourselves that we possess good qualities. I haven&#x27;t read enough of The Last Psychiatrist to be able to provide a good summary of their ideas, so this will just be a short comment to raise awareness that an alternative theory exists and to discuss how these hypotheses relate.</p><p>The separation between these two theories isn&#x27;t as clear as it may first appear. After all, we may attempt to convince other people of our goodness in order to ultimately convince ourselves or we may attempt to convince ourselves of our goodness so that we can more persuasively convince other people. For the later, imagine someone prepping for a job interview teaching when they are aware that their knowledge of the material isn&#x27;t as strong as they&#x27;d like, but believing they might get hired if they seems confident.</p><p>Trying disambiguate using revealed preferences may be misleading - someone may spend most of their time trying to impress other people, but that may simply be the strategy they&#x27;ve adopted for convincing themselves that they are worthy and they may drop it as soon as they learn other strategies. Alternatively, trying to use people&#x27;s ultimate goals to disambiguate this is tricky when, according to both theories, we often don&#x27;t know why we do what we do. And indeed, when we talk about ultimate goals, are we referring to the ultimate goal that is represented in the brain or are we allowed to reference evolutionary psychology reasons for behaviour? Then of course these the issue that most of the time, both theories will be correct to a certain extent. I&#x27;ll admit the the practical consequences of adopting one theory over another aren&#x27;t always immediately clear, but I expect that adopting one model instead of the other would necessarily result in some differences in predictions.</p>",Chris_Leong,chris_leong,Chris_Leong,
6SwmRb89mwcph3wL2,Why books don't work,why-books-don-t-work,https://www.lesswrong.com/posts/6SwmRb89mwcph3wL2/why-books-don-t-work,2019-05-11T20:40:27.593Z,17,13,19,False,False,https://andymatuschak.org/books/,"<p>A look at how books are not optimal for conveying information. Analogies to lectures, with an interesting take on cognitive models, i.e. the assumptions you make about how learning happens. Also some interesting citations on average reading time and attention span.</p><p>I really like this piece because it ties together lots of thoughts I&#x27;ve previously tried to express, but didn&#x27;t find the right words for. I think it does a very good job of pointing out how the default mediums are not optimal.</p><p>Also interesting to note the author has collaborated with Michael Nielsen (who wrote a <a href=""http://neuralnetworksanddeeplearning.com/"">fantastic online book on neural networks</a>) on another online book on <a href=""https://quantum.country/qcvc/"">quantum computing</a> which incorporates spaced repetition, and he has also done prior work for Khan Academy.</p>",,,,
xW9wGN9GN3guB9bZK,Probability interpretations: Examples,probability-interpretations-examples,https://www.lesswrong.com/posts/xW9wGN9GN3guB9bZK/probability-interpretations-examples,2019-05-11T20:32:14.841Z,39,11,23,False,False,,"<p> (<em>Written for Arbital in 2016.</em>) </p><hr class=""dividerBlock""/><h2>Betting on one-time events</h2><p>Consider evaluating, in June of 2016, the question: &quot;What is the probability of Hillary Clinton winning the 2016 US presidential election?&quot;</p><p>On the <strong>propensity</strong> view, Hillary has some fundamental chance of winning the election. To ask about the probability is to ask about this objective chance. If we see a prediction market in which prices move after each new poll — so that it says 60% one day, and 80% a week later — then clearly the prediction market isn&#x27;t giving us very strong information about this objective chance, since it doesn&#x27;t seem very likely that Clinton&#x27;s <em>real</em> chance of winning is swinging so rapidly.</p><p>On the <strong>frequentist</strong> view, we cannot formally or rigorously say anything about the 2016 presidential election, because it only happens once. We can&#x27;t <em>observe</em> a frequency with which Clinton wins presidential elections. A frequentist might concede that they would cheerfully buy for $1 a ticket that pays $20 if Clinton wins, considering this a favorable bet in an <em>informal</em> sense, while insisting that this sort of reasoning isn&#x27;t sufficiently rigorous, and therefore isn&#x27;t suitable for being included in science journals.</p><p>On the <strong>subjective</strong> view, saying that Hillary has an 80% chance of winning the election summarizes our <em>knowledge about</em> the election or our <em>state of uncertainty</em> given what we currently know. It makes sense for the prediction market prices to change in response to new polls, because our current state of knowledge is changing.</p><br/><h2>A coin with an unknown bias</h2><p>Suppose we have a coin, weighted so that it lands heads somewhere between 0% and 100% of the time, but we don&#x27;t know the coin&#x27;s actual bias.</p><p>The coin is then flipped three times where we can see it. It comes up heads twice, and tails once: HHT.</p><p>The coin is then flipped again, where nobody can see it yet. An honest and trustworthy experimenter lets you spin a wheel-of-gambling-odds — reducing the worry that the experimenter might know more about the coin than you, and be offering you a deliberately rigged bet — and the wheel lands on (2 : 1). The experimenter asks if you&#x27;d enter into a gamble where you win $2 if the unseen coin flip is tails, and pay $1 if the unseen coin flip is heads.</p><p>On a <strong>propensity</strong> view, the coin has some objective probability between 0 and 1 of being heads, but we just don&#x27;t know what this probability is. Seeing HHT tells us that the coin isn&#x27;t all-heads or all-tails, but we&#x27;re still just guessing — we don&#x27;t really know the answer, and can&#x27;t say whether the bet is a fair bet.</p><p>On a <strong>frequentist</strong> view, the coin would (if flipped repeatedly) produce some long-run frequency <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> of heads that is between 0 and 1. If we kept flipping the coin long enough, the actual proportion <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span></span></span></span> of observed heads is guaranteed to approach <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> arbitrarily closely, eventually. We can&#x27;t say that the <em>next</em> coin flip is guaranteed to be H or T, but we can make an objectively true statement that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span></span></span></span> will approach <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> to within epsilon if we continue to flip the coin long enough.</p><p>To decide whether or not to take the bet, a frequentist might try to apply an unbiased estimator to the data we have so far. An &quot;unbiased estimator&quot; is a rule for taking an observation and producing an estimate <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, such that the <a href=""https://arbital.com/p/expected_value/"">expected value</a> of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>. In other words, a frequentist wants a rule such that, if the hidden bias of the coin was in fact to yield 75% heads, and we repeat many times the operation of flipping the coin a few times and then asking a new frequentist to estimate the coin&#x27;s bias using this rule, the <em>average</em> value of the estimated bias will be 0.75. This is a property of the <em>estimation rule</em> which is objective. We can&#x27;t hope for a rule that will always, in any particular case, yield the true <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> from just a few coin flips; but we can have a rule which will provably have an <em>average</em> estimate of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, if the experiment is repeated many times.</p><p>In this case, a simple unbiased estimator is to guess that the coin&#x27;s bias <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> is equal to the observed proportion of heads, or 2/3. In other words, if we repeat this experiment many many times, and whenever we see <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span></span></span></span> heads in 3 tosses we guess that the coin&#x27;s bias is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{p}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.497em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.703em; top: -1.342em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.703em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.497em;"" class=""mjx-line""></span></span><span style=""height: 1.435em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span>, then this rule definitely is an unbiased estimator. This estimator says that a bet of $2 vs. $1 is fair, meaning that it doesn&#x27;t yield an expected profit, so we have no reason to take the bet.</p><p>On a <strong>subjectivist</strong> view, we start out personally unsure of where the bias <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> lies within the interval [0, 1]. Unless we have any knowledge or suspicion leading us to think otherwise, the coin is just as likely to have a bias between 33% and 34%, as to have a bias between 66% and 67%; there&#x27;s no reason to think it&#x27;s more likely to be in one range or the other.</p><p>Each coin flip we see is then <a href=""https://arbital.com/p/bayes_strength_of_evidence/"">evidence</a> about the value of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, since a flip H happens with different probabilities depending on the different values of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, and we update our beliefs about <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> using <a href=""https://arbital.com/p/bayes_rule_functional/"">Bayes&#x27; rule</a>. For example, H is twice as likely if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f=\frac{2}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mfrac MJXc-space3""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span> than if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f=\frac{1}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mfrac MJXc-space3""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span> so by <a href=""https://arbital.com/p/bayes_rule_proportional/"">Bayes&#x27;s Rule</a> we should now think <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> is twice as likely to lie near <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{2}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span> as it is to lie near <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{1}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span>.</p><p>When we start with a uniform <a href=""https://arbital.com/p/ignorance_prior/"">prior</a>, observe multiple flips of a coin with an unknown bias, see <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span> heads and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span></span></span></span> tails, and then try to estimate the odds of the next flip coming up heads, the result is <a href=""https://arbital.com/p/laplace_rule_of_succession/"">Laplace&#x27;s Rule of Succession</a> which estimates (<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M+1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>) : (<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""N+1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>) for a probability of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{M+1}{M+N+2}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 2.966em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 4.195em; top: -1.471em;""><span class=""mjx-mrow"" style=""""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 4.195em; bottom: -0.764em;""><span class=""mjx-mrow"" style=""""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 2.966em;"" class=""mjx-line""></span></span><span style=""height: 1.581em; vertical-align: -0.54em;"" class=""mjx-vsize""></span></span></span></span></span></span>.</p><p>In this case, after observing HHT, we estimate odds of 2 : 3 for tails vs. heads on the next flip. This makes a gamble that wins $2 on tails and loses $1 on heads a profitable gamble in expectation, so we take the bet.</p><p>Our choice of a <a href=""https://arbital.com/p/ignorance_prior/"">uniform prior</a> over <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> was a little dubious — it&#x27;s the obvious way to express total ignorance about the bias of the coin, but obviousness isn&#x27;t everything. (For example, maybe we actually believe that a fair coin is more likely than a coin biased 50.0000023% towards heads.) However, all the reasoning after the choice of prior was rigorous according to the laws of <a href=""https://arbital.com/p/probability_theory/"">probability theory</a>, which is the only method of manipulating quantified uncertainty that obeys obvious-seeming rules about how subjective uncertainty should behave.</p><br/><h2>Probability that the 98,765th decimal digit of π is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></h2><p>What is the probability that the 98,765th digit in the decimal expansion of π is 0?</p><p>The <strong>propensity</strong> and <strong>frequentist</strong> views regard as nonsense the notion that we could talk about the <em>probability</em> of a mathematical fact. Either the 98,765th decimal digit of π is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span> or it&#x27;s not. If we&#x27;re running <em>repeated</em> experiments with a random number generator, and looking at different digits of π, then it might make sense to say that the random number generator has a 10% probability of picking numbers whose corresponding decimal digit of π is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>. But if we&#x27;re just picking a non-random number like 98,765, there&#x27;s no sense in which we could say that the 98,765th digit of π has a 10% propensity to be <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>, or that this digit is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span> with 10% frequency in the long run.</p><p>The <strong>subjectivist</strong> considers probabilities to just refer to their own uncertainty. So if a subjectivist has picked the number 98,765 without yet knowing the corresponding digit of π, and hasn&#x27;t made any observation that is known to them to be entangled with the 98,765th digit of π, and they&#x27;re pretty sure their friend hasn&#x27;t yet looked up the 98,765th digit of π either, and their friend offers a whimsical gamble that costs $1 if the digit is non-zero and pays $20 if the digit is zero, the Bayesian takes the bet.</p><p>Note that this demonstrates a difference between the subjectivist interpretation of &quot;probability&quot; and Bayesian probability theory. A perfect Bayesian reasoner that knows the rules of logic and the definition of π must, by the axioms of probability theory, assign probability either 0 or 1 to the claim &quot;the 98,765th digit of π is a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>&quot; (depending on whether or not it is). This is one of the reasons why perfect Bayesian reasoning is intractable. A subjectivist that is not a perfect Bayesian nevertheless claims that they are personally uncertain about the value of the 98,765th digit of π. Formalizing the rules of subjective probabilities about mathematical facts (in the way that <a href=""https://arbital.com/p/probability_theory/"">probability theory</a> formalized the rules for manipulating subjective probabilities about empirical facts, such as which way a coin came up) is an open problem; this in known as the problem of <a href=""https://arbital.com/p/logical_uncertainty/"">logical uncertainty</a>.</p>",So8res,so8res,So8res,
jEN7HumfhiWWDitkq,Programming Languages For AI,programming-languages-for-ai,https://www.lesswrong.com/posts/jEN7HumfhiWWDitkq/programming-languages-for-ai,2019-05-11T17:50:22.899Z,3,2,5,False,False,,"<h2>Firstly a chess analogy</h2><p>Suppose that you were part of a team trying to build a chess playing program. Your team has not yet had the fundamental insight of min-max search with approximate evaluations. While you definitely want some people on the team thinking hard about the abstract nature of chess, this is a somewhat serial process, is there anything else that could usefully be done in parallel? </p><p>While we wouldn&#x27;t have the insights to no exactly what a chess engine would look like, we can say some things about the code. The code will almost certainly want some sort of representation of chess pieces or chess boards. So implementing a virtual chessboard would not be a waste of time. </p><p>More speculatively, you might overhear the <strong>Thinking Hard About Chess</strong> department talk about how a good chess position was defined in terms of making the opponents move not good, and invent recursion. </p><p>Ideally, when the crucial insights have been had, all the building blocks needed to make it are ready to go. The first chess engine is half a page of <em>chesslang</em> code.</p><h2>On to AI</h2><p>So, can we think of any programmatic building blocks that are likely to be useful in building an AI. Yes, arithmatic, if statements, lists and so on. </p><p>These features have already been implemented in many programming languages, can we think of any features that might be useful in making AI that aren&#x27;t easily available in any programming languages?</p><p>Much current AI is arithmetical with neural networks and propagation. However, there are already several fairly easy to use libraries for this, and I can&#x27;t see how to make it  substantially easier to program this sort of AI, other than stuff like hyperparameter optimization that lots of people are already working on.</p><p>Much theoretical research on AI is symbolic, even Godelian. AIXItl for example, executes every piece of code up to a certain length and runtime. That would suggest that the programming language should make it easy to generate syntactically correct code, and to run it for a bounded time without side effects. This is also what you would want if you were generating code with an evolutionary algorithm. </p><p>On the alignment forum, several designs of AI mentioned involve &quot;search for a proof that this piece of code halts&quot;. So our programming language for AI should have powerful proof handling facilities. </p><h2>Suggested Mechanics</h2><p><strong>Some inspiration for the potential programming language designer</strong></p><p><strong>For anyone thinking that lisp isn&#x27;t abstract and self referential enough</strong></p><p><strong>First draft level.</strong></p><p>Start with an &quot;everything is a list&quot; approach from lisp/scheme. </p><p>First order propositional logic can be defined in terms of the symbols <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(, ),\implies, \bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⟹</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">⊥</span></span></span></span></span></span> and the propositions <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_1,p_2,\cdots""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋯</span></span></span></span></span></span>. When you are trying to prove something about propositional logic, the fewer symbols to deal with the better. However, when you are trying to prove something in propositional logic, you want extra symbols like <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\wedge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.372em;"">∧</span></span></span></span></span></span>. This can be managed by considering <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(a\wedge b)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.372em;"">∧</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> as syntactic shorthand for <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(a \implies (b\implies \bot))\implies \bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⟹</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⟹</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">⊥</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⟹</span></span><span class=""mjx-mspace"" style=""width: 0.278em; height: 0px;""></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">⊥</span></span></span></span></span></span>. Lisp style macros are good for this. </p><p>We can consider programs as formulas in some first order theory.</p><p>Consider the program <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\newcommand{\t}[1]{\textbf{ #1} }
\t{(+ 5 (* 2 3))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(+ 5 (* 2 3))</span></span></span></span></span></span></span></span> The interpreter can syntactically modify it into the simpler program <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(+ 5 6)} ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(+ 5 6)</span></span></span></span></span></span></span></span> and then into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""11""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">11</span></span></span></span></span></span>. </p><p>A more complex example. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(sum  (map '(1 2 3) (lambda (x) (* x x))))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(sum  (map '(1 2 3) (lambda (x) (* x x))))</span></span></span></span></span></span></span></span> goes to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(sum  '((* 1 1) (* 2 2) (* 3 3)))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(sum  '((* 1 1) (* 2 2) (* 3 3)))</span></span></span></span></span></span></span></span> then to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(sum  '(1 4 9))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(sum  '(1 4 9))</span></span></span></span></span></span></span></span>  and finally to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""14""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">14</span></span></span></span></span></span>. </p><p>Considered like this, the interpreter is automatically generating a proof that the program is equal to some value. Its automatically simplifying the program until it gets its answer. Note that it doesn&#x27;t harness the full power of first order arithmetic, its missing predicates like <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(\forall n\in \mathbb N)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∀</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">N</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> . It can also get stuck in infinite loops.</p><p>In the general view, there are a finite number of transformations that can be applied, and you want a sequence of transformations that leads from one tree to another. These transformations are the <strong>atomic tactics</strong>. (They are equivalent to axioms in some sense).</p><p>Example <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(forall (x N) (< x 7))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(forall (x N) (&lt; x 7))</span></span></span></span></span></span></span></span> can be transformed by the general rule that for any <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{y}\in \t{N}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.151em; padding-bottom: 0.593em;"">&nbsp;y</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;N</span></span></span></span></span></span></span></span> and function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{p}:\t N\rightarrow \t {Bool}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.151em; padding-bottom: 0.593em;"">&nbsp;p</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;N</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;Bool</span></span></span></span></span></span></span></span>,  expressions of the form   <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(forall (x N) (p x))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(forall (x N) (p x))</span></span></span></span></span></span></span></span> are equivalent to  <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(and (p y) (forall (x N)  (p x)))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(and (p y) (forall (x N)  (p x)))</span></span></span></span></span></span></span></span>. This gives (y=9) <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(and (< 9 7) (forall (x N)  (< x 7)))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(and (&lt; 9 7) (forall (x N)  (&lt; x 7)))</span></span></span></span></span></span></span></span>. This turns into  <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(and False (forall (x N)  (< x 7)))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(and False (forall (x N)  (&lt; x 7)))</span></span></span></span></span></span></span></span>  and then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{False}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;False</span></span></span></span></span></span></span></span>.  </p><p>Note that the only difference is that here the choice of local transformations is not uniquely determined. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{forall}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;forall</span></span></span></span></span></span></span></span> makes the abstract symbol <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">&nbsp;x</span></span></span></span></span></span></span></span> available in its interior in much the same way that lisps &quot;let&quot; does. Here <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;N</span></span></span></span></span></span></span></span> the natural number type. This language would be typed at parse time, the type of an expression should depend only on the type of its sub-components. (A strict interpretation might have  <strong>less_reals</strong> and <strong>less_ints</strong> distinct functions, one of type, but using the &lt; symbol for both should work.) A type is just a variable of type type, so using a type that you haven&#x27;t defined, and isn&#x27;t builtin is just a special case of using an undefined variable. When parsing the code, use of any undefined variable fails syntactically. Types can be combined with union and struct as common in strongly typed programming languages. Standard category theory based type system.</p><p>This is where the idea of <strong>tactics</strong> comes in. (word definition) A <strong>tactic</strong> is a function that takes in an arbitrary formulae (and possibly some other stuff), and processes it and outputs a semantically identical formulae. (with runtime bounds on it doing so if need be, and the possibility of arbitrary programmer supplied hints)(it applies a series of syntactic transformations)</p><p>Here a function is any expression with free variables to substitute. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(lambda (x) (exists (y N) (= (* y 2) x)))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(lambda (x) (exists (y N) (= (* y 2) x)))</span></span></span></span></span></span></span></span> is a perfectly good function, which returns  <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(exists (y N) (= (* y 2) 4))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(exists (y N) (= (* y 2) 4))</span></span></span></span></span></span></span></span> when called on <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""4""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">4</span></span></span></span></span></span>. </p><p>One builtin tactic would be <u>evaluate</u>, which evaluates expressions and finite loops, and ignores any predicate. If you just wrapped the rest of the code in an evaluate, an never used any other tactics, you would have a side effect free version of lisp. (or something like it)</p><p>Another tactic might be called <u>example</u>, which removes <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(\exists x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∃</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>  by having the programmer give a suitable <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>. </p><p>A toy example would be this function, which transforms <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\exists y: p(y)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∃</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(p(x))\vee (\exists y: p(y))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.372em;"">∨</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∃</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> . Ie <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(exists (y N) (= (* y 2) 4))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(exists (y N) (= (* y 2) 4))</span></span></span></span></span></span></span></span> into (using x=2)<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(or (= (* 2 2) 4) (exists (y N) (= (* y 2) 4)))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(or (= (* 2 2) 4) (exists (y N) (= (* y 2) 4)))</span></span></span></span></span></span></span></span> </p><p><span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{(lambda (f x) (if (= (car f) 'exists) (list 'or (cddr f) (replace f (caadr f) x)) f))}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">&nbsp;(lambda (f x) (if (= (car f) 'exists) (list 'or (cddr f) (replace f (caadr f) x)) f))</span></span></span></span></span></span></span></span> </p><p>Another could be <u>minimize_metric_neighborhood</u> this would take in some metric, eg number of sub-expressions, and try a bunch of other tactics to minimize it.</p><p>other tactics would be <u>induction</u>. <u>deduction_thm</u> ect.</p><p>The important point is that the programmer is free to design new tactics. The job of the compiler/interpreter is to ensure the tactics transform code in a syntactically valid manor, and to implement the built in tactics.</p><p>Note that you need to use a tactic to define new tactics. </p><p>Suppose you didn&#x27;t have the deduction theorem and you wanted to define it</p><p>Suppose you provide a function that takes in a proof using the deduction theorem, and outputs a proof not using the deduction theorem, without proving that this function always outputs a valid proof. All you have is a macro, a convenient programmer shortcut. Whenever you use the deduction theorem macro, the proof is expanded out behind the scenes. Convenient, but not a new tactic.</p><p>Suppose you prove that &quot;any theorem that can be proved using the deduction theorem can also be proved without it&quot;, not necessarily in a constructive manor. Then any time you want to use the deduction theorem, the program can use that tactic without expanding it out in this specific case. </p><p>To avoid Lobian obstacles to do with self trusting proof systems, all tactics must have a rank, which is an ordinal. </p><p>Suppose a tactic <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> is defined as an arbitrary function from an expression <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> and a hint <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span></span></span></span> to an output <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""s""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span></span></span></span></span>. </p><p>You validate <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> by proving (using tactics <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t_1,t_2\cdots t_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋯</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>) that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\forall e:\exists i\in \mathbb N :\exists r_1,r_2,\cdots r_i\in Q
 :\exists h_1,h_2,\cdots h_i \in \t{hints}:A(e,h)=r_1(r_2(\cdots r_i(e,h_i),\cdots,h_2),h_1)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∀</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∃</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">N</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∃</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋯</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∃</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋯</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;hints</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋯</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">⋯</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> </p><p>(You needn&#x27;t calculate <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> explicitly, just show that they must exist.) </p><p>Where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""Q\subset\t{tactics}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⊂</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;tactics</span></span></span></span></span></span></span></span> is a set such that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup_ {q\in Q} (\t{rank}(q)+1)= \alpha""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-munderover""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.36em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em; padding-right: 0.014em;"">q</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">∈</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em;"">Q</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;rank</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em; padding-right: 0.014em;"">q</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">α</span></span></span></span></span></span> where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\alpha""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">α</span></span></span></span></span></span> is some ordinal.  Then the rank of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> must be chosen such that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\t{rank}(A)\geq \alpha""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;rank</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">≥</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">α</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\forall j\leq n:\t{rank}(A)\geq \t{rank}(t_j)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∀</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">j</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">≤</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;rank</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">≥</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-B"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&nbsp;rank</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">j</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. Most of the time, these will be small finite ordinals that could be filled in automatically. </p><p>Note that any proof that uses tactics of rank at most <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\alpha""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">α</span></span></span></span></span></span> is a valid proof in the language of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""ZFC+\alpha""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;"">Z</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">α</span></span></span></span></span></span>. The basic language would have a ZFC set type, (you need it for the ordinals), but if it wasn&#x27;t there,  you should be able to define it by declaring a bunch of atomic tactics ).</p><p></p><h2>Questions to discuss in comments</h2><p>1) Is it a good real world strategy to design new programming languages more suitable for AI?</p><p>2) Are there any features a good AI language might want other than an excessive amount of self reference and abstract mathematicallity.</p><p>3) Any more suggestions or ambiguities related to the programming language outlined above?</p><p>4) If a programing language like this already exists, let me know.</p><p></p>",donald-hobson,donald-hobson,Donald Hobson,
tuaZhAEQEN4JYeh59,SSC Atlanta,ssc-atlanta,https://www.lesswrong.com/events/tuaZhAEQEN4JYeh59/ssc-atlanta,2019-05-11T17:38:21.671Z,1,1,1,False,False,,,steve-french,steve-french,Steve French,
g4prGhEpSm9inFSnz,alternative history: what if Bayes rule had never been discovered?,alternative-history-what-if-bayes-rule-had-never-been,https://www.lesswrong.com/posts/g4prGhEpSm9inFSnz/alternative-history-what-if-bayes-rule-had-never-been,2019-05-11T07:29:58.979Z,7,3,3,False,True,,"<p>In trying to understand how Bayesian probability is used, I&#x27;m curious to know what wouldn&#x27;t have been possible without it. how important was it in the course of human discovery, and in turn, how it effected history.</p><p>I don&#x27;t demand rigorous answers, feel free to speculate and throw possibilities as you like. </p><p>Bonus question: if Bayes didn&#x27;t discover it, when would it have to be discovered? (full speculation mode)</p>",Yoav Ravid,yoav-ravid,Yoav Ravid,
wmB4nYBrjfXeJZEAh,"How do the different star-types in the universe (red dwarf, etc.) related to habitability for human-like life?",how-do-the-different-star-types-in-the-universe-red-dwarf,https://www.lesswrong.com/posts/wmB4nYBrjfXeJZEAh/how-do-the-different-star-types-in-the-universe-red-dwarf,2019-05-11T01:01:52.202Z,6,1,0,False,True,,,Ruby,ruby,Ruby,
9PJQMwTuaEhEKkSgK,The Athena Rationality Workshop - June 7th-10th at EA Hotel,the-athena-rationality-workshop-june-7th-10th-at-ea-hotel,https://www.lesswrong.com/events/9PJQMwTuaEhEKkSgK/the-athena-rationality-workshop-june-7th-10th-at-ea-hotel,2019-05-11T01:01:01.973Z,26,9,0,False,False,,"<p>For the past few months, Matt Goldenberg has been in charge of teaching applied rationality at the EA hotel. And honestly, we’ve been quite impressed by the quality. Matt has been a great teacher, and some of us felt like we wanted to delve deeper into his material. So let us delve into it together! </p><p>During the first weekend of June, the <a href=""http://eahotel.org"">EA Hotel</a> will host its first rationality workshop. Open to anyone interested.</p><p>We will delve into the <u><a href=""https://www.lesswrong.com/posts/mFvuQTzHQiBCDEKw6/a-framework-for-internal-debugging"">Ease process</a></u>, which is step by step process for overcoming internal blocks and creating psychological alignment towards your goals.</p><p>Matt has been working intensely on self-improvement for the past 15 years, was a professional coach for 5 years and has been running applied rationality group workshops for the past 18 months. Some guest teachers will also be chiming in with their techniques, including Toon Alfrink with some lessons he learned living at a Zen Monastery, and possibly others.</p><p>The workshop will be held June 7th-10th, Friday to Monday, starting at 12:00 and ending at 19:00. Travelers from afar can stay the night on Thursday. There will be an optional chill-out day on Tuesday, June 11th, and you’re welcome to stay longer. Payment will be at the end of the workshop for whatever you think it was worth for you (cost price is £40). All proceeds will go to fund the EA hotel.</p><p>If you want to join: <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLScRXtBkwIQElvEfenxZJ53dlvWRJhfKW4GNZy_tcOTwYBdvVw/viewform"">Sign up here</a></u>.</p>",Linda Linsefors,linda-linsefors,Linda Linsefors,
Tm6cYNLJzqatgiGyP,"How many ""human"" habitable planets/stars are in the universe?",how-many-human-habitable-planets-stars-are-in-the-universe,https://www.lesswrong.com/posts/Tm6cYNLJzqatgiGyP/how-many-human-habitable-planets-stars-are-in-the-universe,2019-05-11T00:59:59.648Z,6,1,0,False,True,,<p>I&#x27;m willing to include planets which could be made habitable via terraforming or slight genetic modification to humans.</p>,Ruby,ruby,Ruby,
HXyGXq9YmKdjqPseW,Rob B's Shortform Feed,rob-b-s-shortform-feed,https://www.lesswrong.com/posts/HXyGXq9YmKdjqPseW/rob-b-s-shortform-feed,2019-05-10T23:10:14.483Z,21,5,79,False,False,,"<p>This is a repository for miscellaneous short things I want to post. Other people are welcome to make top-level comments here if they want. (E.g., questions for me you&#x27;d rather discuss publicly than via PM; links you think will be interesting to people in this comment section but not to LW as a whole; etc.)</p>",RobbBB,robbbb,Rob Bensinger,
s9kjYkRQCrQQQ4qsQ,The Athena Rationality Workshop - June 7th-10th at EA Hotel,the-athena-rationality-workshop-june-7th-10th-at-ea-hotel,https://www.lesswrong.com/posts/s9kjYkRQCrQQQ4qsQ/the-athena-rationality-workshop-june-7th-10th-at-ea-hotel,2019-05-10T22:08:03.600Z,5,3,0,False,False,,"<p>For the past few months, Matt Goldenberg has been in charge of teaching applied rationality at the EA hotel. And honestly, we’ve been quite impressed by the quality. Matt has been a great teacher, and some of us felt like we wanted to delve deeper into his material. So let us delve into it together! </p><p>During the first weekend of June, the <a href=""http://eahotel.org"">EA Hotel</a> (36 York Street, Blackpool, UK) will host its first rationality workshop. Open to anyone interested.</p><p>We will delve into the <u><a href=""https://www.lesswrong.com/posts/mFvuQTzHQiBCDEKw6/a-framework-for-internal-debugging"">Ease process</a></u>, which is step by step process for overcoming internal blocks and creating psychological alignment towards your goals.</p><p>Matt has been working intensely on self-improvement for the past 15 years, was a professional coach for 5 years and has been running applied rationality group workshops for the past 18 months. Some guest teachers will also be chiming in with their techniques, including Toon Alfrink with some lessons he learned living at a Zen Monastery, and possibly others.</p><p>The workshop will be held June 7th-10th, Friday to Monday, starting at 12:00 and ending at 19:00. Travelers from afar can stay the night on Thursday. There will be an optional chill-out day on Tuesday, June 11th, and you’re welcome to stay longer. Payment will be at the end of the workshop for whatever you think it was worth for you (cost price is £40). All proceeds will go to fund the EA hotel.</p><p>If you want to join: <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLScRXtBkwIQElvEfenxZJ53dlvWRJhfKW4GNZy_tcOTwYBdvVw/viewform"">Sign up here</a></u>.</p>",Linda Linsefors,linda-linsefors,Linda Linsefors,
3pKXC62C98EgCeZc4,Complex Behavior from Simple (Sub)Agents,complex-behavior-from-simple-sub-agents,https://www.lesswrong.com/posts/3pKXC62C98EgCeZc4/complex-behavior-from-simple-sub-agents,2019-05-10T21:44:04.895Z,113,42,14,False,False,,"<p><em>Epistemic Status: Simultaneously this is work that took me a long time and a lot of thought, and also a playful and highly speculative investigation. Consider taking this seriously but not literally.</em></p><p><strong>Introduction</strong></p><p>Take a simple agent (<a href=""https://github.com/moridinamael/subagents"">GitHub</a>; Python), with no capacity for learning, that exists on a 2D plane. It shares the plane with other agents and objects, to be described shortly.</p><p>The agent intrinsically doesn&#x27;t want anything. But it can be assigned goal-like objects, which one might view as subagents. Each individual goal-like subagent can possess a simple preference, such as a desire to reach a certain region of space, or a desire to avoid a certain point.</p><p>The goal-like subagents can also vary in the degree to which they remain satisfied. Some might be permanently satisfied after achieving their goal once; some might quickly become unsatisfied again after a few timesteps.</p><p>Every timestep, the agent considers ten random movements of unit-distance, and executes the movement corresponding to the highest expected valence being reported by its goal-like subagents, in a winner-take-all fashion.</p><p>Even with such an intentionally simplistic model, a surprising and illuminating level of behavioral complexity can arise.</p><p>Sections 1-8 concern interesting or amusing behaviors exhibited by the model.</p><p>Sections 8-12 outline future directions for the model and ruminations on human behavior.</p><p><strong>1. Baseline</strong></p><p>In this image, the path of the agent is painted with points, the color of the points changing slowly with the passage of time. This agent possesses three subagents with preferences for reaching the three green circles, and a fourth mild preference for avoiding the red circle. </p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/01_Baseline.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>Once it comes within a set distance of one of the green circles, the corresponding subagent is satisfied, and thus the movement with the highest expected valence switches to the next-highest valence goal. The satisfaction gradually wears off, and the agent begins to be drawn to the goal again. Thus, the agent moves inexorably around the triangle of green circles, sometimes in a circuit, sometimes backtracking.</p><p><strong>2. &quot;Ugh field&quot;</strong></p><p>If the aversion to the red circle is amplified above a certain threshold, this behavior results. The subagent with preferences for reaching the top green circle still exists, but it will never be satisfied, because expected negative valence of passing near the red circle is too high.</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/02_AversiveObstacle.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>But if one is clever, one can find a way around aversions, by inventing intermediary goals or circumventing the aversion with intermediate desirable states.</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/03_EndAround.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>Sometimes a you want to accomplish something, but a seemingly trivial inconvenience will arise to screen off your motivation. If you can&#x27;t remove the inconvenience, you can usually find a path around it.</p><p><strong>3. Smartphone</strong></p><p>What if the agent has, pinned to its position (such that it is constantly somewhat nearby), a low-valence rewarding object, which doesn&#x27;t provide lasting satisfaction? (In other words - the agent has a goal-like subagent which mildly but relatively persistently wants to approach the pinned object.)</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/04_CellPhone.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>The agent suddenly looks very distracted, doesn&#x27;t it? It doesn&#x27;t make the same regular productive circuits of its goals. It seems to frequently get stuck, sphexishly returning to a goal that it just accomplished, and to take odd pointless energy-wasting zigzags in its path.</p><p>Maybe it&#x27;s bad to constantly carry around attention-grabbing objects that provide us with miniscule, unsatisfying hits of positive valence.</p><p>Considered together, Parts 2 and 3 speak to the dangers of convenience and the power of trivial inconvenience. The agents (and humans) are extraordinarily sensitive not only to the absolute valence of an expectation, but to the proximity of that state. Even objectively weak subagents can motivate behavior if they are unceasingly present.</p><p><strong>4. Agitation and/or Energy</strong></p><p>The model does not actually have any concept of energy, but it is straightforward to encode a preference for moving around a lot. When the agent is so inclined, its behavior becomes chaotic.</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/05_Agitated.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>Even a relatively moderate preference for increased movement will lead to some erratic swerves in behavior.</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/06_Unfocused.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>If one wished, one could map this type of behavior onto agitation, or ADHD, or anxiety, or being overly caffeinated. On the other hand, you could view some degree of &quot;restlessness&quot; as a drive toward exploration, without which one might never discover new goals.</p><p>One path of investigation that occurred to me but which I did not explore was to give the agent a level of movement-preference that waxed and waned cyclically over time. Sometimes you subjectively have a lot of willpower, sometimes you subjectively <em>can&#x27;t</em> focus on anything. But, on the whole, we all manage to get stuff done.</p><p><strong>5. Look-Ahead</strong></p><p>I attempted to implement an ability for the agent to scan ahead more than one step into the future and take the movement corresponding the highest expected valence in <em>two</em> timesteps, rather than just the next timestep. This didn&#x27;t really show anything interesting, and remains in the category of things that I will continue to look into. (The Red agent is thinking two moves ahead, the Blue agent only one move ahead. Is there a difference? Is the clustering of the Red agent&#x27;s pathing slightly tighter? Difficult to say.)</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/07_Lookahead.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>I don&#x27;t personally think humans explicitly look ahead very often. We give ourselves credit as the &quot;thinking, planning animal&quot;, but we generally just make whichever choice corresponds to the highest expected valence in the current moment. Looking ahead is also very computationally expensive - both for people, and for these agents - because it inevitably requires something like a model-based tree search. What I think we <em>actually</em> do is better addressed in Section 10 regarding Goal Hierarchies.</p><p><strong>6. Sociability</strong></p><p>Of course, we can give the agents preferences for being near other agents, obeying the same rules as the preferences for any other position in space.</p><p>With hyper-dominant, non-extinguishing preferences for being around other agents, we get this piece of computer generated art that I call &quot;Lovers&quot;.</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/09b_Lovers.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>With more modest preference for the company of other agents, and with partially-overlapping goals (Blue agent wants to spend time around the top and rightmost target, Red agent wants to spend time around the top and leftmost target) you get this <em>other</em> piece of art that I call &quot;Healthy Friendship&quot;. It looks like they&#x27;re having fun, doesn&#x27;t it?</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/10_Friends.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p><strong>7. New Goals Are Disruptive</strong></p><p>Brief reflection should confirm that introducing a new goal into your life can be very disruptive to your existing goals. You could say that permitting a new goal-like subagent to take root in your mind is akin to introducing a competitor who will now be bidding against all your existing goals for the scarce resource of your time and attention.</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/11_Disruption.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>Compare this image with the Baseline at the top of this article. The new, powerful top-right goal has siphoned away all the attention from the formerly stable, well-tended trio of goals.</p><p>I think one of the main reasons we fall down on our goals is simply that we spontaneously generate new goals, and these new goals disrupt our existing motivational patterns.</p><p><strong>8. Winner-Take-All?</strong></p><p>You may have more questions about the winner-take-all assumption that I mentioned above. In this simple model, the goal-like subagents do not &quot;team up&quot;. If two subagents would prefer that the agent move to the left, this does not mean that their associated valence will sum up and make that choice more globally appealing. The reason is simple: if you straightforwardly sum up over all valences instead of picking a winner, this is what happens:</p><span><figure><img src=""https://www.doofmedia.com/wp-content/uploads/2019/05/12_Summation.png"" class=""draft-image center"" style=""width:40%"" /></figure></span><p>The agent simply seeks out a local minimum and stays there.</p><p>I am currently somewhat agnostic as to what the human or animal brain is actually doing. We do appear to get stuck in local minima sometimes. But you can get sphexish behavior that looks like a local minimum out of a particular arrangement of winner-take-all subagents. For example, if an agent is hemmed in by aversive stimuli with no sufficiently positive goal-states nearby, that might look like a local minimum, though it is still reacting to each aversive stimulus in a winner-take-all fashion.</p><p>Subjectively, though, it feels like if you have two good reasons supporting an action, that makes the action feel a bit easier to do, a bit more motivating, than if you just had one good reason. This hints that maybe goal-like subagents can gang up together. But I also doubt that this is anything like strictly additive. Thinking of 2,000 reasons why I should go to the gym isn&#x27;t 2,000 times more compelling than thinking of one reason.</p><p><strong>9. Belief, Bias, and Learning</strong></p><p>The main area of the model that I would like to improve, but which would amplify the complexity of the code tremendously, would be in introducing the concept of bias and/or belief. The agent should be able to be <em>wrong </em>about its expected valence. I think this is hugely important, actually, and explains a lot about human behavior.</p><p>Pathologies arise when we are systematically wrong about how good, or how bad, some future state will be. But we can overcome pathologies by exposing ourselves to those states, and becoming deeply calibrated regarding their reality. On the aversion side this applies to everything from the treatment of phobias and PTSD, to the proper response to a reasonable-seeming anxiety. On the positive-valence side, we may imagine that it would be incredibly cool and awesome to do or to be some particular thing, and only experience can show us that accomplishing such things yields only a shadow of what we expected. Then your brain updates on that, and you cease to feel motivated to do that thing anymore. You can no longer sustain the delusion that it was going to be awesome.</p><p><strong>10. Goal Hierarchies</strong></p><p>It seems clear that, in humans, goals are arranged in something like trees: I finish this current push-up because I want to finish my workout. I want to finish my workout because I want to stay on my workout program. I want to stay on my workout program because I want to be strong and healthy. </p><p>But it&#x27;s almost certainly more complex than this, and I don&#x27;t know how the brain manages its &quot;expected valence&quot; calculations across levels of the tree.</p><p>I hypothesize that it goes something like this. Goal-like subagents concerned with far-future outcomes, like &quot;being strong and healthy&quot;, generate (or perhaps <em>manifest as</em>) more specific near-term goal-like targets, with accompanying concrete sensory-expectation targets, like &quot;working out today&quot;. This seems like one of those mostly automatic things that happens whether or not we engineer it. The automaticity of it seems to rely on our maps/models/beliefs about how the world works. Even much simpler animals can chain together and break down goals, in the course of moving across terrain toward prey, for example.</p><p>The model described above doesn&#x27;t really have a world model and can&#x27;t learn. I could artificially designate some goals as being sub-goals of other goals, but I don&#x27;t think this is how it actually works, and I don&#x27;t actually think it would yield any more interesting behavior. But it might be worth looking into. Perhaps the most compelling aspect of this area is that what would be needed would not be to amplify the cleverness of the agent; it would be to amplify the cleverness of the <em>subagent</em> in manipulating and making its preferences clearer to the agent. For example: give subagents the power to generate new goal-objects, and lend part of their own valence to those subagents.</p><p><strong>11. Suffering</strong></p><p>I toyed with the idea of summing up all the valences of the goal-objects that were being ignored at any given moment, and calling that &quot;suffering&quot;. This sure is what suffering feels like, and it&#x27;s akin to what those of a spiritual bent would call suffering. Basically, suffering is wanting contradictory, mutually exclusive things, or, being aware of wanting things to be a certain way while simultaneously being aware of your inability to work toward making it that way. One subagent wants to move left, one subagent wants to move right, but the agent has to pick one. Suffering is something like the expected valence of the subagent that is left frustrated.</p><p>I had a notion here that I could stochastically introduce a new goal that would minimize total suffering over an agent&#x27;s life-history. I tried this, and the most stable solution turned out to be thus: introduce an overwhelmingly aversive goal that causes the agent to run far away from all of its other goals screaming. Fleeing in perpetual terror, it will be too far away from its attractor-goals to feel much expected valence towards them, and thus won&#x27;t feel too much regret about running away from them. And it is in a sense satisfied that it is always getting further and further away from the object of its dread.</p><p>File this under &quot;degenerate solutions that an unfriendly AI would probably come up with to improve your life.&quot;</p><p>I think a more well-thought-out definition of suffering might yield much more interesting solutions to the suffering-minimization problem. This is another part of the model I would like to improve.</p><p><strong>12. Happiness and Utility</strong></p><p>Consider our simple agents. What makes them happy?</p><p>You could say that something like satisfaction arises the moment they trigger a goal-state. But that goal object immediately begins recharging, becoming &quot;dissatisfied&quot; again. The agent is never actually content, unless you set up the inputs such that the goal valences don&#x27;t regenerate - or if you don&#x27;t give it goals in the first place. But if you did that, the agent would just wander around randomly after accomplishing its goals. That doesn&#x27;t seem like happiness.</p><p>Obviously this code doesn&#x27;t experience happiness, but when I look at the behavior of the agents under different assumptions, the agents <em>seem</em> happy when they are engaged in accomplishing their various goals. They seem <em>unhappy</em> when I create situations that impede the efficiency of their work. This is obviously pure projection, and says more about me, the human, than it says about the agent.</p><p>So maybe a more interesting question: What are the high-utility states for the agent? At any given moment of time the agents certainly have preference orderings, but those preference orderings shift quite dramatically based on its location and the exact states of  each of its subagents, specifically their current level of satisfaction. In other words, in order to mathematically model the preference ordering of the agent across all times, you must model the individual subagents.</p><p>If humans &quot;actually&quot; &quot;have&quot; &quot;subagents&quot; - whatever those words actually end up meaning - then the &quot;human utility function&quot; will need to encompass each and every subagent. Even, I think, the very stupid ones that you don&#x27;t reflectively endorse.</p><p><strong>Conclusion</strong></p><p>I set out on this little project because I wanted to prove some assumptions about the &quot;subagent&quot; model of human consciousness. I don&#x27;t think I can ultimately say that I &quot;proved&quot; anything, and I&#x27;m not sure that one could ever &quot;prove&quot; anything about human psychology using this particular methodology.</p><p>The line of thinking that prompted this exploration owes a lot to Kaj_Sotala, for his <a href=""https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip"">ongoing Sequence</a>, Scott Alexander&#x27;s <a href=""https://slatestarcodex.com/2018/02/07/guyenet-on-motivation/"">reflections</a> on motivation, and Mark Lippman&#x27;s <a href=""https://www.dropbox.com/s/srjro4caxla0pcd/Folding%201.0%20by%20Mark%20Lippmann.pdf?dl=0"">Folding</a> material. It&#x27;s also their fault I used the unwieldy language &quot;goal-like subagent&quot; instead of just saying &quot;the agent has several goals&quot;. I think it&#x27;s much more accurate, and useful, to think of the mind as being composed of subagents, than to say it &quot;has goals&quot;. Do you &quot;have&quot; goals if the goals control you?</p><p>This exercise has changed my inner model of my own motivational system. If you think long enough in terms of subagents, something eventually clicks. Your inner life, and your behaviors, seems to make a lot more sense. Sometimes you can even leverage this perspective to construct better goals, or to understand where some goals are actually coming from.</p><p>The code linked at the top of this page will generate all of the figures in this article. It is not especially well documented, and bears the marks of having been programmed by a feral programmer raised in the wilds of various academic and industrial institutions. Be the at as it may, the interface is not overly complex. Please let me know if anyone ends up playing with the code and getting anything interesting out of it.</p>",moridinamael,moridinamael,moridinamael,
xYav5gMSuQvhQHNHG,Disincentives for participating on LW/AF,disincentives-for-participating-on-lw-af,https://www.lesswrong.com/posts/xYav5gMSuQvhQHNHG/disincentives-for-participating-on-lw-af,2019-05-10T19:46:36.010Z,86,40,45,True,False,,"<html><head></head><body><p>I was in a research retreat recently with many AI alignment researchers, and found that the vast majority of them do not participate (post or comment) on LW/AF or participate to a much lesser extent than I would prefer. It seems important to bring this up and talk about whether we can do something about it. Unfortunately I didn't get a chance to ask them about why that is the case as there were other things to talk about, so I'm going to have to speculate here based on my personal experiences and folk psychology. (Perhaps the LW team could conduct a survey and get a better picture than this.)</p>
<ul>
<li>Criticism that feels overly harsh or is otherwise psychologically unpleasant</li>
<li>Downvotes</li>
<li>Not getting enough upvotes as one feels deserved</li>
<li>Not getting enough engagement</li>
<li>More adversarial (zero-sum) nature of public discussion / preferring private discussions for more collaborative nature</li>
<li>Feeling like ""losing"" a debate when the other person gets more upvotes than you</li>
<li>More effort needed to write comments than to talk to people IRL</li>
<li>Not real-time / time lag between replies</li>
<li>Feeling ignored when someone stops responding</li>
<li>Others?</li>
<li>ETA: Potentially leaving a record of being wrong in public</li>
</ul>
<p>One meta problem is that different people have different sensitivities to these disincentives, and having enough disincentives to filter out low-quality content from people with low sensitivities just necessarily means some potential high-quality content from people with high sensitivities are also kept out. But it seems like there are still some things worth doing or experimenting with. For example:</p>
<ul>
<li>Support for real-time collaborative discussion which subsequently get posted and voted upon as one unit (with votes going equally to both participants)</li>
<li>Disabling downvotes on AF</li>
<li>Having more indications/reminders of how much posting to LW/AF benefits the individual posters and the wider community, in terms of making intellectual progress and spreading good ideas. I'm not sure what form this could take, but maybe things like an indication of how many times a post is read.</li>
<li>My previous feature suggestion to help with the ""feeling ignored"" problem</li>
<li>Being less critical of new users and engaging more positively with them</li>
</ul>
<p>There's a separate issue that some people don't <em>read</em> LW/AF as much as I would prefer but I have much less idea what is going on there.</p>
<p>On a tangentially related topic, is LW making any preparations (such as thinking about what to do) for a seemingly not very far future where automated opinion influencers are widely available as hirable services? I'm imagining some AI that you can hire to scan internet discussion forums and make posts or replies in order to change readers' beliefs/values in some specified direction. This might be very crude at the beginning but could already greatly degrade the experience of participating on public discussion forums.</p>
</body></html>",Wei_Dai,wei-dai,Wei Dai,
cZfNYxd7BRbDb2gY4,Financial engineering for funding drug research,financial-engineering-for-funding-drug-research,https://www.lesswrong.com/posts/cZfNYxd7BRbDb2gY4/financial-engineering-for-funding-drug-research,2019-05-10T18:46:03.029Z,11,5,3,False,False,,"<p><strong>Concept</strong></p><p>A group of people from MIT&#x27;s Sloan School of Management have put together a proposal for using financial engineering to get across the valley of death in drug development. The pitch is, approximately, to securitize a batch of drugs, and then re-securitize them after each stage of FDA trials. By using these securities, it becomes possible to build a fund which will finance a slew of drugs via both debt and equity, with rates of return comparable to things regular financial markets invest in. This makes it possible to put the financial might of mutual funds, retirement accounts, and people interested in hedging like medical insurers, behind drug development.</p><p><strong>Megafunds</strong></p><p>This takes a lot of money. A <em>lot</em> of money. In the <a href=""http://www.rogermstein.com/wp-content/uploads/FernandezSteinLo_NBT_2012.pdf"">original paper</a> they modeled drug development as an investment of $200M, which after 10 years had a 5% success rate, with an average return of $12.3B on success (which number is the expected present value of $2B a year for 10 years, which itself is the expected length of monopoly guarantee). This is a heavy-duty risk, and most investors are unwilling or unable to take it. While it is clearly still worth it for drug companies, there is only so much money they can invest, and so the total investment is constrained. In the basic model they use 150 independent drugs, which means a megafund of 150 * $200M = $30B. The less independent the drugs, the more capital is required. So they need a way to distribute the risks such that they have access to this huge amount of capital.</p><p><strong>Securities</strong></p><p>The tool that they have developed for this is the Research-Backed Obligation, or RBO. Quoting from the original paper linked above:</p><blockquote>A common form of securitization involves “cashflow” transactions in which a portfolio of assets—typically mortgages, auto loans, student loans, or credit-card receivables—is acquired using money raised by issuing equity and bonds of different seniorities. These assets and the cashflow they generate are pledged as collateral for the debt. In our proposed application, the assets include the initial capital raised from investors, all the subsequent biomedical R&amp;D and licenses acquired, and all the profits generated by these activities or through sales of these assets in later periods. The application of securitization to early-stage clinical and preclinical biomedical has not been described previously, and we shall refer to debt that is collateralized by such assets as ‘research-backed obligations’.</blockquote><p>For most of their simulations they have the security broken down into senior-tranche (the debt which gets paid first) junior-tranche (the debt which gets paid last) and equity-tranche (the people who own equity, and get everything that doesn&#x27;t go to debt).</p><p><strong>Benefits</strong></p><p>According to their short paper <a href=""http://www.rogermstein.com/wp-content/uploads/AER2013_Pub1.pdf"">Can Financial Engineering Cure Cancer?</a>, which simulated using these tools, the megafund generated average annualized returns of 5%, 8%, and 9.1% for senior, junior, and equity respectively. These averages are within the range for institutional investors, like mutual funds and pensions, and the risks are low enough to finance with credit. They compared a megafund which was all equity to two different leveraged ones, and via leverage managed to increase the number of drugs funded from 63 to 103, which is the real payoff for the rest of us.</p><p>Here is a <a href=""https://www.ted.com/talks/roger_stein_a_bold_new_way_to_fund_drug_research?language=en"">Ted Talk</a> from Roger Stein, and a <a href=""https://www.youtube.com/watch?v=xu86bYKVmRE"">TedX Talk</a> from Andrew Lo, if you prefer a video summary (though they are short on details). Aside from the original paper they have proposed the cancer fund in the short paper above, as well as how it might work for <a href=""http://www.rogermstein.com/wp-content/uploads/1-s2.0-S1359644613004030-main-1.pdf"">orphan diseases </a>and <a href=""https://poseidon01.ssrn.com/delivery.php?ID=908065002113090029027028015123023092002057081068083017073028117026123026111002073025031050122061114096018114066002082016081066000023046060084070116008088092074087041015095127064087013080009080125009105075120094086075022112007024007069083095126006022&EXT=pdf"">hedging medical insurance</a> risk.</p><p></p>",ryan_b,ryan_b,ryan_b,
GW8CE4EGFtN9qco8S,Where are the Benefits from Conversation?,where-are-the-benefits-from-conversation,https://www.lesswrong.com/posts/GW8CE4EGFtN9qco8S/where-are-the-benefits-from-conversation,2019-05-10T17:49:27.563Z,16,11,0,False,False,,"<p><em>(epistemic status: fairly speculative)</em></p><p>Recently, I&#x27;ve been thinking about where the main benefits of conversation lie, and I&#x27;ve come to some interesting early conclusions.</p><p>Most of the benefits of private conversations come from effects they have on the immediate participants. However, this doesn&#x27;t necessarily hold true for other forms of conversation. For instance, in a public debate, there is often little benefit to the debaters themselves, preparation aside [1], but often a benefit to the audience. On the other hand, in a public <a href=""https://www.lesswrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-resolving-disagreement"">double-crux</a>, the participants as well as the audience can benefit.</p><p>One area that I think this bears special interest for is that of online discussion. Online discussions are in some cases private, but because of the permanence of online conversations I feel they often have much more of a &quot;bystander benefit&quot; than conversations in person do - the arguments being offered are available not just to those who happened to be in the room at the time, but to many others who can view the archives.</p><p>For instance, I think most of the benefit of comments on LW doesn&#x27;t come from the immediate interaction between the commenter and the original poster, but rather from their discussion being read by others. One piece of evidence that helps support this is how frequently many more people vote on a particular comment than are active in the conversation itself - this indicates that the people active in the discussion are often a small fraction of those reading, and when you consider people who don&#x27;t vote, who &quot;lurk&quot;, or who don&#x27;t have accounts the number of readers probably increases further.</p><p>Real-time text conversation, like that offered by Slack, Discord, or IRC, is perhaps &quot;in between&quot; in-person and asynchronous online communication. However, I tend to think that similar assumptions hold, at least on public servers - there are many more &quot;lurkers&quot; who read but don&#x27;t necessarily comment than there are active discussion participants. On Slack or Discord, which allow emoji reacts, this is especially apparent - I frequently see reactions added to conversations well after they have concluded, indicating that people have read the conversation and reacted asynchronously. [2]</p><p>One potential counterargument to this theory is that, while many more people may interact with arguments or statements than those directly involved, those who are directly involved probably derive much more of an impact from interaction. I think that this is likely somewhat true, but even if you assume a large multiplier - let&#x27;s say 10x more value, which I think overstates things considerably - for actively participating vs. &quot;lurking&quot;, there are very easily many conversations online where more than 10x the number of people lurk or observe than actively participate.</p><p>One important result of this is that conversations that may not seem all that productive or informative to the immediate participants can actually be highly valuable to less active users. This can be especially true for &quot;101&quot; type discussions that might seem basic to the participants (likely more experienced people), but can provide helpful context to lurkers. For instance, I recall commentating on a live stream of a strategy game where the players were taking a while to get into the action. In order to fill space in my commentary, I started explaining basic aspects of the strategy and composition of this game.</p><p>Surprisingly, multiple people later commented or messaged me saying that the information I had been broadcasting to fill time was very helpful to them and they wished that more content like that was out there! The most vocal parts of my usual audience might have been more experienced and maybe even bored by these sorts of &quot;basics&quot;, but there were also people who hadn&#x27;t encountered much of this before, and so the &quot;101 content&quot; I was broadcasting to fill time ended being actually very useful - maybe more so than my usual &quot;higher level&quot; stuff!</p><p>The end result, in my view, is that one should keep in mind that, when having conversations in more permanent media, much of the benefit of the conversation is likely not with your direct interlocutor, but with others who may be watching or reading without commenting themselves, even after the fact. As a result of this, conversations - especially basic or &quot;101&quot; conversations - can be helpful and worth having even if they don&#x27;t necessarily feel that productive in the moment.</p><p></p><p></p><p></p><p>[1] I cannot recall any instance where a participant in a formal debate I am aware of changed their mind as an immediate result, even when they very clearly lost - though it&#x27;s of course possible that one could mull over the arguments for a while and eventually change positions.</p><p>[2] Interestingly, on a more active channel or server this effect is probably diminished somewhat, as with more and more messages being sent it becomes more difficult to view the entire backlog so people are less likely to have viewed a particular conversation. However, this is likely mitigated by an increased number of &quot;lurkers&quot; who see things in the moment.</p><p></p>",Davis_Kingsley,davis_kingsley,Davis_Kingsley,
EyX2krxzAjgh5YCW9,"Correspondence visualizations for different interpretations of ""probability""",correspondence-visualizations-for-different-interpretations,https://www.lesswrong.com/posts/EyX2krxzAjgh5YCW9/correspondence-visualizations-for-different-interpretations,2019-05-10T17:10:23.317Z,43,13,4,False,False,,"<p> (<em>Written for Arbital in 2016.</em>)</p><hr class=""dividerBlock""/><p><a href=""https://www.lesswrong.com/posts/BhSL973CGivhDJ4DH/interpretations-of-probability"">Recall</a> that there are three common interpretations of what it means to say that a coin has a 50% probability of landing heads:</p><ul><li><strong>The propensity interpretation:</strong> Some probabilities are just out there in the world. It&#x27;s a brute fact about coins that they come up heads half the time; we&#x27;ll call this the coin&#x27;s physical &quot;propensity towards heads.&quot; When we say the coin has a 50% probability of being heads, we&#x27;re talking directly about this propensity.</li><li><strong>The frequentist interpretation:</strong> When we say the coin has a 50% probability of being heads after this flip, we mean that there&#x27;s a class of events similar to this coin flip, and across that class, coins come up heads about half the time. That is, the <em>frequency</em> of the coin coming up heads is 50% inside the event class (which might be &quot;all other times this particular coin has been tossed&quot; or &quot;all times that a similar coin has been tossed&quot; etc).</li><li><strong>The subjective interpretation:</strong> Uncertainty is in the mind, not the environment. If I flip a coin and slap it against my wrist, it&#x27;s already landed either heads or tails. The fact that I don&#x27;t know whether it landed heads or tails is a fact about me, not a fact about the coin. The claim &quot;I think this coin is heads with probability 50%&quot; is an <em>expression of my own ignorance,</em> which means that I&#x27;d bet at 1 : 1 odds (or better) that the coin came up heads.</li></ul><p>One way to visualize the difference between these approaches is by visualizing what they say about when a model of the world should count as a good model. If a person&#x27;s model of the world is definite, then it&#x27;s easy enough to tell whether or not their model is good or bad: We just check what it says against the facts. For example, if a person&#x27;s model of the world says &quot;the tree is 3m tall&quot;, then this model is correct if (and only if) the tree is 3 meters tall.</p><br/><span><figure><img src=""http://i.imgur.com/5YriFTj.jpg"" class=""draft-image center"" style=""width:54%"" /></figure></span><br/><p>Definite claims in the model are called &quot;true&quot; when they correspond to reality, and &quot;false&quot; when they don&#x27;t. If you want to navigate using a map, you had better ensure that the lines drawn on the map correspond to the territory.</p><p>But how do you draw a correspondence between a map and a territory when the map is probabilistic? If your model says that a biased coin has a 70% chance of coming up heads, what&#x27;s the correspondence between your model and reality? If the coin is actually heads, was the model&#x27;s claim true? 70% true? What would that mean?</p><br/><span><figure><img src=""http://i.imgur.com/EjAto4b.jpg"" class=""draft-image center"" style=""width:52%"" /></figure></span><br/><p>The advocate of <strong>propensity</strong> theory says that it&#x27;s just a brute fact about the world that the world contains ontologically basic uncertainty. A model which says the coin is 70% likely to land heads is true if and only the actual physical propensity of the coin is 0.7 in favor of heads.</p><br/><span><figure><img src=""http://i.imgur.com/0vQamhR.jpg"" class=""draft-image center"" style=""width:56%"" /></figure></span><br/><p>This interpretation is useful when the laws of physics <em>do</em> say that there are multiple different observations you may make next (with different likelihoods), as is sometimes the case (e.g., in quantum physics). However, when the event is deterministic — e.g., when it&#x27;s a coin that has been tossed and slapped down and is already either heads or tails — then this view is largely regarded as foolish, and an example of the <a href=""https://arbital.com/p/mind_projection/"">mind projection fallacy</a>: The coin is just a coin, and has no special internal structure (nor special physical status) that makes it <em>fundamentally </em>contain a little 0.7 somewhere inside it. It&#x27;s already either heads or tails, and while it may <em>feel</em> like the coin is fundamentally uncertain, that&#x27;s a feature of your brain, not a feature of the coin.</p><p>How, then, should we draw a correspondence between a probabilistic map and a deterministic territory (in which the coin is already definitely either heads or tails?)</p><p>A <strong>frequentist</strong> draws a correspondence between a single probability-statement in the model, and multiple events in reality. If the map says &quot;that coin over there is 70% likely to be heads&quot;, and the actual territory contains 10 places where 10 maps say something similar, and in 7 of those 10 cases the coin is heads, then a frequentist says that the claim is true.</p><br/><span><figure><img src=""https://i.imgur.com/RaePEL7.png"" class=""draft-image "" style=""width:100%"" /></figure></span><br/><p>Thus, the frequentist preserves black-and-white correspondence: The model is either right or wrong, the 70% claim is either true or false. When the map says &quot;That coin is 30% likely to be tails,&quot; that (according to a frequentist) means &quot;look at all the cases similar to this case where my map says the coin is 30% likely to be tails; across all those places in the territory, 3/10ths of them have a tails-coin in them.&quot; That claim is definitive, given the set of &quot;similar cases.&quot;</p><p>By contrast, a <strong>subjectivist</strong> generalizes the idea of &quot;correctness&quot; to allow for shades of gray. They say, &quot;My uncertainty about the coin is a fact about <em>me,</em> not a fact about the coin; I don&#x27;t need to point to other &#x27;similar cases&#x27; in order to express uncertainty about <em>this</em> case. I know that the world right in front of me is either a heads-world or a tails-world, and I have a probability distribution that puts 70% probability on heads.&quot; They then draw a correspondence between their probability distribution and the world in front of them, and declare that the more probability their model assigns to the correct answer, the better their model is.</p><br/><span><figure><img src=""http://i.imgur.com/OWczeTe.jpg"" class=""draft-image center"" style=""width:55%"" /></figure></span><br/><p>If the world <em>is</em> a heads-world, and the probabilistic map assigned 70% probability to &quot;heads,&quot; then the subjectivist calls that map &quot;70% accurate.&quot; If, across all cases where their map says something has 70% probability, the territory is actually that way 7/10ths of the time, then the Bayesian calls the map &quot;well calibrated&quot;. They then seek methods to make their maps more accurate, and better calibrated. They don&#x27;t see a need to interpret probabilistic maps as making definitive claims; they&#x27;re happy to interpret them as making estimations that can be graded on a sliding scale of accuracy.</p><br/><h2>Debate</h2><p>In short, the frequentist interpretation tries to find a way to say the model is definitively &quot;true&quot; or &quot;false&quot; (by identifying a collection of similar events), whereas the subjectivist interpretation extends the notion of &quot;correctness&quot; to allow for shades of gray.</p><p>Frequentists sometimes object to the subjectivist interpretation, saying that frequentist correspondence is the only type that has any hope of being truly objective. Under Bayesian correspondence, who can say whether the map should say 70% or 75%, given that the probabilistic claim is not objectively true or false either way? They claim that these subjective assessments of &quot;partial accuracy&quot; may be intuitively satisfying, but they have no place in science. Scientific reports ought to be restricted to frequentist statements, which are definitively either true or false, in order to increase the objectivity of science.</p><p>Subjectivists reply that the frequentist approach is hardly objective, as it depends entirely on the choice of &quot;similar cases&quot;. In practice, people can (and do!) <a href=""https://en.wikipedia.org/wiki/Data_dredging"">abuse frequentist statistics</a> by choosing the class of similar cases that makes their result look as impressive as possible (a technique known as &quot;p-hacking&quot;). Furthermore, the manipulation of subjective probabilities is subject to the <a href=""https://arbital.com/p/bayes_rule/"">iron laws</a> of probability theory (which are the only way to avoid inconsistencies and pathologies when managing your uncertainty about the world), so it&#x27;s not like subjective probabilities are the wild west or something. Also, science has things to say about situations even when there isn&#x27;t a huge class of objective frequencies we can observe, and science should let us collect and analyze evidence even then.</p><p>For more on this debate, see <a href=""https://arbital.com/p/likelihood_vs_pvalue/"">Likelihood functions, p-values, and the replication crisis</a>.</p>",So8res,so8res,So8res,
oFdDponKRqo9uXrS5,Fear as fossil fuel,fear-as-fossil-fuel,https://www.lesswrong.com/posts/oFdDponKRqo9uXrS5/fear-as-fossil-fuel,2019-05-10T15:29:43.709Z,17,6,0,False,False,,"<html><head></head><body><p><em>Previous post: <a href=""https://www.lesswrong.com/posts/7GjmfXBcgzxn33FoZ/extraordinary-ethics-require-extraordinary-arguments"">Extraordinary ethics require extraordinary arguments</a></em></p>
<p><em>My blog entries are about a personal battle against depression and anxiety, from the point of view of someone who has been immersed in rationalist/LW ideas and culture for a few years now.</em></p>
<p>In a chat with my little brother two nights ago, I told him about my ""pain-strain theorem"" - physical strain can be used to alleviate mental pain, and mental strain can be used to alleviate physical pain. (Proof as exercise for the reader.)</p>
<p>I introduced the idea to tie up several narrative-of-our-lives style observations:</p>
<ul>
<li>I worked very hard on my schoolwork in elementary school. A large part of my motivation was that I had a severe chronic illness across my whole body. Keeping myself mentally occupied offered some sweet relief from the constant pain.</li>
<li>Our father also has a chronic illness that causes him a lot of pain. Before he developed this illness, he was a gregarious, vivacious twentysomething - a hard worker to be sure, but also a great jokester and eager team sport player. By the time we were being reared, however, he had pulled away from all of that and started sinking all of his time into his decently mentally challenging work.</li>
<li>Both my brother and I are diagnosed with mental illnesses. Both my brother and I find a solid, high intensity workout to be one of the best ways to escape the vicious thinking cycles we get locked into. For me, sometimes, the unthinking that comes with being 40 minutes into an elliptical workout is akin to sleep.</li>
</ul>
<p>My chronic illness thankfully began to relent as I became a teenager; my grades began to slip. My depression deepened; I isolated myself in academia; my grades returned to their high point. I went to community college and let the maw swallow me. I had very close to a 4.0 before transferring out of my community college to an Ivy League, when everything else in my life was terrible - no money, no career prospects, few friends and newly feralized social skills. Now that I'm here, with much better treated depression, almost complete remission of my first chronic illness, a paid research for the summer in my field, and a loving circle of friends and family, I'm at risk of failing one class and I'm almost certainly taking an incomplete in another.</p>
<p>Of course I'm telling myself a story to fit this data in. To an outside human my life is an n=1 narrative, but from the inside, it's an n=1000 series of vignettes, otherwise unconnected and terrifying in their ambiguity.</p>
<p>The current narrative, then: <strong>I only worked hard at school so I could ignore the other sources of pain in my life.</strong></p>
<p>This is not a sustainable way to live a life unless you make sure your ignorance of those other areas is a total eclipse. Even small improvements can become threatening - losing weight, learning to flirt. It's certainly no way to live a <em>good</em> life, even unsustainably.</p>
<p>When I say ""fear is a fossil fuel"", what I mean is that relying on it to provide your motivation to work hard indefinitely is not going to work. I do not deny that it is a <em>powerful</em> motivator. I mean that you should use it as little as possible to keep your life running the way you want it to. Fear of missing deadlines, fear of unemployment. Fear of failure in all its real, hard-to-ignore forms. Try to remove that from your arsenal and find something better to push you internally to do the same quality work or better than you have been doing. Find a sustainable emotional fuel like... Love. Compassion. Curiosity. Whatever speaks to you.</p>
<p>I remember over the last week seeing two interesting things. One, a study found that over half of its participants who had donated money to effective altruist causes five years ago did not do the same this year. Second, I read a post by Ozymandias on their blog Thing of Things about, among other things, <em>their</em> emotional fuel for donating. And it wasn't from the same scrupulosity that so many EAs fall into - another fossil fuel - it was from a genuine desire to <em>help people</em>. They explicitly said they don't think people who don't donate are ""bad"" people, citing the act/omission distinction as surprisingly important to living a sane modern life. Ozy is coming from an emotional core that is solar-level sustainable. Even if their family fell on hard times I think they would get back to donating.</p>
<p>The new narrative, then: <strong>I <em>used</em> to work hard in school only to keep my mind off things. Now I do it out of love and compassion for all the future human beings I can contribute to the well being of, by building and applying my skills.</strong></p>
<p>Many thanks for reading. 🙂</p>
</body></html>",aaq,aaq,aaq,
wXBC4PMePfjKFFHYJ,AI Forecasting online workshop,ai-forecasting-online-workshop,https://www.lesswrong.com/events/wXBC4PMePfjKFFHYJ/ai-forecasting-online-workshop,2019-05-10T14:54:14.560Z,30,6,0,False,False,,"<p><em>I&#x27;m looking for volunteers to join me for</em> <em><a href=""https://forms.gle/Q3uBVtezdgbJPc8z8"">a 1.5h online AI forecasting workshop</a></em>.</p><p><strong>Why am I doing this?</strong></p><p>I’m working under <u><a href=""http://existence.org/grants-database/"">a BERI grant</a></u> to use forecasting to support work on x-risk, together with Ben Goldhaber. We’re currently experimenting with a novel format for effective group forecasting. </p><p><strong>What does the workshop involve?</strong></p><p>We’ll gather outside views, make guesstimates, factorize the question into sub-questions, turn our uncertainty into probabilities, and so forth! </p><p>Much of the workshop will happen via silent collaboration in a Google doc, using the structured format that we’re developing specifically for this. </p><p><strong>Do I need prior experience with forecasting?</strong></p><p>No! We want to learn how well this format works for people with a wide range of backgrounds. </p><p><strong>What have past attendees said?</strong></p><p>We’ve had about ~20 people try this format over the last weeks, with a wide range of experience from superforecasters and AI safety researchers to amateur forecasters and undergraduates. </p><p>People have generally found it effective and fun, though we have several things we want to improve and are looking for more feedback and volunteers to keep iterating. </p><p><strong>When is it?</strong></p><p>Friday May 17, 11am Pacific time/7pm UK time. If you&#x27;re interested in joining but can&#x27;t make this time, let us know your other availabilities <a href=""https://forms.gle/tCjqJseD2EcXuRQCA"">here</a>.  </p><p><strong>How do I join?</strong></p><p>Sign-up via <a href=""https://forms.gle/uEouxPtUNE6gbPxS9"">this form</a>, and we&#x27;ll send you more details.</p>",jacobjacob,bird-concept,Bird Concept,
upP8PYgHfXgvgh3FF,Training human models is an unsolved problem,training-human-models-is-an-unsolved-problem,https://www.lesswrong.com/posts/upP8PYgHfXgvgh3FF/training-human-models-is-an-unsolved-problem,2019-05-10T07:17:26.916Z,13,6,3,False,False,,"<p><strong>I</strong></p><p>We can’t write down our precise values any more than we can write down the algorithm we use for judging whether an image contains a cat. If we want an AI to abide by human values, it&#x27;s going to have to acquire them without us writing them down. We usually think of this in terms of a process of value learning.</p><p>The easiest kind of value learning involves starting with some pre-written model of humans - <em>this</em> part for the beliefs, and <em>this</em> part for the values, and so on - and tuning its internal parameters until it does a good job on a corpus of training data. The problem is that we want this human model to have lots of nice properties, each of which makes it harder to find a model that will satisfy us.</p><p>There&#x27;s a tension between models that have clear values, and models that are psychologically realistic. The ideal value-haver is <em>homo economicus</em>, the sterile decision-theoretic agent. Consider what such a model must make of a training dataset that includes humans buying lottery tickets, and not wearing seatbelts, and being sold products by modern ad campaigns. The model has no leeway. It must assume that humans are behaving optimally, and therefore that there is some intrinsic value in lottery-tickets and seatbelt-free driving that should be preserved into the far future. As for the survival of humanity as a whole - well, if humans aren&#x27;t taking the optimal action to ensure it, it must not matter all that much.</p><p>The<em> homo economicus</em> model is too psychologically unrealistic to learn what we mean by human values. But if you allow that humans might be lazy, or biased, or incapable of getting a handle on the consequences of their actions, then you&#x27;re adding more and more degrees of freedom to your model. The more you allow for human action to not reflect their modeled values, the more underdetermined the modeled values are.</p><p>One of the various guarantees that people try to extract from value learning schemes is that if humans really did work according to your model, your value learning scheme would eventually make your model of the human converge to the human. <a href=""https://www.lesswrong.com/posts/ANupXf8XfZo2EJxGv/humans-can-be-assigned-any-values-whatsoever"">With even fairly tame models of human bias, you quickly lose this sort of guarantee</a> as the model becomes rich enough to learn unintended answers.</p><p><strong>II</strong></p><p>Let&#x27;s change gears and talk about neural networks. It&#x27;s not too big of a topic switch, though, because neural networks are a family of models that are often given way more free parameters than are necessary to solve the problem. This shows up as the problem of overfitting - if you do a better and better job of making the model correct on the training set, it actually does a worse job of generalizing, like a student who copies someone else&#x27;s answers rather than learning the material.</p><p>The interesting part is not so much that overfitting exists, it&#x27;s that there&#x27;s anything <em>other</em> than overfitting. As neural networks get trained, their ability to generalize becomes very good (as you might notice if you&#x27;ve been paying attention to their results over the last decade) before it turns around and gets worse due to overfitting. With proper training procedures you can stop training while the model is at its peak of generalization, at the low cost of setting aside part of your training data. Again, this is all despite solving an underdetermined problem.</p><p>There are also modifications to the training procedure, broadly called regularization, which trade away pure pursuit of correctness on the training data to try to nudge the model towards better generalization properties. Regularization often works by imposing a cost function that reduces the effective dimensionality of the model, which makes sense from an underdetermination = overfitting perspective, but it&#x27;s not just analogous to decreasing the number of nodes in a neural net; a regularized large network can do better after training than any non-regularized smaller network.</p><p>If you&#x27;re keeping track of the analogy to value learning at home, these ideas are like learning human values by starting with a big, complicated model and then training in a way that stops before you overfit, or uses some kind of cost function to push the model into the part of the solution space you want.</p><p>Sometimes you don&#x27;t have to directly optimize for the information you want. This is like the easy value learning scheme from part 1, where you optimize a human model but only care about the part labeled &quot;values.&quot; It&#x27;s also like word2vec, where the AI learns to predict a word from its neighbors, but you only care about the vector-space representation of words it developed along the way.</p><p>But rather than word2vec, a more interesting (not to mention topical) analogy might be to GPT-2. GPT-2 can answer homework questions. Even though it&#x27;s only been trained to predict the next word, if you prompt it with &quot;Q: What year was the Magna Carta signed? A: &quot;, the most likely continuation also happens to the the answer to your question. If you train a good model of human values as a byproduct of something else, maybe you can extract it by looking at input-output relationships rather than knowing which specific subset of neurons is in charge of modeling human values.</p><p><strong>III</strong></p><p>The root problem here is that you&#x27;re not just trying to model humans in a way that makes good predictions. You&#x27;re not even trying to model humans in a <em>simple</em> way that makes good predictions. You&#x27;re trying to model humans like humans model other humans: the <a href=""https://www.cs.tufts.edu/comp/150AAA/DennettTrueBelievers.pdf"">intentional stance</a>, in which &quot;beliefs,&quot; &quot;desires,&quot; etc sometimes show up as basic building blocks.</p><p>Even if I don&#x27;t think that typical regularization and avoidance of overfitting will solve the problem of learning human values, I think it would be interesting to experiment with. Maybe there is some sense in which the intentional stance is the &quot;obvious&quot; way of modeling humans, and regularization can encourage our model to do the &quot;obvious&quot; thing. But human definitions are fuzzy and messy, so there&#x27;s no chance the L2 norm and dropout are all we need to learn human values.</p><p>By the analogy to regularization, I mostly mean that you can apply a cost function in training to get your model to have some nice property beyond pure accuracy on the training set. Any cost function designed to encourage the artificial intentional stance is going to be a lot more complicated than the L2 norm. This raises the question of where you&#x27;re going to get such a cost function, and if it&#x27;s so complicated you have to get it via machine learning, how do you ground this recursion?</p><p>I used to have this cached thought that if we just found the &quot;right&quot; human model, we could train it for predictive accuracy and it would automatically learn human values. But I&#x27;ve started leaning more and more towards the idea that no such right model exists - that all models that are expressive enough to learn human values are also expressive enough to predict humans without doing it like humans do. If we want the artificial intentional stance, we might have to train the AI in a way that explicitly acknowledges and uses the fact that we want it to think of humans like humans think of humans.</p>",Charlie Steiner,charlie-steiner,Charlie Steiner,
ZqzWHc2sJMGsevTMY,Twin Cities SSC Meetup,twin-cities-ssc-meetup,https://www.lesswrong.com/events/ZqzWHc2sJMGsevTMY/twin-cities-ssc-meetup,2019-05-10T05:10:11.636Z,1,1,0,False,False,,"<p>We&#x27;ll meet in the clubroom at The Knoll Apartments near Dinkytown at 3PM. There will be a sign saying &quot;Slate Star Codex Meetup&quot; visible as you enter the building.</p><p>For this second meetup, we&#x27;re doing lightning talks! Talk about a thing for 5 minutes maximum, use easels and markers as desired. (Or listen to others do the same, if you&#x27;d prefer not to speak yourself.) We&#x27;ll also talk a little bit about longterm plans for the meetup group, and how to organize over the summer. </p><p>(We communicate via email as well - if you can&#x27;t come to this one but want to stay in the loop, shoot an email to <a href=""grahamsnumberisbig@gmail.com"">grahamsnumberisbig@gmail.com</a> and we&#x27;ll keep you updated.)</p>",RavenclawPrefect,drake-thomas,Drake Thomas,
Zq53H3SJJuig9Y9A4,Episode 4 of Tsuyoku Naritai! (the 'becoming stronger' podcast): TAPs,episode-4-of-tsuyoku-naritai-the-becoming-stronger-podcast,https://www.lesswrong.com/posts/Zq53H3SJJuig9Y9A4/episode-4-of-tsuyoku-naritai-the-becoming-stronger-podcast,2019-05-10T02:16:47.857Z,5,2,0,False,False,,"<html><head></head><body><p>Latest episode is up! In this episode, we experiment with forming habits, to hopefully be more effective people. Transcript in description/show notes.</p>
<p><a href=""https://www.youtube.com/watch?v=L1_erZGknEA&amp;feature=youtu.be"">https://www.youtube.com/watch?v=L1_erZGknEA&amp;feature=youtu.be</a></p>
<p><a href=""https://anchor.fm/tsuyokunaritai/episodes/Episode-4---TAPs-e402l1"">https://anchor.fm/tsuyokunaritai/episodes/Episode-4---TAPs-e402l1</a></p>
</body></html>",Senarin,senarin,Bae's Theorem,
EtHvKgkY7KpReDLyj,Tales From the American Medical System,tales-from-the-american-medical-system,https://www.lesswrong.com/posts/EtHvKgkY7KpReDLyj/tales-from-the-american-medical-system,2019-05-10T00:40:00.768Z,64,34,48,False,False,,"<p>Epistemic Status: Overheard in New York</p>
<p>I am walking and talking with my friend, a Type I Diabetic, when he receives a phone call from his doctor’s office.</p>
<p>As a Type I Diabetic, my friend needs insulin. The effects of not having insulin are very bad, and include death.</p>
<p>He has run out of refills on his prescription, and will run out of insulin on Saturday. He called about a week ago to attempt to remedy this situation and get refills.</p>
<p>That’s for background. This isn’t about the order of magnitude higher my friend’s <em>copay </em>is in America, compared to the entire retail price in Canada.</p>
<p>This is about my friend’s attempt to <em>get legal permission to continue buying</em> <em>life-saving medication for a lifelong condition with no known cure.</em></p>
<p></p>
<p>Because for some reason, in America you need legal permission to buy it, and you need to renew that periodically, despite there being chance of the need for said life-saving medicine going away.</p>
<p>I overheard the phone call from my friend’s end. The rest is filled in based on a combination of talking to him after, and extrapolation. He has reviewed this for accuracy.</p>
<p>The nurse tells my friend he needs to go see his doctor, because it has been seven months, and the doctor feels he should see his doctor every three.</p>
<p>My friend replies that he agrees he should see his doctor, and he has made an appointment in a few weeks when he has the time to do that.</p>
<p>The nurse says that he can’t get his prescription refilled until he sees the doctor.</p>
<p>My friend explains that he does not have the time to drop what he is doing and see the doctor the next day. That he is happy to see the doctor in a few weeks. But that until then, he requires insulin to live.</p>
<p>The nurse says that he can’t get his prescription refilled until he sees the doctor. That if he wants it earlier he can find another doctor.</p>
<p>My friend explains again that he does not have the time to see <em>any </em>doctor the next day, nor can one find a doctor on one day’s notice in reasonable fashion. And that he has already made an appointment, and needs insulin to live. And would like to speak with the doctor.</p>
<p>The nurse refuses to get the prescription filled. The nurse does not offer to let him speak to the doctor, and says that he can either wait, make an appointment for the next day, or find a new doctor.</p>
<p>My friend points out that without insulin, he will die. He asks if the nurse wants him to die. Or what the nurse suggests he do instead, rather than die.</p>
<p>This seems not to get through to the nurse, because my friend asks these questions several times. The nurse does not offer to refill the prescription, or let my friend talk to the doctor.</p>
<p>My friend says that if the doctor does not give him access to life saving medicine and instead leaves him to die, he will post about it on social media.</p>
<p>The nurse now decides, for the first time in the conversation, that my friend should perhaps talk to his doctor.</p>
<p>The doctor calls a few minutes later. The doctor is quite upset about this threat to post on social media about being denied access to purchase life saving medicine.</p>
<p>The doctor accuses my friend of having a gun to his head. My friend points out this is a rather interesting choice of metaphor. One could say that the doctor has a gun to his head, in the form of <em>denying him access to life saving medicine.</em> And that the two do not seem remotely comparable.</p>
<p>This seemed right to me, as I had used exactly the words ‘gun to your head’ when discussing the situation with my friend between the two phone calls.</p>
<p>I was not referring to the possibility of posts appearing on social media.</p>
<p>The doctor goes over details of my friend’s care. He wants my friend to come in.</p>
<p>My friend <em>agrees. </em>Points out he already made an appointment. That he <em>needs insulin to live.</em></p>
<p>The doctor asks, what if your sugars are high?</p>
<p>My friend points out that if this were the case, he would still need insulin to live.</p>
<p>The doctor keeps asking my friend to come see him. My friend keeps pointing out <em>he has already agreed to do this.</em></p>
<p>The doctor continues to admonish my friend for his blameworthy behavior of only doing all the things he’d been asked seven months ago to do, of only seeing <em>several other specialists for tests, </em>rather than <em>also </em>seeing this doctor every three months as a good obedient patient properly concerned for his own health would have done.</p>
<p>My friend points out that regardless of all that, <em>he would still need insulin to live.</em></p>
<p>The doctor then admonishes my friend for his terribly blameworthy behavior of <em>not being aware he had run out of refills. </em>Clearly, my friend should have tracked that. My friend points out that he doesn’t keep the prescription boxes, he keeps the vials. That few patients know, no matter what they in theory ‘should’ know, how many refills they have left on a reliable basis. And that he had realized all this a week ago and called his doctor, but was only now hearing that the refill wasn’t going to be forthcoming. Also, to paraphrase a bit, he asked the doctor: Why the hell is it going to run out at all, anyway? Are we expecting a cure <em>real soon now? </em>This need for insulin to live isn’t going to go away.</p>
<p>Having properly pointed out all the ways my friend was bad and should feel bad, the doctor now claims that the nurse was never told that the doctor wasn’t going to refill the prescription without my friend coming in first.</p>
<p>My friend points out that the nurse did in fact say exactly those words. That the prescription would not be refilled without a visit first.</p>
<p>What the doctor then claimed he said to the nurse was rather that the doctor did not <em>want </em>to refill the prescription. That the doctor would <em>prefer </em>that my friend come in.</p>
<p>This is standard implicit command deniability. Pure gaslighting. It’s the same as when a mafia boss says it would be great if a certain someone wasn’t seen round these parts some time soon. Or when the CEO remarks that people seem to be using too many vacation days. The nurse’s job depends on enforcing the implied order given by the doctor.</p>
<p>The doctor asks why my friend is being so <em>unreasonable. </em>My friend points out that he <em>started </em>with an <em>entirely and unquestionably</em> reasonable position of agreeing to come in at his next available time in exchange for <em>continued </em><em>access to life changing medicine. </em></p>
<p>That he’d only changed to what the doctor was characterizing as the <em>unreasonable </em>position of ‘if you deny me life saving medicine I might tell people that you did that’ when it was clear that until he threatened that, he was going to be denied life saving medicine.</p>
<p>If anything, the original position seems to me like it points out that the system has given someone the power to threaten to withhold life saving medicine, that they agree the person needs, in order to coerce the behavior they want from the other person. Which seems bad. But hey.</p>
<p>After a number of minutes of such admonishments, my friend having been sufficiently interrogated and admonished for his dastardly non-submissive, non-compliant role, and his unwillingness to drop everything in his life on a dime for no reason, the doctor offered to renew the prescription for long enough to make it to the appointment. Thus allowing my friend, for the low low <em>co-pay </em>price of ten times what it costs in Canada, to legally purchase the life-saving medicine he will need periodically for the rest of his life.</p>
<p>In some ways this was the good scenario. In the end, access to life saving medicine was in fact renewed. And this was what happened when my friend had, he insists, an <em>unusually</em> <em>conscientious </em>doctor, who is using his powers of coercion, via the threat of withholding lifesaving medicine, entirely to ensure the health of his patients, and who was in the office and capable of responding promptly.</p>
<p>Ladies and gentleman, the American medical system.</p>
<p> </p>",Zvi,zvi,Zvi,
BhSL973CGivhDJ4DH,"Interpretations of ""probability""",interpretations-of-probability,https://www.lesswrong.com/posts/BhSL973CGivhDJ4DH/interpretations-of-probability,2019-05-09T19:16:21.650Z,69,29,22,False,False,,"<p>(<em>Written for Arbital in 2016.</em>)</p><hr class=""dividerBlock""/><p>What does it <em>mean</em> to say that a flipped coin has a 50% probability of landing heads?</p><p>Historically, there are two popular types of answers to this question, the &quot;frequentist&quot; and &quot;<a href=""https://arbital.com/p/subjective_probability/"">subjective</a>&quot; (aka &quot;<a href=""https://arbital.com/p/bayes_reasoning/"">Bayesian</a>&quot;) answers, which give rise to <a href=""https://arbital.com/p/likelihood_vs_pvalue/"">radically different approaches to experimental statistics</a>. There is also a third &quot;propensity&quot; viewpoint which is largely discredited (assuming the coin is deterministic). Roughly, the three approaches answer the above question as follows:</p><ul><li><strong>The propensity interpretation:</strong> Some probabilities are just out there in the world. It&#x27;s a brute fact about coins that they come up heads half the time. When we flip a coin, it has a fundamental <em>propensity</em> of 0.5 for the coin to show heads. When we say the coin has a 50% probability of being heads, we&#x27;re talking directly about this propensity.</li><li><strong>The frequentist interpretation:</strong> When we say the coin has a 50% probability of being heads after this flip, we mean that there&#x27;s a class of events similar to this coin flip, and across that class, coins come up heads about half the time. That is, the <em>frequency</em> of the coin coming up heads is 50% inside the event class, which might be &quot;all other times this particular coin has been tossed&quot; or &quot;all times that a similar coin has been tossed&quot;, and so on.</li><li><strong>The subjective interpretation:</strong> Uncertainty is in the mind, not the environment. If I flip a coin and slap it against my wrist, it&#x27;s already landed either heads or tails. The fact that I don&#x27;t know whether it landed heads or tails is a fact about me, not a fact about the coin. The claim &quot;I think this coin is heads with probability 50%&quot; is an <em>expression of my own ignorance,</em> and 50% probability means that I&#x27;d bet at 1 : 1 odds (or better) that the coin came up heads.</li></ul><p> For a visualization of the differences between these three viewpoints, see <a href=""https://arbital.com/p/probability_interpretations_correspondence/"">Correspondence visualizations for different interpretations of &quot;probability&quot;</a>. For examples of the difference, see <a href=""https://arbital.com/p/probability_interpretations_examples/"">Probability interpretations: Examples</a>. See also the <a href=""http://plato.stanford.edu/entries/probability-interpret/"">Stanford Encyclopedia of Philosophy article on interpretations of probability</a>.</p><p>The propensity view is perhaps the most intuitive view, as for many people, it just feels like the coin is intrinsically random. However, this view is difficult to reconcile with the idea that once we&#x27;ve flipped the coin, it has already landed heads or tails. If the event in question is decided deterministically, the propensity view can be seen as an instance of the <a href=""https://arbital.com/p/mind_projection/"">mind projection fallacy</a>: When we mentally consider the coin flip, it feels 50% likely to be heads, so we find it very easy to imagine a <em>world</em> in which the coin is <em>fundamentally</em> 50%-heads-ish. But that feeling is actually a fact about <em>us,</em> not a fact about the coin; and the coin has no physical 0.5-heads-propensity hidden in there somewhere — it&#x27;s just a coin.</p><p>The other two interpretations are both self-consistent, and give rise to pragmatically different statistical techniques, and there has been much debate as to which is preferable. The subjective interpretation is more generally applicable, as it allows one to assign probabilities (interpreted as betting odds) to one-off events.</p><p></p><h2>Frequentism vs subjectivism</h2><p>As an example of the difference between frequentism and subjectivism, consider the question: &quot;What is the probability that Hillary Clinton will win the 2016 US presidential election?&quot;, as analyzed in the summer of 2016.</p><p>A stereotypical (straw) frequentist would say, &quot;The 2016 presidential election only happens once. We can&#x27;t <em>observe</em> a frequency with which Clinton wins presidential elections. So we can&#x27;t do any statistics or assign any probabilities here.&quot;</p><p>A stereotypical subjectivist would say: &quot;Well, prediction markets tend to be pretty well-calibrated about this sort of thing, in the sense that when prediction markets assign 20% probability to an event, it happens around 1 time in 5. And the prediction markets are currently betting on Hillary at about 3 : 1 odds. Thus, I&#x27;m comfortable saying she has about a 75% chance of winning. If someone offered me 20 : 1 odds <em>against</em> Clinton — they get $1 if she loses, I get $20 if she wins — then I&#x27;d take the bet. I suppose you could refuse to take that bet on the grounds that you Just Can&#x27;t Talk About Probabilities of One-off Events, but then you&#x27;d be pointlessly passing up a really good bet.&quot;</p><p>A stereotypical (non-straw) frequentist would reply: &quot;I&#x27;d take that bet too, of course. But my taking that bet <em>is not based on rigorous epistemology,</em> and we shouldn&#x27;t allow that sort of thinking in experimental science and other important venues. You can do subjective reasoning about probabilities when making bets, but we should exclude subjective reasoning in our scientific journals, and that&#x27;s what frequentist statistics is designed for. Your paper should not conclude &quot;and therefore, having observed thus-and-such data about carbon dioxide levels, I&#x27;d personally bet at 9 : 1 odds that anthropogenic global warming is real,&quot; because you can&#x27;t build scientific consensus on opinions.&quot;</p><p>...and then it starts getting complicated. The subjectivist responds &quot;First of all, I agree you shouldn&#x27;t put posterior odds into papers, and second of all, it&#x27;s not like your method is truly objective — the choice of &quot;similar events&quot; is arbitrary, abusable, and has given rise to <a href=""https://en.wikipedia.org/wiki/Data_dredging"">p-hacking</a> and the <a href=""https://en.wikipedia.org/wiki/Replication_crisis"">replication crisis</a>.&quot; The frequentists say &quot;well your choice of prior is even more subjective, and I&#x27;d like to see you do better in an environment where peer pressure pushes people to abuse statistics and exaggerate their results,&quot; and then <a href=""https://arbital.com/p/likelihood_vs_pvalue/"">down the rabbit hole we go</a>.</p><p>The subjectivist interpretation of probability is common among artificial intelligence researchers (who often design computer systems that manipulate subjective probability distributions), Wall Street traders (who need to be able to make bets even in relatively unique situations), and common intuition (where people feel like they can say there&#x27;s a 30% chance of rain tomorrow without worrying about the fact that tomorrow only happens once). Nevertheless, the frequentist interpretation is commonly taught in introductory statistics classes, and is the gold standard for most scientific journals.</p><p>A common frequentist stance is that it is virtuous to have a large toolbox of statistical tools at your disposal. Subjectivist tools have their place in that toolbox, but they don&#x27;t deserve any particular primacy (and they aren&#x27;t generally accepted when it comes time to publish in a scientific journal).</p><p>An aggressive subjectivist stance is that frequentists have invented some interesting tools, and many of them are useful, but that refusing to consider subjective probabilities is toxic. Frequentist statistics were invented in a (failed) attempt to keep subjectivity out of science in a time before humanity really understood the laws of probability theory. Now we have <a href=""https://arbital.com/p/bayes_rule/"">theorems</a> about how to manage subjective probabilities correctly, and how to factor personal beliefs out from the objective evidence provided by the data, and if you ignore these theorems you&#x27;ll get in trouble. The frequentist interpretation is broken, and that&#x27;s why science has p-hacking and a replication crisis even as all the wall-street traders and AI scientists use the Bayesian interpretation. This &quot;let&#x27;s compromise and agree that everyone&#x27;s viewpoint is valid&quot; thing is all well and good, but how much worse do things need to get before we say &quot;oops&quot; and start acknowledging the subjective probability interpretation across all fields of science?</p><p>The most common stance among scientists and researchers is much more agnostic, along the lines of &quot;use whatever statistical techniques work best at the time, and use frequentist techniques when publishing in journals because that&#x27;s what everyone&#x27;s been doing for decades upon decades upon decades, and that&#x27;s what everyone&#x27;s expecting.&quot;</p><p>See also <a href=""https://arbital.com/p/subjective_probability/"">Subjective probability</a> and <a href=""https://arbital.com/p/likelihood_vs_pvalue/"">Likelihood functions, p-values, and the replication crisis</a>.</p><p></p><h2>Which interpretation is most useful?</h2><p>Probably the subjective interpretation, because it subsumes the propensity and frequentist interpretations as special cases, while being more flexible than both.</p><p>When the frequentist &quot;similar event&quot; class is clear, the subjectivist can take those frequencies (often called base rates in this context) into account. But unlike the frequentist, she can also <a href=""https://arbital.com/p/bayes_rule/"">combine those base rates with other evidence that she&#x27;s seen</a>, and assign probabilities to one-off events, and make money in prediction markets and/or stock markets (when she knows something that the market doesn&#x27;t).</p><p>When the laws of physics actually do &quot;contain uncertainty&quot;, such as when they say that there are multiple different observations you might make next with differing likelihoods (as the Schrodinger equation often will), a subjectivist can combine her propensity-style uncertainty with her personal uncertainty in order to generate her aggregate subjective probabilities. But unlike a propensity theorist, she&#x27;s not forced to think that <em>all</em> uncertainty is physical uncertainty: She can act like a propensity theorist with respect to Schrodinger-equation-induced uncertainty, while still believing that her uncertainty about a coin that has already been flipped and slapped against her wrist is in her head, rather than in the coin.</p><p>This fully general stance is consistent with the belief that frequentist tools are useful for answering frequentist questions: The fact that you can <em>personally</em> assign probabilities to one-off events (and, e.g., evaluate how good a certain trade is on a prediction market or a stock market) does not mean that tools labeled &quot;Bayesian&quot; are always better than tools labeled &quot;frequentist&quot;. Whatever interpretation of &quot;probability&quot; you use, you&#x27;re encouraged to use whatever statistical tool works best for you at any given time, regardless of what &quot;camp&quot; the tool comes from. Don&#x27;t let the fact that you think it&#x27;s possible to assign probabilities to one-off events prevent you from using useful frequentist tools! </p>",So8res,so8res,So8res,
yAKpKKynEzhtcS77j,What Botswana Can Teach Us About Political Stability,what-botswana-can-teach-us-about-political-stability,https://www.lesswrong.com/posts/yAKpKKynEzhtcS77j/what-botswana-can-teach-us-about-political-stability,2019-05-09T18:30:04.588Z,40,13,4,False,False,,"<figure class=""image""><img src=""https://cdn-images-1.medium.com/max/1024/1*gbzrVoG53JfsB9_ngLbkdw.jpeg""></figure><p>US Army Africa/Botswana</p><p><i>From my </i><a href=""https://palladiummag.com/2019/05/09/what-botswana-can-teach-us-about-political-stability/""><i>article</i></a><i> first published on Palladium Magazine.</i></p><p>It is hard to find a clearer outlier among developing countries than <a href=""https://en.wikipedia.org/wiki/Botswana"">Botswana</a>, a landlocked African country where 40% of government revenue comes from <a href=""https://en.wikipedia.org/wiki/Resource_curse"">diamond mining</a> and a quarter of adults are HIV positive. Everything taught by a <a href=""https://en.wikipedia.org/wiki/Development_economics"">development economics</a> department would suggest the country is set up for failure. But well-executed succession between presidents, and the resulting stability and good government, has meant success&nbsp;instead.</p><p>Botswana is possibly the nicest place in Africa — it is quieter and more stable than, say, <a href=""https://en.wikipedia.org/wiki/Greek_military_junta_of_1967%E2%80%931974#Coup_d'%C3%A9tat_of_21_April"">Greece</a>. In the entire period since independence, Botswana has not suffered devastating civil wars like those in the Congo or Mozambique, coups such as in Burkina Faso, or ethnic violence and expropriation as seen in Rwanda and Zimbabwe.</p><p>The country’s living standards <a href=""https://en.wikipedia.org/wiki/List_of_countries_by_Human_Development_Index#Medium_human_development"">are comparable</a> to Turkey, Mexico, and South Africa. It has also been Sub-Saharan Africa’s fastest growing economy for most of the last half&nbsp;century.</p><p>The crucial variable is a sound government making well-informed, long-term choices. A low population density paired with abundant natural resources provides a reasonable standard of living even in the absence of administrative genius or favorable conditions, so long as governance provides stability. Political instability can impede development of physical infrastructure and the business environment, transforming good fundamentals into a bad outcome. See, for example, <a href=""https://palladiummag.com/2019/01/19/authoritarian-development-has-rebuilt-kazakhstan-into-a-eurasian-power/"">Kazakhstan</a> compared to <a href=""https://palladiummag.com/2019/03/06/venezuela-an-up-close-look-at-a-nation-in-free-fall/"">Venezuela</a>.</p><p>Unfortunately, there are many examples of countries that have tried and failed to achieve good governance in the often chaotic post-colonial context. These countries followed Western advice as closely as they could, drafting legally impeccable constitutions and recruiting <a href=""https://answersafrica.com/latest-10-most-educated-african-presidents-no-1-tops-the-world-list.html"">well-educated</a> statesmen, but the results have been mixed at best. Botswana’s positive outlier example raises the question of how it has done so&nbsp;well.</p><p><i>Read the rest&nbsp;</i><a href=""https://palladiummag.com/2019/05/09/what-botswana-can-teach-us-about-political-stability/""><i>here</i></a><i>.</i></p><p><i>Read more from Samo Burja </i><a href=""http://samoburja.com/essays""><i><u>here.</u></i></a></p><figure class=""image""><img src=""https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=532a695ae388""></figure>",Samo Burja,samo-burja,Samo Burja,
HxkvP4AbY8PYaDErM,Kissing Scars,kissing-scars,https://www.lesswrong.com/posts/HxkvP4AbY8PYaDErM/kissing-scars,2019-05-09T16:00:59.596Z,39,24,1,False,False,,"<p>Last year August 6th, I got in a horrible drone accident that destroyed the lens and iris in my left eye and left a scar running down my eye. For a couple months I could barely read, my working memory was horrible, energy levels were shot, and I was in so much pain, especially after surgeries. </p><p>Then a sweet girl kissed my scars. </p><p>In one simple gesture, it was communicated </p><blockquote>&quot;What you&#x27;re going through really sucks and I want to make it better&quot;</blockquote><hr class=""dividerBlock""/><p>Today I realized two people upvoted my birthday comment in an obituary post to a lost friend. That post was almost a year ago, and the comment was a month ago. </p><p>Whoever you two are, thank you for kissing my scars.</p>",elriggs,elriggs,Logan Riggs,
MPKF27kgREzkSiCzu,"How many galaxies could we reach traveling at 0.5c, 0.8c, and 0.99c?",how-many-galaxies-could-we-reach-traveling-at-0-5c-0-8c-and,https://www.lesswrong.com/posts/MPKF27kgREzkSiCzu/how-many-galaxies-could-we-reach-traveling-at-0-5c-0-8c-and,2019-05-08T23:39:16.337Z,6,1,0,False,True,,"<p>The expansion of the universe means that even travelling at the speed of light, over time an increasing number of galaxies will be beyond our reach, hence the concept of &quot;reachable universe.&quot; Right now, how many galaxies could we potentially reach if we travelled at significant fractions of the speed of light? And how quickly are these galaxies moving beyond our reach?</p>",Ruby,ruby,Ruby,
bMrgJC5ReTNAkM76k,How many humans could potentially live on Earth over its entire future? ,how-many-humans-could-potentially-live-on-earth-over-its,https://www.lesswrong.com/posts/bMrgJC5ReTNAkM76k/how-many-humans-could-potentially-live-on-earth-over-its,2019-05-08T23:33:21.368Z,9,3,0,False,True,,<p>(Or person-years if we assume greatly extended life). How many years could the Earth be habitable for?</p><p></p>,Ruby,ruby,Ruby,
8WCPDk3RJ6SLP2ZuR,"Claims & Assumptions made in Eternity in Six Hours
",claims-and-assumptions-made-in-eternity-in-six-hours,https://www.lesswrong.com/posts/8WCPDk3RJ6SLP2ZuR/claims-and-assumptions-made-in-eternity-in-six-hours,2019-05-08T23:11:30.307Z,50,16,7,False,False,,"<p>This is a list of claims and assumptions made in the FHI paper, <em><a href=""https://www.fhi.ox.ac.uk/publications/armstrong-s-sandberg-a-2013-eternity-in-six-hours-intergalactic-spreading-of-intelligent-life-and-sharpening-the-fermi-paradox-acta-astronautica-89-1-13/"">Eternity in Six Hours</a></em>. It is not exhaustive. I collected this list as part of my attempt to answer the questions:</p><ul><li><a href=""https://www.lesswrong.com/posts/k774aKEogcCugmKPY/which-parts-of-the-paper-eternity-in-six-hours-are-iffy"">Which parts of the paper Eternity in Six Hours are iffy?</a></li><li><a href=""https://www.lesswrong.com/posts/gYRsmb9dPreur626t/what-are-the-claims-arguments-made-in-eternity-in-six-hours"">What are the claims/arguments made in Eternity in Six Hours?</a></li></ul><p>Since my interest is writing this is on the feasibility of intergalactic colonization, I&#x27;ve neglected claims in the paper about the Fermi paradox.</p><h2>Abstract</h2><p>The Fermi paradox is the discrepancy between the strong likelihood of alien intelligent life emerging (under a wide variety of assumptions), and the absence of any visible evidence for such emergence. In this paper, we extend the Fermi paradox to not only life in this galaxy, but to other galaxies as well. <strong>We do this by demonstrating that traveling between galaxies – indeed even launching a colonisation project for the entire reachable universe – is a relatively simple task for a star-spanning civilization, requiring modest amounts of energy and resources. We start by demonstrating that humanity itself could likely accomplish such a colonisation project in the foreseeable future, should we want to, </strong>and then demonstrate that there are millions of galaxies that could have reached us by now, using similar methods. This results in a considerable sharpening of the Fermi paradox. [emphasis added]</p><p></p><h2>Claims and Assumptions (not exhaustive)</h2><ul><li>Self-replicating probes for colonizations could be launched to a fraction of lightspeed using fixed launch systems such as coilguns or quenchguns as (opposed to rockets).</li><li>Only six hours of the sun&#x27;s energy (3.8x10^26W) are required to commence the colonization of the entire universe.</li><ul><li>A future human civilization could easily aspire to this amount of energy.</li></ul><li>Since the procedure is conjunction of designs and yet each of the requirements have multiple pathways to implementation, the whole construction is robust.</li><li>Humans have generally been quite successful at copying or co-oping nature. We can assume that anything done in the natural world can be done under human control, e.g. self-replicators and AI.</li><li>Any task which can be performed can be automated.</li><li>It would be ruinously costly to send over a large colonization fleet, and is much more efficient to send over a small payload which builds what is required in situ, i.e. von Neumann probes.</li><li>Data storage will not be much an issue.</li><ul><li>Example: can fit all the world&#x27;s data and upload of everyone in Britain in gram of crystal.</li></ul><li>500 tons is a reasonable upper bound for the size of a self-replicating probe.</li><li>A replicator with mass of 30 grams would not be unreasonable.</li><li>Antimatter annihilation, nuclear fusion, and nuclear fission are all possible rocket types to be used for deceleration.</li><ul><li>Processes like magnetic sail, gravitational assist, and &quot;Bussard ramjet&quot; are conceivable and possible, but to be conservative are not relied on.</li></ul><li>Nuclear fission reactors could be made 90% efficient. Current reactor designs could reach efficiencies of over 50% of the theoretical maximum.</li><ul><li>Any fall-off in fission efficiency results in a dramatic decrease in deceleration potential.</li><li>They ignore deceleration caused by the expansion of the universe.</li></ul><li>Assume probe is of sturdy enough construction to survive a grenade blast (800kJ).</li><li>Redundancy required for a probe to make it to a galaxy is given by R = exp(dAρ ) where is d is distance to be travelled (in comoving coordinate), A is cross-section of the probe, and ρ is the density of dangerous particles.</li><ul><li>Dangerous particle size given as a function of speed of the probe by equation in the paper.</li><li>From slower probes (80%c and 50%c) redundancy required is low, two probes are enough to ensure one survives.</li><li>If you have a 500T replicator, you have more cross-section but also better ability to shield.</li><li>Density of matter in space is much higher in interstellar space compared to intergalactic space. Might not be possible to launch universe-colonization directly from our sun.</li></ul><li>Dyson spheres are very doable. Assumed to have 1/3 efficiencies over sun&#x27;s output (3.8x10^26)</li><ul><li>We could disassemble Mercury and turn it into a Dyson sphere.</li></ul><li>Launch systems could achieve energy efficiency of 50%.</li><li>Apart from risks of collision, getting to the further galaxies is as easy as getting to the closest, the only difference is a longer wait between the acceleration and deceleration phases.</li><li>Travelling at 50c% there are 116 million galaxies reachable; at 80% there are 762 million galaxies reachable; at 99%c, you get 4.13 billion galaxies.</li><ul><li>For reference, there are 100 to 400 billion stars in the Milky Way, and from a quick check it might be reasonable to assume 100 billion is the average galaxy.</li><ul><li>The ability to colonize the universe as opposed to just the Milky Way is the difference between ~10^8 stars and ~10^16 or ~10^17 starts. A factor of 100 million.</li></ul></ul><li>On a cosmic scale, the cost, time and energy needed to commence a colonization of the entire reachable universe are entirely trivial for an advanced human-like civilization.</li><li>Energy costs could be cut by a factor of hundred or thousand by aiming for clusters or superclusters [of galaxies] and spreading out from there.</li></ul>",Ruby,ruby,Ruby,
dYN53QC6h8Y9Htiq6,Dallas SSC Meetup #2,dallas-ssc-meetup-2,https://www.lesswrong.com/events/dYN53QC6h8Y9Htiq6/dallas-ssc-meetup-2,2019-05-08T17:31:37.291Z,3,2,1,False,False,,"<p>Dallas SSC welcomes everyone to our second ever meetup.</p><p>We&#x27;re still very much getting to know each other, so come and make new friends with like-minded individuals in a low-pressure environment.</p><p>We will be meeting at Magic Cup Cafe in Richardson, TX. Saturday, May 18 at 6-8 pm. Email <a href=""tayfie@pm.me"">tayfie@pm.me</a> with additional questions and for update announcements.</p><br/><p>901 N Jupiter Rd<br/>Ste 150<br/>Richardson, TX 75081</p>",tayfie,tayfie,tayfie,
nz2BaA37pa8Fkx7fL,Raleigh SSC/LW/EA Meetup - Meet MealSquares People,raleigh-ssc-lw-ea-meetup-meet-mealsquares-people,https://www.lesswrong.com/events/nz2BaA37pa8Fkx7fL/raleigh-ssc-lw-ea-meetup-meet-mealsquares-people,2019-05-08T00:01:36.639Z,12,3,0,False,False,,"<html><head></head><body><p>Romeo Stevens and I (both cofounders of MealSquares, a SSC sidebar advertiser) are visiting Raleigh/Durham and we're interested in meeting local people.  Romeo is interested in contemplative practice and philosophy of science.  John once won $2000 in the AI Alignment Prize and was the first long-term guest of the EA (Athena) Hotel.  Both of us post heavily here on LW and on the EA Forum and are well connected in the Bay Area EA and rationalist communities.  We'll be at the coffee shop called ""42 &amp; Lawrence"", located at 134 E Martin St in Raleigh, this Sunday, May 12 at 2 PM.  John will be wearing an Effective Altruism t-shirt.  Romeo will be wearing a Qualia Research Institute t-shirt.  We're not sure who else will show up, but we'll hang out there for at least an hour.  If the weather is nice we might go to the park across the street.</p>
</body></html>",John_Maxwell_IV,john_maxwell,John_Maxwell,
S9LBK3dK8hZrLumLj,What speeds do you need to achieve to colonize the Milky Way?,what-speeds-do-you-need-to-achieve-to-colonize-the-milky-way,https://www.lesswrong.com/posts/S9LBK3dK8hZrLumLj/what-speeds-do-you-need-to-achieve-to-colonize-the-milky-way,2019-05-07T23:46:09.214Z,6,1,1,False,True,,,Ruby,ruby,Ruby,
kkQdyMavrWgZuj7eW,"Could a superintelligent AI colonize the galaxy/universe? If not, why not?",could-a-superintelligent-ai-colonize-the-galaxy-universe-if,https://www.lesswrong.com/posts/kkQdyMavrWgZuj7eW/could-a-superintelligent-ai-colonize-the-galaxy-universe-if,2019-05-07T21:33:20.288Z,7,2,0,False,True,,"<p>Arguments for the value of the far future (in turn used as arguments for reducing x-risk) assume that we will colonize the stars, hence it&#x27;s interesting to know whether we should think that really is possible.</p><p>We know that there are <a href=""https://www.fhi.ox.ac.uk/will-we-eventually-be-able-to-colonize-other-stars-notes-from-a-preliminary-review/"">various challenges</a> to be overcome to achieve space colonization, but are any of them so hard that we don&#x27;t think a superintelligent AI could achieve them? This is scenario worth asking about since one of the main ways we overcome near-term x-risk is through the creation of a human-aligned AI which would help us colonize the stars if that&#x27;s what we really want. </p>",Ruby,ruby,Ruby,
BQBpSMnqTqXGMAJRE,Is it definitely the case that we can colonize Mars if we really wanted to? Is it reasonable to believe that this is technically feasible for a reasonably advanced civilization? ,is-it-definitely-the-case-that-we-can-colonize-mars-if-we,https://www.lesswrong.com/posts/BQBpSMnqTqXGMAJRE/is-it-definitely-the-case-that-we-can-colonize-mars-if-we,2019-05-07T20:08:32.105Z,9,3,0,False,True,,"<p>Question phrased to say that I&#x27;m less interested in reasons why humanity might not colonize Mars in the short-term due to lack of interest, politics, or near-term economics. Assume that humanity really wanted to and would put billions or trillions of dollars towards this and decades (centuries) of time. Any real reason we couldn&#x27;t do it?</p>",Ruby,ruby,Ruby,
amLsAeYAqKpY7Aa6D,Why is it valuable to know whether space colonization is feasible?,why-is-it-valuable-to-know-whether-space-colonization-is,https://www.lesswrong.com/posts/amLsAeYAqKpY7Aa6D/why-is-it-valuable-to-know-whether-space-colonization-is,2019-05-07T19:58:59.570Z,6,1,4,False,True,,,Ruby,ruby,Ruby,
gYRsmb9dPreur626t,What are the claims/arguments made in Eternity in Six Hours?,what-are-the-claims-arguments-made-in-eternity-in-six-hours,https://www.lesswrong.com/posts/gYRsmb9dPreur626t/what-are-the-claims-arguments-made-in-eternity-in-six-hours,2019-05-07T19:54:32.061Z,6,1,1,False,True,,"<p>The FHI paper, <a href=""https://www.fhi.ox.ac.uk/publications/armstrong-s-sandberg-a-2013-eternity-in-six-hours-intergalactic-spreading-of-intelligent-life-and-sharpening-the-fermi-paradox-acta-astronautica-89-1-13/"">Eternity in Six Hours</a>, asserts that traveling between galaxies and colonizing them  is a relatively simple task for a star-spanning civilization. The paper even asserts that humanity itself could accomplish this in the foreseeable future. Because of this, the paper says the Fermi Paradox is even &quot;sharper&quot; than it was already. (This paper was published five years before another FHI, <em><a href=""https://arxiv.org/abs/1806.02404"">Dissolving the Fermi Paradox</a>, </em>which shares one of the same authors.)</p><p>Yet even if we consider the Fermi Paradox resolved, it&#x27;s still valuable to know what&#x27;s possible to accomplish with regards to space colonization. Arguments for the astronomical value of the far future assume space colonization is possible, hence we want to evaluate arguments for why this is true.</p>",Ruby,ruby,Ruby,
FjjYGCNXEhhcirp36,Crypto quant trading: Naive Bayes,crypto-quant-trading-naive-bayes,https://www.lesswrong.com/posts/FjjYGCNXEhhcirp36/crypto-quant-trading-naive-bayes,2019-05-07T19:29:40.507Z,33,9,13,False,False,,"<p>Previous post: <a href=""https://www.lesswrong.com/posts/a8MXx3fykQwHnpS7R/crypto-quant-trading-intro"">Crypto quant trading: Intro</a></p>
<p>I didn't get requests for any specific subject from the last post, so I'm going in the direction that I find interesting and I hope the community will find interesting as well. Let's do <a href=""https://en.wikipedia.org/wiki/Naive_Bayes_classifier"">Naive Bayes</a>! You can download the <a href=""https://github.com/STOpandthink/temple-capital"">code</a> and follow along.</p>
<p>Just as a reminder, here's Bayes' theorem: <code>P(H|f) = P(H) * P(f|H) / P(f)</code>. (I'm using <code>f</code> for ""feature"".)<br>
Here's conditional probability: <code>P(A|B) = P(A,B) / P(B)</code></p>
<p>Disclaimer: I was learning Naive Bayes as I was writing this post, so please double check the math. I'm not using 3rd party libraries so I can fully understand how it all works. In fact, I'll start by describing a thing that tripped me up for a bit.</p>
<h2>What not to do</h2>
<p>My original understanding was: Naive Bayes basically allows us to update on various features without concerning ourselves with how all of them interact with each other; we're just assuming they are independent. So we can just apply it iteratively like so:</p>
<pre><code>P(H) = prior
P(H) = P(H) * P(f1|H) / P(f1)
P(H) = P(H) * P(f2|H) / P(f2)
</code></pre>
<p>You can see how that fails if we keep updating <code>P(H)</code> upwards over and over again, until it goes above 1. I did math the hard way to figure out where I went wrong. If we have two features:</p>
<pre><code>P(H|f1,f2) = P(H,f1,f2) / P(f1,f2)
= P(f1|H,f2) * P(H,f2) / P(f1,f2)
= P(f1|H,f2) * P(f2|H) * P(H) / P(f1,f2)
= P(H) * P(f1|H,f2) * P(f2|H) / (P(f1|f2) * P(f2))
Then because we assume that all features are independent:
= P(H) * P(f1|H) * P(f2|H) / (P(f1) * P(f2))
</code></pre>
<p>Looks like what I wrote above. Where's the mistake?
Well, Naive Bayes actually says that all features are independent, <strong>conditional</strong> on H. So <code>P(f1|H,f2) = P(f1|H)</code> because we're conditioning on H, but <code>P(f1|f2) != P(f1)</code> because there's no <code>H</code> in the condition.</p>
<p>One intuitive example of this is a spam filter. Let's say all spam emails (<code>H</code> = email is spam) have random words. So <code>P(word1|word2,H)=P(word1|H)</code>, i.e. if we know email is spam, then the presence of any given word doesn't tell us anything about the probably of seeing another word. Whereas, <code>P(word1|word2) != P(word1)</code> since there are a lot of non-spam emails, where word appearances are very much correlated. (H/t to Satvik for this clarification.)</p>
<p>This is actually good news! Assuming <code>P(f1|f2) = P(f1)</code> for all features would be a pretty big assumption. But <code>P(f1|H,f2) = P(f1|H)</code>, while often not exactly true, is a bit less of stretch and, in practice, works pretty well. (This is called <a href=""https://en.wikipedia.org/wiki/Conditional_independence"">conditional independence</a>.)</p>
<p>Also, in practice, you actually don't have to compute the denominator anyway. What you want is the relative weight you should assign to all the hypotheses under consideration. And as long as they are mutually exclusive and collectively exhaustive, you can just normalize your probabilities at the end. So we end up with:</p>
<pre><code>for each H in HS:
    P(H) = prior
    P(H) = P(H) * P(f1|H)
    P(H) = P(H) * P(f2|H)
    etc...
normalize all P(H)'s
</code></pre>
<p>Which is close to what we had originally, but less wrong.... Okay, now that we know what not to do, let's get on with the good stuff.</p>
<h2>One feature</h2>
<p>For now let's consider one very straight forward hypothesis: the closing price of the next day will be higher than today's (as a shorthand, we'll call tomorrow's bar an ""up bar"" if that's the case). And let's consider one very simple feature: was the current day's bar up or down?</p>
<p><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/ycc0aosphk2tc60bunxt"" alt=""""><br>
<img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/z5vbfheynqdjl6r0qyr7"" alt=""""></p>
<p>Note that even though we're graphing only 2017 onwards, we're updating on all the data prior to that too. Since 2016 and 2017 have been so bullish, we've basically learned to expect up bars under either condition. I guess HODLers were right after all.</p>
<h2>Using more recent data</h2>
<p>So, this approach is a bit suboptimal if we want to try to catch short term moves (like entire 2018). Instead, let's try to look at most recent data. (Question: does anyone know of Bayes-like method that weighs recent data more?)</p>
<p>We slightly modify our algorithm to only look at and update on the past N days of data.</p>
<p><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/urlxpq0ylrtay40yxsut"" alt="""">
<img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/xrlrzklbybihe78yaw75"" alt=""""></p>
<p>It's interesting to see that it still takes a while for the algorithm to catch up to the fact that the bull market is over. Just in time to not totally get crushed by the November 2018 drop.<br>
In the notebook I'm also looking at shorter terms. There are some interesting results there, but I'm not going to post all the pictures here, since that would take too long.</p>
<h2>Additive smoothing</h2>
<p>As we look at shorter and shorter timeframes, we are increasingly likely to run into a timeframe where there are only up bars (or only down bars) in our history. Then <code>P(up)=1</code>, <a href=""https://www.lesswrong.com/posts/QGkYCwyC7wTDyt3yT/0-and-1-are-not-probabilities"">which doesn't allow us to update</a>. (Some conditional probabilities get messed up too.) That's why we had to disable the posterior assert in the last code cell. Currently we just don't trade during those times, but we could instead assume that <a href=""https://en.wikipedia.org/wiki/Additive_smoothing#Pseudocount"">we've always seen at least one up and one down bar</a>. (And, likewise, for all features.)</p>
<p><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/v8jattdqob9fz1q2yp7c"" alt=""""></p>
<p>The results are not different for longer timeframes (as we'd expect), and mostly the same for shorter timeframes. We can reenable our posterior assert too.</p>
<h2>Bet sizing</h2>
<p>Currently we're betting our entire portfolio each bar. But in theory, our bet should probably be proportional to how confident we are. You could in theory use <a href=""https://en.wikipedia.org/wiki/Kelly_criterion"">Kelly criterion</a>, but you'd need to have an estimate of the size of the next bar. So for now we'll just try linear scaling: <code>df[""strat_signal""] = 2 * (df[""P(H_up_bar)""] - 0.5)</code></p>
<p><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/wbl4zkikbwqlgwczre8w"" alt=""""></p>
<p>We get lower returns, but slightly higher SR.</p>
<h2>Ignorant priors</h2>
<p>Currently we're computing the prior for <code>P(next bar is up)</code> by assuming that it'll essentially draw from the same distribution as the last N bars. We could also say that we just don't know! The market is really clever, and on priors we just shouldn't assume we know anything: <code>P(next bar is up) = 50%</code>.</p>
<pre><code># Compute ignorant priors
    for h in hypotheses:
        df[f""P(H_{h})""] = 1 / len(hypotheses)
</code></pre>
<p><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/wmpmhfrhb1usgodtmri6"" alt=""""></p>
<p>Wow, that does significantly worse. I guess our priors are pretty good.</p>
<h2>Putting it all together with multiple features</h2>
<p><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/oyb7gcuynkxk7prwbylr"" alt="""">
<img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/cfalwgy3wh0u1vd69oa4"" alt="""">
<img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/xat3qtlf1vfmvzxjqqc8"" alt="""">
<img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/FjjYGCNXEhhcirp36/jtr7ugr3xtl620hspxny"" alt=""""></p>
<h2>Homework</h2>
<ul>
<li>Examine current features? Are they helpful / do they work?</li>
<li>We're predicting up bars, but what we ultimately want is returns. What assumptions are we making? What should we consider instead?</li>
<li>Figure out other features to try.</li>
<li>Figure out other creative ways to use Naive Bayes.</li>
</ul>
",Alexei,alexei,Alexei,
Lds9opZsAMbjuZp7h,"Coordination Surveys: why we should survey to organize responsibilities, not just predictions",coordination-surveys-why-we-should-survey-to-organize,https://www.lesswrong.com/posts/Lds9opZsAMbjuZp7h/coordination-surveys-why-we-should-survey-to-organize,2019-05-07T17:43:18.768Z,68,23,12,False,False,,"<p><em>Summary:</em> I think it’s important for surveys about the future of technology or society to check how people&#x27;s predictions of the future depend on their beliefs about what actions or responsibilities they and others will take on.  Moreover, surveys should also help people to calibrate their beliefs about those responsibilities by collecting feedback from the participants about their individual plans.  Successive surveys could help improve the groups calibration as people update their responsibilities upon hearing from each other.  Further down, I’ll argue that not doing this — i.e. surveying only for predictions but not responsibilities — might even be actively harmful.</p><h3>An example</h3><p>Here&#x27;s an example of the type of survey question combination I&#x27;m advocating for, in the case of a survey to AI researchers about the future impact of AI.</p><p><strong>Prediction about impact:</strong></p><p><em>1) Do you think AI development will have a net positive or net negative impact on society over the next 30 years?</em></p><p><strong>Prediction about responsibility/action:</strong></p><p><em>2) What fraction of AI researchers over the next 30 years will focus their full-time research attention on ensuring that AI is used for positive and rather than negative societal impacts?</em></p><p><strong>Feedback on responsibility/action:</strong></p><p><em>3) What is the chance that you, over the next 30 years, will transition to focusing your full-time research attention on ensuring that AI is used for positive rather than negative societal impacts?</em></p><p>I see a lot of surveys asking questions like (1), which is great, but not enough of (2) or (3).  Asking (2) will help expose if people think AI will be good as a result of other people will take responsibility for making it good.  Asking (3) will well help the survey respondents to update by seeing if their prediction in (2) matches the responses of other survey respondents in (3).  </p><h3>How this helps</h3><p>I’ve seen it happen that everyone thinks something is fine because someone else will deal with it.  This sort of survey could help folks to notice when that’s not the case.  In other words, it could help mitigate the <u><a href=""https://www.psychologytoday.com/us/basics/bystander-effect"">bystander effect</a></u>.</p><p>Similarly, I’ve also seen it happen that everyone gets worried about a thing because they think no one else is doing anything about it, and then they go around taking a bunch of more-drastic-than-necessary unilateral actions.  This sort of survey can help to mitigate this sort of social malcoordination.  That is, it could help mitigate the “<u><a href=""https://nickbostrom.com/papers/unilateralist.pdf"">unilateralist’s curse</a></u>” (which I think is essentially just the opposite of the bystander effect).</p><p>Finally, surveying to coordinate feels like a more cooperative and agentic game than just collecting socially contingent predictions about what will happen in the future, as though the future is inevitable.  It ascribes agency, rather than merely predictive power, to the group of survey respondents as a whole.  And it suggests what parameters are available for the group to change the future, namely, the allocation of certain responsibilities.</p><h3>The side-taking effect: why surveying for predictions alone can be actively bad</h3><p>More is true.  I claim that without adding this sort of coordination information to the group’s discourse, surveys about prediction can sometimes sow seeds of deep-rooted disagreement that actually make coordination harder to achieve.  Here’s how it works:</p><p><em>Alex: “Why worry about AI safety?  It would be silly to make AI unsafe. Therefore someone will take responsibility for it.”</em></p><p><em>Bailey: “You should definitely worry about AI safety, because many people are not taking responsibility for it.”</em></p><p>These views are strangely compatible and therefore hard to reconcile by evidence alone.  Specifically, Alice is rightly predicting that people like Bob will worry and take responsibility for safety, and Bob is rightly predicting that people like Alice are not worried.</p><p>This causes Alice and Bob to disagree with each other in a way that is fairly robust and difficult to settle without shifting the conversation to being about responsibilities instead of impact predictions.  These persistent disagreements can result in factioning where people end up divided on whether they take the position that the responsibility in question (in the example, AI safety) is important or not.  We end up with a lot of side-taking in favor of or against the responsibility, without a lot of discussion of how or when that responsibility will be distributed.</p><h3>The organic version </h3><p>It’s possible that surveys about prediction alone can still be net-good, because people naturally carry out discussions (2) and (3) slowly and organically on their own.  For instance, I’ve given and seen others give talks about the neglectedness of AI safety as an area of research, by arguing from study results compiled by other researchers about the disparity between (a) the widespread opinion that AI safety is  important, (b) the widespread opinion that AI safety will eventually we well-taken care of as a research area, and (b) the widespread lack of funding for the topic, at least prior to 2015.</p><p>But this sort of organic responsibility-awareness development can take years or decades; at least seems to be taking that that long in the case of “AI safety” as a responsibility.  I’d like to see groups and communities develop a faster turnaround time for adopting and distributing responsibilities, and it seems to me like the sort of survey questions I’m proposing here can help with that.</p><h3>My offer</h3><p>If you’re a researcher who is already conducting a survey on the future of AI, even if you don&#x27;t see a way to incorporate the sort of methodology I’m suggesting for the particular questions you’re asking, I&#x27;d love a chance to see the content you have planned, just in case I can come up with some suggestions myself.  If you’re interested in that, you can email about your upcoming survey at <u><a href=""mailto:critch+upcoming-surveys@eecs.berkeley.edu"">critch+upcoming-surveys@eecs.berkeley.edu</a></u>.  </p><p>(Please don’t use this email for other topics besides surveys that are already definitely going to happen soon; I don’t have a lot of availability to create new initiatives right now.)</p><p>If your survey isn’t about AI but about some other impactful technological or societal change, I think I’m less likely to be able to add value to your thinking about it much beyond the writing of this post, but I might be willing to try anyway depending on my availability at the time.</p><p>Thanks for reading!</p>",Academian,academian,Academian,
FWWADsWoMxSnnhKqi,Models of Memory and Understanding,models-of-memory-and-understanding,https://www.lesswrong.com/posts/FWWADsWoMxSnnhKqi/models-of-memory-and-understanding,2019-05-07T17:39:58.314Z,19,6,2,False,False,,"<p>johnswentworth&#x27;s post on <a href=""https://www.lesswrong.com/posts/MHL4zzzzuDMjYNX7v/declarative-mathematics"">Declarative Mathematics</a> got me thinking about what different types of understanding/learning/memory feel like to me. In order to explain an initial confusion I had, I&#x27;m explicating some of my models on how my mind can work.</p><h1>Jumps vs Procedure</h1><p>I want to highlight two different styles of solving problems. One is where you jump directly to the solution, and the other is where you follow a procedure to produce the solution. </p><p>The prototypical example of these two styles would be a neural net vs an automated theorem prover. Once a neural net is trained, there&#x27;s a sense in which it takes an input and &quot;jumps directly&quot; to an output. An automated theorem prover takes an input and systematically applies a bunch of deduction rules till it gets its output.</p><p>I don&#x27;t care to claim that these two styles of &quot;fundamentally&quot; different (because I&#x27;d have to figure out what that means), but I do want to point out that they certainly feel different. This is what matters to me, because this post is about what it feels like for me to be solving problems in different domains.</p><h1>Memory as a Graph</h1><p>My working model of memory is something like &quot;connected graph of ideas with hebbian learning&quot;. This model explains why <strong>use</strong> and <strong>connection</strong> are such a big deal for making something stick in memory. The more you use something, the &quot;sticker&quot; it becomes (pretty non-controversial empirical claim, seems to be theoretically backed up by observations on how neurons work). The more connections you make between ideas, the &quot;sticker&quot; they become (also non-controversial empirical claim, my theory is something like &quot;doing graph search to get to a node on the idea graph becomes easier the more connected an idea is&quot; (hmmm, seems fishy)).</p><p>My thinking of memory as an idea-graph is shaped by alkjash&#x27;s <a href=""https://www.lesswrong.com/s/pC6DYFLPMTCbEwH8W"">Babble and Prune</a> sequence and Kevin Simler&#x27;s <a href=""https://meltingasphalt.com/a-nihilists-guide-to-meaning/"">Nihilist Guide to Meaning.</a></p><h1>Analogies, mapping between modules</h1><p>I can think of two different ways my mind uses analogies. One is as a mnemonic crutch, and the other is as a licence to substitute.</p><p>The licence to substitute is what happens when I learn that two different math structures are isomorphic. I&#x27;m allowed to map things in the source domain to the target domain, do my work in the target domain, map it back and be guaranteed a correct answer (if I did the work correctly).</p><p>Analogies as a mnemonic crutch is when I only use a one particular idea from a target domain. When I say &quot;juggling is like riding a bicycle&quot; I&#x27;m really only talking about one specific part; at first it seems impossible, you do it a bunch, and eventually you get it, often without a detailed understanding of what you did differently to make it work. Analogies as mnemonics feels like copying a pointer to the same chunk of memory in C (me using analogies to describe how analogies work is sort of like using <a href=""https://www.win.tue.nl/~aeb/linux/hh/thompson/trust.html"">gcc to compile the new version of gcc</a>). My brain already has the experience &quot;impossible-&gt;practice-&gt;it works-&gt;don&#x27;t know how&quot; stored near ideas/experiences related to riding bikes. At some point in time I was told juggling is like riding a bicycle, and in my juggling knowledge I stored a pointer to that previous experience I had with bikes.</p><p>As is often the case, mnemonic vs substitution is probably better thought of as a spectrum. The more you allow an analogy to be a substitution, the less meta-data you have to remember about &quot;what parts of this analogy are valid to draw conclusions from?&quot;</p><p>The book <a href=""https://www.amazon.com/Where-Mathematics-Come-Embodied-Brings/dp/0465037712"">Where Mathematics Comes From</a> claims that analogy based reasoning is one of our fundamental thinking tools, and then goes on to make the more interesting claim, &quot;And here are the grounding analogies that dictate people&#x27;s intuitions about math&quot;. Interesting read, haven&#x27;t finished, but would recommend.</p><p>Key Idea: one might be tempted to throw out mnemonic analogies because if you mistake them for substitution analogies, you get the wrong answer. I claim that mnemonic analogies can be incredibly useful for giving you a memory handle that allows you to even remember all of the new ideas in the first place.</p><p>I&#x27;ll use the term module to refer to a chunk of your mind that is experienced at solving problems of some domain using some combo a mix of jumps and procedural knowledge. The key think I want to communicate when speaking of a module is that it&#x27;s solidly cemented in your memory, and whether fast or slow to produce an answer, it&#x27;s reliable.</p><h1>Rigor: Pre and post</h1><p>Terry Tao has a <a href=""https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/"">post</a> that people here have seen before where he divides one&#x27;s mathematical journey into three stages; pre-rigor, rigor, and post-rigor. His post is short and you should read it. Here&#x27;s each phase translated into my own models described above.</p><p><strong>Pre-rigor</strong>: You have scant procedural knowledge on the topic, you have no well fit modules to map over, and most of you understanding is comes from analogies as mnemonics which,  due to their lack of fit, take a lot of &quot;rote practice glue&quot; to stick together. You are not very good.</p><p><strong>Rigor</strong>: Your procedural knowledge of the topic is gotten a lot more connected and well used. You are getting stronger at getting answers. You see how your previous mnemonic analogies are very misleading and discard them. You distrust people who make jumps and stick to your now familiar formal procedures. You are okay.</p><p><strong>Post-rigor</strong>: Your procedural knowledge has been practiced so much it begins to form a module that allows you to jump to some solutions. You have a sense of what the &quot;shape&quot; and &quot;feel&quot; of different structures are. Having built new modules with rigorous foundations, you are more comfortable using substitution analogies to guide your jumps. You are becoming quite powerful.</p><h1>The actual thing I wanted to talk about</h1><p>See this <a href=""https://www.lesswrong.com/posts/MHL4zzzzuDMjYNX7v/declarative-mathematics#qQdGaMagx8jRxi8sB"">comment</a>.</p><p>Let&#x27;s say I&#x27;m using a high level library  (like <a href=""https://asyncio.readthedocs.io/en/latest/tcp_echo.html"">asyncio</a>) to make calls over a network. The library provides me an interface that very easily maps onto concepts I&#x27;m already familiar with. I&#x27;m doing things like &quot;opening a connection&quot; &quot;writing to the other computer&quot; and &quot;waiting to read&quot;. These are all things that easily map onto mental modules I&#x27;m able to use and make jumps with. </p><p>If the abstraction is good, maps to a module I can already wield, and isn&#x27;t that leaky, I don&#x27;t really care about what&#x27;s under the hood. Sometimes I get curious and investigate, &quot;Hmmmm, what how do you actually get something like &#x27;opening a connection&#x27; with just wires and 1&#x27;s and 0&#x27;s?&quot;, but that&#x27;s not necessary for me to use the abstraction well. It is necessary for me to know what&#x27;s under the hood if the things start breaking, but not until then.</p><p>When I was imagining not knowing how things worked &quot;under the hood&quot; for mathematics, I was imagining my experience with real analysis where I never got solid enough mnemonic analogies (nor built new modules through rigorous practice) for the ideas/concepts/results to stay in my mind. The only tool I had claim to was &quot;start from the basic definitions and slowly work your way towards the proof&quot;.</p><p>Now that I&#x27;ve thought things through and can imagine not knowing what&#x27;s &quot;under the hood&quot; yet still having a mapping to an existing module that leads me remember things, I&#x27;m more inclined to be interested in declarative mathematics.</p>",Hazard,hazard,Hazard,
xWrLpxxHoLTWfQY3g,Towards optimal play as Villager in a mixed game,towards-optimal-play-as-villager-in-a-mixed-game,https://www.lesswrong.com/posts/xWrLpxxHoLTWfQY3g/towards-optimal-play-as-villager-in-a-mixed-game,2019-05-07T05:29:50.826Z,51,15,40,False,False,http://benjaminrosshoffman.com/towards-optimal-play-as-villager-in-a-mixed-game/,"<p>On Twitter, Freyja <a href=""https://twitter.com/utotranslucence/status/1113028181227786240"">wrote</a>:</p><blockquote><em>Things capitalism is trash at:</em><br/><em>Valuing preferences of anything other than adults who earn money (i.e. future people, non-humans)</em><br/><em>Pricing non-standardisable goods (i.e. information)</em><br/><em>Playing nicely with non-quantifiable values + objectives (i.e. love, ritual)</em></blockquote><blockquote><em>Things capitalism is good at:</em><br/><em>Incentivising the production of novel goods and services</em><br/><em>Coordinating large groups of people to produce complex bundles of goods</em><br/><em>The obvious: making value fungible</em></blockquote><blockquote><em>Anyone know of work on -</em><br/><em>a) integrating the former into existing economic systems, or</em><br/><em>b) developing new systems to provide those things while including capitalism&#x27;s existing benefits?</em></blockquote><p>This intersected well enough with my current interests and those of the people I&#x27;ve been discoursing with most closely that I figured I&#x27;d try my hand at a quick explanation of what we&#x27;re doing, which I&#x27;ve lightly edited into blog post form below. This is only a loose sketch, I think it does reasonably precisely outline the argument, but many readers may find that there are substantial inferential leaps. Questions in the comments are strongly encouraged.</p><p>Any serious attempt at (b) will first have to unwind the disinformation that claims that the thing we have now is capitalism, or remotely efficient.</p><p>The short version of the project: learning to talk honestly within a small group about how power works, both systemically and as it applies to us, without trying to hold onto information asymmetries. (There&#x27;s pervasive temptation to withhold political information as part of a zero-sum privilege game, like Plato&#x27;s philosopher-kings.)</p><p>Some background: post-WWII elite institutions (e.g. corps) are competitive to enter, but not under performance pressure, because of US government policy. This strongly <a href=""http://benjaminrosshoffman.com/blame-games/"">selects for zero-sum games</a>, which <a href=""http://benjaminrosshoffman.com/excerpts-from-a-larger-discussion-about-simulacra/"">mimic but wreck discourse</a>. (See <a href=""https://srconstantin.wordpress.com/2019/01/10/book-recommendations-an-everyone-culture-and-moral-mazes/"">Moral Mazes</a> for more, especially the case studies that make up most of the book, starting around chapter 3.)</p><p>This creates opportunity in two ways.</p><p>First, institutions are mostly too stupid to model their environment beyond the zero-sum games they specialize in, so a small group that&#x27;s able to maintain information hygiene and not turn on each other should be able to take &amp; hold territory. &quot;And not turn on each other&quot; turns out to be really hard, because all our role models and intuitions for how to survive in this world involve doing that all the time. But we&#x27;re learning!</p><p>(A mundane example of a decisive advantage due to information hygiene: Paul Graham writes about how his startup did better <a href=""http://www.paulgraham.com/avg.html"">because it used an elegant programming language</a>. That&#x27;s only information hygiene on the purely technical level, but that was enough to outmaneuver huge corporations with a strong perceived incentive to ruin them, for quite a while. For a less mundane example, the story of how Elisha outmaneuvered multiple ruling dynasties is a personal favorite - 2 Kings 5-10. The narrative distorts the &quot;miracles&quot; a bit but it&#x27;s not hard to reconstruct how he actually did it.)</p><p>Second, because most supposed productive activity is done in the context of huge stable corporations, people are trying to maximize the number of jobs and complexity per unit of output. This implies that many things can be done <a href=""https://www.cato-unbound.org/2007/09/10/robin-hanson/cut-medicine-half"">much more easily</a>.</p><p>So that implies that if we can have good enough information hygiene and group cohesion not to fall victim to the perverse impulse to do the kind of make-work or <a href=""http://benjaminrosshoffman.com/there-is-a-war/"">artificial scarcity</a> that creates much of <a href=""https://slatestarcodex.com/2017/02/09/considerations-on-cost-disease/"">cost disease</a>, we can learn how to build a nearly full-stack civilization in a small city-state. Obviously there are many steps between here and there, but since lots of them involve getting collectively smarter, a detailed plan would be inappropriate.</p><p>What does good information hygiene and group cohesion look like? The game Werewolf is a good example. Players are secretly assigned the identity of Villager (initially the majority) or Werewolf (minority). Each round all players vote one player out, and Werewolves secretly do the same. There are other details that allow villagers to make some inferences about who the werewolves are. But they have to play the first few rounds right or they lose.</p><p>Optimal play for Werewolves involves (a) targeting whichever villagers are the most helpful to public deliberation, for exclusion, and (b) during public deliberation, being as unhelpful as they can get away with while appearing to try to help at other times. I realized a lot of things about <a href=""http://benjaminrosshoffman.com/engineer-diplomat/"">how social skills feel from the inside</a> when I finally figured out how to play correctly as a Werewolf.</p><p>Optimal play for Villagers involves creating as much clarity as possible, as soon as possible, and being willing to assume that people who seem to be foolishly gumming up the works are Werewolves if there&#x27;s no other clear target.</p><p>With optimal play, Villagers usually win, but in practice, at best one or two people try to create clarity and are picked off in the first round by the Werewolves. The other Villagers are resigned to trying to die last, so they lose.</p><p>The thing I said about elite culture favoring zero-sum games can be recast as: the social environment favors playing Werewolf over playing Villager. In case it&#x27;s not obvious, optimal real-world play for Villagers can often involve leaving the Werewolves alone. In real life there are better things to do than murder your enemies, like hang out. Villagers just need to defend themselves if and when they&#x27;re actually threatened.</p><p>We&#x27;re trying to learn how to play the Villager strategy successfully, in a context where we&#x27;ve mostly been acculturated to play as Werewolves, especially among elites. This has to involve figuring out how to do interpersonal fault analysis (identify when people are being Werewolfy) without scapegoating (assuming that <a href=""http://benjaminrosshoffman.com/blame-games/"">fault -&gt; blame -&gt; exclusion</a>).</p><p>In other words, justice seeks truth, but intends to leave no one behind; people who can&#x27;t contribute need to feel safe admitting that, and people who hurt the group need the option to repent &amp; heal the breach.</p><p>We don&#x27;t have great finesse yet but optimal play in our world seems to be some fluid integration of talking about politics, healing personal trauma, and intersubjective openness.</p><p>Havel&#x27;s <a href=""https://www.nonviolent-conflict.org/wp-content/uploads/1979/01/the-power-of-the-powerless.pdf"">The Power of the Powerless</a> describes a similar (but less self-aware) strategy which he calls &quot;dissidence.&quot; He (accurately, I think) predicts that the situation in Capitalist countries will be more difficult than the situation in Communist ones, because Capitalist ideology is more persuasive because it&#x27;s more plausibly true.</p>",Benquo,benquo,Benquo,
k774aKEogcCugmKPY,Which parts of the paper Eternity in Six Hours are iffy?,which-parts-of-the-paper-eternity-in-six-hours-are-iffy,https://www.lesswrong.com/posts/k774aKEogcCugmKPY/which-parts-of-the-paper-eternity-in-six-hours-are-iffy,2019-05-06T23:59:16.777Z,21,7,9,False,True,,"<p>The FHI paper, <a href=""https://www.fhi.ox.ac.uk/publications/armstrong-s-sandberg-a-2013-eternity-in-six-hours-intergalactic-spreading-of-intelligent-life-and-sharpening-the-fermi-paradox-acta-astronautica-89-1-13/"">Eternity in Six Hours</a>, is very optimistic about what can be done:</p><blockquote>In this paper, we extend the Fermi paradox to not only life in this galaxy, but to other galaxies as well. We do this by demonstrating that traveling between galaxies – indeed even launching a colonisation project for the entire reachable universe – is a relatively simple task for a star-spanning civilization, requiring modest amounts of energy and resources. We start by demonstrating that humanity itself could likely accomplish such a colonisation project in the foreseeable future, should we want to, and then demonstrate that there are millions of galaxies that could have reached us by now, using similar methods.</blockquote><p>Is this paper reasonable? Which parts of its assertions are most likely to be mistaken?</p><p><em>This question was inspired by a conversation with Nick Beckstead.</em></p>",Ruby,ruby,Ruby,
BCGJ476NiZ7hjSXLB,South Bay Meetup,south-bay-meetup,https://www.lesswrong.com/events/BCGJ476NiZ7hjSXLB/south-bay-meetup,2019-05-06T23:59:09.497Z,2,1,1,False,False,,"<p>We are having our usual South Bay meetup this Saturday. I put up the notice some time ago, but it isn&#x27;t showing, so I am putting it up again. </p>",DavidFriedman,davidfriedman,DavidFriedman,
NZiDAY9b4mZeRWbRc,Space colonization: what can we definitely do and how do we know that?,space-colonization-what-can-we-definitely-do-and-how-do-we,https://www.lesswrong.com/posts/NZiDAY9b4mZeRWbRc/space-colonization-what-can-we-definitely-do-and-how-do-we,2019-05-06T23:05:55.300Z,32,11,6,False,True,,"<p>Arguments for the value of the long-term future tend to make the assumption that we will colonize space. What can we definitely accomplish in terms of space colonization? Why think that we can definitely do those things?</p><p>The FHI paper, <a href=""https://www.fhi.ox.ac.uk/publications/armstrong-s-sandberg-a-2013-eternity-in-six-hours-intergalactic-spreading-of-intelligent-life-and-sharpening-the-fermi-paradox-acta-astronautica-89-1-13/"">Eternity in Six Hours</a>, is very optimistic about what can be done:</p><blockquote>In this paper, we extend the Fermi paradox to not only life in this galaxy, but to other galaxies as well. We do this by demonstrating that traveling between galaxies – indeed even launching a colonisation project for the entire reachable universe – is a relatively simple task for a star-spanning civilization, requiring modest amounts of energy and resources. We start by demonstrating that humanity itself could likely accomplish such a colonisation project in the foreseeable future, should we want to, and then demonstrate that there are millions of galaxies that could have reached us by now, using similar methods.</blockquote><p>Is this paper reasonable? Which parts of its assertions are most likely to be mistaken?</p><p><em>This question was inspired by a conversation with <a href=""https://www.lesswrong.com/users/nick_beckstead"">Nick Beckstead</a>.</em></p>",Ruby,ruby,Ruby,
pWiAuhBmWskgESM4R,How long can people be productive in [time period]?,how-long-can-people-be-productive-in-time-period,https://www.lesswrong.com/posts/pWiAuhBmWskgESM4R/how-long-can-people-be-productive-in-time-period,2019-05-06T22:35:27.700Z,48,14,17,False,True,,"<p>I often see statistics that &quot;people are only productive four hours/day&quot;, but they never seem to cite their sources. The studies I&#x27;ve tracked down are low quality (<a href=""https://www.vouchercloud.com/resources/office-worker-productivity"">example</a>). 30 minutes poking around google scholar produced nothing useful.</p><p>Where are the high quality studies showing how long people can work productivity?</p>",pktechgirl,elizabeth-1,Elizabeth,
wkcvDuMLq9D2D6KjX,Hierarchy and wings,hierarchy-and-wings,https://www.lesswrong.com/posts/wkcvDuMLq9D2D6KjX/hierarchy-and-wings,2019-05-06T18:39:43.607Z,25,11,22,False,False,http://benjaminrosshoffman.com/hierarchy-wings/,"<p>(Note for LessWrong: This is more overtly about partisan politics than the norm, but I think it&#x27;s not <em>more</em> about that than <a href=""https://www.lesswrong.com/posts/qAJgWCWJJkke4mE8x/the-two-party-swindle"">The Two-Party Swindle</a>, from the Sequences, and it proposes a structural model that doesn&#x27;t require people to be as stupid.)</p><p>There are a few points I didn&#x27;t make in my <a href=""http://benjaminrosshoffman.com/blame-games/"">post on blame games</a> because they seemed extraneous to the core point, which are still important enough to write down.</p><h1>Hierarchy</h1><p>The Hierarchy game is a zero-sum game in which people closer to the center expropriate from people farther from the center, and use some of those resources to perpetuate the power imbalances that enable the expropriation. Players that fail to submit to expropriation by higher-level players are punished by those more-powerful players, often through intermediaries. Players that fail to help members of their class expropriate from those beneath them are excluded from their class, and often coordinated against more overtly.</p><p>This game isn&#x27;t inherently majoritarian, - instead, it allows smaller groups to stably expropriate from larger ones, because every player has a short-run incentive to go along with the arrangement. Feudalism is a simple example of the hierarchy game. Modern states almost always have some hierarchical arrangements, such as the police and military, and (less formally) economic class. </p><h1>Political handedness</h1><p>Around the time of the French revolution - a replacement of Feudal arrangements with Modern states - people started using terms like &quot;left&quot; and &quot;right&quot; to refer to political orientations. These terms are related to natural structural coalitions within a modern democratic state.</p><p>Political parties don&#x27;t overtly promise to expropriate from 49% on behalf of an arbitrary 51%. This is probably in part because this would be correctly viewed as a proposal to massively increase expropriative activity relative to other activity, accelerating the rate of expropriation, which actually isn&#x27;t in the majority&#x27;s interests, and would quickly undermine the democratic paradigm without providing a replacement to enforce property claims. Instead, appropriation is opportunistic, and political coalitions seem to be oriented around natural power bases which could in principle replace deliberative democracy.</p><h2>Right-wing</h2><p>One natural sort of organization to orient around is the formal hierarchy with a monopoly on force - the military and police. The staffing needs of these organizations are substantial, especially in wartime (democracies perform well in wars in part because of their ability to mobilize a large share of the population without destabilizing their internal political arrangement) so they already form a natural constituency.</p><p>The obvious advantage of control over these organizations is in the event of a civil war, control over the army and police would be a massive advantage. So, building a group identity around those things is a pretty plausible way to expropriate the country from the other half.</p><p>The &quot;right wing&quot; is the part of the political spectrum that most resembles or is most naturally allied with this coordination strategy. Generally, if there&#x27;s an identifiable majority group (ethnic, cultural, religious, etc.), the hierarchy of violence will perceive members of that group as more &quot;central&quot; and want to help them expropriate from minority groups more than vice versa, <a href=""http://benjaminrosshoffman.com/nightmares-perfectly-principled/"">insofar as gaps in the rule of law allow this</a>. People rewarded by the existing credit-allocation, the &quot;upper classes,&quot; will also tend to favor and be favored by this arrangement.</p><h2>Left-wing</h2><p>The &quot;left wing&quot; is the natural complement to this strategy: a political &quot;big tent&quot; made up of all the noncentral groups. Such a coalition has a structural advantage as long as democratic institutions persist, since any new group (e.g. immigrants) that isn&#x27;t part of the majority is a natural member of the &quot;left wing&quot; coalition. Such groups also tend to seek control of, and expropriate resources through, the parts of the state that are responsible for information processing, investment, and resource allocation rather than the administration of violence. In short, the bureaucracies and those who staff them.</p><p>Related: <a href=""http://benjaminrosshoffman.com/nightmares-perfectly-principled/"">Nightmare of the Perfectly</a> <a href=""http://benjaminrosshoffman.com/nightmares-perfectly-principled/"">Principled</a>, <a href=""https://blog.danieldavies.com/2011/02/arseholes-considered-as-strategic.html"">Arseholes, considered as a strategic resource</a></p>",Benquo,benquo,Benquo,
gPPduz7pTJHotuut6,Value learning for moral essentialists,value-learning-for-moral-essentialists,https://www.lesswrong.com/posts/gPPduz7pTJHotuut6/value-learning-for-moral-essentialists,2019-05-06T09:05:45.727Z,11,5,3,False,False,,"<p>Many people - people we want to persuade - are essentialists about morality and ethics. They give weight to the idea that just like how knowing facts about my shoes is possible because my shoes exist and interact with me, facts about what is right or good are possible because there is some essence of rightness or goodness &quot;out there&quot; that we somehow interact with.</p><p>This isn&#x27;t totally wrong. But I think it reflects the usual human heuristic of assuming that every category has an essence that makes it what it is. Put a human race in a world with water, air, and fire, and the first thing they&#x27;ll think is that the basic categories of water, air, and fire must somehow be reflected in the fundamental order of the world. And why does heat behave the way it does? The flow of <a href=""https://en.wikipedia.org/wiki/Caloric_theory"">heat</a> <a href=""https://en.wikipedia.org/wiki/Caloric_theory"">substance</a>. Why does opium make you drowsy? It has <a href=""https://en.wiktionary.org/wiki/dormitive_virtue"">sleepiness essence</a>.</p><p>This sort of heuristic passes for everyday use, but if you assume that goodness is a fundamental part of the world, the idea of an AI learning to do the right thing is going to sound a bit weird. How can we talk about value learning without even once checking if the AI interacts with the goodness-essence?</p><p>This post outlines the sort of strategy I&#x27;d use to try to get people following essentialist intuitions on board with value learning. I&#x27;ll indirectly rely on some properties of morality that behave more like a pattern and less like an essence. I&#x27;d definitely be interested in feedback, and if you have moral essentialist intuitions, please forgive me for framing this post as talking <em>about</em> you, not <em>to</em> you.</p><p><strong>1: Why bother?</strong></p><p>AI is going to be the pivotal technology of the coming century. AI that does good things can help us manage existential risks like climate change, bio-engineered diseases, asteroids, or rogue AIs build by less careful people.</p><p>In a future where very clever AI does good things, everything is probably pretty great. In a future where very clever AI does things without any regard to their goodness, even if humanity doesn&#x27;t get swept away to extinction, we&#x27;re certainly not realizing the potential boon that AI represents.</p><p>Therefore, it would be really handy if you could program a computer to figure out what the right thing to do was, and then do it - or at least to make an honest try on both accounts. The status quo of humanity is not necessarily sustainable (see above about climate change, disease, asteroids, other AIs), so the point is not to design an AI where we&#x27;re 100% absolutely certain that it will do the right thing, the point is just to design an AI that we&#x27;re more confident in than the status quo.</p><p><strong>2: It goes from God, to Jerry, to me.</strong></p><p>Suppose that humans have knowledge of morality. Then we just need to have the AI learn that knowledge. Just like how you can know that lithium is the third element without having experimentally verified it yourself - you learn it from a trustworthy source. Hence, &quot;value learning.&quot;</p><p>Problem solved, post over, everyone go home and work on value learning? Well...</p><p>The basic question someone might have about this is &quot;what about moral progress?&quot; For example, if one models the transition from slavery being legal to illegal as moral progress made by interacting with the external goodness-essence, what if there are further such transitions in our future that the AI can&#x27;t learn about? Or what if futuristic technology will present us with new dilemmas, moral terra incognita, which can only be resolved correctly by consultation of the goodness-essence?</p><p>This rather depends on how the AI works. If what the AI learns from humans is some list of rules that humans follow, then absolutely it can become morally outdated. But what if the AI learns the human intuitions and dispositions that lead humans to make moral judgments? Then maybe if you sent this AI back to the 1700s, it would become an abolitionist.</p><p>In other words, the real goal of value learning isn&#x27;t just to regurgitate human opinions, it&#x27;s to become connected to moral judgments in the same way humans are. If you think that the human connection to morality is supernatural, even then there are conceptions of the supernatural that would allow AI to reach correct moral conclusions. But I think that even people who say they think morality is supernatural still share a lot of the same intuitions that would let an AI learn morality. Like &quot;moral reasoning can be correct or not independent of the person who thinks it.&quot;</p><p>If the human connection to the goodness-essence is something that depends on the details of how humans reason about morality, then I think the success of value learning is very much still on the table, and we should be looking for ways to achieve it. If you think human morality isn&#x27;t supernatural but don&#x27;t think that merely copying human moral reasoning to the extent that you could be an early abolitionist is sufficient, don&#x27;t use that as an excuse to give up! Try to figure out how an AI could learn to do the right thing, because it might be important!</p>",Charlie Steiner,charlie-steiner,Charlie Steiner,
r2dTchodfqX4o5DYH,Blame games,blame-games,https://www.lesswrong.com/posts/r2dTchodfqX4o5DYH/blame-games,2019-05-06T02:38:12.868Z,46,12,13,False,False,http://benjaminrosshoffman.com/blame-games/,"<p>In <a href=""http://benjaminrosshoffman.com/excerpts-from-a-larger-discussion-about-simulacra/"">Excerpts from a larger discussion about simulacra</a>, I worked through a well-known schema for distinguishing different relationships towards semantic reference, that are a natural result of interactions between shared-production games and expropriation games. Here, I analyze the coalition politics of such games.</p><h1>The Survivor game</h1><p>In zero-sum games, majoritarian decision rules (such as democracy) create an asymmetry - it's much easier to expropriate from a minority than from a majority - or, easier to transfer wealth to a majority than to a minority. Why would the majority vote for something they don't all benefit from?</p><p>A simple variant of this is the Survivor game, in which a single player is voted off the island at a time (see also the ancient Greek custom of ostracism). Since there's comparatively little advantage to being singled out for good, players will tend to want to <a href=""http://benjaminrosshoffman.com/engineer-diplomat/"">avoid revealing information</a> about themselves or their allies. Loudly voicing consensus opinion in ways that don't specify the implications for any person is fine because it's not informative. Anything that lets people distinguish you from the others is dangerous.</p><p>The idea of a Schelling point is that if players in a game need to converge on one location in a map, then in the absence of a strong incentive to favor one location, they will tend to converge on some obviously identifiable feature. For instance, in surveys, Thomas Schelling found that a surprisingly large number of people, if tasked with meeting someone on a specified day, in New York, with no further information, would converge on the information booth in Grand Central - and if no time was specified, they favored noon.</p><p>In a pure Survivor game, the first player to reveal their ""location"" loses. They become the feature everyone else converges on as an expropriation target. One natural side effect of this is coordination against any players who are narratively constrained by something other than the zero-sum game. For instance, if a widget-making group isn't under sharp performance pressure, anyone who's focused on actually making the widgets is going to have a hard time staying in lockstep with the group story, and is therefore the easiest target for expropriation and exclusion.</p><p>(Compare with Sarah Constantin's <a href=""https://srconstantin.wordpress.com/2017/04/25/on-drama/"">claim</a> that group-coordination activities like dancing serve as a way to identify and exclude people who are out of sync with the whole. This stands in some tension with her <a href=""https://twitter.com/s_r_constantin/status/1122859836968804352"">more recent claim</a> that people should exaggerate differences in order to have some social standing within a group.)</p><h1>The Scapegoating game</h1><p>What if you try to play the Survivor game in the real world, where there are other games going on? Now your environment is not exclusively populated with zero-sum players and strategies, which means that revealing info isn't always an unforced error.</p><h2>Level 1: Fault analysis</h2><p>I already mentioned that people trying to coordinate in objective reality will be narratively constrained in ways that make them easier targets for expropriation. But there's another feature of group coordination that's very exploitable in the Survivor game: fault analysis. We try to improve maps to improve productive capacity and mitigate risks external to the social game. An important part of this is revealing flaws in the current arrangement.</p><p>If you reveal a flaw, you might try to repair the defect (e.g. getting someone to change their behavior - ""the squeaky wheel gets the grease"") or you might just discard the flawed part (e.g. punishments for bad behavior, ""the squeaky wheel gets replaced""). This is what fault analysis looks like in <a href=""http://benjaminrosshoffman.com/excerpts-from-a-larger-discussion-about-simulacra/"">simulacrum level 1</a> - the meaning of ""flaw"" correspond to the anticipation that if you remove the flaw, some objective problem is eliminated or ameliorated.</p><h2>Level 2: Framing</h2><p>If there's any amount of zero-sum conflict going on inside the group, the fault-analysis machinery - if coupled to punishment at all - becomes a weapon in the hands of anyone willing to lie. If I want to target someone for expropriation in a zero-sum conflict, I can recruit naive level-1 players by accusing them of some objective flaw - framing them.</p><p>Consider the story of the vineyard of Naboth, from 1 Kings 21:</p><blockquote><em>And it came to pass after these things, that Naboth the Jezreelite had a vineyard, which was in Jezreel, hard by the palace of Ahab king of Samaria. And Ahab spake unto Naboth, saying, Give me thy vineyard, that I may have it for a garden of herbs, because it is near unto my house: and I will give thee for it a better vineyard than it; or, if it seem good to thee, I will give thee the worth of it in money.</em></blockquote><blockquote><em>And Naboth said to Ahab, The&nbsp;Lord&nbsp;forbid it me, that I should give the inheritance of my fathers unto thee.</em></blockquote><blockquote><em>And Ahab came into his house heavy and displeased because of the word which Naboth the Jezreelite had spoken to him: for he had said, I will not give thee the inheritance of my fathers. And he laid him down upon his bed, and turned away his face, and would eat no bread.</em></blockquote><blockquote><em>But Jezebel his wife came to him, and said unto him, Why is thy spirit so sad, that thou eatest no bread?</em></blockquote><blockquote><em>And he said unto her, Because I spake unto Naboth the Jezreelite, and said unto him, Give me thy vineyard for money; or else, if it please thee, I will give thee another vineyard for it: and he answered, I will not give thee my vineyard.</em></blockquote><blockquote><em>And Jezebel his wife said unto him, Dost thou now govern the kingdom of Israel? arise, and eat bread, and let thine heart be merry: I will give thee the vineyard of Naboth the Jezreelite.</em></blockquote><blockquote><em>So she wrote letters in Ahab's name, and sealed them with his seal, and sent the letters unto the elders and to the nobles that were in his city, dwelling with Naboth. And she wrote in the letters, saying, Proclaim a fast, and set Naboth on high among the people:&nbsp;And set two men, sons of Belial, before him, to bear witness against him, saying, Thou didst blaspheme God and the king. And then carry him out, and stone him, that he may die.</em></blockquote><blockquote><em>And the men of his city, even the elders and the nobles who were the inhabitants in his city, did as Jezebel had sent unto them, and as it was written in the letters which she had sent unto them.&nbsp;They proclaimed a fast, and set Naboth on high among the people.&nbsp;And there came in two men, children of Belial, and sat before him: and the men of Belial witnessed against him, even against Naboth, in the presence of the people, saying, Naboth did blaspheme God and the king. Then they carried him forth out of the city, and stoned him with stones, that he died. Then they sent to Jezebel, saying, Naboth is stoned, and is dead.</em></blockquote><blockquote><em>And it came to pass, when Jezebel heard that Naboth was stoned, and was dead, that Jezebel said to Ahab, Arise, take possession of the vineyard of Naboth the Jezreelite, which he refused to give thee for money: for Naboth is not alive, but dead.</em></blockquote><blockquote><em>And it came to pass, when Ahab heard that Naboth was dead, that Ahab rose up to go down to the vineyard of Naboth the Jezreelite, to take possession of it.</em></blockquote><blockquote><em>And the word of the&nbsp;Lord&nbsp;came to Elijah the Tishbite, saying, Arise, go down to meet Ahab king of Israel, which is in Samaria: behold, he is in the vineyard of Naboth, whither he is gone down to possess it.&nbsp;And thou shalt speak unto him, saying, Thus saith the&nbsp;Lord, Hast thou killed, and also taken possession? And thou shalt speak unto him, saying, Thus saith the&nbsp;Lord, In the place where dogs licked the blood of Naboth shall dogs lick thy blood, even thine.</em></blockquote><blockquote><em>And Ahab said to Elijah, Hast thou found me, O mine enemy?</em></blockquote><blockquote><em>And he answered, I have found thee: because thou hast sold thyself to work evil in the sight of the&nbsp;Lord. Behold, I will bring evil upon thee, and will take away thy posterity, and will cut off from Ahab him that pisseth against the wall, and him that is shut up and left in Israel,&nbsp;And will make thine house like the house of Jeroboam the son of Nebat, and like the house of Baasha the son of Ahijah, for the provocation wherewith thou hast provoked me to anger, and made Israel to sin.</em> [...]</blockquote><blockquote><em>And it came to pass, when Ahab heard those words, that he rent his clothes, and put sackcloth upon his flesh, and fasted, and lay in sackcloth, and went softly.</em></blockquote><p>King Ahab, a level-1 player, sees no way to acquire his neighbor's vineyard lawfully. But his foreign queen Jezebel, used to higher simulacrum level royal politics, sees no impediment to simply framing Naboth, a simulacrum level 2 tactic.</p><p>Elijah sees this as an existential threat, flips out, and yells at the king that he deserves the death penalty for this, since by going along with this he's raised the simulacrum level of his kingdom, making object-level coordination harder in a way that can, if it goes too far, become irreversible. Ahab, still a level 1 player, accepts the validity of Elijah's critique and tries to learn his lesson.</p><p>When the Survivor game is coupled to fault-analysis in this way, it becomes the Scapegoat game. If the simulacrum level 1 players are naive about this, a minority of zero-sum players can quickly acquire an advantage, since they're working harder to avoid becoming expropriation targets.</p><h2>Level 3: Prosecutorial discretion</h2><p>When enough players are mainly using fault-analysis to play the Scapegoat game instead of to fix things, the penal code can be redefined so that nearly everyone is technically guilty of some serious crime, and prosecutorial discretion is required. Then, you don't even need to lie to target someone (thus opening yourself up to expropriation for the crime of lying) - since everyone's guilty, actually being guilty of a crime doesn't single you out anymore. The crimes that get punished are the ones where the governing majority sees a shared interest in expropriating from someone. This is simulacrum level 3, where there's no underlying consistent mapping of crimes to punishments that would be good if enforced, just a standardized list of approved attacks.</p><p>Consider the case of Martin Shkreli, who everyone hated because of some perfectly legal price gouging  (not morally innocent or sympathetic like Naboth, but not actually criminal), and was consequently prosecuted for the common and totally unrelated crime of securities fraud. There's not really a norm against securities fraud in the sense of effectual coordination to prevent it from happening, there's just a norm that it's a valid accusation. It's increasingly expensive to be innocent.</p><p>(But Martin Shkreli was a bad guy and deserved prison? Whatever. Once we're arguing about that instead of trying to criminalize the behavior we actually object to, we've abandoned the pretense that the penal code is a serious attempt to represent which behavior we intend to punish.)</p><p>Completely fictitious crimes like witchcraft are a natural outgrowth of this, provided there's a mechanism for confirming that some such claims are true and therefore that the target should be punished. At the limit, we start to see fully general fault-assignment stories, such as such as the Original Sin of Adam and Eve, for which humanity was punished with babies, crops, and the ability to kill snakes, or St. Andreas's Fault, for which Californians are punished with earthquakes.</p><h2>Level 4: Shoot the messenger</h2><p>Finally, at simulacrum level 4, people stop tracking the objective meaning of the law even locally, and it collapses to the pure Survivor game again. Prosocial behavior like revealing information about other people's crimes (e.g. Edward Snowden and Reality Winner, but also Frank Serpico) can be enough.</p><h1>Good and Evil in the Færie courts</h1><p>There are also natural coordination strategies between groups within a mixed simulacrum level blame game. One natural coordination mechanism for a majority (which has some control over which accusations are followed up on) is try to avoid being blamable for anything by only expropriating in ""legitimate"" ways that have narrative cover. This allows them to expropriate from others without being punished, and to recruit level-1 players who still take fault analysis literally into their coalition. The price of this coordination strategy is that they can't coordinate overtly. This kind of coalition tends to fly the ""good"" flag - in Lexical Doll's <a href=""https://lexicaldoll.wordpress.com/2017/08/09/on-the-seelie-and-unseelie-courts/"">Seelie and Unseelie Courts</a> paradigm, this is the Seelie Court.</p><p>The complement to this coalition is the Unseelie Court, or ""Evil,"" which is willing to be maximally blameworthy. While the Seelie court coordinates to avoid any of its members being blamed, the Unseelie court aestheticizes blameworthiness. Both courts are fundamentally defined by the blame-allocation game.</p><p>The ""Evil"" strategy allows the Unseelie to more overtly coordinate to expropriate from others via mechanisms other than the blame game. Overt coordination - especially on otherwise-unobjectionable things that are simulacrum level 3 crime - makes the Unseelie Court sympathetic to a different class of level 1 players, who see and like that ""Evil"" is making concrete improvements to the world. The downside of this strategy is that ""Evil"" is structurally incapable of excluding bad actors, unless it gets big enough that it wants to convert from ""Evil"" to ""Good.""</p><p>Until recently, Google was ""Good"" and Uber was ""Evil.""</p><p>""Good"" is winning. ""Evil"" is winning. Who's losing? The level-1 players who just want to fix the things that are wrong and don't want to expropriate from anyone.</p><p>**********</p><p>Related: <a href=""http://benjaminrosshoffman.com/talents/"">Talents</a>, <a href=""http://benjaminrosshoffman.com/model-building-and-scapegoating/"">Model building and</a> <a href=""http://benjaminrosshoffman.com/model-building-and-scapegoating/"">scapegoating</a></p>",Benquo,benquo,Benquo,
yT7G8jLGPusTgWjeC,Building trusted third parties,building-trusted-third-parties,https://www.lesswrong.com/posts/yT7G8jLGPusTgWjeC/building-trusted-third-parties,2019-05-05T23:18:27.786Z,12,6,0,False,False,,"<html><head></head><body><p>How do two mutually distrusting entities(AGIs, space-faring societies, etc.) enact the results of a negotiated agreement when neither trusts the other? In cryptography there are Trusted third parties. This is a proposal for a protocol allowing them to be built.</p>
<p>This is done by having a replicator supplied by party A(Alice) self replicate. Party B(Bob) chooses one offspring from each generation to inspect destructively and another to continue the process. At each step Bob becomes twice as confident the remaining replicator is trustable. This is similar to a split and choose zero knowledge proof.</p>
<p>This protocol is carried out by smaller agents that Alice and Bob both trust. These entities must meet a few requirements.</p>
<ul>
<li>They have to detect tampering</li>
<li>They have to hold secrets used for secure communication</li>
<li>They have to destroy the secrets if tampered with</li>
</ul>
<p>How can these conditions fail?:</p>
<ul>
<li>new physics is discovered allowing remote scanning or manipulation of matter</li>
<li>A very large nanotechnology gap between the two parties(IE:one is actually incompetent)</li>
<li>One knows femtotech the other doesn't (same as previous)</li>
</ul>
<p>If these conditions cannot be met (the universe doesn't allow for them) then this isn't going to work and more generally it isn't possible to build trustable infrastructure. That's it. Secrets are used to secure communication with other agents that are part of or created by Alice or Bob. The physics we know about seems to allow this.</p>
<p>If one party has enough of a technological advantage they would just subsume the other rather than negotiate. Also, if precognition or time travel is possible the coin flip step of the protocol fails.</p>
<h2>Implementation concerns</h2>
<p>Alice would likely send more than just the replicator. Additional monitoring of the process might be necessary depending on the quality of tamper detection that is possible. Carrying out the process in space far from large masses that Bob could use to hide nefarious things seems like a sensible precaution.</p>
<p>The replicator might be designed to do mostly inspection and assembly rather than fabrication of components. This makes the replicator smaller and the replication process faster. A preferred embodiment is the use of thin sheet form components that can be fed into the replicator and inspected by nano-scale probing.</p>
<p>Bob can attack the process by tampering with the replicator or the materials he provides to it. For an inspecting replicator he could install nano-scale defects in components. The replicator should either have good enough inspection equipment to catch such defects. Have a way of fixing them or rendering them harmless (eg:heating components to high temperature to damage fine structure) or be immune to such things by design (eg:voting logic and error detection to detect incorrect component behavior).</p>
<p>Alice has a greater ""attack surface"" available to her since she supplies the initial replicator. She can make any design alterations she likes. An attack from her end would be a heritable malicious change to the replicator that disappears when inspection begins. This should be prevented by design. One embodiment of such would be to separate the computing and assembly/inspection halves of the replicator. The computer would be designed with read only logic and programming so it cannot alter itself without help from the assembly parts. The assembly and inspection part is designed to have as little logic as possible so that, if altered, the process fails rather than producing working malicious offspring. During the coin flip, there is inert material separating the two. During inspection the replicator is de-powered and the two halves separated. There should not be enough time or energy available to allow a malicious change in the computer to be removed.</p>
<p>If strong Drexler style nanotechnology is possible, this is would be an easy problem to solve. Otherwise, it's harder but I think still feasible.</p>
<h2>Game theory</h2>
<p>My assumptions here are that the payoff matrix looks something like this</p>
<pre><code>Alice   Bob      pay     P(works)
coop.   coop.    +1,+1   ~1
defect  coop.    +5,-1   2^-n
X       defect   -1,+5   ~0        
</code></pre>
<p>The payoff values are relative to the base case where nothing happens. The last row is included for completeness sake. A good implementation makes it nearly impossible for Bob to subvert the protocol thus approximately zero chance of success. Likewise if both are honest approximately unity chance of success.</p>
<p>Each party wins a lot by screwing the other over. If Bob just surrenders to Alice and gives her control of his assets she will defect because that gets her +4 over the cooperate case. What this protocol does is add that probability column which makes Alice's chance of defect success negligible. The assured +1 becomes the better choice <code>(+5*2^-n &lt;&lt; +1*1)</code> so she cooperates. Bob Obviously has an incentive to cooperate since he gets the +1. The +5 isn't worth it since it's overwhelmingly likely to fail. Both cooperate, everyone ends up better off.</p>
<p>This is a bit of a simplification. The payoff matrix represents the overall benefit to both parties if they carry out the agreement completely. The agreed upon contract should reflect this with logic in place for one party not carrying through on their end of the agreement. Alice might refuse to hand over her assets after Bob's are taken over. In this case the contract logic should leave Bob in control of his assets until Alice makes good on her end. Alternatively, it might be worth the sending a dishonest replicator on the off chance of scoring a solar system's worth of resources. The +1,+1 outcome is better for everyone though and rational agents should end up there. The payoff matrix would have to be really skewed for them not to.</p>
<p>As someone who cares about efficiency, I like the idea that future entities, whatever they may be, might be able to cooperate.</p>
</body></html>",obserience,anithite,anithite,
FjtN4EY8K4mQ2jwuZ,How much do major foundations grant per hour of staff time?,how-much-do-major-foundations-grant-per-hour-of-staff-time,https://www.lesswrong.com/posts/FjtN4EY8K4mQ2jwuZ/how-much-do-major-foundations-grant-per-hour-of-staff-time,2019-05-05T19:57:42.756Z,22,6,4,False,True,,"<p><em>[Edit: original source has been found. The way I framed this question was off, since I&#x27;d mis-remembered it as &quot;amount that a given grantmaker grants per year&quot; rather than &quot;grants per hour of staff time&quot;. Updated the title]</em></p><p>I recall reading an article once that claimed that, when examining many small and large foundations, it turned out that there was a maximum amount that a given grantmaker typically gave out. And as organizations scaled to give out more money, this amount stayed surprisingly fixed, with a higher overhead ratio than you might have expected.</p><p>(i.e. when an org gives out a million a year, it has N grantmakers, and when it gives out 100 million a year, it typically has 100N grantmakers).</p><p>I don&#x27;t remember the number, or the methodology that determined it. Curious if anyone can remember the article. (It might have been from OpenPhil&#x27;s blog, or it might have been some random news site).</p><p>I vaguely remember the number &quot;3&quot; being involved, possibly $300k, or $3 million.</p><p>The takeaway I remember was something like &quot;you might naively think you can scale up an organization and then give away money more efficiently, but weird forces seem to limit that.&quot;</p><p>Does this sound familiar to anyone?</p>",Raemon,raemon,Raemon,
JvTM68yzurLzJ3Xua,The why and how of daily updates,the-why-and-how-of-daily-updates,https://www.lesswrong.com/posts/JvTM68yzurLzJ3Xua/the-why-and-how-of-daily-updates,2019-05-05T15:21:42.300Z,33,13,3,False,False,,"<html><head></head><body><p>In August 2018, my work colleague Tomo Kazahaya and I came up with the
idea of using GitHub issues to keep track of daily work checklists. We
created a private GitHub repository called <code>daily-updates</code>. In
October, I copied over the idea to managing personal checklists; you
can see <a href=""https://github.com/vipulnaik/daily-updates/issues/1"">my first issue created October
20</a> or <a href=""https://github.com/vipulnaik/daily-updates/issues/63"">my issue
for yesterday</a>.</p>
<p>Since then, I've been creating daily updates issues on my personal
repository on any days where I'm doing meaningful work on personal
projects or tasks beyond daily personal maintenance.</p>
<p>In this post, I'll talk briefly about the following:</p>
<ul>
<li>The benefits of a broadly visible written document for a personal checklist</li>
<li>The benefits of daily granularity for a personal checklist</li>
<li>The benefits of using GitHub issues to record daily updates</li>
<li>Some protocol questions I don't have clear answers to</li>
</ul>
<h2>The benefits of a broadly visible written document for a personal checklist</h2>
<p>I'm using the term ""broadly visible"" instead of public, because in
some cases (such as companies) daily updates of employees refer to a
lot of confidential company information, and therefore can only be
visible within the company. In this context, ""broadly visible"" would
mean visible within the company.</p>
<p>The emphasis on ""broadly visible written document"" is to contrast with
two other kinds of approaches:</p>
<ul>
<li>
<p>Private personal checklists, that each person manages on their own,
but are not visible to others: The advantage of a broadly visible
document rather than a private personal checklist is that people can
check any time what the others are working on. This allows them to
offer thoughts and feedback, and also gives a better
organization-wide picture of what is going on.</p>
</li>
<li>
<p>Daily stand-ups, where everybody describes what they plan to do
during the day: Written documents are preferable to daily stand-ups
because they can be continuously updated as needed, can be
referenced any time, and work better for teams that don't all start
work at the same time. Also, my historical experience has been that
most people hate stand-ups; the Internet
<a href=""https://news.ycombinator.com/item?id=14271670"">seems</a>
<a href=""https://blog.standuply.com/stand-up-meetings-are-soon-dead-e74118f788f4"">to</a>
<a href=""http://blog.idonethis.com/daria-developer-hates-standup/"">agree</a>.</p>
</li>
</ul>
<p>A dilemma that sometimes comes up is that some subset of one's daily
tasks needs to be kept private, and therefore cannot be explicitly
included in a broadly visible daily checklist. I've encountered this
sort of situation both in my work checklists and non-work checklists.</p>
<p>For these kinds of situations, I've generally found it good enough to
include stand-in checklist items that may not accurately describe
exactly what the underlying task is, but frame it in a way that, <em>when
I read it, I know what it is</em>. For instance, a confidential meeting
may be written up as ""meeting to brainstorm ideas"" or something
similar, which is vaguely true and good enough to keep track of
things.</p>
<p>If most of the items in the checklist need to be highly confidential,
though, broadly visible checklists may not make sense. It may
therefore be better to restrict the visibility of the checklist to
just yourself and one or two other people who collaborate closely with
you.</p>
<h2>The benefits of daily granularity</h2>
<p>Checklists can be made at different granularies: hourly, daily,
weekly, monthly. I have found that daily is a good unit for a certain
kind of checklist.</p>
<p>In my experience, a day is long enough and flexible enough to have a
reasonable set of things to fit in (without being too prescriptive
about what to do at what time) while still short enough to plan even
in chaotic environments.</p>
<p>For larger teams and/or more complex projects, planning needs to be
done on longer timescales, but a flat checklist of items may be too
simplistic for longer timescales, and tailored project management
tools (such as Jira) may be better suited to such planning. Such
planning can be complementary to the daily checklist.</p>
<p>Why have a daily checklist if we have broader project planning? A few
reasons:</p>
<ul>
<li>
<p>Daily checklists can include items that are not part of the broader
plan, but more one-off pieces of work.</p>
</li>
<li>
<p>Daily checklists offer a clearer sense of how the work breaks down
in practice at a daily granularity. Project management tools can be
quite complex, and while they may be better at overall task
tracking, they may not be that good at getting a sense of ""how much
work of what kind can be done within a day?""</p>
</li>
</ul>
<h2>The benefits of using GitHub issues to record daily updates</h2>
<p>Using GitHub issues for daily updates is a bit of a hack, since that's
not the original purpose of GitHub issues. Nonetheless, the hack has
worked well in the two contexts where I've tried it (work-related
checklists at my company, and personal checklists). Here are some of
the advantages of GitHub issues for daily updates:</p>
<ul>
<li>
<p>GitHub has good checklist/checkbox support, which makes it easy to
track progress. On the main issues page, one can see at a glance the
number of checklist items per day and how many of them were
completed.</p>
</li>
<li>
<p>The concept of closing an issue helps create a sense of finality:
once somebody has finished checking boxes and updating their daily
updates issues, they can close the issue. Then others know that the
issue represents the final state of what was done during the day.</p>
</li>
<li>
<p>If much of the other work being done is also recorded in GitHub,
GitHub's support for linking within GitHub can make it easy and fast
to add links to the actual work. This could include links to GitHub
issues, commits, or pull requests.</p>
</li>
<li>
<p>It's easy to see daily checklists for many different people together.</p>
</li>
</ul>
<h2>Some protocol questions I don't have clear answers to</h2>
<p>Some of the questions I've wondered about, but don't have clear
answers to, are below. There are pros and cons of various approaches
and I'm guessing the optimal answer varies by context.</p>
<h3>How should we handle stuff that came in after the original checklist was made?</h3>
<p>My approach is to just add it to the list.</p>
<p>If it's particularly important to know what fraction of work is
pre-planned versus spontaneous, the stuff added later can be put in a
separate section for spontaneous tasks. I've tried this in the past,
back when getting a sense of the level of pre-planned versus
spontaneous in the task mix was important to me. However, I nowadays
organize my checklist by topic instead.</p>
<h3>Should boxes be checked if the whole task as intended wasn't completed, but part of it was?</h3>
<p>My current strategy is to check the box and edit the description to
note that only part of the work was done.</p>
<h3>Should people be expected to keep the checklist updated throughout the day, or only once when closing the issue?</h3>
<p>I think that as an organizational requirement, there should be only a
requirement to create the checklist (open the issue) early in the day,
and close it either at end of day or early in the next day. People who
want to update the checklist more frequently are welcome to, but there
is no requirement. For some organizations, there may be good reasons
to impose a requirement for more real-time up-to-dateness.</p>
</body></html>",VipulNaik,vipulnaik,VipulNaik,
vTS8K4NBSi9iyCrPo,A reckless introduction to Hindley-Milner type inference,a-reckless-introduction-to-hindley-milner-type-inference,https://www.lesswrong.com/posts/vTS8K4NBSi9iyCrPo/a-reckless-introduction-to-hindley-milner-type-inference,2019-05-05T14:00:00.862Z,17,5,4,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><p><em>(I've been editing this post on and off for almost a year. I'm not really happy with it, but I suspect I never will be.)</em></p>
<p>Note: the math formatting got lost in crossposting to LW. With the help of the mods, I've mostly cleared it up, but you may wish to read <a href=""http://reasonableapproximation.net/2019/05/05/hindley-milner.html"">on my blog</a> instead.</p>
<p>Several months ago I gave a talk at work about Hindley-Milner type inference. When I agreed to give the talk I didn't know much about the subject, so I learned about it. And now I'm writing about it, based on the contents of my talk but more fleshed out and hopefully better explained.</p>
<p>I call this a reckless introduction, because my main source is <a href=""https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system"">wikipedia</a>. A bunch of people on the internet have collectively attempted to synthesise a technical subject. I've read their synthesis, and now I'm trying to re-synthesise it, without particularly putting in the effort to check my own understanding. I'm not going to argue that this is a good idea. Let's just roll with it.</p>
<p>I'm also trying to tie in some quasi-philosophy that surely isn't original to me but I don't know if or where I've encountered it before.<a href=""#fn:constraints-liberties"">1</a></p>
<h3>Background</h3>
<p>When people write software, sometimes it doesn't do exactly what we want. One way to find out is to try running it and see, but that's not ideal because any complicated program will have way too many possible inputs to test. (Especially when you consider that inputs include things like ""amount of free space on disk"" and ""time taken for a web server to respond to a request"".) So it would be nice if we could mathematically prove whether our software does what we want, without actually running it. Can we do that?</p>
<p>That's not a very well-defined question, but we can ask more precise versions of it. Here's a well-known one: given some possible input to our software, we might want to prove that our software will eventually stop running. Can we prove that?</p>
<p>That question is known as the halting problem, and the simple answer is that we can't, not in general; the halting problem is <em>undecideable</em>. But the full answer is more complicated.</p>
<p>To solve the halting problem, we want a program that, when shown another program and some input to be fed to that program, satisfies three different conditions:</p>
<ol>
<li>
<p>It will always return an answer.</p>
</li>
<li>
<p>The answer will always be either ""yes, this always terminates"" or ""no, sometimes this doesn't terminate"".</p>
</li>
<li>
<p>The answer is always correct.</p>
</li>
</ol>
<p>And that's not possible. But we can compromise on any of the three. We can make a program that sometimes doesn't return an answer, or one that sometimes gets the answer wrong. But perhaps most interestingly, we can make a program that sometimes says ""I don't know"".</p>
<p>And when you allow that answer, you can create a <em>language</em> on which the halting problem is decideable. You can write a program that will tell you truthfully whether any program written <em>in that language</em> will terminate; and for any other program, will say ""I don't know"". (Perhaps expressed in words like ""syntax error on line 1"".)</p>
<p>Now, the halting problem is tricky. It turns out that if you create a language like that, there are a lot of interesting things that programs written in that language just won't be able to do; the language will necessarily be <a href=""https://en.wikipedia.org/wiki/Turing_completeness"">Turing incomplete</a>.<a href=""#fn:incomplete"">2</a> But there are also lots of interesting things that they can do. To give three examples of such languages<a href=""#fn:nonterminating"">3</a>:</p>
<ul>
<li>
<p>Regular expressions are really useful for certain operations on strings, but that's about all they're good for.</p>
</li>
<li>
<p>SQL is really useful for working with databases. According to <a href=""https://stackoverflow.com/questions/900055/is-sql-or-even-tsql-turing-complete"">some people on stack overflow</a>, the ANSI SQL-92 standard was Turing incomplete and the ANSI SQL-99 standard is Turing complete. (No mention of the SQL-96 standard that came between these, but reading between the lines, probably Turing incomplete.) If I understand correctly, the feature required to make SQL-99 Turing complete<a href=""#fn:recursive-cte"">4</a> is one I've literally never used; so for my purposes, it may as well be Turing incomplete.</p>
</li>
<li>
<p>Coq is used for proving math theorems. It's an interesting one because when you write your program, you have to also provide a proof that your program terminates. (I think this is <a href=""https://news.ycombinator.com/item?id=9038315"">slightly false</a>, but again, good enough for the point I'm making.)</p>
</li>
</ul>
<p>So although these languages can't do everything, they can still be incredibly useful in their domains. More useful than a more general purpose language might be. One reason for this is that being able to prove non-termination is a useful property of the language. If you had to write a SQL query in C, it would be all too easy to write some C code that would accidentally loop forever.</p>
<p>I'm trying to illustrate here something that seems to me important, which is that there's a tradeoff between what I'll call expressiveness and legibility. A programming language is <em>expressive</em> if you can easily write many interesting programs in it<a href=""#fn:expressive"">5</a>; it's <em>legible</em> if you can easily say many interesting things about the programs you've written in it. And I claim that the most expressive programming languages won't be the most legible, and vice-versa; though there will certainly be <a href=""https://en.wikipedia.org/wiki/Malbolge"">languages</a> which are neither expressive nor legible. This tradeoff seems fundamental to me, and I expect that some approximation of it has been proven as a theorem.<a href=""#fn:zfpa"">6</a></p>
<p>I haven't defined these very well, but hopefully some examples will help. I will also clarify that both of them are highly dimensional; and that ""raw computational power"" is one of the things that expressiveness can point at, but not the only thing; and ""human readability"" is not really one of the things that legibility points at, but many things that increase legibility will also increase human readability.</p>
<ul>
<li>
<p><a href=""https://en.wikipedia.org/wiki/Perl_Compatible_Regular_Expressions"">Perl-compatible regular expressions</a> can classify sets of strings that normal regular expressions can't. But they're harder to make time and space guarantees about. And it's possible to prove whether two regular expressions are equivalent, but that's not possible in general for PCREs (proof: <a href=""https://nikic.github.io/2012/06/15/The-true-power-of-regular-expressions.html"">PCREs can encode CFGs</a>; <a href=""https://math.stackexchange.com/questions/231187/an-efficient-way-to-determine-if-two-context-free-grammars-are-equivalent"">CFGs can't be proved equivalent</a>).</p>
</li>
<li>
<p>Under certain assumptions, Haskell's monadic IO lets you look at the type of a piece of code and know that it won't depend on external state. In return, a function can only bring in external state if its caller allows it to (which requires having permission from its own caller, and so on).</p>
<p>The assumptions in question are false (partly because <code>unsafePerformIO</code> exists), but I've been able to get away with pretending they're true (partly because <code>unsafePerformIO</code> is punishable with excommunication).</p>
</li>
<li>
<p>Custom operators (at least as implemented in Haskell and Elm) are equivalent to named functions, and don't gain or cost much in terms of legibility and expressivity. They simply make code more or less readable. But operator overloading, at least when combined with dynamic typing, gains expressivity at the cost of legibility (you no longer know that <code>a + b</code> will do anything remotely like an addition).</p>
</li>
<li>
<p>Macros make it easier to do things like create DSLs, reduce boilerplate, and set compile-time config options. But they mean that a function call might not look like one, or vice-versa; expressions might get evaluated many times, or not at all; and the code might perform differently depending on the phase of the moon when it was compiled.</p>
</li>
</ul>
<h3>Motivation</h3>
<p>So we've got this tradeoff, and in our programming language design we try to navigate it. We try to find kinds of legibility that can be bought for little cost in expressiveness. Or more precisely, we try to find kinds of legibility <em>that we care about</em>, and that can be bought for little cost in <em>kinds of expressiveness that we care about</em>.</p>
<p>And Hindley-Milner type systems are a tradeoff that's proved fairly successful, both in direct use and as inspiration. At my company<a href=""#fn:my-company"">7</a>, we use <a href=""https://en.wikipedia.org/wiki/Elm_(programming_language)"">Elm</a><a href=""#fn:elm18"">8</a>, which runs on an approximately HM type system. (I don't think it's pure HM, due to extensible record types.) We also use <a href=""https://en.wikipedia.org/wiki/Haskell_(programming_language)"">Haskell</a><a href=""#fn:ghc"">9</a>, which runs on a type system that extends HM in many directions. Haskell's system is more expressive and less legible, but still successful. (I'll mostly be using Elm for examples in this post, and not extensible records.) ML and OCaml are other notable languages based on HM, though I haven't used either.</p>
<p>The legibility HM offers is, roughly, the ability to prove that a program typechecks. I'm not going to clarify exactly what that means, but we probably all have a decent idea. It's the thing that lets the Elm compiler say ""no, that program is trying to add a string to an int, bad program"", while the Python interpreter doesn't know that's going to happen until it's too late. The Elm compiler will refuse to compile your program unless it can logically prove that it will typecheck.</p>
<p>More precisely, what HM offers isn't type <em>checking</em> but the more general type <em>inference</em>. (And beyond that, type inference <em>in roughly linear time</em>.) Type inference doesn't just tell you <em>whether</em> a program typechecks, but <em>what</em> its type is; a program fails to typecheck iff no type can be inferred for it.</p>
<p>What this means is that there's no need to supply type annotations. And indeed, in Elm you can get away without them, except I think for extensible records. In Haskell you sometimes can't, because Haskell loses some of the legibility that HM offers.</p>
<p>(We typically do supply type annotations, but that's because they're useful. Partly as documentation for humans, partly to help pinpoint errors when our programs fail to typecheck.)</p>
<p>And so in an HM system you get no runtime type errors. And although not all runtime errors are type errors, in many cases they could be. For example, an array out-of-bounds exception isn't a type error. But when designing a language, you can decide that array out-of-bounds exceptions won't exist, any array lookup will return either a value from the array or <code>null</code>. If type errors are possible, you've just eliminated one source of errors by pushing them somewhere else, and possibly somewhere harder to debug. But in HM, you've eliminated one source of errors by pushing them somewhere more visible, where they can be ruthlessly executed.</p>
<p>Elm actually tries to promise no runtime errors, period, provided you stay inside Elm. On one level, I think that's a fairly minor imposition on language design, something you get ""for free"" by deciding that none of the built-in functions you provide will ever throw a runtime error. On another level, it seems completely impractical to decide for example that <code>cons</code> will return a meaningful value if it can't allocate more memory. I'm not aware that Elm even tries to handle those errors.</p>
<p>(Haskell doesn't try to promise the same thing, and allows functions to return <code>undefined</code>. This is another legibility-expressiveness tradeoff.)</p>
<p>So HM's legibility gain is: type inference, powerful type system, no runtime type errors, optionally no runtime errors at all. It's good.</p>
<p>Meanwhile, the expressiveness cost is that you need to write your programs in ways that the type inference algorithms can work with, which forbids some things that you might like to do.</p>
<p>For example, suppose you want to clamp a number to between -1 and +1. In Python, you could write that like</p>
<pre><code>def clamp(x): sorted([-1, x, 1])[1]
</code></pre>
<p>and as long as <code>sorted</code> always returns a list of the same length it started with, that works fine<a href=""#fn:clamp"">10</a>. But it only works because the Python interpreter allows you to be reckless with array indexing. Elm doesn't let you be reckless, and so Elm has no equivalent way to perform array lookup. If you tried to write the same function in the same way in Elm, the result in the compiler's eyes would not be a number but a <code>Maybe</code> number - AKA ""either a number or <code>Nothing</code>"". (<code>Nothing</code> is roughly equivalent to <code>None</code> in python or <code>null</code> in many other languages, but you have to explicitly flag when it's allowed.) When you actually run this code, you will always get a number and never <code>Nothing</code>. But the compiler can't prove that.</p>
<p>(Again, I stress that you will never get <code>Nothing</code> <em>as long as</em> your sort function always returns a list of the same length it started with. That's something you can prove for yourself, but it's not something the Elm compiler can prove. It's not even the sort of thing the Elm compiler knows can be proven. And so in turn, it can't prove that you'll never get a <code>Nothing</code> here.)</p>
<p>And then the Elm compiler would force you to account for the possibility of <code>Nothing</code>, even though there's no way that possibility could occur at runtime. One option is to pick an arbitrary result that will never be exposed. That works fine until the code goes through several layers of changes, an assumption that used to be true is now violated, and suddenly that arbitrary result is wreaking havoc elsewhere. Or in Haskell, your program is crashing at runtime.</p>
<p>To be clear, that's not significantly worse than what we get in Python, where the code can also go through several layers of changes that result in it crashing at runtime. But we were hoping for better.</p>
<p>And in this case ""better"" is easy enough, you can just write your function to avoid indexing into a list, and then it can return a number with no need for trickery. The point isn't that you can't do the thing. The point is that (a), even if the thing is safe, the compiler might not know that; (b), if you decide it's safe anyway and find some way to trick the compiler, the compiler no longer protects you; and (c), if you want to do it in a way the compiler knows is safe, you might need to put in some extra work.</p>
<p>For another example, HM type systems can't implement heterogenous lists. So this is really easy in python:</p>
<pre><code>def stringify_list(l):
    return [ repr(x) for x in l ]

stringify_list([""hello"",
                0,
                [""here's a"", ""nested list"", {""and"": ""maybe"", ""a"": ""dict""}],
                ""it can even be passed itself, like so:"",
                stringify_list])
</code></pre>
<p>but impossible in Elm. You can <em>sort of</em> get the same effect by creating a type with many constructors</p>
<pre><code>type HeteroType = HTInt Int
                | HTString String
                | HTBool Bool
                | HTList (List HeteroType)
                | ...
</code></pre>
<p>but it's not quite the same, because it can only accept types you know about in advance. Also, it's a massive pain to work with.</p>
<p>For a third example: Haskell is known for its monads. But Elm has no equivalent, because an HM type system can't support generic monad programming. You can implement the generic monad functions for specific cases, so there's <code>Maybe.map</code> and <code>List.map</code>, but there's no equivalent of Haskell's <code>fmap</code> which works on all monads.</p>
<h3>Hindley-Milner type systems</h3>
<p>I've talked about the tradeoffs that HM type systems offer, but not what HM type systems actually are. So here is where I get particularly reckless.</p>
<p>This bit is more formal than the rest. It's based on the treatment at wikipedia, but I've tried to simplify the notation. I'm aiming for something that I would have found fairly readable several months ago, but I no longer have access to that version of me.</p>
<p>Also, this part is likely to make more sense if you're familiar with at least one HM-based language. That's not a design feature, I just don't trust myself to bridge that inferential gap.</p>
<p>For an HM system, you need a language to run type inference on, and you need types to run type inference with, and you need some way to combine the two. You could use the language with no type inference, if you didn't mind crashes or weird behaviour at runtime, when you made a mistake with typing. (Haskell <a href=""https://ghc.haskell.org/trac/ghc/wiki/DeferErrorsToRuntime"">allows this</a> with a compiler option.<a href=""#fn:defer-type-errors"">11</a>) And you could run type inference without caring about the semantics of the language, treating it as essentially a SuDoku, an interesting puzzle but meaningless. (Haskell <a href=""https://stackoverflow.com/questions/12373722/make-ghc-only-type-check"">supports this</a>, too.) But by combining them, the semantics of the language are constrained by the type system, and runtime type errors are eliminated.</p>
<p><strong>Types</strong></p>
<p>Types come in a conceptual hierarchy which starts with <strong>type constants</strong>. That's things like, in Elm, <code>Int</code>, <code>Float</code>, <code>Bool</code>, <code>String</code>, <code>Date</code>, <code>()</code>. It also includes type variables, which in Elm are notated with initial lower-case, like <code>a</code> and <code>msg</code>. (Though the type variables <code>number</code>, <code>comparable</code> and <code>appendable</code> are special cases that I won't cover here.)</p>
<p>Next in the type hierarchy is <strong>applied types</strong>. Here a ""type function"" is applied to arguments, which are type constants and/or other applied types. These are things like <code>List Int</code>, <code>Maybe (List Float)</code>, <code>Result () Date</code>, and <code>a -&gt; String</code>. (In that last one, the type function is the arrow; Haskell would allow you to write it <code>(-&gt;) a String</code>. Also, <code>(-&gt;)</code> is the only type that HM specifically requires to exist.) Notably, an applied type must have a specific named type function as its root; you can't have <code>m Int</code>, which you would need for generalised monads.</p>
<p>Type constants and applied types are <strong>monotypes</strong>. You get a <strong>polytype</strong> by optionally sticking one or more ""∀""s in front of a monotype. So for example <code>a -&gt; Int</code> is a monotype, but <code>∀a. a -&gt; Int</code> is a polytype. So is <code>∀a. ∀b. a -&gt; Int -&gt; b</code>, which is written equivalently as <code>∀a b. a -&gt; Int -&gt; b</code>. <code>∀b. a -&gt; Int</code> is also a polytype; since the quantified variable doesn't show up, it's equivalent to the monotype <code>a -&gt; Int</code>. We can do something like that to any monotype, so for simplicity we might as well decide that monotypes count as a special case of polytypes, not as a distinct set.</p>
<p>Type signatures in Elm typically have an implied ""∀"" over whichever variables it makes sense to quantify. (There's no syntax for explicitly writing the ""∀"".) So the type of <code>List.map</code> would be written</p>
<p><code>map : (a -&gt; b) -&gt; List a -&gt; List b</code></p>
<p>but I'll be writing</p>
<p><code>map : ∀a b. (a -&gt; b) -&gt; List a -&gt; List b</code></p>
<p>for clarity. Because there's one place where Elm <em>doesn't</em> give an implied ∀, which is when you have scoped types. To demonstrate by example,</p>
<pre><code>const : ∀a b. a -&gt; b -&gt; a
const x = let foo : b -&gt; a
              foo y = x
           in foo
</code></pre>
<p><code>const</code> has a polytype here, but <code>foo</code> has a monotype, because (in context) its argument type and return type are constrained. If you tried to swap <code>a</code> and <code>b</code> in the type signature for <code>foo</code>, or rename either of them, the Elm compiler would complain.</p>
<p><strong>Language</strong></p>
<p>The <strong>language</strong> has four kinds of expression, and each has a rule relating it to the type system. You need variables and constants, function calls, lambda expressions, and let statements.</p>
<p><strong>Variables and constants</strong></p>
<p>Variables and constants are things like <code>True</code>, <code>0.2</code>, <code>Just</code>, <code>""Hello""</code>, <code>[]</code>, <code>()</code>, <code>List.map</code>. Each of these has a declared type, which in Elm is notated with <code>:</code>. So <code>True : Bool</code>, <code>0.2 : Float</code>, <code>Just : ∀a. a -&gt; Maybe a</code>, <code>""Hello"": String</code>, <code>[] : ∀a. List a</code>, <code>() : ()</code>, <code>List.map : ∀a b. (a -&gt; b) -&gt; List a -&gt; List b</code>.</p>
<p>The rule that relates these to the type system is that <em>type declarations imply type judgments</em>. Mathematically it looks like</p>
<p><span class=""mjpage mjpage__block""><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label="" \frac{x : π \quad π ⊑ μ}{x \sim μ}. ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 5.682em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""width: 5.682em; top: -1.442em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">π</span></span></span></span><span class=""mjx-mspace"" style=""width: 1em; height: 0px;""></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">π</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">⊑</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span><span class=""mjx-denominator"" style=""width: 5.682em; bottom: -0.927em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 5.682em;"" class=""mjx-line""></span></span><span style=""height: 2.369em; vertical-align: -0.927em;"" class=""mjx-vsize""></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span></span></span></span></span></p>
<p>Reading clockwise from top left, this says: if you have a variable <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> declared to have some polytype <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""π""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">π</span></span></span></span></span></span></span></span>, and if the monotype <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span> is a specialisation of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""π""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">π</span></span></span></span></span></span></span></span>, then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> can be judged to have type <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span>. (<span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""π""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">π</span></span></span></span></span></span></span></span> always denotes a polytype, and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span> always denotes a monotype.)</p>
<p>A type <em>judgment</em>, as opposed to a declaration, provides a type that an expression can be used as. A judgment is always as a monotype.</p>
<p>And type specialisation, denoted <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""⊑""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">⊑</span></span></span></span></span></span>, is the process of replacing quantified variables with less-quantified ones. So for example the type <code>∀a b. a -&gt; b -&gt; a</code> might be specialized to <code>∀a. a -&gt; String -&gt; a</code>, or to <code>∀b. Int -&gt; b -&gt; Int</code>; and from either of those, it could be further specialised to <code>Int -&gt; String -&gt; Int</code>. Of course <code>String -&gt; Int -&gt; String</code> and <code>List Float -&gt; (Float -&gt; String) -&gt; List Float</code> are valid specialisations too.</p>
<p>Thus: we have the type declaration <code>[] : ∀a. List a</code>, and we have <code>(∀a. List a) ⊑ List Int</code>, and so we can form the type judgment <code>[] ~ List Int</code>. We also have <code>(∀a. List a) ⊑ List String</code>, and so <code>[] ~ List String</code>. And <code>[] ~ List (List (Maybe Bool))</code>, and so on.</p>
<p><strong>Function calls</strong></p>
<p>Function calls are things like <code>not True</code>, <code>(+ 1)</code>, <code>List.Map Just</code>. And the rule relating them to the type system is that <em>function calls consume function types</em>. This is the simplest of the rules. Mathematically it looks like</p>
<p><span class=""mjpage mjpage__block""><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label="" \frac{f \sim μ → μ' \quad v \sim μ}{f v \sim μ'}. ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 8.496em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""width: 8.496em; top: -1.558em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span><span class=""mjx-mspace"" style=""width: 1em; height: 0px;""></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">v</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span><span class=""mjx-denominator"" style=""width: 8.496em; bottom: -1.011em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">v</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 8.496em;"" class=""mjx-line""></span></span><span style=""height: 2.569em; vertical-align: -1.011em;"" class=""mjx-vsize""></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span></span></span></span></span></p>
<p>Or: if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> can be judged to have a function type <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ → μ'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>, and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""v""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">v</span></span></span></span></span></span> can be judged to have type <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span>, then the function call <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""fv""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">v</span></span></span></span></span></span> can be judged to have type <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>.</p>
<p>Thus: we can infer the type judgment <code>toString ~ (Int -&gt; String)</code>, and we can infer <code>3 ~ Int</code>, and so we can infer <code>toString 3 ~ String</code>.</p>
<p>Also, we can infer <code>List.map ~ ((Int -&gt; Maybe Int) -&gt; (List Int -&gt; List (Maybe Int)))</code>, and we can infer <code>Just ~ (Int -&gt; Maybe Int)</code>. So we can infer <code>List.map Just ~ (List Int -&gt; List (Maybe Int))</code></p>
<p><strong>Lambda expressions</strong></p>
<p>Lambda expressions are things like <code>\x -&gt; Just x</code>, and in Elm they're used implicitly when something like <code>const x y = x</code> is turned into <code>const = \x -&gt; \y -&gt; x</code>. The type system rule is that <em>lambda expressions produce function types</em>. Mathematically:</p>
<p><span class=""mjpage mjpage__block""><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label="" \frac{x : μ ⇒ e \sim μ'}{λx.e \sim μ → μ'}. ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 6.591em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""width: 6.591em; top: -1.558em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⇒</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span class=""mjx-denominator"" style=""width: 6.591em; bottom: -1em;""><span class=""mjx-mrow""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 6.591em;"" class=""mjx-line""></span></span><span style=""height: 2.558em; vertical-align: -1em;"" class=""mjx-vsize""></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span></span></span></span></span></p>
<p>Or: suppose that the type declaration <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x : μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span> would allow us to infer the judgment <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e \sim μ'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>. In that case, we could judge that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""λx.e \sim (μ → μ)'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>.</p>
<p>Typically <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> would be some expression mentioning the variable <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, but it's no problem if not. In that case, if you can get <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e \sim μ'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span> at all, you can get it assuming any <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x : μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span>, and so you have <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""λx.e \sim (\mathtt{Int} → μ')""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">I</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""λx.e \sim (\mathtt{String} → μ')""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">S</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">r</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">g</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""λx.e \sim (\mathtt{Result\ String\ (List\ (Maybe\ Float))} → μ')""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">u</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">S</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">r</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">g</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">L</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">M</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">y</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">)</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> and so on.</p>
<p>Thus: given the declaration <code>x : Int</code>, we can infer the judgment <code>[x] ~ List Int</code>. And so we can infer the judgment <code>(\x -&gt; [x]) ~ (Int -&gt; List Int)</code>.</p>
<p><strong>Let expressions</strong></p>
<p>Let expressions read like <code>let x = y in a</code>. Semantically, this is very similar to using a lambda expression, <code>(\x -&gt; a) y</code>. But HM treats them differently in the type system, allowing a let expression to introduce polytypes. That permits code like</p>
<pre><code>let f x = [x]
in (f """", f True)
-- returns ([""""], [True])
</code></pre>
<p>If you tried to rewrite this as a lambda, you would get</p>
<pre><code>(\f -&gt; (f """", f True))(\x -&gt; [x])
</code></pre>
<p>But type inference fails here, because there's no monotype declaration for <code>f</code> that allows a type judgment for <code>(f """", f True)</code>. So the precondition for the lambda rule never obtains, and so in turn, no type judgment can be made for the expression <code>\f -&gt; (f """", f True)</code>.</p>
<p>Let expressions compensate for this deficiency, with the rule <em>let expressions are like polymorphic lambda applications</em>. (I don't have a good name for it.) Mathematically:</p>
<p><span class=""mjpage mjpage__block""><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label="" \frac{a \sim μ \quad x : \bar{μ} ⇒ b \sim μ'}
        {(\mathtt{let}\ x = a\ \mathtt{in}\ b) \sim μ'} ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 9.825em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""width: 9.825em; top: -1.558em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mspace"" style=""width: 1em; height: 0px;""></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.096em; padding-bottom: 0.06em; padding-left: 0.079em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">¯</span></span></span><span class=""mjx-op""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⇒</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span class=""mjx-denominator"" style=""width: 9.825em; bottom: -1.09em;""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span></span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 9.825em;"" class=""mjx-line""></span></span><span style=""height: 2.648em; vertical-align: -1.09em;"" class=""mjx-vsize""></span></span></span></span></span></span></p>
<p>Or: suppose that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span> can be judged to have type <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span>, and that the declaration <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x : \bar{μ}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.096em; padding-bottom: 0.06em; padding-left: 0.079em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">¯</span></span></span><span class=""mjx-op""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span></span></span></span></span></span> would allow us to infer the judgment <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b \sim μ'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>. In that case, we could judge that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(\mathtt{let}\ x = a\ \mathtt{in}\ b)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span></span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> has type <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>.</p>
<p>This introduces the notation <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bar{μ}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.096em; padding-bottom: 0.06em; padding-left: 0.079em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">¯</span></span></span><span class=""mjx-op""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span></span></span></span></span></span>, which generalises a monotype to a polytype. How it works is: if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""μ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span> mentions a type variable <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span>, and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span> isn't quantified over in the surrounding context, then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bar{μ}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.096em; padding-bottom: 0.06em; padding-left: 0.079em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">¯</span></span></span><span class=""mjx-op""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span></span></span></span></span></span> contains a ""<span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""∀a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∀</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span>"".</p>
<p>Thus: we can infer <code>(\x -&gt; [x]) ~ (a -&gt; List a)</code>, where <code>a</code> is a type variable unused in the surrounding context. That type generalises to <code>∀a. a -&gt; List a</code>. And given the declaration <code>f : ∀a. a -&gt; List a</code>, we can infer <code>(f """", f True) ~ (List String, List Bool)</code>. So in total, we can infer</p>
<p><span class=""mjpage mjpage__block""><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label="" (\mathtt{let\ f\ x\ =\ [x]\ in\ (f\ &quot;&quot;,\ f\ True)})
   \sim \mathtt{(List\ String,\ List\ Bool)}. ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.225em;"">f</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">x</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">=</span></span><span class=""mjx-mtext MJXc-space3""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">]</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.225em;"">f</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.225em;"">""<span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em;"">""</span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""margin-top: -0.07em; padding-bottom: 0.372em;"">,</span></span><span class=""mjx-mtext MJXc-space1""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.225em;"">f</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">T</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">r</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">u</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">)</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">L</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">S</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">r</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""margin-top: -0.07em; padding-bottom: 0.372em;"">,</span></span><span class=""mjx-mtext MJXc-space1""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">L</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">s</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mtext""><span class=""mjx-char"" style=""margin-top: -0.217em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-type-R"" style=""padding-bottom: 0.233em; margin-right: 0.275em;"">&nbsp;</span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">B</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.519em; padding-bottom: 0.372em;"">)</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span></span></span></span></span></p>
<p>(It seems a little strange to me that the approach here is to first construct a meaningless type, and then quantify over it. Still, that's my understanding. It's of course possible I'm mistaken.)</p>
<p>Why do we need both <code>let</code> and lambda? Well, we can't replace lambda expressions with let expressions: they're not re-usable. (When you translate a let expression into a lambda expression, you actually generate a lambda <em>applied to an argument</em>. There's no way to translate a lambda expression by itself into a let expression.) Meanwhile, I'm not entirely sure why we can't make lambdas polymorphic in the same way let expressions are. I think the answer is that if we tried it, we'd lose some of the legibility that HM offers - so let can be more powerful in the type system because it's less powerful in the language. But I'm not sure exactly what legibility would be lost.</p>
<p><strong>Recursion</strong></p>
<p>There's an interesting thing about the system I just described: it may or may not be Turing complete.</p>
<p>The problem is that there's no specified way of doing recursion. A function can't call itself, and it can't call any other function that can call it.</p>
<p>But a <a href=""https://en.wikipedia.org/wiki/Fixed-point_combinator"">fixed-point combinator</a> allows recursion, and might be included in the initial set of variables. Failing that, the proper recursive types can be used to define one. (Elm and Haskell <a href=""http://rosettacode.org/wiki/Y_combinator"">allow us</a> to define such types<a href=""#fn:brag"">12</a>.)</p>
<p>Failing both of those, we can introduce a new kind of expression</p>
<p><span class=""mjpage mjpage__block""><span class=""mjx-chtml MJXc-display"" style=""text-align: center;""><span class=""mjx-math"" aria-label="" \frac{x : μ ⇒ a \sim μ \quad x : \bar{μ} ⇒ b \sim μ'}
        {(\mathtt{letrec}\ x = a\ \mathtt{in}\ b) \sim μ'}. ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 13.389em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""width: 13.389em; top: -1.558em;""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⇒</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span><span class=""mjx-mspace"" style=""width: 1em; height: 0px;""></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.096em; padding-bottom: 0.06em; padding-left: 0.079em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">¯</span></span></span><span class=""mjx-op""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">⇒</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span class=""mjx-denominator"" style=""width: 13.389em; bottom: -1.09em;""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">l</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">r</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">c</span></span></span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-type-R"" style=""padding-top: 0.225em; padding-bottom: 0.225em;"">n</span></span></span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.291em; padding-bottom: 0.372em;"">&nbsp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">∼</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em;"">μ</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.409em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 13.389em;"" class=""mjx-line""></span></span><span style=""height: 2.648em; vertical-align: -1.09em;"" class=""mjx-vsize""></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span></span></span></span></span></p>
<p>This is much the same as <code>let</code>, but makes the variable <code>x = a</code> available when evaluating <code>a</code>. It's only available as a monotype when evaluating <code>a</code>, and still doesn't get generalised to a polytype until evaluating <code>b</code>.</p>
<p>(Elm and Haskell provide <code>letrec</code> as <code>let</code> and don't provide simple <code>let</code> at all.)</p>
<p>But if an HM language doesn't provide the appropriate variables or types, and doesn't implement <code>letrec</code> or something similar, it won't be Turing complete. Legibility gain, expressivity cost.</p>
<h3>Wrapping up</h3>
<p>And modulo some small details, that's the entirety of a Hindley-Milner type system. If you have a language with those features, and a suitable set of types, you can perform type inference.</p>
<p>What we have is a set of rules that allows us to construct proofs. That is, if we look at a program written in this language, we would be able to construct a proof of its type (or lack thereof). But I already said HM is better than that: it lets us <em>mechanically</em> construct a proof, in (roughly) linear time.</p>
<p>I confess, I'm not entirely sure how to do that. The outline is obvious, recurse down the parse tree and at each step apply the appropriate rule. But since a constant can be judged as one of many types, you need to keep track of which types are acceptable. Wikipedia hints at how it works, but not in a way that I understand particularly well.</p>
<p>Elm and Haskell both support many things not covered so far. To look at some of them briefly, and occasionally getting even more recklesss,</p>
<ul>
<li>
<p>It seems obvious, but both allow you to evaluate the language, something I haven't touched on much. And it does need to be touched on, because there's more than one way to do it. Haskell uses a lazy evaluation model, while Elm is strict.</p>
</li>
<li>
<p>Both have ways to introduce new types. That doesn't change what we've seen, but it does separate the languages into two parts. One part describes the types used in a program and one part implements the semantics of a program.</p>
</li>
<li>
<p>Both also support case statements along with destructuring, like</p>
</li>
</ul>
<pre><code>mHead : Maybe (List a) -&gt; Result Bool a
mHead ml = case ml of
    Just (a::_) -&gt; Ok a
    Just _ -&gt;     Err True
    Nothing -&gt;    Err False
</code></pre>
<p>To implement these, you'd want to add a fifth class of language expression. But I think it would be possible in theory to write a ""thin"" first-pass compiler to translate these statements into the existing language. By ""thin"" I mean to do this in such a way that we don't lose any of the legibility guarantees we care about.<a href=""#fn:case-compiled"">13</a> (For example, if this compiler turned <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> bytes of code in a case statement into more than <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O(n)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> bytes of code in the base language, or if it ran in more than O(n) time, this condition would fail.)</p>
<p>If I'm right about that, then case statements neither make the language more expressive nor less legible, at least in one important sense.</p>
<ul>
<li>
<p>(By comparison, if-then-else statements are also another class of language expression, but one which can obviously be thinly compiled down to the existing ones.)</p>
</li>
<li>
<p>In the type system, Elm supports record types, which are a lot like tuples but with nicer syntax. I believe these too could be thinly compiled down. But it also supports <em>extensible</em> records, which are more complicated. On one level you can think of a type like <code>{a | x : Int, y : Int}</code> like a tuple <code>∀a. (a, Int, Int)</code>. But then this tuple needs to be unpacked and manipulated when you pass it into a function expecting an <code>{a | x : Int}</code>.</p>
<p>I believe this is unresolvable, and extensible records represent an extension of Elm from HM. (But one with fairly minor legibility costs, in comparison to the expressiveness gains.)</p>
</li>
<li>
<p>Haskell supports typeclasses, which are a way of allowing functions to operate on multiple different types. (For example, the <code>show</code> function can be applied to a <code>String</code>, an <code>Int</code>, a <code>()</code>, a <code>[Float]</code>, ….) Elm doesn't, but simple typeclasses can be emulated with only a little added verbosity.</p>
</li>
</ul>
<p>Another thing I'll say is that I've been talking about legibility and expressivity of a language. But a type system is itself a language, and may be more or less legible and expressive. I don't have a strong intuition for how these interact.</p>
<p>There's a lot more I could add to this post. Some things that I omitted for brevity, some that I omitted because I don't know enough about them yet<a href=""#fn:enough"">14</a>, and some that I omitted because I don't know about them at all. I don't know what a sensible cutoff point is, so I'm just going to end it here.</p>
<p>From writing my original talk, and subsequently this blog post, I think I understand HM type systems much better than I used to. Hopefully you think the same. Hopefully we're both correct. If you see any inaccuracies, please point them out.</p>
<hr>
<ol>
<li>
<p>While writing this essay I came across the talk <a href=""https://www.youtube.com/watch?v=GqmsQeSzMdwz"">Constraints Liberate, Liberties Constrain</a>. From the title and the context I encountered it, it sounds like it's on the same subject. But I haven't watched it, because it's in the form of a 50 minute video. <a href=""#fnref:constraints-liberties"">↩</a></p>
</li>
<li>
<p>If the halting problem is decideable on a language, the language is Turing incomplete. I don't know whether the reverse is true: are there Turing incomplete languages on which the halting problem is still undecideable? I'm mostly going to assume not. At any rate, I don't think I'm going to discuss any such languages. <a href=""#fnref:incomplete"">↩</a></p>
</li>
<li>
<p>To nitpick myself: these aren't just languages for which you can prove termination, they're languages which never terminate, at least not for finite inputs. I don't offhand know any languages which are Turing incomplete but have the ability to loop forever, though such a thing can exist. <a href=""#fnref:nonterminating"">↩</a></p>
</li>
<li>
<p>Specifically, it looks to me like SQL-99 without recursive common table expressions is Turing incomplete. I've only ever used nonrecursive CTEs. <a href=""#fnref:recursive-cte"">↩</a></p>
</li>
<li>
<p>I've subsequently discovered that wikipedia uses <a href=""https://en.wikipedia.org/wiki/Expressive_power_(computer_science)"">the same name</a> for this concept. <a href=""#fnref:expressive"">↩</a></p>
</li>
<li>
<p>I think this is related to the way that ZF set theory can encode Peano arithmetic. Thus, ZF is more expressive than PA. But because ZF allows you to construct objects that PA doesn't, there are more things you can say about ""all objects in PA"" than about ""all objects in ZF"". So PA is more legible than ZF. I don't understand the <a href=""https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence"">Curry-Howard correspondence</a>, but I think that's related too. <a href=""#fnref:zfpa"">↩</a></p>
</li>
<li>
<p>""My company"" is a phrase which sometimes means ""the company I own or run"" and sometimes ""the company I work for"". Here it means <a href=""https://proda.ai"">the latter</a>. I don't know an unambigous way to phrase that which I don't find slightly awkward, so instead I'm using a super-awkward footnote. But, y'know. Ironically, or something. <a href=""#fnref:my-company"">↩</a></p>
</li>
<li>
<p>We use Elm 0.18. 0.19 is a fairly significant version change, but I think not different enough to be relevant for this post. <a href=""#fnref:elm18"">↩</a></p>
</li>
<li>
<p>Specifically <a href=""https://en.wikipedia.org/wiki/Glasgow_Haskell_Compiler"">GHC</a>, which offers many extensions over Haskell proper. Whenever I refer to Haskell, I'm really talking about the language that GHC implements. <a href=""#fnref:ghc"">↩</a></p>
</li>
<li>
<p>At any rate, it works fine when you pass it a number. If you pass it something else, it might do anything. <a href=""#fnref:clamp"">↩</a></p>
</li>
<li>
<p>Well, sort of. It still performs type inference, it just allows it to fail. I'm not sure if ""no type inference at all"" would work for Haskell; but I do think it would work for a pure HM system, if you count things like ""<code>3</code> is of type <code>Int</code>"" as a raw fact, non-inferred. <a href=""#fnref:defer-type-errors"">↩</a></p>
</li>
<li>
<p>Minor brag: I myself contributed the Elm implementation on that page. <a href=""#fnref:brag"">↩</a></p>
</li>
<li>
<p>I think it might look something like this:</p>
</li>
</ol>
<pre><code>mHead ml =
    if *isJust ml &amp;amp;&amp;amp; (*fromJust ml (\_x -&gt; *isCons _x)) then
        *fromJust ml (\_x -&gt; *fromCons _x (\a _ -&gt; Ok a))
    else if *isJust ml then
        *fromJust ml (\_ -&gt; Err True)
    else if *isNothing ml then
        Err False
    else
        *fail
</code></pre>
<p>functions marked with a <code>*</code> can be hidden from the language user. Additionally, <code>*fromJust</code>, <code>*fromCons</code> and <code>*fail</code> would be able to throw runtime errors. These don't violate Elm's ""no runtime errors"" policy, because the compiler would only generate them in contexts where it could prove they wouldn't throw. (In the case of <code>*fail</code>, when it could prove that code branch was unreachable, so it could also just not bother.)</p>
<p>I'm very much spitballing here. I wouldn't be surprised to discover that the approach I've described is completely unworkable. <a href=""#fnref:case-compiled"">↩</a></p>
<ol start=""14"">
<li>Not that that stopped me from writing this entire post. <a href=""#fnref:enough"">↩</a></li>
</ol>
</body></html>",philh,philh,philh,
KxnGu8idv7tPEuqwx,"Gwern's ""Why Tool AIs Want to Be Agent AIs: The Power of Agency"" ",gwern-s-why-tool-ais-want-to-be-agent-ais-the-power-of,https://www.lesswrong.com/posts/KxnGu8idv7tPEuqwx/gwern-s-why-tool-ais-want-to-be-agent-ais-the-power-of,2019-05-05T05:11:45.805Z,27,10,3,False,False,https://www.gwern.net/Tool-AI,"<p>I somehow hadn&#x27;t read this post until now, so I am posting this here in case I am not the only one (and I wasn&#x27;t able to find a previous linkpost for it). Relevant to relatively recent discussion on AI-as-a-service, but also just good as a broad reference. </p>",habryka4,habryka4,habryka,
P5oRDmQugJzSRRhu7,345M version GPT-2 released,345m-version-gpt-2-released,https://www.lesswrong.com/posts/P5oRDmQugJzSRRhu7/345m-version-gpt-2-released,2019-05-05T02:49:48.693Z,37,12,0,False,False,https://openai.com/blog/better-language-models/#update,<p>OpenAI has released a larger GPT-2 model for public testing. They&#x27;ve also released the two larger models to select groups for experimenting.</p>,,,,
viou3zpFHSZS8ugc4,"Is value drift net-positive, net-negative, or neither?",is-value-drift-net-positive-net-negative-or-neither,https://www.lesswrong.com/posts/viou3zpFHSZS8ugc4/is-value-drift-net-positive-net-negative-or-neither,2019-05-05T02:37:40.880Z,5,4,3,False,True,,"<p><em><a href=""https://forum.effectivealtruism.org/posts/Ly7diLpRmKEigFpde/is-value-drift-net-positive-net-negative-or-neither"">Crossposted</a> from the EA forum</em></p><p>I&#x27;ve been asked variations of this question a few times recently, as I&#x27;m studying value drift for my undergraduate thesis, so I thought I would seek out others&#x27; thoughts on this.</p><p>I suppose part of this depends on how we define value drift. I&#x27;ve seen value drift defined as broadly as changes in values (from the <a href=""http://globaloptimum.libsyn.com/value-drift-how-to-not-be-evil-part-i"">Global Optimum podcast</a>) and as narrowly as becoming less motivated to do altruistic things over time (from <a href=""https://forum.effectivealtruism.org/posts/mZWFEFpyDs3R6hD3r/empirical-data-on-value-drift"">Joey Savoie&#x27;s forum post</a>). While the latter seems almost certainly net-negative, how the former plays out is a little less clear to me.</p><p>This leads me to wonder if there might be different kinds of value drift that may be varying degrees of good or bad.</p><p>Thoughts?</p>",MarisaJurczyk,marisajurczyk,MarisaJurczyk,
ZQJ9H9ZeRF8mjB2aF,[AN #55] Regulatory markets and international standards as a means of ensuring beneficial AI,an-55-regulatory-markets-and-international-standards-as-a,https://www.lesswrong.com/posts/ZQJ9H9ZeRF8mjB2aF/an-55-regulatory-markets-and-international-standards-as-a,2019-05-05T02:20:01.030Z,17,6,2,False,False,,"<p>Find all Alignment Newsletter resources <u><a href=""http://rohinshah.com/alignment-newsletter/"">here</a></u>. In particular, you can <u><a href=""http://eepurl.com/dqMSZj"">sign up</a></u>, or look through this <u><a href=""https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing"">spreadsheet</a></u> of all summaries that have ever been in the newsletter.</p><p>The improvements to the newsletter continue! <strong>Rob Miles has generously volunteered to make the <u><a href=""http://alignment-newsletter.libsyn.com/"">Alignment Newsletter Podcast</a></u>.</strong> Chances are that the podcast will trail a week behind the emails, unless I manage to get my act together and give Rob a preview of the newsletter in advance.</p><h2><strong>Highlights</strong></h2><p><u><a href=""https://www.fhi.ox.ac.uk/standards-technical-report/"">Standards for AI Governance: International Standards to Enable Global Coordination in AI Research &amp; Development</a></u> <em>(Peter Cihon)</em>: This technical report argues that we can have an outsized impact on the future of AI by influencing standards on AI so that they help ensure that AI systems are safe and beneficial, in addition to making the deployment of AI more efficient. A standard here could be a product like Tensorflow or Gym, or a process like <u><a href=""https://ai.google/education/responsible-ai-practices"">this list</a></u>. It&#x27;s particularly useful to focus on international standards: since corporations can simply leave the country to escape national regulations, there is a race to the bottom on the stringency of national standards, and so they can&#x27;t effect as much change.</p><p>It may be particularly valuable to influence existing organizations that set standards because they are very responsive to expert opinion. It is also possible to develop a standard privately, and then &quot;convert&quot; it into an international standard. (This happened with the C programming language and the PDF file format.) Such influence can be used to change the culture around AI development, e.g. to put safety more at the forefront.</p><p><strong>Rohin&#x27;s opinion:</strong> I would guess that the most influential standards are &quot;network standards&quot; like Tensorflow: they make it easier for everyone to develop AI systems. However, the benefit here is in having any standard at all, and so it seems unlikely that such standards could also effect a change in culture that&#x27;s unrelated to the efficiency aspect of the standard. That said, the report convinced me that &quot;enforced standards&quot; are also impactful: even if the standard requires active enforcement to prevent organizations from ignoring it, organizations will often choose to comply with the standard in order to get a certification that builds consumer trust in them.</p><p><u><a href=""https://drive.google.com/uc?export=download&id=1bFPiwLrZc7SQTMg2_bW4gt0PaS5NyqOH"">Regulatory Markets for AI Safety</a></u> <em>(Jack Clark et al)</em>: This paper presents an idea on how AI could be regulated: by the introduction of a <strong>market of private regulators</strong> that themselves are regulated by the government. Companies would be required by law to purchase regulatory services, but could choose which regulator they purchase from. The regulators compete to attract companies, but are all required to meet goals set by the government.</p><p>The key benefit of such an approach is that the government now only needs to set <strong>goals</strong> for regulation (e.g. for self-driving cars, a limit on the rate of accidents) while offloading to private regulators the regulations on <strong>processes</strong> (e.g. required adversarial training on the vision models employed in self-driving cars). This relieves the burden on government, which is currently too slow-moving to effectively regulate AI. It gets the best of both worlds: as with government regulation, it can optimize for the public good, and as with tech self-regulation, it can have best practices emerge from the researchers who know best (since they can build their own regulatory startups).</p><p>Of course, for this to work, it is crucial that the private regulators avoid regulatory capture, and that <strong>the market for regulators is competitive and independent</strong>.</p><p><strong>Rohin&#x27;s opinion:</strong> This seems very related to the notion of an &quot;enforced standard&quot; in the previous paper, though here it is only necessary to enforce a <em>goal</em> across everyone, and the details of processes can vary across regulators. I especially like the scenario in which regulators emerge &quot;bottom-up&quot; from researchers thinking about potential problems with AI, though I&#x27;m not sure how likely it is.</p><p>With both this and the previous paper, I can see how they would apply to e.g. self-driving cars and adversarial robustness, but it&#x27;s less clear to me how such an approach can help with AI alignment. If we believe that alignment is really hard and we only get one shot at it, then it seems especially difficult to have legible regulations that ensure, <strong>without any testing</strong>, that we don&#x27;t build a misaligned superintelligent AI. Alternatively, if we believe that we will have lots of non-catastrophic experience with aligning AI systems, and can iterate on our processes, then it seems more likely that we could develop useful, legible regulations. (I am more inclined to believe this latter scenario, based on <u><a href=""https://www.fhi.ox.ac.uk/reframing/"">CAIS</a></u> (<u><a href=""https://mailchi.mp/b649f32b07da/alignment-newsletter-40"">AN #40</a></u>) and other intuitions.) Even in this scenario I don&#x27;t yet know what regulations I would place, but it seems likely that with more experience we would be able to develop such regulations.</p><h1><strong>Technical AI alignment</strong></h1><h3><strong>Technical agendas and prioritization</strong></h3><p><u><a href=""https://www.youtube.com/watch?v=AMSKIDEbjLY"">Overview of AGI Safety Research Agendas</a></u> <em>(Rohin Shah)</em>: The video from my talk at the Beneficial AGI conference has just been released. In this talk, I cover five broad safety-related areas that people are investing: understanding the future of AI (<u><a href=""https://www.alignmentforum.org/posts/p7x32SEt43ZMC9r7r/embedded-agents"">embedded agency</a></u> (<u><a href=""https://mailchi.mp/7d0e3916e3d9/alignment-newsletter-31"">AN #31</a></u>), <u><a href=""https://www.fhi.ox.ac.uk/reframing/"">CAIS</a></u> (<u><a href=""https://mailchi.mp/b649f32b07da/alignment-newsletter-40"">AN #40</a></u>)), limiting the influence of an AI system (<u><a href=""https://www.alignmentforum.org/posts/pZhDWxDmwzuSwLjou/asymptotically-benign-agi"">boxing</a></u> (<u><a href=""https://mailchi.mp/3e2f43012b07/an-54-boxing-a-finite-horizon-ai-system-to-keep-it-unambitious"">AN #54</a></u>), <u><a href=""https://medium.com/@deepmindsafetyresearch/designing-agent-incentives-to-avoid-side-effects-e1ac80ea6107"">impact regularization methods</a></u> (<u><a href=""https://mailchi.mp/efed27be268a/alignment-newsletter-49"">AN #49</a></u>)), robustness (<u><a href=""https://arxiv.org/abs/1801.09344"">verification</a></u> (<u><a href=""https://mailchi.mp/4b19d2caa5a9/alignment-newsletter-19"">AN #19</a></u>), <u><a href=""https://ai-alignment.com/red-teams-b5b6de33dc76"">red teaming</a></u>), helpful AI systems (<u><a href=""https://www.alignmentforum.org/posts/5eX8ko7GCxwR5N9mN/what-is-ambitious-value-learning"">ambitious value learning</a></u> (<u><a href=""https://mailchi.mp/7d0e3916e3d9/alignment-newsletter-31"">AN #31</a></u>), <u><a href=""https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/"">preference learning</a></u>, <u><a href=""https://bair.berkeley.edu/blog/2017/08/17/cooperatively-learning-human-values/"">Cooperative IRL</a></u>, <u><a href=""https://www.alignmentforum.org/posts/fkLYhTQteAu5SinAc/corrigibility"">corrigibility</a></u> (<u><a href=""https://mailchi.mp/bbd47ba94e84/alignment-newsletter-35"">AN #35</a></u>), <u><a href=""https://www.alignmentforum.org/posts/DFkGStzvj3jgXibFG/factored-cognition"">factored cognition</a></u> (<u><a href=""https://mailchi.mp/6751e45fbb48/alignment-newsletter-36"">AN #36</a></u>), <u><a href=""https://www.alignmentforum.org/s/EmDuGeRw749sD3GKd"">iterated amplification</a></u>, <u><a href=""https://blog.openai.com/debate/"">debate</a></u> (<u><a href=""https://mailchi.mp/0ae5d69de63b/alignment-newsletter-5"">AN #5</a></u>)) and <u><a href=""https://distill.pub/2019/activation-atlas/"">interpretability</a></u> (<u><a href=""https://mailchi.mp/efed27be268a/alignment-newsletter-49"">AN #49</a></u>). My <u><a href=""https://futureoflife.org/2019/04/11/an-overview-of-technical-ai-alignment-with-rohin-shah-part-1/"">podcast</a></u> (<u><a href=""https://mailchi.mp/3e2f43012b07/an-54-boxing-a-finite-horizon-ai-system-to-keep-it-unambitious"">AN #54</a></u>) covers almost all of this and more, so you may want to listen to that instead.</p><p><u><a href=""https://www.youtube.com/channel/UC-rCCy3FQ-GItDimSR9lhzw"">FLI&#x27;s YouTube channel</a></u></p><h3><strong>Preventing bad behavior</strong></h3><p><u><a href=""https://www.alignmentforum.org/posts/KoEY9CjrKe93ErYhd/self-confirming-predictions-can-be-arbitrarily-bad"">Self-confirming predictions can be arbitrarily bad</a></u> and <u><a href=""https://www.alignmentforum.org/posts/i2dNFgbjnqZBfeitT/oracles-sequence-predictors-and-self-confirming-predictions"">Oracles, sequence predictors, and self-confirming predictions</a></u> <em>(Stuart Armstrong)</em>: Let&#x27;s consider an oracle AI system tasked with accurate prediction, with a strong enough world model that it could understand how its prediction will affect the world. In that case, &quot;accurate prediction&quot; means giving a prediction P such that the world ends up satisfying P, <em>given</em> the knowledge that prediction P was made. There need not be a single correct prediction -- there could be no correct prediction (imagine predicting what I will say given that I commit to saying something different from what you predict), or there could be many correct predictions (imagine instead that I commit to say whatever you predict). These self-confirming predictions could be arbitrarily bad.</p><p>Part of the point of oracles was to have AI systems that don&#x27;t try to affect the world, but now the AI system will learn to manipulate us via predictions such that the predictions come true. Imagine for example the self-confirming prediction where the oracle predicts zero profit for a company, which causes the company to shut down.</p><p>In order to fix this, we could have <em>counterfactual oracles</em>, which predict what would have happened in a counterfactual where the prediction couldn&#x27;t affect the world. In particular, we ask the oracle to predict the future <strong>given that the prediction will immediately be erased and never be read by anyone</strong>. We can also use this to tell how much the prediction can affect us, by looking at the difference between the unconditional prediction and the prediction conditioned on erasure.</p><p><strong>Read more:</strong> <u><a href=""https://arxiv.org/abs/1711.05541"">Good and safe uses of AI Oracles</a></u></p><h1><strong>AI strategy and policy</strong></h1><p><u><a href=""https://www.vox.com/future-perfect/2019/4/3/18292526/google-ai-ethics-board-letter-acquisti-kay-coles-james"">Google’s brand-new AI ethics board is already falling apart</a></u> <em>(Kelsey Piper)</em>: Google <u><a href=""https://www.blog.google/technology/ai/external-advisory-council-help-advance-responsible-development-ai/"">announced</a></u> an ethical advisory council, that quickly became controversial, and was then <u><a href=""https://www.vox.com/future-perfect/2019/4/4/18295933/google-cancels-ai-ethics-board"">cancelled</a></u>. The author makes the point that the council was not well-placed to actually advise on ethics -- it would only meet four times a year, and could only give recommendations. This committee, and others at Facebook and Microsoft, seem to be more about PR and less about AI ethics. Instead, an AI ethics council should include both insiders and outsiders, should be able to make formal, specific, detailed recommendations, and would publicly announce whether the recommendations were followed. <strong>Key quote:</strong> &quot;The brouhaha has convinced me that Google needs an AI ethics board quite badly — but not the kind it seems to want to try to build.&quot;</p><p>In a <u><a href=""https://twitter.com/KelseyTuoc/status/1113544870625308673"">tweetstorm</a></u>, the author holds OpenAI up as a large organization that is at least <em>trying</em> to engage deeply with AI ethics, as evidenced by their safety and policy team, their <u><a href=""https://blog.openai.com/openai-charter/"">charter</a></u> (<u><a href=""https://mailchi.mp/14782876a85d/alignment-newsletter-2"">AN #2</a></u>), <u><a href=""https://blog.openai.com/better-language-models/"">GPT-2</a></u> (<u><a href=""https://mailchi.mp/c48f996a5db5/alignment-newsletter-46"">AN #46</a></u>). They make public, contentful statements that are weird, controversial and seem bad from a PR perspective. The arguments they make and hear about AI ethics and policy lead to real decisions with consequences.</p><p><strong>Rohin&#x27;s opinion:</strong> I broadly agree with this article -- I can&#x27;t imagine how a council that meets four times a year could properly provide advice on Google&#x27;s AI projects. I&#x27;m not sure if the solution is more powerful and intensive ethics councils whose primary power is public accountability. I expect that making good decisions about AI ethics requires either a technical background, or a long, detailed conversation with a person with that background, neither of which are possible with the public. This could mean that an ethics board could struggle to raise a legitimate issue, or that they could cause outrage about an issue that is upon closer examination not an issue at all. I would feel better about a board with some more formal power, such as the ability to create investigations that could lead to fines, the ability to sue Google, specific whistleblowing affordances, etc. (I have no idea how feasible any of those suggestions are, even assuming Google was okay with them.)</p><p>On the tweetstorm about OpenAI, I&#x27;m not sure if I&#x27;ve said it before in this newsletter, but I generally trust OpenAI to be trying to do the right thing, and this is one of the reasons for that. Of course, I also know and trust many people who work there.</p><p><u><a href=""http://www.rationallyspeakingpodcast.org/show/rs-231-helen-toner-on-misconceptions-about-china-and-artific.html"">Rationally Speaking #231 - Helen Toner on &quot;Misconceptions about China and artificial intelligence&quot;</a></u> <em>(Julia Galef and Helen Toner)</em>: In this podcast Helen talks about AI policy, China, and the Center for Security and Emerging Technology, where she is the director of strategy. Some of her opinions that stood out to me:</p><ul><li>While Baidu is a huge tech company and is the main search engine, it&#x27;s a bit misleading to call it the Google of China, since it doesn&#x27;t have the same diversity of products that Google does.</li><li>While the social credit score story seems overblown, the reporting on the Uighur situation seems to be basically accurate.</li><li>Based on a very small sample of AI researchers in China, it seems like Chinese researchers are less interested in thinking about the real-world effects of the technology they&#x27;re building, relative to Western researchers.</li><li>Since people in government have so little time to think about so many issues, they have simple versions of important ideas. For example, it&#x27;s easy to conclude that China must have an intrinsic advantage at data since they have more people and fewer privacy controls. However, there&#x27;s a lot of nuance: for example, most of the Internet is in English, which seems like a big advantage for the US.</li><li>The incentives in China can be quite different: in at least one case, a chemistry professor&#x27;s salary depended on the number of papers published.</li><li>A particularly interesting question: &quot;how does it help the US geopolitically if an American company is developing powerful AI?&quot;</li></ul><p><u><a href=""https://www.partnershiponai.org/when-is-it-appropriate-to-publish-high-stakes-ai-research/"">When Is It Appropriate to Publish High-Stakes AI Research?</a></u> <em>(Claire Leibowicz et al)</em>: Following the <u><a href=""https://blog.openai.com/better-language-models/"">GPT-2 controversy</a></u> (<u><a href=""https://mailchi.mp/c48f996a5db5/alignment-newsletter-46"">AN #46</a></u>), the Partnership on AI held a dinner with OpenAI and other members of the AI community to discuss the tension between the norm of openness and the desire to mitigate potential unintended consequences and misuse risks of AI research. The post discusses some of the relevant considerations, and highlights a key conclusion: while there is not yet a consensus on on review norms for AI research, there <em>is</em> a consensus that <strong>whatever the review norms are, they should be standardized across the AI community</strong>.</p><p><strong>Rohin&#x27;s opinion:</strong> I definitely agree that having everyone follow the same review norms is important: it doesn&#x27;t do much good to hold back from publishing something problematic if a different group will publish all of the details a few weeks later. However, getting everyone to agree on a change to the existing norms seems incredibly hard to do, though it might be feasible if it was limited to only the largest actors who can engage deeply in the debate of what these norms should be.</p><h1><strong>Other progress in AI</strong></h1><h3><strong>Unsupervised learning</strong></h3><p><u><a href=""https://deepmind.com/blog/unsupervised-learning/"">Unsupervised learning: the curious pupil</a></u> <em>(Alexander Graves et al)</em> (summarized by Cody): A high-level but well-written explanation of why many believe unsupervised learning will be key to achieving general intelligence, touching on the approaches of GANs and autoregressive models as examples.</p><p><strong>Cody&#x27;s opinion:</strong> This is a clean, clear summary, but one without any real technical depth or detail; this would be a good writeup to hand someone without any machine learning background who wanted to get an intuitive grasp for unsupervised learning as a field.</p><p><u><a href=""https://ai.googleblog.com/2019/04/evaluating-unsupervised-learning-of.html"">Evaluating the Unsupervised Learning of Disentangled Representations</a></u> <em>(Olivier Bachem)</em> (summarized by Cody): This blog post and paper describe a Google-scale comparative study of different representation learning methods designed to learn &quot;disentangled&quot; representations, where the axes of the representation are aligned with the true underlying factors generating the data. The paper&#x27;s claims are a sobering result for the field, both theoretically and empirically. Theoretically, they show that in an unsupervised context, it&#x27;s not possible to find a disentangled representation without embedding some form of inductive bias into your model. Empirically, they present evidence suggesting that variation between random seeds for a given hyperparameter setting (in particular, regularization strength) matters as much or more than variation between that hyperparameter&#x27;s values. Finally, they run experiments that call into question whether disentangled representations actually support transfer learning, or can be identified as in fact being disentangled without using a metric that relies on having ground truth factors of variation to begin with, making it difficult to evaluate on the many realistic contexts where these aren&#x27;t available.</p><p><strong>Cody&#x27;s opinion:</strong> This strikes me as a really valuable injection of empirical realism, of the kind that tends to be good for research fields to have periodically, even if it can be a bit painful or frustrating. I appreciate in particular the effort and clarity that this paper puts into articulating the implicit assumptions of how disentanglement can be used or evaluated, and trying to test those assumptions under more real-world settings, such as the one where you don&#x27;t have any ground truth factors of variation, since the real world doesn&#x27;t tend to just hand out the Correct factorized model of itself.</p><p><u><a href=""https://bair.berkeley.edu/blog/2019/04/11/tools/"">Robots that Learn to Use Improvised Tools</a></u> <em>(Annie Xie et al)</em></p>",rohinmshah,rohinmshah,Rohin Shah,
naPsaBR3j73Lem4Y2,Should Effective Altruism be at war with North Korea?,should-effective-altruism-be-at-war-with-north-korea,https://www.lesswrong.com/posts/naPsaBR3j73Lem4Y2/should-effective-altruism-be-at-war-with-north-korea,2019-05-05T01:50:15.218Z,14,14,48,False,False,http://benjaminrosshoffman.com/should-effective-altruism-be-at-war-with-north-korea/,"<p>Summary: Political constraints cause supposedly objective technocratic deliberations to adopt frames that any reasonable third party would interpret as picking a side. I explore the case of North Korea in the context of nuclear disarmament rhetoric as an illustrative example of the general trend, and claim that people and institutions can make better choices and generate better options by modeling this dynamic explicitly. In particular, Effective Altruism and academic Utilitarianism can plausibly claim to be the British Empire&#x27;s central decisionmaking mechanism, and as such, has more options than its current story can consider.</p><h1>Context</h1><p>I wrote to my friend <a href=""https://eukaryotewritesblog.com/"">Georgia</a> in response to <a href=""https://existentialterror.tumblr.com/post/184578140574/this-is-a-north-korean-nuclear-science-facility"">this Tumblr post</a>.</p><h1>Asymmetric disarmament rhetoric</h1><p>Ben: It feels increasingly sketchy to me to call tiny countries surrounded by hostile regimes &quot;threatening&quot; for developing nuclear capacity, when US official policy for decades has been to threaten the world with nuclear genocide.</p><p>Strong recommendation to read Daniel Ellsberg&#x27;s <em>The Doomsday Machine</em>.</p><p>Georgia: <a href=""https://eukaryotewritesblog.com/2018/09/09/book-review-the-doomsday-machine/"">Book review: The Doomsday Machine</a></p><p>So I get that the US&#x27; nuclear policy was and probably is a nightmare that&#x27;s repeatedly skirted apocalypse. That doesn&#x27;t make North Korea&#x27;s program better.</p><p>Ben [feeling pretty sheepish, having just strongly recommended a book my friend <em>just reviewed on her blog</em>]: &quot;Threatening&quot; just seems like a really weird word for it. This isn&#x27;t about whether things cause local harm in expectation - it&#x27;s about the frame in which agents trying to organize to defend themselves are the aggressors, rather than the agent insisting on global domination. </p><p>Georgia: I agree that it&#x27;s not the best word to describe it. I do mean &quot;threatening the global peace&quot; or something rather than &quot;threatening to the US as an entity.&quot; But, I do in fact think that North Korea building nukes is pretty aggressive. (The US is too, for sure!)</p><p>Maybe North Korea would feel less need to defend itself from other large countries if it weren&#x27;t a literal dictatorship - being an oppressive dictatorship with nukes is strictly worse.</p><p>Ben: What&#x27;s the underlying thing you&#x27;re modeling, such that you need a term like &quot;aggression&quot; or &quot;threatening,&quot; and what role does it play in that model?</p><p>Georgia: Something like destabilizing to the global order and not-having-nuclear-wars, increases risk to people, makes the world more dangerous. With &quot;aggressive&quot; I was responding to to your &quot;aggressors&quot; but may have misunderstood what you meant by that.</p><p>Ben: This feels like a frame that fundamentally doesn&#x27;t care about distinguishing what I&#x27;d call aggression from what I&#x27;d call defense - if they do a thing that escalates a conflict, you use the same word for it regardless. There&#x27;s some sense in which this is the same thing as being &quot;disagreeable&quot; in action.</p><p>Georgia: You&#x27;re right. The regime is building nukes at least in large part because they feel threatened and as an active-defense kind of thing. This is also terrible for global stability, peace, etc.</p><p>Ben: If I try to ground out my objection to that language a bit more clearly, it&#x27;s that a focus on which agent is proximately escalating a conflict, without making distinctions about the kinds of escalation that seem like they&#x27;re about controlling others&#x27; internal behavior vs preventing others from controlling your internal behavior is an implicit demand that everyone immediately submit completely to the dominant player.</p><p>Georgia: It&#x27;s pretty hard to make those kind of distinctions with a single word choice, but I agree that&#x27;s an important distinction.</p><p>Ben: I think this is exactly WHY agents like North Korea see the need to develop a nuclear deterrent. (Plus the dominant player does not have a great track record for safety.) Do you see how from my perspective that amounts to &quot;North Korea should submit to US domination because there will be less fighting that way,&quot; and why I&#x27;d find that sketchy?</p><p>Maybe not sketchy coming from a disinterested Martian, but very sketchy coming from someone in one of the social classes that benefit the most from US global dominance?</p><p>Georgia: Kind of, but I believe this in the nuclear arena in particular, not in general conflict or sociopolitical tensions or whatever. Nuclear war has some very specific dynamics and risks.</p><h1>Influence and diplomacy</h1><p>Ben: The obvious thing from an Effective Altruist perspective would be to try to establish diplomatic contact between Oxford EAs and the North Koreans, to see if there&#x27;s a compromise version of Utilitarianism that satisfies both parties such that North Korea is happy being folded into the Anglosphere, and then push that version of Utilitarianism in academia.</p><p>Georgia: That&#x27;s not obvious. Wait, are you proposing that?</p><p>Ben: It might not work, but &quot;stronger AI offers weaker AI part of its utility function in exchange for conceding instead of fighting&quot; is the obvious way for AGIs to resolve conflicts, insofar as trust can be established. (This method of resolving disputes is also probably part of why animals have sex.)</p><p>Georgia: I don&#x27;t think academic philosophy has any direct influence on like political actions. (Oh, no, you like Plato and stuff, I probably just kicked a hornet&#x27;s nest.) Slightly better odds on the Oxford EAs being able to influence political powers in some major way.</p><p>Ben: Academia has hella indirect influence, I think. I think Keynes was right when he said that &quot;practical men who believe themselves to be quite exempt from any intellectual influence, are usually the slaves of some defunct economist. Madmen in authority, who hear voices in the air, are distilling their frenzy from some academic scribbler of a few years back.&quot; Though usually on longer timescales.</p><p>FHI is successfully positioning itself as an advisor to the UK government on AI safety. </p><p>Georgia: Yeah, they are doing some cool stuff like that, do have political ties, etc, which is why I give them better odds.</p><p>Ben: Utilitarianism is nominally moving substantial amounts of money per year, and quite a lot if you count Good Ventures being aligned with GiveWell due to Peter Singer&#x27;s recommendation.</p><p>Georgia: That&#x27;s true.</p><p>Ben: The whole QALY paradigm is based on Utilitarianism. And it seems to me like you either have to believe</p><p>(a) that this means academic Utilitarianism has been extremely influential, or</p><p>(b) the whole EA enterprise is profiting from the impression that it&#x27;s Utilitarian but  then doing <a href=""https://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/"">quite different</a> stuff in a way that if not literally fraud is definitely a bait-and-switch.</p><p>Georgia: I&#x27;m persuaded that EA has been pretty damn influential and influenced by academic utilitarianism. Wouldn&#x27;t trying to convince EAs directly or whatever instead of routing through academia be better?</p><p>Ben: Good point, doesn&#x27;t have to be exclusively academic - you&#x27;d want a mixture of channels since some are longer-lived than others, and you don&#x27;t know which ones the North Koreans are most interested in. Money now vs power within the Anglo coordination mechanism later.</p><p>Georgia: The other half of my incredulity is that fusing your value functions does not seem like a good silver bullet for conflicts.</p><p>Ben: It <a href=""https://en.wikipedia.org/wiki/The_Federalist_Papers"">worked for America</a>, <a href=""https://slatestarcodex.com/2016/04/27/book-review-albions-seed/"">sort of</a>. I think it&#x27;s more like, rarely tried because people aren&#x27;t thinking systematically about this stuff. Nearly no one has the kind of perspective that can do proper diplomacy, as opposed to <a href=""http://benjaminrosshoffman.com/engineer-diplomat/"">clarity-opposing power games</a>.</p><p>Georgia: But saying that an academic push to make a fused value function is obviously the most effective solution for a major conflict seems ridiculous on its face.</p><h1>Is it coherent to model an institution as an agent?</h1><p>Ben: I think the perspective in which this doesn&#x27;t work, is one that thinks modeling NK as an agent that can make decisions is fundamentally incoherent, and also that taking claims to be doing utilitarian reasoning at face value is incoherent. Either there are agents with utility functions that can and do represent their preferences, or there aren&#x27;t.</p><p>Georgia: Surely they can be both - like, conglomerations of human brains aren&#x27;t really perfectly going to follow any kind of strategy, but it can still make sense to identify entities that basically do the decisionmaking and act more-or-less in accordance to some values, and treat that as a unit</p><p>It is both true that &quot;the North Korean regime is composed of multiple humans with their own goals and meat brains &quot; and that &quot;the North Korean regime makes decisions for the country and usually follows self-preservationist decisionmaking.&quot;</p><p>Ben:I&#x27;m not sure which mode of analysis is correct, but I am sure that doing the reconciliation to clarify what the different coherent perspectives are, is a strong step in the right direction.</p><p>Georgia: Your goal seems good!</p><h1>Philosophy as perspective</h1><p>Ben: Maybe EA/Utilitarianism should side with the Anglo empire against NK, but if so, it should probably account for that choice internally, if it wants to be and be construed as a rational agent rather than a fundamentally political actor cognitively constrained by institutional loyalties.</p><p>Thanks for engaging with this - I hadn&#x27;t really thought through the concrete implications of the fact that any system of coordinated action is a &quot;side&quot; or agent in a decision-theoretic landscape with the potential for conflict.</p><p>That&#x27;s the conceptual connection between my sense that calling North Korea&#x27;s nukes &quot;threatening&quot; is mainly just shoring up America&#x27;s rhetorical position as the legitimate world empire, and my sense that reasoning about ends that doesn&#x27;t concern itself with the reproduction of the group doing the reasoning is <a href=""http://benjaminrosshoffman.com/totalitarian-ethical-systems/"">implicitly totalitarian</a> in a way that nearly no one actually wants.</p><p>Georgia: &quot;With the reproduction of the group doing the reasoning&quot; - like spreading their values/reasoning-generators or something?</p><p>Ben: Something like that.</p><p>If you want philosopher kings to rule, you need a system adequate to keep them in power, when plenty of non-philosophers have an incentive to try to get in on the action, and then that ends up constraining most of your choices, so you don&#x27;t end up benefiting much from the philosophers&#x27; competence!</p><p>So you build a totalitarian regime to try to hold onto this extremely fragile arrangement, and it fails anyway. The amount of narrative control they have to exert to prevent people from subverting the system by which they&#x27;re in charge ends up being huge.</p><p>(There&#x27;s some ambiguity, since part of the reason for control is education into virtue - but if you&#x27;re not doing that, there&#x27;s not really much of a point of having philosophers in charge anyway.)</p><p>I&#x27;m definitely giving you a summary run through a filter, but that&#x27;s true of all summaries, and I don&#x27;t think mine is less true than the others -just, differently slanted.</p><p>Related: <a href=""http://www.hidysmith.com/blog/2018/4/26/on-geopolitical-domination-as-a-service"">ON GEOPOLITICAL DOMINATION AS A</a> <a href=""http://www.hidysmith.com/blog/2018/4/26/on-geopolitical-domination-as-a-service"">SERVICE</a></p>",Benquo,benquo,Benquo,
XKGPgNLjPbjSAwLiL,Dishonest Update Reporting,dishonest-update-reporting,https://www.lesswrong.com/posts/XKGPgNLjPbjSAwLiL/dishonest-update-reporting,2019-05-04T14:10:00.742Z,61,19,27,False,False,,"<p>Related to: <a href=""https://thezvi.wordpress.com/2019/04/25/asymmetric-justice/"">Asymmetric Justice</a>, <a href=""https://thezvi.wordpress.com/2019/03/15/privacy/"">Privacy</a>, <a href=""https://thezvi.wordpress.com/2019/02/19/blackmail/"">Blackmail</a></p>
<p>Previously (Paul Christiano): <a href=""https://sideways-view.com/2018/07/12/epistemic-incentives-and-sluggish-updating/"">Epistemic Incentives and Sluggish Updating</a></p>
<p>The starting context here is the problem of what Paul calls sluggish updating. Bob is asked to predict the probability of a recession this summer. He said 75% in January, and how believes 50% in February. What to do? Paul sees Bob as thinking roughly this:</p>
<blockquote><p>If I stick to my guns with 75%, then I still have a 50-50 chance of looking smarter than Alice when a recession occurs. If I waffle and say 50%, then I won’t get any credit even if my initial prediction was good. Of course if I stick with 75% now and only go down to 50% later then I’ll get dinged for making a bad prediction right now—but that’s little worse than what people will think of me immediately if I waffle.</p></blockquote>
<p>Paul concludes that this is likely:</p>
<blockquote><p>Bob’s optimal strategy depends on exactly how people are evaluating him. If they care exclusively about evaluating his performance in January then he should always stick with his original guess of 75%. If they care exclusively about evaluating his performance in February then he should go straight to 50%. In the more realistic case where they care about both, his optimal strategy is somewhere in between. He might update to 70% this week.</p>
<p>This results in a pattern of “sluggish” updating in a predictable direction: once I see Bob adjust his probability from 75% down to 70%, I expect that his “real” estimate is lower still. In expectation, his probability is going to keep going down in subsequent months. (Though it’s not a sure thing—the whole point of Bob’s behavior is to hold out hope that his original estimate will turn out to be reasonable and he can save face.)</p></blockquote>
<p>This isn’t ‘sluggish’ updating, of the type we talk about when we discuss the Aumann Agreement Theorem and its claim that rational parties can’t agree to disagree. It’s dishonest update reporting. As Paul says, explicitly.</p>
<p></p>
<blockquote><p>I think this kind of sluggish updating is quite common—if I see Bob assign 70% probability to something and Alice assign 50% probability, I expect their probabilities to gradually inch towards one another rather than making a big jump. (If Alice and Bob were epistemically rational and honest, their probabilities would immediately take big enough jumps that we wouldn’t be able to predict in advance who will end up with the higher number. Needless to say, this is not what happens!)</p>
<p>Unfortunately, I think that sluggish updating isn’t even the worst case for humans. It’s quite common for Bob to double down with his 75%, only changing his mind at the last defensible moment. This is less easily noticed, but is even more epistemically costly.</p></blockquote>
<p>When Paul speaks of Bob’s ‘optimal strategy’ he does not include a cost to lying, or a cost to others getting inaccurate information.</p>
<p>This is a world where all one cares about is how one is evaluated, and lying and deceiving others is free as long as you’re not caught. You’ll get <em>exactly </em>what you incentivize.</p>
<p>What that definitely <em>won’t </em>get you are a lot more than just accurate probability estimates.</p>
<p>The only way to get accurate probability estimates from Bob-who-is-happy-to-strategically-lie is to use a mathematical formula to reward Bob based on his log likelihood score. Or to have Bob bet in a prediction market, or another similar robust method. And then use that as the <em>entirety </em>of how one evaluates Bob. If<em> </em>human judgment is allowed<em> </em>in the process, the value of that will overwhelm any desire on Bob’s part to be precise or properly update.</p>
<p>Since Bob is almost certainly in a human context where humans are evaluating him based on human judgments, that means all is mostly lost.</p>
<p>As Paul notes, <em>consistency </em>is crucial in how one is evaluated. Even bigger is <em>avoiding mistakes. </em></p>
<p>Given the <a href=""https://thezvi.wordpress.com/2019/04/25/asymmetric-justice/"">asymmetric justice</a> of punishing mistakes and inconsistency that can be proven and identified, the strategic actor must seek cognitive <a href=""https://thezvi.wordpress.com/2019/03/15/privacy/"">privacy.</a> The more others know about the path of your beliefs, the easier it will be for them to spot an inconsistency or a mistake. It’s hard enough to give a reasonable answer once, but updating in a way that never can be shown to have <em>ever </em>made a mistake or been inconstant? Impossible.</p>
<p>A mistake or inconsistency are the <em>bad things </em>one must avoid getting docked points for.</p>
<p>Thus, Bob’s full strategy, in addition to choosing probabilities that sound best and give the best cost/benefit payoffs in human intuitive evaluations of performance, is to <em>avoid making any clear statements of any kind. </em>When he must do so, he will do his best to be able to deny having done so. Bob will seek to <em>destroy the historical record </em>of his predictions and statements, and their path. And also <em>prevent the creation of any common knowledge, at all. </em>Any knowledge of the past situation, or the present outcome, could be shown to not be consistent with what Bob said, or what we believe Bob said, or what we think Bob implied. And so on.</p>
<p>Bob’s <em>optimal strategy </em>is <em>full anti-epistemology. </em>He is opposed to knowledge.</p>
<p>In that context, Paul’s suggested solutions seem highly unlikely to work.</p>
<p>His first suggestion is to<em> exclude information – </em>to judge Bob only by the aggregation of all of Bob’s predictions, and ignore any changes. Not only does this throw away vital information, it also isn’t realistic. Even if it was realistic for some people, others would still punish Bob for updating.</p>
<p>Paul’s second suggestion is to make predictions about others’ belief changes, which he himself notes ‘literally wouldn’t work.’ And that it is ‘a recipe for epistemic catastrophe.’ The whole thing is convoluted and unnatural at best.</p>
<p>Paul’s third and final suggestion is social disapproval of sluggish updating. As he notes, this twists social incentives potentially in good ways but likely in ways that make things worse:</p>
<blockquote><p>Having noticed that sluggish updating is a thing, it’s tempting to respond by just penalizing people when they seem to update sluggishly. I think that’s a problematic response:</p></blockquote>
<ul>
<li>
<blockquote><p>I think the rational reaction to norms against sluggish updating may often be no updating at all, which is much worse.</p></blockquote>
</li>
<li>
<blockquote><p>In general combating non-epistemic incentives with other non-epistemic incentives seems like digging yourself into a hole, and can only work if you balance everything perfectly. It feels much safer to just try to remove the non-epistemic incentives that were causing the problem in the first place.</p></blockquote>
</li>
<li>
<blockquote><p>Sluggish updating isn’t easy to detect in any given case.  For example, suppose that Bob expects an event to happen, and if it does he expects to get a positive sign on any given day with 1% probability. Then if the event doesn’t happen his probability will decay exponentially towards zero, falling in half every ~70 days. This will look like sluggish updating.</p></blockquote>
</li>
</ul>
<p>Bob already isn’t excited about updating. He’d prefer to not update at all. He’s upset about having had to give that 75% answer, because now if there’s new information (including others’ opinions) he can’t keep saying ‘probably’ and has to give a new number, again giving others information to use as ammunition against him.</p>
<p>The reason he updated visibly, at all, was that not updating would have been inconsistent or otherwise punished. Punish updates for being <em>too small </em>on top of <em>already </em>looking bad for changing at all, and the chance you get the incentives right here are almost zero. Bob will game the system, one way or another. And now, you won’t know <em>how </em>Bob is doing it. Before, you could know that Bob moving from 75% to 70% meant going to something lower, perhaps 50%. Predictable bad calibration is much easier to fix. Twist things into knots and there’s no way to tell.</p>
<p>Meanwhile, Bob is going to reliably get evaluated as smarter and more capable than Alice, who for reasons of principle is going around reporting her probability estimates accurately. Those observing might even punish Alice further, as someone who does not know how the game is played, and would be a poor ally.</p>
<p>The best we can do, under such circumstances, if we want insight from Bob, is to do our best to make Bob believe we will reward him for updating correctly and reporting that update honestly, then consider Bob’s incentives, biases and instincts, and attempt as best we can to back out what Bob actually believes.</p>
<p>As Paul notes, we can try to combat non-epistemic incentives with equal and opposite other non-epistemic incentives, but going deep on that generally only makes things more complex and rewards more attention to our procedures and how to trick us, giving Bob an even bigger advantage over Alice.</p>
<p>A last-ditch effort would be to give Bob sufficient skin in the game. If Bob directly benefits enough from us having accurate models, Bob might report more accurately. But outside of very small groups, there isn’t enough skin in the game to go around. And that still assumes Bob thinks the way for the group to succeed is to be honest and create accurate maps. Whereas most people like Bob do not think that is how winners behave. Certainly not with vague things that don’t have direct physical consequences, like probability estimates.</p>
<p>What can be done about this?</p>
<p>Unless we care enough, very little. We lost early. We lost on the meta level. We didn’t <a href=""https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/"">Play in Hard Mode.</a></p>
<p>We accepted that Bob was optimizing for how Bob was evaluated, rather than Bob optimizing for accuracy. But we didn’t evaluate Bob on that basis. We didn’t place the virtues of honesty and truth-seeking above the virtue of looking good sufficiently to make Bob’s ‘look good’ procedure evolve into ‘be honest and seek truth.’ We didn’t work to instill epistemic virtues in Bob, or select for Bobs with or seeking those virtues.</p>
<p>We didn’t reform the local culture.</p>
<p>And we didn’t fire Bob the moment we noticed.</p>
<p>Game over.</p>
<p>I once worked for a financial firm that made this priority clear. On the very first day. You need to always be ready to explain and work to improve your reasoning. If we catch you lying, <em>about anything at all, ever, </em>including a <em>probability estimate, </em>that’s it. You’re fired. Period.</p>
<p>It didn’t solve all our problems. More subtle distortionary dynamics remained, and some evolved as reactions to the local virtues, as they always do. For these and other reasons, that I will not be getting into here or in the comments, it ended up not being a good place for me. Those topics are for another day.</p>
<p>But they sure as hell didn’t have to worry about the likes of Bob.</p>",Zvi,zvi,Zvi,
uGHBbALsfSA6BAFoo,A Map of the Lesswrong-O-Sphere of Interest,a-map-of-the-lesswrong-o-sphere-of-interest,https://www.lesswrong.com/posts/uGHBbALsfSA6BAFoo/a-map-of-the-lesswrong-o-sphere-of-interest,2019-05-04T04:19:25.345Z,35,12,1,False,False,,"<p>It&#x27;s clear to me that we on lesswrong operate on a pile of different interest areas.  In my head I am doing a sorting method that divides topics.  There&#x27;s not just topics I (personally) like and topics I don&#x27;t like but also many sub-topics within those.  Here&#x27;s a list of the domain areas as I see them:</p><p><strong>Lesswrong</strong>:</p><ul><li>Artificial intelligence</li><ul><li>Programming (not just AI)</li><li>Machine learning</li><li>Ethics</li><li>Math</li><ul><li>Decision theory</li></ul></ul><li>Philosophy</li><ul><li>Effective Altruism (mostly on the EA forum)</li><li>Ethics</li><li>Scientific method and crisis</li><li>Decision problems</li></ul><li>Human Psychology</li><ul><li>Therapy and related personal work</li><li>Biases and related thinking</li><li>Group thinking and how to work with people</li><li>Personal development (other than therapy)</li><li>How humans think (consciousness - overlapping with Post-rationality area) </li><ul><li>Guides for doing things, like problem solving</li><li>Thinking exercises to try</li><li>reports/retrospective reflection on some event that has happened</li></ul></ul><li>Post-rationality</li><ul><li>Buddhism</li><li>Mysticism</li><li>Woo</li><li>map/territory blurring</li></ul><li>Human health and medical</li><ul><li>Wellness</li><li>Longevity</li><li>Diet </li><li>Cryonics (uncommon)</li></ul><li>Society</li><ul><li>Economics</li><ul><li>forecasting/prediction</li></ul><li>History</li><li>Culture</li><ul><li>The state of culture in other places virtually or physically</li></ul><li>Book reviews</li></ul><li>Meta: how lesswrong works or could work.</li><li>Original sequences and relevant theory or ongoing development (as opposed to new sequences)</li><li><em>Uncommon areas</em></li><ul><li>Physics </li><li>Politics (discouraged)</li><li>Big/small (new) ideas and theories</li></ul></ul><p>--------------</p><p>We’re not doing one thing.  We’re not even doing three things, we are interested in a whole lot more topics.  I could reformat the list to include more questions, along the lines of, “what are we trying to answer when we ask a history question?” but that’s not it.  My point here is that we are investigating a diverse bunch of topics, and there’s a structure to our pattern.  Even if it might look like a mess.</p><p>For me, I know AI is not my domain.  EA, decision theory are not my domain.  My domain is Humans and how they work, how they think, and (personally) how I relate to the world around me.</p><p>Personally, in regard to archipelago of forums or dividing up topics, I know I don’t comment on AI information, but I do comment on human, PR and a few other specific topics.</p><p>This post is to follow <u><a href=""https://www.greaterwrong.com/posts/kpFXfYbvQY5GhyqKL/open-thread-may-2019/comment/taJxkoyxyABBxLvmo"">this</a></u> comment because I wanted to expand on my understanding of where lesswrong has moved since the original sequence materials.</p><p>Maybe you have a better classification of the many diverse topics we cover, but as a start, here’s what’s floating in my head.  Prove me wrong by writing your own list of what is covered by lesswrong and what domains you engage in.  </p><p></p><p>What did I miss?</p>",Elo,elo,Elo,
rtEAZgc97fnCep2RL,[Meta] Hiding negative karma notifications by default,meta-hiding-negative-karma-notifications-by-default,https://www.lesswrong.com/posts/rtEAZgc97fnCep2RL/meta-hiding-negative-karma-notifications-by-default,2019-05-04T02:36:43.919Z,26,8,9,True,False,,"<p>A few weeks ago we launched karma notifications, and I&#x27;ve been overall pretty happy with the feature. However, we and many other users noticed that while the current system treats upvotes and downvotes as symmetric, humans tend to definitely not perceive those two as symmetric and so the lived experience of having a single day with a slightly negative karma total tends to outweigh many days of strongly positive karma scores. </p><p>I also noticed that this experience has backpropagated into me being much more hesitant to downvote users or even to remove my upvotes since I know they will perceive this as a downvote and if they are not a frequent user might feel quite punished as a response.</p><p>As a consequence, we decided to hide negative karma notifications for users by default, though you can change that in your settings. My current model of users suggests it is very unlikely for users to not notice if they are getting significantly downvoted, so I am not very worried about that information getting lost, and I expect it will overall make people&#x27;s site-experience better (and their beliefs about the value and reception of their content more, not less, accurate)</p><p>For some more context, see <a href=""https://www.lesswrong.com/posts/EQJfdqSaMcJyR5k73/habryka-s-shortform-feed#ZG5muBXfx3Tb7jjph"">this</a> discussion on my short-form feed.</p>",habryka4,habryka4,habryka,
DdwEHxX4SNuecjhfm,Zurich SSC,zurich-ssc,https://www.lesswrong.com/events/DdwEHxX4SNuecjhfm/zurich-ssc,2019-05-03T20:11:08.060Z,1,1,0,False,False,,,ssczurich,ssczurich,ssczurich,
eqyTwrSuQZs7p2njS,Totalitarian ethical systems,totalitarian-ethical-systems,https://www.lesswrong.com/posts/eqyTwrSuQZs7p2njS/totalitarian-ethical-systems,2019-05-03T19:35:28.800Z,33,12,12,False,False,http://benjaminrosshoffman.com/totalitarian-ethical-systems/,"<p>(Excerpt of another <a href=""https://www.lesswrong.com/posts/eiPyYDaGcHeJGP33k/authoritarian-empiricism"">conversation with my friend Mack</a>.)</p><p>Mack: Do you consider yourself an Effective Altruist (capital letters, aligned with at least some of the cause areas of the current <em>movement</em>, participating, etc)?</p><p>Ben: I consider myself strongly aligned with the things Effective Altruism says it&#x27;s trying to do, but don&#x27;t consider the movement and its methods a good way to achieve those ends, so I don&#x27;t feel comfortable identifying as an EA anymore.</p><p>Consider the position of a communist who was never a Leninist, during the Brezhnev regime.</p><p>Mack: I am currently Quite Confused about suffering. Possibly my confusions have been addressed by EA or people who are also strongly aligned with the stated goals of EA and I just need to read more. I want people to <em>thrive</em> and this feels important, but I am pretty certain that &quot;suffering&quot; as I think the term is colloquially used is a really hard thing to evaluate, so &quot;end suffering&quot; might be a dead end as a goal</p><p>Ben: I think the frame in which it&#x27;s important to evaluate global states using simple metrics is kind of sketchy and leads to people mistakenly thinking that they don&#x27;t know what&#x27;s good locally. You have a somewhat illegible but probably coherent sense that capacity and thriving are important, and that suffering matters in the context of the whole minds experiencing the suffering, not atomically</p><p>There&#x27;s not actually a central decisionmaker responsible for all the actions, who has to pick a metric to add up all the goods and bads to decide which actions to prioritize. There are a lot of different decisionmakers with different capacities, who can evaluate or generate specific plans to e.g. alleviate specific kinds of suffering, and counting the number of minds affected and weighting by impact is one thing you might do to better fulfill your values. And one meta-intervention might be centralizing or decentralizing decisions.</p><p>Since you wouldn&#x27;t need to do this if the info were already processed, the best you can do really is try to see (a) how different levels of centralization have worked out in terms of benefiting from economies of scale vs costs due to value-distortion in the past, and (b) whether there&#x27;s a particular class of problem you care about that requires one or the other.</p><p>So, for instance, you might notice that factory farming creates a lot of pointless (from the animal&#x27;s perspective) suffering that doesn&#x27;t enable growth and thriving, but results from constantly thwarted intentions. This is pretty awful, and you might come up with one of many plans to avert that problem. Then you might, trying to pool resources to enact such a plan, find that other people have other plans they think are better, and try to work out some way to decide which large-scale plans to use shared resources to enact. (Assuming everyone with a large-scale plan thinks it&#x27;s better than smaller-scale plans, or they&#x27;d just do their own thing)</p><p>So, one way to structure that might be hiring specialists like <a href=""http://benjaminrosshoffman.com/givewell-and-partial-funding/"">GiveWell / Open Phil</a> - that&#x27;s one extreme where a specialized group of plan-comparers are entrusted with the prioritization. At the other extreme there are things like <a href=""http://benjaminrosshoffman.com/claim-explainer-returns-to-scale/"">donor lotteries</a>, where if you have X% of the funds to do something, the expected value of participating has to be at least X% of the value of funding the thing. And somewhere in the middle is some combination of direct persuasion and negotiation / trade.</p><p>Only if you go all the way to the extreme of total central planning do you really need a single totalizing metric, so to some extent proposing such a metric is proposing a totalitarian central planner, or at least a notional one like <a href=""http://www.overcomingbias.com/2008/12/two-visions-of.html"">a god</a>. This should make us at least a little worried about the proposal if it seems like <a href=""http://benjaminrosshoffman.com/effective-altruism-is-self-recommending/"">the proposers are likely to be part of the decisionmaking group in the new regime</a>. E.g. Leninism.</p><p>Mack: I&#x27;m...very cognizant of my uncertainty around what&#x27;s good for other people, in part because I am often uncertain about what&#x27;s good for <em>me.</em></p><p>Ben: Yeah, it&#x27;s kind of funny in the way Book II (IIRC) of Plato&#x27;s Republic is funny. &quot;I don&#x27;t know what <strong><em>I</em></strong>want, so maybe I should just add up what <strong><em>everyone in the world</em></strong> wants and do that instead...&quot;</p><p>&quot;I don&#x27;t know what a single just soul looks like, so let&#x27;s figure out what an ENTIRE PERFECTLY JUST CITY looks like, and then assume a soul is just a microcosm of that.&quot;</p><p>Mack: Haven&#x27;t read it, heard his Republic is a bit of a nightmare.</p><p>Ben: Well, it&#x27;s a dialogue Socrates is having with some ambitious young Spartaphilic aristocrats. He points out that their desire to preserve class differences AND have good people in charge requires this totalitarian nightmare (since more narrowminded people will ALSO want the positions of disproportionate power - to be <a href=""http://benjaminrosshoffman.com/authoritarian-empiricism/"">captain of the Titanic</a>, to use a metaphor from earlier - I actually stole the ship metaphor from <em>Republic</em> - and be less distracted by questions of &quot;how to steer the ship safely.&quot;)</p><p>He describes how even a totalitarian nightmare like this will break down in stages of corruption, and then suggests that maybe they just be happy with what they have and mostly leave other people alone.</p><p>Mack: That seems like...replacing a problem small enough for the nuance to intimidate you with one large enough that you can abstract away the nuance that would intimidate you if you acknowledged the nuance</p><p>Ben: Yes, it&#x27;s not always a bad idea to try. But, like, it&#x27;s one possible trick for becoming unconfused, and deciding a priori to stick with the result even if it seems kind of awful isn&#x27;t usually gonna be a good move. You still gotta check that it seems right and nonperverse when applied to particular cases, using the same metrics that motivated you to want to solve the problem in the first place.</p>",Benquo,benquo,Benquo,
eiPyYDaGcHeJGP33k,Authoritarian Empiricism,authoritarian-empiricism,https://www.lesswrong.com/posts/eiPyYDaGcHeJGP33k/authoritarian-empiricism,2019-05-03T19:34:18.549Z,38,13,10,False,False,http://benjaminrosshoffman.com/authoritarian-empiricism/,"<p>(Excerpts from a conversation with my friend Mack, very slightly edited for clarity and flow, including getting rid of most of the metaconversation.)</p><p>Ben: Just spent 2 full days offline for the holiday - feeling good about it, I needed it.</p><p>Mack: Good!</p><p>Ben: Also figured out some stuff about acculturation I got and had to unlearn, that was helpful</p><p>Mack: I&apos;m interested if you feel like elaborating</p><p>Ben: OK, so, here&apos;s the deal.</p><p>I noticed over the first couple days of Passover that the men in the pseudo-community I grew up in seem to think there&apos;s a personal moral obligation to honor contracts, pretty much regardless of the coercion involved. The women seem to get that this increases the amount of violence in the world by quite a lot relative to optimal play, but they don&apos;t really tell the men. This seems related somehow to a thing where the men feel anxious about the prospect of modeling people as autonomous subjects - political creatures - instead of just objectifying them, but when they slap down attempts to do that, they pretend they&apos;re insisting on rigor and empiricism.</p><p>Which I&apos;d wrongly internalized, as a kid, as good-faith critiques of my epistemics.</p><p>Story 1:</p><p>I was talking with my father about Adorno, the Enlightenment, and anti-Semitism, and the conversation was doing a reasonable-seeming thing, UNTIL he brought up the issue of high-fertility ethnic minorities with distinct political loyalties in democracies. So, naturally, first I explored the specific thing he brought up, which was that this strategy exploits a real security flaw in the democratic setup, and (since this came up in the context of Israel) that hypocritical ethnic majorities willing to occasionally violate their &quot;standards&quot; do a lot better patching the security flaw, than do ethnic majorities who insist on ACTUALLY having structurally neutral liberalism that takes care of and empowers everyone.</p><p>But, then, since we&apos;d been talking about anti-Semitism, I had to point out that there&apos;s a structurally similar thing going on with Jews and credit-allocation systems in early financialized states like pre- and interwar Germany. If there had been actual coordination and an actual agenda, it would have been trivial to take over the state. (There wasn&apos;t and there wasn&apos;t, it&apos;s a trope in pre-WWII-era Jewish humor that the anti-Semitic newspapers kind of read like escapist fantasy). But, like, a double-digit percentage of elites is obviously enough, in a modern state where info-processing is abstract and mostly automated, to control quite a lot, given perfect coordination.</p><p>And he basically said, &quot;you can&apos;t say that, because you don&apos;t have hard data.&quot;</p><p>Which, like, where am I gonna find hard data on the incidence of coups via groups with unreasonably high levels of coordination seizing control of the state&apos;s information-processing apparatus (thus causing the records to misreport reality as a side effect)?</p><p>When I poked him on this, he ended up retreating to the <a href=""https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/"">motte</a> of &quot;it&apos;s possible that what you&apos;re saying isn&apos;t true&quot;. Which, yes, obviously - it&apos;s speculation. But also obviously that isn&apos;t what he was originally saying. He was saying something like: It&apos;s wrong to reason about concrete situations based on hypotheticals about human potential; legitimate discourse is the sort of thing that could get into an academic journal (which is necessarily at least performing being apolitical in some sense, even in the journal&apos;s explicitly about political theory).</p><p>This helped a bunch of past stuff click for me, where e.g. he knows a lot about what the Rabbis of the Talmud said, and what later medieval commentators have said, and historical scholarship about how the text developed, and that&apos;s fine to talk about, but if I read them as though they were arguing about some specific real thing, try to understand and then talk about it, and use it to contextualize individual statements, that seems like &quot;irresponsible&quot; speculation to him.</p><p>Digression to an example I think is cool:</p><p>At the Passover Seder, we traditionally read a story about five Rabbis, in Roman times, staying up all night to study the Exodus from Egypt (the Passover story). (These are guys who were also associated both with the rebellions against Rome, and the successful transition to a permanently exilic Judaism.) And then in the morning their students come in and say &quot;it&apos;s time to recite the morning Shema&quot; (central affirmation that traditional Jews recite communally twice daily).</p><p>Turns out there&apos;s ANOTHER story in the Talmud about a rabbi staying up studying until his students come in to tell him it&apos;s time for the morning Shema, but this one is very different. It&apos;s Bar Yochai, a figure associated with mysticism / proto-Kabbalah. He&apos;s just generically studying Torah, not specifically the Exodus story. He&apos;s alone, not with peers. And when his students come in, he says that studying Torah takes precedence over anything else, so he&apos;s not going to come say the Shema with them, even though it&apos;s an obligatory commandment.</p><p>This is part of a broader disagreement between Bar Yochai and the other rabbis.</p><p>Another instance of the same disagreement:<br>Most of the Rabbis think that the commandment to attend to Torah (the teachings of Moses) all day means that if e.g. you&apos;re planting your crops, figure out how to do that in a Torah-ish way. Bar Yochai says you should literally just sit studying Torah, and if you do that well enough, gentiles will show up and plant your crops for you as a reward. So, Bar Yochai and his students tried it his way, and the other rabbis and their students tried it their way. And, empirically, Bar Yochai turned out to be mistaken. He got magic powers (the Talmud is very clear on this point), but his crops failed because he ... didn&apos;t plant or harvest them.</p><p>Basically he prioritized inner work over everything else, assuming that it&apos;s high enough leverage that other stuff would take care of itself, and the other rabbis thought that this stuff doesn&apos;t work outside the context of a community operating with some sort of synchronization, or outside the context of the mundane activities of life.</p><p>It&apos;s not hard to see why (a) the Talmud says that if there&apos;s any other school of thought available, never go with Bar Yochai&apos;s opinion on a legal matter, but also (b) the kabbalists saw him as an intellectual precursor.</p><p>So, linking this back to the underlying problem - describing the stories is OK, making inferences about them sort of registers as a kind of storytelling that can be fun/interesting, but my dad just can&apos;t engage with the idea that there&apos;s a fact of the matter about what these people were talking *about*, separate from what they explicitly said, and talk about kabbalah as political theory of change with concrete mundane implications.</p><p>Story 2:<br>I&apos;d just talked with my mom a bunch about her adult ESL students - some of them are &quot;unmotivated&quot; and she&apos;d recently realized it&apos;s in part because some are coerced to show up lest they lose their visas. I pointed out that she could just negotiate directly with them to work out a solution that allows the ones who want to learn to not be distracted, and that she&apos;s not morally obliged to force the ones who aren&apos;t interested in the class to pretend they are.</p><p>Then at 2nd seder a friend&apos;s father was talking with her about this, and as soon as he heard about the symptoms, he declared that she should set a firm boundary so that students that e.g. after n minutes the door of the classroom is locked and students who are too late are absent, that her first obligation is to her contract as a teacher, etc. And he basically just couldn&apos;t hear or wasn&apos;t interested in the fact that some of the students were under coercion, didn&apos;t seem to think that fact was morally relevant at all.</p><p>(None of these examples is hugely persuasive on their own, but each of them caused a long pattern of similar things to click).</p><p>When I pointed out that my mom wasn&apos;t morally obliged to collaborate with ICE he just denied that this had anything to do with what he was saying, without offering an argument.</p><p>Story 2b:<br>Same night, different incident.</p><p>My friend (the son of the guy from story 2) asked me how Pittsburgh was.</p><p>I responded with the following analogy:</p><p>While in Berkeley, it&apos;s like I was living on the first-class deck of the Titanic. In the distance, I can see the ship heading towards an iceberg. Meanwhile, all the first-class passengers are obsessed with scheming about how to become the captain, or otherwise take over the ship and get the nice staterooms and privileges.</p><p>I&apos;m concerned with steering the ship to safety, but when I find people rallying around the stated intent to steer the ship to safety, they&apos;re mostly just another faction trying to take over the ship. I try to persuade individuals that ACTUALLY navigating is object-level important even though it doesn&apos;t affect anything in our immediate concrete environment, but this just seems to people like a weird bank-shot attempt to gain status by dominating the &quot;steer the ship to safety&quot; faction.</p><p>So, depressed and scared and emotionally scarred by this, I go to a place I&apos;ve heard there are a bunch of sane competent engineers: the engine room!</p><p>It turns out, they ARE locally sane here. They&apos;re collaborating to do means-ends reasoning to keep the engine running, which keeps the lights on and keeps the ship moving forwards. Given the crazy situation we&apos;re in, keeping the ship moving forwards is not helping. But at least it&apos;s literally not their job to know about that, and they&apos;re doing what literally is their job. When I describe what&apos;s going on on the upper deck they don&apos;t seem particularly inclined to drop everything and come help, but they do seem sincerely concerned and interested in finding out whether they have any relevant resources they can direct to me. They understand in principle why steering the ship matters, and that hitting an iceberg would be bad in a way totally unrelated to factional politics.</p><p>Pittsburgh is the engine room.</p><p>So, I&apos;m in the part of this analogy that&apos;s about the Bay, and my friend&apos;s dad jumps into the conversation to tell me that my analogy is too convoluted. So, I pause and ask him what part&apos;s hard to follow (he wasn&apos;t part of the conversation at first, but if someone wants to understand what I&apos;m saying at a social event, it seems correct to try to include them), and he just keeps repeating that it&apos;s too convoluted, until eventually he changes his story and says &quot;it&apos;s too crazy, I don&apos;t want to hear about it.&quot;</p><p>So, he was pretending to be critiquing my analogy, actually feels too much anxiety about the situation I&apos;m describing to be OK letting someone else talk about it where he can hear, but felt the need to put himself above me by framing it as me making some sort of technical error in conversation.</p><p>Do you see how this seems like the same kind of thing my actual dad did?</p><p>Meanwhile, (back to the contracts thing), his wife works as a lawyer to advocate for kids whose needs aren&apos;t met by the family law &amp; school system. She can&apos;t possibly do that job and think that the letter of the law even has an objective meaning, since it&apos;s literally her job to make it mean the thing that gets an okay outcome for the child.</p><p>The men of this category often end up in a position where they are the only one in their area who are technically adept at the thing people with their job description are supposedly certified to know about, or who care to do the object-level technical work.</p><p>I think this specific gendered dynamic might be particular to secular American Jews.</p><p>Mack: Okay that&apos;s interesting. Definitely seen similar things play out but not in such a gendered way. Thinking about my parents in particular, they end up on the &quot;male&quot; side of your stories occasionally. Not consistently at all. Hm maybe the examples coming to mind are only superficially similar.</p><p>Ben: Want to work through the details of one? Might be good to precisely formulate the distinction if there is one.</p><p>Mack: Re: not treating people like political entities, I can think of examples of that. But I suspect the reasons are different.</p><p>Ben: I suspect there&apos;s a shared sense to think of people of the other political party as defective parts of a machine, rather than as adversaries who might be negotiated with or fought but with whom there&apos;s not currently a shared paradigm. But, not a shared tendency to specifically dismiss attempts to model people as agents, as unscientific.</p><p>Mack: Things that come to mind: a knee jerk reaction among the older members on one side of the family to treat this kind of reasoning as...vulgar?</p><p>Ben: What does an example of the sort of thing they&apos;ve reacted to this way look like? Actual or fictional examples both fine. Actual are better, but whatever prediction/generation function you learned is also valuable intel. (Just like <a href=""http://benjaminrosshoffman.com/poets-are-intelligence-assets/"">fictional stories by competent poets are valuable intel</a>)</p><p>Mack: I&apos;m thinking of a cousin who is very similar to me. There are running jokes about us being in the same room and driving people crazy because we &quot;start controversies.&quot; I think there was a conversation about Boise&apos;s homelessness policies, and she and I were talking about things like: the reasons the city might have taken recent aggressive action against the homeless population, essentially the different incentives at play.</p><p>We disagreed but it was sane disagreement, and her mother and grandmother were just visibly distressed. And they tried talking about ministry attempts, harsher drug laws, etc. Retreating to party lines on homelessness (red tribe). The conversation ended with her mother saying &quot;Well then why bother!&quot; as we poked at the policies they&apos;d brought up.</p><p>It isn&apos;t the same retreat to what could be published in an academic journal, or to the obligation of a contract. But it is kind of like your Titanic analogy. Laying out the specific reasons a problem is hard, the normal party lines or grumbling not being sufficient or satisfying, and finding it rude to point out why a problem is hard, especially if it isn&apos;t about the outgroup being wrong or misled by satanic forces.</p><p>Ben: OK, so it sounds like your family is nondissociatedly anxious about politics, while mine (at least the men) retreats to dissociatedly identifying with an authority narrative that insists that only &quot;apolitical&quot; knowledge is speakable; your family more overtly identifies as members of a faction, while mine identifies with abstract shared authority.</p><p>Mack: That sounds right. Ah, so this side of the family is also pretty bound to contracts of a sort, though they aren&apos;t quite as aligned with the law.</p><p>Ben: All &quot;legally binding&quot; contracts, or just uncoerced personal agreements?</p><p>Mack: All legally binding contracts to an extent though that&apos;s more about avoiding punishment and being Good. Seeing the local social mores *as* binding contracts, I think.</p><p>Ben: That last thing seems noncrazy to me - like, an attitude I&apos;d see in some fully functional societies.</p><p>Mack: It isn&apos;t crazy.</p><p>Ben: Whereas I think the thing I was pointing to is crazy, and the other things are somewhere in between.</p><p>Mack: I think I see the distinction. Feels like there&apos;s something familiar in my experience that&apos;s closer to the crazy side and I&apos;m trying to figure out where that comes from.</p><p>Initial recognition was about the discomfort and retreat - I have a lot of examples of the role you took in those anecdotes being seen as extremely rude, uncomfortable, vulgar. I don&apos;t think it comes from the same place as the specific dynamic, though.</p><p>Recognition also of the realization that the people arguing around me were not arguing to try to understand something or solve the problem.</p><p>Ben: OK, I think the discomfort-and-retreat pattern is a specific kind of defensiveness, on behalf of the ruling regime by people identifying with it (where the ruling regime can be a local community&apos;s norms, or the state, or an ideology, etc etc.)</p><p>That&apos;s an important piece of model to have, it&apos;s one of the gears here. It connects to more than one possible type of defense or sense of threat.</p><p>Mack: I am curious about whether I&apos;ve observed something closer.</p><p>Maybe this: at work some very expensive material was mixed. The timeline for new material was too long to meet even the revised deadlines for the product, there was no good mechanical solution, etc. So the bosses had been rotating employees through the tedious task of unmixing it by hand.</p><p>HR lady and I helped with this during some plant wide mandatory overtime.</p><p>She was insistent that the right thing to do would be to force the person responsible for the mess to devote all of their work hours plus overtime to fixing it.</p><p>I argued a little - not too hard because office norms. But her retreat was to a supposed alignment with company interests (even though, IMO, the solution was an okay compromise with multiple goals for the plant).</p><p>And it has come out over time that, as far as I can tell, she believes very strongly that when you begin employment you must suspend a large chunk of your personal interests and align them with the firm, or you&apos;re a subpar employee. And while this probably helps her a lot in some of her HR functions, she is resistant to discussing the individual incentives that prevent people from being &quot;good employees&quot; once they&apos;ve come on to her radar as &quot;bad employees.&quot;</p><p>Ben: The HR thing sounds like it might be an exact match with a big part of this. I do want to distinguish loyalty to a specific local institution, from loyalty to one&apos;s profession/contract. They&apos;re different kinds of implied coordination strategies.</p><p>Mack: Which loyalty is the one present in your stories?</p><p>Ben: The latter. So, the HR lady identifies her interests with the interests of the company she&apos;s attached to, that&apos;s her gang. But the guys I&apos;m talking about identify with each other as members of a mercenary class with a perceived shared interest in upholding professional standards, so that they can be interchangeable pieces and charge for this.</p><p>Mack: Ahhh<br>Okay<br>Something clicked</p><p>Ben: Like, a doctor will identify with Doctors as a profession, not with the hospital and nurses. In-house counsel will often favor the class interests of lawyers over the interests of their company.</p><p>The Guild.</p><p>*****</p><p>Related: <a href=""https://www.lesswrong.com/posts/6n9aKApfLre5WWvpG/blind-empiricism"">Blind Empiricism</a></p>",Benquo,benquo,Benquo,
wKySaqFHpfzMTGmNx,The State of Affairs,the-state-of-affairs,https://www.lesswrong.com/posts/wKySaqFHpfzMTGmNx/the-state-of-affairs,2019-05-03T16:18:31.706Z,33,16,0,False,False,,"<p>Cross posted from <a href=""https://putanumonit.com/2019/04/30/the-state-of-affairs/"">Putanumonit</a>.</p><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/04/state-of-affairs-red-cover.jpg"" class=""draft-image center"" style=""width:40%"" /></figure></span><hr class=""dividerBlock""/><h2>The Modern Model</h2><p>Marriage is a lot like physics – it runs into trouble when <a href=""https://xkcd.com/613/"">a third body</a> is introduced.</p><p>Both fields also experienced a revolution in the last century or two, with old ideas being replaced by new conceptions of how things work. For marriage, what was once a mostly economic and societal arrangement is now a romantic one, and is subject (at least in the West) to the “Modern Model of Marriage”.</p><p>The modern model goes something like this: a couple meets, feels strong chemistry, discovers shared interests, and starts having sex. The next step is emotional intimacy, as the partners are expected to become each other’s best friends and confidants. Next comes economic partnership: living together, making and spending money together, getting ready for parenthood. A spiritual dimension is added as each partner finds meaning and transcendence in their shared love. Finally, the wedding vows lock in the final requirement: that all of the above will now be provided exclusively within the couple, forever.</p><p>This exclusivity is meant to provide security, which has to take precedence in the trade-off against the other benefits of marriage. A union that scores a B grade on chemistry, engagement, sex, meaning, intimacy, and economics with an A+ on security is considered a great marriage, about as good as one can hope for. We accept that couples may face financial troubles, a drifting apart of interests and hobbies, decreased intimacy, and lackluster sex. But it’s an oxymoron to say: <em>“my marriage is great, there’s just a bit of infidelity”</em>.</p><p>And yet, as Esther Perel quips<em>:</em></p><blockquote>Infidelity has a tenacity that marriage can only envy.</blockquote><p>The quote is from Perel’s book, <em><a href=""https://www.goodreads.com/book/show/34017010-the-state-of-affairs?ac=1&from_search=true"">The State of Affairs: Rethinking Infidelity</a></em>. I bought it <a href=""https://www.audible.com/pd/The-State-of-Affairs-Audiobook/B072WBLT3K?ref=a_ep_esther_c12_banner_img&pf_rd_p=95e4d47f-4e73-4061-b773-8ab62e2c288b&pf_rd_r=3BF424MAMN9SQ1WD7VK8"">on audio</a> (Perel narrates it herself with passion and a delightful Belgian accent), then immediately ordered a paperback copy for my wife, who read it in one day.</p><p>Relationship science seems to lag about 24 centuries behind physics, the modern model of marriage is quite reminiscent of <a href=""https://en.wikipedia.org/wiki/Aristotelian_physics"">Aristotelian physics</a>. It is a neatly organized package of rules that makes sense when you see it on the page. But it is not built on solid first principles, and it certainly doesn’t hold up to a close inspection of reality.</p><p><em>The State of Affairs</em> is a close inspection of the reality of marriage and adultery. For the most part it relies not on p&lt;0.05 studies but on Perel’s three-decade career as a therapist in a dozen countries. The diversity of perspectives in the book is its great strength; it does not offer a single Theory of Relationships and is skeptical of all such attempts. Instead, Perel explores how affairs happen, what it means for all three people involved, and what we can learn from them about the foundation of human desire, fear, sexuality, and love.</p><p>The book is subtitled <em>“Rethinking Infidelity”</em>, but I read it as a primer for rethinking relationships more broadly. The multitude of affairs recounted in the book happen in good marriages and bad, new marriages and old, gay and straight, Morrocan and Swiss. Combined, the point to myriad structural weaknesses of the modern model, to the point where launching into a relationship guided by it seems as reckless as sailing into the ocean on a leaky ship.</p><p>The book doesn’t offer an alternative set of rules but encourages a fluid approach to marriage that requires constant attention, flexibility, and communication. The romantic dance can only take so many missteps before it falls apart, which is where <em>The State of Affairs</em> comes in. It allows the reader an opportunity to learn from the mistakes and successes of others. Or simply, to learn from their affairs. The book concludes:</p><blockquote>At their peak, affairs rarely lack imagination. Nor do they lack desire, abundance of attention, romance, and playfulness. Shared dreams, affection, passion and endless curiosity – all these are natural ingredients found in the adulterous plot. They are also the ingredients of thriving relationships.</blockquote><h2>Cheating for Utilitarians</h2><p>Why do we get married? The reason for most people used to be <em>“because father said so”</em>, along with a citation from the appropriate religious text. But modern individualist culture is based on an explicit rejection of the power of family and tradition to dictate our choices. Having enough children to work the farm used to be a core motivation as well, but we don’t use procreation to justify a <em>romantic</em> relationship (and what about infertile, same-sex, and voluntarily childless couples?)</p><p>We enter relationships not out of duty and obligation, but rather in the pursuit of happiness. We tell others to <em>“do what makes you happy” </em>in relationships and don’t judge whatever sexual kinks or corny nicknames this entails. We warn against excess sacrifice, neediness, or co-dependence.</p><p>And yet, when it comes to infidelity, we become deontologists. A woman rationalizing an affair by calculating that the pleasure shared by her and her lover exceeds the husband’s pain wouldn’t get much sympathy. In the United States, <a href=""https://news.gallup.com/poll/210542/americans-hold-record-liberal-views-moral-issues.aspx"">infidelity is the single most condemned legal behavior</a>, clocking a moral disapproval rate of 91%. In a culture that leaves little room for the sacred, romantic fidelity is a sacred value.</p><p>In the past, sexual infidelity used to cause tangible harm. Men ran the risk of raising other men’s children, women ran the risk of their husband’s vital resources being diverted elsewhere. Both partners were exposed to sexually transmitted diseases which could be life-threatening. In the age of birth control, paternity testing, child support, condoms, antibiotics, and female economic empowerment, these harms are significantly mitigated. And yet, infidelity seems to hurt <em>more</em> than it did in previous centuries.</p><p>Perel explains that infidelity today is not a threat to our economic or physical security, but to our emotional security. It’s a threat to our very identity.</p><blockquote>At so many weddings, starry-eyed dreamers recite a list of vows, swearing to be everything to each other, from soul mate to lover to teacher to therapist.</blockquote><p>It is a grand ambition, and infidelity tells the betrayed partner that they failed at it. A prerequisite for romantic marriage is succumbing to the illusion that one can make their partner happy like no one else can, that the union is unique and special. The marriage ceremony fuses this illusion into one’s identity, reinforced by the social proof of friends and family offering their tearful congratulations. Infidelity shatters this illusion in a moment.</p><p>Affairs can also unmoor the betrayed partner from their own past. Realizing that they lived a lie forces them to reassess their entire personal history for the length of the relationship. The loss of personal history is also experienced as a loss of identity.</p><p>The trauma caused by affairs is real, as both the cheater and the betrayed know. Infidelity certainly deserves moral condemnation. And yet, Perel suggests that a focus on moralizing isn’t the most productive reaction to the discovery of an affair.</p><p>First, she considers cheating in the context of all other marital misdemeanors. The book recounts the stories of people who cheated on spouses who for years ignored them, bullied and belittled them, emotionally abused them, sacrificed their relationships for work or gambling or crystal meth. It is strange that in all those cases we support the right of the abused partner to find love and comfort with someone else, but only on the condition that they first go through the drawn-out and potentially ruinous process of official divorce. If someone seeks an escape from loneliness and misery before the final papers are signed we turn them from victim to villain.</p><p>More importantly, the more moral opprobrium a society has for cheating, the harder life becomes for the betrayed partner. In countries where infidelity is expected, betrayal hurts but is not life-shattering:</p><blockquote>We would love to think that pain is pain, democratic and universal. In fact, an entire cultural framework shapes the way we give meaning to our heartbreak. In my conversations with a group of Senegalese women, several of whom had been cheated on by their husbands, none talked about having lost their entire identity. They described sleepless nights, jealousy, endless crying, outbursts of anger. But in their view, husbands cheat because “that’s what men do,” not because their wives are mysteriously inadequate.</blockquote><p>Other cultures leave space for jealousy:</p><blockquote>In Latin America, the term “jealousy” is bound to appear in the first breath. “In our culture, jealousy is the gut issue,” a woman in Buenos Aires told me. “We want to know, does he still love me? What does she have that I don’t?”<br/>“What about the lying?” I asked. She laughed dismissively. “We’ve been<br/>lying since the Spanish arrived!”<br/>Such cultures tend to emphasize the loss of love and the desertion of eros over the deception.</blockquote><p>Jealousy arises from the fear of losing the love you have. Admitting to jealousy gives people social (and personal) permission to fight to reclaim the love that is dear to them. It is the <em>absence</em> of jealousy that signals the end of the relationship.</p><p>In other cultures, however, jealousy is absent by default:</p><blockquote>In the United States and other Anglo-Saxon cultures (which tend to be Protestant), people are remarkably silent on the subject of this perennial malady of love. Instead, they want to talk about betrayal, violated trust, and lying. Jealousy is denied in order to protect the victim’s moral superiority. We take pride in being above such a petty sentiment that reeks of dependency and weakness. “Me, jealous? Never! I’m just angry!” […]<br/>As Sissa points out in her refreshing book on the subject, jealousy has a built-in paradox—we need to love in order to be jealous, but if we love, we should not be jealous. And still, we are. Everybody speaks ill of jealousy. Therefore, we experience it as an “inadmissible passion.” We are not only forbidden to admit we are jealous, we are not allowed to feel jealous. These days, Sissa warns us, jealousy is politically incorrect.</blockquote><p>Discovering that your beloved is having an affair plunges people into a maelstrom of emotions that can be hard to interpret. How much of the emotional force is righteous anger, and how much is it fear of abandonment, resentment, loss of history, crumbling of future plans, social shame, inadequacy, or a dozen other things? This interpretation shapes the universe of possible responses.</p><p>The moralization of cheating pushes the victim of an affair to resolve the emotional confusion in favor of moral indignation, which makes angry divorce the default response. As Hillary Clinton and others have found out, now that divorce is allowed it is the choice to <em>stay</em> with a cheating partner that carries a stigma. The Anglo-Saxon norm of punishing defectors can be constructive, but there no evidence that divorce-as-default is good for the cheated-on partner, the cheater, or society as a whole.</p><blockquote>The rush to divorce makes no allowance for error, for human fragility. It also makes no allowance for repair, resilience, and recovery. And it makes no allowance for people who want to learn and grow from what happened.</blockquote><p>As a relationship therapist, Perel’s job is not to moralize but to help <em>both</em>partners have the best relationships they can, whether together or apart. And for that, the first step is to investigate the reasons an affair happened.</p><h2>Mysterious Affairs</h2><p>The prevailing view of infidelity is that it’s a symptom of a troubled relationship. Perel agrees that is quite often the case.</p><blockquote>Plenty of relationships culminate in an affair to compensate for a lack, to fill a void, or to set up an exit. Insecure attachment, conflict avoidance, prolonged lack of sex, loneliness, or just years of being stuck rehashing the same old arguments—many adulterers are motivated by marital dysfunction.</blockquote><p>And yet, marital dysfunction is clearly neither a sufficient nor necessary condition for infidelity. Plenty of miserable couples are faithful. Plenty of other couples come to Esther Perel in the wake of an affair while assuring her that their marriage is full of love and joy.</p><p>Why do people have sex and then don’t tell their partners about it? One may propose a naive hypothesis: sex is fun, and getting shit for it isn’t. I think there is a lot of truth in this hypothesis, but it doesn’t lend itself to the framework that Americans want to apply to infidelity. That framework is one of <em>sin and absolution, </em>or, in its modern incarnation:</p><blockquote>The idea that infidelity can happen in the absence of serious marital problems is hard to accept. Our culture does not believe in no-fault affairs. So when we can’t blame the relationship, we tend to blame the individual instead. The clinical literature is rife with typologies for cheaters—as if character always trumps circumstance. Psychological jargon has replaced religious cant, and sin has been eclipsed by pathology. We are no longer sinners; we are sick. Ironically, it was much easier to cleanse ourselves of our sins than it is to get rid of a diagnosis.</blockquote><p>This view of infidelity is monetized by the burgeoning industry of <em>sex addiction</em>, the “diagnosis” and “treatment” of which are so Kafkaesque <a href=""https://www.ncbi.nlm.nih.gov/pubmed/19937105"">there’s literally a psychiatrist named Kafka</a> involved in promoting it. For a sober overview of the issue, you can read Dr. David Ley’s <em><a href=""https://www.goodreads.com/book/show/13145839-the-myth-of-sex-addiction"">The Myth of Sex Addiction</a>. </em>For the opposite of sobriety: Neil Strauss’  deranged voyage through sex addiction therapy in <em><a href=""https://www.goodreads.com/book/show/26887738-the-truth"">The Truth</a></em>.</p><p>Perel does recognize people whose individual affliction stands in the way of a fulfilling and faithful marriage. But often the affliction is a lot more complex than a compulsive desire for sex.</p><blockquote>It is my first session alone with Garth. He proceeds to tell me a “sordid” tale of the assorted infidelities that have played out, not just with Valerie, but in each of his two prior marriages. […]<br/>“Believe me, I don’t like it this way,” Garth tells me. “I don’t want to be the kind of guy who cheats. Plus, I feel very bad that I’m not able to satisfy Valerie, and I try to make up for it by taking care of her in all other ways. She thinks the ED is because of my diabetes, but this happened to me long before.” […]<br/>Garth’s is a long, sad tale in which his father played a central role. An alcoholic and a violent man prone to bursts of wrath, he left both visible and invisible marks on his firstborn son. More often than not, Garth chose to take the blows to protect his helpless mother and his younger brother. […]<br/>The emotional resonance between his relationship with his parents and his relationship with his wife is so strong that it leads to an unfortunate crosswiring. Hence, the feeling that sex is “wrong,” almost incestuous. When a partner starts to feel too familial, sex will inevitably be the casualty. Ironic as it may seem, at that moment the taboo of infidelity feels less transgressive than sex at home.</blockquote><p>There is a milder version of the same thing, the tension between security and eroticism, that afflicts many if not most couples. It is the subject of Perel’s other book, <em><a href=""https://www.goodreads.com/book/show/27485.Mating_in_Captivity"">Mating in Captivity</a></em>. She quotes Pamela Haag:</p><blockquote>A marriage adds things to your life, and it also takes things away. Constancy kills joy; joy kills security; security kills desire; desire kills stability; stability kills lust. Something gives; some part of you recedes. It’s something you can live without, or it’s not. And maybe it’s hard to know before the marriage which part of the self is expendable . . . and which is part of your spirit.</blockquote><p>Humans also have needs beyond simply getting off. We have the power of imagination, which means that we always have multiple lives on our minds: the one we live, and the counterfactual ones we imagine. The allure of unlived lives and unexplored identities can push the healthiest people in the best marriages into having affairs.</p><p>Perel tells the story of Priya, a doctor and mother of three, happily married to a man she describes as <em>“a phenom at work, fucking handsome, an attentive lover, fit, and generous to everyone including my parents.”</em> Priya is also sleeping with a tattoo-covered gardener in the back seat of his truck. And she can’t figure out why.</p><p>Through conversations with Esther, Priya’s life story emerges:</p><blockquote>“I’ve always been good. Good daughter, good wife, good mother. Dutiful. Straight As.” Priya comes from an Indian immigrant family of modest means. For her, “what do I want?” has never been separated from “what do they want from me?” She never partied, drank, or stayed out late, and she had her first joint at twenty-two. After medical school, she married the right guy and even welcomed her parents into their home before buying them a retirement condo. […]<br/>Her daughters are becoming teenagers and enjoying a freedom she never knew. Priya is at once supportive and envious. As she nears the mid-century mark, she is having her own belated adolescent rebellion.</blockquote><p>Everyday life is mundane, stressful, and predictable. Affairs are exciting and uncertain – not knowing if and when you’ll see your lover again only adds to the appeal. The fact that Priya has fallen for someone from a very different class and culture to her own only reinforces this separation setting the affair in its own half-fantasy world.</p><p>Perel notes that the imaginative aspect of affairs is the reason they rarely survive the breakup of the original marriage. The harsh light of normalization leaves little room for fantasy and dispels the transgressive nature that made the affair irresistible in the first place.</p><p>Affairs often live in the gaps left by the primary relationship, but the gaps themselves are not a solid foundation to build a marriage on. Priya values her children, husband, house, career, and reputation much more than she values the thrill of her fling. She wants dirty sex with the gardener <em>because</em> everything else is taken care of.</p><p>This doesn’t change the fact that in every relationship, no matter how diligently the partners live up to their vows, the gaps of unmet needs remain. They draw our attention like a missing tooth draws the tongue. They make us want more.</p><h2>More than Monogamy</h2><p>To recap, modern couples find themselves in a perplexing conundrum:</p><ol><li>People have many needs in relationships, and in the modern West, we expect that they will all be met. In fact, these needs are the very reason we enter into relationships (rather than social pressure, or the necessity of procreation).</li><li>The modern model tells us that all these needs will be met by a single person. We spend longer than ever <a href=""https://putanumonit.com/2019/03/03/exponential-secretary/"">selecting the right partner</a> and tie up ever more of our hopes, dreams, and identity in the partnership.</li><li>Almost inevitably, the relationship fails to fulfill its promise. The reason is not just that we and our partners have limited capacity to meet its demands, but also that many of these are in tension: security vs. adventure, togetherness vs. autonomy, stability vs. novelty</li><li>When needs aren’t met, people cheat. This is widely interpreted as a symptom of something being terribly wrong with either the cheater or the relationship; the default course of action in both cases is to break up.</li><li>Starting an official and exclusive relationship with the formerly-secret lover is not a solution either, because it is not going to do much better at meeting all of one’s desires.</li></ol><p>As the book deals with each tangle separately, it becomes apparent which single strand can untie the knot: the demand for romantic exclusivity and the moral weight we place on it. After skirting the idea throughout, the penultimate chapter of <em>The State of Affairs</em> makes explicit the case for consensual nonmonogamy as a possible solution to the conundrum.</p><p>A common objection to polyamory is: <em>“There is enough drama and difficulty with just two people, now you want to multiply that?” </em>One possible answer is that drama arises from the number of unmet needs, not the number of people involved. Given the conundrum of Modern Model Monogamy, it may be easier for people to deal with a polyamorous relationship that makes them happy than a monogamous relationship of perpetual internal conflict. After all, by the logic of this objection, we should all <a href=""https://www.urbandictionary.com/define.php?term=volcel"">go volcel</a> and avoid the drama altogether.</p><p>Perel starts the chapter on polyamory with a warning: people who think that it disposes of infidelity are soon disappointed.</p><blockquote>Monogamy may or may not be natural to human beings, but transgression surely is.<br/>Every relationship, from the most stringent to the most lenient, has boundaries, and boundaries invite trespassers. Breaking the rules is thrilling and erotic—whether those rules are “one person for life” or “sex is okay but no falling in love” or “always use a condom” or “he can’t come inside you” or “you can fuck other people, but only when I’m watching.” Hence there is plenty of infidelity in open relationships, with all of the ensuing turmoil. If the desire to transgress is the driving force, opening the gate will not prevent adventurers from climbing the fence.</blockquote><p>But if the goal is not to avoid cheating at all costs but to live a happy and fulfilled life, Perel recounts many nonmonogamous arrangements that meet that goal quite well.</p><p>People who value independence and autonomy often have don’t-ask-don’t-tell open relationships that simply allow for casual engagements on the side. Others are happy to share the burden of meeting their partner’s needs, and so form close friendships with the extended group of their lovers’ lovers. Yet others look for additional partners to meet very specific needs, like BDSM.</p><p>Poly people are also quick to point out that exclusivity is just that, it is not a synonym for loyalty or commitment or devotion. Dan Savage asked after a five-times-married woman accused him of not being committed because he and his husband of twenty years are nonexclusive: <em>“Which of us is more committed?”</em></p><p>Monogamous couples often rely on implicit assumptions that are not actually shared by the two partners, or that are simply wrong. A couple can have very different ideas of what actually counts as infidelity (porn? chatting with your ex? swiping on Tinder for fun?) but these differences are never discussed until a boundary is transgressed. Another common assumption is that both partners have the same needs and desires, although some very monogamous people have <a href=""https://www.5lovelanguages.com/"">also figured out that it’s often not the case</a>.</p><p>In contrast, polyamorous people are known for explicitly negotiating the wants and boundaries in their relationships. It is hard to tell which comes first: do nonmonogamous people have to discuss everything because there’s no default playbook for polyamory, or does thinking explicitly about relationship design makes one likely to do away with exclusivity?</p><p>Personally, I endorse <a href=""https://putanumonit.com/2018/06/20/miller-3-polyamory-mating/#com1"">conscious relationship design</a> whether or not polyamory is the end result of the design process. Like Geoffrey Miller, Perel sees today’s polyamorists as beta-testers of a new relationship playbook that future generations could follow. I sometimes wonder if any playbook will end up doing more harm than good once it becomes popular enough that people copy it wholesale instead of thinking of their own circumstances and personalities. Still, a new playbook can’t do much worse than the old one.</p><h2>Role Models</h2><p>What today’s love seekers need more than a finished playbook are opportunities to learn and improve, and those are scarce. People who want to improve at a craft or skill can study the detailed training guides of top performers. Students of business pore over hundreds of case studies of corporate decisions and their consequences. But with all the demands and expectations of modern marriage, it’s hard to know where to turn for exemplars.</p><p>Perel likes to ask people if they have couples whom they think of as relationship role models; most struggle to name any. We have the example of our parents, perhaps a few friends, but even there we may not be getting the full and honest picture of what the relationship is like beneath the surface appearances.</p><p>This is the main thing that <em>The State of Affairs</em> offers: an opportunity to learn from the thousands of couples Esther Perel worked with, their fuckups and their triumphs, and Perel’s own unparalleled insight. The book is fun enough to read as a collection of stories of love and betrayal, but it would be a waste not to use it as inspiration to reflect on your own relationships.</p><p>In the next post, I will list the lessons I took from <em>The State of Affairs</em>, the advice I would give myself and others based on it. In the meantime, I encourage you to <a href=""https://www.amazon.com/dp/B01N5PY4ZN"">pick up a copy</a> and rethink infidelity for yourself.</p>",Jacobian,jacob-falkovich,Jacob Falkovich,
i2dNFgbjnqZBfeitT,"Oracles, sequence predictors, and self-confirming predictions",oracles-sequence-predictors-and-self-confirming-predictions,https://www.lesswrong.com/posts/i2dNFgbjnqZBfeitT/oracles-sequence-predictors-and-self-confirming-predictions,2019-05-03T14:09:31.702Z,22,9,0,False,False,,"<p>My <a href=""https://arxiv.org/abs/1711.05541"">counterfactual Oracle</a> design uses a utility function/reward function in order to train it to give the right predictions. Paul Christiano asked whether the whole utility function approach was necessary, and whether it could be replaced with a simple sequence predictor.</p>
<p>It turns out the answers are no, and yes. The counterfactual nature of the approach can be preserved, without needing a utility function.</p>
<h1>Counterfactual sequence prediction</h1>
<p>There is a boxed Oracle, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></span></span>, which gets fed a series of observations <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_0, o_1,\ldots o_{n-1}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">…</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span></span></span>, and must make a prediction <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> about the next observation.</p>
<p>If the prediction was sent out into the world, then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> is attempting to make <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> into a self-confirming prediction, with all the <a href=""https://www.lesswrong.com/posts/KoEY9CjrKe93ErYhd/self-confirming-predictions-can-be-arbitrarily-bad"">problems that this could entail</a>.</p>
<p>However, we make <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> into a counterfactual Oracle; on some occasions, the output <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> is erased, and not seen by anyone. In that case, the Oracle will get a special message <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> (for ""erasure""), that will be added on after of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_{n-1}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span></span></span>.</p>
<p>Then the job of the counterfactual Oracle is, given a history <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_{n-1} = o_0 p_1 o_1 \ldots p_{n-1}o_{n-1}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">…</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span></span></span> (including past ""<span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span>""s), to produce a prediction <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> that is the best prediction for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> given the history <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_{n-1} e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span>. In terms of words, the Oracle is trying to best predict the next observation, <strong>given that erasure is assumed to happen</strong> (the definition of ""best"" depends on the details of the design).</p>
<p>If our setup is well designed and there is no information leakage, then any <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> has a probability that is independent of the prediction <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>:</p>
<ul>
<li><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\forall o_n, h_{n-1},p_n, p_n' : P(o_n \mid h_{n-1} e p_n) =P(o_n \mid h_{n-1} e p_n')""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">∀</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.157em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.157em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</li>
</ul>
<h2>Meaning of predictions</h2>
<p>If we ran the oracle without the assumption that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> would be observed, we'd have the standard self-confirming predictor (that being the only correct predictions); with that assumption, it becomes a counterfactual predictor.</p>
<p>Though counterfactuals are conceptually tricky, it's actually easier to understand what a counterfactual predictor is doing than a general sequence predictor Oracle. We understand that a general sequence predictor is trying to find a self-confirming prediction - one where <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> is the best estimate of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>, given <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_{n-1} p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> - but unless we understand the structure of the world very well, we don't have a clue <a href=""https://www.lesswrong.com/posts/KoEY9CjrKe93ErYhd/self-confirming-predictions-can-be-arbitrarily-bad"">where that self-confirming prediction might be</a>.</p>
<p>In contrast, the counterfactual prediction is easy to interpret: ""had we not seen <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>, that is what <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> would have been""; there are no loops in the definition.</p>
<h2>Extent of manipulation via prediction</h2>
<p>Note that the Oracle can be used to estimate the extent to which the prediction is manipulative, by contrasting its predictions for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> given the  <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_{n-1}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span></span></span>, and given <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_{n-1} e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span>. This reveals the extent to which the prediction is potentially manipulative.</p>
<h2>Non-explicit erasure</h2>
<p>If the Oracle isn't given an explicit erasure message, but has a causal model of the world, we can still run the counterfactual Oracle by having it choose <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> to be the best fit for the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>, conditional on <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h_n p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> and on the erasure happening.</p>
<h1>Factoring out certain routes</h1>
<p>Assume now that the AI is an active AI, that can take actions in the world, affecting the observation <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>. So we'll replace <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> terminology with <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span>; note that the predictions <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> were already actions, just actions of a particular type in particular setup.</p>
<p>We want to have the AI only consider certain routes to influence <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>. This might be because there is a reward-function learning process involved, and we <a href=""https://www.lesswrong.com/posts/5bd75cc58225bf06703752aa/uninfluenceable-agents"">don't want the AI to influence the learning process</a>. Or maybe there is a corrigibility button involved, and we don't want the AI to <a href=""https://arxiv.org/abs/1712.06365"">try and ensure it is pressed or not pressed</a>.</p>
<p>In any case, label the banned routes of influence by the variables <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span></span></span></span></span>:</p>
<p><img src=""https://www.dropbox.com/s/rk6kbvhedjam3ra/causal_graph.png?raw=1"" alt=""""></p>
<p>Note that the Oracle case is just a special case of this, where <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span></span></span></span></span> corresponds to ""humans reading the prediction"", and there being no direct arrow from <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a_n/p_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">/</span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>.</p>
<h2>Factoring out</h2>
<p>Assume that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\hat{a}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.213em; padding-bottom: 0.06em; padding-left: 0.015em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">^</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span></span></span></span></span></span> is the default action. Then we want the AI to maximise some expected score <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""S""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;"">S</span></span></span></span></span></span> of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>, but acting as if the values of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span></span></span></span></span> were set by <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\hat{a}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.213em; padding-bottom: 0.06em; padding-left: 0.015em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">^</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span></span></span></span></span></span> rather than the value of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span>.</p>
<p>Let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\{\beta_i\}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">{</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">}</span></span></span></span></span></span> be the possible values of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span></span></span></span></span>. We require one more assumption: that if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b=\beta_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> is possible given <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\hat{a}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.213em; padding-bottom: 0.06em; padding-left: 0.015em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">^</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span></span></span></span></span></span>, then it is also possible given any other action <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span> (technically, we only need for the conditional probabilities <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(o_n \mid b=\beta_i, a_n=a)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> to make sense).</p>
<p>Then if the AI has sufficient data to estimate expressions like <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(b=\beta_i \mid a)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, we act as if the AI was off-policy where <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span></span></span></span></span> is concerned. Namely, we get it to compute the action <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span> that maximises:</p>
<ul>
<li><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sum_{\beta_i} P(b=\beta_i \mid a_n=\hat{a}, h_{n-1}) \mathbb{E}[S(o_n, a) \mid b=\beta_i, a_n = a, h_{n-1}]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-munderover""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size1-R"" style=""padding-top: 0.519em; padding-bottom: 0.519em;"">∑</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.439em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.213em; padding-bottom: 0.06em; padding-left: 0.015em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">^</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">E</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;"">S</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.007em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;"">β</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>.</li>
</ul>
<p>Note that if we had <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a_n=a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span> instead of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""a_n=\hat{a}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-texatom MJXc-space3""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.213em; padding-bottom: 0.06em; padding-left: 0.015em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">^</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span></span></span></span></span></span> in that expression, then this would just be the classical <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb{E}[S(o_n, a) \mid a_n =a, h_{n-1}]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">E</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;"">S</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">∣</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>.</p>
<p>This construction is essentially the same as the <a href=""https://www.lesswrong.com/posts/5bd75cc58225bf067037536b/counterfactually-uninfluenceable-agents"">counterfactually uninfluenceable agent design</a>, with <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""b""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">b</span></span></span></span></span></span> representing the weights of the different reward functions that the AI was to ""learn"".</p>
",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
KoEY9CjrKe93ErYhd,Self-confirming predictions can be arbitrarily bad,self-confirming-predictions-can-be-arbitrarily-bad,https://www.lesswrong.com/posts/KoEY9CjrKe93ErYhd/self-confirming-predictions-can-be-arbitrarily-bad,2019-05-03T11:34:47.441Z,49,22,11,False,False,,"<html><head></head><body><h1>Predicting perverse donors</h1>
<p>There is a rich donor who is willing to donate up to £2,000,000 to your cause. They’ve already written a cheque for £1,000,000, but, before they present it to you, they ask you to predict how much they'll be donating.</p>
<p>The donor is slightly perverse. If you predict any amount £P, they’ll erase their cheque and write £(P-1) instead, one pound less than what your predicted.</p>
<p>Then if you want your prediction to be accurate, there’s only one amount you can predict: £P=£0, and you will indeed get nothing.</p>
<p>Suppose the donor was perverse in a more generous way, and they’d instead write £(P+1), one more than your prediction, up to their maximum. In that case, the only accurate guess is £P=£2,000,000, and you get the whole amount.</p>
<p>If we extend the range above £2,000,000, or below £0 (maybe the donor is also a regulator, who can fine you) then the correct predictions get ever more extreme. It also doesn’t matter if the donor subtracts or adds £1, £100, or one pence (£0.01): the only accurate predictions are at the extreme of the range.</p>
<p>Greek mythology is full of oracular predictions that only happened because people took steps to avoid them. So there is a big difference between “prediction P is true”, and “prediction P is true even if P is generally known”.</p>
<h2>Continuity assumption</h2>
<p>A prediction P is self-confirming if, once P is generally known, then P will happen (or P is the expectation of what will then happen). The previous section has self-confirming predictions, but these don’t always exist. They <a href=""https://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem"">exist when the outcome is continuous</a> in the prediction P (and a few technical assumptions, like the outcome taking values in a closed interval). If that assumption is violated, then there need not be any self-confirming prediction.</p>
<p>For example, the generous donor could give £(P+1), except if you ask for too much (more than £1,999,999), in which case you get nothing. In that case, there is no correct prediction £P (the same goes for the £(P-1) donor who will give you the maximum if you’re modest enough to ask for less than £1).</p>
<h2>Prediction feedback loops</h2>
<p>But the lack of self-confirming prediction is not really the big problem. The big problem is that, as you attempt to refine your prediction (maybe you encounter perverse donors regularly), where you end up at will not be determined by the background facts of the world (the donor’s default generosity) but it will entirely be determined by the feedback loop with your prediction. See <a href=""https://www.lesswrong.com/posts/jz5QoizH8HkQwWZ9Q/nash-equilibriums-can-be-arbitrarily-bad"">here</a> for a similar example in game theory.</p>
<h2>Sloppier prediction are no better</h2>
<p>One obvious answer would be to allow sloppier predictions. For example, if we require that the prediction be ""within £1 of the true value"", then all values between £0 and £2,000,000 are equally valid; averaging those, we get £1,000,000, the same as would have happened without the prediction.</p>
<p>But that's just a coincidence. We could have constructed the example so that only a certain region has ""within £1"" performance, while all others have ""within £2"" performance. More dammingly, we could have defined ""they’ve already written a cheque for £X"" for absolutely any X, and it wouldn't have changed anything. So there is no link between the self-confirming prediction and what would have happened without prediction. And making the self-confirming aspect weaker won't improve matters.</p>
<h1>Real-world dangers</h1>
<p>How often would scenarios like that happen in the real world? The donor example is convoluted, and feels very implausible; what kind of person is willing to donate around £1,000,000 if no predictions are made, but suddenly changes to £(P±1) if there is a prediction?</p>
<p>Donations normally spring from better thought-out processes, involving multiple actors, for specific purposes (helping the world, increasing a certain subculture or value, PR...). They are not normally so sensitive to predictions. And though there are cases where there are true self-confirming or self-fulfilling predictions (notably in politics), these tend to be areas which are pretty close to a knife-edge anyway, and could have gone in multiple directions, with the prediction giving them a small nudge in one direction.</p>
<p>So, though in theory there is no connection between a self-confirming prediction and what would have happened if the prediction had not been uttered, it seems that in practice they are not too far apart (for example, no donor can donate more money than they have, and they generally have their donation amount pretty fixed).</p>
<p>Though beware prediction like ""what's the value of the most undervalued/overvalued stock on this exchange"", where knowing predictions will affect behaviour quite extensively. That is a special case of the next section; the ""new approach"" the prediction suggests is ""buy/sell these stocks"".</p>
<h2>Predictions causing new approaches</h2>
<p>There is one area where it is very plausible for a prediction to cause a huge effect, though, and that's when the prediction suggests the possibilities of new approaches. Suppose I'm running a million-dollar company with a hundred thousand dollars in yearly profit., and ask a smart AI to predict my expected profit next year. The AI answers zero.</p>
<p>At that point, I'd be really tempted to give up, and go home (or invest/start a new company in a different area). The AI has foreseen some major problem, making my work useless. So I'd give up, and the company folds, thus confirming the prediction.</p>
<p>Or maybe the AI would predict ten million dollars of profit. What? Ten times more than the current capitalisation of the company? Something strange is going on. So I sift through the company's projects with great care. Most of them are solid and stolid, but one looks like a massive-risk-massive-reward gamble. I cancel all the other projects, and put everything into that, because that is the only scenario where I see ten million dollar profits being possible. And, with the unexpected new financing, the project takes off.</p>
<p>There are some more exotic scenarios, like an AI that predicts £192,116,518,914.20 profit. Separating that as 19;21;16;5;18;9;14;20 and replacing numbers with letters, this is is SUPERINT: the AI is advising me to build a superintelligence, which, if I do, will grant me exactly the required profit to <a href=""https://wiki.lesswrong.com/wiki/Acausal_trade"">make that prediction true</a> in expectation (and after that... well, then bad things might happen). Note that the AI need not be malicious; if it's smart enough and has good enough models, it might realise that £192,116,518,914.20 is self-confirming, without ""aiming"" to construct a superintelligence.</p>
<p>All these examples share the feature that the prediction P causes a great change in behaviour. Our intuitions that outcome-with-P and outcome-without-P should be similar, is based on the idea that P does not change behaviour much.</p>
<h2>Exotic corners</h2>
<p>Part of the reason that AIs could be so powerful is that they could unlock new corners of strategy space, doing things that are inconceivable to us, to achieve objectives in ways we didn't think was possible.</p>
<p>A predicting AI is more constrained than that, because it can't act directly. But it can act indirectly, with its prediction causing <em>us</em> to unlock new corners of strategy space.</p>
<p>Would a purely predictive AI do that? Well, it depends on two things:</p>
<ol>
<li>How self-confirming the exotic corners are, compared with more mundane predictions, and</li>
<li>Whether the AI could explore these corners sufficiently well to come up with self-confirming prediction in them.</li>
</ol>
<p>For 1, it's very hard to tell; after all, in the example of this post and in the <a href=""https://www.lesswrong.com/posts/jz5QoizH8HkQwWZ9Q/nash-equilibriums-can-be-arbitrarily-bad"">game-theory example</a>, arbitrarily tiny misalignment at standard outcomes, can push the self-confirming outcome arbitrarily far into the exotic area. I'd be nervous about trusting our intuitions here, because approximations don't help us. And the Quine-like ""P causes the production of a superpowered AI that causes P to be true"" seems like a perfect and exact exotic self-confirming prediction that works in almost all areas.</p>
<p>What about 2? Well, that's a practical barrier for many designs. If the AI is a simple sequence predictor without a good world-model, it might not be able to realise that there are exotic self-confirming predictions. A predictor that had been giving standard stock market predictions for all of its existence, is unlikely to suddenly hit on a highly manipulative prediction.</p>
<p>But I fear scenarios where the AI gradually learns how to manipulate us. After all, even for standard scenarios, we will change our behaviour a bit, based on the prediction. The AI will learn to give the most self-confirming of these standard predictions, and so will gradually build up experience in manipulating us effectively (in particular, I'd expect the ""zero profit predicted -&gt; stockholders close the company"" to become quite standard). The amount of manipulation may grow slowly, until the AI has a really good understanding of how to deal with the human part of the environment, and the exotic manipulations are just a continuation of what it's already been doing.</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
cHxzEwzXQ8hyN5228,Bay Summer Solstice 2019,bay-summer-solstice-2019,https://www.lesswrong.com/events/cHxzEwzXQ8hyN5228/bay-summer-solstice-2019,2019-05-03T04:49:10.287Z,26,6,0,False,False,,"<p><em>tldr: If you&#x27;re coming, please <a href=""https://www.paypal.com/pools/c/8epJnHnejo"">donate here</a>. Suggested donation are sliding scale of $15 / $35 / $100 depending on financial situation. If you use facebook, <a href=""https://www.facebook.com/events/267521990851501/"">RSVP here</a>.</em></p><hr class=""dividerBlock""/><p>We were hoping this year for Bay Summer Solstice to actually be on the weekend of Summer Solstice. Alas, <a href=""https://www.eaglobal.org/"">EA</a> <a href=""https://www.eaglobal.org/"">Global</a> is that weekend. So instead we&#x27;re celebrating it the week before – on Saturday, June 15th. Apologies to the purists.</p><p>Most communication will happen on the <a href=""https://www.facebook.com/events/267521990851501/"">Facebook</a> <a href=""https://www.facebook.com/events/267521990851501/"">Event</a>, but major updates will be posted here. </p><p>We&#x27;ll be journeying out to Marin Headlands –  a surreal, remote world of hidden beaches, spooky ruins and epic cliffs. </p><p>There&#x27;ll be caravan that departs from central Berkeley around 11am. (If you&#x27;re interested in a caravan from San Francisco or South Bay, please post a comment either here or on Facebook and hopefully others can coordinate with you)</p><p>What&#x27;s the deal with Summer Solstice? I&#x27;ve written in the past:</p><ul><li><a href=""https://www.lesswrong.com/posts/KnpxChD9fnT9785FR/visions-of-summer-solstice"">Visions of Summer</a> <a href=""https://www.lesswrong.com/posts/KnpxChD9fnT9785FR/visions-of-summer-solstice"">Solstice</a></li><li><a href=""https://www.lesswrong.com/posts/e9Fgj2mHS8BqGbiZf/stories-of-summer-solstice"">Stories of Summer</a> <a href=""https://www.lesswrong.com/posts/e9Fgj2mHS8BqGbiZf/stories-of-summer-solstice"">Solstice</a></li></ul><span><figure><img src=""https://i.imgur.com/wLc7V6e.jpg"" class=""draft-image "" style=""width:100%"" /></figure></span><p>An except from <a href=""https://www.lesswrong.com/posts/KnpxChD9fnT9785FR/visions-of-summer-solstice"">Visions of Summer</a> <a href=""https://www.lesswrong.com/posts/KnpxChD9fnT9785FR/visions-of-summer-solstice"">Solstice</a>:</p><blockquote>The experience begins with a journey.</blockquote><blockquote>This partly by design, but largely by necessity.</blockquote><blockquote>Winter Solstice is about the long arc of history. Summer Solstice is about the here and now, and why <em>being human</em> is something worth protecting. It&#x27;s about freedom, fun, physicality. It&#x27;s about figuring things out in Near Mode. It&#x27;s about building things together.</blockquote><blockquote>Getting a particular kind of Special out of that physicality requires a particular kind of space.</blockquote><blockquote>It&#x27;s not enough to find a small nearby park. Ideally, you want an outdoor space vast enough to <em>feel in your bones that the sky is the limit</em>. There is no one and nothing to help you build a tower to the stars, or to cross the ocean, or cartwheel forever in any direction. But neither is there anyone to stop you. There is only nature, and you, and your tribe, and whatever you choose to do.</blockquote><blockquote>If you live in a major city, this probably means you may need to undertake a nontrivial journey before finding such a place. The best places will be off the beaten path, and a bit hard to navigate to. If it were easy, humans would have already crowded around it. You might be able to have fun, but you wouldn&#x27;t be able to carve out a spot for <em>your people</em> to invoke a <em>Sacred Fun.</em></blockquote><blockquote>As you contemplate this from your comfortable couch and think about the journey, you may find it daunting. If you attempted it alone, you might find it frustrating and lonely.</blockquote><blockquote>So, don&#x27;t attempt it alone.</blockquote><blockquote>Journey together. If you get lost along the way, getting un-lost is part of the fun. You may find something valuable in overcoming the obstacles. I do, anyway.</blockquote><blockquote>The best journey is one that borders on the mythologic – you pass through narrow passages, winding your way through wild undergrowth, slightly confused about where you are going but compelled onwards by curiosity. You cross a threshold into a fae-like enclave that clear communicates &quot;you have left the default world behind.&quot;</blockquote><blockquote>And then suddenly find yourself at the top (or edge) of the world, slightly unclear how you got there.</blockquote><blockquote>Sometimes you are lucky, and such hidden enclaves exist right in your backyard. But the efficient Other World hypothesis says that such unspoiled passages are rare.</blockquote><blockquote>There are many possible destinations you can choose for your journey. I suggest one additional constraint: As much as possible, find a low horizon line – a beach, or hilltop. Dense foliage is beautiful in it&#x27;s own way, but there is something valuable, for this holiday, about getting a clear view of the sunset.</blockquote><blockquote>You are here to celebrate the longest day of the year.</blockquote>",Raemon,raemon,Raemon,
jpMGyemfq2nAjWWnA,Episode 3 of Tsuyoku Naritai! (the 'becoming stronger podcast): Nike Timers,episode-3-of-tsuyoku-naritai-the-becoming-stronger-podcast,https://www.lesswrong.com/posts/jpMGyemfq2nAjWWnA/episode-3-of-tsuyoku-naritai-the-becoming-stronger-podcast,2019-05-03T02:53:07.600Z,5,2,2,False,False,,"<p>Latest episode is up! In this episode, we learn rationality from Shia LeBeouf.</p><p>https://anchor.fm/tsuyokunaritai/episodes/Episode-3---Nike-Timers-e3trl2</p><p><a href=""http://bit.ly/2GZnB0E"">http://bit.ly/2GZnB0E</a></p>",Senarin,senarin,Bae's Theorem,
YK2poJiW4w58t6mfr,Functional Decision Theory vs Causal Decision Theory: Expanding on Newcomb's Problem,functional-decision-theory-vs-causal-decision-theory,https://www.lesswrong.com/posts/YK2poJiW4w58t6mfr/functional-decision-theory-vs-causal-decision-theory,2019-05-02T22:15:39.128Z,2,7,7,False,False,,"<p>  </p><p>I’ve finished reading through <strong>Functional Decision Theory: A New Theory of Instrumental Rationality, </strong>and in my mind, the main defense of causal-decision-theory (CDT) agents in Newcomb’s Problem is not well-addressed. As they stated in the paper, the standard defense of two-boxing is that Newcomb’s Problem explicitly punishes rational decision theories, and rewards others. The paper then refutes this by saying: “<em>In short, Newcomb’s Problem doesn’t punish rational agents; it punishes two-boxers</em>”. </p><p>It is true that FDT agents will “win” at Newcomb’s Problem, but what the paper doesn’t address is that it is quite easy to come up with similar situations where FDT agents are punished and CDT agents are not. A simple example of this is something I’ll call the Inverse Newcomb’s Problem since it only requires changing a few words relative to the original.</p><p><strong>Inverse Newcomb’s Problem:</strong></p><p><em>An agent finds herself standing in front of a transparent box labeled “A” that contains $1,000, and an opaque box labeled “B” that contains either $1,000,000 or $0. A reliable predictor, who has made similar predictions in the past and been correct 99% of the time, claims to have placed $1,000,000 in box B iff she predicted that the agent would <strong>two-box in the standard Newcomb’s problem</strong>. The predictor has already made her prediction and left. Box B is now empty or full. Should the agent take both boxes, or only box B, leaving the transparent box containing $1,000 behind?</em></p><p>The bolded part is the only difference relative to the original problem. The situation initially plays out the same, but just branches at the end:</p><p>1. The prediction is made by a reliable predictor (I’ll use the name Omega) for how the agent would respond in a standard Newcomb’s dilemma (“one-box” or “two-box”)</p><p>2. Armed with this prediction, Omega stands in front of box B and decides whether to place the $1,000,000 inside.</p><p>3. The $1,000,000 goes in the box iff:</p><p>    a. The prediction was “one-box” (Standard Newcomb’s Problem)</p><p>    b. The prediction was “two-box” (Inverse Newcomb’s Problem)</p><p>Because FDT agents would one-box in a standard Newcomb’s problem, their box B in the inverse problem is empty. In this inverse problem, there is no reason for FDT agents not to two-box, and they end up with $1,000. In contrast, because CDT agents would two-box in a standard Newcomb’s problem, their box B in the inverse problem has $1,000,000. They two-box in this case as well and end up with $1,001,000. In much the same way that Omega in the standard Newcomb’s problem “<em>punishes two-boxers</em>”, in the inverse problem it punishes one-boxers. </p><p>One may try to argue that the Standard Newcomb’s problem is much more plausible than the inverse, but this does not hold weight. The standard problem has a certain level of elegance and interest to it due to the dilemma it creates, and the fact that Omega has reproduced the scenario from its prediction, but this does not mean that it’s more likely. Whether Omega rewards standard one-boxers (3a) or two-boxers (3b) is completely tied to the motivations of this hypothetical predictor, and there’s no way to justify that one is more likely than the other.  </p><p>By the very nature of this situation, it is impossible for a single agent to get the $1,000,000 in both the Standard and Inverse Newcomb’s Problems; they are mutually exclusive. Both FDT and CDT agents are punished in one scenario and rewarded in the other, so to measure their relative performance in a fair manner, we can imagine that each agent gets presented with both the Standard and Inverse problems, and the total money earned is calculated:</p><p>The CDT agent will two-box in each case and earn <strong>$1,002,000</strong> ($1,000 in the Standard problem and $1,001,000 in the Inverse problem).<br/> The FDT agent will one-box in the Standard problem ($1,000,000) and two-box in the Inverse problem ($1,000), earning <strong>$1,001,000</strong>.</p><p>It is clear that when the agents are presented with the same sequence of two scenarios, one that rewards Standard one-boxers and the other that rewards Standard two-boxers, the CDT agent outperforms the FDT agent. By choosing to one-box in the Standard problem, the FDT agent leaves $1,000 on the table, while the CDT agent claims all the money that was available to them.</p><p>To conclude, FDT agents undoubtedly beat CDT agents at the Standard Newcomb’s problem, but that result alone is not relevant in comparing the two in general. This situation is one where a third agent (Omega) has explicitly chosen to reward one-boxers, but as shown above, it is simple enough to imagine an equally-likely case where one-boxers are punished instead. When the total performance of both agents across the two equally-likely scenarios is considered, CDT ends up with an extra $1,000. Based on this, I don’t see how FDT can be considered a strict advance over CDT.   </p><p>   </p>",Geropy,geropy,Geropy,
pzqnQZ4ruEjLYn9yK,What is corrigibility? / What are the right background readings on it?,what-is-corrigibility-what-are-the-right-background-readings,https://www.lesswrong.com/posts/pzqnQZ4ruEjLYn9yK/what-is-corrigibility-what-are-the-right-background-readings,2019-05-02T20:43:45.303Z,6,1,2,False,True,,"<p>Ryan Carey asks in a related question <a href=""https://www.lesswrong.com/posts/edi9Y4vYtdNRbui3u/what-are-some-good-examples-of-incorrigibility"">&quot;What are some good examples of incorrigibility?&quot;</a> He provides the following overview:</p><blockquote>The idea of corrigibility is roughly that an AI should be aware that it may have faults, and therefore allow and facilitate human operators to correct these faults. I&#x27;m especially interested in scenarios where the AI system controls a particular input channel that is supposed to be used to control it, such as a shutdown button, a switch used to alter its mode of operation, or another device used to control its motivation. </blockquote><p>What&#x27;s a more detailed understanding? What are the right things to read? I believe there&#x27;s at least one MIRI paper, some Arbital posts. Writing to this question to center my inquiry.</p>",Ruby,ruby,Ruby,
WqKucz7SSaxpncfq9,South Bay SSC Meetup May 11th,south-bay-ssc-meetup-may-11th,https://www.lesswrong.com/events/WqKucz7SSaxpncfq9/south-bay-ssc-meetup-may-11th,2019-05-02T18:09:57.719Z,2,1,0,False,False,,"<p>We are having our usual South Bay meetup next Saturday, May 11th. 3806 Williams Rd., San Jose, CA. Let me know if you are planning to come so we will have a rough count of how many we are feeding. Children welcome.</p>",DavidFriedman,davidfriedman,DavidFriedman,
tmEEyE8de99rESx6A,Neural networks for games,neural-networks-for-games,https://www.lesswrong.com/posts/tmEEyE8de99rESx6A/neural-networks-for-games,2019-05-02T04:28:06.234Z,0,3,1,False,True,,"<html><head></head><body><p>Recently, I've read tutorial about neural network in a snake game.
(you can see it here - <a href=""https://towardsdatascience.com/today-im-going-to-talk-about-a-small-practical-example-of-using-neural-networks-training-one-to-6b2cbd6efdb3"">https://towardsdatascience.com/today-im-going-to-talk-about-a-small-practical-example-of-using-neural-networks-training-one-to-6b2cbd6efdb3</a>)
But, the way it train the neural network it bit funny - in practice, it depends on knowing what the snake should do in every step, and when he didn't, train him. Not very useful(cause, you know, I could just program him to do that).</p>
<p>The other way, I guess, is to use log of the game, assume that the players doing the optimal steps (lets say, exept of the end of there game😉) and then train the network on this situations.</p>
<p>But, when I haven't log of the game, is there a way I can use neural networks for a game? And if there is, how?</p>
</body></html>",bipolo,bipolo,bipolo,
vW24BnrpEsigEtxCn,Swarm AI (tool),swarm-ai-tool,https://www.lesswrong.com/posts/vW24BnrpEsigEtxCn/swarm-ai-tool,2019-05-01T23:39:51.553Z,17,4,3,False,False,,"<html><head></head><body><p><a href=""https://unanimous.ai/swarm/"">https://unanimous.ai/swarm/</a></p>
<p>I remember playing with this a while back, answering random questions. I guess now they've released it as a business tool for companies to run their own voting rooms.</p>
<p>Quick overview:</p>
<ol>
<li>You create a room.</li>
<li>You invite 4-200 participants.</li>
<li>You ask questions.</li>
<li>Participants vote.</li>
<li>You get prediction results using their AI.</li>
</ol>
<p>Their <a href=""https://vimeo.com/306667996"">video</a> and website claims they got a lot of hard predictions right. Of course, they aren't saying how many other things they guessed. So it's hard to say how magical it is, but it seems worth trying out. I'm up for joining people's room if they want to run some experiments.</p>
</body></html>",Alexei,alexei,Alexei,
kpFXfYbvQY5GhyqKL,Open Thread May 2019,open-thread-may-2019,https://www.lesswrong.com/posts/kpFXfYbvQY5GhyqKL/open-thread-may-2019,2019-05-01T15:43:23.982Z,10,4,66,False,False,,"<p>If it’s worth saying, but not worth its own post, you can put it here.</p><p>Also,  if you are new to LessWrong and want to introduce yourself, this is the  place to do it. Personal stories, anecdotes, or just general comments  on how you found us and what you hope to get from the site and community  are welcome. If you want to explore the community more, I recommend <a href=""https://www.lesswrong.com/library"">reading the Library</a>, <a href=""https://www.lesswrong.com/?view=curated"">checking recent Curated posts</a>, and <a href=""https://www.lesswrong.com/community"">seeing if there are any meetups in your area</a>.</p><p>The Open Thread sequence is <a href=""https://www.lesswrong.com/s/yai5mppkuCHPQmzpN"">here</a>.</p>",ryan_b,ryan_b,ryan_b,
jz5QoizH8HkQwWZ9Q,Nash equilibriums can be arbitrarily bad,nash-equilibriums-can-be-arbitrarily-bad,https://www.lesswrong.com/posts/jz5QoizH8HkQwWZ9Q/nash-equilibriums-can-be-arbitrarily-bad,2019-05-01T14:58:21.765Z,35,17,24,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><h1>Go hungry with Almost Free Lunches</h1>
<p>Consider the following game, called ""Almost Free Lunches"" (<strong>EDIT</strong>: this seems to be a variant of the <a href=""https://en.wikipedia.org/wiki/Traveler%27s_dilemma"">traveller dilemma</a>). You name any pound-and-pence amount between £0 and £1,000,000; your opponent does likewise. Then you will both get whichever amount named was lowest.</p>
<p>On top of that, the person who named the highest amount must give £0.02 to the other. If you tie, no extra money changes hands.</p>
<p>What's the <a href=""https://en.wikipedia.org/wiki/Nash_equilibrium"">Nash equilibrium</a> of this game? Well:</p>
<ul>
<li>The only Nash equilibrium of Almost Free Lunches is for both of you to name £0.00.</li>
</ul>
<p><em>Proof</em>: Suppose player A has a probability distribution <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span> over possible amounts to name, and player <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> has a probability distribution <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span> over possible amounts. Let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span> be the highest amount such that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_A(m_A)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is non-zero; let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span> be the same, for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>. Assume that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(p_A,p_B)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is a Nash equilibrium.</p>
<p>Assume further that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A \geq m_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">≥</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span> (if that's not the case, then just switch the labels <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>). Then either <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A>""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span></span></span></span> £0.00 or <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A=""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span></span></span></span></span> £0.00 (and hence both players select £0.00).</p>
<p>We'll now rule out <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A >""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span></span></span></span> £0.00. If <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_B >""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span></span></span></span> £0.00, then player <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> can improve their score by replacing <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span> with <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A' = m_B - £0.01""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">£</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.01</span></span></span></span></span></span>. To see this, assume that player <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> has said <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span>, and player <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> has said <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span>. If <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_B < m_A' < m_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span>, then player <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> can say <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span></span> just as well as <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span> - either choice gives them the same amount (namely, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_B -""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span></span></span></span></span> £0.02).</p>
<p>There remain two other cases. If  <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_B=m_A'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span></span>, then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span></span> is superior to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span>, getting <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span></span> (rather than <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A' -""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span></span></span></span></span> £0.02). And if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_B = m_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span>, then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span></span> gets <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A'+""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.35em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span></span></span></span></span> £0.02 <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""=m_B+""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span></span></span></span></span> £0.01, rather than <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span> (if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A=m_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span>) or <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_B-£0.02""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-texatom MJXc-space2""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char"" style=""padding-top: 0.519em; padding-bottom: 0.225em;""><span class=""mjx-charbox MJXc-TeX-unknown-R"" style=""padding-bottom: 0.3em; width: 0.5em;"">£</span></span></span></span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0.02</span></span></span></span></span></span> (if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A > m_B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span></span></span>).</p>
<p>Finally, if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_B =""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span></span></span></span></span> £0.00, then player <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> gets -£0.02 unless they also say £0.00.</p>
<p>Hence if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A >""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span></span></span></span> £0.00, the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span></span></span> cannot be part of a Nash Equilibrium. Thus <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m_A=""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span></span></span></span></span> £0.00 and hence the only Nash Equilibrium is at both players saying £0.00.</p>
<h2>Pareto optimal</h2>
<p>There are three Pareto-optimal outcomes: (£1,000,000.00, £1,000,000.00), (£1,000,000.01, £999,999.97), and (£999,999.97, £1,000,000.01). All of them are very much above the Nash Equilibrium.</p>
<h2>Minmax and maximin</h2>
<p>The <a href=""https://en.wikipedia.org/wiki/Minimax"">minmax and maximin values</a> are also both terrible, and also equal to £0.00. This is not surprising, though, as minmax and maximin implicitly assume the other players are antagonistic to you, and are trying to keep your profits low.</p>
<h1>Arbitrary badness with two options</h1>
<p>This shows that choosing the Nash Equilibrium can be worse than almost every other option. We can of course increase the maximal amount, and get the Nash Equilibrium to be arbitrarily worse than any reasonable solution (I would just say either £1,000,000.00 or £999,999.99, and leave it at that).</p>
<p>But we can also make the Nash Equilibrium arbitrarily close to the worst possible outcome, and that without even requiring more than two options for each player.</p>
<p>Assume that there are four ordered amounts of money/utility: <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_3 > n_2 > n_1 > n_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>. Each player can name <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span> or <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>. Then if they both name the same, they get that amount of utility. If they name different ones, then then player naming <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span> gets <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>, and the player naming <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span> gets <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span></span></span>.</p>
<p>By the same argument as above, the only Nash equilibrium is for both to name <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>. The maximum possible amount is <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span></span></span>; the maximum they can get if they both coordinate is <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span>, the Nash equilibrium is <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>, and the worst option is <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>. We can set <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_1= n_0 +\epsilon""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">ϵ</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_3=n_2 + \epsilon""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">ϵ</span></span></span></span></span></span> for arbitrarily tiny <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\epsilon > 0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">ϵ</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>, while setting <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span> to be larger than <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span> by some arbitrarily high amount.</p>
<p>So the situation is as bad as it could possibly be.</p>
<p>Note that this is a variant of the prisoner's dilemma with different numbers. You could describe it as ""Your companion goes to a hideous jail if and only if you defect (and vice versa). Those that don't defect will also <a href=""https://www.lesswrong.com/posts/3wYTFWY3LKQCnAptN/torture-vs-dust-specks"">get a dust speck in their eye</a>.""</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
Pb7sT5CdaM3fc5BPK,April 2019 gwern.net newsletter,april-2019-gwern-net-newsletter,https://www.lesswrong.com/posts/Pb7sT5CdaM3fc5BPK/april-2019-gwern-net-newsletter,2019-05-01T14:43:18.952Z,11,2,3,False,False,https://www.gwern.net/newsletter/2019/04,<html><head></head><body></body></html>,gwern,gwern,gwern,
KrDJQp7kL2YG4YByP,Has government or industry had greater past success in maintaining really powerful technological secrets?,has-government-or-industry-had-greater-past-success-in,https://www.lesswrong.com/posts/KrDJQp7kL2YG4YByP/has-government-or-industry-had-greater-past-success-in,2019-05-01T02:24:52.302Z,27,7,15,False,True,,"<p>Context: As part of our efforts of working on Open Questions the LessWrong team has been reaching out to various researchers we know and asked them about questions they would be interested in getting answered. </p><p>This question was given to us by <a href=""https://www.lesswrong.com/users/ryancarey"">Ryan</a> <a href=""https://www.lesswrong.com/users/ryancarey"">Carey</a> and some of the answers below are the result of us trying to answer the question for a day on a private LessWrong instance, copied over to allow other people to contribute and read what we wrote. </p>",habryka4,habryka4,habryka,
XTgXETRh96CbqkiwA,Does the patent system prevent industry from keeping secrets?,does-the-patent-system-prevent-industry-from-keeping-secrets,https://www.lesswrong.com/posts/XTgXETRh96CbqkiwA/does-the-patent-system-prevent-industry-from-keeping-secrets,2019-05-01T02:24:35.928Z,8,1,0,False,True,,,habryka4,habryka4,habryka,
Zcoqc2R5rsS9nsSHd,What are concrete historical examples of powerful technological secrets?,what-are-concrete-historical-examples-of-powerful,https://www.lesswrong.com/posts/Zcoqc2R5rsS9nsSHd/what-are-concrete-historical-examples-of-powerful,2019-05-01T02:22:37.870Z,9,2,7,False,True,,,habryka4,habryka4,habryka,
AMnwQDYx97nEp53df,A quick map of consciousness,a-quick-map-of-consciousness,https://www.lesswrong.com/posts/AMnwQDYx97nEp53df/a-quick-map-of-consciousness,2019-05-01T02:17:42.593Z,11,6,0,False,False,,"<p>Original post: <a href=""http://bearlamp.com.au/a-quick-map-of-consciousness/"">http://bearlamp.com.au/a-quick-map-of-consciousness/</a></p><hr class=""dividerBlock""/><p>Prior knowledge: <a href=""http://bearlamp.com.au/many-maps-lightly-held/"">Many maps lightly held</a>, <a href=""http://bearlamp.com.au/leaky-concepts/"">Leaky concepts</a>, <a href=""http://bearlamp.com.au/boundaries/"">Boundaries</a><br/></p><span><figure><img src=""https://i1.wp.com/bearlamp.com.au/wp-content/uploads/2019/05/consciousness-map.png?w=667"" class=""draft-image "" style=""width:40%"" /></figure></span><p><em>Map and territory: mind to reality – To be presented alongside the caveat, “what is good?”</em></p><p>(Well “good” is in the map, not the territory.  This diagram very quickly becomes a mess, but before that happens, let’s talk about reifying the parts of this model to see if it’s useful)<br/></p><hr class=""dividerBlock""/><p><em>To me right now</em>, it seems like consciousness is the ladder between the map and the territory.  In the diagram, on the left is a thought, suggesting that “this is an apple” on the right, pictured is a red apple.  When the attention points at a red apple, the consciousness is filled with a map of declarative definition that labels, names and concludes that this is an apple.  <br/></p><p>Consciousness seems to be a label generating machine.  Something fundamental about brains is that they map the territory.  They quest towards mapping the territory.<br/></p><p>That’s.Just.What.They.Do.<br/></p><p>This brings us to the question of – how do I have a good life.  I have 3 strategies:<br/></p><p>1. [<strong>content</strong>] Look at different apples</p><p>2. [<strong>map</strong>] modify so that there are more positive opinions of apples</p><p>3. [<strong>relationality</strong>] appreciate looking at rotten apples if that’s what’s to look at today.</p><hr class=""dividerBlock""/><h2><strong>Content</strong></h2><p>If I look at dead apples all day, I’m not going to auto-magically have a great day.  On the other hand if I look at great apples, I’m going to be impressed and delighted.  The apple could be replaced with beautiful artwork, nice sunsets, tasty food, nice music.  Whatever strikes in the heart of desire to be attended to. <em>Improve the content</em> is a reasonable and helpful strategy sometimes.<br/></p><p>Sometimes it’s not the content that’s the problem.  Maybe there’s nothing wrong with apples but they make me puke.  Then I can try the map.</p><h2><strong>Map</strong></h2><p>If every time I see an apple I remember that one time I bit an apple and found half a worm, maybe there’s some work I can do so that I don’t keep thinking worms when I see an apple.  Even sunsets are irrelevant when I’m too busy on my phone. If art galleries remind me of my ex, music reminds me of screeching cats (not in a good way), food reminds me of how fat I am (and how I can’t take care of my body). Maybe the work to be done is in the map.  Sometimes with more and less force, the map can be trained to be less miserable when presented with stimuli. Usually the good stuff is found by passing through the uncomfortable, not avoiding it.</p><p>Sometimes I can’t shift the content.  I’m living in the developing world, sometimes sickness and suffering is visible.  Sometimes it’s a very real awareness that if I’m not careful it could be me. That’s where the 3rd method comes in.</p><p>There’s parts of the map that start to relate to other parts of the map. That’s what I start to call “relationality”.</p><h2><strong>Relationality</strong></h2><p>I look at an apple.  It reminds me of the time I bit into a worm.  How I relate to that content is flexible. I can feel bad about being dumb that time, or I can look at it and laugh about how ridiculous that was. Maybe thinking of worm-apple-gate is my minds way of warning me to be careful it doesn’t happen again.  That time I went to see the sunset and could not get off my phone, I was upset about something, maybe I’m being reminded to be kind to myself, now I know better. Screeching cats – Hilarious! Food makes me fat, but it’s really really good food.  So tasty! Maybe the question of balancing good food and living!life is worth considering.<br/></p><p>I have a chance to see how I’m relating to the content, and I can travel to different maps.  <br/></p><p>How?  Slowly. <br/></p><p>That process of “travel to different maps” needs to be done in the way of being that travels all the way down the ladder.  If I brute force the attention to move elsewhere, my relationality is “brute force”. My map says, “I gotta brute force my way around here” or “that’s not important” and my content becomes all about the things I avoid.  Sure I can brute force my content to be butterflies not machine guns, but that’s not going to substantially change a map with trouble brewing. I can’t always control what I see. but I can work towards relating to those experiences better.</p><hr class=""dividerBlock""/><p>This post has been quick and dirty. I hope to build on it later.</p>",Elo,elo,Elo,
AouZH7x76bxmPAjTq,Why is it important whether governments or industry projects are better at keeping secrets?,why-is-it-important-whether-governments-or-industry-projects,https://www.lesswrong.com/posts/AouZH7x76bxmPAjTq/why-is-it-important-whether-governments-or-industry-projects,2019-05-01T02:10:21.533Z,8,1,5,False,True,,,habryka4,habryka4,habryka,
peCFP4zGowfe7Xccz,Natural Structures and Conditional Definitions,natural-structures-and-conditional-definitions,https://www.lesswrong.com/posts/peCFP4zGowfe7Xccz/natural-structures-and-conditional-definitions,2019-05-01T00:05:35.698Z,20,8,14,False,False,,"<p>There&apos;s a sense in which definitions are arbitrary. Words are made by humans and no-one can stop me from calling red blue and blue red if I really want to. So when people ask questions like, &quot;What is consciousness?&quot; or &quot;What is free-will?&quot;, it seems quite reasonable to respond, &quot;Just pick a definition. These terms can be defined many different ways and it&apos;s completely your choice which one you choose to use&quot;.</p><p>This may appear to dissolve the question, however, I would suggest that such an answer often misunderstands what the asker is attempting. Typically the asker is concerned by more than the linguistic question, but also with attempting to understand the ontology or structure of reality. And it may be the case that this structure includes a substructure that naturally fits with our intuitions of what consciousness is or what freewill is or it may be the case, as per the standard LW view of these two cases, that such a structure doesn&apos;t exist.</p><p>What makes this especially confusing is that many people will <em>conditionally accept</em> the &quot;it&apos;s arbitrary&quot; answer when they are convinced that such a natural structure doesn&apos;t exist, while pointing out the natural structure otherwise. Here&apos;s an example. Let&apos;s suppose it was common knowledge that we all have souls. Then whenever someone asked about the definition of consciousness, we&apos;d be tempted to point to the soul, just as whenever people ask about the definition of trees, we&apos;d be tempted to talk about leaves and branches. The arguments for being able to use language arbitrarily and the fact that this isn&apos;t a perfectly well-specified definition remain. It&apos;s just that one definition suffices for 95% of cases, so we don&apos;t bring up that argument. But if instead it was common knowledge that there are no souls, it&apos;d be much more likely they&apos;d say that the definition is arbitrary. And by accepting answers to different questions depending on how things turn out, the intent behind the original question can easily be obscured.</p><p><strong>Appendix</strong></p><p>Here are some possible interpretations of, &quot;What is X?&quot;:</p><ul><li>What does term X intrinsically mean? (no intrinsic meaning exists)</li><li>What natural structure (if any) corresponds to X?</li><li>What are some useful interpretations of the term X?</li><li>How is the term X used in society?</li></ul><p>These kinds of discussions tend to work better if everyone is on the same page about what is being asked.</p><p><strong>Note:</strong> Apparently, I actually had an <a href=""https://www.lesswrong.com/posts/p6wSGPzgocPqkHuYZ/map-and-territory-natural-structures"">old post</a> on this topic here which I&apos;d completely forgotten about.</p><p>I&apos;ve also discovered that the philosophical term is <a href=""https://plato.stanford.edu/entries/natural-kinds/"">natural kinds</a>.</p>",Chris_Leong,chris_leong,Chris_Leong,
