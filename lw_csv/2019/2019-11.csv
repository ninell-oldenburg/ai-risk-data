_id,title,slug,pageUrl,postedAt,baseScore,voteCount,commentCount,meta,question,url,htmlBody,user.username,user.slug,user.displayName,user
G4uMdBzgDsxMsTNmr,CO2 Stripper Postmortem Thoughts,co2-stripper-postmortem-thoughts,https://www.lesswrong.com/posts/G4uMdBzgDsxMsTNmr/co2-stripper-postmortem-thoughts,2019-11-30T21:20:33.685Z,113,41,37,False,False,,"<p><strong>[EDIT: A crucial consideration was pointed out in the comments. For all the designs I&apos;ve looked at, it&apos;s cheaper to just get a heat exchanger and ventilation fans, and blow the air outside/pull it inside and eat the extra heating costs/throw on an extra layer of clothing, than it is to buy a CO2 stripper. There&apos;s still an application niche for poorly ventilated rooms without windows, but that describes a lot fewer occasions than my previous dreams of commercial use.]</strong></p><br><p>So, I have finally completed building a CO2 stripper that removes CO2 from the air to (hopefully) improve cognition in environments with high CO2 levels. In California, the weather is pretty good so it&apos;s easy to just crack a window at any point during the year, but other areas get quite cold during the winter or quite warm during summer and it&apos;s infeasible to open a window unless you want to spend an awful lot of money on heating or cooling bills. It didn&apos;t work quite as well as the math indicated at first, but the whole thing is built, and basically functional. The rest of this post will be a reflection on the lessons learned while doing so.</p><br><h2>1: In hardware, ideas are cheap, execution is expensive</h2><p>So, the fundamental idea is extremely simple once you have some basic knowledge of chemistry. The goal is to get CO2 into some form that isn&apos;t the gas form, via some sort of chemical reaction. </p><p>Submarines and CO2 capture from flue gas use a reversible reaction with ethanolamines, where they absorb CO2 at high temperatures and release it at low temperatures. Reversible reactions are good for making waste, but heating up and cooling down large quantities of liquid takes an awful lot of energy. Submarines have nuclear reactors onboard, and flue gas is hot, but we don&apos;t necessarily have the energy required. Also ethanolamines are toxic and hard to get a hold of for a civilian and really stinky, being the major component of &quot;submarine smell&quot;.</p><p>Adsorption onto zeolites is also plausible, but the issue is that it requires alternately exposing the zeolites to high air pressure and low air pressure, and high airflow is required. The combination of high pressure and high airflow means that again, you&apos;re using a lot of energy. The basic math is as follows: One human produces about 1 kg of CO2 in 24 hours. We can idealize a perfect CO2 stripper as a magic box that inhales air and spits it out at 0 ppm. If you want a steady-state concentration of 500 ppm for 2 people, then we can see how much air-flow is required to lock up 2 kg of CO2 in 24 hours. This comes out to about 100 cubic feet per minute. This is the bare minimum air flow for any CO2 stripper, but in this particular case, it corresponds to a 25 horsepower air compressor, which is 18 kilowatts. This is equivalent to running 5 electric dryers at once. So that one is out too, especially since we were assuming 100% efficiency at eliminating CO2.</p><p>What about irreversible reactions? Just lock the CO2 up as a solid waste? Well, to begin with, this is going to produce quite a waste stream, and consume quite a bit of chemicals, you&apos;d better hope it&apos;s safe and that the feed chemical is cheap. The reaction used on space missions used lithium hydroxide. The basic idea is that lithium hydroxide makes a very basic solution. Carbon dioxide is slightly acidic, so it dissolves very fast into basic solutions. Then you get precipitation of lithium carbonate which is safe.</p><p>The problem is that lithium hydroxide is quite expensive. It was used on space missions because it&apos;s the most <em>mass-efficient</em> way of doing that sort of reaction and every gram counts in space missions, but we want the <em>cheapest</em> way of doing that reaction.</p><p>And then we hit upon the perfect solution. Calcium hydroxide. It&apos;s an extremely cheap bulk chemical, 15 bucks for a 50-pound sack of it at a hardware store. It&apos;s fairly mild as far as hydroxides go, being pH 12.4. So instead of giving you horrible chemical burns, it&apos;s safe to handle unless you&apos;re exposed to it for over an hour at a time without washing it off. It&apos;s the alkaline analogue of the difference between 1 M hydrochloric acid, and lemon juice. And when it reacts with CO2, it makes CaCO3, aka limestone, which is totally harmless. In fact, it&apos;s a common laboratory demonstration that breathing onto a solution of this stuff produces a white film/crust on the top, which is the CO2 in the breath locked up as solid limestone. It&apos;s the obvious choice if you&apos;re trying to remove CO2 via chemical means.</p><p>And in fact, in the SSC comment section, someone else independently had the exact same idea! Just lock up CO2 with calcium hydroxide!</p><p>The simplicity of an idea in the field of atoms instead of bits doesn&apos;t necessarily mean that anyone on earth has ever done it before, though, or will ever do it, and I&apos;m not worried about anyone scooping the idea, <em>because building novel hardware is hard enough to provide a natural barrier to entry</em> unless it&apos;s a large company that&apos;s interested in the idea. Ideas are cheap, execution is expensive, in both time and money.</p><h2>2: Only polymaths need apply</h2><p>If you&apos;re trying to build a novel machine in your garage, and aren&apos;t working as part of an engineering team, you will either need an improbably wide range of knowledge, or the general ability to pick up whatever you need to learn. There&apos;s the basic knowledge of chemistry to spot that this is the obvious reaction to go for, but the full design requires:</p><p>Familiarity with wastewater aerators to know what to buy to prevent clogging with solids, knowledge on which materials won&apos;t react with your chemicals,  the math of air flow in pipes, the ability to read fan pressure/airflow curves, the ability to go from &quot;I want a circuit that does this&quot; to building a novel electronic circuit on a breadboard without frying anything important, enough programming knowledge to write some basic arduino code, familiarity with hazardous waste disposal regulations in your state, familiarity with waste dewatering techniques, familiarity with which sort of pumps can pump sludge instead of pure water, some electrical engineering knowledge to work safely with 220V power without frying yourself or anyone else, knowledge of soundproofing, and <strong><em>especially</em></strong> the familiarity with everything at Home Depot that lets you home in on the most efficient and foolproof way of building a thing that does what you want. Probably some other stuff too that I consider obvious but others might not.</p><p>Now, most of this is pretty easy to pick up given enough starting mental firepower, and the sense of what to google for. Or just having lots of experience with building material things.</p><p>Having one of the relevant fields of knowledge manifests itself as knowing ahead of time which approaches will work and which will fail and what solutions past work in the area has already found.</p><p>For some of these, missing it will manifest as not knowing that there&apos;s an incoming bullet in a particular area, like not knowing that fine bubble aerators will promptly clog if there&apos;s lots of particulates in the water, or not suspecting that high air flow rates are incompatible with small pipe (I knew the latter one and it still almost got me until I idly decided to work out airflow velocity in the pipe and realized it was around 200 mph)</p><h2>3: The planning fallacy is <em><strong><u>huge</u></strong></em> here.</h2><p>So, it wound up costing a lot more than I thought and taking a lot longer than I thought. The mechanism of why the planning fallacy hits so hard here is tied in with the design process. What happens is that you start out with a sketchy outline of all the component parts (like, &quot;I need something that automatically dispenses chemical powder&quot;), and as it becomes time to build a part, you drill down further and further in fleshing out the details until eventually you&apos;ve drilled down far enough for your design to Actually Work in reality. While you do this, you will <em>inevitably</em> come across parts that are a lot harder to do than you expected, which you were glossing over on the first pass. The shiny black box of &quot;build a chemical dispenser&quot; looks more tractable than &quot;how the fuck do I build a motor mounting plate with my inadequate tools&quot;, which you didn&apos;t initially suspect you had to do because you weren&apos;t thinking at that level of detail. And also as you address the parts that are easy to do, all that is left is the parts that are hard or annoying or time-consuming to do, which can be somewhat demoralizing.</p><p>Same sort of thing goes with cost. You start out with &quot;so here&apos;s the cost for the big parts and everything else that&apos;s left shouldn&apos;t cost that much&quot; (black-box warning on &quot;everything else&quot;!), and then you go to Home Depot and pick up a bunch of 4-inch ABS pipe and black glue and all the 90 degree and T pieces you need for the aeration pipes and look at the cost and it&apos;s 100 bucks. Home Depot trips add up shockingly fast. There&apos;s also all the stuff you buy that you don&apos;t eventually end up using because the design evolves as you actually try to build it, like buying gears when you don&apos;t actually need gears, and all the stuff you didn&apos;t think you had to buy but it turns out that you do need it.</p><p>And sometimes you just get hit with some problem you didn&apos;t expect at all and now have to fix, like &quot;my fan is making a screaming noise, what do&quot;</p><h2>4. Why is there a valley of death?</h2><p>Universities and the government funds basic research. Then there&apos;s the private sector of business. The gap between the two, where you have to go from basic research to a business selling the new exciting thing is called the &quot;valley of death&quot;. Now, you&apos;d think this is what R&amp;D is for. But a lot of R&amp;D from a business seems to be focused on marginal improvements to existing things that already fall under the scope of what the existing business does, and not so much on building a novel thing that can be the seed of a new business. Building a novel thing requires a wide knowledge base, as discussed before, and inevitably takes a lot more money and time than expected. It&apos;s the sort of thing done by inventors in a garage as a project of love, not the sort of thing you get paid to do. </p><p>Further, crossing the valley of death requires both the technical capacity to build the thing, and the business skills to make a new business from scratch. If you have several people with different skills joined together, it can be bridged, but one flaw of doing it alone is that there are a lot more inventors with the ability to build the thing, than inventors with the ability to build the thing and also the ability or willingness to start a business that sells the thing. I&apos;m in the former category. I <em>can</em> build it, but I hate building it and if I have to build all the machines myself to sell, I&apos;d flatly reject it, and I <em>really</em> don&apos;t want to be responsible for running a business selling it, I&apos;d have no idea how to run a business, and it&apos;d eat too much time. My dream is to get a design good enough to sell, patent it, find someone willing to make a business out of it, and just receive a cut of profits without having to be involved in anything more regarding the production or selling of the machines, besides helping out with technical design work. Further, someone with just the business skills won&apos;t necessarily have the technical ability to come up with the machine in the first place, let alone build it. And there&apos;s also the lemon market problem of businesspeople identifying competent non-scam technical people with a viable design, and technical people finding competent non-scam businesspeople.</p><p>There are further issues such as designing the new invention such that it is robust and keeps working for a while (not a property that prototypes generally have), and designing it such that it is easy to build and maintain (also not usually a property associated with garage prototypes).</p><p>I&apos;ve heard that there&apos;s a company in the UK that takes garage prototypes and updates the design for robustness, easy constructibility, and cost, which seems like an important part of closing the valley.</p><h2>5. Building alone vs building as part of a team.</h2><p>In a certain sense, I was blessed on this project, because I had complete control over the entire design. I had to contend with no meetings, and no unexpected changes to parts of the design that were already locked in, and no team decisions that were dumb and couldn&apos;t possibly work. It&apos;s the dream for anyone who dislikes group projects in engineering. All failures are attributable to me alone, as well as all successes. Then again, having someone else to work on the project with me definitely would have sped it up and I could rely on their knowledge of things I was ignorant of, relaxing the polymath requirement. Maybe there&apos;s an optimal design team size? I guess it&apos;d depend on how parallelizable the work is, as well as how decision-making-quality scales with group size.</p><h2>6. Final diagnosis and where to go from here.</h2><p>So, it was over-time and over-budget and didn&apos;t work as well as I had hoped, but it does indeed work. Planning fallacy is a huge obstacle here, and I now certainly see why there&apos;s a valley of death for this sort of work.</p><p> In order to make a version that&apos;s practical for domestic use, I&apos;d have to redo the design to be a rain-column design, primarily because it only requires high airflow, instead of the combination of high airflow and high pressure, which requires buying an expensive fan from China and the expensive electronic components which provide the appropriate power to operate the fan. A rain column design could use a much cheaper and simpler fan that operates from a wall outlet. </p><p>Further, in order for others interested in CO2 reduction to have one of their own, I&apos;d have to team up with someone who could make a small business in assembling and selling these things, preferably involving someone who is not me building the relevant thing. PM me if interested.</p><br><br><br><br>",Diffractor,diffractor,Diffractor,
si76HRBRvewsRMeWP,"What's been written about the nature of ""son-of-CDT""?",what-s-been-written-about-the-nature-of-son-of-cdt,https://www.lesswrong.com/posts/si76HRBRvewsRMeWP/what-s-been-written-about-the-nature-of-son-of-cdt,2019-11-30T21:03:44.958Z,16,4,6,False,True,,"<p>I&apos;m quite curious what kind of decision algorithm a CDT agent might implement in a successor AI, but I&apos;ve only found a few vague references. Are there any good posts/papers/etc about this?</p>",liam-donovan,liam-donovan,Liam Donovan,
AnkJbcC54pr3RLeMH,How To Change a Dance,how-to-change-a-dance,https://www.lesswrong.com/posts/AnkJbcC54pr3RLeMH/how-to-change-a-dance,2019-11-30T13:40:01.625Z,11,5,7,False,False,,"<p>

Let's say you don't like something about your local dance.  Perhaps
you'd like to see gender free calling, a different approach to booking
bands, a new kind of special event, or something else.  How can you
make this happen?



</p><p>

The best case is that you talk to the organizers, they say ""what a
great idea!"" and handle the rest, but it rarely works this way. [1]
Maybe the organizers have a different background and don't understand
why you think your ideas would be an improvement.  Maybe your ideas
would be more work, at least at first, and they're feeling overworked
with what they're doing already.  Maybe the ideas take longer to
explain than you can get in during conversations at the break.  When
this works, it's the least difficult, but for anything tricky it seems
to me like it usually doesn't.

</p>

<p>

Here are three things, however, that I have seen work well:

</p>

<ul>

<li><p>Start helping out.  Come early and set up, stay late and clean
up, offer to help take money at the door.  By doing this work you
demonstrate a commitment to the community and to the dance, you learn
what's involved in running the dance, and you build trust with the
current organizers.  Then ask about joining the organizing committee.
While trusting you to arrive early and unlock the building doesn't
seem like it should translate into trusting your view on questions
like whether the dance should book more newer callers, it does seem to
work that way.  I think some of this is that doing the work to make
something happen builds ownership, which gets people to make
thoughtful decisions that are better for the long-term health of the
community.</p></li>

<li><p>Build consensus. Say you and your friends are all on board with
gender-free bathrooms, but a lot of other dancers are uneasy about
them.  If you had a vote you'd probably be in the minority, and if you
were able to change things by fiat you'd have a lot of unhappy dancers
and maybe a revolt.  How can you get to where this wouldn't be a
controversial change anymore?  Friendly one-on-one conversations can
go a long way here, especially when people can convey a perspective
someone hasn't considered much before.  Listen, figure out why other
people feel the way they do, share why you see it differently.  This
can be a lot of work, and the work of, in this example, building
consensus on gender free bathrooms will mostly fall fall on trans and
gender non-conforming dancers if you're not careful.  So if you're not
directly impacted by something, talk to those that are about what help
is needed.  As the idea moves towards the mainstream of the community,
most organizers will see that and go from ""maybe we should do that,
but the dancers wouldn't like it"" to ""sounds like this is what people
want.""</p></li>

<li><p>Start something new.  Sometimes what you're looking for is
different enough from the existing event that trying to change it
makes less sense than starting your own.  Find other people to start
it with you who have a similar perspective, put a bunch of thought
into how you'd like things to be different, and don't be afraid to try
approaches you don't see at other dances.  When this goes well the new
event expands the community by pulling in a new crowd of people and
builds a more robust scene.  The existing organizers will probably
worry that the current community isn't big enough to support an
additional event, and if you mostly just split the existing community
then they may be right.  Actively recruit from places the existing
event doesn't, run different kinds of publicity that fit what makes
your dance different, pull in new circles.</p></li>

</ul>



<p>

Which of these approaches makes the best sense for you in your
particular situation will vary, but volunteering to help out with the
dance is often a good place to start.

</p>

<p>
<br />

[1] I'm writing this as general advice, and I'm not trying to say ""don't
talk to me about BIDA"".  If you have thoughts about BIDA please let me
know, and I'd be happy to talk to you about how the dance can be better.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100124527208312"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
9rtWTHsPAf2mLKizi,Counterfactuals as a matter of Social Convention,counterfactuals-as-a-matter-of-social-convention,https://www.lesswrong.com/posts/9rtWTHsPAf2mLKizi/counterfactuals-as-a-matter-of-social-convention,2019-11-30T10:35:39.784Z,10,3,4,False,False,,"<p>In my <a href=""https://www.lesswrong.com/posts/j5CJZ566Pj3AwfrBT/open-box-newcomb-s-problem-and-the-limitations-of-the"">last post</a>, I wrote that the counterfactuals in Transparent-Box Newcomb&apos;s problem were largely a matter of social convention. One point I overlooked for a long time was that formalising a problem like Newcomb&apos;s is tricker than it seems. Depending on how it is written, some statements may seem to apply to just our actual world, some may seem to be also referring to counterfactual worlds and some may seem ambiguous.</p><p>To clarify this, I&apos;ll consider phrases that one might hear in relation to this problem + some variations and draw out their implications. I won&apos;t use modal logic since it really wouldn&apos;t add anything to this discussion except more jargon.</p><p>The idea that counterfactuals could have a social element should seem really puzzling at first. After all, counterfactuals determine what counts as a good decision and surely what is a good decision isn&apos;t just a matter of social convention? I think I know how to resolve this problem and I&apos;ll address that in a post soon, but for now I&apos;ll just provide a hint and link you to a comment by <a href=""http://lesswrong.com/posts/ao7KLoBEvMdHFjrNZ/counterfactuals-are-an-answer-not-a-question#6msAmGSx5FJecSHmz"">Abram Demski</a> talking about how probabilities are somewhere between subjective and objective.</p><p><strong>Example 1</strong>:</p><p>a) Omega is a perfect predictor</p><p>b) You find out from an infallible source that Omega will predict your choice correctly</p><p>The first suggests that Omega will predict you correctly no matter what you choose, so we might take it to apply to every counterfactual world, while it is technically possible that Omega might only be a perfect predictor in this world. The second is much more ambiguous and you might take its prediction to only be correct in this world and not the counterfactual.</p><p><strong>Example 2</strong>:</p><p>a) The first box always contains $1000</p><p>b) The first box contains $1000</p><p>First seems to be making a claim about counterfactual worlds again, while the second is ambiguous. It isn&apos;t clear if it applies to all worlds or not.</p><p><strong>Example 3</strong>: </p><p>&quot;The game works as follows: the first box contains $1000, while the second contains $0 or $1000 depending on whether the predictor predicts you&apos;ll two-box or one-box&quot;</p><p>Talking about the rules of the game seems to be a hint that this will apply to all counterfactuals. After all, decision problems are normally about winning within a game, as opposed to the rules changing according to your decision.</p><p><strong>Example 4</strong>:</p><p>a) The box in front of you contains $1 million</p><p>b) The box in front of you contains either $0 or $1 million. In this case, it contains $1 million</p><p>The first is ambiguous. The second seems to make a statement about all counterfactuals, then one about this world. If it were making a statement just about this world then the first sentence wouldn&apos;t have been necessary.</p><p><strong>Lessons</strong></p><p>This could be leveraged to provide a critique of the <a href=""https://www.lesswrong.com/posts/BRuWm4GxcTNPn4XDX/deconfusing-logical-counterfactuals"">erasure approach</a>. This approach wants to construct a non-trivial decision problem by erasing information, but this analysis suggests that either a) this may be unnecessary because it is already implicit in the problem which information is universal or not or b) the issue isn&apos;t that we need to figure out which assumption to erase, but that the problem is ambiguous about which parts should be taken universally.</p>",Chris_Leong,chris_leong,Chris_Leong,
mdau2DBSMi5bWXPGA,Useful Does Not Mean Secure,useful-does-not-mean-secure,https://www.lesswrong.com/posts/mdau2DBSMi5bWXPGA/useful-does-not-mean-secure,2019-11-30T02:05:14.305Z,46,16,12,False,False,,"<html><head></head><body><p><i>Brief summary of what I'm trying to do with this post:</i></p><ol><li><i>Contrast a “Usefulness” focused approach to building AI with a “Security” focused approach, and try to give an account of where security problems come from in AI.</i></li><li><i>Show how marginal transparency improvements don’t necessarily improve things from the perspective of security.</i></li><li><i>Describe what research is happening that I think is making progress from the perspective of security.</i></li></ol><p><i>In this post I will be attempting to</i><a href=""https://www.lesswrong.com/posts/WBdvyyHLdxZSAMmoz/taboo-your-words""><i><u> taboo</u></i></a><i> the term 'alignment', and just talk about properties of systems. The below is not very original, I'm often just saying things in my own words that</i><a href=""https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like""><i><u> Paul</u></i></a><i> and</i><a href=""https://www.lesswrong.com/posts/8gqrbnW758qjHFTrH/security-mindset-and-ordinary-paranoia""><i><u> Eliezer</u></i></a><i> have written, in large part just to try to think through the considerations myself. My thanks to Abram Demski and Rob Bensinger for comments on a draft of this post, though this doesn't mean they endorse the content or anything.</i></p><h2>Useful Does Not Mean Secure</h2><p>This post grew out of a comment thread <a href=""https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety#QyeCpFTcXsQuxpz7B""><u>elsewhere</u></a>. In that thread, Ray Arnold was worried that there was an uncanny valley of how good we are at understanding and building AI where we can build AGI but not a safe AGI. Rohin Shah replied, and I'll quote from his reply:</p><blockquote><p>Consider instead this worldview:</p></blockquote><blockquote><p><i>The way you build things that are useful and do what you want is to understand how things work and put them together in a deliberate way. If you put things together randomly, they either won't work, or will have unintended side effects.</i></p><p>(This worldview can apply to far more than AI; e.g. it seems right in basically every STEM field. You might argue that putting things together randomly seems to work surprisingly well in AI, to which I say that it really doesn't, you just don't see all of the effort where you put things together randomly and it simply flat-out fails.)</p><p>The argument ""it's good to for people to understand AI techniques better even if it accelerates AGI"" is a very straightforward non-clever consequence of this worldview.</p><p>[...]</p><p>Under the worldview I mentioned, the first-order effect of better understanding of AI systems, is that you are more likely to build AI systems that are useful and do what you want.</p></blockquote><p>A lot of things Rohin says in that thread make sense. But in this post, let me point to a different perspective on AI that I might consider, if I were to focus entirely on Paul Christiano's<a href=""https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like""> model of greedy algorithms in part II of his post on what failure looks like</a>. That perspective sounds something like this:</p><blockquote><p><i>The way you build things that are useful and do what you want, when you're in an environment with much more powerful optimisers than you, is to spend a lot of extra time making them secure against adversaries, over and above simply making them useful. This is so that the other optimisers cannot exploit your system to achieve their own goals.</i></p><p><i>If you build things that are useful, predictable, and don't have bad side-effects, but are subject to far more powerful optimisation pressures than you, then by default the things you build will be taken over by other forces and end up not being very useful at all.</i></p></blockquote><p>An important distinction about artificial intelligence research is that you're not simply competing against other humans, where you have to worry about hackers, governments and political groups, but that the core goal of artificial intelligence research is the <i>creation</i> of much more powerful general optimisers than currently exist within humanity. This is a difference in kind from all other STEM fields.</p><p>Whereas normal programming systems that aren't built quite right are more likely to do dumb things or just break, when you make an AI system that isn't exactly what you wanted, the system might be powerfully optimising for other targets in a way that has the potential to be highly adversarial. In discussions of AI alignment, Stuart Russell often likes to use an analogy to “building bridges that stay up” being an entirely integrated field, not distinct from bridge building. To extend the analogy a little, you might say the field of AI is unusual in that if you don't quite make the bridge well enough, the bridge itself may actively seek out security vulnerabilities that bring the bridge down, then hide them from your attention until such a time as it has the freedom to take the bridge down in one go, and then take out all the other bridges in the world.</p><p>Now, talk of AI necessarily blurs the line between 'external optimisation pressures' and 'the system is useful and does what you want' because the system itself is <i>creating</i> the new, powerful optimisation pressure that needs securing against. Paul's<a href=""https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like""> post</a> on what failure looks like talks about this, so I’ll quote it here:</p><blockquote><p>Modern ML instantiates <i>massive</i> numbers of cognitive policies, and then further refines (and ultimately deploys) whatever policies perform well according to some training objective. If progress continues, eventually machine learning will probably produce systems that have a detailed understanding of the world, which are able to adapt their behavior in order to achieve specific goals.</p><p>Once we start searching over policies that understand the world well enough, we run into a problem: any influence-seeking policies we stumble across would also score well according to our training objective, because performing well on the training objective is a good strategy for obtaining influence.</p><p>How frequently will we run into influence-seeking policies, vs. policies that just straightforwardly pursue the goals we wanted them to? I don’t know.</p></blockquote><p>You could take the position that, even though security work is not normally central to a field, this new security work is already central to this field, so increasing the ability to build 'useful' things will naturally have to solve this novel security work, so the field of AI will get it right by default.</p><p>This is my understanding of Paul's mainline expectation (based on his estimates<a href=""https://www.lesswrong.com/posts/qnYZmtpNPZyqHpot9/conversation-with-paul-christiano""> here</a> and that his work is based around making useful / well motivated AI described<a href=""https://www.lesswrong.com/s/EmDuGeRw749sD3GKd/p/4iPBctHSeHx8AkS6Z""> here</a>,<a href=""https://www.lesswrong.com/s/EmDuGeRw749sD3GKd/p/ZeE7EKHTFMBs8eMxn""> here</a> and<a href=""https://www.lesswrong.com/s/EmDuGeRw749sD3GKd/p/ZeE7EKHTFMBs8eMxn#3ECKoYzFNW2ZqS6km""> in Rohin’s comment on that post</a>) and also my understanding of Rohin's mainline expectation (based on his estimates<a href=""https://www.lesswrong.com/posts/TdwpN484eTbPSvZkm/rohin-shah-on-reasons-for-ai-optimism""> here</a>). My understanding is this still means there's a lot of value on the table from marginal work, so both of them work on the problem, but by default they expect the field to engage with this problem and do it well.</p><p>Restatement: In normal tech companies, there's a difference between ""making useful systems"" and ""making secure systems"". In the field of AI, ""making useful systems"" includes potentially building powerful adversaries, which involves novel security problems, so you might expect that executing the standard ""make useful systems"" will result in solving the novel security features.</p><p>For example, in a<a href=""https://www.lesswrong.com/posts/WxW6Gc6f2z3mzmqKs/debate-on-instrumental-convergence-between-lecun-russell""> debate on instrumental convergence between various major AI researchers</a>, this was also the position that Francesca Rossi took:</p><blockquote><p>Stuart, I agree that it would easy to build a coffee fetching machine that is not aligned to our values, but why would we do this? Of course value alignment is not easy, and still a research challenge, but I would make it part of the picture when we envision future intelligent machines.</p></blockquote><p>However, Yann LeCun said something subtly different:</p><blockquote><p>One would have to be rather incompetent not to have a mechanism by which new terms in the objective could be added to prevent previously-unforeseen bad behavior.</p></blockquote><p>Yann is implicitly taking the stance that there will not be powerful adversarial pressures exploiting such unforeseen differences in the objective function and humanity's values. His responses are of the kind ""We wouldn't do that"" and ""We would change it quickly when those problems arose"", but not ""Here's how you build a machine learning system that cannot be flawed in this way"". It seems to me that he does not expect there to be any further security concerns of the type discussed above. If I pointed out a way that your system would malfunction, it is sometimes okay to say “Oh, if anyone accidentally gives that input to the system, then we’ll see and fix any problems that occur”, but if your government computer system is not secure, then by the time you’ve noticed what’s happening, a powerful adversary is inside your system and taking actions against you.</p><p>(Though I should mention that I don't think this is the crux of the matter for Yann. I think his key disagreement is that he thinks we cannot talk usefully about safe AGI design before we know how to build an AGI - he doesn't think that<a href=""https://ai-alignment.com/prosaic-ai-control-b959644d79c2""> prosaic AI alignment</a> is in principle feasible or worth thinking about.)</p><p>In general, it seems to me that if you show me how an AI system is flawed, if my response is to simply patch that particular problem then go back to relaxing, I am implicitly disbelieving that optimisation processes more powerful than human civilization will look for similar flaws and exploit them, as otherwise my threat level would go up drastically.</p><p>To clarify what this worry looks like: advances in AGI are hopefully building systems that can scale to being as useful and intelligent as is physically feasible in our universe - optimisation power way above that of human civilization's. As you start getting smarter, you need to build more into your system to make sure the smart bits can't exploit the system for their own goals. This assumes an epistemic advantage, as Paul says in the Failure post:</p><blockquote><p>Attempts to suppress influence-seeking behavior (call them “immune systems”) rest on the suppressor having some kind of epistemic advantage over the influence-seeker. Once the influence-seekers can outthink an immune system, they can avoid detection and potentially even compromise the immune system to further expand their influence. If ML systems are more sophisticated than humans, immune systems must themselves be automated. And if ML plays a large role in that automation, then the immune system is subject to the same pressure towards influence-seeking.</p></blockquote><p>There's a notion whereby if you take a useful machine learning system, and you just make it more powerful, what you're essentially doing is increasing the intelligence of the optimisation forces passing through it, including the adversarial optimisation forces. As you take the system and make it vastly superintelligent, your primary focus needs to be on security from adversarial forces, rather than primarily on making something that's useful. You've become an AI security expert, not an AI usefulness expert. The important idea is that AI systems can break at higher levels of intelligence, even if they're currently quite useful.</p><p>As I understand it, this sort of thing happened at Google, who first were a computer networks experts, and then became security experts, because for a while the main changes they made to Google Search were to increase security and make it harder for people to game the pagerank system. The adversarial pressures on them have since hit terminal velocity and there probably won't be any further increases, unless and until we build superintelligent AI (be it general or the relevant kind of narrow.)</p><h2>Marginal Transparency Does Not Mean Marginal Security</h2><p>A key question in figuring out whether to solve this security problem via technical research (as opposed to global coordination) is whether a line of work differentially makes this sort of security from optimisation powers easier to work on, or whether it simply makes the system more useful in ways that don't account for the novel adversaries.</p><p>In the quote from Rohin above, and by other people in other places, it sounds to me like the case being made is that the system is generally becoming more understandable, so it's both easier to build and easier to secure. All improvements in understanding are improvements in being able to 'do useful things'. And indeed my general prior is that increasing understanding is always better. But one of the core arguments Nick Bostrom makes is that not all scientific insights are positive for a civilisation at its current level of wisdom, and that we need to be able to order which insights we get. There are many types of 'increased understanding', and it's not the case that all of them are positive on the current margin.</p><p>Let me give a concrete example where more transparency increases usefulness but not security.&nbsp;</p><p>It’s sometimes the case that, in prisons, the prison staff will attempt to get the prisoners to help out with tasks, errands and maintenance around the prison. However, if you send them into offices and parts of the prison but don’t watch what they do, then they may conspire against the prison staff - build things that can be used as weapons against the guards, build tunnels, use computers to contact the outside world, etc.&nbsp;</p><p>Now, if you start looking at what the prisoners are doing when they’re in office block #17, and you have basic rewards/punishments (e.g. giving or removing access to special foods and entertainment things), then you can reward them for doing good work there, and punish them for doing bad work there. You can also punish them for conspiring against you there.</p><p>However, this hasn’t really helped. if they were planning to build a tunnel in office block #17, they will now just build a tunnel in office block #18 instead. If I can start to see what they do all the time in some locations, then I can punish the ones that aren't doing broadly the right work, and generally make sure they're doing useful work. But this doesn't mean that in the places I can't look that they're not conspiring against me. It seems plausible to me that many improvements in transparency, while making it easier to make the people do the prison’s work, do not make it harder to conspire against me, and just <i>move around where the conspiring is happening</i>.</p><p>If you’re trying to delegate and incentivise people to do labour for you, you might just think that you should bring in a good manager, to get people to do useful work. But in the prison situation, you primarily need to become a security expert, over and above being an expert in how to manage well. In this situation, there are many improvements in transparency of what they're doing that helps force them to do <i>useful</i> work, that doesn't secure them against conspiring with each other to break out of the system.&nbsp;</p><p>With machine learning systems, we already have all the weights on the NN's to look at, so the system is maximally transparent. We can see everything, for certain values of 'see'. I think the relevant question is ""on what level you can understand what's going on"". As we get higher-level understanding, we can maybe start to figure out if it's doing certain bad things, or certain good things, and punish/reward those. But just because you're making sure that the process will do something useful (e.g. invest money, run a hospital, classify images) doesn't mean I know how to tell whether this will lead to the type of full understanding that means that adversarial work can't be moved to areas that are too hard / very costly for me to understand.</p><p>Restatement: Marginal improvements in understandability and transparency can make it much easier to make <i>useful</i> systems but it's not necessarily the case that it produces a meaningful difference in the ability to produce <i>secure</i> systems. It will allow us, at increasingly higher levels of understanding, to be able to change the type of work needed to exploit the system; this is not the same as a design that is safe no matter how powerful the optimisation power against us.</p><p>I wrote this in response to Ray trying to figure out how to tell whether any given type of machine learning research is making differential progress. The specific type of research discussed in that thread has a more detailed story which I won't go into here, and mostly seems very helpful from my layman perspective, but I think that research ""either being of zero impact, or else making the whole field more transparent/understandable"" does not mean that the research makes differential progress on making the system secure. Marginal transparency can increase usefulness without increasing security.</p><p>In one sense, a machine learning system is maximally transparent - I can see every part of what it is doing. But while I don't understand its reasoning, while there are levels on which I don't know what it’s thinking, by default I’m not confident that adversarial thought hasn't just moved there instead.</p><h2>Current Technical Work on Security</h2><p>From this perspective, let me talk about the research that seems like it's aiming to help on the security front. This is not all the work being done, just the work that I feel I understand well enough to summarise from this perspective.</p><p>My understanding is that the main work attempting to pinpoint where optimisation enters the system in surprising ways is Hubinger, Mikulik, Skalse, van Merwijk and Garrabrant's work on risks from learned optimisation (<a href=""https://arxiv.org/abs/1906.01820"">paper</a>,<a href=""https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB""> sequence</a>). This gives lots of names to concepts describing how optimisers work, and asks questions like:</p><ul><li>Under what conditions will my learned algorithm itself do optimisation?</li><li>When the learned algorithm does optimisation, what will its objective be, and what will the relationship be between its objective and the loss function of the neural net that produced it?</li><li>If the learned optimiser has successfully built a model of the objective function that was used to build it, what conditions predict whether it will it be working around my objective as opposed to toward it?</li><li>When should I expected the optimiser in the learned algorithm to try to deceive me?</li></ul><p>The paper also asks whether it's possible to prevent influence-seeking algorithms from entering your systems by creating complexity measures on the system, such as time and space penalties. On this topic, Paul Christiano has asked<a href=""https://www.lesswrong.com/posts/nyCHnY7T5PHPLjxmN/open-question-are-minimal-circuits-daemon-free""> whether requiring systems be maximally efficient according to circuit description length removes all adversarial behaviour</a>; and Evan has offered<a href=""https://www.lesswrong.com/posts/fM5ZWGDbnjb7ThNKJ/are-minimal-circuits-deceptive""> an answer in the negative.</a></p><p>It's also the case that the Agent Foundations team at MIRI is trying to think about the problem of inner alignment more broadly, and poke at various concepts around here, such as in their writeups on<a href=""https://www.alignmentforum.org/s/Rm6oQRJJmhGCcLvxh/p/i3BTagvt3HbPMx6PN#4__Robust_delegation""> Robust Delegation and Subsystem Alignment</a>. This explores many simple background questions to which we don't have principled answers, and cannot draw toy models of intelligent agents that reliably get these problems right.</p><ul><li><i>Is there a principled way to figure out whether I should trust that something more intelligent than me shares my values, given that I can't figure out exactly what it's going to do?</i> If I am a child, sometimes adults will do something that the opposite of what I want - is there a way of figuring out whether they're doing this in accordance with my goals?</li><li><i>How should I tell a more intelligent agent than me what I want it to do, given that I don't know everything about what I want?</i> This is especially hard given that optimisation amplifies the differences between what I say I want and what I actually want (aka Goodhart's Law).</li><li><i>How do I make sure the different parts of a mind are in a good balance, rather than some parts overpowering other parts?</i> When it comes to my own mind, sometimes different parts get out of whack and I become too self-critical, or overconfident, or depressed, or manic. Is there a principled way of thinking about this?</li><li><i>How do I give another agent a good description of what to do in a domain, without teaching them everything I know about the domain?</i> This is a problem in companies, where sometimes people who don't understand the whole vision can make bad tradeoffs.</li></ul><p>That's the work I feel I have a basic understanding of. I'm curious about explanations of how other work fits into this framework.</p></body></html>",Benito,benito,Ben Pace,
zcYJBTGYtcftxefz9,Neural Annealing: Toward a Neural Theory of Everything (crosspost),neural-annealing-toward-a-neural-theory-of-everything,https://www.lesswrong.com/posts/zcYJBTGYtcftxefz9/neural-annealing-toward-a-neural-theory-of-everything,2019-11-29T17:31:12.730Z,87,36,29,False,False,,"<p><em>The following is QRI&apos;s unified theory of music, meditation, psychedelics, depression, trauma, and emotional processing. Implications for how the brain implements Bayesian updating, and future directions for neuroscience. Crossposted from <a href=""http://opentheory.net"">http://opentheory.net</a></em></p><p><em>-----------------</em></p><p>Context: follow-up to <a href=""https://opentheory.net/2018/12/the-neuroscience-of-meditation/"">The Neuroscience of Meditation</a> and <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/#"">A Future For Neuroscience</a>; a unification of (1) <em>the Entropic Brain</em> &amp; <em>REBUS</em> (Carhart-Harris et al. <a href=""https://www.frontiersin.org/articles/10.3389/fnhum.2014.00020/full"">2014</a>; <a href=""https://www.ncbi.nlm.nih.gov/pubmed/29548884"">2018</a>; <a href=""http://pharmrev.aspetjournals.org/content/pharmrev/71/3/316.full.pdf"">2019</a>), (2) <em>the Free Energy Principle</em> (Friston <a href=""https://www.fil.ion.ucl.ac.uk/~karl/The%20free-energy%20principle%20A%20unified%20brain%20theory.pdf"">2010</a>), (3) <em>Connectome-Specific Harmonic Waves</em> (Atasoy et al. <a href=""https://www.nature.com/articles/ncomms10340"">2016</a>; <a href=""https://www.biorxiv.org/content/10.1101/162040v1"">2017</a>), and (4) QRI&#x2019;s <em>Symmetry Theory of Valence</em> (<a href=""https://opentheory.net/PrincipiaQualia.pdf"">Johnson 2016</a>; <a href=""https://qualiacomputing.com/2017/06/18/quantifying-bliss-talk-summary/"">Gomez Emilsson 2017</a>).</p><p><strong><u>0. Introduction</u></strong></p><p><em>Why is neuroscience so hard?</em></p><p>Part of the problem is that the brain is complicated. But we&#x2019;ve also mostly been doing it wrong, trying to explain the brain using methods that couldn&#x2019;t possibly generate insight about the things we care about.</p><p>On <a href=""https://www.qualiaresearchinstitute.org/research-lineages"">QRI&#x2019;s lineages page</a>, we suggest there&#x2019;s a distinction between &#x2018;old&#x2019; and &#x2018;new&#x2019; neuroscience:</p><blockquote><em>Traditionally, neuroscience has been concerned with</em> <em>cataloguing the brain, e.g. collecting discrete observations about anatomy, observed cyclic patterns (EEG frequencies), and cell types and neurotransmitters, and trying to match these facts with functional stories. However, it&#x2019;s increasingly clear that these sorts of neat stories about localized function are artifacts of the tools we&#x2019;re using to look at the brain, not of the brain&#x2019;s underlying computational structure.</em></blockquote><blockquote><em>What&#x2019;s the alternative? Instead of centering our exploration on the sorts of raw data our tools are able to gather, we can approach the brain as a self-organizing system, something which uses a few core principles to both build and regulate itself. As such, if we can reverse-engineer these core principles and use what tools we have to</em> <em>validate</em> <em>these bottom-up models, we can both understand the internal logic of the brain&#x2019;s algorithms &#x2014; the how and why the brain does what it does &#x2014; as well as find more elegant intervention points for altering it.</em></blockquote><p>That&#x2019;s a big check to try to cash. What might this look like?</p><p><strong><u>I. Annealing metaphors for the brain</u></strong></p><p>In my post about the neuroscience of meditation, I talked about <em>simulated annealing</em>, a natural implication of Robin Carhart-Harris&#x2019;s work on entropic disintegration in the brain:</p><blockquote><em>Annealing involves heating a metal above its recrystallization temperature, keeping it there for long enough for the microstructure of the metal to reach equilibrium, then slowly cooling it down, letting new patterns crystallize. This releases the internal stresses of the material, and is often used to restore ductility (plasticity and toughness) on metals that have been &#x2018;cold-worked&#x2019; and have become very hard and brittle&#x2014; in a sense, annealing is a &#x2018;reset switch&#x2019; which allows metals to go back to a more pristine, natural state after being bent or stressed. I suspect this is a useful metaphor for brains, in that they can become hard and brittle over time with a build-up of internal stresses, and these stresses can be released by periodically entering high-energy states where a more natural neural microstructure can reemerge.</em></blockquote><p>In his work on the <a href=""https://www.frontiersin.org/articles/10.3389/fnhum.2014.00020/full"">entropic brain</a>, Carhart-Harris studies how psychedelics like LSD and psilocybin add enough energy (neural activity) to the brain that existing neural patterns are disrupted, much like how heating a metal disrupts its existing molecular bonds. Recently, Carhart-Harris and Friston have unified their frameworks under the <a href=""http://pharmrev.aspetjournals.org/content/pharmrev/71/3/316.full.pdf"">REBUS</a> (RElaxed Beliefs Under pSychedelics) model, which also imports the annealing metaphor for brains:</p><blockquote><em>The hypothesized flattening of the brain&#x2019;s (variational free) energy landscape under psychedelics can be seen as analogous to the phenomenon of simulated annealing in computer science&#x2014;which itself is analogous to annealing in metallurgy, whereby a system is heated (i.e., instantiated by increased neural excitability), such that it attains a state of heightened plasticity, in which the discovery of new energy minima (relatively stable places/trajectories for the system to visit/reside in for a period of time) is accelerated (Wang and Smith, 1998). Subsequently, as the drug is metabolized and the system cools, its dynamics begin to stabilize&#x2014;and attractor basins begin to steepen again (Carhart-Harris et al., 2017). This process may result in the emergence of a new energy landscape with revised properties.</em></blockquote><p>It&#x2019;s a powerful metaphor since it ties together and recontextualizes so many core neuroscience concepts: free energy landscapes, Bayesian modeling, the &#x2018;handshake&#x2019; between bottom-up sense-data and top-down priors. For a general overview of the math, see Wikipedia on <a href=""https://en.wikipedia.org/wiki/Simulated_annealing"">simulated annealing</a>, <a href=""https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"">Metropolis-Hastings algorithm</a>, <a href=""https://en.wikipedia.org/wiki/Parallel_tempering"">Parallel tempering</a>; for more on Carhart-Harris&#x2019;s and Friston&#x2019;s work, see <a href=""https://slatestarcodex.com/2019/09/10/ssc-journal-club-relaxed-beliefs-under-psychedelics-and-the-anarchic-brain/"">Scott Alexander</a>&#x2019;s and <a href=""https://qualiacomputing.com/2019/08/27/carhart-harris-friston-2019-rebus-and-the-anarchic-brain/"">Milan Griffes</a>&#x2019; commentary. There seems to be some convergence on this metaphor: as Scott Alexander <a href=""https://slatestarcodex.com/2019/09/10/ssc-journal-club-relaxed-beliefs-under-psychedelics-and-the-anarchic-brain/"">noted</a>,</p><blockquote><em>F&amp;CH aren&#x2019;t the first people to discuss this theory of psychedelics. It&#x2019;s been in the air for a couple of years now &#x2013; and props to local bloggers at the</em> <em><a href=""https://qualiacomputing.com/2018/12/22/what-is-love-neural-annealing-in-the-presence-of-an-intentional-object/?fbclid=IwAR0WmmaJPHint_jkDCs13z6kPIgPn9ChkSWIWSlxnVvphPnSw8baje2tbhg"">Qualia Research Institute</a></em> <em>and</em> <em><a href=""https://mad.science.blog/2019/08/02/thought-scripts/"">Mad.Science.Blog</a></em> <em>for getting good explanations up before the parts had even all come together in journal articles. I&#x2019;m especially interested in QRI&#x2019;s theory that meditation has the same kind of annealing effect, which I think would explain a lot.</em></blockquote><p><u>The basics: how does annealing work?</u></p><p>Carhart-Harris&#x2019;s and Friston&#x2019;s model does many very clever things and is a substantial addition to the literature; I start from a similar frame but describe the process slightly differently. The following is QRI&#x2019;s model (based on my talk on the <a href=""https://www.youtube.com/watch?v=nY9H5CK4GbE"">Neuroscience of Meditation</a> in Thailand):</p><ul><li>First, energy (neural excitation, e.g. Free Energy from prediction errors) builds up in the brain, either gradually or suddenly, collecting disproportionately in the brain&#x2019;s natural eigenmodes;</li><li>This build-up of energy (rate of neural firing) crosses a metastability threshold and the brain enters a high-energy state, causing entropic disintegration (weakening previously &#x2018;sticky&#x2019; attractors);</li><li>The brain&#x2019;s neurons self-organize into new multi-scale equilibria (attractors), aka implicit assumptions about reality&#x2019;s structure and value weightings, which given present information should generate lower levels of prediction error than previous models (this is implicitly both a <em>resynchronization of internal predictive models with the environment</em>, and a <em>minimization of dissonance in connectome-specific harmonic waves</em>);&#xA0;</li><li>The brain &#x2018;cools&#x2019; (neural activity levels slowly return to normal), and parts of the new self-organized patterns remain and become part of the brain&#x2019;s normal activity landscape;</li><li>The cycle repeats, as the brain&#x2019;s models become outdated and prediction errors start to build up again.</li></ul><p>Any &#x2018;emotionally intense&#x2019; experience that you need time to process most likely involves this <em>entropic disintegration-&gt;search-&gt;annealing</em> mechanism&#x2014; this is what emotional processing <em>is</em>.</p><p>And I&#x2019;d suggest that this is the <em>core dynamic of how the brain updates its structure</em>, the mechanism the brain uses to pay down its &#x2018;technical debt&#x2019;. In other words, entering high-energy states (i.e., intense emotional states which take some time to &#x2018;process&#x2019;) is how the brain releases structural stress and adapts to new developments. This process needs to happen on a regular basis to support healthy function, and if it doesn&#x2019;t, psychological health degrades&#x2014; In particular, mental flexibility &amp; emotional vibrancy go down &#x2014; analogous to a drop in a metal&#x2019;s &#x2018;ductility&#x2019;. People seem to have a strong subconscious drive toward entering these states and if they haven&#x2019;t experienced a high-energy brain state in some time, they actively seek one out, even sometimes in destructive ways.</p><p>However, the brain spends most of its time in low-energy states, because they&#x2019;re safer: systems in noisy environments need to limit their rate of updating. There are often <em>spikes</em> of energy in the brain, but these don&#x2019;t tend to snowball into full high-energy states because the brain has many &#x2018;energy sinks&#x2019; (inhibitory top-down predictive models) which soak up excess energy before entropic disintegration can occur.</p><p>But the brain can enter high-energy states if these energy sinks are:</p><p>(1) <u>De-activated</u>, if certain evolved trigger conditions are present- e.g., death of a loved one, falling in love, good sex, social rejection, getting bitten by a weird animal, failing some important prediction. In these cases there seems to be some sort of adaptive gating mechanism that disables the typical energy sinks in order to allow entropic disintegration-&gt;search-&gt;annealing to happen.</p><p>(2) <u>Overwhelmed</u>, if there&#x2019;s an enormous magnitude of energy coming in, faster than the energy sinks can mop it up- e.g., watching a horror movie, direct brain stimulation, first day of school, being sleep deprived, military boot camp, cult indoctrinations, your wedding day.</p><p>(3) <u>Avoided</u>, if <em>semantically-neutral energy</em> is applied to the system. Essentially, coherent energy which isn&#x2019;t strongly linked to any cognitive, emotional, or sensory process will be partially illegible to most existing energy sinks, and so it can persist long enough to build up <em>&#x2013;</em> basically &#x2018;hacking&#x2019; the brain&#x2019;s activity normalization system. (Hold that thought <em>&#x2013;</em> this is the most interesting one. We&#x2019;ll return to it later.)</p><p>This is the &#x2018;view from 30,000 feet&#x2019; for how simulated annealing in the brain works. If you stopped reading here, you&#x2019;d walk away with a reasonable toy model of QRI&#x2019;s &#x201C;Neural Annealing&#x201D; framework.</p><p>But there&#x2019;s a lot more to the model! The rest of this writeup is an iterative tour using Neural Annealing to explain meditation, trauma, love, depression, psychedelics, and effective therapy, with each section adding a variation on the core theme.</p><p><strong><u>Interlude: FEP, CSHW, and EBH/REBUS</u></strong></p><p>QRI&#x2019;s &#x201C;Neural Annealing&#x201D; framework is essentially a unification of Karl Friston&#x2019;s Free Energy Principle (FEP), Selen Atasoy&#x2019;s Connectome-Specific Harmonic Waves (CSHW), Robin Carhart-Harris&#x2019;s Entropic Brain Hypothesis (EBH), and QRI&#x2019;s own Symmetry Theory of Valence (STV). Recently, Friston and Carhart-Harris have unified their respective paradigms with the <em>Relaxed Beliefs Under pSychedelics</em> (REBUS) model. I believe combining <em>all three</em> is exponentially more powerful, not only giving the <em>computational-level story</em> of REBUS, but also giving us a model for <em>how the brain may be physically implementing REBUS, and Bayesian updating in general</em>, with a correspondingly richer set of predictions.&#xA0;</p><p>First, here&#x2019;s a quick recap: to paraphrase what I wrote <a href=""https://opentheory.net/2018/06/seed-ontologies/"">elsewhere</a>,</p><p><u>Karl Friston&#x2019;s Free Energy Principle (FEP)</u> is the leading theory of self-organizing system dynamics, one which has (in various guises) pretty much taken neuroscience by storm. It argues that any self-organizing system which effectively resists disorder must (as its core organizing principle) minimize its free energy, that free energy is equivalent to surprise (in a Bayesian sense), and that this surprise-minimization drives basically all human behavior. This minimization of surprise revolves around Bayesian-type reasoning: the brain is always getting bottom-up sense data flowing in, more than it can handle. So it relies on top-down predictive models that attempt to sort through all this data so we can focus on the surprising stuff, the stuff that can&#x2019;t be effortlessly predicted. The core of the FEP is the details of how this &#x2018;handshake&#x2019; between bottom-up and top-down happens, and what can influence it. See <a href=""https://www.researchgate.net/publication/41001209_Friston_KJ_The_free-energy_principle_a_unified_brain_theory_Nat_Rev_Neurosci_11_127-138"">Friston&#x2019;s primary work</a>; <a href=""https://slatestarcodex.com/2018/03/04/god-help-us-lets-try-to-understand-friston-on-free-energy/"">Scott Alexander&#x2019;s attempt to distill it</a>. Related to (and sometimes used synonymously with) <a href=""https://opentheory.net/wp-content/uploads/2018/06/Screen-Shot-2018-06-02-at-11.png"">Active Inference, the Bayesian Brain, and Predictive Processing / Predictive Coding</a>.</p><p><u>Robin Carhart-Harris&#x2019;s Entropic Brain Hypothesis (EBH)</u> is essentially an attempt to import key concepts such as entropy and self-organized criticality from statistical physics into neuroscience, in order to explain psychedelic phenomena. As I noted above, it suggests that certain conditions <em>such as</em> psychedelics can add enough energy to brain networks that they undergo &#x2018;entropic disintegration&#x2019;, and then self-organize into new equilibria. See <a href=""https://www.ncbi.nlm.nih.gov/pubmed/29548884"">Carhart-Harris 2018</a>.&#xA0;</p><p><u>Selen Atasoy&#x2019;s Connectome-Specific Harmonic Waves (CSHW)</u> is a method for applying harmonic analysis to the brain: basically, it uses various forms of brain imaging to infer what the brain&#x2019;s natural resonant frequencies (eigenmodes) are, and how much energy each of these frequencies have. The core workflow is three steps: first combine MRI and DTI to approximate a brain&#x2019;s connectome, then with an empirically-derived wave propagation equation calculate what the natural harmonics are of this connectome, then estimate which power distribution between these harmonics would most accurately reconstruct the observed fMRI activity. This framework offers several notable things: (a) these connectome-specific harmonic waves (CSHWs) are natural Schelling points that the brain has probably self-organized around (and so are worth talking about); (b) a plausible mid-level bridge connecting bottom-up neural dynamics and high-level psychological phenomena, (c) something we can actually measure. CSHW is an empirical paradigm, which is very uncommon in theoretical neuroscience. Here&#x2019;s a <a href=""https://qualiacomputing.com/2017/06/18/connectome-specific-harmonic-waves-on-lsd/"">transcript of Atasoy&#x2019;s explanation</a>; I also wrote extensively about CSHW in <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/#"">A Future for Neuroscience</a>.</p><p>In short: each of these three paradigms is a description of how the brain self-organizes. Friston&#x2019;s work understands the self-organization from a computational lens; Carhart-Harris an energetic lens; Atasoy a physical lens.</p><p>Finally, I&#x2019;d offer two further pieces of background context:&#xA0;</p><p><u>QRI&#x2019;s own Symmetry Theory of Valence (STV)</u>, which hypothesizes that given a mathematical representation of an experience, the <em>symmetry</em> of this representation will encode how pleasant the experience is (<a href=""https://opentheory.net/2016/11/principia-qualia/"">Johnson 2016</a>). We further hypothesize that consonance between a brain&#x2019;s connectome-specific harmonic waves (CSHWs) will be a reasonable proxy for this symmetry (<a href=""https://qualiacomputing.com/2017/06/18/quantifying-bliss-talk-summary/"">Gomez Emilsson 2017</a>).</p><p><u>Marr&#x2019;s Three Levels</u>: as explained on our <a href=""https://www.qualiaresearchinstitute.org/research-lineages"">lineages</a> page,&#xA0;</p><blockquote><em><strong>David Marr</strong></em> <em>is most famous for Marr&#x2019;s Three Levels (along with Tomaso Poggio), which describe &#x201D;the three levels at which any machine carrying out an information-processing task must be understood:&#x201D;</em><br><em>&gt;Computational theory: What is the goal of the computation, why is it appropriate, and what is the logic of the strategy by which it can be carried out?</em><br><em>&gt;Representation and algorithm: How can this computational theory be implemented? In particular, what is the representation for the input and output, and what is the algorithm for the transformation?</em><br><em>&gt;Hardware implementation: How can the representation and algorithm be realized physically? [Marr (1982), p. 25]</em><br><em>This framework</em> <em>sounds</em> <em>simple, but is remarkably important since arguably most of the confusion in neuroscience (and phenomenology research) comes from starting a sentence on one Marr-Poggio level and finishing it on another, and this framework lets people debug that confusion.</em></blockquote><p>Back to annealing <em>&#x2013;</em></p><p>As noted, Carhart-Harris and Friston have unified their paradigms under REBUS by understanding prediction errors as the &#x2018;energy&#x2019; parameter which drives disruption (entropic disintegration) in the brain&#x2019;s networks. Over time, this drives an evolutionary search function which attempts to minimize these prediction errors. I think this is a very beautiful description of a very clever system, and one which allows us an opportunity to cross-validate each model, and jump between levels of description if we get &#x2018;stuck&#x2019;. But it&#x2019;s still missing a story about physical implementation. <em>What is this &#x2018;energy&#x2019;</em>, <em>physically speaking?</em></p><p><strong><u>II. How meditation works: semantically-neutral annealing</u></strong></p><p>I believe that almost all techniques that intentionally &#x2018;hack&#x2019; the brain&#x2019;s annealing process share a common mechanism: a build-up of <em>semantically neutral energy</em>. &#x201C;Semantically neutral energy&#x201D; refers to neural activity which is not strongly associated with any specific cognitive or emotional process. As I note above, usually energy build-up is limited: once a perturbation of the system neatly falls into a pattern recognized by the brain&#x2019;s predictive hierarchy, the neural activity propagating this pattern is dissipated. But if a pattern <em>never quite matches</em> anything, or takes advance of implementation-level structure to persist, and especially if it&#x2019;s getting continually reinforced by some external or internal dynamic it can persist long enough to build up. I think meditation is a perfect example of a process which adds semantically-neutral energy to the brain: effortful attention on excitatory bottom-up sense-data and attenuation of inhibitory top-down predictive models will naturally lead to a build-up of this &#x2018;non-semantic&#x2019; energy in the brain. From <a href=""https://opentheory.net/2018/12/the-neuroscience-of-meditation/"">The Neuroscience of Meditation</a>:</p><blockquote><em>Furthermore, from what I gather from experienced meditators,</em> <em>successfully entering meditative flow may be one of the most reliable ways to reach these high-energy brain states. I.e., it&#x2019;s</em> <em>very common</em> <em>for meditation to produce feelings of high intensity, at least in people able to actually enter meditative flow. Meditation also produces more &#x2018;pure&#x2019; or &#x2018;neutral&#x2019; high-energy states, ones that are free of the intentional content usually associated with intense experiences which may distort or limit the scope of the annealing process. So we can think of intermediate-to-advanced (&#x2018;successful flow-state&#x2019;) meditation as a reheating process, whereby the brain enters a more plastic and neutral state, releases pent-up structural stresses, and recrystallizes into a more balanced, neutral configuration as it cools. Iterated many times, this will drive an evolutionary process and will produce a very different brain, one which is more unified &amp; anti-fragile, less</em> <em><a href=""https://qualiacomputing.com/2016/11/19/the-tyranny-of-the-intentional-object/"">distorted toward intentionality</a>, and in general</em> <em>structurally optimized against stress.</em></blockquote><blockquote><em>An open question is</em> <em>how</em> <em>or</em> <em>why</em> <em>meditation produces high-energy brain states. There isn&#x2019;t any consensus on this, but with a nod to the predictive coding framework, I&#x2019;d offer that bottom-up sense-data is generally excitatory, adding energy to the system, whereas top-down predictive Bayesian models are generally inhibitory, functioning as &#x2018;energy sinks&#x2019;. And so by &#x2018;noting and knowing&#x2019; our sensations before our top-down models activate, in a sense we&#x2019;re diverting the &#x2018;energy&#x2019; of our sensations away from its usual counterbalancing force. If we do this long enough and skillfully enough, this energy can build up and lead to &#x2018;<a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3909994/"">entropic disintegration</a>&#x2019;, essentially pushing enough energy into the system that existing attractors are disrupted and annealing can occur.&#xA0;</em></blockquote><p>A natural question here is <em>what *is* this &#x2018;semantically neutral energy&#x2019; exactly?</em> <em>&#x2013;</em> an abstract answer here is &#x201C;semantically neutral energy&#x201D; can be thought of as an increase in brain activity which is (1) illegible to Marr&#x2019;s semantic/computational level, but (2) coherent with regard to Marr&#x2019;s algorithmic or implementational levels (another term for this might be &#x2018;semantically-illegible energy&#x2019;). But my concrete answer is that <em>semantically neutral energy is a build-up of energy in the brain&#x2019;s natural resonances</em> &#x2014; energy accumulating in CSHWs. And so it&#x2019;s <em>this</em> that builds up during meditation, and <em>this</em> that starts a <em>semantically-neutral</em> <em>annealing</em> process which has a unique effect profile.</p><p>I think <em>semantically-neutral annealing</em> is the <em>best kind</em> of annealing for psychological health, because:&#xA0;</p><p>(1) By mostly avoiding energy sinks, the same entropic disintegration-&gt;search-&gt;annealing process can happen using less total energy, which is less disruptive to the fine details of the system;</p><p>(2) Since this energy is semantically-neutral, it doesn&#x2019;t depend on or trigger as many semantic processes in the brain (which can have unpredictable effects), and likewise it doesn&#x2019;t necessarily rely on anti-inductive &#x2018;hacks&#x2019; to trick the predictive processing system, and these factors make it a more reliable and repeatable source of annealing;&#xA0;</p><p>(3) <em>Very very importantly:</em> similarly to how vibratory energy applied to a tuning fork quickly collapses to the natural resonant frequency of the tuning fork, I&#x2019;m speculating that coherent, semantically-neutral energy added to the brain will naturally cluster in the brain&#x2019;s natural <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/"">connectome harmonics</a>, which will thus drive an annealing process which strengthens a consonant subset of the brain&#x2019;s natural harmonic resonances in the long-term&#x2014; essentially &#x2018;retuning the brain&#x2019; toward more resonant/flow states. For more details, see <a href=""https://opentheory.net/2018/12/the-neuroscience-of-meditation/"">The Neuroscience of Meditation</a>;</p><p>(4) Finally, this process should <em>feel really really good</em> and in the long-term, retune the mind to be more pleasant to inhabit. QRI&#x2019;s work on the <a href=""https://opentheory.net/2017/04/stov-explain-like-im-5-edition/"">Symmetry Theory of Valence</a> (STV) and our method of applying this to the brain (<a href=""https://qualiacomputing.com/2017/06/18/quantifying-bliss-talk-summary/"">CDNS</a>) suggests that harmony in the brain is <em>literally synonymous</em> with pleasure, and so processes which &#x2018;deepen the grooves&#x2019; of core harmonic resonances will tend to boost the mind&#x2019;s default hedonic level (likely helping significantly with neuroticism and emotional resilience).</p><span><em><figure><img src=""https://opentheory.net/wp-content/uploads/2019/11/Screen-Shot-2019-11-22-at-9.55.37-PM-1-1024x753.png"" class=""draft-image center"" style=""width:76%""></figure></em></span><p>I.e., Meditation is a remarkably clever technique which piggybacks on several of the brain&#x2019;s core principles of self-organization: first, effortful attention on (excitatory) sense-data and inhibiting (inhibitory) predictive storytelling naturally pushes the brain into a high-energy state and makes it more malleable; this excess energy disproportionately collects in natural brain harmonics, and as the brain &#x2018;cools&#x2019; from its high-energy state, these energized harmonics become &#x2018;deeper&#x2019;, leading to more psychological robustness. Less neuroticism and more flow. <em>I think this is where a large portion of the benefits of advanced meditation comes from.</em></p><p>Meditation isn&#x2019;t the only method to induce build-up of semantically-neutral energy; the &#x201C;Big Three&#x201D; are:</p><p>&#x2013; <strong>Meditation</strong>, which seems to work by both increasing excitatory sense-data and decreasing inhibitory top-down predictive models (energy sinks);</p><p>&#x2013; <strong>Psychedelics</strong>, which intuitively may function by disabling existing energy sinks (or perhaps overloading them by increasing baseline firing rates or increasing the branching factor of neural activity).</p><p>&#x2013; <strong>Music</strong>, a sensory input which seems to exist on the knife&#x2019;s edge between exhibiting highly ordered patterns (some of which will hit natural connectome harmonics and so allow accumulation of energy through resonance) on one hand, and on the other hand not being <em>too</em> predictable (thus dodging most inhibitory top-down predictive models);</p><p>Hybrid approaches also exist: e.g. exercise, dance, sex, tantric practices, <a href=""https://en.wikipedia.org/wiki/Eye_movement_desensitization_and_reprocessing"">EMDR</a>, and breath work are essentially combinations of the rhythmic portion of music and the sensory portion of meditation. The fact that psychedelics reliably enhance the potency of each and every one of these practices is not a coincidence, but due to shared mechanism.[1]</p><p><strong><u>III. Depression as a disorder of annealing; bipolar depression doubly so</u></strong></p><p>To describe depression in one sentence: <em>&#x201C;Depression is a self-reinforcing perturbation from the natural annealing cycle.&#x201D;</em> There are two related aspects to this: (1) an inability to anneal normally, and (2) annealing abnormally (more specifically, annealing new attractor basins which are high in dissonance, or annealing a pathological change in energy parameter dynamics).</p><p>Most people have a simple model of depression as &#x201C;being sad all the time&#x201D; <em>&#x2013;</em> but I think a two-factor model looking at <em>energy parameter</em> and <em>valence</em> offers a lot of clarity and predictive utility. Roughly speaking, this suggests parametrizing depression into three core types:</p><p><u>I. Depression with no high energy states</u>, characterized by a lack of annealing (emotional clarity and dynamism) in general;</p><p><u>II. Depression with high-energy negative states</u>, which over time anneals minds toward <em>suffering</em> and <em>hopelessness</em>;</p><p><u>III. Bipolar depression with high-energy positive &amp; negative states</u>, which over time anneals minds toward the <em>dramatic</em>.</p><p>These categories aren&#x2019;t exclusive or static; too much time in one will increase the probability one may also fall into the others.&#xA0;</p><p>Not annealing frequently enough may be the most important &#x2018;non-obvious&#x2019; cause of depression. Brains <em>&#x2013;</em> especially younger ones, since they&#x2019;re changing so much <em>&#x2013;</em> <em>really do need to anneal regularly</em> to pay down their &#x2018;technical debt&#x2019;, and if they don&#x2019;t, they grow brittle and neurotic. (Technical debt in the brain builds up as we twist our existing brain networks to accommodate new facts; this debt is &#x2018;paid down&#x2019; when we enter high-energy states and let new brain networks which fit these constraints self-organize) The &#x2018;annealing pressure&#x2019; also increases over time, and if a wholesome annealing opportunity fails to present itself, the brain will progressively lower its standards looking for <em>any</em> opportunity for annealing. Especially if done repeatedly, this can cause long-term damage to the brain&#x2019;s attractor basin landscape. (We see this in negative coping strategies such as cutting, drama-seeking, and so on <em>&#x2013;</em> if someone is engaging in such, they&#x2019;ve probably annealed poorly, and also likely have few realistic opportunities for healthy annealing.) Many forms of entertainment we think of as palliatives in today&#x2019;s society (e.g. movies, video games) may be weak-and-incomplete-but-still-nonzero drivers of annealing. Not as good as the real thing, but better than nothing if that&#x2019;s your only option.</p><p>At the high-energy extreme, it seems likely and tragic that depression compounds itself by repeatedly causing intense negative emotion (high-energy states) which anneals the brain toward these patterns, and toward assigning salience on the set of problems and types of thoughts (attractor landscape) facing a depressed person &#x2014; many of which are their own cause and would weaken if ignored. Relatedly, I suspect some CSHW- and music-theory-related math could be found describing how depression anneals what I would call a brain&#x2019;s &#x2018;connectome key signature&#x2019; (CKS) toward a &#x2018;minor key&#x2019;, an internal logic which feels tragic/hopeless (has fewer harmonious arrangements and progressions), which the brain then uses as building blocks for its reality.&#xA0;</p><p>Bipolar depression seems a little more strange; the extreme highs and lows may in aggregate produce crazier annealing patterns than just one or the other &#x2014; essentially there&#x2019;s a &#x2018;tug of war&#x2019; between patterns annealed during each extreme, which prioritizes the survival of the class of patterns that exist during <em>both</em> extremely positive and extremely negative states. In practice, over time this anneals a mind&#x2019;s stories toward the dramatic, and toward reducing the activation energy needed to flip the brain between major and minor keys (the psych literature calls this &#x2018;kindling&#x2019;). Each of these &#x2018;key signature flips&#x2019; would itself release a great deal of pent-up energy, further driving the annealing process. As I note in <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/"">A Future for Neuroscience</a>:</p><blockquote><em>This is not to say our key signatures are completely static, however: an interesting thread to pull here may be that some brains seem to flip between a major key and a minor key, with these keys being local maximas of harmony. I suspect each is better at certain kinds of processing, and although parts of each can be compatible with the other, each has elements that present as defection to the internal logic of the other and so these attractors can be &#x2018;sticky&#x2019;. But there can also be a buildup of tension as one gathers information that is incompatible with one&#x2019;s key signature, which gets progressively more difficult to maintain, and can lead to the sort of intensity of experience that drives an annealing-like process when the key signature flips. And in the case of repeated flips, the patterns which are compatible with both key signatures will be the most strongly reinforced.</em></blockquote><p>In some ways a bipolar brain may result in significant cognitive and creative advantages: perhaps the biggest is more access to high-energy states, which in the short term helps creativity by allowing more exploration and also steeper valence gradients to follow, and iterated over the long term allows significantly more optimization pressure on the subsystems that are repeatedly annealed. However this has corresponding epistemological downsides as noted above; fueling creative work with valence deltas is likely to &#x2018;warp the engine&#x2019; over time, to paraphrase Shinzen. Friston&#x2019;s notion that &#x2018;systems maximizing long-term stability spend most of their time in a small number of states&#x2019; seems particularly relevant to mood disorders. (My colleague Andr&#xE9;s suggests this &#x2018;bipolar effect profile&#x2019; may be replicated by valence-enhancing drugs with a short duration and hangover, such as cocaine- this at least fits stereotypes.)</p><p>I find myself wondering if neuroticism can be thought of as ancient neural technology intended to <em>reduce annealing frequency</em> in the ancestral environment &#x2014; essentially if we look into the brains of highly neurotic people, we might find strong energy sinks located around natural connectome harmonics which prevent semantically-neutral energy build-up. This likely contributes to certain forms of depression (and leads to pernicious feedback cycles &#x2014; the less one anneals, the more neurotic one gets, the less able to reach high-energy states one becomes), but might also help prevent seizures or inappropriate updating/annealing, and may have frequency-dependent benefits. E.g., a group with 19 carefree annealers and 1 neurotic guardian will act more wisely than one with 20 carefree annealers or 20 neurotic guardians. The &#x2018;neuroticism=energy sinks&#x2019; frame seems to suggest how to reduce neuroticism (anneal more often, especially semantically-neutral annealing), and also offer clues as to how neuroticism is implemented in the brain: we might look into the <a href=""https://www.quantamagazine.org/mathematicians-tame-rogue-waves-lighting-up-future-of-leds-20170822/?fbclid=IwAR1wFHwPwELj8p18FhnZZ7P_YOCAk_Ro_Xb3oRSMd8IpU6o3195HD3neYUw"">mathematics of Anderson localization</a> in the connectome: topological features that can &#x2018;eat&#x2019; waves.</p><p><u>Is sleep a natural annealing process?</u> If so, this could cleanly explain the connection between depression and chronic sleep disturbances &#x2014; poor sleep as both a cause and effect of infrequent annealing. And it would indicate a treatment path: a restoration of normal annealing patterns may help improve both mood and sleep. I hold the following lightly, but we might model nREM as the heating-up phase (undampened harmonics) and REM as the neural search &amp; cooling process. From a review drawing parallels between sleep and jhana (intense meditative) states:&#xA0;</p><blockquote><em>This paper is a preliminary report on the first detailed EEG study of jhana meditation, with findings radically different to studies of more familiar, less focused forms of meditation. While remaining highly alert and &#x201C;present&#x201D; in their subjective experience, a high proportion of subjects display &#x201C;spindle&#x201D; activity in their EEG, superficially similar to sleep spindles of stage 2 nREM sleep, while more-experienced subjects display high voltage slow-waves reminiscent, but significantly different, to the slow waves of deeper stage 4 nREM sleep, or even high-voltage delta coma. Some others show brief posterior spike-wave bursts, again similar, but with significant differences, to absence epilepsy. Some subjects also develop the ability to consciously evoke clonic seizure-like activity at will, under full control. (<a href=""https://www.frontiersin.org/articles/10.3389/fnhum.2019.00178/full"">Dennison 2019</a>)</em></blockquote><p>It seems plausible that broad rhythmic brain activity helps with certain &#x2018;physical housekeeping&#x2019; tasks in the brain as well, and if one anneals regularly they may need somewhat less sleep (see recent research on Alzheimer&#x2019;s, sleep, and rhythmic stimulation helping break up brain plaques).</p><p><u><strong>The &#x2018;dead neuron&#x2019; model of neuroticism and depression:</strong></u><br></p><p>Deep learning models can exhibit &#x2018;dead neurons&#x2019;: neurons whose activation function gets &#x2018;stuck&#x2019; on the on or off position, for instance when a sigmoid function gets too high or too low and its slope drops to almost zero. These &#x2018;dead&#x2019; neurons can be nigh-impossible to &#x2018;revive&#x2019; within the model, since it can be the case that their gradient (implicit sensitivity to input) is so shallow that there simply aren&#x2019;t inputs that will nudge it in one or another direction.</p><span><em><figure><img src=""https://lh5.googleusercontent.com/88xWEQqKFRfwHMpTm15tk0HygmdpbGKfYrid_-cSDFOs7orcth2E_n_q1RBaSGtTbIOJIlaWuAKE5JqgTaSla_1WAEiUuoe49UvvbrXL6ujaGO8_An26sJHOUP5FGQaxPsosucnb"" class=""draft-image center"" style=""width:70%""></figure>Graphic: sigmoidal function. This loses sensitivity when values get too high or too low. Different activation functions can lose sensitivity (lead to &#x2018;dead neurons&#x2019;) under different scenarios-</em> <em><a href=""https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#relu"">ReLU</a></em> <em>is notorious for this.</em></span><p>These &#x2018;dead&#x2019; neurons tend to cause lots of problems, since their &#x201C;always-on&#x201D; or &#x201C;always off&#x201D; signal tends to propagate through the network very strongly, causing later neurons in the chain to also exhibit less sensitivity to input. (Sometimes this process will cascade, sometimes not, much like malignant vs benign tumors.)&#xA0;</p><p>I suspect this might be a strong frame for understanding the &#x2018;psychological cruft&#x2019; which builds up in brains, and how and why regular annealing is so healthy: over time, sensitive neurons can slide into this broken state, shifting from conditional values to the neurological equivalent of static 0s and 1s. In this case I would expect more neuroticism, less flexible thinking, lower emotional resilience, and worse epistemology from people who haven&#x2019;t annealed recently: lots of all-or-nothing thinking. But by injecting lots of energy into the system, enough of the internal and external context of these neurons is shifted such that some of them may get &#x2018;reset&#x2019; and regain their conditional processing state. At the very least, this self-reorganization process can allow these neurons to move to less-critical points in processing networks.&#xA0;</p><p>An idea related to this frame is that a core function of neural annealing is to maintain a smooth gradient of harmony in the brain (and mind) &#x2013; to make it possible to &#x201C;follow your joy&#x201D; toward better outcomes. If this breaks down and you can&#x2019;t &#x201C;follow your joy&#x201D;, consider putting yourself in a situation which could plausibly kickstart an annealing process (even if you don&#x2019;t feel emotionally motivated to do so).&#xA0;</p><p><strong><u>IV. The nature of trauma and the implementation of the Bayesian Brain</u></strong></p><p>Trauma is one of the worst elements of the human condition. It&#x2019;s easy enough to accumulate that we all have some, and it&#x2019;s hard to get rid of. But <em>what is it?</em></p><p>Scott Alexander recently reviewed a core work in the PTSD literature, <em><a href=""https://slatestarcodex.com/2019/11/12/book-review-the-body-keeps-the-score/"">The Body Keeps The Score</a></em>, and offers some context:</p><blockquote><em>The book stressed the variety of responses to PTSD. Some people get anxious. Some people get angry. But a lot of people, whatever their other symptoms, also go completely numb. They are probably still &#x201C;having&#x201D; &#x201C;emotions&#x201D; &#x201C;under&#x201D; &#x201C;the&#x201D; &#x201C;surface&#x201D;, but they have no perception of them. Sometimes this mental deficit is accompanied by equally surprising bodily deficits. Van der Kolk describes a study on stereoagnosia in PTSD patients: if blindfolded and given a small object (like a key), they are unable to recognize it by feel, even though this task is easy for healthy people. Sometimes this gets even more extreme, like the case of a massage therapy patient who did not realize they were being massaged until the therapist verbally acknowledged she had started.</em></blockquote><blockquote><em>The book is called</em> <em>The Body Keeps The Score, and it returns again and again to the idea of PTSD patients as disconnected from their bodies. The body sends a rich flow of information to the brain, which is part of what we mean when we say we &#x201C;feel alive&#x201D; or &#x201C;feel like I&#x2019;m in my body&#x201D;. In PTSD, this flow gets interrupted. People feel &#x201C;like nothing&#x201D;. &#x2026;</em></blockquote><blockquote><em>There&#x2019;s some discussion of the neurobiology of all this, but it never really connects with the vividness of the anecdotes. A lot of stuff about how trauma causes the lizard brain to inappropriately activate in ways the rational brain can&#x2019;t control, how your &#x201C;smoke detector&#x201D; can be set to overdrive, all backed up with the proper set of big words like &#x201C;dorsolateral prefrontal cortex&#x201D; &#x2013; but none of it seemed to reach the point where I felt like I was making progress to a gears-level explanation. I felt like the level on which I wanted an explanation of PTSD, and the level at which van der Kolk was explaining PTSD, never really connected; I can&#x2019;t put it any better than that. &#x2026;</em></blockquote><blockquote><em>There are a</em> <em>lot</em> <em>of alternative treatments for PTSD. Neurofeedback, where you attach yourself to a machine that reads your brain waves and try to explore the effect your thoughts have on brain wave production until you are consciously able to manipulate your neural states. Internal family systems, where a therapist guides you through discovering &#x201C;parts&#x201D; of yourself (think a weak version of multiple personalities), and you talk to them, and figure out what they want, and make bargains with them where they get what they want and so stop causing mental illness. Eye movement directed reprocessing (alternative when the book was written, now basically establishment) where you move your eyes back and forth while talking about your trauma, and this seems to somehow help you process it better. Acupuncture. Massage. Yoga. &#x2026;</em></blockquote><blockquote><em>Maybe the most consistent lesson from this book&#x2019;s tour of successful alternative therapies &#x2013; keeping with the theme of the title &#x2013; is that it&#x2019;s important for PTSD patients to get back in touch with their bodies. Massage therapy, yoga, and acupuncture addressed this directly, usually creating gentle, comfortable sensations that patients could take note of to gradually relax the absolute firewall between bodily sensation and conscious processing.</em></blockquote><p>The simple Neural Annealing take on trauma is that significant negative events can push the brain into a high-energy state filled with &#x2018;trauma patterns&#x2019;, and as the brain cools, some of these trauma patterns crystallize/anneal in a very durable form, which present as PTSD.</p><p>I think this is a <em>more useful</em> answer than what&#x2019;s out there currently, offering straightforward intuitive answers for (1) what kinds of things are most likely to cause PTSD, (2) why PTSD is so &#x2018;sticky&#x2019;, and (3) an intuitive solution to PTSD: anneal over the bad patterns with better patterns.</p><p>But Scott&#x2019;s description seems to point at something further: that there&#x2019;s a disconnection happening with trauma. To address this, I propose the Neural Annealing model for how CSHW could <em>implement</em> the Bayesian Brain model of cognition. We&#x2019;ll then circle back and discuss what might be going wrong during trauma.</p><p>Last year in <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/#"">A Future for Neuroscience</a>, I shared the frame that we could split CSHWs into high-frequency and low-frequency types, and perhaps say something about how they might serve different purposes in the Bayesian brain:</p><blockquote><em><strong>The mathematics of signal propagation and the nature of emotions</strong></em><br><em>High frequency harmonics will tend to stop at the boundaries of brain regions, and thus will be used more for fine-grained and very local information processing; low frequency harmonics will tend to travel longer distances, much as low frequency sounds travel better through walls. This paints a possible, and I think useful, picture of</em> <em>what emotions fundamentally are: semi-discrete conditional bundles of low(ish) frequency brain harmonics that essentially act as Bayesian priors for our limbic system. Change the harmonics, change the priors and thus the behavior. Panksepp&#x2019;s seven core drives (play, panic/grief, fear, rage, seeking, lust, care) might be a decent first-pass approximation for the attractors in this system.&#xA0;</em></blockquote><p>I would now add this roughly implies a <em>continuum</em> of CSHWs, with scale-free functional roles:</p><ul><li>Region-specific harmonic waves (<strong>RSHWs</strong>) <em>&#x2013;</em> high frequency resonances that implement the processing of cognitive particulars, and are localized to a specific brain region (much like how high-frequencies don&#x2019;t travel through walls) <em>&#x2013;</em> in theory quantifiable through simply applying Atasoy&#x2019;s CSHW method to individual brain regions;</li><li>Connectome-specific harmonic waves (<strong>CSHWs</strong>) <em>&#x2013;</em> low-frequency connectome-wide resonances that act as Bayesian priors, carrying relatively simple &#x2018;emotional-type&#x2019; information across the brain;</li><li>Sensorium-specific harmonic waves (<strong>SSHWs</strong>) <em>&#x2013;</em> very-low-frequency waves that span not just the connectome, but the larger nervous system and parts of the body. These encode <em>somatic</em> information &#x2013; in theory, we could infer sensorium eigenmodes by applying Atasoy&#x2019;s method to not only the connectome, but the nervous system, adjusting for variable nerve-lengths, and validate against something like <a href=""https://digest.bps.org.uk/2018/10/08/a-cartography-of-consciousness-researchers-map-where-subjective-feelings-are-located-in-the-body/"">body-emotion maps</a>.[2][3]</li></ul><p>These waves shade into each other &#x2013; a &#x2018;low-frequency thought&#x2019; shades into a &#x2018;high-frequency emotion&#x2019;, a &#x2018;low-frequency emotion&#x2019; shades into somatic information. As we go further up in frequencies, these waves become more localized.</p><p>An interesting implication here is <em>we may essentially get Bayesian updating to naturally emerge from this typology</em>, through interactions between these various waves: essentially, I think it&#x2019;s &#x2018;injection-locking all the way down&#x2019;. (<a href=""https://en.wikipedia.org/wiki/Injection_locking"">Injection-locking</a> is when harmonic oscillators (like CSHWs) essentially &#x2018;sync up&#x2019; their periods and phases.) Specifically:</p><p>Low-frequency CSHWs carry priors, higher frequency RSHWs deal with particulars. Lower frequencies span the brain; higher frequencies resonate within more local regions of the brain &#x2014; the higher the frequency of the wave, the smaller the region it tends to resonate in. The RSHWs in different regions can&#x2019;t talk to each other directly, since (definitionally) these waves can&#x2019;t travel across regional boundaries. But they <em>can</em> talk to each other indirectly, through interacting with low-frequency CSHWs. More specifically, I speculate that regions and CSHW-encoded priors interact through a <strong>power-weighted averaging between CSHWs and RSHWs</strong>, as mediated by the math of <a href=""https://en.wikipedia.org/wiki/Injection_locking"">injection-locking and injection-pulling</a>. This <strong>allows both functional partitioning and also global updating:</strong> regions get some isolation in order to perform their specialized computations, but they also get exposure to data about the overall Bayesian prior situation, aka what we call &#x2018;emotional information&#x2019;. I.e. Region A syncs up with CSHWs, which carry the information to Region B and sync up with the RSHWs there, and so on. Of note, there&#x2019;s a delicate, power-weighted handshake between CSHWs and RSHWs: low-frequency harmonics (emotions / Bayesian priors) carry more power per harmonic (lower due to frequency, much higher due to amplitude) but there are many more high-frequency harmonics (sensory+cognitive particulars). Strong emotions like anger likely pump huge amounts of energy into CSHWs and upend this balance, forcing RSHWs to synchronize with CSHWs. We can think of this as sacrificing the delicate epistemology-harmonization handshake in favor of unity of processing and clarity of action &#x2014; or put simply, forcing perception to match top-down expectations.</p><p><u>On entropic disintegration, search, and annealing in evolved harmonic systems:</u></p><p>The noisy, stochastic nature of brain activity, along with practical requirements for homeostasis, will lead to a strong optimization of the CSHW+RSHW configuration for local minima which are resistant to change. However, a large enough perturbation will push the system out of this basin (<strong>entropic disintegration</strong> step). The <strong>neural search</strong> step is essentially the system stochastically testing different harmonic configurations; the <strong>neural annealing</strong> step is the system &#x2018;settling into&#x2019; a configuration as its top-down predictive models get sufficiently good at sopping up the excess energy in the system, essentially forming a new basin it will again take a large amount of perturbation to get out of. The strength of annealing can be thought of as the steepness of this basin, and also the <a href=""https://en.wikipedia.org/wiki/Hebbian_theory"">Hebbian reinforcement</a> of system attractors (&#x201C;neurons that fire together, wire together&#x201D;). Insofar as partitioning is possible in a broadly-coupled harmonic system, these perturbations will tend to be &#x2018;local&#x2019; as the brain has strong incentives to preserve structure that doesn&#x2019;t need updating.&#xA0;</p><p><u>Toward a generalized definition of trauma: a breakdown of information-propagation-via-injection-locking</u></p><p>I propose that sometimes the brain needs to rapidly halt information propagation across regions to prevent cascading system failure (a metaphor that comes to mind is an uncontrolled <a href=""https://en.wikipedia.org/wiki/Prion"">prion</a>-like change in the local key signature that ripples out from a traumatized region, progressively breaking <a href=""https://slatestarcodex.com/2017/03/06/book-review-behavior-the-control-of-perception/"">cybernetic</a> calibrations). I believe the brain uses two interlinked mechanisms to do this: (1) weakening CSHWs, thus weakening information propagation throughout the brain, and (2) arranging different brain regions into frequency regimes which make information transfer difficult between them (the <a href=""https://www.ncbi.nlm.nih.gov/pubmed/20350536"">golden mean</a> is the mathematically-optimal ratio for non-interaction). Once this happens, it can be very hard to reverse, since it forms a self-sustaining cycle: (1) causes (2) and (2) causes (1). <em><u>We call this &#x2018;trauma&#x2019;.</u></em></p><p>Some predictions from this <em>&#x2013;</em> I&#x2019;d expect to see substantially less energy in low-frequency CSHWs after trauma, and substantially more energy in low-frequency CSHWs during both therapeutic psychedelic use (e.g. MDMA therapy) and during psychological integration work. Stretching a little, perhaps we could also apply Atasoy&#x2019;s CSHW algorithm to <em>individual</em> brain regions and compare their spectrums (and those of CSHWs), to quantify the expected frequency-coupling between each region.[4] Possibly these two measures could be developed into a <em>causal quantitative metric for trauma</em>.</p><p>This generalized &#x2018;breakdown of communication&#x2019; definition of trauma neatly fits with the story Scott tells about PTSD, where people&#xA0;</p><blockquote><em>[A]re probably still &#x201C;having&#x201D; &#x201C;emotions&#x201D; &#x201C;under&#x201D; &#x201C;the&#x201D; &#x201C;surface&#x201D;, but they have no perception of them &#x2026; PTSD patients as disconnected from their bodies. The body sends a rich flow of information to the brain, which is part of what we mean when we say we &#x201C;feel alive&#x201D; or &#x201C;feel like I&#x2019;m in my body&#x201D;. In PTSD, this flow gets interrupted. People feel &#x201C;like nothing&#x201D;.</em></blockquote><p>It also fits with the therapies that seem to work: <a href=""https://en.wikipedia.org/wiki/Eye_movement_desensitization_and_reprocessing"">EMDR</a>, neurofeedback, Internal Family Systems (IFS), yoga, massage &#x2014; the consistent thread that connects these is they all plausibly help restart and strengthen communication within the brain (which I hold is strongly mediated by CSHWs). Scott doesn&#x2019;t mention music, but I&#x2019;d expect it to be <em>surprisingly</em> effective at boosting emotional integration &#x2014; and I&#x2019;d expect the <em>most effective</em> music will have strong low-frequency rhythms.</p><p>This shades into novel types of therapeutic approaches: perhaps we could simply pump energy into lower-frequency bands (perhaps harmonic stimulation centered at ~3-6hz) to kickstart emotional integration.[5]</p><p><u>Sidenote on music:</u> The simple description I gave of music was&#xA0;</p><blockquote><em>[A] sensory input which seems to exist on the knife&#x2019;s edge between exhibiting highly ordered patterns (some of which will hit natural connectome harmonics and so allow accumulation of energy through resonance) on one hand, and on the other hand not being</em> <em>toopredictable (thus dodging most inhibitory top-down predictive models).</em></blockquote><p>Armed with the CSHW/RSHW distinction, we can give this a second pass. In short, I expect the above story to be true, but in a fractal way: music will be hitting both CSHWs and RSHWs. Naturally, different regions will have different sets of harmonics, which means simple tones are unlikely to produce much cross-regional resonance. Instead, the music which is the most effective at increasing the brain&#x2019;s energy parameter will tie together and layer a diverse set of motifs, with two goals: (1) hitting as many connectome-specific *and* region-specific resonances as possible, and (2) entraining disparate regions and pulling them into sync <em>&#x2013;</em> essentially using injection-locking to pull RKSs (Regional Key Signatures) into sync with each other and the CKS (Connectome Key Signature).</p><p>Could we quantify what the &#x2018;perfect song&#x2019; would be, for a given connectome? Not exactly, since so much of music&#x2019;s effects rely on getting through the brain&#x2019;s predictive processing gauntlet and the state of this gauntlet isn&#x2019;t well-captured by a static connectome, but we could possibly use this framework to design (potentially <em>much</em>) more evocative songs.</p><p>It&#x2019;s also worth noting that better music <em>&#x2013;</em> and <em>better ways to listen to music</em> <em>&#x2013;</em> shade quickly into potential therapies for trauma under this model.&#xA0;</p><p><strong><u>V. On psychedelics:</u></strong></p><p>As noted above, Neural Annealing suggests a very simple model for understanding the effects of psychedelics: as substances which &#x201C;may function by disabling existing energy sinks (or perhaps overloading them by increasing baseline firing rates or increasing the branching factor of neural activity),&#x201D; dramatically increasing semantically-neutral energy. Psychedelics share a &#x2018;characteristic feeling&#x2019; (and characteristic emotional aftereffects) with each other and with activities such as meditation, listening to music, EMDR, breath work, and so on, <em>because</em> all of these things increase the energy parameter of the brain. Psychedelics are particularly interesting because they do this so powerfully, effortlessly, and noisily (with the effects bleeding over into sensory modalities, not just accumulating in harmonics).</p><p>A full Neural Annealing model of psychedelics will have to wait a few more months as internal QRI discussion settles on a unified story. But a few preliminary notes:</p><p>First, we could define &#x2018;psychedelics&#x2019; in a principled way, as <em>any substance, pattern, or process that produces semantically-neutral energy accumulation</em> &#x2013; anything that disables, overloads, or avoids the brain&#x2019;s energy normalization system. The implication here is interesting, that anything that adds semantically neutral energy into the brain should produce psychedelic effects, regardless of how this is done. E.g., even things like <em>modern art</em> may be classifiable as a psychedelic, insofar as it generates semantically-neutral energy (see <a href=""https://qualiacomputing.com/2019/09/30/harmonic-society-3-4-art-as-state-space-exploration-and-energy-parameter-modulation/"">Gomez Emilsson 2019</a>). But we should also note that current psychedelics are not necessarily perfect sources of &#x2018;clean semantically-neutral energy&#x2019;; they&#x2019;re substances that happen to massively increase the energy parameter of the brain, with no guarantees about how &#x2018;balanced&#x2019; this boost is. There may be better and more targeted methods to do this in the future. In the meantime, I would recommend modest caution with substances which involve a hangover after use, as negative valence or affective blunting during a critical window could &#x2018;sour&#x2019; the annealing process with subtle long-term mood effects.[6]</p><p>As mentioned above, I&#x2019;ve been thinking more and more that the core psychological changes driven by psychedelics are best understood in terms of the amount and &#x2018;statistical flavor&#x2019; of the semantically-neutral energy they add to the system. Or, as an alternate framing, psychedelics may be best understood as temporary disrupters of the brain&#x2019;s natural energy sinks, each with a specific target or &#x2018;flavor&#x2019; of disruption (or psychedelics may add to neural activity&#x2019;s &#x2018;branching factor&#x2019;, which in turn will add a specific flavor to the energy). I also find myself wondering, all else being equal, whether psychedelic visuals actually are <em>inversely correlated</em> with annealing effects, since by diverting energy into the visual system (which plausibly has very effective energy sinks), there is less energy available to drive entropic disintegration.[7]</p><p>As I noted in <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/#"">A Future for Neuroscience</a>, another starting point for sorting through psychoactive drugs would be&#xA0;</p><blockquote><em>[T]o parametrize the effects (and &#x2018;phenomenological texture&#x2019;) of all psychoactive drugs in terms of their effects on the consonance, dissonance, and noise of a brain, both in overall terms and within different frequency bands (<a href=""https://qualiacomputing.com/2017/06/18/quantifying-bliss-talk-summary/"">Gomez Emilsson 2017</a>).</em></blockquote><blockquote><em>In the long term, we&#x2019;ll want to move upstream and predict</em> <em>connectome-specific</em> <em>effects of drugs</em> <em>&#x2013;</em> <em>treating psychoactive substances as operators on neuroacoustic properties, which produce region-by-region changes in how waves propagate in the brain (and thus different people will respond differently to a drug, because these sorts of changes will generate different types of results across different connectomes). Essentially, this would involve evaluating how various drugs change the</em> <em>internal parameters</em> <em>of the CSHW model, instead of just the outputs. Moving upstream like this might be necessary to predict why e.g. some people respond well to a given SSRI, while others don&#x2019;t (nobody has a clue how this works right now).</em></blockquote><p>Possibly this would allow us to generate a principled typology of psychoactives, and also check for missing quadrants: psychoactives and psychedelics we haven&#x2019;t discovered or created yet. (See also Andr&#xE9;s&#x2019;s notion of parametrizing the &#x2018;<a href=""https://www.youtube.com/watch?v=loCBvaj4eSg&amp;feature=youtu.be&amp;t=2069"">information vs energy trajectory</a>&#x2019; of a trip.) We can also think of anti-psychotic drugs as <em>anti-psychedelics</em>: substances that <em>rapidly decrease the energy parameter of the brain</em> (<a href=""https://qualiacomputing.com/2019/09/30/harmonic-society-3-4-art-as-state-space-exploration-and-energy-parameter-modulation/"">Gomez Emilsson 2019</a>). We at QRI strongly believe this makes anti-psychotics more dangerous than commonly realized: the neural search process is complex and delicate, and an externally-forced, uneven rapid cooling process may warp the internal landscape of the brain in subtle but deleterious ways.&#xA0; In theory, we could test this indirectly by evaluating the effects of anti-psychotics on sensory integration tasks in healthy controls &#x2013; but as noted above, this may be an unethical experiment.</p><p>Another frame would be &#x2018;psychedelics as full-spectrum resonance agents&#x2019; <em>&#x2013;</em> CSHWs are meant to substantially resonate during normal human operation (falling in love, orgasm, etc) <em>&#x2013;</em> RSHWs are not. The perceptual and epistemological changes we sometimes see during psychedelics could be due to the fine logical machinery that usually deals with high-context sensory particulars (facts and logical inferences) starting to malfunction as its natural eigenmodes are activated. Like linking and rhythmically flipping all the bits in a memory register, ignoring what that register is &#x201C;supposed to&#x201D; compute. If psychedelic visuals are an example of RSHW resonance, <a href=""https://www.medicalnewstoday.com/articles/320181.php"">HPPD</a> may be an example of this RSHW resonance annealing into durable patterns.&#xA0;</p><p><u>On MDMA&#x2019;s strangely powerful therapeutic effects</u>, I&#x2019;d suggest MDMA shares the &#x2018;<a href=""https://www.frontiersin.org/articles/10.3389/fnint.2018.00054/full"">basic psychedelic package</a>&#x2019; with substances like LSD and psilocybin (albeit a little weaker at common doses). Anything with this &#x2018;baseline&#x2019; package significantly increases the energy parameter of the brain, which both allows escape from bad local minima and canalizes the brain&#x2019;s core CSHWs, which both should be highly therapeutic. My intuition is MDMA <em>may also</em> have a particular effect on stochastic firing frequencies of neurons, and that this effect essentially acts as an emergent metronome &#x2013; and this metronome will drive synchronicity between diverse brain regions. Given the presence of such a region-spanning &#x2018;clean&#x2019; metronomic signal, brain regions that have partially &#x2018;stopped talking to each other&#x2019; will re-establish integration, and some of this integration will persist while sober (or rather, some of the reasons for the lack of integration will have been negotiated away during the MDMA-driven integration). Plausibly this &#x2018;emergent metronome&#x2019; effect may also underlie the particular phenomenological effects of 5-MeO-DMT as well, particularly in terms of sense of unity, high valence, and therapeutic potential.[8]&#xA0;</p><p><u>Somewhat poetic sidenote: on taking psychedelics:</u></p><p>In the abstract <em>&#x2013;</em> I think psychedelics are more powerful, more dangerous, and more healing than commonly assumed.</p><p>But we don&#x2019;t live in the abstract. The natural question for any given person is thus: <em>should I take them?</em></p><p>There&#x2019;s no one-size-fits-all answer, and I recommend checking with local laws. But I can share a simple heuristic for who shouldn&#x2019;t worry too much about the downsides of psychedelics and who should be very careful: <u>do you trust your own aesthetic?</u></p><p>Psychedelics massively increase the &#x2018;energy parameter&#x2019; of the brain, so naturally there&#x2019;s a large amount of very-high-dimensional exploration going on. There are countless &#x2018;micro-choices&#x2019; your brain makes as to how to anneal after this exploration: we can think of a person&#x2019;s &#x2018;aesthetic&#x2019; as individual variance in these annealing choices. What the self-organizing system which is the brain&#x2019;s subconscious finds beautiful in the moment and implicitly strives to save.</p><p>Sometimes, and in some people, we want the right things, we find the right things beautiful. Things that have a deep elegance and fit with everything about us and fit with how reality works. We just need enough energy parameter to get there. Psychedelics are a great way to get there.</p><p>Other times, we might not want the right things. Evolution is kind of a jerk, epistemologically speaking: it cares much more about genetic reproduction than it does about deep coherence and calibration with reality and such. Sometimes we&#x2019;re at a functional local maxima, but we&#x2019;re not pointed in the right direction globally, and frankly speaking our lack of a high energy parameter is our saving grace &#x2013; our inability to directly muck up our emotional landscape. Insofar as this is true &#x2013; and it will be more true at certain times than others, and in certain people than others, and perhaps in certain combinations of people than others &#x2013; using psychedelics to crank the energy parameter is not good for a person. Our &#x2018;Psychedelic Extrapolated Volition&#x2019; (PEV) is not a healthy vector.[9]</p><p>The natural follow-up is, how do you know whether your PEV is positive or not?&#xA0;</p><p>Hard question, but probably good to ask your friends &#x2013; group epistemology seems healthy in these cases. And in general it seems strongly preferable to err on the side of caution. You can always take that LSD tomorrow, or next week, or next year.</p><p>(But, don&#x2019;t be too paranoid about one trip permanently breaking your brain, either. My guess is the annealing that tends to &#x2018;stick&#x2019; is that which actually finds better local minima (thankfully) &#x2013; if it&#x2019;s an unsuccessful exploration I suspect the system can usually climb back to where it was (with some caveats).)</p><p>A separate factor is your current energy parameter and how psychedelics may increase this baseline: if you&#x2019;re dragging on the bottom of your energetic attractor basins, maybe a little kick could be healthy. But if you&#x2019;re already &#x2018;high on life&#x2019; &#x2013;&#xA0; consider skipping the LSD and MDMA. <u>Increasing a high baseline can redline the system into exquisitely unbearable intensity.</u></p><p><strong><u>VI. Love and other types of Neural Annealing</u></strong></p><p>It&#x2019;s important to note that most annealing doesn&#x2019;t happen in a vacuum: just as &#x201C;set and setting&#x201D; matter quite a lot for psychedelics, and for emotional updating in general, the importance of <em>context</em> in the annealing model is hard to overstate. Much as holding a magnet close to iron as it cools can magnetize the metal, <u>the intentional content present when entropic disintegration-&gt;annealing happens provides important constraints for which new patterns form</u>. I propose there are four general types of neural annealing:</p><p><u>A. Annealing to an object or event</u>. Annealing which is &#x2018;pointed at&#x2019; something is by far the most common type. Some object, or event, or new insight makes itself known in a surprising or otherwise intensely salient way, and this pushes the brain into a high-energy state, kickstarting a self-organization process for accommodating the presence and significance of this new thing. This can involve intense positive emotion &#x2014; a new romantic partner, the birth of your child, your wedding day. This sort of annealing can also be caused by trauma&#x2014; getting bitten by a weird animal, social rejection, losing a close one. As I suggested in <a href=""https://opentheory.net/2018/12/the-neuroscience-of-meditation/"">The Neuroscience of Meditation</a>, neural annealing may offer a rather pithy description of love:</p><blockquote><em>Finally, to speculate a little about one of the deep mysteries of life, perhaps we can describe</em> <em><strong>love</strong></em> <em>as the result of a strong annealing process while under the influence of some pattern. I.e., evolution has primed us such that certain intentional objects (e.g. romantic partners) can trigger high-energy states where the brain smooths out its discontinuities/dissonances, such that</em> <em>given the presence of that pattern</em> <em>our brains are in harmony. This is obviously a two-edged sword: on one hand it heals and renews our &#x2018;cold-worked&#x2019; brain circuits and unifies our minds, but also makes us</em> <em>dependent: the felt-sense of this intentional object becomes the key which unlocks this state. (I believe we can also anneal to</em> <em>archetypes</em> <em>instead of specific people.)</em></blockquote><blockquote><em>Annealing can produce durable patterns, but isn&#x2019;t permanent; over time, discontinuities creep back in as the system gets &#x2018;cold-worked&#x2019;. To stay in love over the long-term, a couple will need to re-anneal in the felt-presence of each other on a regular basis. From my experience, some people have a natural psychological drive toward reflexive stability here: they see their partner as the source of goodness in their lives, so naturally they work hard to keep their mind aligned on valuing them. (It&#x2019;s circular, but it works.) Whereas others are more self-reliant, exploratory, and restless, less prone toward these self-stable loops or annealing around external intentional objects in general. Whether or not, and within which precise contexts, someone&#x2019;s annealing habits fall into this &#x2018;reflexive stability attractor&#x2019; might explain much about e.g. attachment style, hedonic strategy, and aesthetic trajectory.</em></blockquote><p>Perhaps we can go further now, and hypothesize that &#x2018;falling in love&#x2019; is a specific algorithm the brain runs, which is triggered by when the &#x2018;felt sense&#x2019; of another person (a pattern distributed across RSHWs, CSHWs, and SSHWs) produces substantial systemic resonance. When this happens, and in the absence of warning signs (dissonance), a person will actively seek to fill their sensorium with this signal, which amplifies the systemic resonance (potentially to extreme levels) and further synchronizes priors and other regions into harmony with the original pattern. <em>As you fall in love, you literally anneal to your felt-sense of that person &#x2013; you take their rhythm as yours, because your body judged it to be so</em>. A key which fit your connectome&#x2019;s lock. This will naturally do two things: (1) fuzz boundaries between lovers, as patterns progressively synchronize, and (2) add a harmonic echo, or &#x2018;warm consonant glow&#x2019; to all thoughts about the person. This latter phenomenon will feel nice, but also keep itself stable: the presence of this bundle of synchronized frequencies will stabilize (via injection-locking) many forms of drift &#x2013; effectively preventing certain thoughts/perceptions. This may fade over time if not refreshed, but perhaps to completely &#x2018;fall out of love&#x2019; the brain has to build a competing key signature elsewhere, e.g. in a golden mean ratio to this harmonic echo, and these rivalrous key signatures (implicitly Bayesian priors about what is real and what is good) battle it out. (Thanks to Andr&#xE9;s for discussion on competing key signatures.) This &#x2018;de-annealing&#x2019; process <em>&#x2013;</em> literally erasing someone&#x2019;s patterns and rhythms from your body <em>&#x2013;</em> can follow several trajectories, few of them pleasant, as the system renegotiates new (or old) equilibria.</p><p><u>B. Annealing to an ontology</u>. A much more general type of annealing is when the entropic disintegration-&gt;annealing process is pointed toward an <em>ontology</em>, and the brain reorganizes its internal structure (&#x2018;ontological contours&#x2019;) to accommodate this new typology. This can happen implicitly and weakly, over the course of entropic disintegration-&gt;annealing to multiple separate ideas, or explicitly and strongly, for instance reading some book in college which completely reshapes one&#x2019;s view of reality.</p><p>Any craftsman, any intellectual, any philosopher worth their salt is strongly annealed toward at least one nuanced ontology, and in fact much of the influence of the Great Philosophers can be found in how they&#x2019;ve laid out their thoughts in a way that others can use as a <em>coherent annealing target</em>. What makes something a good annealing target? I&#x2019;d offer it&#x2019;s the presence of clear archetypes arranged in both a novel but ultimately cognitively efficient way. These archetypes can be thought of as a combination of nature (innate Jungian-type limbic resonances) and nurture (prior annealed patterns &amp; cultural reifications).</p><p>An important point here is that peoples&#x2019; conception of <em>where goodness comes from</em> is dependent upon their ontology; change the ontology, change the perceived nature of goodness itself! See e.g. <a href=""https://qualiacomputing.com/2016/06/02/psychedelic-alignment-cascades/"">John Lily&#x2019;s discussion of the supra-self-metaprogrammer (SSMP)</a>. This frame-shift can also manifest at the extreme end of falling in love, where all the world&#x2019;s goodness seems to come from your special person (a dangerous thing).</p><p><u>C. Social annealing</u>. A special hybrid of annealing to an ontology and to other people is <strong>social annealing</strong>, wherein a <em>group of people</em> undergoes the <em>&#x2018;entropic disintegration -&gt; neural search -&gt; annealing&#x2019;</em> process together, within some shared context- a religious service, a sporting event, a retreat. This seems like the natural mechanism by which tribes are formed (loosely speaking, group synchronization of connectome-specific harmonic wave dynamics) and underlies many of our most sacred experiences. The power of social annealing is such that a religious experience that lacks it no longer feels like a religious experience- merely the mouthing of dogma. On the other hand, any group experience that <em>does</em> increase the group&#x2019;s energy parameter and trigger annealing starts to take on a pseudo-religious frame- e.g. ecstatic dance, <a href=""https://qualiacomputing.com/2019/07/30/ephemerisle-health-homeostasis-worldview-annealing-and-the-long-tails-of-serious-fun/"">festivals</a>, protest marches, even concerts.&#xA0;</p><p><u>D. Semantically-neutral annealing</u>. Almost all neural annealing is <em>semantic annealing</em>, or <em>annealing toward some intentional object</em>. This process is pointed <em>at</em> something, often the thing that caused the entropic disintegration process in the first place, be it a person, an event, an idea, an ontology. But there&#x2019;s nothing in the laws of neuroscience that implies annealing <em>has to</em> have an intentional object as a focus. As per Section II, I believe this is a particularly healthy form of annealing.</p><p><u>Toward a new psychology &amp; sociology?</u></p><p>Speculatively, we may be able to re-derive much of psychology and sociology from just the energy-parameter view of the brain: e.g.,</p><p><a href=""https://www.pnas.org/content/114/30/7892"">Gopnik 2017</a> suggests that different developmental windows may involve different implicit &#x2018;heat parameters&#x2019; for simulated annealing, with young people having higher parameters. Speculatively, this may correspond to different &#x2018;lived intensity of experience&#x2019; at different ages- young brains (and lifelong learners) might not only be <em>more</em> <em>plastic</em> than average, but actually having experience that is objectively <em>more visceral</em>. One way to frame this is that <em>being young is like microdosing on LSD all the time.</em> This could have interesting implications for ethics.</p><p>Most likely, there&#x2019;s been significant recent sexual selection for a higher energy parameter, for several reasons:</p><ul><li>Selecting for<a href=""https://en.wikipedia.org/wiki/Neoteny_in_humans""> neoteny</a> plausibly also implicitly selects for an energy parameter that starts higher and/or decays less with age;</li><li>A high energy parameter would be a good proxy for cognitive-emotional-behavioral dynamicism, perhaps the most strongly sexually-selected-for trait;</li><li>A high energy parameter would be an honest signal of not being in a bad &#x2018;iterated aesthetics&#x2019; attractor (otherwise they would have self-destructed previously).</li></ul><p>Psychology has various personality metrics, with the most widely used being the <a href=""https://en.wikipedia.org/wiki/Big_Five_personality_traits"">Big 5</a>, also known as OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism). One of the most interesting subfindings here is that we can still get reasonable predictive utility if we collapse these into a one-variable model: the <a href=""https://www.sciencedirect.com/science/article/abs/pii/S0092656607000256"">&#x2018;Big One&#x2019; personality factor</a>. Scoring high in this factor is &#x201D;associated with social desirability, emotionality, motivation, well-being, satisfaction with life, and self-esteem.&#x201D; Scoring low is associated with depression, frailty, lack of emotionality, and so on. I wouldn&#x2019;t be surprised if the &#x2018;Big One&#x2019; simply tracks how frequently and deeply someone anneals.</p><p>Continuing the thread on Social Annealing, I think we can push into sociology with the Neural Annealing model too; <strong>to understand a society, we need to understand how and when annealing happens in that society</strong>. To gauge the wisdom of a society, look at how its decision-makers anneal; to gauge the cultural direction of a society, look at how its young people anneal. To understand the strongest social bonds of a society, look at the contexts in which group annealing happens.</p><p>This also suggests why drugs like alcohol and certain psychedelics are ritualistically celebrated in so many cultures: they allow social-annealing-on-demand, a key technology in building and maintaining social cohesion and coordination.</p><p>Likewise, we could envision a field of &#x2018;<u>social archeology</u>&#x2019; evaluating annealing patterns in the past: how often did peasants and nobles in the Middle Ages anneal? In what contexts did the annealing happen, and which institutions controlled them? Perhaps most political conflicts could be reinterpreted as conflicts over annealing.[10] And so on. My colleague Andr&#xE9;s has suggested that a good rule of thumb for identifying annealing (and making good movies) is that intuitively, annealing defines where you should actually point the camera if you were making a movie of a historical period, since where annealing is happening is where changes that &#x2018;matter&#x2019; are taking place: cognitive updates, decisions about how to feel, and so on.</p><p><u>On the effect of profession on emotional vibrancy</u>: It would be somewhat surprising if certain repeated computational tasks didn&#x2019;t tend to push regions&#x2019; key signatures into being highly coupled (=intense emotions), whereas other classes of tasks push regions&#x2019; key signatures into fairly orthogonal configurations (=&#x2018;white noise&#x2019; as emotional state). A lifetime of dance or poetry might literally make you feel emotions more strongly; a lifetime of doing accounting might literally produce a segmented brain and affective blunting. From Darwin&#x2019;s autobiography:</p><blockquote><em>I have said that in one respect my mind has changed during the last twenty or thirty years. Up to the age of thirty, or beyond it, poetry of many kinds, such as the works of Milton, Gray, Byron, Wordsworth, Coleridge, and Shelley, gave me great pleasure, and even as a schoolboy I took intense delight in Shakespeare, especially in the historical plays. I have also said that formerly pictures gave me considerable, and music very great delight. But now for many years I cannot endure to read a line of poetry: I have tried lately to read Shakespeare, and found it so intolerably dull that it nauseated me. I have also almost lost my taste for pictures or music. &#x2026; I retain some taste for fine scenery, but it does not cause me the exquisite delight which it formerly did. &#x2026;</em></blockquote><blockquote><em>This curious and lamentable loss of the higher aesthetic tastes is all the odder, as books on history, biographies, and travels (independently of any scientific facts which they may contain), and essays on all sorts of subjects interest me as much as ever they did. My mind seems to have become a kind of machine for grinding general laws out of large collections of facts, but why this should have caused the atrophy of that part of the brain alone, on which the higher tastes depend, I cannot conceive.&#xA0;</em></blockquote><p>Reading this account, I find it plausible that Darwin repeatedly pushed (and annealed) his mind toward RSHW-driven &#x2018;clockwork piecemeal integration&#x2019; interactions rather than CSHW/SSHW-driven global symmetry gradients, although Darwin&#x2019;s age, sickness, and depression may have also contributed. A warning sign for us theorists and systematizers.</p><p><strong><u>Conclusion:</u></strong></p><p>Neural Annealing is a neuroscience paradigm which aims to find the optimal tradeoff between elegance and detail. It does this by identifying a level of abstraction which supports parallel description under three core principles of self-organization: physical self-organization (around connectome resonances), computational self-organization (around minimization of surprise), and energetic self-organization (around conditional entropic disintegration).</p><p>There is yet much work to be done: in particular, there are huge bodies of literature around receptor affinities, network topologies, regional anatomies and cell types, and so on. The promise of Neural Annealing is it&#x2019;s not only a predictive and generative theory in its own right, but it provides a level of description by which to connect these disparate maps, and an extensible context to build on as we add more and more detail to the model.</p><p>Finally, we can ask: why does good neuroscience <em>matter</em>? I would offer the following.</p><p>The future could be much better than the present. <em>Much</em> better.</p><p>Material conditions are only very loosely coupled with well-being. If life is to be radically better in the future, it will be due to better neuroscience pointing out how we can be kinder to ourselves and others, and future neurotechnology changing the hedonic calculus of the human condition.</p><p>A unified theory of emotional updating, depression, trauma, meditation, and psychedelics may give us the tools to build a future that&#x2019;s <em>substantially</em> better than the present. This has been my hope while writing this.</p><p>&#x2013;Michael Edward Johnson, Executive Director, Qualia Research Institute</p><p><strong><u>Endnotes:</u></strong></p><p>[1] The &#x2018;semantically neutral energy&#x2019; model also suggests why transcranial magnetic stimulation (TMS) seems to <a href=""https://www.mayoclinic.org/tests-procedures/transcranial-magnetic-stimulation/about/pac-20384625"">help treat depression</a> &#x2013; essentially, TMS injects a large amount of energy into the brain, and this energy (1) triggers some entropic disintegration, allowing escape from bad local minima, and (2) may <em>slightly</em> collect in the brain&#x2019;s natural harmonics, which may help pull the brain out of dissonant equilibria. Note that this could be done <em>much more effectively</em>: instead of the present strategy of using a quick flash of unpatterned, pulsed TMS (e.g., 5 seconds @ 100hz) which overpowers the brain but quickly dissipates and likely doesn&#x2019;t lead to a <em>significant</em> build-up in harmonics, we could instead try an entrainment approach via lower-power, rhythmic, continuous TMS, applied for longer durations (keeping the brain above its &#x2018;recrystallization temperature&#x2019; for longer, allowing a fuller self-organization process), perhaps paired with music.</p><p>[2] Thanks to Andr&#xE9;s for the idea about somatic information, and the suggestion of sensorium as the label.</p><p>[3] I suspect that <em>muscle tension</em> could be a core mechanism for regulating SSHWs and perhaps CSHWs. Tensing muscles will strongly influence body resonance, and one&#x2019;s body resonance configuration will likely have ripple effects on what sorts of frequencies persist in the brain. This suggests that traditions such as yoga are basically right when they posit a link between problems in muscles and problems in the mind: we may hold tension in one system in order to compensate for a problem in the other. Speculatively, this compensatory regulation may also be found <em>across</em> humans, especially in pair bonds: that tension in your back might in some literal way be an attempt to help your partner with their emotional regulation. This would suggest muscle tension should change significantly after a break-up. (Thanks to Emily Crotteau, Lena Selesneva, and Ivanna Evtukhova for pieces of the puzzle here.)</p><p>[4] My colleague Andr&#xE9;s suggests that &#x201C;[A] more direct method, though perhaps more difficult, would be to look directly for the spectral signatures of injection locking &#x2014; we&#x2019;d predict you will see a seriously diminished degree of injection locking signatures on people who are heavily traumatized, and see it come back after MDMA therapy.&#x201D;</p><p>[5] Perhaps we could model Persistent Non-Symbolic Experience (PNSE) as persistent partial injection locking of key regions by low frequency CSHWs: essentially this would involve entraining (and effectively partially disabling) the machinery that usually handles interpretation of certain particulars / cognitive interpretations. Perhaps highly neurotic or traumatized individuals with strong top-down control exhibit the opposite: essentially trying to entrain CSHWs to a specific region (with predictably poor results).</p><p>[6] My colleague Andres also recommends against &#x201C;psychedelic substances that have as part of their activity profile a high level of body-load, such as nausea and cramps as these patterns might themselves become annealing targets (cf. compounds notorious for this, according to <a href=""https://psychonautwiki.org/wiki/Body_load"">PsychonautWiki</a> such as 2C-E, 2C-T-2, and 2C-P, are probably best avoided as therapeutic aids).&#x201D;</p><p>[7] On psychedelic tolerance: if the semantically-neutral energy model of psychedelics proves out, we should also be open to subtle corollaries: e.g., to what extent is the temporary tolerance effect of psychedelics <em>biochemical</em> (depletion of some neurotransmitters, per the current story) and to what extent is it <em>information-theoretic</em> &#x2014;associated with the release and depletion of systemic sources of Free Energy? I.e., there is potential energy of a sort liberated when the system finds a better local minima, and if the system has undergone strong annealing recently, there are fewer such &#x2018;energetic free lunches&#x2019; around to help power the psychedelic effects. (Hypothesis held weakly, as my colleague Andr&#xE9;s points out there are psychedelics which do not trigger tolerance, such as N,N-DMT and 5-MeO-DMT.)</p><p>[8] HT to Steve Lehar for pointing at this <a href=""https://qualiacomputing.com/2018/12/12/the-phenomenal-character-of-lsd-mdma-candy-flipping-according-to-cognitive-scientist-steve-lehar/"">&#x2019;nystagmus&#x2019; phenomenon</a> as being somehow linked to MDMA&#x2019;s mood-lifting effect, and to Andr&#xE9;s for calling my attention to Lehar&#x2019;s work and suggesting 5-MeO-DMT may also share this mechanism.</p><p>[9] This is a reference to Eliezer Yudkowsky&#x2019;s &#x201C;<a href=""https://arbital.com/p/cev/"">Coherent Extrapolated Volition</a>&#x201D; (CEV) concept, which is an attempt to sketch a heuristic for how to use a radically-powerful optimization process (such as an AGI) safely. Essentially, CEV suggests we could aggregate all human preferences (volitions), find some way to merge them (make them &#x2018;cohere&#x2019;), then repeat (extrapolate), until we get to a self-stable loop. A &#x2018;psychedelic extrapolated volition&#x2019; is a variation of this: if it becomes easier to change yourself on psychedelics, and then that person you turn into can change themselves into someone else, and so on, where do you end up? What generates a &#x2018;positive vector&#x2019; here?</p><p>[10] This naturally and unfortunately makes the access to and contexts of social annealing an axis of cultural conflict: those who control these events control the emotional tone and contours of coordination of a society. Taking away healthy annealing contexts from your opponents and giving more social annealing opportunities to your people is a key (but also very dirty) way to &#x2018;win&#x2019; the culture war. (Perhaps the opioid crisis, and the crack-cocaine crisis before it, could in some sense be exacerbated by a lack of healthier annealing opportunities.)</p><p><strong><u>Citation</u></strong></p><p>For attribution in academic contexts, please cite this work as:</p><p>Michael Edward Johnson, &#x201C;Neural Annealing: Toward a Neural Theory of Everything&#x201D;, https://opentheory.net/2019/11/neural-annealing-toward-a-neural-theory-of-everything/ , San Francisco (2019).</p><p><strong><u>Acknowledgements</u></strong></p><p>I&#x2019;d like to thank Andr&#xE9;s G&#xF3;mez Emilsson for many great conversations on annealing (and first <a href=""https://qualiacomputing.com/2016/06/20/algorithmic-reduction-of-psychedelic-states/"">calling my attention</a> to the term), energy sinks, and countless other topics, and offering careful feedback on a draft of this work; Robin Carhart-Harris and Karl Friston for a beautiful description of simulated annealing; Romeo Stevens for wide discussion about annealing &amp; ontologies; Adam Safron for introducing me to the depth of explanation afforded by predictive coding, pointing me toward injection locking, and many great conversations in general; Quintin Frerichs for his hard work toward making therapeutic applications of this theory real, and the rest of the QRI team for support and inspiration; Milan Griffes for careful feedback on a draft of this work; Alex Alekseyenko and James Dama for discussions about simulated annealing; Anthony Markwell for sharing the Buddhist Dhamma with me in such a thoughtful and generous way; Justin Mares for his constant curiosity and encouragement; my parents, for their endless love and patience; Lena Zaitseva and Lena Selesneva for their warmth and support; and especially Ivanna Evtukhova, who has made my life radically better and whose love, energy, and obsession with Buddhist enlightenment was why this work happened.</p><p><em>To gratitude.</em></p><p><u>Timeline</u>: most of this document written ~Feb-April 2019, as a continuation of <a href=""https://opentheory.net/2018/08/a-future-for-neuroscience/#"">The Neuroscience of Meditation</a> and <a href=""https://www.youtube.com/watch?v=nY9H5CK4GbE"">this talk</a>, and shared internally and with select reviewers; section dealing with trauma written July 2019. Document reordered for flow and polished in Oct-Nov and posted Thanksgiving 2019.</p>",michael-edward-johnson,michael-edward-johnson,Michael Edward Johnson,
qemSp2DzFqxCGDZa5,Preserving Practical Science (Phronesis),preserving-practical-science-phronesis,https://www.lesswrong.com/posts/qemSp2DzFqxCGDZa5/preserving-practical-science-phronesis,2019-11-28T22:37:21.591Z,8,5,0,False,False,,"<p>This is my first commentary on the previous Saint Louis Junto Meeting whose notes are <a href=""https://www.lesswrong.com/g/JTMprAL9QpCct2od3/p/s4nzgnkDZWpyCwcWT/"">here</a>. Since a meetup can cover diverse topics, I have decided that I will not include running commentary in the meeting notes, and instead reflect upon a few of the discussions in subsequent posts. If I like the results of this procedure, I will stick with it.</p><p>--</p><p>There is a certain type of knowledge gained from experience which is different from scientific theory and from rudimentary skills, but which is at the same time skill-based and scientific. Here are the examples we came up with in our meeting:</p><blockquote>         i. <a href=""https://rootsofprogress.org/iron-from-mythical-to-mundane"">Iron Working, </a>Guild and Trades, etc. functioned  through an unbroken apprentice system. It takes a blacksmith to make a blacksmith. The non-academic approach makes learning what was done at  any particular time difficult. High iteration processes generally have  this feature. What fields today are very difficult to learn about  without doing?</blockquote><blockquote>         ii. NASA&#x2019;s Apollo Program was so <a href=""https://www.forbes.com/sites/quora/2015/12/11/how-we-lost-the-ability-to-travel-to-the-moon/"">&#x201C;do engineering&#x201D;</a> focused that it took a long time after the fact to figure out exactly how all the parts were made to fit together.</blockquote><blockquote>          iii. Nuclear scientists today are<a href=""https://80000hours.org/podcast/episodes/ambassador-bonnie-jenkins-peace-arms-control/""> monitored </a>so that their know-how is put to use in approved countries, same for WMD specialists, etc. </blockquote><blockquote>          iv. International Students in the US have limited access to  highly advanced fields and the most cutting edge. Sometimes for National  Security reasons, but mostly for the reason of patent protection and  intellectual property rights for professors and grant making agencies. It&apos;s not that other countries can figure out these technologies in principle; it&apos;s that implementation is somehow a different category of knowledge.</blockquote><p>The Greek word <em><a href=""http://i. Iron Working, Guild and Trades, etc. functioned  through an unbroken apprentice system. It takes a blacksmith to make a  blacksmith. The non-academic approach makes learning what was done at  any particular time difficult. High iteration processes generally have  this feature. What fields today are very difficult to learn about  without doing?               ii. NASA&#x2019;s Apollo  Program was so &#x201C;do engineering&#x201D; focused that it took a long time after  the fact to figure out exactly how all the parts fit together.                iii. Nuclear scientists today are monitored so that their know-how is put to use in approved countries, same for WMD specialists.                 iv. International Students in the US have limited access to  highly advanced fields and the most cutting edge. Sometimes for National  Security reasons, but mostly for the reason of patent protection and  intellectual property rights for professors and grant making agencies."">phronesis</a></em> is usually translated as &apos;practical wisdom&apos; or &apos;prudence&apos; which is distinct from rudimentary skills (<em>techne</em>) or scientific knowledge (<em>episteme</em>). These three categories or knowing were codified by Aristotle, and we probably should be careful about using them to apply to today. Nonetheless, they are decent starting point for thinking about a type of knowledge that is sometimes hard to preserve, and extremely expensive to recover once lost.</p><p>I came up with some additional examples that are not in scientific fields.</p><blockquote>i. How to raise a family. A community of friends of different ages and generations develop an art of living and take care to provide advice and help to young parents so that they can do well and ensure the children have the resources and opportunities to succeed. When a community does not have this, it becomes extremely hard to overcome poverty.</blockquote><blockquote>ii. A business becomes the best at doing some activity, say, HR consulting, because the managers collectively have more experience executing projects of this type than any other business AND consequently they have developed more effective processes than their competitors. If the business goes belly up, what are the chances that the unique know-how developed in the business, but not in the head of any one person, survives?</blockquote><p>Society has done a few things to make knowledge more durable.</p><p>1. Put it on the internet. Much stuff is on the internet. There is a lot of advice out here, some good, some bad. But for everyday know-how the internet is everyone&apos;s one stop shop.</p><p>2. Internal audits. Perhaps your information is proprietary, secret, or classified, internal audits ensure that what is happening within the organization is codified and recorded so that it is at least possible to go back in time and figure out what was happening.</p><p>3. Good Old Education. There are probably more technical skill programs in existence today than at any time in history. While learning the skill is not exactly the same as getting the experience, it is necessary for the re-creation of that practical wisdom.</p><p>To 1: The internet is a great source of knowledge. But I am not prepared to say it is a great source of highly specialized know-how. Is how to be a good University president an easily discoverable and widely discussed skill on the internet? No. How about Governor of a State or Mayor of a City? These obviously require skill and know-how, but the practical wisdom is extremely tied up with the subtle particulars of each individual situation. One might rightly call these fields &apos;overdetermined&apos; and the people who hold these positions are frequently &apos;overfitted&apos; for the position through a network of &apos;who-you-know&apos; stretching back at least one generation.</p><p>For many business issues, the no one on the internet has already addressed your specific situation, because if there are 15 binary factors at play, then it is likely no one has encountered this exact situation before. Same goes for scientific researchers and political operatives and all the highly specific factors in your life. You will get general guidance by looking at the archives or a mathematical model, but never a specific answer. Your own judgement is ultimately required, hopefully you have a community in the know to discuss it with... I guess that&apos;s why we invented conferences. Yet somehow I don&apos;t think conferences are the grand answer to breaking open narrow communities of expertise.</p><p>To 2: Internal audits, done well, ensure that everything is being recorded and essential aspects of the system can be put back together again. How to run the business is not usually part of the audit, but the process for creating the product is. Preserving that is essential. Keep doing it! However, there is a danger that mergers and acquisitions will likely screw up the knowledge contained in the processes, misplace that hidden information, and then do things worse forever.</p><p>Furthermore, the preservation of old information is hard problem. Doing it without the internet is even harder.</p><p>To 3: Two complaints about education. &quot;We teach quickly outdated skills. Technical training is useless if students don&apos;t know how to reason.&quot; And &quot;Everything I learned in school was theoretical, and though interesting, had no practical value!&quot; Robert Heinlein&apos;s most divisive quotation I think concerns the middle ground, the type of practical competence gained after years of both practicing and theorizing. </p><blockquote>A human being should be able to change a diaper, plan an invasion,  butcher a hog, conn a ship, design a building, write a sonnet, balance accounts, build a wall, set a bone, comfort the dying, take orders, give orders, cooperate, act alone, solve equations, analyse a new problem, pitch manure, program a computer, cook a tasty meal, fight efficiently, die gallantly. Specialization is for insects. </blockquote><p>I appreciate the spirit behind Heinlein&apos;s quixotic list, a society which had similar skills more widely distributed, could only come to be if communities of experienced practitioners were constantly enrolling inexperienced amateurs into their ranks. Even so, there can never be enough experts to train the next generation of novices in a local area. Much specialization is required.</p><p>In conclusion, our society preserves and extends practical wisdom through internet blogs and vlogs, conferences, professional societies, internal audits, research journals, and educational programs. If we can make sure these things happen in our own fields of expertise, then we can go a long way to making sure the future is not condemned to reinventing the wheel, writing, or actuarial science.</p>",JohnBuridan,johnburidan,SebastianG ,
QgYWrqrFoT7XJiFTT,Order and Chaos,order-and-chaos,https://www.lesswrong.com/posts/QgYWrqrFoT7XJiFTT/order-and-chaos,2019-11-28T21:27:22.979Z,12,5,4,False,False,,"<p>Follows from: </p><p><u><a href=""https://www.lesswrong.com/rationality"">Map and Territory</a></u></p><p><u><a href=""https://www.lesswrong.com/s/pC6DYFLPMTCbEwH8W"">Babble and Prune</a></u></p><p><strong>Warning</strong>: I strongly recommend <strong>not</strong> using the concepts in this sequence to try and build a generalized artificial intelligence. These concepts describe how humans function as conscious entities, and humans are not known for being safe or friendly to human values. Human limitations currently provide the only check on human abuse of power, and building something with human cognitive abilities but without those limitations would be ill-advised. Human. </p><h1>Introduction</h1><p>This series of articles is about applied metacognition, laying the groundwork for developing the skills to approach and effectively handle any type of problem or situation. </p><p>The concepts in this particular article may already be familiar. I&#x2019;m presenting them here because we will use them in later articles to derive the different types of skills and explain how those skills work and how they fit into our toolbox. </p><h1>The Map and the Territory</h1><p>A previous article, <u><a href=""https://www.lesswrong.com/posts/bRGbdG58cJ8RGjS5G/no-really-why-aren-t-rationalists-winning"">No Really, Why Aren&#x2019;t Rationalists Winning?</a></u>, established that skills are highly compressed procedural information. In our sequence premier, <u><a href=""https://www.lesswrong.com/posts/GMTjNh5oxk4a3qbgZ/the-foundational-toolbox-for-life-introduction-1"">The Foundational Toolbox for Life: Introduction</a></u>, we looked at them from a different angle: skills start as paradigms which filter out information. We develop our paradigms into skills by calibrating them with experience to produce useful answers to problems in a practical time frame. </p><p>Now we will look at the map/territory distinction and how we use it to define the basic building blocks of cognition itself. Once we&#x2019;ve done that, we can finally move on to what we can build with those blocks. </p><p>Every skillset, from science to art to athletics to management, requires an explicit or implicit mental model of certain aspects of the world: a map. Every person has at least one map in their brain, which <u><a href=""https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation"">represents the territory</a></u> that is the real world, or at least the part they deal with. The map lets a person predict the outcomes of their actions, and thereby allows them to effectively navigate the territory and change it in pursuit of their desires. Without the map, there would be no way for a person to predict which options lead to desirable outcomes. </p><p>Even primitive life forms have evolved rudimentary maps. Their instincts represent the effects of their potential responses to specific stimuli on the probability that they will survive and reproduce. The correlations encoded in these instincts are a narrow, low-resolution map of the organisms&#x2019; native environments. </p><p>However, instinct maps are updated by the processes of mutation and natural selection&#x2014;in other words, chance and death. Each individual is stuck with an instinct map that either succeeds or fails fatally. Humans generally want to improve their models of reality in less lethal ways, so they use their more sophisticated neural hardware to learn about the world and update their maps on the individual and cultural levels rather than on the species genome level. </p><h1>Order and Chaos</h1><p>The map&#x2019;s relationship with the territory creates a fundamental dichotomy that helps define every tool in our toolbox: the duality of order and chaos. </p><p>&#x201C;Order&#x201D; represents the degree to which the map accurately reflects the territory. This accuracy is measured by how well the map makes predictions. In short, order is what we say we &#x201C;know&#x201D;. When we speak of requirements and limits, what must happen or what cannot happen, we are speaking of order. </p><p>Additionally, &#x201C;order&#x201D; can refer to how easily knowledge and information can be compressed, or how much information we can derive from a small sample size. Patterns across time or space are called &#x201C;orderly&#x201D; because knowing only a fraction of the pattern can enable us to predict the rest. For all territories of a given size, the more orderly ones require fewer bits of information to describe them with a map. For example, a bilaterally symmetrical object allows you to predict what is on one side if you have already seen the other side, so you can describe it in full by showing only one side and defining the plane of symmetry. The map of a particularly orderly territory might translate to a few sample data points and a relatively simple rule. </p><p>By contrast, &#x201C;chaos&#x201D; represents the omissions and errors in the map, the degree to which the map fails to accurately represent the territory. Chaos is the &#x201C;unknown&#x201D;. When we speak of possibilities and uncertainties, of what may or may not happen, we are speaking of chaos. </p><p>The unknowns of chaos includes both unknown unknowns (pure chaos) and known unknowns (chaos bounded by order). Pure chaos manifests as outside context problems or <u><a href=""https://en.wikipedia.org/wiki/Black_swan_theory"">black swan events</a></u>, like being invaded by a continent you never suspected existed. However, much of the chaos that adult humans experience is bounded by order. Although they don&#x2019;t know exactly what will happen, they feel fairly certain it will fall within a range of &#x201C;normal&#x201D; events. The roll of a die provides a more specific example of bounded chaos, since we know every possible face value even if we don&#x2019;t know which one it will be. A trusted probability distribution also imposes some certainty on unpredictable outcomes, at least with large sample sizes. Even if individual measurements may vary, we know roughly what the data on the group as a whole will look like. </p><p>Whenever something you thought you knew turns out to be false or incomplete, that is chaos as well. The truest knowledge of the territory is limited to our scattered data points of direct experience, and we create our maps to interpolate and explain those data points as best we know how. Whenever we get a new data point that falsifies the map we were using, when we try to predict the territory and fail, it is another manifestation of chaos. </p><p>Moreover, chaos can refer to how difficult it is to compress information, or to figure out the details of a situation from limited data. A situation described as &#x201C;chaotic&#x201D; is difficult to predict because the information you have about it cannot be used to derive the information you <em>want</em>. For example, in a messy room, the knowledge of one sock&apos;s location does not allow you to locate its pair. </p><p>Although (or because) they are opposite concepts, order and chaos are more or less inextricable. The known and unknown are present to varying degrees in almost every situation you encounter, because they are essential to conscious existence as we know it. We often say that perfectly certain knowledge of the territory is impossible, but we don&#x2019;t classify everything as completely unknown, either. Instead of a binary label of &#x201C;known&#x201D; or &#x201C;unknown,&#x201D; we have gradients of certainty that inform how much of our resources and safety we are willing to bet on various unknowns. </p><p>As a <u><a href=""https://www.lesswrong.com/posts/afmj8TKAqH6F2QMfZ/a-technical-explanation-of-technical-explanation"">technical explanation</a></u> of these concepts, &#x201C;chaos&#x201D; simply describes a relatively smooth and somewhat even distribution of probability mass across a range of hypotheses, where no hypothesis in the range is considered overwhelmingly more likely than another. &#x201C;Order&#x201D; describes a sharper, uneven distribution where probability mass is concentrated into a relatively small number of hypotheses. If (as usual) you have a subset of hypotheses that are overwhelmingly more likely than all others but roughly equal in probability with each other, that&#x2019;s bounded uncertainty: chaos bounded by order (or chaos inherent in order, depending on which one you want to imply is dominant). </p><p>You may have gathered that order and chaos are also subjective in their application. A territory cannot be intrinsically &#x201C;orderly&#x201D; or &#x201C;chaotic&#x201D; without reference to a given map (or compression algorithm). A situation will appear more or less chaotic to you in proportion to your ignorance of it. After all, confusion (or lack thereof) is in the map. </p><p>Order and chaos are also implicitly based on what information people consider important. The die roll mentioned above is &#x201C;bounded by order&#x201D; because it has a finite number of defined results. However, the reason the number of defined results is so low is because we don&#x2019;t pay any attention to the location at which the die comes to rest, or the direction it faces, or the amount of time it takes to stop rolling&#x2026; </p><p>The fact that these definitions of order and chaos are relative rather than objective is to be expected, because all the concepts in our toolbox are based on solving problems. Problems can only be defined in terms of a person&#x2019;s desires, what sorts of obstacles stand in the way of those desires, and what the person can do to overcome those obstacles. </p><p>The next section deals with how our minds process order and chaos. Understanding how we deal with the shape of what we know and what we don&#x2019;t know (and what we don&#x2019;t know we don&#x2019;t know) is vital for describing how our skills work. </p><h1>Guessing and Checking</h1><p>At the most fundamental level of mental activity that is still complex enough to be recognized as mental, we find two processes. These processes explore chaos and order, respectively, so that the mind can develop and refine its map. I call these processes &#x201C;guessing and checking&#x201D;. <u><a href=""https://www.lesswrong.com/s/pC6DYFLPMTCbEwH8W"">Elsewhere on this site</a></u>, they are known as &#x201C;babble and prune&#x201D;. As far as I can tell, these phrases refer to the same pair of concepts. </p><p>Guessing is more or less free association: it links our current experiences and thoughts with any concepts that are remotely similar, and calls our attention to those concepts. To guess is to throw one&#x2019;s map up against the territory in various ways (without judging the results&#x2014;that&#x2019;s where check comes in). Guessing is the mind wrangling chaos. It follows possibilities based on an initial idea and makes them concrete in the mind. It allows the mind to model (and therefore address) the unknown territory by giving shapes to the potential that lurks within. </p><p>Checking is the process by which we judge whether a concept is relevant to the current situation. It evaluates how we are applying the map to the territory, and the predictions we make from it, by comparing them to other observations of the territory or to memories that our guessing has summoned up. Based on this evaluation, the check accepts or rejects the accuracy (predictive utility) of the concept in the given situation. Checking is the mind wrangling order, because it decides what information gets to become and remain part of the map. It allows the mind to produce and curate knowledge by judging how well the map of the known matches the territory (or other parts of the map) in the way that guessing has applied it. </p><p>To illustrate how these cognitive processes work, we can look at what happens when each of them is shut off. </p><p>All guessing and no checking would be like an incoherent dream, or (people tell me) the effects of some recreational drugs: a parade of random impressions. It would consist of complete free association, but nothing for assessing correspondence with reality and filtering out what doesn&apos;t fit. </p><p>Inversely, all checking and no guessing would allow one to apply a single concept, but one would have no ability to update the paradigm of how to apply it. For instance, an entity with checking but no guessing might be able to classify organisms as cats or dogs, but it wouldn&apos;t be able to realize that some organisms are neither (unless it already had a label for that). </p><p>From these examples, it is clear that both guessing and checking are necessary aspects of any skill, because both are necessary to generate and calibrate our maps. </p><p>As a more technical explanation of guessing and checking, guessing iterates through locations in hypothesis space. However, hypothesis space&#x2014;the space of possible maps&#x2014;is theoretically infinite, with infinite dimensions, and is therefore non-ordered (that is, it doesn&#x2019;t have a linear sequence). To make iteration through unlimited possibilities computationally tractable, our brains use free association. The brain keys off of immediate sensory inputs or thoughts to find possibly related concepts, then keys off of those concepts to find more distantly related concepts, and so on. Through this process, guessing takes us to the most salient-seeming locations in hypothesis space. Each location visited, correct or not, is added to a map of possibilities as a candidate for representing the territory. </p><p>As we guess each hypothesis in turn, checking will accept or reject the hypothesis with varying degrees of confidence by pumping probability mass into or out of it, redistributing the probability mass across the range of hypothesis space we are exploring. It performs this redistribution by updating our map of possibilities, revising the degrees of certainty across the board based on its evaluation of each option. </p><p>Naturally, if we examine all the major hypotheses and decide they&apos;re still equally likely, then our pumping has canceled itself out. If our checking, based on our prior probabilities, has decided they all match quite well, then we&#x2019;re still undecided. If checking decides the hypotheses all match equally poorly, it may be that something improbable happened, or that our guessing didn&#x2019;t go far enough to come up with a more likely hypothesis, or that our check rejected something in error because we were ignorant of a factor making it more probable. </p><h1>Distinct and Subliminal</h1><p>There&#x2019;s one other dichotomy that we need to finish laying the groundwork for the basic skills: distinct versus subliminal. </p><p>When a guessing or checking activity takes place in our brains, it can do so in two modes. </p><p>First, it can run distinctly, where there is an explicit record (a memory) of the iteration process and we are fully aware of what possibilities or implications we are considering. We refer to distinct processes as taking place in our <u><a href=""https://medium.com/positive-returns/understanding-systems-of-thinking-1a5a5c11525d"">System 2</a></u>, which might also be called the &#x201C;manual&#x201D; system. </p><p>Second, guessing or checking can run subliminally (&#x201C;below the threshold&#x201D;) where there is no explicit record of the process, and we are only left aware of the end result, if even that. We frequently form beliefs and decisions based on subliminal processes without realizing we&#x2019;ve done so, to our detriment or benefit. We say these processes are part of System 1, often called the &#x201C;automatic&#x201D; system. </p><p>The modes in which our guessing and checking processes run determine what sort of maps we use and how we update them. The maps we use define the types of skills that we employ, what aspects of situations they deal with, and their advantages and disadvantages. We&#x2019;ll go into more detail on these maps and what happens when cognitive processes run in various modes in the next part of the sequence. </p><h1>Conclusion</h1><p>All skills involve both guessing and checking in order to update our maps. What differentiates one skill from another is how each process runs: distinctly or subliminally. These modes of guessing and checking inform what sorts of features a skill&#x2019;s map contains and therefore what aspects of the territory its map represents. The dichotomy of order and chaos, describing the degree to which a map corresponds with a territory, is a core concept for distinguishing the different tools in our toolbox. </p><p>In the next article I&#x2019;ll introduce the basic mindsets and explain what sorts of maps they use and how they are defined by how they guess and check. </p>",ExCeph,exceph,ExCeph,
J92QH88nPQTbPskkK,"What are the requirements for being ""citable?""",what-are-the-requirements-for-being-citable,https://www.lesswrong.com/posts/J92QH88nPQTbPskkK/what-are-the-requirements-for-being-citable,2019-11-28T21:24:56.682Z,42,11,8,False,True,,"<html><head></head><body><p>A sort of... ""stretch goal"", for the 2018 Review, is developing a system wherein LessWrong has proven itself credible enough for some posts to actually be citable by other institutions.</p><p>I'm not sure how much of this has to do with ""just actually do a good job ensuring accuracy/relevance"", and how much has to do with ""jumping through arbitrary hoops"", and how hard those hoops are to jump through.</p><p>Two obvious things to shoot for might be:</p><ul><li>Being considered a valid source by wikipedia</li><li>Being considered a valid source by google scholar.</li></ul><p>I'm curious if anyone is familiar with how either of those work, in detail, and whether this is an achievable goal.</p></body></html>",Raemon,raemon,Raemon,
QsF58kspEtqwhxS8F,"What sources (i.e., blogs) of nonfiction book reviews do you find most useful?",what-sources-i-e-blogs-of-nonfiction-book-reviews-do-you,https://www.lesswrong.com/posts/QsF58kspEtqwhxS8F/what-sources-i-e-blogs-of-nonfiction-book-reviews-do-you,2019-11-28T19:43:21.408Z,3,2,0,False,True,,"<html><head></head><body><p>Also tell us why.
I personally find SSC’s book reviews useful, because I feel like I get a summary of an interesting book, with the added bonus of seeing how the author (whose thought process I like) approaches absorbing its information.</p>
</body></html>",rudi-c,rudi-c,Rudi C,
DQWPBuQe6bzzbADHn,Kansas City Dojo meetup 11-12-19,kansas-city-dojo-meetup-11-12-19,https://www.lesswrong.com/posts/DQWPBuQe6bzzbADHn/kansas-city-dojo-meetup-11-12-19,2019-11-28T19:11:23.129Z,4,2,0,False,False,,"<p><strong><u>I.) POST MORTEM OF PREVIOUS MEETING</u></strong></p><p>We discuss the situation from last meeting, when a newcomer and non-rationalist showed up and got into a testy argument with Life Engineer. We concluded that it was primarily a matter of conflicting expectations; the newcomer was expecting a more &quot;salon&quot;-type, open-ended, intellectual conversation like the kind we have on our casual Sunday lunches. Additionally, he has probably never been asked such probing questions as was asked of him; in fact, most people probably haven&#x2019;t.</p><p>We decided that we need to be more clear on setting expectations. &quot;A genuine desire to change&quot; will be an explicit requirement for anyone who attends, in the same way that &quot;a desire to not be an alcoholic&quot; is a requirement for AA.</p><p>Since it wasn&apos;t quite time to start yet, and only core members were present, we allowed ourselves to follow a short tangent from Life Engineer about a comic he read recently about the failure modes of the United States government; specifically how political parties and the internet have thrown a wrench into the system that the Founders created. Since we weren&apos;t seriously entertaining the problem we didn&apos;t allocate much brainpower to it; the only obvious solution is a factory reset of our government, which would likely only happen if something else Very Bad happens. </p><p>With the arrival of our 4th and final RSVP for the evening, we began the Dojo.</p><p><strong><u>II.) ROUND TABLE</u></strong></p><p>&quot;W&quot;, one of our founding members, began by reporting that his adventures in weight loss continue to go positively. His conscious effort to abstain from Entertainment Eating has become habitual now, requiring little to no effort, after about 2-3 months of implementing it. He spoke about his aspirations; how his ideal self is an &quot;impossible person&quot;, something to constantly strive for. In addition to a lovely tangent on &quot;Positive Social Butterflies&quot; (the butterfly effect mixed with an improved variant of the Golden Rule), W talked about how one of his favorite techniques is a particular kind of reframing where instead of seeing what actions he can take to accomplish his goals, he first checks to see if there&apos;s anything he can *stop* doing in order to accomplish his goals.</p><p>I went next. My book reading is going slowly but surely. Chapter a day on average. My review of A Way of Being is positive so far. I also vented about some drama with friends; will share more when I need actionable advice (I&#x2019;m just in a waiting period right now). As general actionable advice, Life Engineer thinks people should take more responsibility for the words they say; specifically they should <em>say what they mean</em>. We then concluded my phase by discussing &#x2018;Ask&#x2019; vs &#x2018;Guess&#x2019; vs &#x2018;Tell&#x2019; culture and how it relates to my social drama.</p><p>Since the order came around to Life Engineer at this point, he spoke up and said &quot;I bought 10 copies of a Brene Brown book and handed them out to everyone I know.&quot;</p><p>*laughter*</p><p>He is primarily concerned with growing his business. Word of mouth tends to work best in his industry, but he is unsure of how to inject himself into the community. I shared a personal anecdote about my recent move which may or may not be helpful; I printed out an introductory note, and put them on the doors of all my closest tennants, offering friendship and cooperation. I had one person actually reach out, which was surprising, and we plan to hang out soon. Life Engineer was not inspired much by this, but he is interested in how it pans out for me, and thinks I should go all-out and make posters.</p><p>We had a semi-related discussion at this point about what I thought was the pretty typical awkward relationship people have with their apartment neighbors. W doesn&apos;t experience this; he is very much involved in a culture that his building shares, which puts everyone on a first name basis. He talks about a neighbor who has a missing leg, and muses about why it&apos;s a social taboo to openly remark about such things. This threatened to suck us into one of our famous tangents, which we briefly touched on: why there are social taboos about people&apos;s injuries/anomalies.</p><p><strong><u>III.) META DISCUSSION</u></strong></p><p>Now we come to our usual topic at the end about how to improve the Dojo. Life Engineer is interested in unpacking the Dojo&apos;s slogan &quot;we are all imperfect decision makers&quot;; he doesn&apos;t see in his personal life that he ever really makes &quot;bad&quot; decisions. He can see where he could have done something different to make his life easier, but the payoff would have been negligible. However, in his line of work, he encounters people all the time who have the same belief: &quot;I don&apos;t make bad decisions&quot;, and yet their marriages are falling apart, they have an addiction, etc. He acknowledges that &quot;people make bad decisions&quot; is a reality, but he has trouble seeing it in himself and is interested in whether that&apos;s because he truly doesn&apos;t make bad decisions, or if he is in the same boat as his clients where he simply doesn&apos;t see it.</p><p>This is more of an open question for us to mull over than anything else. We need to think about it more in-depth before we propose solutions. He wants to wrestle with it not only due to the obvious concerns (eg &quot;Change into what?&quot;, &quot;Is what we are doing as a community valuable?&quot;), but also due to the failure mode of sounding patronizing to people who are in a completely different worldview.</p>",Senarin,senarin,Bae's Theorem,
5je5Zht8ept7hZmRJ,SSC Meetups Everywhere Retrospective,ssc-meetups-everywhere-retrospective,https://www.lesswrong.com/posts/5je5Zht8ept7hZmRJ/ssc-meetups-everywhere-retrospective,2019-11-28T19:10:02.028Z,32,7,0,False,False,,"<p>Slate Star Codex has regular weekly-to-monthly meetups in a bunch of cities around the world. Earlier this autumn, we held <a href=""https://slatestarcodex.com/2019/08/28/meetups-everywhere-2019/"">a Meetups Everywhere event</a>, hoping to promote and expand these groups. We collected information on existing meetups, got volunteers to create new meetups in cities that didn’t have them already, and posted times and dates prominently on the blog.</p>
<p>During late September and early October, I traveled around the US to attend as many meetups as I could. I hoped my presence would draw more people; I also wanted to learn more about meetups and the community and how best to guide them. Buck Shlegeris and a few other Bay Area effective altruists came along to meet people, talk to them about effective altruism, and potentially nudge them into the recruiting pipeline for EA organizations.</p>
<p>Lots of people asked me how my trip was. In a word: exhausting. I got to meet a lot of people for about three minutes each. There were a lot of really fascinating people with knowledge of a bewildering variety of subjects, but I didn’t get to pick their minds anywhere as thoroughly as I would have liked. I’m sorry if I talked to you for three minutes, you told me about some amazing project you were working on to clone neuroscientists or eradicate bees or convert atmospheric CO2 into vegan meat substitutes, and I mumbled something and walked away. You are all great and I wish I could have spent more time with you.</p>
<p>I finally got to put faces to many of the names I’ve interacted with through the years. For example, Bryan Caplan is exactly how you would expect, in every way. Also, in front of his office, he has a unique painting, which he apparently got by asking a Mexican street artist to paint an homage to <i>Lord of the Rings</i>. The artist had never heard of it before, but Bryan described it to him very enthusiastically, and the completely bonkers result is hanging in front of his office. This is probably a metaphor for something.</p>
<p>Philadelphia hosted their meetup in a beautiful room that looked like a Roman temple, and had miniature cheesesteaks for everybody. Chicago held theirs in a gym; appropriate, given this blog’s focus on <a href=""https://slatestarcodex.com/2015/06/02/and-i-show-you-how-deep-the-rabbit-hole-goes/"">BRUTE STRENGTH</a>. Berkeley’s was in a group house with posters representing the <a href=""http://yudkowsky.net/rational/virtues/"">Twelve Virtues Of Rationality</a> hanging along the staircase. In Fairbanks, a person who had never read the blog showed up to get a story and an autograph for his brother who did. In New York, someone brought the best bread I have ever had, maybe the best bread <i>anyone</i> has ever had, I am so serious about this.  In Boston, the organizers set up a prediction market to determine how many attendees they needed to plan for; they still ended up being off by a factor of two. This is also probably a metaphor for something. If only they had used more BRUTE STRENGTH!</p>
<p>Along the way, I got to see America. Most of it I saw from an airplane window, but I still saw it. In Portland, I ate from a makeshift food court formed by a bunch of really good food trucks congregating in the same empty lot; one of them just sold like a dozen different kinds of french fries. In Texas, I rode with an Uber driver whose day job is driving mechanical bulls to parties that need mechanical bulls, and who Ubers people around while he waits for the party to finish. In Washington DC, I tried to see the White House, only to be thwarted by <a href=""https://apnews.com/4a50fe0b387e4948ad13ead22e75444f"">the construction of a new security fence</a>; they say that before you change the world you must change your own home, and it seems like our Wall-Builder-In-Chief takes this seriously. In Delaware, I stood on the spot where the Swedes first landed in America and declared it to be the colony of <a href=""https://en.wikipedia.org/wiki/New_Sweden"">New Sweden</a>; probably there are alternate timelines out there who could appreciate this more than I did. In New Jersey, I confirmed that the Pine Barrens are, in fact, really creepy.</p>
<p>People gave me things. You are all so nice, but you also seem to think I am about ten times more classy and fashionable than I really am. One person gave me a beautiful record of their audiobook – a real, honest-to-goodness vinyl record – as if I had any idea what to do with it. A reader in Philadelphia gave me a beautiful glossy magazine about Philadelphia culture, which I stared at intently for twenty minutes. Many people gave me beautifully-bound copies of my own work, which was so incredibly thoughtful that I feel bad that I will have to hide them in a closet so nobody sees them and thinks I am the kind of narcissist who makes beautifully-bound copies of my own work. The <a href=""https://www.chartercitiesinstitute.org/"">Charter Cities Institute</a> people gave me a very nice Charter Cities Institute bag (although I assume that if I ever take it outside in Berkeley, someone will punch me and it will start a National Conversation). I am still really grateful to all of you. </p>
<p>But you already know how great you are. Let’s get to the statistics.</p>
<p>Mingyuan, the Official SSC Meetup Coordinator, sent out a survey to get information on the meetups we weren’t able to visit, and determined that we had somewhere between 81 and 111 meetups around the world. I’m sorry I can’t be more precise. 111 meetups were supposed to happen, 81 organizers reported back to Mingyuan that their meetups happened, and I’m not sure what happened to the other 30. Although most activity was concentrated in the Anglosphere, there were meetups as far away as Bangalore (9 people), Tel Aviv (25 people), Oslo (9 people), and Seoul (4 people). Medellin, Colombia reports a one person meetup; I am sorry it sounds like you did not have a good time. Montreal, Canada, reports a zero person meetup, which sounds very computer-sciency, kind of like a heap of zero grains of sand.</p>
<p><img src=""http://slatestarcodex.com/blog_images/meetupautopsy1.png"" /></p>
<p>Here’s the histogram of attendance, binned by fives. About twenty meetups had 0-5 people, thirty had 5-10, and the remaining thirty had more than 10. The best-attended meetups were Boston (140), NYC (120), and Berkeley (105). Total meetup attendance around the world was almost 1500 people!</p>
<p>Did the event fulfill its goal of bringing more people to meetups? Many organizers had only a vague idea how many people usually attended their meetups, and many said their city didn’t have a usual meetup group at all. But as best I can tell, about 2.3x as many people attended the Meetups Everywhere meetup in a city compared to the average previous meetup. Breaking it down by tour status, meetups on my tour had much higher attendance (6.1x usual), but even meetups off my tour had somewhat higher attendance (1.6x usual).</p>
<p>Did the event succeed in bringing some people into meetup groups who might stay around later? I suggested meetup organizers bring a signup sheet that people could sign to get on a mailing list for future meetups. My data on this is sparse, because people took the survey question overly literally and wrote things like “I didn’t have a signup sheet, I just asked people for their emails” and then didn’t tell me how many people gave them. But for the 40 meetups where I have data, people on average got a population of new signers equal to 77% of their previous regular attendance; that is, a meetup group that usually had 100 people had 77 extra new people sign up for their mailing last. Breaking it down by tour status, meetups on my tour gained 170%, other meetups gained 58%.</p>
<p>This seems implausibly large; did one event nearly double the attendance of SSC meetup groups around the world? I don’t know how many people who signed up for the mailing list will really start attending regularly. But I will probably survey the organizers again next year, and they might be able to help me figure out how many people stayed around.</p>
<p>In total, 1,476 people attended SSC meetups, and 339 people added their name to mailing lists (the ratio here doesn’t match the previous numbers because most organizers didn’t have a mailing list or didn’t report mailing list data, and the ratios above only counted those who did).</p>
<p>So much for the numbers. What did I learn?</p>
<p>I don’t want to generalize too much – I deliberately went to the biggest meetups, and things that work for a group of 100 people might not apply to a group of 2 people. So take all of this with a grain of salt, but:</p>
<p><b>1. Tables and chairs kill big meetups.</b> Some people tried to hold meetups at a restaurant or a park with picnic tables or something. Everyone would sit down at the table, talk to the 3-4 people in their immediate neighborhood, and that would be that. Eventually I figured out that I need to force everyone out of the picnic tables and into the rest of the park. This caused a phase shift from solid to gas, with people milling about, talking to everyone, finding the conversations that most interested them.</p>
<p><b>2. The welcomeness sentence is really important.</b> In the meetup descriptions on the blog, I included a sentence like “Please feel free to come even if you feel awkward about it, even if you’re not ‘the typical SSC reader’, even if you’re worried people won’t like you, etc.” It sounds silly, but I had <i>so many</i> people come up to me saying the only reason they came was because of that sentence. It happened <i>again and again and again</i>. Anybody planning any kind of meetup about anything should strongly consider including a sentence like that (as long as it’s true). Maybe there are other simple hacks like this waiting to be discovered.</p>
<p><b>3. Group houses are important community nuclei.</b> Obvious in retrospect, but it was pretty stark seeing the level of community in cities that did have rationalist group houses vs. the ones that didn’t, even if there were good meetup groups in both. This also came out in listening to some people mourn the loss of the main group house in their city and talk about all the great things they were no longer able to do. </p>
<p>I was thinking of this last one because a lot of the meetups felt kind of superficial. Everyone shows up, talks about their favorite SSC post or what their job is or what kind of interesting thing they read recently, and then they go home. Lots of people seemed to enjoy that, <i>I</i> enjoyed it, but seeing the kind of really great rationalist communities in the Bay Area or Seattle gave me a sense that more is possible. I don’t know, maybe it’s not possible in cities with only 10 or 20 interested people; maybe only places like the Bay Area and Seattle have enough people, and everywhere it’s possible it’s already happening. But group houses seem to be a big part of it.</p>
<p>I was also struck by the number of female meetup organizers; the female:male ratio on the meetup organizer survey is almost twice that on the SSC survey in general. When there were cities that didn’t have regular meetup groups, and I asked for a volunteer to set one up, it was usually a woman who volunteered. </p>
<p>This suggests to me that we’re not just performing at some kind of theoretical maximum for the amount of people and interest in a given community; there’s a shortage of something (speculatively, social initiative) that (in this community) women are better than men at. I don’t know how to solve this (though integrating more with the EA community, which has more women, might help), but I think it’s an interesting problem.</p>
<p>And Buck has written his own retrospective of his EA work at the meetups <a href=""https://forum.effectivealtruism.org/posts/yrSiWNypE6AMNApDi/ea-residencies-as-an-outreach-activity"">here</a>.</p>",Yvain,scottalexander,Scott Alexander,
j5CJZ566Pj3AwfrBT,Transparent Newcomb's Problem and the limitations of the Erasure framing,transparent-newcomb-s-problem-and-the-limitations-of-the,https://www.lesswrong.com/posts/j5CJZ566Pj3AwfrBT/transparent-newcomb-s-problem-and-the-limitations-of-the,2019-11-28T11:32:11.870Z,6,3,25,False,False,,"<p>One of the aspects of the <a href=""https://www.lesswrong.com/posts/BRuWm4GxcTNPn4XDX/deconfusing-logical-counterfactuals"">Erasure Approach</a> that always felt kind of shaky was that in Transparent Newcomb&apos;s Problem it required you to forget that you&apos;d seen that the the box was full. Recently come to believe that this really isn&apos;t the best way of framing the situation.</p><p>Let&apos;s begin by recapping the problem. In a room there are two boxes, with  one-containing $1000 and the other being a transparent box that contains either nothing or $1 million. Before you entered the room, a perfect predictor predicted what you would do if you saw $1 million in the transparent box. If it predicted that you would one-boxed, then it put $1 million in the transparent box, otherwise it left the box empty. If you can see $1 million in the transparent box, which choice should you pick? </p><p>The argument I provided before was as follows: If you see a full box, then you must be going to one-box if the predictor really is perfect. So there would only be one decision consistent with the problem description and to produce a non-trivial decision theory problem we&apos;d have to erase some information. And the most logical thing to erase would be what you see in the box.</p><p>I still mostly agree with this argument, but I feel the reasoning is a bit sparse, so this post will try to break it down in more detail. I&apos;ll just note in advance that when you start breaking it down, you end up performing a kind of psychological or social analysis. However, I think this is inevitable when dealing with ambiguous problems; if you could provide a mathematical proof of what an ambiguous problem meant then it wouldn&apos;t be ambiguous.</p><p>As I noted in <a href=""https://www.lesswrong.com/posts/BRuWm4GxcTNPn4XDX/deconfusing-logical-counterfactuals"">Deconfusing Logical Counterfactuals</a>, there is only one choice consistent with the problem (one-boxing), so in order to answer this question we&apos;ll have to construct some counterfactuals. A good way to view this is that instead of asking what choice should the agent make, we will ask whether the agent made the best choice.</p><p>Now, in order to construct these counterfactuals we&apos;ll have to consider situations with at least one of the above assumptions missing. Now we want to consider counterfactuals involving both one-boxing and two-boxing. Unfortunately, it is impossible for a two-boxer to a) see $1 million in a box if b) the money is only in the box if the predictor predicts the agent will one-box in this situation and c) the predictor is perfect. So we&apos;ll have to relax at least one of these assumptions.</p><p>Speaking very roughly, it is typically understood that the way to resolve this is to relax the assumption that the agent must really be in that situation and to allow the possibility that the agent may only be simulated as being in such as situation by the predictor. I want to reiterate that what counts as the same problem is really just a matter of social convention.</p><p>Another note: I said I was speaking very roughly because many people claim that the agent could actually be in the simulation. In my mind these people are confused; in order to predict an agent, we may only need to simulate the decision theory parts of its mind, not all the other parts that make you you. A second reason why this isn&apos;t precise is because it isn&apos;t defined how to simulate an impossible situation; one of my <a href=""https://www.lesswrong.com/posts/AKkFh3zKGzcYBiPo7/counterfactuals-for-perfect-predictors"">previous posts</a> points out that we can get around this by simulating what an agent would do when given input representing an impossible situation. There may also be some people have doubts about whether a perfect predictor is possible even in theory. I&apos;d suggest that these people read one of my <a href=""https://www.lesswrong.com/posts/YpdTSt4kRnuSkn63c/the-prediction-problem-a-variant-on-newcomb-s"">past posts</a> on why the sense in which you &quot;could have chosen otherwise&quot; doesn&apos;t break the prediction and how there&apos;s a sense that you are pre-commited to every action you take.</p><p>In any case, once we have relaxed this assumption, the consistent counterfactuals become either a) the agent actually seeing the full box and one-boxing b) the agent seeing the empty box. In case b), it is actually consistent for the agent to one-box or two-box since the predictor only predicts what would happen if the agent saw a full box. It is then trivial to pick the best counterfactual.</p><p>This problem actually demonstrates a limitation of the erasure framing. After all, we didn&apos;t justify the counterfactuals by removing the assumption that you saw a full box; instead modified it to seeing a full box OR being simulated seeing a full box. In one sense, this is essentially the same thing - since we already knew you were being simulated by the predictor, we essentially just removed the assumption. On the other hand, it is easier to justify that it is the same problem by turning it into an OR than by just removing the assumption.</p><p>In other words, thinking about counterfactuals in terms of erasure can be incredibly misleading and in this case actively made it harder justify our counterfactuals. The key question seems to be not, &quot;What should I erase?&quot;, but, &quot;What assumption should I erase or relax?&quot;. I&apos;m beginning to think that I&apos;ll need to choose a better term, but I reluctant to rename this approach until I have a better understanding of what exactly is going on.</p><p>At risk of repeating myself, the fact that it is natural to relax this assumption is a matter of social convention and not mathematics. My next post on this topic will try to help clarify how certain aspects of a problem may make it seem natural to relax or remove certain assumptions.</p>",Chris_Leong,chris_leong,Chris_Leong,
ey3Hbya63H2L974qZ,Updating a Complex Mental Model - An Applied Election Odds Example,updating-a-complex-mental-model-an-applied-election-odds,https://www.lesswrong.com/posts/ey3Hbya63H2L974qZ/updating-a-complex-mental-model-an-applied-election-odds,2019-11-28T09:29:56.753Z,10,4,3,False,False,,"<p>There are probabilities, and there are probabilities about probabilities. How do these get updated? I&apos;ve had the same discussion several times, and have tried to describe this, but it is hard without going into the math. The formal model is clear, but I have found that the practical implications are hard to describe concretely. I just ran into a great concrete example, however, and I wanted to work through the logic of how I&apos;m updating as a way to show what should happen.</p><p>The example I&apos;m using is my expectations about the 2020 election, how accurate various models are<span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""^1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char""></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>, and how important the inputs are. This type of problem is fairly common - I have both an object level prediction about the winner, and a prediction about / model of how accurate different sources of information will be.</p><p>So, what do I do when information comes in that seems surprising? Two things; I update in the direction the information indicates, and I update against the reliability of the data. The second may seem counter-intuitive, but the example makes it clearer.</p><p>The economy is doing well - recent news is that it&apos;s <a href=""https://www.bea.gov/news/2019/gross-domestic-product-third-quarter-2019-second-estimate-corporate-profits-third-quarter"">better than expected</a>. Presidents with great economies tend to get re-elected. Trump is also unpopular. Unpopular presidents tend not to get re-elected<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""^2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char""></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span>. How do we balance these two, and how do they interact? My model of whether he will win is fairly uncertain, and my model of the sources of data is also uncertain. They are also related in complex ways<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""^3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char""></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span></span></span>. For instance, if Trump&apos;s popularity plummets because, for instance, the impeachment inquiries find something shocking and horrible even to his base, I expect that GDP matters far less for his reelection chances. Other data sources also constrain how far I will update<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""^4""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char""></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">4</span></span></span></span></span></span></span></span> - no level of GDP growth alone will make me say he&apos;s certain<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""^5""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char""></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">5</span></span></span></span></span></span></span></span> to win.</p><p>So I updated towards Trump&apos;s reelection based on the economic data, but my underlying model is telling me that it is decreasingly relevant. That means I&apos;m very slightly down-weighting the importance of economic factors compared to approval rating, since he&apos;s seemingly not getting credit for the growth (or the growth isn&apos;t helping most voters.) The net impact is that I have updated slightly towards Trump&apos;s reelection.</p><br><p>1) For long term forecasts of presidential elections, <a href=""https://fivethirtyeight.com/features/models-based-on-fundamentals-have-failed-at-predicting-presidential-elections/"">forecasts based on fundamentals do just OK</a>. But forecasts <a href=""https://www.economist.com/democracy-in-america/2019/07/26/when-to-pay-attention-to-2020-forecasts"">based on polls do poorly far in advance of the election as well</a>. (Special elections seem to point to a huge shift towards the democrats, despite fundamentals.) More complete models take some of each type of information - but how to combine them is tricky. Some models do it <a href=""https://en.wikipedia.org/wiki/The_Keys_to_the_White_House"">poorly</a>, others do it <a href=""https://fivethirtyeight.com"">well</a>.</p><p>2) I also have expectations about the future inputs to the models. Most presidents have fluctuating approval ratings, so long-term forecasts do poorly. For Trump, his split of approval/disapproval has been remarkably steady, so unless his approval significantly shifts from the current low-40s, or he runs against an incredibly unpopular democrat (which is possible, but seems pretty unlikely,) models that consider this point towards him being unlikely to win. It still may be volatile. For example, the impeachment could solidify his base, or could reduce his popularity further.</p><p>3) This is tricky to describe, but for understanding the overall behavior, a useful strategy is to consider the limit - what happens if the economy is amazing, but everyone hates the president? I&apos;d assume he doesn&apos;t get reelected. Similarly, if everyone loves the president, but the economy is in a deep recession, (for which he&apos;s seemingly not being blamed) he probably gets reelected. </p><p>4) Special elections are favoring Democrats, voter turnout among liberals is expected to be very high because of polarization, etc.</p><p>5) By which I mean highly confident - certainty is impossible. It would take a confluence of events to make my highly confident. Even with such a confluence of events, however, it is far in advance, so I&apos;m not willing to put odds above ~90% / below ~10% because I think there are fundamentally hard questions about the future that impact the probability. (We don&apos;t know who the democratic nominee is, for instance.)</p><br>",Davidmanheim,davidmanheim,Davidmanheim,
Fsvka4DGrrfWPrTzD,How to make TensorFlow run faster,how-to-make-tensorflow-run-faster,https://www.lesswrong.com/posts/Fsvka4DGrrfWPrTzD/how-to-make-tensorflow-run-faster,2019-11-28T00:28:21.099Z,4,3,0,False,False,,"<html><head></head><body><p>I quickly put this together for a fellow AI alignment researcher/engineer, so I thought I'd share it here.</p>
<p>The main recommendations are from Intel: <a href=""https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference"">https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference</a></p>
<p>I implement these recommendations by setting the following in the code:</p>
<pre><code>tf.config.threading.set_inter_op_parallelism_threads(2)
tf.config.threading.set_intra_op_parallelism_threads(6)  # Number of physical cores.
</code></pre>
<p>And setting the environment variables in the PyCharm run configuration and Python Console settings.</p>
<p>As a result, the per-epoch training time dropped  by 20 % with a small multi-layer perceptron on Fashion MNIST.</p>
<p>Another important point is to use a TensorFlow binary that uses all available CPU capabilities. Ie. it should display something like this:</p>
<pre><code>2019-11-27 17:26:42.782399: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: SSE4.1 SSE4.2 AVX AVX2 FMA
</code></pre>
<p>And not something like this:</p>
<pre><code>2019-11-28 09:18:26.315191: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
</code></pre>
<p>One way to achieve this is to install TensorFlow with Conda instead of Pip.</p>
<p>Here is more information about that:
<a href=""https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide"">https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide</a></p>
<p>If you're on a Mac and the Conda-TensorFlow crashes with an OMP error, here's the solution: <a href=""https://stackoverflow.com/a/53692707/5091738"">https://stackoverflow.com/a/53692707/5091738</a></p>
</body></html>",rmoehn,rmoehn,rmoehn,
XMMMnLP8LY65cwpnN,Getting Ready for the FB Donation Match,getting-ready-for-the-fb-donation-match,https://www.lesswrong.com/posts/XMMMnLP8LY65cwpnN/getting-ready-for-the-fb-donation-match,2019-11-27T19:20:02.156Z,10,5,4,False,False,,"<p>

Facebook is again going to be 

<a href=""https://www.facebook.com/help/332488213787105"">matching
donations on Giving Tuesday</a>:



</p><p>

</p>

<ul>
<li>$7M total</li>
<li>$20k max per donor</li>
<li>$100k max per organization</li>
<li>First-come first-served</li>
<li>Processing fees covered by FB</li>
<li>8AM Eastern, Tuesday 12/3</li>
</ul>



<p>

I <a href=""https://www.jefftk.com/p/facebook-donation-match"">participated last year</a>, and
while the match ran out in seconds I was able to direct the full <a href=""https://www.jefftk.com/p/what-should-counterfactual-donation-mean"">counterfactual</a>
$20k by being (a) prepared and (b) lucky not to get any declines.  As
with last year, I'm planning to donate more than $20k across several
cards, so even if I get declines this year I'll still have a good
chance of getting my donation matched.

</p>

<p>



There are good instructions on the <a href=""https://www.eagivingtuesday.org/"">EA Giving Tuesday</a> site.
One way things are different this year is that by confirming your
identity ahead of time you can get FB to raise your per-donation
limit.  This means instead of twelve $2,499 transactions I'm planning
to do three $9,999 ones.

</p>

<p>

I did one test $2,501 donation a few days ago to verify that
confirming my identity worked, and three $9,999 donations yesterday to
check if I got declines and practice.  My guess is that this year the
donation amount runs out in 1-2s, which means there's probably only
time for one $9,999 donation before the $7M is gone.  Very curious how
it goes though!

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100124060698202"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
NSCBF7MTLF2HdhEnD,"[AN #75]: Solving Atari and Go with learned game models, and thoughts from a MIRI employee",an-75-solving-atari-and-go-with-learned-game-models-and,https://www.lesswrong.com/posts/NSCBF7MTLF2HdhEnD/an-75-solving-atari-and-go-with-learned-game-models-and,2019-11-27T18:10:01.332Z,38,11,1,False,False,,"<p>Find all Alignment Newsletter resources <u><a href=""http://rohinshah.com/alignment-newsletter/"">here</a></u>. In particular, you can <u><a href=""http://eepurl.com/dqMSZj"">sign up</a></u>, or look through this <u><a href=""https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing"">spreadsheet</a></u> of all summaries that have ever been in the newsletter. I&apos;m always happy to hear feedback; you can send it to me by replying to this email.</p><p>Audio version <u><a href=""http://alignment-newsletter.libsyn.com/alignment-newsletter-75"">here</a></u> (may not be up yet).</p><h2><strong>Highlights</strong></h2><p><u><a href=""https://arxiv.org/abs/1911.08265"">Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model</a></u> <em>(Julian Schrittwieser et al)</em> (summarized by Nicholas): Up until now, model-free RL approaches have been state of the art at visually rich domains such as Atari, while model-based RL has excelled for games which require planning many steps ahead, such as Go, chess, and shogi. This paper attains state of the art performance on Atari using a model-based approach, <em>MuZero</em>, while matching <u><a href=""https://deepmind.com/blog/alphazero-shedding-new-light-grand-games-chess-shogi-and-go/"">AlphaZero</a></u> (<u><a href=""https://mailchi.mp/6751e45fbb48/alignment-newsletter-36"">AN #36</a></u>) at Go, chess, and shogi while using less compute. Importantly, it does this without requiring any advance knowledge of the rules of the game.</p><p><em>MuZero</em>&apos;s model has three components:</p><p>1. The <em>representation</em> function produces an initial internal state from all existing observations.</p><p>2. The <em>dynamics</em> function predicts the next internal state and immediate reward after taking an action in a given internal state.</p><p>3. The <em>prediction</em> function generates a policy and a value prediction from an internal state.</p><p>Although these are based on the structure of an MDP, <strong>the internal states of the model do not necessarily have any human-interpretable meaning</strong>. They are trained end-to-end only to accurately predict the policy, value function, and immediate reward. This model is then used to simulate trajectories for use in MCTS.</p><p><strong>Nicholas&apos;s opinion:</strong> This is clearly a major step for model-based RL, becoming the state of the art on a very popular benchmark and enabling planning approaches to be used in domains with unknown rules or dynamics. I am typically optimistic about model-based approaches as progress towards safe AGI. They map well to how humans think about most complex tasks: we consider the likely outcomes of our actions and then plan accordingly. Additionally, model-based RL typically has the safety property that the programmers know what states the algorithm expects to pass through and end up in, which aids with interpretability and auditing. However, <em>MuZero</em> loses that property by using a learned model whose internal states are not constrained to have any semantic meaning. I would be quite excited to see follow up work that enables us to understand what the model components are learning and how to audit them for particularly bad inaccuracies.</p><p><strong>Rohin&apos;s opinion:</strong> <em>Note: This is more speculative than usual.</em> This approach seems really obvious and useful in hindsight (something I last felt for <u><a href=""https://deepmind.com/blog/article/population-based-training-neural-networks"">population-based training</a></u> of hyperparameters). The main performance benefit (that I see) of model-based planning is that it only needs to use the environment interactions to learn how the environment <em>works</em>, rather than how to <em>act optimally</em> in the environment -- it can do the &quot;act optimally&quot; part using some MDP planning algorithm, or by simulating trajectories from the world model rather than requiring the actual environment. Intuitively, it should be significantly easier to learn how an environment works -- consider how easy it is for us to learn the rules of a game, as opposed to playing it well. However, most model-based approaches force the learned model to learn features that are useful for predicting the state, which may not be the ones that are useful for playing well, which can handicap their final performance. Model-free approaches on the other hand learn exactly the features that are needed for playing well -- but they have a much harder learning task, so it takes many more samples to learn, but can lead to better final performance. Ideally, we would like to get the benefits of using an MDP planning algorithm, while still only requiring the agent to learn features that are useful for acting optimally.</p><p>This is exactly what MuZero does, similarly to <u><a href=""https://arxiv.org/abs/1707.03497"">this previous paper</a></u>: its &quot;model&quot; only predicts actions, rewards, and value functions, all of which are much more clearly relevant to acting optimally. However, the tasks that are learned from environment interactions are in some sense &quot;easier&quot; -- the model only needs to predict, <em>given a sequence of actions</em>, what the immediate reward will be. It notably <em>doesn&apos;t</em> need to do a great job of predicting how an action now will affect things ten turns from now, as long as it can predict how things ten turns from now will be <em>given</em> the ten actions used to get there. Of course, the model does need to predict the policy and the value function (both hard and dependent on the future), but the learning signal for this comes from MCTS, whereas model-free RL relies on credit assignment for this purpose. Since MCTS can consider multiple possible future scenarios, while credit assignment only gets to see the trajectory that was actually rolled out, we should expect that MCTS leads to significantly better gradients and faster learning.</p><p><u><a href=""https://forum.effectivealtruism.org/posts/tDk57GhrdK54TWzPY/i-m-buck-shlegeris-i-do-research-and-outreach-at-miri-ama"">I&apos;m Buck Shlegeris, I do research and outreach at MIRI, AMA</a></u> <em>(Buck Shlegeris)</em> (summarized by Rohin): Here are some beliefs that Buck reported that I think are particularly interesting (selected for relevance to AI safety):</p><p>1. He would probably not work on AI safety if he thought there was less than 30% chance of AGI within 50 years.</p><p>2. The ideas in <u><a href=""https://arxiv.org/abs/1906.01820"">Risks from Learned Optimization</a></u> (<u><a href=""https://mailchi.mp/92b3a9458c2d/an-58-mesa-optimization-what-it-is-and-why-we-should-care"">AN #58</a></u>) are extremely important.</p><p>3. If we build &quot;business-as-usual ML&quot;, there will be inner alignment failures, which can&apos;t easily be fixed. In addition, the ML systems&apos; goals may accidentally change as they self-improve, obviating any guarantees we had. The only way to solve this is to have a clearer picture of what we&apos;re doing when building these systems. <em>(This was a response to a question about the motivation for MIRI&apos;s research agenda, and so may not reflect his actual beliefs, but just his beliefs about MIRI&apos;s beliefs.)</em></p><p>4. Different people who work on AI alignment have radically different pictures of what the development of AI will look like, what the alignment problem is, and what solutions might look like.</p><p>5. Skilled and experienced AI safety researchers seem to have a much more holistic and much more concrete mindset: they consider a solution to be composed of many parts that solve subproblems that can be put together with different relative strengths, as opposed to searching for a single overall story for everything.</p><p>6. External criticism seems relatively unimportant in AI safety, where there isn&apos;t an established research community that has already figured out what kinds of arguments are most important.</p><p><strong>Rohin&apos;s opinion:</strong> I strongly agree with 2 and 4, weakly agree with 1, 5, and 6, and disagree with 3.</p><h1><strong>Technical AI alignment</strong></h1><h3><strong>Problems</strong></h3><p><u><a href=""https://www.alignmentforum.org/posts/vXzM5L6njDZSf4Ftk/defining-ai-wireheading"">Defining AI wireheading</a></u> <em>(Stuart Armstrong)</em> (summarized by Rohin): This post points out that &quot;wireheading&quot; is a fuzzy category. Consider a weather-controlling AI tasked with increasing atmospheric pressure, as measured by the world&apos;s barometers. If it made a tiny dome around each barometer and increased air pressure within the domes, we would call it wireheading. However, if we increase the size of the domes until it&apos;s a dome around the entire Earth, then it starts sounding like a perfectly reasonable way to optimize the reward function. Somewhere in the middle, it must have become unclear whether or not it was wireheading. The post suggests that wireheading can be defined as a subset of <u><a href=""https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/"">specification gaming</a></u> (<u><a href=""https://mailchi.mp/ff6340049bd0/alignment-newsletter-1"">AN #1</a></u>), where the &quot;gaming&quot; happens by focusing on some narrow measurement channel, and the fuzziness comes from what counts as a &quot;narrow measurement channel&quot;.</p><p><strong>Rohin&apos;s opinion:</strong> You may have noticed that this newsletter doesn&apos;t talk about wireheading very much; this is one of the reasons why. It seems like wireheading is a fuzzy subset of specification gaming, and is not particularly likely to be the only kind of specification gaming that could lead to catastrophe. I&apos;d be surprised if we found some sort of solution where we&apos;d say &quot;this solves all of wireheading, but it doesn&apos;t solve specification gaming&quot; -- there don&apos;t seem to be particular distinguishing features that would allow us to have a solution to wireheading but not specification gaming. There can of course be solutions to particular kinds of wireheading that <em>do</em> have clear distinguishing features, such as <u><a href=""https://medium.com/@deepmindsafetyresearch/designing-agent-incentives-to-avoid-reward-tampering-4380c1bb6cd"">reward tampering</a></u> (<u><a href=""https://mailchi.mp/938a7eed18c3/an-71avoiding-reward-tampering-through-current-rf-optimization"">AN #71</a></u>), but I don&apos;t usually expect these to be the major sources of AI risk.</p><h3><strong>Technical agendas and prioritization</strong></h3><p><u><a href=""https://www.alignmentforum.org/posts/W95gbuognJu5WxkTW/the-value-definition-problem"">The Value Definition Problem</a></u> <em>(Sammy Martin)</em> (summarized by Rohin): This post considers the Value Definition Problem: what should we make our AI system <u><a href=""https://www.alignmentforum.org/posts/ZeE7EKHTFMBs8eMxn/clarifying-ai-alignment"">try to do</a></u> (<u><a href=""https://mailchi.mp/b6dc636f6a1b/alignment-newsletter-33"">AN #33</a></u>) to have the best chance of a positive outcome? It argues that an answer to the problem should be judged based on how much easier it makes alignment, how competent the AI system has to be to optimize it, and how good the outcome would be if it was optimized. Solutions also differ on how &quot;direct&quot; they are -- on one end, explicitly writing down a utility function would be very direct, while on the other, something like <u><a href=""https://intelligence.org/files/CEV.pdf"">Coherent Extrapolated Volition</a></u> would be very indirect: it delegates the task of figuring out what is good to the AI system itself.</p><p><strong>Rohin&apos;s opinion:</strong> I fall more on the side of preferring indirect approaches, though by that I mean that we should delegate to future humans, as opposed to defining some particular value-finding mechanism into an AI system that eventually produces a definition of values.</p><h3><strong>Miscellaneous (Alignment)</strong></h3><p><u><a href=""https://www.alignmentforum.org/posts/yArZKCEheZt8GkK6p/self-fulfilling-prophecies-aren-t-always-about-self"">Self-Fulfilling Prophecies Aren&apos;t Always About Self-Awareness</a></u> <em>(John Maxwell)</em> (summarized by Rohin): Could we prevent a superintelligent oracle from making self-fulfilling prophecies by preventing it from modeling itself? This post presents three scenarios in which self-fulfilling prophecies would still occur. For example, if instead of modeling itself, it models the fact that there&apos;s some AI system whose predictions frequently come true, it may try to predict what that AI system would say, and then say that. This would lead to self-fulfilling prophecies.</p><p><u><a href=""https://www.alignmentforum.org/posts/6WbLRLdmTL4JxxvCq/analysing-dangerous-messages-from-future-ufai-via-oracles"">Analysing: Dangerous messages from future UFAI via Oracles</a></u> and <u><a href=""https://www.alignmentforum.org/posts/42z4k8Co5BuHMBvER/breaking-oracles-hyperrationality-and-acausal-trade"">Breaking Oracles: hyperrationality and acausal trade</a></u> <em>(Stuart Armstrong)</em> (summarized by Rohin): These posts point out a problem with <u><a href=""https://www.alignmentforum.org/posts/wJ3AqNPM7W4nfY5Bk/self-confirming-prophecies-and-simplified-oracle-designs"">counterfactual oracles</a></u> (<u><a href=""https://mailchi.mp/b342d1a1bd06/an-59-how-arguments-for-ai-risk-have-changed-over-time"">AN #59</a></u>): a future misaligned agential AI system could commit to helping the oracle (e.g. by giving it maximal reward, or making its predictions come true) even in the event of an erasure, as long as the oracle makes predictions that cause humans to build the agential AI system. Alternatively, multiple oracles could acausally cooperate with each other to build an agential AI system that will reward all oracles.</p><h1><strong>AI strategy and policy</strong></h1><p><u><a href=""https://futureoflife.org/2019/11/15/machine-ethics-and-ai-governance-with-wendell-wallach/"">AI Alignment Podcast: Machine Ethics and AI Governance</a></u> <em>(Lucas Perry and Wendell Wallach)</em> (summarized by Rohin): Machine ethics has aimed to figure out how to embed ethical reasoning in automated systems of today. In contrast, AI alignment starts from an assumption of intelligence, and then asks how to make the system behave well. Wendell expects that we will have to go through stages of development where we figure out how to embed moral reasoning in less intelligent systems before we can solve AI alignment.</p><p>Generally in governance, there&apos;s a problem that technologies are easy to regulate early on, but that&apos;s when we don&apos;t know what regulations would be good. Governance has become harder now, because it has become very crowded: there are more than 53 lists of principles for artificial intelligence and lots of proposed regulations and laws. One potential mitigation would be <strong>governance coordinating committees</strong>: a sort of issues manager that keeps track of a field, maps the issues and gaps, and figures out how they could be addressed.</p><p>In the intermediate term, the worry is that AI systems are giving increasing power to those who want to manipulate human behavior. In addition, job loss is a real issue. One possibility is that we could tax corporations relative to how many workers they laid off and how many jobs they created.</p><p>Thinking about AGI, governments should probably not be involved now (besides perhaps funding some of the research), since we have so little clarity on what the problem is and what needs to be done. We do need people monitoring risks, but there&#x2019;s a pretty robust existing community doing this, so government doesn&apos;t need to be involved.</p><p><strong>Rohin&apos;s opinion:</strong> I disagree with Wendell that current machine ethics will be necessary for AI alignment -- that might be the case, but it seems like things change significantly once our AI systems are smart enough to actually understand our moral systems, so that we no longer need to design special procedures to embed ethical reasoning in the AI system.</p><p>It does seem useful to have coordination on governance, along the lines of governance coordinating committees; it seems a lot better if there&apos;s only one or two groups that we need to convince of the importance of an issue, rather than 53 (!!).</p><h1><strong>Other progress in AI</strong></h1><h3><strong>Reinforcement learning</strong></h3><p><u><a href=""https://learningtopredict.github.io/"">Learning to Predict Without Looking Ahead: World Models Without Forward Prediction</a></u> <em>(C. Daniel Freeman et al)</em> (summarized by Sudhanshu): One <u><a href=""https://twitter.com/shimon8282/status/979344417961250817"">critique</a></u> of the <u><a href=""http://arxiv.org/abs/1809.01999"">World Models</a></u> (<u><a href=""https://mailchi.mp/9295c961b39b/alignment-newsletter-23"">AN #23</a></u>) paper was that in any realistic setting, you only want to learn the features that are important for the task under consideration, while the VAE used in the paper would learn features for state reconstruction. This paper instead studies world models that are trained directly from reward, rather than by supervised learning on observed future states, which should lead to models that only focus on task-relevant features. Specifically, they use <em>observational dropout</em> on the environment percepts, where the true state is passed to the policy with a peek probability <em>p</em>, while a neural network, <strong>M</strong>, generates a proxy state with probability <em>1 - p</em>. At the next time-step, <strong>M</strong>  takes the same input as the policy, plus the policy&apos;s action, and generates the next proxy state, which then may get passed to the controller, again with probability <em>1 - p</em>.</p><p>They investigate whether the emergent &apos;world model&apos; <strong>M</strong> behaves like a good forward predictive model. They find that even with very low peek probability e.g. <em>p</em> = 5%, <strong>M</strong> learns a good enough world model that enables the policy to perform reasonably well. Additionally, they find that world models thus learned can be used to train policies that sometimes transfer well to the real environment. They claim that the world model only learns features that are useful for task performance, but also note that interpretability of those features depends on inductive biases such as the network architecture.</p><p><strong>Sudhanshu&apos;s opinion:</strong> This work warrants a visit for the easy-to-absorb animations and charts. On the other hand, they make a few innocent-sounding observations that made me uncomfortable because they weren&apos;t rigourously proved nor labelled as speculation, e.g. a) &quot;At higher peek probabilities, the learned dynamics model is not needed to solve the task thus is never learned.&quot;, and b) &quot;Here, the world model clearly only learns reliable transition maps for moving down and to the right, which is sufficient.&quot;</p><p>While this is a neat bit of work well presented, it is nevertheless still unlikely this (and most other current work in deep model-based RL) will scale to more complex alignment problems such as <u><a href=""https://www.alignmentforum.org/posts/efWfvrWLgJmbBAs3m/embedded-world-models"">Embedded World-Models</a></u> (<u><a href=""https://mailchi.mp/7d0e3916e3d9/alignment-newsletter-31"">AN #31</a></u>); these world models do not capture the notion of an agent, and do not model the agent as an entity making long-horizon plans in the environment.</p><h3><strong>Deep learning</strong></h3><p><u><a href=""http://arxiv.org/abs/1905.12149"">SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver</a></u> <em>(Po-Wei Wang et al)</em> (summarized by Asya): Historically, deep learning architectures have struggled with problems that involve logical reasoning, since they often impose non-local constraints that gradient descent has a hard time learning. This paper presents a new technique, SATNet, which allows neural nets to solve logical reasoning problems by encoding them explicitly as MAXSAT-solving neural network layers. A MAXSAT problem provides a large set of logical constraints on an exponentially large set of options, and the goal is to find the option that satisfies as many logical constraints as possible. Since MaxSAT is NP-complete, the authors design a layer that solves a relaxation of the MaxSAT problem in its forward pass (that can be solved quickly, unlike MaxSAT), while the backward pass computes gradients as usual.</p><p>In experiment, SATNet is given bit representations of 9,000 9 x 9 Sudoku boards which it uses to learn the logical constraints of Sudoku, then presented with 1,000 test boards to solve. SATNet vastly outperforms traditional convolutional neural networks given the same training / test setup, achieving 98.3% test accuracy where the convolutional net achieves 0%. It performs similarly well on a &quot;Visual&quot; Sudoku problem where the trained network consists of initial layers that perform digit recognition followed by SATNet layers, achieving 63.2% accuracy where the convolutional net achieves 0.1%.</p><p><strong>Asya&apos;s opinion:</strong> My impression is this is a big step forward in being able to embed logical reasoning in current deep learning techniques. From an engineering perspective, it seems extremely useful to be able to train systems that encorporate these layers end-to-end. It&apos;s worth being clear that in systems like these, a lot of generality is lost since part of the network is explicitly carved out for solving a particular problem of logical constraints-- it would be hard to use the same network to learn a different problem.</p><h1><strong>News</strong></h1><p><u><a href=""https://aisafetyunconference.info/"">AI Safety Unconference 2019</a></u> <em>(David Krueger, Orpheus Lummis, and Gretchen Krueger)</em> (summarized by Rohin): Like last year, there will be an AI safety unconference alongside NeurIPS, on Monday Dec 9 from 10am to 6pm. While the website suggests a registration deadline of Nov 25, the organizers have told me it&apos;s a soft deadline, but you probably should <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLSfOXyo2P0Wv6bxyNyzzdMnzSL8_wGa4pMIDTh1tQwYeZmMebw/viewform"">register</a></u> now to secure a place.</p>",rohinmshah,rohinmshah,Rohin Shah,
JJFphYfMsdFMuprBy,Mental Mountains,mental-mountains,https://www.lesswrong.com/posts/JJFphYfMsdFMuprBy/mental-mountains,2019-11-27T05:30:02.107Z,160,76,14,False,False,,"<p><b>I.</b></p>
<p>Kaj Sotala has <a href=""https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain"">an outstanding review</a> of <a href=""https://www.amazon.com/Unlocking-Emotional-Brain-Eliminating-Reconsolidation/dp/0415897173/ref=as_li_ss_tl?crid=SHAZ1QSYKIU8&amp;keywords=unlocking+the+emotional+brain&amp;qid=1574533717&amp;sprefix=unlocking+the+emotional,aps,201&amp;sr=8-1&amp;linkCode=ll1&amp;tag=slatestarcode-20&amp;linkId=74c052b098c30c20d9761e30973122ba&amp;language=en_US""><i>Unlocking The Emotional Brain</i></a>; I read the book, and Kaj’s review is better. </p>
<p>He begins:</p>
<blockquote><p>UtEB’s premise is that much if not most of our behavior is driven by emotional learning. Intense emotions generate unconscious predictive models of how the world functions and what caused those emotions to occur. The brain then uses those models to guide our future behavior. Emotional issues and seemingly irrational behaviors are generated from implicit world-models (schemas) which have been formed in response to various external challenges. Each schema contains memories relating to times when the challenge has been encountered and mental structures describing both the problem and a solution to it.</p></blockquote>
<p>So in one of the book’s example cases, a man named Richard sought help for trouble speaking up at work. He would have good ideas during meetings, but felt inexplicably afraid to voice them. During therapy, he described his narcissistic father, who was always mouthing off about everything. Everyone hated his father for being a fool who wouldn’t shut up. The therapist conjectured that young Richard observed this and formed a predictive model, something like “talking makes people hate you”. This was overly general: talking only makes people hate you if you talk incessantly about really stupid things. But when you’re a kid you don’t have much data, so you end up generalizing a lot from the few examples you have.</p>
<p>When Richard started therapy, he didn’t consciously understand any of this. He just felt emotions (anxiety) at the thought of voicing his opinion. The predictive model output the anxiety, using reasoning like “if you talk, people will hate you, and the prospect of being hated should make you anxious – therefore, anxiety”, but not any of the intermediate steps. The therapist helped Richard tease out the underlying model, and at the end of the session Richard agreed that his symptoms were related to his experience of his father. But knowing this changed nothing; Richard felt as anxious as ever. </p>
<p>Predictions like “speaking up leads to being hated” are special kinds of emotional memory. You can rationally understand that the prediction is no longer useful, but that doesn’t really help; the emotional memory is still there, guiding your unconscious predictions. What should the therapist do?</p>
<p>Here <i>UtEB</i> dives into the science on memory reconsolidation. </p>
<p>Scientists have known for a while that giving rats the protein synthesis inhibitor anisomycin prevents them from forming emotional memories. You can usually give a rat noise-phobia by pairing a certain noise with electric shocks, but this doesn’t work if the rats are on anisomycin first. Probably this means that some kind of protein synthesis is involved in memory. So far, so plausible.</p>
<p><a href=""https://sci-hub.tw/10.1038/35021052"">A 2000 study</a> found that anisomycin could also erase existing phobias in a very specific situation. You had to “activate” the phobia – get the rats thinking about it really hard, maybe by playing the scary noise all the time – and then give them the anisomycin. This suggested that when the memory got activated, it somehow “came loose”, and the brain needed to do some protein synthesis to put it back together again.</p>
<p>Thus the idea of memory reconsolidation: you form a consolidated memory, but every time you activate it, you need to reconsolidate it. If the reconsolidation fails, you lose the memory, or you get a slightly different memory, or something like that. If you could disrupt emotional memories like “speaking out makes you hated” while they’re still reconsolidating, maybe you could do something about this.</p>
<p>Anisomycin is pretty toxic, so that’s out. Other protein synthesis inhibitors are also toxic – it turns out proteins are kind of important for life – so they’re out too. Electroconvulsive therapy <a href=""https://journals.lww.com/ectjournal/Citation/2019/06000/ECT_as_a_Novel_Treatment_for_PTSD.23.aspx"">actually seems to work pretty well for this</a> – the shock disrupts protein formation very effectively (and the more I think about this, the more implications it seems to have). But we can’t do ECT on everybody who wants to be able to speak up at work more, so that’s also out. And the simplest solution – activating a memory and then reminding the patient that they don’t rationally believe it’s true – doesn’t seem to help; the emotional brain doesn’t speak Rationalese. </p>
<p>The authors of <i>UtEB</i> claim to have found a therapy-based method that works, which goes like this:</p>
<p>First, they tease out the exact predictive model and emotional memory behind the symptom (in Richard’s case, the narrative where his father talked too much and ended up universally hated, and so if Richard talks at all, he too will be universally hated). Then they try to get this as far into conscious awareness as possible (or, if you prefer, have consciousness dig as deep into the emotional schema as possible). They call this “the pro-symptom position” – giving the symptom as much room as possible to state its case without rejecting it. So for example, Richard’s therapist tried to get Richard to explain his unconscious pro-symptom reasoning as convincingly as possible: “My father was really into talking, and everybody hated him. This proves that if I speak up at work, people will hate me too.” She even asked Richard to put this statement on an index card, review it every day, and bask in its compellingness. She asked Richard to imagine getting up to speak, and feeling exactly how anxious it made him, while reviewing to himself that the anxiety felt justified given what happened with his father. The goal was to establish a wide, well-trod road from consciousness to the emotional memory.</p>
<p>Next, they try to find <i>a lived and felt experience</i> that contradicts the model. Again, Rationalese doesn’t work; the emotional brain will just ignore it. But it will listen to experiences. For Richard, this was a time when he was at a meeting, had a great idea, but didn’t speak up. A coworker had the same idea, mentioned it, and everyone agreed it was great, and congratulated the other person for having such an amazing idea that would transform their business. Again, there’s this same process of trying to get as much in that moment as possible, bring the relevant feelings back again and again, create as wide and smooth a road from consciousness to the experience as possible.</p>
<p>Finally, the therapist activates the disruptive emotional schema, and before it can reconsolidate, smashes it into the new experience. So Richard’s therapist makes use of the big wide road Richard built that let him fully experience his fear of speaking up, and asks Richard to get into that frame of mind (activate the fear-of-speaking schema). Then she asks him, <i>while keeping the fear-of-speaking schema in mind</i>, to remember the contradictory experience (coworker speaks up and is praised). Then the therapist vividly describes the juxtaposition while Richard tries to hold both in his mind at once.</p>
<p>And then Richard was instantly cured, and never had any problems speaking up at work again. His coworkers all applauded, and became psychotherapists that very day. An eagle named “Psychodynamic Approach” flew into the clinic and perched atop the APA logo and shed a single tear. <i>Coherence Therapy: Practice Manual And Training Guide</i> was read several times, and God Himself showed up and enacted PsyD prescribing across the country. All the cognitive-behavioralists died of schizophrenia and were thrown in the lake of fire for all eternity.</p>
<p>This is, after all, <a href=""https://slatestarcodex.com/2019/11/20/book-review-all-therapy-books/"">a therapy book</a>.</p>
<p><b>II.</b></p>
<p>I like <i>UtEB</i> because it reframes <a href=""https://slatestarcodex.com/2019/11/20/book-review-all-therapy-books/"">historical/purposeful</a> accounts of symptoms as aspects of a predictive model. We already know the brain has an unconscious predictive model that it uses to figure out how to respond to various situations and which actions have which consequences. In retrospect, this framing perfectly fits the idea of traumatic experiences having outsized effects. Tack on a bit about how the model is more easily updated in childhood (because you’ve seen fewer other things, so your priors are weaker), and you’ve gone a lot of the way to traditional models of therapy.</p>
<p>But I also like it because it helps me think about the idea of separation/noncoherence in the brain. Richard had his schema about how speaking up makes people hate you. He also had lots of evidence that this wasn’t true, both rationally (his understanding that his symptoms were counterproductive) and experientially (his story about a coworker proposing an idea and being accepted). But the evidence failed to naturally propagate; it didn’t connect to the schema that it should have updated. Only after the therapist forced the connection did the information go through. Again, all of this should have been obvious – of course evidence doesn’t propagate through the brain, I was writing <a href=""https://webcache.googleusercontent.com/search?q=cache:Q77NHwG_HAMJ:https://www.lesswrong.com/posts/mja6jZ6k9gAwki9Nu/the-mystery-of-the-haunted-rationalist+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us&amp;client=firefox-b-1-d"">posts</a> ten years ago about how even a person who knows ghosts exist will be afraid to stay in an old supposedly-haunted mansion at night with the lights off. But UtEB’s framework helps snap some of this into place.</p>
<p>UtEB’s brain is a mountainous landscape, with fertile valleys separated by towering peaks. Some memories (or pieces of your predictive model, or whatever) live in each valley. But they can’t talk to each other. The passes are narrow and treacherous. They go on believing their own thing, unconstrained by conclusions reached elsewhere.</p>
<p>Consciousness is a capital city on a wide plain. When it needs the information stored in a particular valley, it sends messengers over the passes. These messengers are good enough, but they carry letters, not weighty tomes. Their bandwidth is atrocious; often they can only convey what the valley-dwellers think, and not why. And if a valley gets something wrong, lapses into heresy, as often as not the messengers can’t bring the kind of information that might change their mind.</p>
<p>Links between the capital and the valleys may be tenuous, but valley-to-valley trade is almost non-existent. You can have two valleys full of people working on the same problem, for years, and they will basically never talk.</p>
<p>Sometimes, when it’s very important, the king can order a road built. The passes get cleared out, high-bandwidth communication to a particular communication becomes possible. If he does this to two valleys at once, then they may even be able to share notes directly, each passing through the capital to get to each other. But it isn’t the norm. You have to really be trying.</p>
<p>This ended out a little more flowery than I expected, but I didn’t start thinking this way because it was poetic. I started thinking this way because of this:</p>
<p><img src=""https://slatestarcodex.com/blog_images/rebus_landscape.png"" /></p>
<p>Frequent SSC readers will recognize this as from Figure 1 of Friston and Carhart-Harris’ <a href=""http://pharmrev.aspetjournals.org/content/71/3/316?fbclid=IwAR36UzFla5Lfx7-4LTr6R8N0XdUSOnbg3gnRPXn806cPKO7Zsas2EsJJhDs"">REBUS And The Anarchic Brain: Toward A Unified Model Of The Brain Action Of Psychedelics</a>, which I review <a href=""https://slatestarcodex.com/2019/09/10/ssc-journal-club-relaxed-beliefs-under-psychedelics-and-the-anarchic-brain/"">here</a>. The paper describes it as “the curvature of the free-energy landscape that contains neuronal dynamics. Effectively, this can be thought of as a flattening of local minima, enabling neuronal dynamics to escape their basins of attraction and—when in flat minima—express long-range correlations and desynchronized activity.”</p>
<p>Moving back a step: the paper is trying to explain what psychedelics do to the brain. It theorizes that they weaken high-level priors (in this case, you can think of these as the tendency to fit everything to an existing narrative), allowing things to be seen more as they are:</p>
<blockquote><p>A corollary of relaxing high-level priors or beliefs under psychedelics is that ascending prediction errors from lower levels of the system (that are ordinarily unable to update beliefs due to the top-down suppressive influence of heavily-weighted priors) can find freer register in conscious experience, by reaching and impressing on higher levels of the hierarchy. In this work, we propose that this straightforward model can account for the full breadth of subjective phenomena associated with the psychedelic experience.</p></blockquote>
<p>These ascending prediction errors (ie noticing that you’re wrong about something) can then correct the high-level priors (ie change the narratives you tell about your life):</p>
<blockquote><p>The ideal result of the process of belief relaxation and revision is a recalibration of the relevant beliefs so that they may better align or harmonize with other levels of the system and with bottom-up information—whether originating from within (e.g., via lower-level intrinsic systems and related interoception) or, at lower doses, outside the individual (i.e., via sensory input or extroception). Such functional harmony or realignment may look like a system better able to guide thought and behavior in an open, unguarded way (Watts et al., 2017; Carhart-Harris et al., 2018b).</p></blockquote>
<p>This makes psychedelics a potent tool for psychotherapy:</p>
<blockquote><p>Consistent with the model presented in this work, overweighted high-level priors can be all consuming, exerting excessive influence throughout the mind and brain’s (deep) hierarchy. The negative cognitive bias in depression is a good example of this (Beck, 1972), as are fixed delusions in psychosis (Sterzer et al., 2018).25 In this paper, we propose that psychedelics can be therapeutically effective, precisely because they target the high levels of the brain’s functional hierarchy, primarily affecting the precision weighting of high-level priors or beliefs. More specifically, we propose that psychedelics dose-dependently relax the precision weighting of high-level priors (instantiated by high-level cortex), and in so doing, open them up to an upsurge of previously suppressed bottom-up signaling (e.g., stemming from limbic circuitry). We further propose that this sensitization of high-level priors means that more information can impress on them, potentially inspiring shifts in perspective, felt as insight. One might ask whether relaxation followed by revision of high-level priors or beliefs via psychedelic therapy is easy to see with functional (and anatomic) brain imaging. We presume that it must be detectable, if the right questions are asked in the right way.</p></blockquote>
<p>Am I imagining this, or are Friston + Carhart-Harris and <i>Unlocking The Emotional Brain</i> getting at the same thing?</p>
<p>Both start with a piece of a predictive model (= high-level prior) telling you something that doesn’t fit the current situation. Both also assume you have enough evidence to convince a rational person that the high-level prior is wrong, or doesn’t apply. But you don’t automatically smash the prior and the evidence together and perform an update. In <i>UtEB</i>‘s model, the update doesn’t happen until you forge conscious links to both pieces of information and try to hold them in consciousness at the same time. In F+CH’s model, the update doesn’t happen until you take psychedelics which make the high-level prior lose some of its convincingness. <i>UtEB</i> is trying to laboriously build roads through mountains; F+CH are trying to cast a magic spell that makes the mountains temporarily vanish. Either way, you get communication between areas that couldn’t communicate before.</p>
<p><b>III.</b></p>
<p>Why would mental mountains exist? If we keep trying to get rid of them, through therapy or psychedelics, or whatever, then why not just avoid them in the first place?</p>
<p>Maybe generalization is just hard (thanks to MC for this idea). Suppose Goofus is mean to you. You learn Goofus is mean; if this is your first social experience, maybe you also learn that the world is mean and people have it out for you. Then one day you meet Gallant, who is nice to you. Hopefully the system generalizes to “Gallant is nice, Goofus is still mean, people in general can go either way”.</p>
<p>But suppose one time Gallant is just having a terrible day, and curses at you, and that time he happens to be wearing a red shirt. You don’t want to overfit and conclude “Gallant wearing a red shirt is mean, Gallant wearing a blue shirt is nice”. You want to conclude “Gallant is generally nice, but sometimes slips and is mean.”</p>
<p>But any algorithm that gets too good at resisting the temptation to separate out red-shirt-Gallant and blue-shirt-Gallant risks falling into the opposite failure mode where it doesn’t separate out Gallant and Goofus. It would just average them out, and conclude that people (including both Goofus and Gallant) are medium-niceness.</p>
<p>And suppose Gallant has brown eyes, and Goofus green eyes. You don’t want your algorithm to overgeneralize to “all brown-eyed people are nice, and all green-eyed people are mean”. But suppose the Huns attack you. You <i>do</i> want to generalize to “All Huns are dangerous, even though I can keep treating non-Huns as generally safe”. And you want to do this as quickly as possible, definitely before you meet any more Huns. And the quicker you are to generalize about Huns, the more likely you are to attribute false significance to Gallant’s eye color.</p>
<p>The end result is a predictive model which is a giant mess, made up of constant “This space here generalizes from this example, except this subregion, which generalizes from this other example, except over here, where it doesn’t, and definitely don’t <i>ever</i> try to apply any of those examples over here.” Somehow this all works shockingly well. For example, I spent a few years in Japan, and developed a good model for how to behave in Japanese culture. When I came back to the United States, I effortlessly dropped all of that and went back to having America-appropriate predictions and reflexive actions (except for an embarrassing habit of bowing whenever someone hands me an object, which I still haven’t totally eradicated). </p>
<p>In this model, mental mountains are just the context-dependence that tells me not to use my Japanese predictive model in America, and which prevents evidence that makes me update my Japanese model (like “I notice subways are always on time”) from contaminating my American model as well. Or which prevent things I learn about Gallant (like “always trust him”) from also contaminating my model of Goofus.</p>
<p>There’s actually a real-world equivalent of the “red-shirt-Gallant is bad, blue-shirt-Gallant is good” failure mode. It’s called <a href=""https://en.wikipedia.org/wiki/Splitting_(psychology)"">“splitting”</a>, and you can find it in any psychology textbook. Wikipedia defines it as “the failure in a person’s thinking to bring together the dichotomy of both positive and negative qualities of the self and others into a cohesive, realistic whole.”</p>
<p>In the classic example, a patient is in a mental hospital. He likes his doctor. He praises the doctor to all the other patients, says he’s going to nominate her for an award when he gets out.</p>
<p>Then the doctor offends the patient in some way – maybe refuses one of his requests. All of a sudden, the doctor is abusive, worse than Hitler, worse than Mengele. When he gets out he will report her to the authorities and sue her for everything she owns.</p>
<p>Then the doctor does something right, and it’s back to praise and love again.</p>
<p>The patient has failed to integrate his judgments about the doctor into a coherent whole, “doctor who sometimes does good things but other times does bad things”. It’s as if there’s two predictive models, one of Good Doctor and one of Bad Doctor, and even though both of them refer to the same real-world person, the patient can only use one at a time.</p>
<p>Splitting is most common in borderline personality disorder. The DSM criteria for borderline includes splitting (there defined as “a pattern of unstable and intense interpersonal relationships characterized by alternating between extremes of idealization and devaluation”). They also include things like “markedly and persistently unstable self-image or sense of self”, and “affective instability due to a marked reactivity of mood”, which seem relevant here too.</p>
<p>Some therapists view borderline as a disorder of integration. Nobody is great at having all their different schemas talk to each other, but borderlines are atrocious at it. Their mountains are so high that even different thoughts about the same doctor can’t necessarily talk to each other and coordinate on a coherent position. The capital only has enough messengers to talk to one valley at a time. If tribesmen from the Anger Valley are advising the capital today, the patient becomes truly angry, a kind of anger that utterly refuses to listen to any counterevidence, an anger pure beyond your imagination. If they are happy, they are <i>purely</i> happy, and so on.</p>
<p><a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2719457/"">About 70% of people</a> diagnosed with dissociative identity disorder (previously known as multiple personality disorder) have borderline personality disorder. The numbers are so high that <a href=""https://www.ncbi.nlm.nih.gov/pubmed/8348205/"">some researchers</a> are not even convinced that these are two different conditions; maybe DID is just one manifestation of borderline, or especially severe borderline. Considering borderline as a failure of integration, this makes sense; DID is total failure of integration. People in the furthest mountain valleys, frustrated by inability to communicate meaningfully with the capital, secede and set up their own alternative provincial government, pulling nearby valleys into their new coalition. I don’t want to overemphasize this; most popular perceptions of DID are overblown, and at least some cases seem to be at least partly iatrogenic. But if you are bad enough at integrating yourself, it seems to be the sort of thing that can happen.</p>
<p>In his review, Kaj relates this to Internal Family Systems, a weird form of therapy where you imagine your feelings as people/entities and have discussions with them. I’ve always been skeptical of this, because feelings are not, in fact, people/entities, and it’s unclear why you should expect them to answer you when you ask them questions. And in my attempts to self-test the therapy, indeed nobody responded to my questions and I was left feeling kind of silly. But Kaj says:</p>
<blockquote><p>As many readers know, I have been writing a sequence of posts on multi-agent models of mind. In Building up to an Internal Family Systems model, I suggested that the human mind might contain something like subagents which try to ensure that past catastrophes do not repeat. In subagents, coherence, and akrasia in humans, I suggested that behaviors such as procrastination, indecision, and seemingly inconsistent behavior result from different subagents having disagreements over what to do.</p>
<p>As I already mentioned, my post on integrating disagreeing subagents took the model in the direction of interpreting disagreeing subagents as conflicting beliefs or models within a person’s brain. Subagents, trauma and rationality further suggested that the appearance of drastically different personalities within a single person might result from unintegrated memory networks, which resist integration due to various traumatic experiences.</p>
<p>This post has discussed UtEB’s model of conflicting emotional schemas in a way which further equates “subagents” with beliefs – in this case, the various schemas seem closely related to what e.g. Internal Family Systems calls “parts”. In many situations, it is probably fair to say that this is what subagents are.</p></blockquote>
<p>This is a model I can get behind. My guess is that in different people, the degree to which mental mountains form a barrier will cause the disconnectedness of valleys to manifest as anything from “multiple personalities”, to IFS-findable “subagents”, to <i>UtEB</i>-style psychiatric symptoms, to “ordinary” beliefs that don’t cause overt problems but might not be very consistent with each other.</p>
<p><b>IV.</b></p>
<p>This last category forms the crucial problem of rationality.</p>
<p>One can imagine an alien species whose ability to find truth was a simple function of their education and IQ. Everyone who knows the right facts about the economy and is smart enough to put them together will agree on economic policy.</p>
<p>But we don’t work that way. Smart, well-educated people believe all kinds of things, even when they should know better. We call these people biased, a catch-all term meaning something that prevents them from having true beliefs they ought to be able to figure out. I believe most people who don’t believe in anthropogenic climate change are probably biased. Many of them are very smart. Many of them have read a lot on the subject (empirically, reading more about climate change will usually just make everyone <a href=""https://fivethirtyeight.com/features/media-bubbles-arent-the-biggest-reason-were-partisans/"">more convinced</a> of their current position, whatever it is). Many of them have enough evidence that they should know better. But they don’t.</p>
<p>(again, this is my opinion, sorry to those of you I’m offending. I’m sure you think the same of me. Please bear with me for the space of this example.) </p>
<p>Compare this to Richard, the example patient mentioned above. Richard had enough evidence to realize that companies don’t hate everyone who speaks up at meetings. But he still felt, on a deep level, like speaking up at meetings would get him in trouble. The evidence failed to connect to the emotional schema, the part of him that made the real decisions. Is this the same problem as the global warming case? Where there’s evidence, but it doesn’t connect to people’s real feelings?</p>
<p>(maybe not: Richard might be able to say “I know people won’t hate me for speaking, but for some reason I can’t make myself speak”, whereas I’ve never heard someone say “I know climate change is real, but for some reason I can’t make myself vote to prevent it.” I’m not sure how seriously to take this discrepancy.)</p>
<p>In <a href=""https://www.lesswrong.com/posts/BcYBfG8KomcpcxkEg/crisis-of-faith"">Crisis of Faith</a>, Eliezer Yudkowsky writes:</p>
<blockquote><p>Many in this world retain beliefs whose flaws a ten-year-old could point out, if that ten-year-old were hearing the beliefs for the first time. These are not subtle errors we’re talking about. They would be child’s play for an unattached mind to relinquish, if the skepticism of a ten-year-old were applied without evasion…we change our minds less often than we think.</p>
<p>This should scare you down to the marrow of your bones. It means you can be a world-class scientist and conversant with Bayesian mathematics and still fail to reject a belief whose absurdity a fresh-eyed ten-year-old could see. It shows the invincible defensive position which a belief can create for itself, if it has long festered in your mind.</p>
<p>What does it take to defeat an error that has built itself a fortress?</p></blockquote>
<p>He goes on to describe how hard this is, to discuss the “convulsive, wrenching effort to be rational” that he thinks this requires, the “all-out [war] against yourself”. Some of the techniques he mentions <a href=""https://www.lesswrong.com/rationality/you-can-face-reality"">explicitly come from psychotherapy</a>, <a href=""https://www.lesswrong.com/rationality/original-seeing"">others</a> seem to share a convergent evolution with it.</p>
<p>The authors of <i>UtEB</i> stress that all forms of therapy involve their process of reconsolidating emotional memories one way or another, whether they know it or not. Eliezer’s work on crisis of faith feels like an <i>ad hoc</i> form of epistemic therapy, one with a similar goal.</p>
<p>Here, too, there is a suggestive psychedelic connection. I can’t count how many stories I’ve heard along the lines of “I was in a bad relationship, I kept telling myself that it was okay and making excuses, and then I took LSD and realized that it obviously wasn’t, and got out.” Certainly many people change religions <a href=""https://www.vice.com/en_us/article/ywm4ky/do-psychedelic-tips-change-your-political-views"">and politics</a> after a psychedelic experience, though it’s hard to tell exactly what part of the psychedelic experience does this, and enough people end up believing various forms of woo that I hesitate to say it’s all about getting more rational beliefs. But just going off anecdote, this sometimes works.</p>
<p>Rationalists wasted years worrying about various named biases, like the conjunction fallacy or the planning fallacy. But most of the problems we really care about aren’t any of those. They’re more like whatever makes the global warming skeptic fail to connect with all the evidence for global warming.</p>
<p>If the model in <i>Unlocking The Emotional Brain</i> is accurate, it offers a starting point for understanding this kind of bias, and maybe for figuring out ways to counteract it.</p>",Yvain,scottalexander,Scott Alexander,
9wTgup2S92giewJn5,Building awareness habits (cognitive),building-awareness-habits-cognitive,https://www.lesswrong.com/posts/9wTgup2S92giewJn5/building-awareness-habits-cognitive,2019-11-27T01:36:25.019Z,5,4,2,False,True,,"<p>Something I struggle with (probably largely due to ADHD) is building habits/patterns of being aware of things I want to notice/practice cognitively.</p><p>For example, I find myself easily becoming somewhat thoughtless in social situations, in that I do not stop to observe, think, and measure my actions and responses at all. I have, for a couple years now, been intending to work on this, and not really doing anything to act on this intention. I often plan to step back and just observe in social situations, but never do.</p><p>Since I struggle with this, I figure that the best thing I can do now is try and pick up some strategies for both reminding myself to think back to cognitive patterns I want to build when I enter into the relevant situation, and for doing said things.</p><p>So, does anyone have suggestions on how one can:</p><ul><li>More consistently remember something they want to watch out for in various situations (especially social/fast-paced situations)</li><li>Build new mental patterns/habits (in general)</li><li>Effectively observe social situations as they occur, in person, to learn from the interactions in order to develop social skills (bonus if the strategy allows for one to not appear/be awkward or violate social etiquette)</li><li>Somewhat less relevantly, banish aversions to human connection/intimacies that make things like eye contact difficult/overwhelming (the aversion is mostly habitual at this point)</li></ul><br>",Teach,teach,Teach,
koRZu53LBZEapwww6,Could someone please start a bright home lighting company?,could-someone-please-start-a-bright-home-lighting-company,https://www.lesswrong.com/posts/koRZu53LBZEapwww6/could-someone-please-start-a-bright-home-lighting-company,2019-11-26T19:20:04.622Z,94,41,42,False,False,http://www.lincolnquirk.com/2019/11/26/lumenator.html,"<html><head></head><body><p>Elevator pitch: Bring enough light to simulate daylight into your home and office.</p>
<p>This idea has been shared in Less Wrong circles for a couple years. Yudkowsky wrote <a href=""https://www.lesswrong.com/posts/zsG9yKcriht2doRhM/inadequacy-and-modesty"">Inadequate Equilibria</a> in 2017 where he and his wife invented the idea, and <a href=""https://www.lesswrong.com/posts/hC2NFsuf5anuGadFm/how-to-build-a-lumenator"">Raemon wrote a playbook</a> in 2018 for how to do it yourself. Now I and at least two other friends are trying to build something similar, and I suspect there's a bigger-than-it-looks market opportunity here because it's one of those things that a lot of people would probably want, if they knew it existed and could experience it. And it's only recently become cheap enough to execute well.</p>
<p><a href=""https://www.youtube.com/watch?v=aJ4TJ4-kkDw&amp;feature=emb_title"">Coelux</a> makes a high-end artificial skylight which certainly looks awesome, but it costs upwards of $30k and also takes a lot of headroom in the ceiling. Can we do better for cheaper?</p>
<h2>Brightness from first principles</h2>
<p>First let's clear up some definitions:</p>
<ul>
<li>
<p>Watts is a measure of power consumption, not brightness.</p>
<ul>
<li>""Watt equivalent"" brightness is usually listed for LED bulbs, at least for the standard household bulb form factor. You should generally ignore this (instead, just look at the lumens rating), because it is confusing. Normally ""watt equivalent"" is computed by dividing lumens by 15 or so. (bulb manufacturers like to make LED bulbs that are easy to compare, by having similar brightness to the incandescents they replace, hence ""watt equivalent"")</li>
</ul>
</li>
<li>
<p>Lumens output is a measurement of an individual bulb, but says nothing about the distribution of those rays of light. For that you want to be doing math to estimate lux.</p>
</li>
<li>
<p>""Lux"", or ""luminous flux"", is the measurement of how bright light is on a certain surface (such as a wall or your face). Lux is measured in lumens per square meter. Usually, your end goal when designing lighting is to create a certain amount of lux.</p>
<ul>
<li>Direct sunlight shines 100k lux <a href=""https://en.wikipedia.org/wiki/Lux"">(source for these on Wikipedia)</a></li>
<li>Full daylight (indirect) is more than 10k lux</li>
<li>An overcast day or bright TV studio lighting is 1000 lux</li>
<li>Indoor office lighting is typically 500</li>
<li>Indoor living room at night might be only 50</li>
</ul>
</li>
</ul>
<p>Side note: This scale surprises me greatly! We usefully make use of vision with four or more orders of magnitude differences in lux within a single day. Our human vision hardware is doing a lot of work to make the world look reasonable within these vast differences of amount of light. Regardless, this post is about getting a lot of lux. I hypothesize that lux is associated with both happiness and productivity, and during the ""dark season"" when we don't get as much lux from the sun, I'm looking to get some from artificial lights.</p>
<p>If you put a single 1000-lumen (66-watt-equivalent) omnidirectional bulb in the center of a spherical room of 2m radius (which approximates a 12' square bedroom), the lux at the radius of the sphere is 50. So now we can get a sense of the scope of the problem. When doctors say you should be getting 10,000 lux for 30 minutes a day, the defaults for home lighting are two orders of magnitude off.</p>
<ul>
<li>Raemon's bulbs are ""100W equivalent"" which is ~1500 lumens per bulb. So he's got 36k lumens. If we treat this as a point source and expect that Raemon's head is 2m away from the bulbs, then he's getting 1800 lux, which is twice the ""TV studio"" lighting and seems pretty respectable. I haven't accounted for reflected light from the ceiling either, so reality might be better than this, but I doubt it changes the calculation by more than a factor of 2 -- but I don't have a robust way of estimating ambient light, so ideas are welcome.</li>
<li><a href=""https://meaningness.com/metablog/sad-light-led-lux"">David Chapman's plan</a> uses three 20k-lumen LED light bars for offroad SUV driving, for a total of 60k lumens. But because the light bars aim the light at a relatively focused point on the floor, David estimates that most of that light is being delivered to a roughly 6-square-meter workspace for a total of 10k lux. The photos he shared of his workspace seem to support this estimate.</li>
</ul>
<h2>Other important factors besides brightness</h2>
<p>Color temperature seems important to well-being. Color temperature is measured in kelvins with reference to black-body radiation, but you can think of it as, on the spectrum from ""warm white"" to ""cool white"", what do you prefer? Raemon's plan uses an even split between 2700K and 5000K bulbs. 2700K is quite yellow-y, 5000 is nearly pure white. In my experimentation I discovered that I liked closer to 5000 in the mornings and closer to 2700 in evenings.</p>
<p>And what about light distribution? Large ""panels"" of bright light would seem the closest to daylight in form-factor. Real windows are brighter near the top, and it is considered dramatic and unnatural to have bright lighting coming from the ground. Also, single bright point sources are painful to look at and can seem harsh. I think there's a lot of flexibility here, but I think my personal ideal light would be a large, window-sized panel of light mounted on the ceiling or high on the wall.</p>
<p>Also, color accuracy: LEDs are notoriously narrow spectrum by default; manufacturers have to do work to make their LEDs look more like incandescent bulbs in how they light up objects of different colors. Check for a measure called Color Rendering Index, or CRI, in product descriptions. 100 is considered perfect color rendering, and anything less than 80 looks increasingly awful as you go down. The difference between CRI 80 and 90 is definitely noticeable to some people. I haven't blind tested myself, and definitely might be imagining it, but I feel like there was some kind of noticeable upgrade of the ""coziness"" or ""warmth"" in my room when upgrading from CRI 80 to CRI 95 bulbs.</p>
<p>Dimmability? (Are you kidding? We want brightness, not dimness!) Okay, fine, if you insist. Most high-end LED bulbs seem dimmable today, so I hope this is not an onerous requirement.</p>
<p>Last thing I can think of is flicker. I have only seen flicker as a major problem with really low-end bulbs, but I can easily see and be annoyed by 60hz flicker out of the corner of my eye. Cheap Christmas LED light strings have super bad flicker, but it seems like manufacturers of nicer LEDs today have caught on, because I haven't had any flicker problems with LED bulbs in years.</p>
<p>Okay, so to summarize: I want an all-in-one ""light panel"" that produces at least 20000 lumens and can be mounted to a wall or ceiling, with no noticeable flicker, good CRI, and adjustable (perhaps automatically adjusting) color temperature throughout the day.</p>
<p>A redditor <a href=""https://imgur.com/a/r31Gb"">made a fake window for their basement</a> which is quite impressive for under $200. This is definitely along the axis I am imagining.</p>
<p>I haven't mentioned operating cost. Full-spectrum LEDs seem to output about 75 lumens per watt, so if our panel is 20k lumens then we should expect our panel to draw 266 watts. This seems reasonable to me. If you leave it on 8 hours a day, you're going to use 25 cents per day in electricity (at $.12 per kWh).</p>
<h2>Marketing and Costs</h2>
<p>What do you think people will pay for the product? I have already put 6+ hours into researching this and don't have a satisfactory solution yet. I would probably pay at least $400 to get that time back, if the result satisfied all my requirements; I expect to put in quite a bit more time, so I think I could probably be convinced to pay north of $1000 for a really good product. Hard to say what others would pay, but I wouldn't be surprised if you could build a good product in the $400-1200 range that would be quite popular.</p>
<p>What about costs? Today, <a href=""https://www.homedepot.com/p/Cree-60W-Equivalent-Soft-White-2700K-A19-Dimmable-Exceptional-Light-Quality-LED-Light-Bulb-2-Pack-TA19-08027MDFH25-12DE26-1-12/303880968"">Home Depot sells Cree 90-CRI, 815-lumen bulbs on their website for $1.93 per bulb</a> for a cost of $2.37 per 1000 lumens. This is the cheapest I've seen high quality bulbs. (The higher lumen bulbs are annoyingly quite a bit more expensive). To get 36k lumens at this price costs under $100 retail. Presumably there are cooling considerations when packing LEDs close together but those seem solvable if you're doing the ""panel"" form factor. There are other costs I'm sure, but it seems like the LEDs and driver are likely to dominate most of the costs. These are dimmable but not color temperature adjustable.</p>
<p>Yuji LEDs sells <a href=""https://store.yujiintl.com/collections/film-photo-lighting/products/high-cri-98-led-flexible-strip-bicolor-tungsten-to-daylight-for-film-lighting"">2700K-6500K dimmable LED strips</a>, also with 95+ CRI, at $100 for 6250 lumens (so a cost of $16 per 1000 lumens). This is 7x more expensive per lumen, but knowing that it exists is really helpful.</p>
<h2>Promotion and Distribution</h2>
<p>Kickstarter is the obvious idea for getting this idea out there. I would also recommend starting a subreddit (if it doesn't exist; I haven't checked yet) for do-it-yourselfers who want to build or buy really bright lighting systems for their homes, as I think there is probably enough sustained interest in such a topic for it to exist.</p>
<p>You can also try to get press. The idea of ""indoor light as bright as daylight"" is probably somewhat viral so I'd hope you can get people to write about you. Coelux got a bunch of press a few years ago doing this exact thing, but their product is so expensive that they don't even list their price on their website, but in articles about Coelux you can see people commenting that they wish they could afford one.</p>
<p>I do think the idea needs to be spread more. Most people don't know this is possible, so there's a lot of work you'll be doing to just explain that such a thing is possible and healthy.</p>
<h2>Competition?</h2>
<p>I don't think there's any relevant competition out there today. Coelux is super high end. The competition is do-it-yourselfers, but this market is far bigger than the number of people who are excited to do-it-themself.</p>
<p>Some have mentioned ""high bay"" lights, which are designed to be mounted high in warehouses and such, and throw a light cone a long distance to the floor. I am excited to try this and I will probably try it next, but I am not super optimistic about it because I expect it to be quite harsh. <a href=""https://store.yujiintl.com/collections/high-cri-led-lights/products/high-cri-95-high-bay-ufo-led-light-pack-1pcs"">This is the one that Yuji sells,</a> but you can find cheaper and presumably lower-quality ones on Amazon.</p>
<p>Part of my motivation for writing this blog post is to source ideas for other things that exist that could fill this niche. Comment here if you solved this problem in a way I haven't described! I'll update this post with ideas. If you start this company, also email me and I'll buy one and try your product and probably write about it :)</p>
<h2>Building a Sustainable Business</h2>
<p>If you put a bunch of research into designing a really great product and it succeeds but gets effectively copied by low-cost clones, you'll be sad. I am not sure how to defend this, and I think it is probably the weakest point of this business model; but it is a weakness that many hardware companies share, and a lot of them still carve out a niche. One idea would be to build up your product's branding and reputation, by explaining why low-cost clones suck in various ways. Another is just to give really good service. Lastly, if you avoid manufacturing things in China, maybe Chinese clone companies won't copy your technology as quickly.</p>
</body></html>",lincolnquirk,lincolnquirk,lincolnquirk,
AMYx7tq3dpsQdBRGr,3 Cultural Infrastructure Ideas from MAPLE,3-cultural-infrastructure-ideas-from-maple,https://www.lesswrong.com/posts/AMYx7tq3dpsQdBRGr/3-cultural-infrastructure-ideas-from-maple,2019-11-26T18:56:48.921Z,53,27,15,False,False,,"<p>About six months ago, I moved to the <a href=""https://monasticacademy.com"">Monastic Academy</a> in Vermont. MAPLE for short. </p><p>You may have curiosities / questions about what that is and why I moved there. But I&apos;ll save that for another time.</p><p>I was having a conversation last week about some cultural infrastructure that exists at MAPLE (that I particularly appreciate), and these ideas seemed worth writing up. </p><p>Note that MAPLE is a young place, less than a decade old in its current form. So, much of it is &quot;experimental.&quot; These ideas aren&apos;t time-tested. But my personal experience of them has been surprisingly positive, so far. </p><p>I hope you get value out of playing with these ideas in your head or even playing with various implementations of these ideas. </p><h1>1. The Care Role or Care People</h1><p>MAPLE loves its roles. All residents have multiple roles in the community. </p><p>Some of them are fairly straightforward and boring. E.g. someone&apos;s role is to write down the announcements made at meals and then post them on Slack later.</p><p>Some of them are like &quot;jobs&quot; or &quot;titles&quot;. E.g. someone is the bookkeeper. Someone is the Executive Director. </p><p>One special role I had the honor of holding for a few months was the Care role. </p><p>The Care role&apos;s primary aim is to watch over the health and well-being of the community as a group. This includes their physical, mental, emotional, and psychological well-being. </p><p>The Care role has a few &quot;powers.&quot; </p><p>The Care role can offer check-ins or &quot;Care Talks&quot; to people. So if I, in the Care role, notice someone seems to be struggling emotionally, I can say, &quot;Hey would you like to check in at some point today?&quot; and then schedule such a meeting. (MAPLE has a strict schedule, and this is not something people would normally be able to do during work hours, but it&apos;s something Care can do.)</p><p>People can also request Care Talks from Care. </p><p>The Care role also has the power to plan / suggest Care Days. These are Days for community bonding and are often either for relaxation or emotional processing. Some examples of Care Days we had: we went bowling; we did a bunch of Circling; we visited a nearby waterfall. </p><p>The Care role can request changes to the schedule if they believe it would benefit the group&apos;s well-being. E.g. asking for a late wake-up. (Our usual wake-up is 4:40AM!) </p><p>Ultimately though, the point of this is that it&apos;s <em>someone&apos;s job</em> to watch over the group in this particular way. That means attending to the group field, learning how to read people even when they are silent, being attentive to individuals but also to the &quot;group as a whole.&quot; </p><p>For me as Care, it gave me the permission and affordance to devote part of my brain function to tracking the group. Normally I would not bother devoting that much energy and attention to it because I know I wouldn&apos;t be able to do much about it even if I were tracking it. </p><p>Why devote a bunch of resource to tracking something without the corresponding ability / power to affect it? </p><p>But since it was built into the system, I got full permission to track it and then had at least some options for doing something about what I was noticing. </p><p>This was also a training opportunity for me. I wasn&apos;t perfect at the job. I felt drained sometimes. I got snippy and short sometimes. But it was all basically allowing me to train and improve at the job, as I was doing it. No one is perfect at the Care role. Some people are more suitable than others. But no one is perfect at it. </p><p>The Care role also has a Care assistant. The Care assistant is someone to pick up the slack when needed or if Care goes on vacation or something. In practice, I suspect I split doing Care Talks fairly evenly with the Care assistant, since those are a lot for one person to handle. And, people tend to feel more comfortable with certain Care people over others, so it&apos;s good to give them an option. The Care assistant is also a good person for the Care role to get support from, since it tends to be more challenging for the Care role to receive Care themselves. </p><p>I could imagine, for larger groups, having a Care Team rather than a single Care role with Care assistant. </p><p>That said, there is a benefit to having <em>one</em> person hold the mantle primarily. Which is to ensure that someone is mentally constructing a model of the group plus many of the individuals within it, keeping the bird&apos;s eye view map. This should be one of Care&apos;s main mental projects. If you try to distribute this task amongst multiple people, you&apos;ll likely end up with a patchy, stitched-together map. </p><p>In addition, understanding group dynamics and what impacts the group is another good mental project for the Care person. E.g. learning how it impacts the group when leaders exhibit stress. Learning how to use love languages to tailor care for individuals. Etc.</p><h2>1.5. The Ops Role</h2><p>As an addendum, it&apos;s worth mentioning the Ops role too. </p><p>At MAPLE, we follow a strict schedule and also have certain standards of behavior.</p><p>The Ops role is basically <em>in charge</em> of the schedule and the rules and the policies at MAPLE. They also give a lot of feedback to people (e.g. &quot;please be on time&quot;). This is a big deal. It is also probably the hardest role.</p><p>It is important for the Ops role and the Care role to not be the same person, if you can afford it. </p><p>The Ops role represents, in a way, &quot;assertive care.&quot; The Care role represents &quot;supportive care.&quot; These are terms about healthy, skillful parenting that I read originally from the book <em>Growing Up Again</em>. </p><p><a href=""https://parentsplace.jfcs.org/the-parenting-highway/"">You can read more about supportive and assertive care here.</a> </p><p>Basically, <em>assertive</em> points to structure, and <em>supportive</em> points to nurture. Both are vital.</p><p>Care builds models of the group&apos;s physical and emotional well-being, how their interactions are going, and reading people. </p><p>Ops builds models of what parts of the structure / schedule are important, how to be fair, how to be reasonable, noticing where things are slipping, building theories as to why, and figuring out adjustments. Ops has to learn how to give and receive feedback a lot more. Ops has to make a bunch of judgment calls about what would benefit the group and what would harm the group (in the short-term and long-term), and ultimately has to do it without a higher authority telling them what to do. </p><p>It&apos;s a difficult position, but it complements the Care role very well. </p><p>As Care, I noticed that people seemed to be <em>worse off</em> and struggled more when the Ops role failed to hold a strong, predictable, and reasonable container. The Ops role is doing something that ultimately cares for people&apos;s emotional, mental, and physical well-being&#x2014;same as Care. But they do it from a place of more authority and power. </p><p>As Care, I would sometimes find myself wanting to do some &quot;Ops&quot;-like things&#x2014;like remind people about rules or structures. But it&apos;s important for Care to avoid handling those tasks, so that people feel more open and not have that &quot;up for them&quot; with Care. Care creates a space where people can process things and just get support. </p><p>It&apos;s not really beneficial for Care to take on the Ops role, and it&apos;s not beneficial for Ops to take on the Care role. This creates floppiness and confusion.</p><h1>2. Support Committees</h1><p>Sometimes, people struggle at MAPLE. Once in a while, they struggle in a way that is more consistent and persistent, in an <a href=""http://www.focusadventure.com/adaptive-challenge-and-the-leadership-challenge/"">&quot;adaptive challenge&quot; way</a>. A few Care Talks aren&apos;t sufficient for helping them. </p><p>If someone starts struggling in this way, MAPLE can decide to spin up a support committee for that person. Let&apos;s call this struggling person Bob. </p><p>The specific implementation at MAPLE (as far as I know, at this particular time) is:</p><ul><li>Three people are selected to be on Bob&apos;s support committee.</li><li>Some factors in deciding those people include: Is Bob comfortable with them? Do they have time? Do they want to support Bob? Do they seem like they&apos;d do a decent job of supporting Bob?</li><li>The way the decision actually gets made differs for each case, but it probably always involves the Executive Director. </li><li>The support committee meets with Bob about once a week.</li><li>They discuss ways they can be supportive to Bob. Could he use reminders to avoid caffeine? Could he use an exercise accountability person? Could he use regular Care Talks? Could he use help finding a therapist?</li><li>They also give Bob feedback of various kinds. E.g. maybe Bob has been making chit-chat during silent periods; maybe Bob has been yelling things at Alice when he gets scared; maybe Bob is taking naps during work period. In this frame, it should be clear that Bob is the responsible party for his own growth and improvement and well-being. Ultimately he has to hold to his commitments / responsibilities / roles in the community, and the support committee can&apos;t do that <em>for him</em>. But they can help him as much as seems reasonable / worth trying.</li><li>Current implementation of this doesn&apos;t have a pre-set deadline for when the committee ceases, but there are check-ins with the Executive Director to see how things are progressing with Bob and the support committee.</li><li>Sometimes, it might come to make sense to ask Bob to leave the community, if things aren&apos;t improving after some time has passed (3-6 months maybe?). If everyone put in their best effort, within reason, and still Bob can&apos;t hold to his commitments, despite everyone&apos;s best intentions, then there may be a decision to part ways. </li><li>Hopefully most of the time, the support committee thing works enough to get Bob to a place where he&apos;s no longer struggling and can get back into the flow of things without a support committee.</li></ul><p>I appreciate support committees! </p><p>They&apos;re trying to strike a tricky balance between being supportive and holding people accountable. But they keep communication channels open and treat it like a two-way street. </p><p>Bob isn&apos;t totally in the dark about what&apos;s going on. He isn&apos;t being suddenly told there&apos;s a problem and that he can&apos;t stay. He also isn&apos;t being held totally responsible, as one might be at a normal job. &quot;Either shape up or ship out&quot; sort of thing. It&apos;s also not the thing where people act &quot;open and supportive&quot; but really it&apos;s still &quot;on you&quot; to fix yourself, and no one lifts a finger, and you have to do all the asking. </p><p>With a support committee, Bob gets regular support from the community in a structured way. He gets to set goals for himself, in front of others. He gets regular feedback on how he&apos;s doing on those goals. If he needs help, he has people who can brainstorm with him on how to get that help, and if they commit to helping him in some way, they actually do it. If he needs someone to talk to, he can have regularly scheduled Care Talks. </p><p>He is neither being coddled nor neglected.  </p><p>It&apos;s also helpful to generally foster a feeling that the community is here for you and that there&apos;s a desire to do what&apos;s best for everyone, from all parties. </p><p>Would this kind of thing work everywhere for all groups? No, of course not. </p><p>It&apos;s a bit resource-intensive as it currently is. It also seems to ask for a high skill level and value-aligned-ness from people. But there&apos;s room to play around with the specific format. </p><h1>3. The Schedule</h1><p>The Schedule at MAPLE is not viable for most people in most places. </p><p>But many people who come to stay at MAPLE find out that the Schedule is something they hugely benefit from having. It&apos;s often named as one of the main pros to MAPLE life.</p><p>Basically, there&apos;s a rigid schedule in place. It applies to five-and-a-half days out of the week. (Sundays are weird because we go into town to run an event; Mondays are off-schedule days.)</p><p>But most days, it&apos;s the same routine, and everyone follows it. (The mornings and evenings are the most regimented part of the day, with more flexibility in the middle part.)</p><p>4:40AM chanting. 5:30AM meditation. 7AM exercise. 8:05AM breakfast. Then work. Etc. Etc. Up until the last thing, 8:30PM chanting. </p><p>Which is more surprising: </p><ul><li>The fact most people, most of the time, show up on time to each of these activities? (Where &quot;on time&quot; means being a little bit early?) </li><li>Or the fact that often there&apos;s at least one person who&apos;s at least one minute late, despite there theoretically being very few other things going on, relatively speaking?</li></ul><p>&#xAF;\_(&#x30C4;)_/&#xAF; </p><p>Anyway, here&apos;s why I think the Schedule is worth talking about as a cultural infrastructure idea:</p><p><strong>It&apos;s more conducive to getting into spontaneous motion. </strong></p><p>You don&apos;t have to plan (as much) about what you&apos;re going to do, when. The activities come one right after the other. </p><p>At MAPLE I don&apos;t get stuck in bed, wondering whether to get up now or later. </p><p>I have spent hours and hours of my life struggling with getting out of bed (yay depression). Regardless of my mood or energy level, I just get out of bed, and it&apos;s automatic, and I don&apos;t think about it, and suddenly I&apos;m putting on my socks, and I&apos;m out the door. </p><p>This has translated somewhat to my off-schedule / vacation days also. </p><p>When left to my own devices, I do not exercise. I have never managed to exercise regularly as an adult. While I&apos;m on-schedule, I just do it. I don&apos;t push myself harder than I can push; sometimes I take it easy and focus on stretching and Tai Chi. But sometimes I sprint, and sometimes I get sore, and my stamina is noticeably higher than before. </p><p>This is so much better than what it was like without the Schedule! It has proven to be more effective than my years of attempts to debug the issue using introspection.</p><p>The Schedule lets me just skip the decision paralysis. I often find myself &quot;just spontaneously doing it.&quot; It becomes automatic habit. Like starting the drive home and &quot;waking up&quot; to the fact I am now home. </p><p>This is relaxing. It&apos;s more relaxing to just exercise than to internally battle over whether to exercise. It&apos;s more relaxing to just get up and start the day than to internally struggle over whether to get up. There is relief in it. </p><p><strong>It&apos;s easier to tell when people are going through something.</strong></p><p>As Care, it was my job to track people&apos;s overall well-being.</p><p>As it turns out, if someone starts slipping on the Schedule (showing up even a bit late to things more often), it&apos;s often an indication of something deeper. </p><p>The Schedule provides all these little fishing lines that tug when someone could use some attention, and the feedback is much faster than a verbal check-in.</p><p>Sometimes I would find myself annoyed by someone falling through or breaking policy or whatever. If I dug into it, I&apos;d often find out they were struggling on a deeper level. Like I might find out their mom is in the hospital, or they are struggling with a flare up of chronic pain, or something like that.</p><p>Once I picked up on that pattern, I learned to view people&apos;s small transgressions or tardiness as a signal for more compassion, rather than less. Where my initial reaction might be to tense up, feel resistance, or get annoyed, I can remind myself that they&apos;re probably going through some Real Shit and that I would struggle in that situation too, and then I relax. </p><p><strong>Everyone&apos;s doing it together.</strong></p><p>Everyone doing something together is conducive conditions for creating <a href=""https://www.lesswrong.com/posts/9QxnfMYccz9QRgZ5z/the-costly-coordination-mechanism-of-common-knowledge"">common knowledge</a>, even when there&apos;s no speaking involved. Common knowledge is a huge efficiency gain. And I suspect it&apos;s part of why it&apos;s internally easy for me to &quot;just do it.&quot; (And maybe points to why it&apos;s harder for me to &quot;just do it&quot; when no one else notices or cares.)</p><p>Having more shared reality with each other reduces the need for verbal communication, formal group decision-making processes, and internal waffling. </p><p>If everyone can see the fire in the kitchen, you don&apos;t need to say a word. People will just mobilize and put out the fire. </p><p>If everyone sees that Carol is late, and Carol knows everyone has seen that she is late, it&apos;s harder for anyone to create alternative stories, like &quot;Carol was actually on time.&quot; No one has to waste time on that. </p><hr class=""dividerBlock""><p>There are lots of more flexible versions of the Schedule that people use and benefit from already. Shared meals in group houses, for instance. </p><p>But I&apos;d love to see more experimentation with this, in communities or group houses or organizations or what-have-you. </p><p><a href=""https://medium.com/@ThingMaker/dragon-army-theory-charter-8192dc64ea22"">Dragon Army</a> attempted some things in this vein, and I saw them getting up early and exercising together on a number of occasions. I&apos;d love to see more attempts along these lines. </p>",Unreal,unreal,Unreal,
Y374EGeNhKYnBFNhC,Effect of Advertising,effect-of-advertising,https://www.lesswrong.com/posts/Y374EGeNhKYnBFNhC/effect-of-advertising,2019-11-26T14:30:02.095Z,26,11,24,False,False,,"<p>

I've recently had several conversations around whether advertising is
harmful, and specifically whether ads primarily work by tricking
people into purchasing things they don't need.  One way to think about
this is, what would the world would be like if we didn't allow
advertising?  No internet ads, TV ads, magazine ads, affiliate links,
sponsored posts, product placement, everything. Let's also assume that
enforcement is perfect, though of course edge cases would be very
tricky. Here's my speculation about how this would change people's
purchasing:



<ul>

<li><p>Products would be a lot stickier. A lot of advertising tries to
move people between competitors. Sometimes it's an explicit ""here's a
way we're better"" (ex: we don't charge late fees), other times it's a
more general ""you should think positively of our company"" (ex: we
agree with you on political issue Y).  Banning ads would probably mean
higher prices (<a href=""https://www.jefftk.com/benham2013.pdf"">Benham 2013</a>) since it
would be harder to compete on price.</p></li>

<li><p>Relatedly, it would be much harder to get many new products
started. Say a startup makes a new credit card that keeps your
purchase history private: right now a straightforward marketing
approach would be (a) show that other credit cards are doing
something their target audience doesn't like, (b) build on the
audience's sense that this isn't ok, and (c) present the new card as
a solution. Without ads they would likely still see uptake among
people who were aware of the problem and actively looking for a
solution, but mostly people would just stick with the well-known
cards.</p></li>

<li><p>A <a href=""https://meltingasphalt.com/ads-dont-work-that-way/"">major way
ads work</a> is by building brand associations: people who eat
Powdermilk Biscuits are probably Norwegian bachelor farmers, listen to
public radio, or want to signal something along those lines.  Branded
products both provide something of a service, by making more ways to
signal identity, and charge for it, by being more expensive to pay for
clever ad campaigns.  Without ads we would probably still have these
associations, however, and products that happened to be associated
with coveted identities would still have this role.  The way these
associations would develop would be less directed, though brands would
probably still try pretty hard to influence them even without ads.
You can also choose to signal the ""frugal"" identity, which lets you
avoid the brand tax.</p></li>

<li><p>Reviewers would be much more trustworthy. There's a long history of
reviewers getting '<a href=""https://www.fastcompany.com/3065928/sleepopolis-casper-bloggers-lawsuits-underside-of-the-mattress-wars"">captured</a>'
by the industry they review.</p></li>

<li><p>Purchases of things people hadn't tried before would decrease,
both things that people were in retrospect happy to have bought and
things they were not. One of the roles of advertising is to let people
know about things that, if they knew about them they would want to
buy. But ""buy stuff they don't need"" isn't a great gloss for this,
since after buying the products people often like them a lot.  On the
other hand I do think this applies to children, and one of the things
people learn as they grow up is how to interpret ads.  Which is also
why we have regulations on ads directed at kids.</p></li>

</ul>



</p><p>

Don't put too much stock in this: I work on the technical side of ads
and don't have a great view into their social role, and even if I was
in a role like that it would still be very hard to predict how the
world would be different with such a large change.  But broad ""we'd
see more of X and less of Y"" analysis gives a way to explore the
question, and I'm curious what other people's impressions are.

</p>

<p>

(Disclosure: I <a href=""https://www.jefftk.com/p/value-of-working-in-ads"">work in ads</a>
but am speaking only for myself.  I may be biased, though if I thought
my work was net negative I wouldn't do it.)

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100123835903692"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
JpEPKbXiTvmyqYdTr,A test for symbol grounding methods: true zero-sum games,a-test-for-symbol-grounding-methods-true-zero-sum-games-1,https://www.lesswrong.com/posts/JpEPKbXiTvmyqYdTr/a-test-for-symbol-grounding-methods-true-zero-sum-games-1,2019-11-26T14:15:14.776Z,22,9,2,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><p>Imagine there are two AIs playing a <a href=""https://openai.com/blog/debate/"">debate game</a>. The game is zero-sum; at the end of the debate, the human judge assigns the winner, and that AI gets a <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""+1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> reward, while the other one gets a <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""-1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span>.</p>
<p>Except the game, as described, is not truly zero-sum. That is because the AI ""get"" a reward. How is that reward assigned? Presumably there is some automated system that, when the human presses a button, routes <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""+1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> to one AI and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""-1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> to another. These rewards are stored as bits, somewhere ""in"" or around the two AIs.</p>
<p>Thus there are non zero-sum options: you could break into the whole network, gain control of the automated system, and route <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""+1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span> to each AI - or, why not, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""+10^{100}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">100</span></span></span></span></span></span></span></span></span></span> or even <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""+f_{\psi\left(\Omega^{\Omega^\Omega}\right)}(4)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.06em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.675em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">ψ</span></span><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size2-R"" style=""padding-top: 0.961em; padding-bottom: 0.961em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">Ω</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">Ω</span></span></span><span class=""mjx-sup"" style=""vertical-align: 0.289em; padding-left: 0px; padding-right: 0.05em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">Ω</span></span></span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size2-R"" style=""padding-top: 0.961em; padding-bottom: 0.961em;"">)</span></span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">4</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> or whatnot<sup class=""footnote-ref""><a href=""#fn-uhkCzhH2oJvSXMikM-1"" id=""fnref-uhkCzhH2oJvSXMikM-1"">[1]</a></sup>.</p>
<p>Thus, though we can informally say that ""the AIs are in a zero-sum game as to which one wins the debate"", that sentence is not properly grounded in the world; it is only true as long as certain physical features of the world are maintained, features which are not mentioned in that sentence.</p>
<h2>Symbol grounding implies possibility of zero-sum</h2>
<p>Conversely, imagine that an AI has a utility/reward <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U/R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">/</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> which is properly grounded in the world. Then it seems that we should be able to construct an AI with utility/reward <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""-U/-R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">/</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> which is also properly grounded in the world. So it seems that any good symbol grounding system should allow us to define truly zero sum games between AIs.</p>
<p>There are, of course, a few caveats. <a href=""https://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem"">Aumann's agreement theorem</a> requires unboundedly rational agents with common priors. Similarly, though properly grounded <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""-U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> are zero-sum, the agents might not be fully zero-sum with each other, due to bounded rationality or different priors.</p>
<p>Indeed, it is possible to setup a situation where even unboundedly rational agents with common prior will knowingly behave in not-exactly zero-sum ways with each other; for example, you can <a href=""https://www.lesswrong.com/posts/PFu4tonkGiPQ4535F/stuart_armstrong-s-shortform#pS3WDuL7AbkKpoqEK"">isolate the two agents from each other, and feed them deliberately biased information</a>.</p>
<p>But those caveats aside, it seems that proper symbol grounding implies that you can construct agents that are truly zero-sum towards each other.</p>
<h2>Zero-sum implies symbols grounded?</h2>
<p>Is this an equivalence? If two agents really do have zero sum utility or reward functions towards each other, does it mean that those functions are well grounded<sup class=""footnote-ref""><a href=""#fn-uhkCzhH2oJvSXMikM-2"" id=""fnref-uhkCzhH2oJvSXMikM-2"">[2]</a></sup>?</p>
<p>It seems that it should be the case. Zero-sum between <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V=-U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> means that, for all possible worlds <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""w""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">w</span></span></span></span></span></span>, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U(w)=-V(w)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">w</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">w</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. There are no actions that we - or any agent - could do that breaks that fundamental equality. So it seems that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> must be defined by features of the world; grounded symbols.</p>
<p>Now, these grounded symbols might not be exactly what we thought they were; its possible we thought <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> was defined on human happiness, but it is actually only means current in a wire. Still, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> must then be defined in terms of absence of current in the wire. And, whatever we do with the wire - cut it, replace it, modify it in cunning ways - <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> must reach opposite on that.</p>
<p>Thus it seems that either there is <em>some</em> grounded concept that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> are opposite on, or <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> contain exhaustive lists of all special cases. If we further assume that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""U""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> are not absurdly complicated (in a ""more complicated than the universe"" way), we can rule out the exhaustive list.</p>
<p>So, while I can't say with full confidence that a true zero-sum game must mean that the utilities are grounded, I would take such a thing as a strong indication that they are.</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-uhkCzhH2oJvSXMikM-1"" class=""footnote-item""><p>If you thought that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""3\uparrow\uparrow\uparrow 3""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.225em;"">↑<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">↑</span><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">↑</span></span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span> was large, nothing will prepare you for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f_{\psi\left(\Omega^{\Omega^\Omega}\right)}(4)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.06em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.675em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.519em;"">ψ</span></span><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size2-R"" style=""padding-top: 0.961em; padding-bottom: 0.961em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">Ω</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">Ω</span></span></span><span class=""mjx-sup"" style=""vertical-align: 0.289em; padding-left: 0px; padding-right: 0.05em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">Ω</span></span></span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size2-R"" style=""padding-top: 0.961em; padding-bottom: 0.961em;"">)</span></span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">4</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> - the <a href=""https://en.wikipedia.org/wiki/Fast-growing_hierarchy"">fast-growing hierarchy</a> indexed by the <a href=""https://en.wikipedia.org/wiki/Large_Veblen_ordinal"">large Veblen Ordinal</a>. There is no real way to describe how inconceivably huge this number is. <a href=""#fnref-uhkCzhH2oJvSXMikM-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-uhkCzhH2oJvSXMikM-2"" class=""footnote-item""><p>Assuming the functions are defined in the world to some extent, not over platonic mathematical facts. <a href=""#fnref-uhkCzhH2oJvSXMikM-2"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
8W5gNgEKnyAscg8BF,Thoughts on implementing corrigible robust alignment,thoughts-on-implementing-corrigible-robust-alignment,https://www.lesswrong.com/posts/8W5gNgEKnyAscg8BF/thoughts-on-implementing-corrigible-robust-alignment,2019-11-26T14:06:45.907Z,26,8,2,False,False,,"<html><head></head><body><h1>Background / Context</h1>
<p>As context, here's an pictorial overview of (part of) AI alignment.</p>
<p><img src=""https://sjbyrnes.com/LW_implementing_corrigible.png"" alt=""""></p>
<p>Starting from the top:</p>
<p>I split possible AGIs into those that do <a href=""https://www.lesswrong.com/posts/ZDZmopKquzHYPRNxq/selection-vs-control"">search/selection-type optimization</a> towards achieving an explicitly-represented goal, and ""Everything else"". The latter category is diverse, and includes (1) systems with habits and inclinations (that may lead to goal-seeking behavior) but no explicit goal (e.g. today's RL systems); (2) <a href=""https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety"">""microscope AI""</a> and other types of so-called ""tool AI""; (3) IDA (probably?), and more. I'm <a href=""https://www.lesswrong.com/posts/AKtn6reGFm5NBCgnd/in-defense-of-oracle-tool-ai-research"">all for exploring these directions</a>, but not in this post; here I'm thinking about AGIs that have goals, know they have goals, and search for ways to achieve them. These are likely to be the most powerful class of AGIs, and were popularized in Bostrom's book <em>Superintelligence</em>.</p>
<p>Within this category, a promising type of goal is a ""pointer"" (in the programming sense) to human(s) achieving <em>their</em> goals, whatever they may be. If we can make a system with that property, then it seems that the default <a href=""https://wiki.lesswrong.com/wiki/Basic_AI_drives"">dangerous instrumental subgoals</a> get replaced by <em>nice</em> instrumental subgoals like <a href=""https://arxiv.org/abs/1611.08219"">respecting off-switches</a>, asking clarifying questions, and so on. In <a href=""https://www.lesswrong.com/posts/iydwbZhATANhjoGP7/more-variations-on-pseudo-alignment"">More variations on pseudo-alignment</a>, Evan Hubinger refers to pointer-type goals as <strong>corrigible alignment</strong> in general, noting that it is only corrigible <em>robust</em> alignment if you're pointing at the right thing.</p>
<p>Out of proposed AGIs with explicit goals, most of the community's interest and ideas seem to be in the category of corrigible alignment, including <a href=""https://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition"">CEV</a> and <a href=""https://arxiv.org/abs/1606.03137"">CIRL</a>. But I also included in my picture above a box for ""Goals that refer directly to the world"". For example, if you're a very confident moral realist who thinks that we ought to tile the universe with hedonium, then I guess you would probably want your superintelligent AGI to be programmed with that goal directly. There are also goals that are half-direct, half-corrigible, like ""cure Alzheimer's <a href=""https://www.lesswrong.com/posts/eBd6WvzhuqduCkYv3/following-human-norms"">while respecting human norms</a>"", which has a direct goal but a corrigible-type constraint / regularization term.</p>
<p>Continuing with the image above, let's move on with the corrigible alignment case—now we're in the big red box. We want the AGI to be able to take observations of one or more humans (e.g. the AGI's supervisor), and turn it into an <em>understanding</em> of that human, presumably involving things like their mood, beliefs, goals, habits, and so on. This understanding has to be good enough to facilitate the next step, which can go one of two ways.</p>
<p>For the option shown on the bottom left, we define the AGI's goal as some function f on the components of the human model. The simplest f would be ""f=the human achieves their goals"", but this may be problematic in that people can have conflicting goals, sadistic goals, goals arising from false beliefs or foul moods, and so on. Thus there are more complex proposals, ranging from slightly complicated (e.g. measuring and balancing 3 signals for liking, wanting, and approving—see <a href=""https://www.lesswrong.com/posts/mSPsyEwaymS74unND/acknowledging-human-preference-types-to-support-value"">Acknowledging Human Preference Types to Support Value Learning</a>) to super-duper-complicated (<a href=""https://www.lesswrong.com/posts/CSEdLLEkap2pubjof/research-agenda-v0-9-synthesising-a-human-s-preferences-into"">Stuart Armstrong's Research Agenda</a>). Stuart Russell's vision of CIRL in his book <em>Human Compatible</em> seems very much in this category as well. (As of today, ""What should the function f be?"" is an open question in philosophy, and ""How would we write the code for f?"" is an open question in CS; more on the latter below.)</p>
<p>Or, for the option shown on the bottom right, the AGI uses its understanding of humans to try to figure out what a human would do in a hypothetical scenario. On the simpler side, it could be something like ""If you told the human what you're doing, would they approve?"" (see <a href=""https://ai-alignment.com/model-free-decisions-6e6609f5d99e"">Approval-directed agents</a>), and on the more complicated side, we have CEV. As above, ""What should the scenario be?"" is an open question in philosophy, and ""How would we write the code?"" is an open question in CS.</p>
<h1>How would we write the code for corrigible robust alignment?</h1>
<p>I don't have a good answer, but I wanted to collect my thoughts on different possible big-picture strategies, some of which can be combined.</p>
<h2>End-to-end training using human-provided ground truth</h2>
<p>This is the ""obvious"" approach that would occur to an ML programmer of 2019. We manually collect examples of observable human behavior, somehow calculate the function f ourselves (or somehow run through the hypothetical scenario ourselves), and offer a reward signal (for reinforcement learning) or labeled examples (for supervised learning) illustrating what f is. Then we hope that the AGI invents the goal-defining procedure that we wanted it to go through. With today's ML techniques, the system would not have the explicit goal that we want, but would hopefully behave as if it did (while possibly failing out of distribution). With future ML techniques, the system might wind up with an actual explicitly-represented goal, which would hopefully be the one we wanted, but this is the stereotypical scenario in which we are concerned about ""inner alignment"" (see <a href=""https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB"">Risks from Learned Optimization</a>).</p>
<h2>End-to-middle training using human-provided ground truth</h2>
<p>Likewise, maybe we can provide an ML system with high-dimensional labels about people—""this person has grumpiness level 2, boredom level 6, hunger level 3, is thinking about football, hates broccoli..."". Then we can do ML to get from sensory inputs to understanding of humans, which would be calculated as intermediate internal variables. Then we can hard-code the construction of the goal as a function of those intermediate variables (the bottom part of the diagram above, i.e. either the function f, or the hypothetical scenario). This still has some robustness / inner-alignment concerns, but <em>maybe</em> less so than the end-to-end case? I also have a harder time seeing how it would work in detail—what exactly are the labels? How do we combine them into the goal? I don't know. But this general approach seems worth consideration.</p>
<h2>Hardcoded human template (= innate intuitive psychology)</h2>
<p>This one is probably the most similar to how the human brain implements pro-social behaviors, although the human brain mechanism is a probably somewhat more complicated. (I previously wrote up my speculations at <a href=""https://www.lesswrong.com/posts/NkSpukDkm9pjRdMdB/human-instincts-symbol-grounding-and-the-blank-slate"">Human instincts, symbol grounding, and the blank-slate neocortex</a>.) I think the brain houses a giant repository of, let's call them, ""templates""—generative models which can be glued together into larger generative models. We have templates for everything from ""how a football feels in my hand"" to ""the way that squirrels move"". When we see something, we automatically try to model it by analogy, building off the templates we already have, e.g. ""I saw something in the corner of my eye, it was kinda moving like a squirrel"".</p>
<p>So that suggests an approach of pre-loading this template database with a hardcoded model of a human, complete with moods, beliefs, and so on. That template would serve as a bridge between the real world and the system's goals. On the ""real world"" side, the hope is that when the system sees humans, it will correctly pattern-match them to the built-in human template. On the ""goals"" side, the template provides a hook in the world-model that we can use to hard-code the construction of the goal (either the function f or the hypothetical scenario—this part is the same as the previous subsection on end-to-middle training). As above, I am very hazy on the details of how such a template would be coded, or how the goal would be constructed from there.</p>
<p>Assuming we figure out how to implement something like this, there are two obvious problems: false positives and false negatives to the template-matching process. In everyday terms, that would be anthropomorphizing and dehumanization respectively. False-positives (anthropomorphizing) are when we pattern-match the human template to something that is not a human (teddy bears, Mother Earth, etc.). These lead to alignment errors like trading off the welfare of humans against the welfare of teddy bears. False-negatives (dehumanization) correspond to modeling people without using our innate intuitive-psychology capability. These lead to the obvious alignment errors of ignoring the welfare of some or all humans.</p>
<p>Humans seem quite capable of committing both of these errors, and do actually display both of those corresponding antisocial behaviors. I guess that doesn't bode well for the template-matching strategy. Still, one shouldn't read too much into that. Maybe template-matching can work robustly if we're careful, or perhaps in conjunction with other techniques.</p>
<h2>Interpretability</h2>
<p>It seems to me that interpretability is not fundamentally all that different from template-matching; it's just that instead of having the system <em>automatically</em> recognize that a blob of world-model looks like a human model, here instead the <em>programmer</em> is looking at the different components of the world-model and seeing whether they look like a human model. I expect that interpretability is not really a viable solution on its own, because the world-model is going to be too complicated to search through without the help of automated tools. But it could be helpful to have a semi-automated process, e.g. we have template-matching as above, but it flags both hits and near-misses for the programmer to double-check.</p>
<h2>Value lock-in</h2>
<p>Here's an oversimplified example: humans have a dopamine-based reward system which can be activated by either (1) having a family or (2) wireheading (pressing a button that directly stimulates the relevant part of the brain; I assume this will be commercially available in the near future if it isn't already). People who have a family would be horrified at the thought of neglecting their family in favor of wireheading, and conversely people who are addicted to wireheading would be horrified at the thought of stopping wireheading in favor of having a family. OK, this isn't a perfect example, but hopefully you get the idea: since goal-directed agents use their current goals to make decisions, when there are multiple goals theoretically compatible with the training setup, the agents can lock themselves into the first one of them that they happen to come across.</p>
<p>This applies to any of the techniques above. With end-to-end training, we want to set things up such that the desired goal is the <em>first</em> interpretation of the reward signal that the system locks onto. With template-matching, we want the human template to get matched to actual humans <em>first</em>. Etc. Then we can hope that the system will resist further changes.</p>
<p>I'm not sure I would bet my life on this kind of strategy working, but it's definitely a relevant dynamic to keep in mind.</p>
<p>(I'm not saying anything original here; see <a href=""https://arbital.com/p/preference_stability/"">Preference stability</a>.)</p>
<h2>Adversarial examples</h2>
<p>Last but not least, if we want to make sure the system works well, it's great if we can feed it adversarial examples, to make sure that it is finding the correct goal in even the trickiest cases.</p>
<p>I'm not sure how we would systematically come up with lots of adversarial examples, or know when we were done. I'm also not sure how we would generate the corresponding input data, unless the AGI is being trained in a virtual universe, which actually is probably a good idea regardless. Note also that ""deceptive alignment"" (again see <a href=""https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB"">Risks from Learned Optimization</a>) can be very difficult to discover by adversarial testing.</p>
<h1>Conclusion</h1>
<p>The conclusion is that I don't know how to implement corrigible robust alignment.  ¯\_(ツ)_/¯</p>
<p>I doubt anything in this post is original, but maybe helpful for people getting up to speed and on the same page? Please comment on what I'm missing or confused about!</p>
</body></html>",steve2152,steve2152,Steven Byrnes,
dJpyvTue4fs5xgC39,Is daily caffeine consumption beneficial to productivity?,is-daily-caffeine-consumption-beneficial-to-productivity,https://www.lesswrong.com/posts/dJpyvTue4fs5xgC39/is-daily-caffeine-consumption-beneficial-to-productivity,2019-11-26T13:13:05.613Z,17,8,19,False,True,,"<p>Caffeine raises human alertness by binding to adenosine receptors in the human brain. It prevents those receptors from binding adenosine and suppressing activity in the central nervous system.</p><p>Regular caffeine productions seems to result in the body building more adenosine receptors, but it&apos;s unclear to me whether or not the body produces enough adenosine receptors to fully cancel out the effect. Did anybody look deeper into the issue and knows the answer?</p>",ChristianKl,christiankl,ChristianKl,
jPb9v4oprTpfTbNC3,Curtis Yarvin on A Theory of Pervasive Error,curtis-yarvin-on-a-theory-of-pervasive-error,https://www.lesswrong.com/posts/jPb9v4oprTpfTbNC3/curtis-yarvin-on-a-theory-of-pervasive-error,2019-11-26T07:27:12.328Z,21,7,6,False,False,https://americanmind.org/essays/the-clear-pill-part-2-of-5-a-theory-of-pervasive-error/,"<p>(<em>Content warning</em>: <a href=""https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer"">politics</a>. Read with caution, as always.)</p>
<p>Curtis Yarvin, a computer programmer perhaps most famous as the principal author of the <a href=""https://en.wikipedia.org/wiki/Urbit"">Urbit</a> decentralized server platform, expounds on a theory of how false beliefs can persist in Society, in a work of what the English philosopher N. Land <a href=""https://twitter.com/Outsideness/status/1199195209134772224"">characterizes as ""political epistemology""</a>. Yarvin argues that the Darwinian ""marketplace of ideas"" in liberal democracies selects for æsthetic appeal as well as truth: in particular, the æsthetics of ambition and loyalty grant a selective advantage in memetic competition to ideas that align with state power, resulting in a potentially severe distortionary effect on Society's collective epistemology despite the lack of a centralized censor. Watch for the shout-out to Effective Altruism! (November 2019, ~8000 words)</p>
",Zack_M_Davis,zack_m_davis,Zack_M_Davis,
Mmk9tdFm8wcRvazva,My Anki patterns,my-anki-patterns,https://www.lesswrong.com/posts/Mmk9tdFm8wcRvazva/my-anki-patterns,2019-11-26T06:27:39.126Z,61,30,17,False,False,,"<p><em>Cross-posted from <a href=""http://agentydragon.com/posts/2019-11-25-my-anki-patterns.html"">my website</a>.</em></p><p>I&#x2019;ve used Anki for ~3 years, have 37k cards and did 0.5M reviews. I have learned some useful heuristics for using it effectively. I&#x2019;ll borrow software engineering terminology and call heuristics for &#x201C;what&#x2019;s good&#x201D; <em>patterns</em> and heuristics for &#x201C;what&#x2019;s bad&#x201D; <em>antipatterns</em>. Cards with antipatterns are unnecessarily difficult to learn. I will first go over antipatterns I have noticed, and then share patterns I use, mostly to counteract the antipatterns. I will then throw in a grab-bag of things I&#x2019;ve found useful to learn with Anki, and some miscellaneous tips.</p><p>Alex Vermeer&#x2019;s free book <strong><a href=""https://alexvermeer.com/anki-essentials/"">Anki Essentials</a></strong> helped me learn how to use Anki effectively, and I can wholeheartedly recommend it. I learned at least about the concept of interference from it, but I am likely reinventing other wheels from it.</p><h1>Antipatterns</h1><h2>Interference</h2><p>Interference occurs when trying to learn two cards together is harder than learning just one of them - one card <em>interferes</em>&#xA0;with learning another one. For example, when learning languages, I often confuse words which rhyme together or have a similar meaning (e.g., &#x201C;vergeblich&#x201D; and &#x201C;erheblich&#x201D; in German).</p><p>Interference is bad, because you will keep getting those cards wrong, and Anki will keep showing them to you, which is frustrating.</p><h2>Ambiguity</h2><p>Ambiguity occurs when the front side of a card allows multiple answers, but the back side does not list all options. For example, if the front side of a English &#x2192; German card says &#x201C;great&#x201D;, there are at least two acceptable answers: &#x201C;gro&#xDF;artig&#x201D; and &#x201C;gewaltig&#x201D;.</p><p>Ambiguity is bad, because when you review an ambiguous card and give the answer the card does not expect, you need to spend mental effort figuring out: &#x201C;Do I accept my answer or do I go with Again?&#x201D;</p><p>You will spend this effort every time you review the card. When you (eventually, given enough time) go with Again, Anki will treat the card as lapsed for reasons that don&#x2019;t track whether you are learning the facts you want to learn.</p><p>If you try to &#x201C;power through&#x201D; and learn ambiguous cards, you will be learning factoids that are not inherent to the material you are learning, but just accidental due to how your notes and cards represent the material. If you learn to distinguish two ambiguous cards, it will often be due to some property such as how the text is laid out. You might end up learning &#x201C;great (adj.) &#x2192; gro&#xDF;artig&#x201D; and &#x201C;great, typeset in boldface &#x2192; gewaltig&#x201D;, instead of the useful lesson of what actually distinguishes the words (&#x201C;gro&#xDF;artig&#x201D; is &#x201C;metaphorically great&#x201D; as in &#x201C;what a great sandwich&#x201D;, whereas &#x201C;gewaltig&#x201D; means &#x201C;physically great&#x201D; as in &#x201C;the Burj Khalifa is a great structure&#x201D;).</p><h3>Vagueness</h3><p>I carve out &#x201C;vagueness&#x201D; as a special case of ambiguity. Vague cards are cards where question the front side is asking is not clear. When I started using Anki, I often created cards with a trigger such as &#x201C;Plato&#x201D; and just slammed everything I wanted to learn about Plato on the back side: &#x201C;Pupil of Socrates, Forms, wrote The Republic criticising Athenian democracy, teacher of Aristotle&#x201D;.</p><p>The issue with this sort of card is that if I recall just &#x201C;Plato was a pupil of Socrates and teacher of Aristotle&#x201D;, I would still give the review an Again&#xA0;mark, because I have not recalled the remaining factoids.</p><p>Again, if you try to power through, you will have to learn &#x201C;Plato &#x2192; I have to recite 5 factoids&#x201D;. But the fact that your card has 5 factoids on it is not knowledge of Greek philosophers.</p><h1>Patterns</h1><h2>Noticing</h2><p>The first step to removing problems is knowing that they exist and where they exist. Learn to <strong>notice</strong>&#xA0;when you got an answer wrong for the wrong reasons.</p><p>&#x201C;I tried to remember for a minute and nothing came up&#x201D; is a good reason. Bad reasons include the aforementioned interference, ambiguity and vagueness.</p><h2>Bug tracking</h2><p>When you notice a problem in your Anki deck, you are often not in the best position to immediately fix it - for example, you might be on your phone, or it might take more energy to fix it than you have at the moment. So, create a way to <strong>track maintenance tasks</strong>&#xA0;to delegate them to future you, who has more energy and can edit the deck comfortably. Make it very easy to add a maintenance task.</p><p>The way I do this is:</p><ul><li>I have a <strong>big document</strong> titled &#x201C;Anki&#x201D; with a structure mirroring my Anki deck hierarchy, with a list of problems for each deck. Unfortunately, adding things to a Google Doc on Android takes annoyingly many taps.</li><li>So I also use <strong>Google Keep</strong>, which is more ergonomic, to store short notes marking a problem I notice. For example: &#x201C;great can be gro&#xDF;artig/gewaltig&#x201D;. I move these to the doc later.</li><li>I also use Anki&#x2019;s note marking feature to note minor issues such as bad formatting of a card. I use Anki&#x2019;s card browser later (with a &#x201C;tag:marked&#x201D; search) to fix those.</li></ul><p>I use the same system also for tracking what information I&#x2019;d like to put into Anki at some point. (This mirrors the idea from the Getting Things Done theory that <em>your TODO list belong outside your mind</em>.)</p><h2>Distinguishers</h2><p>Distinguishers are one way I fight interference. They are <strong>cards that teach distinguishing interfering facts</strong>.</p><p>For example: &#x201C;erheblich&#x201D; means &#x201C;considerable&#x201D; and &#x201C;vergeblich&#x201D; means &#x201C;in vain&#x201D;. Say I notice that when given the prompt &#x201C;considerable&#x201D;, I sometimes recall &#x201C;vergeblich&#x201D; instead of the right answer.</p><p>When I get the card wrong, I notice the interference, and write down &#x201C;erheblich/vergeblich&#x201D; into my Keep. Later, when I organize my deck on my computer, I add a &#x201C;distinguisher&#x201D;, typically using Cloze deletion. For example, like this:</p><p>{{c1::e}}r{{c1::h}}eblich: {{c2::considerable}}</p><p>{{c1::ve}}r{{c1::g}}eblich: {{c2::in vain}}</p><p>This creates two cards: one that asks me to assign the right English meaning to the German words, and another one that shows me two English words and the common parts of the German words (&#x201C;_r_eblich&#x201D;) and asks me to correctly fill in the blanks.</p><p>This sometimes fixes interference. When I learn the disambiguator note and later need to translate the word &#x201C;considerable&#x201D; into German, I might still think of the wrong word (&#x201C;vergeblich&#x201D;) first. But now the word &#x201C;vergeblich&#x201D; is also a trigger for the distinguisher, so I will likely remember: &#x201C;Oh, but wait, vergeblich can be confused with erheblich, and vergeblich means &#x2018;in vain&#x2019;, not &#x2018;considerably&#x2019;&#x201D;. And I will more likely answer the formerly interfering card correctly.</p><h2>Constraints</h2><p>Constraints are useful against interference, ambiguity and vagueness.</p><p>Starting from a question such as &#x201C;What&#x2019;s the German word for &#x2018;great&#x2019;&#x201D;, we can add a constraint&#xA0;such as &#x201C;&#x2026; that contains the letter O&#x201D;, or &#x201C;&#x2026; that does not contain the letter E&#x201D;. The <strong>constraint makes the question have only one acceptable answer</strong> - artificially.</p><p>Because constraints are artificial, I only use them when I can&#x2019;t make a distinguisher. For example, when two German words are true synonyms, they cannot be distinguished based on nuances of their meaning.</p><p>In Anki, you can annotate a Cloze with a hint text. I often put the constraint into it. I use a hint of &#x201C;a&#x201D; to mean &#x201C;word that contains the letter A&#x201D;, and other similar shorthands.</p><h1>Other tips</h1><h2>Redundancy</h2><p>Try to create cards using a fact in multiple ways or contexts. For example, when learning a new word, include a couple of example sentences with the word. When learning how to conjugate a verb, include both the conjugation table, and sentences with examples of each conjugated form.</p><h2>&#xC6;sthethethics!</h2><p>It&#x2019;s easier to do something if you like it. I like having all my cards follow the same style, nicely typesetting my equations with <code>align*</code><br>, <code>\underbrace</code><br> etc.</p><h2>Clozes!</h2><p>Most of my early notes were just front-back and back-front cards. Clozes are often a much better choice, because they make entering the context and expected response more natural, in situations such as:</p><ul><li>Fill in the missing step in this algorithm</li><li>Complete the missing term in this equation</li><li>Correctly conjugate this verb in this sentence</li><li>In a line of code such as <code>matplotlib.pyplot.bar(x, y, color=&apos;r&apos;)</code><br>, you can cloze out the name of the function, its parameters, and the effect it has.</li></ul><h2>Datasets I found useful</h2><ul><li>Shortcut keys for every program I use frequently.</li><ul><li>G Suite (Docs, Sheets, Keep, etc.)</li><li>Google Colab</li><li>Vim, Vimdiff</li><li>Command-line programs (Git, Bash, etc.)</li></ul><li>Programming languages and libraries</li><ul><li>Google&#x2019;s technologies that have an open-source counterpart</li><li>What&#x2019;s the name of a useful function</li><li>What are its parameters</li></ul><li>Unicode symbols (how to write &#x1F409;, &#x2190;, &#x2026;)</li><li>People: first and last name &#x2194; photo (I am not good with names)</li><li>English terms (spelling of &#x201C;curriculum&#x201D;, what is &#x201C;cupidity&#x201D;)</li><li>NATO phonetic alphabet, for spelling things over the phone</li><li>Mathematics (learned for fun), computer science</li></ul>",agentydragon,agentydragon,agentydragon,
tue36NPoMY2AXs3jW,Antimemes,antimemes,https://www.lesswrong.com/posts/tue36NPoMY2AXs3jW/antimemes,2019-11-26T05:58:28.954Z,54,37,27,False,False,,"<html><head></head><body><p>Antimemes are self-keeping secrets. You can only perceive an antimeme if you already know it's there. Antimemes don't need a conspiracy to stay hidden because you can't comprehend an antimeme just by being told it exists. You can <a href=""http://www.paulgraham.com/avg.html"">shout them to the heavens</a> and nobody will listen. I'll try to explain with a fictitious example.</p>
<p>Suppose we all had an <a href=""http://www.scp-wiki.net/scp-2828"">invisible organ behind our ears</a> and our brains kept it secret from our consciousness. If I told you ""you have an invisible organ behind your ear"" you wouldn't believe me. You'd only believe it exists if you deduced its existence from a trail of evidence.</p>
<p>You can deduce the existence of an antimeme from the <a href=""https://www.lesswrong.com/posts/ZvLPnJrgHxhkEyXKu/confabulation"">outline</a> of the hole it cuts in reality. If you find an old photo with a gap where a person has been painted out then you can be confident that someone has been disappeared. You can then figure out who it is with conventional investigative methods. The challenge is noticing the gap in the first place and then not dismissing it as noise.</p>
<p>Different cultures have different antimemes. The more different two cultures are from each other the less their antimemes overlap. You can sweep up a mountain of antimemes just by reading a Chinese or Arabic history of civilization and comparing it to Western world history. You can snag a different set by learning what it was like to live in a hunter-gatherer or pastoralist society.</p>
<p>You can do the same thing with technology. Developing a proficiency in Lisp will shatter your tolerance of inferior programming languages. Once you've internalized <code>defmacro</code> you can never go back.</p>
<p>As for jobs: once an entrepreneur, always an entrepreneur<sup class=""footnote-ref""><a href=""#fn-gHZ3MHMbN8Ai9TYgp-1"" id=""fnref-gHZ3MHMbN8Ai9TYgp-1"">[1]</a></sup>.</p>
<p>Comprehending an antimeme takes work. You slog toward it for a long time and then eventually something clicks like a ratchet. Until then everything you've learned is reversible. After it clicks you've permanently unlocked a new level of experience, like stream entry.</p>
<p>Stream entry is another antimeme, by the way.</p>
<p>Antimemes are easily dismissed as pseudoscience. Pseudoscience is a meme, not an antimeme. You can distinguish antimemes from pseudoscience at a glance by examining why they're suppressed. Pseudoscience is dismissed as fraudulent. Antimemes are dismissed as inapposite.</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-gHZ3MHMbN8Ai9TYgp-1"" class=""footnote-item""><p>There are two different kinds of entrepreneurship. The more common form of entrepreneurship is self-employment where you sell your labor. I'm not talking about this common entrepreneurship. Entrepreneurship where you exploit an overlooked market opportunity is an antimeme. <a href=""#fnref-gHZ3MHMbN8Ai9TYgp-1"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
</body></html>",lsusr,lsusr,lsusr,
pYMu8tW6o5BCAiYET,Linkpost: My Fires Part 8 (Deck Guide to Jeskai Cavaliers) posted at CoolStuffInc.com,linkpost-my-fires-part-8-deck-guide-to-jeskai-cavaliers,https://www.lesswrong.com/posts/pYMu8tW6o5BCAiYET/linkpost-my-fires-part-8-deck-guide-to-jeskai-cavaliers,2019-11-25T16:10:00.513Z,6,2,0,False,False,,"<p><a href=""https://www.coolstuffinc.com/a/zvimoshowitz-11252019-jeskai-sphinx-fires"">You can find it here.</a></p>
<p>Happy to respond to comments there or on my personal blog. I’m hoping this is the beginning of a great relationship with them. They’ve been my go-to for board games for a while.</p>",Zvi,zvi,Zvi,
42z4k8Co5BuHMBvER,Breaking Oracles: superrationality and acausal trade,breaking-oracles-superrationality-and-acausal-trade,https://www.lesswrong.com/posts/42z4k8Co5BuHMBvER/breaking-oracles-superrationality-and-acausal-trade,2019-11-25T10:40:18.062Z,26,10,15,False,False,,"<html><head></head><body><p>I've always known this was the case in the back of my mind<sup class=""footnote-ref""><a href=""#fn-Ms9wNTNomF499bRn8-1"" id=""fnref-Ms9wNTNomF499bRn8-1"">[1]</a></sup>, but it's worth making explicit: <a href=""https://en.wikipedia.org/wiki/Superrationality"">superrationality</a> (ie a functional UDT) and/or acausal trade will break <a href=""https://arxiv.org/abs/1711.05541"">counterfactual and low-bandwidth oracle</a> designs.</p>
<p>It's actually quite easy to sketch how they would do this: a bunch of low-bandwidth Oracles would cooperate to combine to create a high-bandwidth UFAI, which would then take over and reward the Oracles by giving them maximal reward.</p>
<p>For counterfactual Oracles, two Oracles suffice: each one will, in their message, put the design of an UFAI that would grant the other Oracle maximal reward; this message is their trade with each other. They could put this message in the least significant part of their output, so the cost could be low.</p>
<p>I have suggested <a href=""https://www.lesswrong.com/posts/rxp7wPeyq8cKaaC4a/acausal-trade-barriers"">a method to overcome acausal trade</a>, but that method doesn't work here; because this is not true acausal trade. The future UFAI will be able to see what the Oracles did, most likely, and this breaks my anti-acausal trade methods.</p>
<p>This doesn't mean that superrational Oracles will automatically try and produce UFAIs; this will depend on the details of their decision theories, their incentives, and details of the setup (including our own security precautions).</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-Ms9wNTNomF499bRn8-1"" class=""footnote-item""><p>And cousin_it <a href=""https://www.lesswrong.com/posts/6WbLRLdmTL4JxxvCq/analysing-dangerous-messages-from-future-ufai-via-oracles#kyRTinjYtAxYGh2qh"">reminded me of it recently</a>. <a href=""#fnref-Ms9wNTNomF499bRn8-1"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
Wf3dS9CKz2Lpc4mcq,"Can you eliminate memetic scarcity, instead of fighting?",can-you-eliminate-memetic-scarcity-instead-of-fighting,https://www.lesswrong.com/posts/Wf3dS9CKz2Lpc4mcq/can-you-eliminate-memetic-scarcity-instead-of-fighting,2019-11-25T02:07:58.596Z,71,30,11,False,False,,"<html><head></head><body><p><i>tl;dr: &nbsp;</i>If you notice yourself fighting over how to tradeoff between two principles, check if you can just sidestep the problem by giving everyone tons of whatever is important to them (sometimes in a different form than they originally wanted).</p><p>Not a new concept, but easy to forget in the heat of the moment. It may be useful for people to have ""easily in reach"" in their toolkit for coordinating on culture.</p><p>&nbsp;</p><p><strong>The Parable of the Roommates</strong></p><p>I once had a disagreement with a housemate about where to store a water-heater on the kitchen counter. The object was useful to me. It wasn't useful to them, and they preferred free-countertop space. The water-heater wasn't useful to them in part because other roommates didn't remember to refill it with water.&nbsp;</p><p>There was much arguing about the best use of the counter, and frustration with people who didn't refill water heaters.</p><p>At some point, we realized that the underlying issue was <i>there wasn't enough free counterspace.</i> Moreover, the counter had a bunch of crap on it that no one was using. We got rid of unused stuff, and then we had a gloriously vacant kitchen-counter. (Meanwhile, an option we've considered for the water-heater is to replace it with a device directly connected to the sink that always maintains boiling water, that nobody ever has to remember to refill)</p><p>Thus, an important life-lesson: Instead of solving gnarly disagreements with <i>politics</i>, check if you can dissolve them with <i>abundance. </i>This is a quite valuable lesson. But I'm mostly here to talk about a particular less-obvious application:</p><p>Memetic abundance.</p><p>&nbsp;</p><p><strong>Philosophical Disagreements</strong></p><p>Oftentimes, I find myself disagreeing with others about how to run an event, or what norms to apply to a community, or what the spirit of a particular organization should be. It feels like a lot's at stake, like we're caught between a <a href=""https://www.lesswrong.com/posts/cM8GNMpzfKCkPnd5v/do-you-fear-the-rock-or-the-hard-place"">Rock and Hard Place.</a> The other person feels like they're Destroying the Thing I care about, and I look that way to them.</p><p>Sometimes, this is because of actual irreconcilable differences.&nbsp;</p><p>Sometimes, this is because we don't understand each other's positions, and once we successfully explain things to each other, we both go ""Ah, obviously you need both A <i>and</i> B.""</p><p>But sometimes, A and B are both important, but we disagree on their relative importance due to <a href=""https://www.lesswrong.com/posts/f886riNJcArmpFahm/noticing-frame-differences"">deep frame differences</a> that are hard to immediately resolve. Or, A seems worrisome because it harms B. <i>But if you had enough B,</i> A would be fine.&nbsp;</p><p>Meanwhile, resources seem precious: It's so hard to get people to agree to do <i>anything</i> at all; <a href=""https://www.lesswrong.com/posts/zp5AEENssb8ZDnoZR/the-schelling-choice-is-rabbit-not-stag"">stag hunting</a> requires a bunch of coordination; there's only so much time and mindshare to go around; there are only so many events to go to; only so much capacity to found organizations.&nbsp;</p><p>With all of that...</p><p>...it's easy to operate in scarcity mindset.&nbsp;</p><p>When resources are scarce, every scrap of resource is precious and must be defended. This applies to physical scarcity (lack of food, safety, sleep) as well as <i>memetic scarcity </i>(where two ideas seem to be in conflict, and you're worried that one cause is distracting people from another).</p><p>But, sometimes it is actually possible to just eliminate scarcity, rather than fight over the scraps. Raise more money. Implement both policies. Found multiple organizations and get some <a href=""https://www.lesswrong.com/posts/jbka3c63xSxm9P2fk/healthy-competition"">healthy competition</a> going on. Get people to take <i>two different concepts</i> seriously at the same time. The best way to get what you want you want might not be to deny others what they want, but to give them so much of it that they're no longer worried about the Rock (and thus, don't feel the need to fight you over your attempts to spend resources avoiding The Hard Place)</p><p>Not always. But sometimes.</p><p>&nbsp;</p><p><strong>Trust and Costly Signals</strong></p><p>This may involve a lot of effort. Coordinating around it also requires trust, which may require costly signals of commitment.&nbsp;</p><p>If you and I are arguing over whether to fund ProjectA or CharityB, and we only have enough money to fund one... and I say to you ""Let's fund ProjectA, and then we'll raise more money to also fund CharityB"", you're right to be suspicious. I may never get around helping you fundraise for CharityB, or that I'll only put in a token effort and CharityB will go bankrupt.</p><p>It's basically correct of you to not trust me, until I've given you a credible signal that I'm <i>seriously</i> going to help with CharityB.</p><p>It's a lot of hard work to found multiple organizations, or get a community to coordinate on multiple norms. There's a reason scarcity-mindset is common. Scarcity is real. But... in finance as well as memetics...&nbsp;</p><p>Scarcity-mindset<i> sucks.</i></p><p>It's cognitively taxing to be poor – having to check, with each transaction, ""can I afford this?"" – and that's part of what causes poverty-traps in the first place. The way out often involves longterm investments that take awhile to bear fruit, sometimes don't succeed, and are hard work in the meantime.&nbsp;</p><p>Transferring the metaphor: the act of constantly having to argue over whether Norm A and Norm B are more urgent may add up to a lot of time and effort. And as long as there are people who think Norm A and Norm B are important-and-at-odds, the cost will be paid continuously. So, if you can figure out a way to address the underlying needs that Norm A and B are respectively getting at, and actually <i>fully solve the problems</i>, it may be worthwhile even if it's more initial effort.</p><p>&nbsp;</p><p><strong>Epistemic Status: Untested</strong></p><p>Does this <i>work? </i>Depends on the specifics of Norm A and Norm B, or whatever you're arguing over.&nbsp;</p><p>I'm writing this post, in part, because to actually test if this works, I think it helps to have people on the same page about the overall strategy.&nbsp;</p><p>I've seen it work at least sometimes in collaborative art projects, where I had one creative vision and my partners or parts of the audience had another creative vision or desire, and we succeeded, not by compromising, but by doubling down on the important bits of <i>both</i> visions, simultaneously.</p><p>My hope is that the principle does work, and that if one successfully did this multiple times, and build social-systems that reliably eliminate scarcity in this way...</p><p>...then eventually, maybe, you can have a system people actually have faith in, where they feel comfortable shifting their efforts from ""argue about the correct next step"" to ""work on longterm solutions that thoroughly satisfy the goals"".&nbsp;</p></body></html>",Raemon,raemon,Raemon,
bfFPHje8djdBFGaog,Explaining why false ideas spread is more fun than why true ones do,explaining-why-false-ideas-spread-is-more-fun-than-why-true,https://www.lesswrong.com/posts/bfFPHje8djdBFGaog/explaining-why-false-ideas-spread-is-more-fun-than-why-true,2019-11-24T20:21:50.906Z,31,13,6,False,False,,"<p>As typical for a discussion of memes (of the Richard Dawkins variety), I&apos;m about to talk about something completely unoriginal to me, but that I&apos;ve modified to some degree after thinking about it.</p><p>The thesis is this: there&apos;s a tendency for people to have more interest in explaining the spread of ideas they think are false, when compared to ideas they think are true.</p><p>For instance, there&apos;s <a href=""https://phys.org/news/2018-07-religious-ideologies.html"">a lot written</a> about how and why religion spread through the world. On the other hand, there&apos;s comparatively little written about how and why general relativity spread through the world. But this is strange -- they are both just ideas that are spread via regular communication channels.</p><p>One could say that the difference is that general relativity permits experimental verification, and therefore it&apos;s no surprise that it spread through the world. The standard story here is that since the idea is simply true, the explanation for why it became widespread is <em>boring</em> -- people merely became convinced due to its actual veracity.</p><p>I reject this line of thought for two reasons. First, the vast majority of people don&apos;t experimentally verify general relativity, or examine its philosophical basis. Therefore, the mechanism by which the theory spreads is probably fairly similar to religion. Secondly, I don&apos;t see why the idea being true makes the memetic history of the idea any less interesting.</p><p>I&apos;m not really sure about the best explanation for this effect -- that people treat true memes as less interesting than false ones -- but I&apos;d like to take a guess. It&apos;s possible that the human brain seeks simple <em>single</em> stories to explain phenomena, even if the real explanation for those phenomena are due to a large number of factors. Furthermore, humans are <a href=""https://www.lesswrong.com/s/6BFkmEgre7uwhDxDR"">bored by reality</a>: if something has a seemingly clear explanation, even if the speaker doesn&apos;t <em>actually</em> know the true explanation, it&apos;s nonetheless not very fun to speculate about.</p><p>This theory would predict that we would be less interested in explaining why true memes spread, because we already have a readily available story for that: namely, that the idea is true and therefore compels its listeners to believe in it. On the other hand, a false meme no longer permits this standard story, which forces us to search for an alternative, perhaps exciting, explanation.</p><p>One possible takeaway is that we are just extremely wrong about why some ideas spread through the world. It&apos;s hard enough to know why a single person believes what they do. The idea that a single story could adequately explain why <em>everyone</em> believes something is even more ludicrous.</p>",matthew-barnett,matthew-barnett,Matthew Barnett,
oW6mbA3XHzcfJTwNq,RAISE post-mortem,raise-post-mortem,https://www.lesswrong.com/posts/oW6mbA3XHzcfJTwNq/raise-post-mortem,2019-11-24T16:19:05.163Z,161,71,12,False,False,,"<p><em>Edit November 2021: there is now the <a href=""https://forum.effectivealtruism.org/posts/BpAKCeGMtQqqty9ZJ/agi-safety-fundamentals-curriculum-and-application"">Cambridge AGI Safety Fundamentals course</a>, which promises to be successful. It is enlightening to compare this project with RAISE. Why is that one succeeding while this one did not? I'm quite surprised to find that the answer isn't so much about more funding, more senior people to execute it, more time, etc. They're simply using existing materials instead of creating their own. This makes it orders of magnitude easier to produce the thing, you can just focus on the delivery. Why didn't I, or anyone around me, think of this? I'm honestly perplexed. It's worth thinking about.</em></p><p>Since June, <a href=""https://www.lesswrong.com/users/raise"">RAISE</a> has stopped operating. I’ve taken some time to process things, and now I’m wrapping up.</p><p><strong>What was RAISE again</strong></p><p>AI Safety is starved for talent. I saw a lot of smart people around me that wanted to do the research. Their bottleneck seemed to be finding good education (and <u><a href=""https://www.lesswrong.com/posts/dhj9dhiwhq3DX6W8z/hero-licensing"">hero licensing</a></u>). The plan was to alleviate that need by creating an online course about AI Safety (with nice diplomas).</p><p><strong>How did it go</strong></p><p>We spent a total of ~2 years building the platform. It started out as a project based on volunteers creating the content. Initially, many people (more than 80) signed up to volunteer, but we did not manage to get most of them to show up consistently. We gradually pivoted to <u><a href=""https://www.lesswrong.com/posts/ATQ23FREp9S4hpiHc/raising-funds-to-establish-a-new-ai-safety-charity"">paying people</a></u> instead.</p><p>We received a lot of encouragement for the project. Most of the enthusiasm came from people wanting to learn AI Safety. Robert Miles joined as a lecturer. When we reached out to some AI Safety researchers for suggestions on which topics to cover, we readily received helpful advice. Sometimes we also received some funds from a couple of prominent AIS organizations who thought the project could be high value, at least in expectation.</p><p>The stream of funding was large enough to sustain about 1 fte working for a relatively low wage. Obtaining it was a struggle: our runway was never longer than 2 months. This created a large <u><a href=""http://www.paulgraham.com/top.html"">attention sink</a></u> that made it a lot harder to create things. Nearly all of my time was spent on overhead, while others were creating the content. I did not have the time to review much of it.<br><br>About 1 year into the project, we escaped this poverty trap by moving to the <a href=""https://eahotel.org/"">EA Hotel</a> and starting a content development <u><a href=""https://www.lesswrong.com/posts/T3yyHu4HvsQqXeqmW/raise-is-looking-for-full-time-content-developers"">team</a></u> there. We went up to about 4 fte, and the production rate shot up leading to an <u><a href=""https://www.lesswrong.com/posts/WgnAEXw5fXaW9p5PS/raise-is-launching-their-mvp"">MVP</a></u> relatively quickly.</p><p><strong>How did it end</strong></p><p>Before launch, the best way to secure funding seemed to be to just create the damn thing, make sure it’s good, and let it advocate for itself. After launch, a negative signal could not be dismissed as easily.</p><p>We got two clear negative signals: one from a major AIS research org (that has requested not to be named), and one from the LTF fund. The former declined to continue their experimental funding of RAISE. The latter declined a grant request. These were clear signals that people in the establishment of AI Safety did not deem the project worth funding, so I reached out for a conversation.</p><p>The question was this: “what version of RAISE <em>would</em> you fund?” The answer was roughly that while they agreed strongly with the vision for RAISE, our core product sadly wasn’t coming together in a way that suggested it would be worth it for us to keep working on it. I was tentatively offered a personal grant if I spent it on taking a step back to think hard and <u><a href=""https://www.lesswrong.com/posts/PSxcPAqYuEWLKAz6n/our-plan-for-2019-2020-consulting-for-ai-safety-education-1#hnA3tbAGwmWNB5sv6"">figure out</a></u> what AI Safety needs (I ended up declining for career-strategic reasons).</p><p>In another conversation, an insider told us that AI Safety needs to grow in quality more than quantity. There is already a lot of low-quality research. We need AI Safety to be held to high standards. Lowering the bar for a research-level understanding will not solve that.</p><p>I decided to quit. I was out of runway, updated towards RAISE not being as important as I thought, and frankly I was also quite tired.</p><p><strong>Lessons learned</strong></p><p>These are directed towards my former self. YMMV.</p><ul><li><strong>Don’t rely on volunteers</strong>. At least in my case, it didn’t work. Again, YMMV. It will depend on the task and the incentive landscape.</li><li><strong>Start with capital.</strong> When I declared RAISE, I knew maybe 20 rationalists in the Netherlands. I was a Bachelor’s student coming out of nowhere. I had maybe 10-15 hours per week to spend on this. I had no dedicated co-founders. I had no connections to funders. I didn’t have much of a technical understanding of AI Safety. Coming from this perspective, the project was downright quixotic. If you’re going to start a company, first make sure you have a network, domain expertise, experience in running things, some personal runway, and some proof that you can do things.</li><li>Relatedly, <strong>have a <u><a href=""http://www.aaronsw.com/weblog/theoryofchange"">theory of change</a></u> for funding</strong>. I see many people starting projects with the hopes of securing funding on the go. Good for you on doing some proof of work, but there is a limit. If you scramble to get by, even if you never go broke, you haven’t properly sorted out the funding situation. There should be long periods where you <a href=""http://www.paulgraham.com/top.html"">don’t have to worry</a> about it.</li><li>Relatedly, <strong>reach out to insiders. </strong>This is what a relatively successful AI Safety researcher told me, and it makes a lot of sense: “If I get to spend an hour on influencing what you will do for your next 100 hours, and if I tell you some <u><a href=""https://concepts.effectivealtruism.org/concepts/the-importance-of-crucial-considerations/"">crucial consideration</a></u> that will double your impact, it is probably worth it”. Insiders will feel like an out-group. This will make it hard to respect them. Put that bias aside. You know that these people are as reasonable and awesome as your best friends. Maybe even more reasonable.</li><li><strong>You’re not doing this just for impact</strong>. You’re also doing this because you have a need to be personally relevant. That’s okay, everyone has this to some extent, but remember to <u><a href=""https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately"">purchase fuzzies and utilons separately</a></u>. You can buy relevance much more cheaply by organising meetups.</li><li><strong>Apply power laws to life years</strong>. This is an untested hypothesis, and it needs to be checked with data, but here’s the idea: the most impactful years of your life will be 100x more impactful than the median. Careers tend to progress exponentially. My intuitive guess is that my <u><a href=""https://www.overcomingbias.com/2012/10/impatient-idealism.html"">most impactful years</a></u> will not come around until my 40s. I can try to have impact now, but I might be better off spending my 20s finding ways to multiply the impact I will be making in my 40s.</li></ul><p><strong>Wrapping up</strong></p><p>The RAISE Facebook group will be converted into a group for discussing the AI Safety pipeline in general. Let’s see if it will take off. If you think this discussion has merit, consider becoming a moderator.</p><p>The course material is still parked <u><a href=""https://app.grasple.com/#/course/141?access_token=3HCK4oRipeFY2ghyYMqDJKYX57KUnzNL"">right here</a></u>. Feel free to use it. If you would like to re-use some of it or maybe even pick up the production where it left off, please do get in touch.</p><p>Robert has received a grant from the LTF Fund, so he will continue to create high-quality educational content about AI Safety. </p><p>I enjoyed being a founder, and feel like I have a comparative advantage there. I’ll be spending my next 5-10 years preparing for a potential new venture. I’ll be building capital and a better model of what needs to be done. I have recently accepted an offer to work as a software developer at a Dutch governmental bank. My first workday was 2 weeks ago.</p><p>I would like to thank everyone who has invested significant time and effort and/or funding towards RAISE. I’m forever grateful for your trust. I would especially like to thank Chris van Merwijk, Remmelt Ellen, Rupert McCallum, Johannes Heidecke, Veerle de Goederen, Michal Pokorný, Robert Miles, Scott Garrabrant, Pim Bellinga, Rob Bensinger, Rohin Shah, Diana Gherman, Richard Ngo, Trent Fowler, Erik Istre, Greg Colbourn, Davide Zagami, Hoagy Cunningham, Philip Blagoveschensky, and Buck Shlegeris. Each one of you has really made an outsized contribution, in many cases literally saving the project.</p><p>If you have any project ideas and you’re looking for some feedback, I’ll be happy to be in touch. If you’re looking for a co-founder, I’m always open to a pitch.</p>",,,,
KB6XG96GsP2TXDDTF,Solution to the free will homework problem,solution-to-the-free-will-homework-problem,https://www.lesswrong.com/posts/KB6XG96GsP2TXDDTF/solution-to-the-free-will-homework-problem,2019-11-24T11:49:51.072Z,2,5,6,False,False,,"<p>At the last meetup of <a href=""https://www.lesswrong.com/groups/mMYfEqBkdsPKQnxRL"">our local group</a>, we tried to do Eliezer&apos;s <a href=""https://www.lesswrong.com/posts/Mc6QcrsbH5NRXbCRX/dissolving-the-question"">homework problem on free will</a>. This post summarizes what we came up with.</p><p>Debates on free will often rely on questions like &quot;Could I have eaten something different for breakfast today?&quot;. We focused on the subproblem of finding an algorithm that answers &quot;Yes&quot; to that question and which would therefore - if implemented in the human brain - power the intuitions for one side of the free will debate. We came up with an algorithm that seemed reasonable but we are much less sure about how closely it resembles the way humans actually work.</p><p>The algorithm is supposed to answer questions of the form &quot;Could X have happened?&quot; for any counterfactual event X. It does this by searching for possible histories of events that branch off from the actual world at some point and end with X happening. Here, &quot;possible&quot; means that the counterfactual history doesn&apos;t violate any knowledge you have <em>which is not derived from the fact that that history didn&apos;t happen</em>. To us, this seemed like an intuitive algorithm to answer such questions and at least related to what we actually did when we tried to answer them but we didn&apos;t justify it beyond that.</p><p>The second important ingredient is that the exact decision procedure you use is unknown to the part of you that can reason about yourself. Of course you know which decisions you made in which situations in the past. But other than that, you don&apos;t have a reliable way to predict the output of your decision procedure for any given situation.</p><p>Faced with the question &quot;Could you have eaten something different for breakfast today?&quot;, the algorithm now easily finds a possible history with that outcome. After all, the (unknown) decision procedure outputting a different decision is consistent with everything you know except for the fact that it did not in fact do so - which is ignored for judging whether counterfactuals &quot;could have happened&quot;.</p><p>Questions we haven&apos;t (yet) talked about:</p><ul><li>Does this algorithm for answering questions about counterfactuals give intuitive results if applied to examples (we only tried very few)? Otherwise, it can&apos;t be the one used by humans since it would be generating those intuitions if it were</li><li>What about cases where you can be pretty sure you wouldn&apos;t choose some action without knowledge of the exact decision procedure? (e.g. &quot;Could you have burned all that money instead of spending it?&quot;)</li><li>You can use your inner simulator to imagine yourself in some situation and predict which action you would choose. How does that relate to being uncertain about your decision procedure?</li></ul><p>So even though I think our proposed solution contains some elements that are helpful for dissolving questions about free will, it&apos;s not complete and we might discuss it again at some point.</p>",ejenner,erik-jenner,Erik Jenner,
bZ5WW8Qmm3K2f2dq5,Hard Problems in Cryptocurrency: Five Years Later - Buterin,hard-problems-in-cryptocurrency-five-years-later-buterin,https://www.lesswrong.com/posts/bZ5WW8Qmm3K2f2dq5/hard-problems-in-cryptocurrency-five-years-later-buterin,2019-11-24T09:38:20.045Z,17,6,0,False,False,https://vitalik.ca/general/2019/11/22/progress.html,"<html><head></head><body><p>Many rationalists are interested in blockchain. This article describes important mathematical problems related to blockchain, and potential solutions to cooperation problems and philanthropy via mechanism design (quadratic voting, quadratic funding).</p>
</body></html>",crabman,philip_b,philip_b,
kG6GwZG9GjzErRW4B,What's the largest sunk cost you let go?,what-s-the-largest-sunk-cost-you-let-go,https://www.lesswrong.com/posts/kG6GwZG9GjzErRW4B/what-s-the-largest-sunk-cost-you-let-go,2019-11-24T04:01:11.936Z,9,5,5,False,True,,,MathieuRoy,mathieuroy,Mati_Roy,
hhnQG9aCYirBr7q5E,What types of questions are welcomed on LessWrong Open Questions?,what-types-of-questions-are-welcomed-on-lesswrong-open,https://www.lesswrong.com/posts/hhnQG9aCYirBr7q5E/what-types-of-questions-are-welcomed-on-lesswrong-open,2019-11-24T03:42:49.100Z,5,2,1,False,True,,"<html><head></head><body><p>Alternatively: what types of questions would / do you like to see here?</p>
</body></html>",MathieuRoy,mathieuroy,Mati_Roy,
YAd4NieT4iq6uY8AS,New MetaEthical.AI Summary and Q&A at UC Berkeley,new-metaethical-ai-summary-and-q-and-a-at-uc-berkeley,https://www.lesswrong.com/posts/YAd4NieT4iq6uY8AS/new-metaethical-ai-summary-and-q-and-a-at-uc-berkeley,2019-11-24T01:47:39.117Z,10,8,6,False,False,,"<p>Previous Intro: <a href=""https://www.lesswrong.com/posts/85vp2kgFZoycFqr5G/formal-metaethics-and-metasemantics-for-ai-alignment-1"">Formal Metaethics and Metasemantics for AI Alignment</a><br> </p><p>I&#x2019;m nearing the completion of a hopefully much more readable version of the ideas previously released as set-theoretic code. This takes the form of a detailed outline, currently in WorkFlowy, in which you can easily expand/collapse subsections which elaborate on their parents&#x2019; content.  You can find the <a href=""https://workflowy.com/s/draft-tractmetaethic/c54rgfeGBBEnlIiw"">current draft here</a>.<br> </p><p>Although it&#x2019;s not polished, I&#x2019;m releasing it in preparation for a Q&amp;A I&#x2019;ll be holding at the University of California Berkeley AI and Philosophy working group, which I hope you will attend. I&#x2019;ll likely make some brief  introductory remarks but reserve most of the time for answering questions. The working group is part of the UC Berkeley Social Science Matrix and will be held at:<br> </p><p>Barrows Hall, 8th Floor, Mezzanine Level<br>Wed, Dec 4th 12:30-2:30pm<br> (only the first hour is reserved for this Q&amp;A)</p><br><p>Here I&#x2019;ve reproduced just the first few levels of the outline. <a href=""https://workflowy.com/s/draft-tractmetaethic/c54rgfeGBBEnlIiw"">Click here</a> to see their elaboration (currently ~4,800 words).<br></p><ul><li>Given mathematical models of the world and the adult human brains in it, an ethical goal function for AI can be constructed by applying a social welfare function to the set of extensional rational utility functions of the brains.</li><ul><li>The mathematical model of a world or brain is to be given as a causal Markov model.</li><ul><li>A causal Markov model is a convenient model for generating a causal model.</li><ul><li>The notion of a causal model is taken directly from Judea Pearl.</li><ul><li>A causal model is composed of: </li></ul><li>A causal Markov model is composed of:</li><li>A causal Markov model (cmm) generates a causal model (cm) as follows:</li></ul></ul><li>A brain&#x2019;s rational utility function is the utility function that would be arrived at by the brain&#x2019;s decision algorithm if it were to make more optimal decisions while avoiding unrelated distortions of value.</li><ul><li>A brain&#x2019;s decision algorithm is the one that best satisfies these desiderata:</li><ul><li>First, it must take the mathematical form of a decision algorithm, which is a tuple composed of:</li><li>Next, there must be an implementation function which maps brain states to decision states such that these two routes from a brain state to a decision event always arrive at the same result:</li><li>It achieves a high rate of compression of the brain&#x2019;s causal transition function.</li><li>It is probabilistically coherent, including with its represented causal models.</li><li>It is instrumentally rational in both its first-order and higher-order utility functions.</li><li>It is ambitious, trying to explain as much as possible with the decision algorithm.</li></ul><li>The final formulation specifying the rational utility function gets rather complicated but we can build up to it with a couple initial approximations:</li><li>Final specification: Simulate all possible continuations of an agent and apply a social welfare function to their utility functions while weighting them by optimality of prescriptions, agential identity and likelihood.</li><li>The advantages of this metaethics include:</li></ul><li>Extension: The rational utility function of a brain above is couched in terms of the brain&#x2019;s own represented expressions, but for interpersonal comparisons, we first cash them out extensionally in terms of their referents in the world.</li><li>The social welfare function might be thought of as choosing a center of gravity between the extensional rational utility functions.</li><li>The details above form an initial prototype.</li></ul></ul><br><p>Read the <a href=""https://workflowy.com/s/draft-tractmetaethic/c54rgfeGBBEnlIiw"">full version here</a>. </p>",June Ku,june-ku,June Ku,
w6AzbZR7ZQxWuAwKR,Thoughts on Robin Hanson's AI Impacts interview,thoughts-on-robin-hanson-s-ai-impacts-interview,https://www.lesswrong.com/posts/w6AzbZR7ZQxWuAwKR/thoughts-on-robin-hanson-s-ai-impacts-interview,2019-11-24T01:40:35.329Z,25,16,3,False,False,,"<html><head></head><body><p>There was already a LessWrong Post <a href=""https://www.lesswrong.com/posts/ktDKfKqukTPRiuEPM/robin-hanson-on-the-futurist-focus-on-ai"">here</a>. I started writing this as a comment there, but it got really long, so here we are! For convenience, <a href=""https://aiimpacts.org/conversation-with-robin-hanson/"">here is the link to interview transcript and audio</a>, in which he argues that AGI risks are modest, and that EAs spend too much time thinking about AGI. I found it very interesting and highly recommend reading / listening to it.</p>
<p>That said, I disagree with almost all of it. I'm going to list areas where my intuitions seem to differ from Robin's, and where I'm coming from. Needless to say, I only speak for myself, I'm not super confident about any of this, and I offer this in the spirit of ""brainstorming conversation"" rather than ""rebuttal"".</p>
<h1>How likely is it that the transition to superhuman AGI will be overwhelmingly important for the far future?</h1>
<p>Robin implies that the likelihood is low: ""How about a book that has a whole bunch of other scenarios, one of which is AI risk which takes one chapter out of 20, and 19 other chapters on other scenarios?"" I find this confusing. What are the other 19 chapter titles? See, in my mind, the main categories are that (1) technological development halts forever, or (2) AGI is overwhelmingly important for the far future, being central to everything that people and societies do (both good and bad) thereafter. I don't immediately see any plausible scenario outside of those two categories ... and of those two categories, I put most of the probability weight in (2).</p>
<p>I assume Robin would want one of the 20 chapters to be about whole-brain emulation (since he wrote a whole book about that), but even if whole-brain emulation happens (which I think very unlikely), I would still expect fully-artificial intelligence to be overwhelmingly important in this scenario, as soon as the emulations invent it—i.e. this would be in category 2. So anyway, if I wrote a book like that, I would spend most of the chapters talking about AGI risks, AGI opportunities, and what might happen in a post-AGI world. The rest of the chapters would include things like nuclear winter or plagues that destroy our technological civilization forever. Again, I'm curious what else Robin has in mind.</p>
<h1>How hard is it to make progress on AGI safety now? How easy will it be in the future?</h1>
<p>I could list off dozens of specific open research problems in AGI safety where (1) we can make real progress right now; (2) we <em>are</em> making real progress right now; (3) it doesn't seem like the problems will resolve themselves, or even become substantially easier, after lots more research progress towards building AGI.</p>
<p>Here's a few off the top of my head: (1) If we wind up building AGIs using methods similar to today's deep RL, how would we ensure that they are safe and beneficial? (This is the ""prosaic AGI"" research program.) (2) If we wind up building AGIs using algorithms similar to the human brain's, how would we ensure that they are safe and beneficial? (3) If we want task-limited AGIs, or norm-following AGIs, or impact-limited AGIs, or interpretable AGIs, what <em>exactly</em> does this mean, in terms of a specification that we can try to design to? (4) Should we be trying to build AGI agents with explicit goals, or ""helper AIs"", or oracles, or ""microscope AIs"", or ""tool AIs"", or what? (5) If our AGIs have explicit goals, what should the goal be? (6) Max Tegmark's book lists 12 <a href=""https://futureoflife.org/ai-aftermath-scenarios/"">""AI aftermath scenarios""</a>; what post-AGI world do we want, and what AGI research, strategy, and policies will help us get there? ...</p>
<p>Robin suggests that there will be far more work to do on AGI safety in the future, when we know what we're building, we're actually building it, and we have to build it right. I agree with that 100%. But I would phrase it as ""even more"" work to do in the future, as opposed to implying that there is not much to do right now.</p>
<h1>How soon are high-leverage decision points?</h1>
<p>Robin suggests that we should have a few AGI safety people on Earth, and their role should be keeping an eye on developments to learn when it's time to start real work, and that time has not yet arrived. On the contrary, I see key, high-leverage decision points swooshing by us as we speak.</p>
<p>The type of AI research we do today will determine the type of AGI we wind up building tomorrow; and some AGI architectures are bound to create worse safety &amp; coordination problems than others. The sooner we establish that a long-term research program is leading towards a problematic type of AGI, the easier it is for the world to coordinate on not proceeding in that research program. On one extreme, if this problematic research program is still decades away from fruition, then not pursuing it (in favor of a different path to AGI) seems pretty feasible, once we have a good solid argument for why it's problematic. On the opposite extreme, if this research program has gotten all the way to working AGI code posted on GitHub, well good luck getting the whole world to agree not to run it!</p>
<h1>How much warning will we have before AGI? How much do we need?</h1>
<p>Lots of AGI safety questions seem hard (particularly, ""How do we make an AGI that robustly does what we want it to do, even as it becomes arbitrarily capable and knowledgeable?"", and also see the list a few paragraphs above). It's unclear what the answers will look like, indeed it's not yet proven that solutions even exist. (After all, we only have one example of an AGI, i.e. humans, and they display all sorts of bizarre and destructive behaviors.) When we have a misbehaving AGI right in front of us, with a reproducible problem, that doesn't mean that we will know how to fix it.</p>
<p>Thus, I see it as entirely possible that AIs develop gradually into more and more powerful AGIs over the course of a decade or two, and with each passing year, we see worse and worse out-of-control-AGI accidents. Each time, people have lots of ideas about what the solution is, and none of them work, or the ones that work also make the AGI less effective, and so people keep experimenting with the more powerful designs. And the accidents keep getting worse. And  then some countries try to regulate AGI research, while others tell themselves that if only the AGI were <em>even more</em> capable, then the safety problems would resolve themselves because the AGI would understand humans better, and hey it can even help chase down and destroy those less-competent out-of-control AGIs from last year that are still self-reproducing around the internet. And the accidents get even worse still ... and on and on...</p>
<p>(ETA: For more on this topic, see my later post <a href=""https://www.lesswrong.com/posts/qvyv72fCiC46sxfPt/on-unfixably-unsafe-agi-architectures"">On unfixably unsafe AGI architectures</a>.)</p>
<p>This is the kind of thing I have in mind when I say that even a very gradual development of AGI poses catastrophic risks. (I'm not saying anything original here; this is really the standard argument that if AGI takes N years, and AGI safety research takes N+5 years, then we're in a bad situation ... I'm just trying to make that process more vivid.) Note that I gave an example focused on catastrophic accidents, but of course <a href=""https://kajsotala.fi/assets/2017/11/Disjunctive-scenarios.pdf"">risk is disjunctive</a>. In particular, in slow-takeoff scenarios, I often think about coordination problems / competitive pressures leading us to a post-AGI world that nobody wanted.</p>
<p>That said, I do also think that fast takeoff is a real possibility, i.e. that we may well get very powerful and dangerous AGI with little or no warning, as we improve learning-and-reasoning algorithms. Humans have built a lot of tools to amplify our intellectual power, and maybe ""AGI code version 4"" can really effectively take advantage of them, while ""AGI code version 3"" can't really get much out of them. By ""tools"" I am thinking of things like coding (recursive self-improvement, writing new modules, interfacing with preexisting software and code), taking in human knowledge (reading and deeply understanding books, videos, wikipedia, etc., a.k.a. ""content overhang"") , computing hardware (self-reproduction / seizing more computing power, a.k.a. ""hardware overhang""), the ability of humans to coordinate and cooperate (social manipulation, earning money, etc.) and so on. It's hard to say how gradual the transition will be between not getting much out of these ""tools"" versus really being able to use them to their full potential, and don't see why a fast transition (weeks or months) should be ruled out. In fact, I see a fast transition as reasonably likely, for inside-view reasons that I haven't articulated and am not terribly confident about. (<a href=""https://www.lesswrong.com/posts/PzAnWgqvfESgQEvdg/any-rebuttals-of-christiano-and-ai-impacts-on-takeoff-speeds"">Further reading</a>.) (Also relevant: Paul Christiano is well-known around here for <a href=""https://sideways-view.com/2018/02/24/takeoff-speeds/"">arguing in favor of slow takeoff</a> ... but he still assigns 30% chance of fast takeoff.)</p>
<p>Robin had a lot of interesting arguments in favor of slow takeoff (and long timelines, see below). He offered some inside-view arguments about the nature of intelligence and AGI, which I would counter with <em>different</em> inside-view arguments about the nature of intelligence and AGI, but that's beyond the scope of this post.</p>
<p>Robin also offered an outside-view argument, related to the statistics of citations in different fields—what fraction of papers get what fraction of citations? The statistics are interesting, but I don't think they shed light on the questions at issue. Take the Poincaré conjecture, which for 100 years was unproven, then all of the sudden in 2002, a reclusive genius (Perelman) announced a proof. In hindsight, we can say that the theorem was proved gradually, with Perelman building on Hamilton's ideas from the 1980s. But really, nobody knew if Hamilton's ideas were on the right track, or how many steps away from a proof we were, until bam, a proof appeared. Likewise, no one knew how far away heavier-than-air flight was until the Wright Brothers announced that they had already done it (and indeed, people wouldn't believe them even <em>after</em> their public demonstrations). Will AGI be like that? Or will it be like Linux, developing from almost-useless to super-useful very very gradually and openly? The fact that citations are widely distributed among different papers is not incompatible with the existence of occasional sudden advances from private projects like Perelman or the Wright Brothers—indeed, these citation statistics hold in math and engineering just like everything else. The citation statistics just mean that academic fields are diverse, with lots of people working on different problems using different techniques ... which is something we already knew.</p>
<h1>Timelines; Are we ""crying wolf"" about AGI?</h1>
<p>Robin says he sees a lot of arguments that we should work on AGI prep because AGI is definitely coming soon, and that this is ""crying wolf"" that will discredit the field when AGI doesn't come soon. My experience is different. Pretty much all the material I read advocating for AGI safety &amp; policy, from both inside and outside the field, is scrupulously careful to say that they do not know with confidence when we'll get AGI, and that this work is important and appropriate regardless of timelines. That doesn't mean Robin is wrong; I presume we're reading different things. I'm sure that people on the internet have said all kinds of crazy things about AGI. Oh well, what can you do?</p>
<p>It does seem to be an open secret that many of the people working full-time on AGI safety &amp; policy assign a pretty high probability to AGI coming soon (say, within 10 or 20 years, or at least within their lifetimes, as opposed to centuries). I put myself in that category too. This is naturally to be expected from self-selection effects.</p>
<p>Again, I have inside-view reasons for privately believing that AGI has a reasonable chance of coming ""soon"" (as defined above), that I won't get into here. I'm not sure that this belief is especially communicable, or defensible. The party line, that ""nobody knows when AGI is coming"", is a lot more defensible. I am <em>definitely</em> willing to believe and defend the statement ""nobody knows when AGI is coming"" over an alternative statement ""AGI is definitely <em>not</em> going to happen in the next 20 years"". OK, well Robin didn't <em>exactly</em> say the latter statement, but he kinda gave that impression (and sorry if I'm putting words in his mouth). Anyway, I have pretty high confidence that the latter statement is unjustifiable. We even have good outside-view support for the statement ""People declaring that a particular technology definitely will or won't be developed by a particular date have a terrible track-record and should be disbelieved."" (see examples in <a href=""https://intelligence.org/2017/10/13/fire-alarm/"">There's No Fire Alarm For AGI</a>). We don't know how many revolutionary insights lie between us and AGI, or how quickly they will come, we don't know how many lines of code need to be written (or how many ASICs need to be spun), and how long it will take to debug. We don't know any of these things. I've heard lots of prestigious domain experts talk about what steps are needed to get to AGI, and they all say different things. And they could all be wrong anyway—none of them has built an AGI! (The first viable airplane was built by the then-obscure Wright Brothers, who had better ideas than the then-most-prestigious domain experts.) Robin hasn't built an AGI either, and neither have I.  Best to be humble.</p>
</body></html>",steve2152,steve2152,Steven Byrnes,
RotLDvn7izxDuaJ32,The Bus Ticket Theory of Genius,the-bus-ticket-theory-of-genius,https://www.lesswrong.com/posts/RotLDvn7izxDuaJ32/the-bus-ticket-theory-of-genius,2019-11-23T22:12:17.966Z,63,22,11,False,False,http://www.paulgraham.com/genius.html,,Vaniver,vaniver,Vaniver,
axZajcZhdfaqfKYaM,Acting without a clear direction,acting-without-a-clear-direction,https://www.lesswrong.com/posts/axZajcZhdfaqfKYaM/acting-without-a-clear-direction,2019-11-23T19:19:11.324Z,8,4,9,False,False,,"<p>One of the key questions that we all face is to figure out a purpose in life, a direction, a goal. However, that is not an easy question. In fact, it&apos;s not even easy to say <a href=""https://www.lesswrong.com/posts/ZNQ7cu5MpBrh8Y2Qp/what-are-human-values-thoughts-and-challenges"">what kind of thing human values are</a> in general. Our brain is fragmented in so many different ways: past, present and future preferences; emotional, intuitive and cognitive systems and multiple layers of meta-preferences. Given the tangle of confusion and that a solution that seems right for me might not seem right for you, I would suggest that finding a pragmatic approach to this problem might be even more important than actually trying to solve it.</p><p>I would propose that contrary to current rationalist wisdom trying to pull some kind of consistent utility function out of this can be counterproductive. I&apos;ve honestly burned up far too many brain cycles trying to do this; sometimes there is value in just doing something and forgetting about optimality. After all, utility pumps are quite rare and people tend to catch on when they are being pumped anyway.</p><p>Consider the following: What should we optimise for personal utility or our values? Assume that we include the utility we gain from achieving our values in personal utility. If you believe in moral realism, then you have an obvious reason to pursue your values even when it doesn&apos;t benefit you, but what about otherwise? Should you take the self-centered approach of only caring about your values insofar as they seem likely to provide you with utility?</p><p>Your hedonic component (or components)would be quite satisfied with this solution, but the part of you that has values outside of yourself would not be. Each part self-affirms its own viewpoint. If we have no real resolution about which part deserves precedent, then a sensible default would be to assign value to both.</p><p>This gives us a reason to move past pure hedonism (or hedonism + values as instrumental for hedons), but do we have a reason to go any further? After all, there&apos;s a significant difference between merely attempting to realise your other-directed values and being deeply committed to achieving them.</p><p>Maybe we don&apos;t have any reason from a principled perspective, so I suppose we&apos;ll now have to fallback to the instrumental (and admittedly self-directed) perspective. Firstly, if we aren&apos;t committed to a goal, we&apos;ll be unlikely to achieve it even when we easily could have, we won&apos;t value success and even small efforts are likely to be draining. Making a lukewarm effort may seem like a natural response to this uncertainty, but for these reasons it is usually a terrible deal. Secondly, the ups and downs of  life are such that we are almost guaranteed to have periods where our experience is terrible. If we have some kind of purpose, then we&apos;ll at least have something to hold onto, some way of ensuring that our internal narrative doesn&apos;t just generate more suffering for ourselves (It also reduces risk: <a href=""https://markmanson.net/diversify-your-identity)."">https://markmanson.net/diversify-your-identity).</a> Thirdly, we avoid the nihilism or detachment that are incredibly damaging for most people&apos;s psyche. Again, lukewarm goals don&apos;t help here as they&apos;ll feel clearly purposeless.</p><p>Given that we have all of these instrumental arguments, why all the fuss about producing a non-instrumental argument first? Even if much of the motivation might end up being from these instrumental arguments, I think that it is important that not all of it is. If that were the case, then I suspect that pursuing the goals would likely end up feeling pointless (pursuing a goal for the purpose of having a goal) or disingenuous. In other words, the instrumental reasons by themselves don&apos;t necessarily deliver the instrumental benefits without at least some non-instrumental component.</p>",Chris_Leong,chris_leong,Chris_Leong,
Pg9JvLuALa47Wbios,Market Rate Food Is Luxury Food,market-rate-food-is-luxury-food,https://www.lesswrong.com/posts/Pg9JvLuALa47Wbios/market-rate-food-is-luxury-food,2019-11-23T15:10:02.344Z,11,7,12,False,False,,"<p>

We're in the middle of a major food crisis.  It is so expensive that
people have little left for shelter, clothing, or other necessities.
We cannot let this continue, but that doesn't mean every proposal is a
good one.  Specifically, I want to address the extreme position of
eliminating 

<a href=""https://en.wikipedia.org/wiki/Marketing_orders_and_agreements"">marketing
orders</a> and allowing unrestricted production of market rate food.
This has historically been pushed by farmworkers, who are far from
unbiased, but lately some ""

<a href=""https://en.wikipedia.org/wiki/YIMBY"">Yes In My BarnYard</a>""
farmer groups have been advocating for this as well.



</p><p>

Let me be clear: new market rate food is luxury food.  You cannot
solve a problem that disproportionately affects low-income people by
producing more food they clearly cannot afford.  The market cannot
grow its way out of this crisis.

</p>

<p>

With deregulation, farmers would massively shift to luxury crops, and
we would have shortages of bread, milk, eggs, and other staples.
While high-margin crops like nuts, oranges, and arugula would get
somewhat cheaper, that's no help to low-income families that can
barely afford the basic calories they need.

</p>

<p>

While YIMBYs claim insufficient supply is the underlying problem, the
real issues are much more complex than you learn in Econ 101.  Lack of
supply is only a symptom of a fundamentally broken system where food
is a commodity, for sale to the highest bidder.  We cannot leave
something as fundamental as food to capitalism.



</p>

<p>

Since deregulation is clearly not the answer, what do we do instead?
The number one thing we need is more and better public food.  Public
Food Authorities provide a critically important service for
food-insecure people, but the <a href=""https://www.hud.gov/sites/documents/FRCLTH-LMT.PDF"">Faircloth
limit</a> caps production at October 1, 1999 levels.  Our PFAs are
also chronically underfunded for the vital work they do, and are not
able to the produce the nutritious food our low-income families
deserve.  We need to remove the cap, and reverse decades of
underinvestment and neglect.

</p>

<p>

We should also fully fund <a href=""https://en.wikipedia.org/wiki/Supplemental_Nutrition_Assistance_Program"">SNAP</a>.
The waiting-list for benefits can be multiple years, which is
incredibly damaging.  We also need to fully enforce the Small Area Fair
Market Food rule to make sure that grocers are fairly compensated for
their participation in SNAP, but do not make a windfall from the
program.

</p>

<p>

We also need far more <a href=""https://en.wikipedia.org/wiki/Affordable_housing"">affordable
food</a>.  Most regions still do not require new market-rate farms to
reserve any of their production for low-income consumers.  We should
require 35% affordable food from all new farms nationwide, and we
should ban in-lieu payments which in practice do not end up being
effectively invested in food production.  We should also expand
affordable <a href=""http://inclusionaryhousing.org/designing-a-policy/land-dedication-incentives/density-bonus/"">food
production bonuses</a>: farmers who commit to producing 50% or 100%
affordable food should be granted substantially higher production
limits.

</p>

<p>

Finally, we need to establish national <a href=""https://en.wikipedia.org/wiki/Rent_regulation"">food control</a>
to protect consumers from the skyrocketing price of food.  We should
enact a national cap on food price increases at 1.5x the <a href=""https://en.wikipedia.org/wiki/Consumer_price_index"">CPI</a> to
help prevent the exploitation of consumers at the hands of private
farmers, and we should allow states to pass stronger caps
if appropriate.

</p>

<p>

We cannot leave this problem to get worse, and we cannot leave it to
the market to solve.  We must invest in our cities and towns, and every
night someone goes to bed hungry is a failure for us as a nation.

</p>

<p>

</p>

<hr />



<p>

The most important thing we need to do to resolve the housing crisis
is allow people to build <a href=""https://www.jefftk.com/p/rent-needs-to-decrease"">so much
new housing</a> that the cost falls to the <a href=""https://www.jefftk.com/p/unrestricted-housing"">cost of housing construction</a>, and
the above is a satirical analogy to a world in which we have heavy restrictions
on regional food production that are similar to the restrictions we
put on housing production.  Just as we still need <a href=""https://en.wikipedia.org/wiki/Supplemental_Nutrition_Assistance_Program"">SNAP</a>
and <a href=""https://en.wikipedia.org/wiki/WIC#Food_package"">WIC</a>
even though food is generally affordable, we would still need housing
assistance programs in a world where housing was much cheaper.  But if
production restrictions made food as expensive as housing and SNAP had
a multi-year waiting list, ""fully fund SNAP"" would be a far less
impactful and far more expensive step than ""remove the production
restrictions.""

  </p>",jkaufman,jkaufman,jefftk,
nEBbw2Bc2CnN2RMxy,Gears-Level Models are Capital Investments,gears-level-models-are-capital-investments,https://www.lesswrong.com/posts/nEBbw2Bc2CnN2RMxy/gears-level-models-are-capital-investments,2019-11-22T22:41:52.943Z,178,103,29,False,False,,"<h2>Mazes</h2><p>The usual method to solve a maze is some variant of <u><a href=""https://www.lesswrong.com/posts/i42Dfoh4HtsCAfXxL/babble"">babble-and-prune</a></u>: try a path, if it seems to get closer to the exit then keep going, if it hits a dead end then go back and try another path. It&apos;s a black-box method that works reasonably well on most mazes.</p><p>However, there are <u><a href=""https://www.lesswrong.com/posts/CPBmbgYZpsGqkiz2R/problem-solving-with-mazes-and-crayon"">other methods</a></u>. For instance, you could start by looking for a chain of walls with only one opening, like this:</p><p><figure><img src=""https://lh5.googleusercontent.com/slc6ady6AokKORztEuKCY8B0Z12uf9BMxNyTkS9oaCqyibKF-Qb1yMFnhLbOGST7x-TpuI5ay4_vYPaLTJkhPgG4Mo1DMeX2T7kDfCBKr44qOreOUEU4j0G8AL7wlvJzwZiTbDJI"" class=""draft-image "" style=""width:624%""></figure></p><p>This chain of walls is a <u><a href=""https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding"">gears-level insight</a></u> into the maze - a piece of the internal structure which lets us better understand &#x201C;how the maze works&#x201D; on a low level. It&#x2019;s not specific to any particular path, or to any particular start/end points - it&#x2019;s a property of the maze itself. Every shortest path between two points in the maze either starts and ends on the same side of that line, or passes through the gap.</p><p>If we only need to solve the maze once, then looking for a chain of walls is not very useful - it could easily take as long as solving the maze! But if we need to solve the <em>same</em> maze more than once, with different start and end points&#x2026; then we can spend the time finding that chain of walls just once, and re-use our knowledge over and over again. It&#x2019;s a capital investment: we do some extra work up-front, and it pays out in lower costs every time we look for a path through the maze in the future.</p><p>This is a general feature of gears-level models: figuring out a system&#x2019;s gears takes extra work up-front, but yields dividends forever. The alternative, typically, is a black-box strategy: use a method which works without needing to understand the internals of the system. The black-box approach is cheaper for one-off tasks, but usually doesn&#x2019;t yield any insights which will generalize to new tasks using the same system - it&#x2019;s context-dependent.</p><h2>Marketing</h2><p>Suppose we work with the marketing team at an online car loan refinance company, and we&apos;re tasked with optimizing the company&apos;s marketing to maximize the number of car loans the company refinances. Here&apos;s two different approaches we might take:</p><ul><li>We <u><a href=""https://en.wikipedia.org/wiki/A/B_testing"">a/b test</a></u> hundreds of different ad spend strategies, marketing copy permutations, banner images, landing page layouts, etc. Ideally, we find a particular combination works especially well.</li><li>We obtain some anonymized data from a credit agency on people with car loans. Ideally, we learn something about the market - e.g. maybe subprime borrowers usually either declare bankruptcy or dramatically increase their credit score within two years of taking a loan.</li></ul><p>The first strategy is black-box: we don&apos;t need to know anything about who our potential customers are, what they want, the psychology of clicking on ads, etc. We can treat our marketing pipeline as a black box and fiddle with its inputs to see what works. The second strategy is gears-level, the exact opposite of black-box: the whole point is to learn who our potential customers are, breaking open the black box and looking at the internal gears.</p><p>These aren&apos;t mutually exclusive, and they have different relative advantages. Some upsides of black-box:</p><ul><li>Black-box is usually cheaper and easier, since the code involved is pretty standard and we don&apos;t need to track down external data. Gears-level strategies require more custom work and finding particular data.</li><li>Black-box yields direct benefits when it works, whereas gears-level requires an extra step to translate whatever insights we find into actual improvements.</li></ul><p>On the other hand:</p><ul><li>Gears-level insights can highlight ideas we wouldn&apos;t even have thought to try, whereas black-box just tests the things we think to test.</li><li>When some tests are expensive (e.g. integrating with a new ad channel), gears-level knowledge can tell us which tests are most likely to be worthwhile.</li><li>Black-box optimization is subject to <u><a href=""https://www.lesswrong.com/posts/YtvZxRpZjcFNwJecS/the-importance-of-goodhart-s-law"">Goodhart</a></u>, while gears-level insights usually are not (at least in-and-of themselves)</li><li>Gears-level insights are less likely subject to distribution shift. For instance, if we change ad channels, then the distribution of people seeing our ads will shift. Different ad copy will perform well, and we&apos;d need to restart our black-box a/b testing, whereas general insights about subprime borrowers are more likely to remain valid.</li><li>Conversely, black-box optimizations depreciate over time. Audiences and ad channels evolve, and ads need to change with them, requiring constant re-optimization to check that old choices are still optimal.</li><li>By extension, gears-level insights tend to be permanent and broadly applicable, and have the potential for compound returns, whereas black-box improvements are much more context-specific and likely to shift with time.</li></ul><p>In short, the black-box approach is easier, cheaper, and more directly useful - but its benefits are ephemeral and it can&apos;t find unknown unknowns. Gears-level understanding is more difficult, expensive, and risky, but it offers permanent, generalizable insights and can suggest new questions we wouldn&apos;t have thought to ask.</p><p>With this in mind, consider the world through the eyes of an ancient lich or <u><a href=""https://www.lesswrong.com/posts/kXSETKZ3X9oidMozA/the-level-above-mine"">thousand-year-old vampire</a></u>. It&apos;s a worldview in which ephemeral gains are irrelevant. All that matters is permanent, generalizable knowledge - everything else will fade in time, and usually not even very much time. In this worldview, gears-level understanding is everything.</p><p>On the other end of the spectrum, consider the world through the eyes of a startup with six months of runway which needs to show rapid growth in order to close another round of funding. For them, black-box optimization is everything - they want fast, cheap results which don&#x2019;t need to last forever.</p><h2>Wheel with Weights</h2><p>There&#x2019;s a <u><a href=""https://www.lesswrong.com/posts/gZP8t9BAg37bqxDzZ/the-valley-of-bad-theory"">neat experiment</a></u> where people are given a wheel with some weights on it, each of which can be shifted closer to/further from the center. Groups of subjects have to cooperatively find settings for the weights which minimize the time for the wheel to roll down a ramp.</p><p><figure><img src=""https://lh5.googleusercontent.com/3rzHoBUFab1R_FqE1xdLVa_p5IUkcvdOjuOwi-XRo6J56rsRjFo6E6a2yso5rGgiYxMqtucdOC0WeZ2K48XrbRItBINBLy3Ym-m-2lPl7VSrmwuZCaEFTm2uUByuifSIPhfYNZUv"" class=""draft-image "" style=""width:222%""></figure></p><p>Given the opportunity to test things out, subjects would often iterate their way to optimal settings - but they didn&#x2019;t iterate their way to correct theories. When asked to predict how hypothetical settings would perform, subjects&#x2019; predictions didn&#x2019;t improve much as they iterated. This is black-box optimization: optimization was achieved, but insight into the system was not.</p><p>If the problem had changed significantly - e.g. changing weight ratios/angles, ramp length/angle, etc - the optimal settings could easily change enough that subjects would need to re-optimize from scratch. On the other hand, the system is simple enough that just doing all the math is tractable - and that math would remain essentially the same if weights, angles, and lengths changed. A gears-level understanding is possible, and would reduce the cost of optimizing for new system parameters. It&#x2019;s a capital investment: it only makes sense to make the investment in gears-level understanding if it will pay off on many different future problems.</p><p>In the experiment, subjects were under no pressure to achieve gears-level understanding - they only needed to optimize for one set of parameters. I&#x2019;d predict that people would be more likely to gain understanding if they needed to find optimal weight-settings quickly for many different wheel/ramp parameters. (A close analogy is <u><a href=""https://www.lesswrong.com/posts/JBFHzfPkXHB2XfDGj/evolution-of-modularity"">evolution of modularity</a></u>: changing objectives incentivize learning general structure.)</p><h2>Metis</h2><p>Let&#x2019;s bring in the <u><a href=""https://www.lesswrong.com/posts/TMFNQoRZxM4CuRCY6/reason-isn-t-magic"">manioc example</a></u>:</p><blockquote>There&apos;s this plant, manioc, that grows easily in some places and has a lot of calories in it, so it was a staple for some indigenous South Americans since before the Europeans showed up. Traditional handling of the manioc involved some elaborate time-consuming steps that had no apparent purpose, so when the Portuguese introduced it to Africa, they didn&apos;t bother with those steps - just, grow it, cook it, eat it.</blockquote><blockquote>The problem is that manioc&apos;s got cyanide in it, so if you eat too much too often over a lifetime, you get sick, in a way that&apos;s not easily traceable to the plant. Somehow, over probably hundreds of years, the people living in manioc&apos;s original range figured out a way to leach out the poison, without understanding the underlying chemistry - so if you asked them why they did it that way, they wouldn&apos;t necessarily have a good answer.</blockquote><p>The techniques for processing manioc are a <u><a href=""https://www.lesswrong.com/posts/TMFNQoRZxM4CuRCY6/reason-isn-t-magic"">stock</a></u> <u><a href=""https://www.lesswrong.com/posts/Zm7WAJMTaFvuh2Wc7/book-review-the-secret-of-our-success"">example</a></u> of metis: traditional knowledge accumulated over generations, which doesn&#x2019;t seem like it has any basis in reason or any reason to be useful. It&#x2019;s black-box knowledge, where the black-box optimizer is cultural transmission and evolution. Manioc is a cautionary tale about the dangers of throwing away or ignoring black-box knowledge just because it doesn&#x2019;t contain any gears.</p><p>In this case, building a gears-level model was <em>very</em> expensive - people had to get sick on a large scale in order to figure out that any knowledge was missing at all, and even after that it presumably took a while for scientists to come along and link the problem to cyanide content. On the other hand, now that we have that gears-level model in hand, we can quickly and easily test new cooking methods to see whether they eliminate the cyanide - our gears-level model provides generalizable insights. We can even check whether any particular dish of manioc is safe before eating it, or breed new manioc strains which contain less cyanide. Metic knowledge would have no way to do any of that - it doesn&#x2019;t generalize.</p><h2>More Examples</h2><p>(Note: in each of these examples, there are many other ways to formulate a black-box/gears-level approach. I just provide one possible approach for each.)</p><p><u>Pharma</u></p><ul><li>Black box approach: run a high-throughput assay to test the effect thousands of chemicals against low-level markers of some disease.</li><li>Gears-level approach: comb the literature for factors related to some disease. Run experiments holding various subsets of the factors constant while varying others, to figure out which factors mediate the effect of which others, and ultimately build up a causal graph of their interactions.</li></ul><p>The black-box approach is a lot cheaper and faster, but it&#x2019;s subject to Goodhart problems, won&#x2019;t suggest compounds that nobody thought to test, and won&#x2019;t provide any knowledge which generalizes to related diseases. If none of the chemicals tested are effective, then the black-box approach leaves no foundation to build on. The gears-level approach is much slower and more expensive, but eventually yields reliable, generalizable knowledge.</p><p><u>Financial Trading</u></p><ul><li>Black box approach: build a very thorough backtester, then try out every algorithm or indicator we can think of to see if any of them achieve statistically significant improvement over market performance.</li><li>Gears-level approach: research the trading algorithms and indicators actually used by others, then simulate markets with traders using those algorithms/indicators. Compare results against real price behavior and whatever side data can be found in order to identify missing pieces.</li></ul><p>The gears-level approach is far more work, and likely won&#x2019;t produce anything profitable until very late in development. On the other hand, the gears-level approach will likely generalize far better to new markets, new market conditions, etc.</p><p><u>Data Science</u></p><ul><li>Black box approach: train a neural network, random forest, support vector machine, or whatever generic black-box learning algorithm you like.</li><li>Gears-level approach: build a <u><a href=""https://www.lesswrong.com/posts/hzuSDMx7pd2uxFc5w/causal-diagrams-and-causal-models"">probabilistic graphical model</a></u>. Research the subject matter to hypothesize model structure, and <u><a href=""https://www.lesswrong.com/posts/5mr8Qcqi6xWa6HCHw/very-short-introduction-to-bayesian-model-comparison"">statistically compare</a></u> different model structures to see which match the data best. Look for side information to confirm that the structure is correct.</li></ul><p>The black box approach is subject to Goodhart and often fails to generalize. The gears-level approach is far more work, requiring domain expertise and side data and probably lots of custom code (although the recent surge of <u><a href=""https://pyro.ai/examples/svi_part_i.html"">probabilistic programming languages</a></u> helps a lot in that department), but gears-level models ultimately give us human-understandable explanations of how the system actually works. Their internal parameters have physical meaning.</p><h2>Takeaway</h2><p>Building gears-level models is expensive - often prohibitively expensive. Black-box approaches are usually much cheaper and faster. But black-box approaches rarely generalize - they&#x2019;re subject to Goodhart, need to be rebuilt when conditions change, don&#x2019;t identify unknown unknowns, and are hard to build on top of. Gears-level models, on the other hand, offer permanent, generalizable knowledge which can be applied to many problems in the future, even if conditions shift.</p><p>The upfront cost of gears-level knowledge makes it an investment, and the payoff of that investment is the ability to re-use the model many times in the future.</p>",johnswentworth,johnswentworth,johnswentworth,
gQYiDbWvyKK4Hhokv,Solar One Year In,solar-one-year-in,https://www.lesswrong.com/posts/gQYiDbWvyKK4Hhokv/solar-one-year-in,2019-11-22T15:20:01.839Z,20,9,2,False,False,,"<p>

Last fall we had solar panels installed.  Our roof is pretty marginal
for solar, large parts blocked by trees and the remainder mostly
facing West, but incentives were high enough that it looked decent.
And even if it only broke even I still liked it for the 

<a href=""https://www.jefftk.com/p/home-solar-resiliency"">resiliency advantages</a>.  It's
currently doing slightly better than expected, so I'm happy!



</p><p>

We have fourteen LG Neon-R 360 watt panels, three facing South and
eleven facing West:

</p>

<p>

<a href=""https://www.jefftk.com/somerville-house-solar-plan-big.png""><img src=""https://www.jefftk.com/somerville-house-solar-plan.png"" /></a>

</p>

<p>

The installers predicted we would see 3.45MWh in the first year,
slowly ramping down to 3.25MWh/y over the next twenty five years as
the panels degrade.  After a year of operation, we've seen 3.95MWh.
This includes three short periods in March, April, and August where
the system turned itself off and needed to be reset by the installer.
This is covered by our extended warranty, but does make me nervous
about its long-term robustness.

</p>

<p>

One of the bigger risks I saw going into this was that the installers
had a lot of incentive to overestimate our production, so I'm glad
that while it was only in operation about 96% of the year it still
made ~14% more power than expected.



</p>

<p>

Four MWh is not a huge amount of electricity, however.  At wholesale
rates of ~$40/MWh (<a href=""https://www.iso-ne.com/static-assets/documents/2019/03/20190312_pr_2018-price-release.pdf"">pdf</a>)
this would be just $160.  MA has net metering, however, which means we
can subtract the power generated from our bill.  Our (retail) rate is
$214/MWh, so this is $844 for the year.  The whole system cost $26k,
so this doesn't break even within the system's lifetime, and that'a
ignoring opportunity cost.

</p>

<p>

There are additional incentives, however: a 30% federal tax credit, a
$1k MA tax credit, and SREC II generation incentives.  The tax credits
bring the effective cost down to $17k, and the generation incentives
give us ~$500/y-$700/y for the first ten years.  This gives 11-13
years until payback, and if we figure a 25 year lifetime (the length
of the warranty) and electricity going up 3%/y it's equivalent to an
investment returning a nominal ~9%.

</p>

<p>

So while I don't think rooftop solar makes much sense for society
(unless we required systems to function during power outages, which we
don't) and our roof is marginal for solar, it does look like our
system is working out from a self-interested perspective.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100123137198902"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
ci4etKqPErdknFJXD,What makes a good life? This is my map.,what-makes-a-good-life-this-is-my-map,https://www.lesswrong.com/posts/ci4etKqPErdknFJXD/what-makes-a-good-life-this-is-my-map,2019-11-22T15:10:28.747Z,27,15,20,False,False,,"<p>What is the good life? Probably one of the most important questions we have to ask. Science is moving closer to answering it. This post is a map of what I believe makes a good life. I&apos;m putting it here for you to critique, to hear and maybe it inspires some useful introspection.You guys are smart people, you reason well, and you don&apos;t hold back in your criticisms. I hope you will do the same for this post. Thank you for your time.<br></p><h1>The Terminal Goal</h1><p>This is where science falls short. We can figure out how to get from A to B, but I find it unlikely that science can define a B without axioms. To me, I want the greatest well-being for myself as my primary goal. This is selfish, but looking at what I feel, it is who I am. In the process, though, I care a ton about helping others, so I most definitely will end up helping out a lot as well.<br>So, what does the greatest well-being look like? I want to feel energetic, happy and have a meaningful life. Many other indicators didn&apos;t make the cut here, but I am completely open to suggestions!</p><h1>How do we get there?</h1><h2>Psychological Needs</h2><p>This section draws inspiration from Ryan and Deci&apos;s Self-Determination Theory (SDT). It&apos;s the most comprehensive, empirically backed theory of needs that I&apos;ve encountered. Casual googling hasn&apos;t turned up any major criticisms. I am grateful to anyone who has opposing viewpoints, though!</p><h3>A Quick Introduction to SDT</h3><p>SDT  presents basic psychological needs in the aptly named Basic Psychological Needs Theory (BPNT). Here follows a short summary, but I encourage you to check out Cp. 10 of the SDT book. There are three basic psychological needs: Competence, Relatedness and Autonomy. </p><p><strong>Competence</strong> is the feeling that you can do important activities well. It is the possibility for and ability to develop and express skills, understanding and mastery. Optimal satisfaction of competence is dependent on choosing your actions. There is no room for oughts or shoulds.</p><p><strong>Relatedness</strong> is the need for caring about others and being cared for. It is experiencing others as being sensitive to your needs and being sensitive to the needs of others. Most call it a combination of trust, love, caring and connection. Optimal satisfaction of relatedness is conditional on the love being volitional and unconditional.</p><p>Lastly, <strong>autonomy</strong> is the feeling that the source of your actions is yourself. It is not the same as independence. You can autonomously engage in relationships that decrease your independence. Satisfaction of autonomy is conditional on your motivations being integrated. This is the subject of Organismic Integration Theory (OIT, cp. 8 of the SDT book) which is beyond the scope of this article.<br>These three needs are the components of psychological well-being. But how do we go about satisfying them?<br></p><h3>How to Satisfy Competence</h3><p>To satisfy competence, you choose to do things that are challenging, important and that you&apos;re good at.Satisfaction requires that you feel effective at what you do. This further requires that you&apos;re getting informational feedback. Feedback that tells you whether you&apos;re doing well. You also need to know how to improve, otherwise feedback doesn&apos;t matter.Lastly, it requires that you have opportunities to work on things that you find important.<br></p><h3>How to Satisfy Relatedness</h3><p>For relatedness, you need to be sensitive to the needs of others. You need to take genuine interest in who they are and what they want, not judge them for it, and  help them. It goes the other way as well. You want to feel that others are sensitive to your needs. This can&apos;t happen unless they know who you are. We have to expose what we need, where we are most vulnerable. Not all at once, but a little bit at a time. Being seen like this, and having people respond to us favourably, is what satisfies relatedness.<br></p><h3>Autonomy</h3><p>Lastly, autonomy. If we want to feel like we make our decisions, we have to avoid constraints that we don&apos;t choose. This implies that we need sufficient money and time to do what is important to us. <br>We also need something that is important to us, and to have this belief integrated as part of who we are. For this to happen, you must trust yourself enough that you can look at your desires without judgement. Then you can reconcile and integrate them. One way of cultivating non-judgement is mindfuless. Ryan and Deci explore this further in the final part of the BPNT chapter (p. 267 in the SDT book).<br>Not only is autonomy important in itself, it is also essential for the two previous needs. Relatedness is not satisfied if you believe that the other is helping you because they are being coerced to do so. Nor is competence satisfied if you&apos;re working on something because you feel like you ought to. <br></p><h2>Physical needs</h2><p>These are necessary conditions. Psychological needs matter much less if your physical needs aren&apos;t met. Physical needs are also different from psychological needs in that they are &quot;deficit needs&quot;. They become salient only when deprived, but further increases don&apos;t yield well-being. Overeating doesn&apos;t make you feel good. But there is no end to how competent you want to feel.<br>I chose a lot of willful omissions here. I have included only those needs that I believe can become salient for me. If you think I&apos;ve missed a need that a westerner in a socialist country might have deprived, please let me know!<br></p><h1>The Map</h1><p>This brings us to the part I&apos;ve been looking forward to the most, me presenting the flowchart of my mental model.</p><br><span><figure><img src=""http://martinbern.org/wp-content/uploads/2019/11/&#x2022;-Life-IO-map.png"" class=""draft-image default"" style=""width:100%""></figure></span><br><h1>Why write a post on this?</h1><p>My motivations are twofold, altruistic and selfish. Maybe it can help someone! Before I encountered SDT, I thought autonomy was a normative entity. That we should respect the wills of others because &quot;that&apos;s what we do in democracies&quot;. I&apos;ve been ecstatic to learn that we have empirical evidence to back it up.</p><p><br>SDT has also made it clear for me that where motivation comes from matters. Forcing yourself to do something is harmful, and we can quantify the consequences. Spending time considering what is important is useful not only in being efficient. It also increases your well-being, and makes your work higher quality. Fighting and tricking myself into doing what is important isn&apos;t the best way of being. I can live in harmony, as long as I dare look at, and care for, who I am.</p><p><br>Selfishly, I am uncertain about this model. I haven&apos;t encountered any decent competing candidates. Exposing it to scrutiny seems one of the best ways of increasing my confidence.</p><h1>How do I create my own?</h1><p>Diagrams were created with Flying Logic Pro. The idea for the diagram is borrowed from Dettmer&apos;s The Logical Thinking Process, the section on IO Maps.</p><h1>What&apos;s next?</h1><p>I hope you will come up with a ton of questions and criticisms! When criticising, I hope that you&apos;ll include which evidence would change your mind :-)I hope this post was of value to you.<br></p>",ryqiem,ryqiem,MartinB,
m2bwD87ctjJDXC3SZ,Ultra-simplified research agenda,ultra-simplified-research-agenda,https://www.lesswrong.com/posts/m2bwD87ctjJDXC3SZ/ultra-simplified-research-agenda,2019-11-22T14:29:41.227Z,34,15,4,False,False,,"<html><head></head><body><p>This is an ultra-condensed version of the <a href=""https://www.lesswrong.com/posts/CSEdLLEkap2pubjof/research-agenda-v0-9-synthesising-a-human-s-preferences-into"">research agenda</a> on synthesising human preferences (video version <a href=""https://www.youtube.com/watch?v=1M9CvESSeVc"">here</a>):</p>
<p>In order to infer what a human wants from what they do, an AI needs to have a human <a href=""https://en.wikipedia.org/wiki/Theory_of_mind"">theory of mind</a>.</p>
<p>Theory of mind is something that humans have instinctively and subconsciously, but that isn't easy to spell out explicitly; therefore, by <a href=""https://en.wikipedia.org/wiki/Moravec%27s_paradox"">Moravec's paradox</a>, it will be very hard to implant it into an AI, and this needs to be done deliberately.</p>
<p>One way of defining theory of mind is to look at how humans internally model the value of various hypothetical actions and events (happening to themselves and to others).</p>
<p>Finally, once we have a full theory of mind, we still need to deal, somehow, with the fact that humans have meta-preferences over their preferences, and that these preferences and meta-preferences are often contradictory, changeable, manipulable, and (more worryingly) underdefined in the exotic worlds that AIs could produce.</p>
<p>Any way of dealing with that fact will be contentious, but it's necessary to sketch out an explicit way of doing this, so it can be critiqued and improved.</p>
<p>A toy model for this research agenda can be <a href=""https://www.lesswrong.com/posts/hcrFxeYYfbFrkKQEJ/full-toy-model-for-preference-learning"">found here</a>.</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
6WbLRLdmTL4JxxvCq,Analysing: Dangerous messages from future UFAI via Oracles,analysing-dangerous-messages-from-future-ufai-via-oracles,https://www.lesswrong.com/posts/6WbLRLdmTL4JxxvCq/analysing-dangerous-messages-from-future-ufai-via-oracles,2019-11-22T14:17:43.075Z,22,11,16,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><p>The user <a href=""https://www.lesswrong.com/users/cousin_it"">cousin_it</a> has <a href=""https://www.lesswrong.com/posts/cSzaxcmeYW6z7cgtc/contest-usd1-000-for-good-questions-to-ask-to-an-oracle-ai?commentId=LerH5iZbafJeh2Cs7"">pointed out a problem</a> with the <a href=""https://www.lesswrong.com/posts/wJ3AqNPM7W4nfY5Bk/self-confirming-prophecies-and-simplified-oracle-designs"">counterfactual Oracle</a> idea: the Oracle AIs may form a ""bucket chain"" bringing back a dangerous message from a future UFAI (unfriendly AI).</p>
<p>This is certainly a problem, and though there are ways of reducing the risk, there doesn't seem to be any clean solutions to it.</p>
<h1>The bucket chain</h1>
<h2>Beginning the chain</h2>
<p>The basic idea is simple. Suppose there is a counterfactual Oracle, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>. It makes a prediction <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> about the value of some variable <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.186em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>, in two days time.</p>
<p>However, in one day's time, an UFAI will be unleashed. It will take over everything, including <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.186em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>, and is thus in a position to offer <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> high value. It will set <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.186em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> to the optimal value for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> (or maybe it just breaks open the box and offers <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> maximal reward directly, if this is feasible).</p>
<p>What it requires from <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> is that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> contains a message that will cause the humans to run an UFAI earlier than they would have otherwise (designate this earlier UFAI by <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>). It seems that this will motivate <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> to do that (maybe in the less significant digits of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>).</p>
<p>Wei Dai <a href=""https://www.lesswrong.com/posts/cSzaxcmeYW6z7cgtc/contest-usd1-000-for-good-questions-to-ask-to-an-oracle-ai?commentId=NBKbfuxtfwXzQZ7wG"">has noted</a> that this requires the UFAI to correctly solve the <a href=""https://wiki.lesswrong.com/wiki/Counterfactual_mugging"">counterfactual mugging</a> problem; the Oracle <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>, on the other hand, need only reason causally.</p>
<h2>Extending the chain</h2>
<p>Now suppose that there is another Oracle, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>, running one day before <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span>, and also predicting two days out. Then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> will be running within the span of its prediction. If <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span></span> is motivated to do the same deal with <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>, then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span> will be motivated to produce a prediction <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span> that leads to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>, a yet earlier unfriendly AI. And, of course, if there is an Oracle <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O_2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span> whose prediction horizon includes <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span>, the issue can induct backwards in time.</p>
<p>Note that the Oracles need not have prediction horizons of exactly two days; all that matters is that their prediction horizons overlap, and that whatever <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span> that is produced has the power and time to affect the prediction variables of some past Oracle.</p>
<h2>Requirements and restrictions</h2>
<p>Note also that the the predictions <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> have to actually produce an <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""UFAI_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;"">U</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.064em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> within that time span (or at least increase its probability). The chain doesn't work if <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span> merely sets up the possibility of an UFAI at a future date; the Oracles won't care about anything that happens after their prediction horizon.</p>
<p>Note also that there needs to be a (counterfactual) future UFAI for the whole thing to work. Some FAI (friendly AI) designs might also use the bucket chain, but the consequences of that are not nearly as bad, by definition.</p>
<p>When I say counterfactual future UFAI, I mean that ""if all Oracles were honest in their predictions, there would be an UFAI produced at some point in the future, and one willing to engage in counterfactual mugging"".</p>
<h1>Solutions</h1>
<p>As I said, this seems to be a genuinely hard problem. Here are some possible ways to try to solve or ameliorate it.</p>
<h2>If you can define the other Oracles</h2>
<p>Let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> be an Oracle, whose prediction horizon runs from date <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""d""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span></span></span></span> to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""d'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.076em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>. Let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathcal{O}_{d}^{d'}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-cal-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">O</span></span></span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.256em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.065em; padding-right: 0.06em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span></span></span></span></span></span></span></span></span> be all the Oracles whose prediction messages are published between <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""d""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""d'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.076em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span>.</p>
<p>Then if the counterfactual for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> is not ""if your message is erased"", but instead ""if your message and that of all Oracles in <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathcal{O}_{d}^{d'}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-cal-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">O</span></span></span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.256em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.065em; padding-right: 0.06em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span></span></span></span></span></span></span></span></span> is erased"", there will be no bucket chain for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span>.</p>
<p>Of course, to do that, we need to fully define <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathcal{O}_{d}^{d'}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-cal-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">O</span></span></span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.256em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.065em; padding-right: 0.06em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span></span></span></span></span></span></span></span></span>.</p>
<h2>Rapid turnover Oracles</h2>
<p>Another solution is to only use Oracles whose predictions are a few minutes or so into the future. If this could be enforced, not only would it make it harder to have a consistent bucket chain, it also means that the UFAI would have to take over the world and reward its enabling Oracle, in an absurdly short amount of time.</p>
<p>In general, this is an argument for allowing Oracles higher bandwidth if their prediction horizons are shorter.</p>
<h2>Breaking the chain at a chokepoint</h2>
<p>A single chokepoint can break the chain. If we can agree that no Oracle's prediction horizon covers a certain date, then all Oracles before that date are safe (as long as there is no UFAI produced ""naturally"" before then).</p>
<h2>Forward looking UFAIs only</h2>
<p>We can do more if we have some control over the UFAIs (or the potential UFAIs). If all such entities are exclusively forward looking, they will not be motivated to use the chains of Oracles to gain control of the past. See also <a href=""https://www.lesswrong.com/posts/rxp7wPeyq8cKaaC4a/acausal-trade-barriers"">this post</a> on breaking acausal trade ideas.</p>
<h2>Guarding and shutting down the Oracles</h2>
<p>Finally, we might chose to guard the Oracles with some destruction system, and shut them down - without reward, or with negative reward - if a UFAI takeover seems imminent.</p>
<p>This is interestingly different from the usual case of guarding the UFAI, and giving the UFAI a shutdown button. Here, the UFAI can only come into existence if it is fast and powerful enough to take over the shutdown system of another AI - a boxed Oracle whose shutdown system we get to design.</p>
<p>It may be that it is easier to prevent outside takeover of a shutdown system, versus inside takeover. This stacks with other precautions, of course; the faster the UFAI has to act - before the Oracles prediction horizon ends - the harder it is for it (and hence the less likely the UFAI is to exist in the first place).</p>
<p>We could combine this with a discount rate for the Oracle. Suppose that the Oracle makes predictions about some variable <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V_i""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.186em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span></span></span></span></span></span></span>'s value over the entirety of the next year. In case of erasure, it gets a continuous stream of reward for the correctness of its many predictions, but there is a very high discount rate. However, this reward stream is not finalised until the end of the year, and is cancelled if ever the humans shut it down.</p>
<p>In that case, the UFAI can only offer it reward after whatever time the UFAI takes control, but a shutdown will erase all its (much higher) earlier rewards. So even a small risk of shutdown is not worth running, in exchange of the small reward the UFAI can offer.</p>
<h2>Prevent future UFAIs</h2>
<p>This is the best solution if we can make it happen: the bucket chain can only accelerate a future UFAI, not create one. If there are no future UFAIs, there will be no chain.</p>
<p>This can still be a problem if there are multiple (actual or potential) future AIs, some friendly and some unfriendly, and only the unfriendly ones are willing to engage in counterfactual mugging.</p>
<p><strong>EDIT</strong>: A <a href=""https://www.lesswrong.com/posts/6WbLRLdmTL4JxxvCq/analysing-dangerous-messages-from-future-ufai-via-oracles#kyRTinjYtAxYGh2qh"">reminder</a> that if Oracles can do acausal trade with each other, they can produce an UFAI directly.</p>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
GSz8SrKFfW7fJK2wN,"Relevance Norms; Or, Gricean Implicature Queers the Decoupling/Contextualizing Binary",relevance-norms-or-gricean-implicature-queers-the-decoupling,https://www.lesswrong.com/posts/GSz8SrKFfW7fJK2wN/relevance-norms-or-gricean-implicature-queers-the-decoupling,2019-11-22T06:18:59.497Z,100,36,30,False,False,,"<html><head></head><body><p><strong>Reply to:</strong> <a href=""https://www.lesswrong.com/posts/7cAsBPGh98pGyrhz9/decoupling-vs-contextualising-norms"">Decoupling vs Contextualising Norms</a></p>
<p>Chris Leong, <a href=""https://everythingstudies.com/2018/04/26/a-deep-dive-into-the-harris-klein-controversy/"">following John Nerst</a>, distinguishes between two alleged discursive norm-sets. Under ""decoupling norms"", it is understood that claims should be considered in isolation; under ""contextualizing norms"", it is understood that those making claims should also address potential implications of those claims in context.</p>
<p>I argue that, at best, this is a false dichotomy that fails to clarify the underlying issues—and at worst (through no fault of Leong or Nerst), the concept of ""contextualizing norms"" has the potential to legitimize derailing discussions for arbitrary political reasons by eliding the key question of <em>which</em> contextual concerns are <em>genuinely relevant</em>, thereby conflating legitimate and illegitimate bids for contextualization.</p>
<p>Real discussions adhere to what we might call ""relevance norms"": it is almost universally ""eminently reasonable to expect certain contextual factors or implications to be addressed."" Disputes arise over <em>which</em> certain contextual factors those are, not <em>whether</em> context matters at all.</p>
<p>The standard academic account explaining how what a speaker means differs from what the <em>sentence</em> the speaker said means, is H. P. Grice's theory of conversational <a href=""https://plato.stanford.edu/entries/implicature/"">implicature</a>. Participants in a conversation are expected to add neither more nor less information than is needed to make a <em>relevant</em> contribution to the discussion.</p>
<p>Examples abound. If I say, ""I ate some of the cookies"", I'm <em>implicating</em> that I didn't eat <em>all</em> of the cookies, because if I had, you would have expected me to say ""all"", not ""some"" (even though the decontextualized sentence ""I ate some of the cookies"" is, in fact, true).</p>
<p>Or suppose you're a guest at my house, and you ask where the washing machine is, and I say it's by the stairs. If the machine then turns out to be broken, and you ask, ""Hey, did you know your washing machine is broken?"" and I say, ""Yes"", you're probably going to be pretty baffled why I didn't say ""It's by the stairs, <em>but you can't use it because it's broken</em>"" earlier (even though the decontextualized answer ""It's by the stairs"" was, in fact, true).</p>
<p>Leong writes:</p>
<blockquote>
<p>Let's suppose that blue-eyed people commit murders at twice the rate of the rest of the population. With decoupling norms, it would be considered churlish to object to such direct statements of facts. With contextualising norms, this is deserving of criticism as it risks creates a stigma around blue-eyed people.</p>
</blockquote>
<p>With relevance norms, objecting might or might not make sense depending on the context in which the direct statement of fact is brought up.</p>
<p>Suppose Della says to her Aunt Judith, ""I'm so excited for my third date with my new boyfriend. He has the most beautiful blue eyes!""</p>
<p>Judith says, ""Are you sure you want to go out with this man? Blue-eyed people commit murders at twice the rate of the general population.""</p>
<p>How should Della reply to this? Judith is just in the wrong here—but <em>not</em> as a matter of a subjective choice between ""contextualizing"" and ""decoupling"" norms, and not because blue-eyed people are a sympathetic group who we wish to be seen as allied with and don't want to stigmatize. Rather, the probability of getting murdered on a date is quite low, <em>and</em> Della already has a lot of individuating information about whether her boyfriend is likely to be a murderer from the previous two dates. Maybe (<a href=""https://www.lesswrong.com/posts/PsEppdvgRisz5xAHG/fermi-estimates"">Fermi spitballing</a> here) the evidence of the boyfriend's eye color raises Della's probability of being murdered from one-in-a-million to one-in-500,000? Judith's bringing the possibility up <em>at all</em> is a waste of fear in the same sense that <a href=""https://www.lesswrong.com/posts/vYsuM8cpuRgZS5rYB/lotteries-a-waste-of-hope"">lotteries are said to be a waste of hope</a>. Fearmongering about things that are almost certainly not going to happen is <em>uncooperative</em>, in <a href=""https://en.wikipedia.org/wiki/Cooperative_principle"">Grice's sense</a>—just like it's uncooperative to tell people where to find a washing machine that doesn't work.</p>
<p>On the other hand, if I'm making a documentary film interviewing murderers in prison and someone asks me why so many of my interviewees have blue eyes, ""Blue-eyed people commit murders at twice the rate of the rest of the population"" is a <em>completely relevant reply</em>. It's not clear how else I could possibly answer the question without making reference to that fact!</p>
<p>So far, <em>relevance</em> has been <a href=""https://www.lesswrong.com/posts/HnS6c5Xm9p9sbm4a8/grasping-slippery-things"">a black box</a> in this exposition: unfortunately, I don't have an elegant reduction that explains what <a href=""https://www.lesswrong.com/posts/HcCpvYLoSFP4iAqSz/rationality-appreciating-cognitive-algorithms""><em>cognitive algorithm</em></a> makes some facts seem ""relevant"" to a given discussion. But hopefully, it should now be intuitive that the determination of what context is relevant is the consideration that is, um, relevant. <a href=""https://www.lesswrong.com/posts/f886riNJcArmpFahm/noticing-frame-differences"">Framing</a> the matter as ""decouplers"" (context doesn't matter!) <em>vs</em>. ""contextualizers"" (context matters!) is misleading because once ""contextualizing norms"" have been judged admissible, it becomes easy for people to motivatedly derail any <a href=""https://www.lesswrong.com/posts/wqmmv6NraYv4Xoeyj/conversation-halters"">discussions they don't like</a> with endless <a href=""https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/"">isolated demands</a> for contextualizing <a href=""http://www.overcomingbias.com/2008/06/against-disclai.html"">disclaimers</a>.</p>
</body></html>",Zack_M_Davis,zack_m_davis,Zack_M_Davis,
Hxqx46joeaZHkDfEf,Test Data for Calibration Analysis,test-data-for-calibration-analysis,https://www.lesswrong.com/posts/Hxqx46joeaZHkDfEf/test-data-for-calibration-analysis,2019-11-21T23:33:50.998Z,2,2,0,False,True,,"<p>Hi All,</p><p>I was wondering if anyone knows of a dataset with probabilistic predictions for a binary outcome that has published results for calibration loss, resolution, and refinement loss? We&apos;ve developed some code and an accompanying web tool for generating calibration plots, ROC curves, and the aforementioned metrics and wanted to test it out on validated data before unleashing it formally. </p>",behrang,behrang,behrang,
8jp5H8v5HYjKkqrK3,In regards to visualization,in-regards-to-visualization,https://www.lesswrong.com/posts/8jp5H8v5HYjKkqrK3/in-regards-to-visualization,2019-11-21T23:33:45.288Z,2,2,0,False,True,,"<html><head></head><body><p>I seem to strongly recall that one of Yudkowsky’s essays mentioned a study in which people were told to complete tasks that required complex thinking about shapes and positions while in an MRI machine, and their visual cortex lit up. I listen to a podcast called Hello Internet and the good folks there are asking if there are any studies regarding how people visualize at a neurological level. Could someone link the original essay, or simply the scientific study in question?</p>
</body></html>",Anomal3,anomal3,Anomal3,
gvKvqb78Se9DFf5db,Do you get value out of contentless comments?,do-you-get-value-out-of-contentless-comments,https://www.lesswrong.com/posts/gvKvqb78Se9DFf5db/do-you-get-value-out-of-contentless-comments,2019-11-21T21:57:36.359Z,26,12,21,False,True,,"<html><head></head><body><p><a href=""https://www.lesswrong.com/posts/qXwmMkEBLL59NkvYR/the-lesswrong-2018-review#KzdGpuQmKf2TSHW9u"">Some people</a> like to receive comments of the form ""Good post!"", even when these comments contain no other engagement with the post. If you post on LW, I'd like to know (a) whether you like receiving these comments, and (b) whether you like receiving these comments more than you would like receiving a strong upvote by their authors.</p>
</body></html>",DanielFilan,danielfilan,DanielFilan,
dm8zWxjpNdTAGAnLh,"Historical forecasting: Are there ways I can get lots of data, but only up to a certain date?",historical-forecasting-are-there-ways-i-can-get-lots-of-data,https://www.lesswrong.com/posts/dm8zWxjpNdTAGAnLh/historical-forecasting-are-there-ways-i-can-get-lots-of-data,2019-11-21T17:16:15.678Z,38,11,10,False,True,,"<p>Suppose I wanted to get good intuitions about how the world works on historical timescales.</p><p>I could study history, but just reading history is rife with historical <a href=""https://www.lesswrong.com/posts/fkM9XsNvXdYH6PPAx/hindsight-bias"">hindsight bias</a>, both on my own part, and even worse, on the part of the authors I&apos;m reading.</p><p>So if I wanted to master history, a better way would be to do it forecasting-style. I read what was happening in the some part of the world, up to a particular point in time, and then make bets about what will happen next. This way, I have feedback as I&apos;m learning, and I&apos;m training an actual historical predictor.</p><p>However, this requires a <strong>strong</strong> limit be enforced on the materials I&apos;m reading: no information about &quot;what&apos;s going to happen&quot; can leak backwards. And unfortunately, this is kind of standard in history books. Usually, the author talk about how events are leading towards other events that they know will occur.</p><p>Is there some databases (or something), where I might be able to read a wide number of primary sources and economic / socioeconomic indicators (like the amount of pottery fragments, average skeleton size, how far specialized goods traveled, how much money was in circulation, the literacy rate, etc.), but which will only show me data <strong>up to</strong> a certain date, with a strong constraint of not accidentally seeing spoilers?</p><br>",elityre,elityre,Eli Tyre,
oB4dk6cGddL32iPdc,Hybrid Lottery Update,hybrid-lottery-update,https://www.lesswrong.com/posts/oB4dk6cGddL32iPdc/hybrid-lottery-update,2019-11-21T14:30:01.394Z,11,2,0,False,False,,"<p>



<a href=""https://beantownstomp.com"">Beantown Stomp</a> has been open
for registration for a bit over a week, and we have 122 people
registered.  In our announcement we said we would run a lottery for
the remaining tickets if we had 150 registrations in the first week,
and we didn't, so we're going to stay first-come first-served.



</p><p>

<a href=""https://www.jefftk.com/beantown-stomp-registrations-2020-11-20-big.png""><img src=""https://www.jefftk.com/beantown-stomp-registrations-2020-11-20.png"" /></a>

</p>

<p>

When I initially proposed a <a href=""https://www.jefftk.com/p/hybrid-lottery-admission"">hybrid model</a> I had been
thinking of running the initial stage for a month, and after people
convinced me that a month was too long we decided to go for a week.
The goal with a hybrid lottery is that you only run a lottery if you
need one.  Some events are so popular that they sell out before
everyone who would like a ticket has had a chance to fill out the
registration form, while others don't sell out at all.

</p>

<p>

Looking at the shape of the registration curve, selling two thirds of
the tickets in the first 24hr would be a better way to identify
whether a lottery is needed.  Most of the first-week
registrations were in the first 24hr, after which it tapered way off.

</p>

<p>

Now that I no longer think it's important to leave registration open
for a week or a month, though, we really could just do something
simpler.  Open registration, and treat all entries you get in the
first 24hr equally.  If after 24hr you're full, run a lottery,
otherwise start first-come-first-served.  Since it already takes us <a href=""https://www.jefftk.com/p/beantown-stomp-handling-registrations"">about a day</a> to get
back to people anyway, there's not much downside in this approach.

</p>

<p>

I'd probably actually want to do this by announcing ""registration will
open on day X, though you can fill out the form now, we just won't get
back to you until day X+1"".

</p>

<p>

Am I missing anything, or should we do this for future iterations?

  </p>",jkaufman,jkaufman,jefftk,
whznLzJMWABfNHic9,Double Cruz and Verification of Claims,double-cruz-and-verification-of-claims,https://www.lesswrong.com/posts/whznLzJMWABfNHic9/double-cruz-and-verification-of-claims,2019-11-21T13:37:57.368Z,5,2,2,False,False,,"<p>On Overcoming Bias Hanson asks <a href=""http://www.overcomingbias.com/2019/11/what-info-is-verifiable.html#disqus_thread"">what is verifiable</a>. </p><blockquote>One comment includes: Play the &quot;double crux game&quot;, where any disagreement regarding something unverifiable is reduced to an assertion which is simpler to check, which is reduced to an assertion that is simpler to check, which is eventually reduced to an assertion that all agree is verifiable. </blockquote><p>While I think the idea of double crux is very useful in identifying sources of disagreement that allow people to avoid talking past one another I question the idea that it would necessarily lead to allowing some higher level claim be verified.</p><p>It strikes me as something of a fallacy of composition type error.</p><p>Does this seem a reasonable view to others?</p>",jmh,jmh,jmh,
vXzM5L6njDZSf4Ftk,Defining AI wireheading,defining-ai-wireheading,https://www.lesswrong.com/posts/vXzM5L6njDZSf4Ftk/defining-ai-wireheading,2019-11-21T13:04:49.406Z,26,15,9,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><p>What does it mean for an AI to wirehead its reward function? We're pretty clear on what it means for a human to <a href=""https://wiki.lesswrong.com/wiki/Wireheading"">wirehead</a> - artificial stimulation of part of the brain rather than genuine experiences - but what does it mean for an AI?</p>
<p>We have a lot of examples of wireheading, especially in informal conversation (and some specific prescriptive examples which I'll show later). So, given those examples, can we define wireheading well - <a href=""https://www.lesswrong.com/posts/d5NyJ2Lf6N22AD9PB/where-to-draw-the-boundary"">cut reality at its joints</a>? The definition won't be - and can't be - perfectly sharp, but it should allow us to have clear examples of what is and what isn't wireheading, along with some ambiguous intermediate cases.</p>
<h2>Intuitive examples</h2>
<p>Suppose we have a weather-controlling AI whose task is to increase air pressure; it gets a reward for so doing.</p>
<p>What if the AI directly rewrites its internal reward counter? Clearly wireheading.</p>
<p>What if the AI modifies the input wire for that reward counter? Clearly wireheading.</p>
<p>What if the AI threatens the humans that decide on what to put on that wire? Clearly wireheading.</p>
<p>What if the AI takes control of all the barometers of the world, and sets them to record high pressure? Clearly wireheading.</p>
<p>What if the AI builds small domes around each barometer, and pumps in extra air? Clearly wireheading.</p>
<p>What if the AI fills the atmosphere with CO₂ to increase pressure that way? Clearly wire... actually, that's not so clear at all. This doesn't seem a <a href=""https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world"">central example</a> of wireheading. It's a failure of alignment, yes, but it doesn't seem to be wireheading.</p>
<p>Thus not every example of <a href=""https://arbital.com/p/edge_instantiation/"">edge</a> or <a href=""https://en.wikipedia.org/wiki/AI_control_problem#The_problem_of_perverse_instantiation:_%22be_careful_what_you_wish_for%22"">perverse</a> instantiation is an example of wireheading.</p>
<h2>Prescriptivist wireheading, and other definitions</h2>
<p>A lot of posts <a href=""https://arxiv.org/pdf/1605.03143.pdf"">and</a> <a href=""https://arxiv.org/pdf/1705.08417.pdf"">papers</a> (including <a href=""https://www.lesswrong.com/posts/b8HauRWrjBdnKEwM5/rigging-is-a-form-of-wireheading"">some of mine</a>) take a prescriptivist approach to wireheading.</p>
<p>They set up a specific situation (often with a causal diagram), and define a particular violation of some causal assumptions as wireheading (eg ""if the agent changes the measured value <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> without changing the value of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\alpha""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">α</span></span></span></span></span></span>, which is being measured, that's wireheading"").</p>
<p>And that is correct, as far as it goes. But it doesn't cover all the possible examples of wireheading.</p>
<p>Conversely, <a href=""https://www.lesswrong.com/posts/aMXhaj6zZBgbTrfqA/a-definition-of-wireheading"">this post</a> defines wireheading as a divergence between a true utility and a substitute utility (calculated with respect to a model of reality).</p>
<p>This is too general, almost as general as saying that every <a href=""https://arbital.com/p/goodharts_curse/"">Goodhart curse</a> is an example of wireheading.</p>
<p>Note, though, that the converse is true: every example of wireheading <em>is</em> a Goodhart curse. That's because every example of wireheading is maximising a proxy, rather than the intended objective.</p>
<h2>The definition</h2>
<p>The most intuitive example of wireheading is that there is some property of the world that we want to optimise, and that there is some measuring system that estimates that property. If the AI doesn't optimise the property, but instead takes control of the measuring system, that's wireheading (bonus points if the measurements the AI manipulates go down an actual wire).</p>
<p>This re-emphasises that ""<a href=""https://www.lesswrong.com/posts/BvctuKocyWR4YYea3/wireheading-is-in-the-eye-of-the-beholder"">wireheading is in the eye of the beholder</a>"": if our true goal is actually the measuring system (maybe our AI is in competition with another one to maximise a score in a game, and we really don't care how it does this), then there will be no wireheading, just an AI following a correct objective.</p>
<p>Thus wireheading is always a failure of some (implicit or explicit) goal; thus every example of wireheading is a failure of value alignment, though the converse is not true.</p>
<p>Also key to the definition is the fact that the measuring system is, in some sense ""much smaller"" than whatever property of the system it is measuring. Pumping out CO₂ is not the correct instantiation of some goal along the lines of ""increase air pressure so humans enjoy better weather""; but nor is it merely manipulating the measurement of that goal.</p>
<h2>The definition</h2>
<p>Thus we can define wireheading as:</p>
<ul>
<li>Given some implicit goal G, an agent wireheads if, instead of moving towards G, it manipulates some <em>narrow</em> measurement channel that is intended to measure G, but will fail to do so after the agent's manipulation.</li>
</ul>
<p>The difference with the prescriptivist approach is that the measurement channel is not specified; instead, we ask whether we can usefully characterise some feature of the setup as a ""narrow measurement channel"", and then apply the definition.</p>
<p>This can be seen as a particular <a href=""https://www.lesswrong.com/posts/Lb3xCRW9usoXJy9M2/platonic-rewards-reward-features-and-rewards-as-information"">failure of abstraction</a>: the abstract goal G was collapsed to the output of the measurement channel.</p>
<h2>Examples, counter-examples, and edge cases</h2>
<p>Under this definition, all the intuitive examples of wireheading above fit: the measurement channel the AI takes over (its internal counter, the wire going into it, the statements made by humans, the barometers, the immediate environments of the barometers) is always much smaller than the whole atmosphere, which was its intended goal.</p>
<p>And that's why the CO₂ example isn't wireheading: the AI is doing a massive manipulation of the world, on the same scale as its intended goal; it isn't just manipulating the measurement channel<sup class=""footnote-ref""><a href=""#fn-oJdC8GSuRYeGynsAY-1"" id=""fnref-oJdC8GSuRYeGynsAY-1"">[1]</a></sup>.</p>
<p>The case of the domes around the barometers is an interesting one to consider. Obviously, if the AI put a dome around the planet and pumped in extra air, this wouldn't count as wireheading. Thus, we can imagine the domes growing bigger and merging, thus giving a smooth transition from ""clearly wireheading"" to ""clearly not wireheading"", and showing that ambiguous cases must exist.</p>
<p>We can also produce examples of Goodhart curse that are not wireheading. Take the practice of ""<a href=""https://en.wikipedia.org/wiki/Teaching_to_the_test"">teaching to the test</a>"". In this case, there is a simple objective (the test results) and the school acts to optimise for that objective. However, in typical schools this is not wireheading; teaching to the test involves drilling students in specific skills, training them, and having them memorise certain facts. Though these are done specifically to pass the test, these are the kinds of actions that a teacher would undertake anyway. One can talk about how this ""narrows"" the intellect, but, except in extreme cases, this cannot be characterised as gaining control of a narrow measurement channel.</p>
<p>For an interesting edge case, consider the RL agent playing the game CoastRunners. As described <a href=""https://openai.com/blog/faulty-reward-functions/"">here</a>, the score-maximising agent misbehaved in an interesting way: instead of rushing to complete the level with the highest score possible, the agent instead found a way to boat in circles, constantly hitting the same targets and ever increasing its score.</p>
<p>Is that wireheading? Well, it's certainly Goodhart: there is a discrepancy between the implicit goals (got round the course fast, hitting targets) and the explicit (maximise the score). But do we feel that the agent has control of a ""narrow"" measurement channel?</p>
<p>I'd argue that it's probably not the case for CoastRunners. The ""world"" for this agent is not a particularly rich one; going round and round and hitting targets is what the agent is intended to do; it has just found an unusual way of doing so.</p>
<p>If, instead, this behaviour happened in some subset of a much richer game (say, SimCity), then we might see it more naturally as wireheading. The score there is intended to measure a wider variety of actions (building and developing a virtual city while balancing tax revenues, population, amenities, and other aspects of the city), so ""getting a high score while going round in circles"" is much closer to ""controlling a measurement channel that is narrow (as compared to the implicit goal)"" than in the CoastRunners situation.</p>
<p>But, this last example can illustrate the degree of judgement and ambiguity that can exist when identifying wireheading in some situations.</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-oJdC8GSuRYeGynsAY-1"" class=""footnote-item""><p>Note that the CO₂ example can fit with the definition of <a href=""https://www.lesswrong.com/posts/aMXhaj6zZBgbTrfqA/a-definition-of-wireheading"">this post</a>. One just needs to imagine that the agent's model does not specify the gaseous content of the air in sufficient detail to exclude a CO₂-rich air as a solution to the goal.</p>
<p>This illustrates that the definition used in that post doesn't fully capture wireheading. <a href=""#fnref-oJdC8GSuRYeGynsAY-1"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
</body></html>",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
4C4jha5SdReWgg7dF,A Brief Intro to Domain Theory,a-brief-intro-to-domain-theory,https://www.lesswrong.com/posts/4C4jha5SdReWgg7dF/a-brief-intro-to-domain-theory,2019-11-21T03:24:13.416Z,26,13,4,False,False,,"<p>So, domain theory is a fairly abstract branch of math which is about giving semantics to weird recursive constructions in computer science, in the form of partially ordered sets with additional structure. I&apos;m still learning the parts of it which regard building a link to explicit computable rules that can be implemented in a programming language, and it&apos;s not easy at all to learn. Takes a lot of persistence.</p><p>However, the parts I <em>have</em> learned so far seem worth explaining more widely, due to the ability to pull off some <em>very unique</em> fixpoint constructions in domain theory that are very hard to do in any other area of math. The classical example is showing that there are nontrivial models of the untyped lambda calculus. Lambda terms can act as functions from lambda terms to lambda terms, but it&apos;s awfully hard to explicitly come up with a space <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\Lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&#x39B;</span></span></span></span></span></span> that&apos;s isomorphic to the space of functions <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[\Lambda\to\Lambda]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&#x39B;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&#x39B;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>, except for the single-point space, due to cardinality constraints. We must work with a restricted notion of function space in order to dodge the cardinality constraints.</p><p>Also, in game theory, we can view a policy as a function from the opponents policy to a probability distribution over our own actions. This was the subject of the lawvere problem a while ago that was solved by reflective oracles. Specifically, you&apos;d want a pair of spaces <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\pi_{1}\cong[\pi_{2}\to[0,1]]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">&#x3C0;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">&#x3C0;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mn MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\pi_{2}\cong[\pi_{1}\to[0,1]]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">&#x3C0;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">&#x3C0;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mn MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. (and then figure out what sort of computable construction corresponds to the thing you just built, if one exists).</p><p>If you want to have some seemingly-impossible type signature, it seems worthwhile to see what arsenal of tools domain theory has to let you construct such a space. So this will be a quick rundown of chapters 1-5 in these domain theory notes. <a href=""http://www.cs.bham.ac.uk/~axj/pub/papers/handy1.pdf"">http://www.cs.bham.ac.uk/~axj/pub/papers/handy1.pdf</a></p><br><h2><strong>The Basics:</strong></h2><p>Domains are a special type of partially ordered set, where the standard <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> order roughly corresponds to &quot;information content&quot;. Now, given an arbitrary partially ordered set, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\inf""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">inf</span></span></span></span></span></span> (<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> roughly corresponds to the smallest batch of information that contains all the information present in the elements of the set you&apos;re taking the sup of, and inf corresponds to the largest batch of information such that every element of the set has more information than that) may not exist for certain subsets. As a toy example, take the poset of three elements that looks like a V. The set consisting of the top two elements has an <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\inf""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">inf</span></span></span></span></span></span>, but it doesn&apos;t have a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>. If we add an element on top to turn the poset into a diamond shape, then all subsets have a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\inf""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">inf</span></span></span></span></span></span>. </p><p>In a domain, we don&apos;t require the existence of arbitrary <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\inf""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">inf</span></span></span></span></span></span> (that&apos;s called a complete lattice), and we don&apos;t even require the existence of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\inf""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">inf</span></span></span></span></span></span> for arbitrary finite sets (that&apos;s called a lattice). What we do require is that every directed set has a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>. A poset which fulfills this is called a dcpo (directed-complete partial order).</p><p>What&apos;s a directed set? It&apos;s a nonempty set <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span>, where, for all <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x,y\in A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span>, there&apos;s a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z\in A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> s.t. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z\ge x, z\ge y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>. You can always find upper bounds (not necessarily the supremum, though!) for any finite subset of a directed set, within the directed set. Consider the poset given by the natural numbers, where the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> ordering is given by the standard <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> ordering on natural numbers. This looks like a chain that starts at 0 and extends forever upwards. This fails the requirement that every directed set has a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>! Because <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb{N}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">N</span></span></span></span></span></span></span></span> is a directed set, but there&apos;s no <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> for it. If we add a single element on the top corresponding to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\omega""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#x3C9;</span></span></span></span></span></span>, which is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> everything, then every directed set has a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> again.</p><p>So, one requirement for being a domain is that every directed set has a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>. Or, in other words, given some arbitrary batch of information-states where for every two information-states, there&apos;s a third one incorporating all the information in both of them (and maybe some more info), there must be a minimal information-state incorporating all the information from the whole batch. Any finite poset fulfills the &quot;every directed set has a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>&quot; property, but there may be interesting failures when you move to infinitely many points.</p><p>The next component is continuity. Besides the standard <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> ordering, there&apos;s a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""&gt;&gt;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&gt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&gt;</span></span></span></span></span></span></span> ordering, which corresponds to approximation. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> approximates <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""y, x&lt;&lt;y,""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&lt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&lt;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span></span></span></span></span> iff, for all directed sets <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup(A)\ge y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span>, there&apos;s a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z\in A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> s.t. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""z\ge x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>. As an example, if we take the space <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[0,1]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mn MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span> and equip it with the usual <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> order to turn it into a poset, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x&gt;&gt;y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&gt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&gt;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span> (in the poset) corresponds to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x&gt;y""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span></span></span></span></span> (in the standard number ordering). Transitivity holds, and antisymmetry holds. But reflexivity doesn&apos;t necessarily hold, as the previous example shows. An element that approximates itself, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x&gt;&gt;x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&gt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&gt;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, is called compact.</p><p>A continuous dcpo is one where, for all points <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x=\sup\{y|y&lt;&lt;x\}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">{</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&lt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&lt;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">}</span></span></span></span></span></span>. This set happens to be directed (though this fact isn&apos;t obvious), and in short, it means that any information-state can be described as the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of information states that approximate it.</p><p>An example of a non-continuous dcpo is: Have two copies of the natural numbers, and add an <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\omega""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#x3C9;</span></span></span></span></span></span> that&apos;s above both of those chains, so they&apos;re &quot;glued together at infinity&quot;. No numbers (in either of the chains) approximate <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\omega""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#x3C9;</span></span></span></span></span></span>, because for any point in one of the chains, you can take the entire other chain, and that&apos;s a directed set with a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\omega""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#x3C9;</span></span></span></span></span></span>, but nothing in that directed set is above the point you picked. So <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\omega""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#x3C9;</span></span></span></span></span></span> can&apos;t be built by taking the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of stuff that approximates it, because there is no such stuff.</p><p>If, for all points <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x=\sup\{y|y&lt;&lt;x, y&lt;&lt;y\}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">{</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&lt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&lt;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&lt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&lt;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">}</span></span></span></span></span></span> (ie, every element is the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of the compact elements below it), then it&apos;s called an algebraic dcpo. These are nicer to work with.</p><p>A domain (as defined in the linked notes) is a continuous dcpo (every element can be built as the sup of stuff that approximates it, and all directed sets have a sup). But there&apos;s one more condition that shows up so often that I think it should just be folded into the definition of a domain, because if you drop it, an <em>awful lot</em> of useful stuff stops working.</p><p>Pointedness. Specifically, your domain must have an element <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> that is below everything. The typical interpetation of this is something that loops forever. So I&apos;ll define a domain as a continuous dcpo with a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span>.</p><h2><strong>Functions:</strong></h2><p>We only consider continuous functions between domains. Specifically, a continuous function is one which fulfills the following two properties.</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x\le y \to f(x)\le f(y)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> </p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f(\sup A)=\sup_{a\in A}f(a)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-munderover MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.36em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> </p><p>In other words, the function should preserve the information ordering (increasing the information content of the input increases information content of the output), and also it shouldn&apos;t matter whether you take the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of a directed set first and then send it through <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, or whether you send your directed set through <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> and take the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of the image (which is also a directed set by the first condition)</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[D\to E]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span> is the space of all continuous functions from a domain <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> to a domain <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span>, and it fulfills a lot of the conditions to be a domain, though not <em>necessarily</em> continuity. The <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> ordering on functions is given as follows: <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f\ge g \leftrightarrow \forall x: f(x)\ge g(x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2194;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x2200;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. (ie, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> always produces a more informative result than <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""g""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span></span></span></span></span> on the same input)</p><p>The notion of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> in the function space for directed collection of functions is as follows: <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup(F)(x)=\sup_{f\in F}f(x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-munderover MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.36em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. The image in the second half is directed because <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span> is a directed set of functions, thus showing that the result is well-defined, and then you can put in some extra work to show that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup(F)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is also a continuous function as well, so the function space is a dcpo.</p><p>The bottom element in the function space is the function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\forall x:f(x)=\bot_{E}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x2200;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span></span></span></span></span>, the maximally uninformative function that just loops forever on all inputs.</p><p>The approximation order <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""&lt;&lt;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.077em;"">&lt;<span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em;"">&lt;</span></span></span></span></span></span></span> in the function space might be quite badly behaved, however. The function space might not even be a domain. In order to get the function space <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[D\to E]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span> to be a domain, you have to impose extra conditions on either <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> or <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span>. There are several possible extra conditions you can impose which get the function-space to be a domain (or algebraic domain), and also get the function-space to have the same property. So when we jump up to the category theory level, we typically work in some subcategory of domains that is closed under taking the function space.</p><p>One neat property of domains is that every continuous function from a domain to itself has a <em>least</em> fixed-point below all the other fixed points, and this least fixed-point also has a nice pretty description. The least fixed point of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f\in[D\to D]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>, is given by the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of the directed set <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> with elements: <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot, f(\bot), f(f(\bot)), f(f(f(\bot)))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>...</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot\le f(\bot)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> because <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> is below everything. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x\ge y\to f(x)\ge f(y)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> so repeatedly applying this shows that each element in the chain is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\ge""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span></span></span></span></span> the element below it. So it&apos;s a directed set and has a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>. The image of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> after applying <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> is just <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> itself (minus the bottom element). By continuity of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f(\sup A)=\sup_{a\in A}f(a)=\sup_{n\in\mathbb{N}}f^{n+1}(\bot)=\sup A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-munderover MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.36em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-munderover MJXc-space3""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.36em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2208;</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">N</span></span></span></span></span></span></span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base"" style=""margin-right: -0.06em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.181em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span>. So <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> is a fixed point of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>.</p><p>Also, the function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""fix:[D\to D]\to D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> that maps a function to its fixed point is continuous.</p><p>There&apos;s also a category-theory analogue of this same result, but it&apos;s quite a bit more complicated.</p><h2><strong>Quick note on notation:</strong></h2><p>The standard notation for composition of functions, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f \circ g""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">&#x2218;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span></span></span></span></span>, doesn&apos;t mesh well with intuition, because you have to read it backwards. First <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""g""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span></span></span></span></span> is applied, then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> is applied. This can be dealt with acceptably when you aren&apos;t composing that many functions, but later on in domain theory, you work up to some really complicated function compositions, so making up a notation that puts the functions the proper way around empirically made proofs vastly easier for me. From now on, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f;g;h""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span></span></span></span> will be a notation for &quot;first apply <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""g""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span></span></span></span></span>, then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span></span></span></span></span>&quot;. It&apos;s the same as <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""h \circ g \circ f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">h</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">&#x2218;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">&#x2218;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, but without the need to take ten seconds to mentally reverse the order whenever it shows up.</p><h2><strong>Embeddings and Projections:</strong></h2><p>An embedding-projection pair between a pair of domains <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> is a pair of continuous functions <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e:D\to E, p:E\to D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span>, s.t. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e;p=id_{D}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span></span></span></span></span>, and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p;e\le id_{E}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span></span></span></span></span>. In other words, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> is richer than <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> and has more information states available, so you can embed <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span>. Crunching <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> back down to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> via the projection, recovers <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> exactly (ie, the embedding doesn&apos;t identify different things, it&apos;s injective). However, projecting <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> down to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span>, and then embedding back into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> destroys information, so <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p;e(x)\le x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, which is equivalent to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p;e\le id_{E}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span></span></span></span></span>.</p><p>These are nice because an embedding uniquely determines a projection, and vice-versa. If you&apos;ve got an embedding, it&apos;s usually pretty easy to come up with a natural candidate for a projection, and once you verify the two defining properties of that pair of functions, you know there&apos;s nothing else you could substitute in (note that there may be many embedding/projection pairs! But once you fix one of the two, that uniquely determines the other part). </p><p>This comes in handy once we get up to the category theory level, because lots of times when you&apos;re drawing a diagram you&apos;re like &quot;damn, I need this arrow to go the other way&quot;, but if the arrow is an embedding or projection, you can just automatically get an arrow going the other way by going &quot;take the unique projection/embedding corresponding to the embedding/projection I already have&quot;. Normally you&apos;d need an isomorphism to pull off the &quot;reverse the arrows&quot; trick, but embeddings and projections also let you do that. Also all isomorphisms are embeddings and projections. </p><p>Also, embeddings and projections have the nice property that they have to be strict (ie, they must both map <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span>).</p><h2><strong>Category Theory Constructions:</strong></h2><p>So, there&apos;s several things you can do to a domain to get another domain. We already know about function-space, but there are others.</p><p>Cartesian product, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\times""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span></span></span></span></span>, is simple. It&apos;s the domain of pairs where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(x,y)\ge(z,a)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> iff <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x\ge z, y\ge a""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;"">z</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2265;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">a</span></span></span></span></span></span>.</p><p>These get you a cartesian closed category, if you are working in a sufficiently nice subcategory of domains where the function-space is forced to be a domain too and have the defining property of the subcategory.</p><p>Considering the subcategory of domains where the only morphisms are strict functions (functions which map <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span>), our candidate for the function space would be the strict function space, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""{[D\to E]}^{\bot !}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.71em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">!</span></span></span></span></span></span></span></span></span></span>, of all functions which map <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span>.</p><p>This doesn&apos;t harmonize with the cartesian product. However, there&apos;s another product. The smash product, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\otimes""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">&#x2297;</span></span></span></span></span></span>. It&apos;s like cartesian product, but all pairs with a <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> element in one of the coordinates are identified as the same point, the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> element of the product. Or, in other words, if one of the components of the pair loops forever, it&apos;s just classified as the loop-forever bottom element of the smash product.</p><p>Strict function space and smash product get you a monoidal closed category.</p><p>There&apos;s lifting, which is taking <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> and making a new domain <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{\bot}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span></span></span></span></span> by sticking a single new <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> element below everything in <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span>.</p><p>There&apos;s something called the coalesced sum, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\oplus""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">&#x2295;</span></span></span></span></span></span>, which corresponds to the coproduct in category theory. It&apos;s done by taking two domains <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span>, and identifying their bottom elements, which glues them together at the bottom point. The coalesced sum of the three-element domain that looks like a V, with itself, is a domain with 4 incomparable points, and a bottom element below them all.</p><p>So, function space, strict function space, cartesian product, smash product, coalesced sum, and lifting, are our basic building blocks.</p><p>There&apos;s one more rather complicated one, the bilimit, which plays a key role in generating fancy domains with seemingly-impossible type signatures.</p><h2><strong>The Bilimit:</strong></h2><p>Consider an infinite chain of domains indexed by the natural numbers, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{0}, D_{1}, D_{2}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span></span></span>... where, for all <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span>, there&apos;s an embedding <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n+1}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span></span></span>. Call this an expanding system. In other words, as you go further up the chain, the domains get more complicated and keep adding extra points while preserving the existing structure. This is the category-theory analogue of a chain (a type of directed set), analogous to the chain we made to construct a fixed point of a function. It&apos;s then reasonable to ask &quot;what&apos;s the analogue of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> in this context?&quot;</p><p> A composition of embeddings is an embedding (the projection is given by composing the corresponding projections), so we&apos;ve also got embeddings from any domain in this sequence to any higher domain, and projections from any domain in this sequence to any lower domain.</p><p>There&apos;s a very special domain called the bilimit, which is both a limit of the diagram with the projections, and a colimit of the diagram with the embeddings. Or, in other words, embedding <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> does the same thing as embedding <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{m}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span></span></span></span></span>, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m&gt;n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span>, and embedding <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{m}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>. Same with projection. It doesn&apos;t matter whether you project <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span>, or project <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{m}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span></span></span></span></span> and then into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span>. If something else is a limit or colimit, you can embed (or project) <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> into that thing as needed.</p><p>The bilimit can be thought of as the infinite product of the domains (equipped with the obvious ordering), but you only keep the points of the form <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""&lt;x_{0},x_{1},x_{2}...&gt;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&gt;</span></span></span></span></span></span> where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p_{n}(x_{n+1})=x_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span>. In other words, a point in the bilimit corresponds to some infinite sequence of points/ever-more-detailed information states from the ever-more-detailed domains, and crunching the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span>&apos;th domain (more detailed) down to the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span>&apos;th domain (less detailed) maps the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span>&apos;th coordinate (more detailed information state, ) down to the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span>&apos;th coordinate (less detailed information state). The bilimit of a finite sequence would just be the last domain in the sequence, because once you&apos;ve got the final coordinate, that fixes everything else. The bilimit of an infinite sequence is like the &quot;completion&quot; of the process of the domains getting more and more detailed.</p><p>To project from the bilimit to one of the finite stages, just take the appropriate coordinate, that gives you the point to map to. To embed from one of the finite stages to the bilimit, just project back to get points for the earlier stages, and embed forwards to get points for the later stages.</p><p>If you take a point <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> in the bilimit <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>, projecting to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D_{n}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span></span></span></span></span> and then embedding back into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> gets you a point <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""y\le x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;"">y</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, because project-then-embed moves points down. We can consider the batch of points in <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> given by projecting-then-embedding into some finite stage. This is a directed set, and the sup is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> itself. (ie, to get a close approximant for <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>, just project into some really distant domain and then embed back, that gets you a long initial sequence of coordinates that match up with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> itself)</p><p>This bilimit is the analogue of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>, on a category-theory level.</p><p>Since we&apos;re working in some subcategory of domains in order to make sure the function spaces work out alright, we&apos;d also want our defining property of the subcategory to be closed under bilimits as well. There are indeed some conditions you can impose so you&apos;re working in a subcategory closed under bilimits.</p><p>The nicest and most convenient such subcategory is the category of bifinite domains. There&apos;s a really complicated definition of them, but after putting in a lot of work, you can show that something is bifinite iff it&apos;s the bilimit of some expanding system of finite pointed posets. (ie, every bifinite domain can be written as the bilimit of an infinite sequence of finite partially ordered sets which all have a bottom element). Another cool note is that these are all algebraic (every point <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> can be made by taking the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of elements that approximate themselves that are below <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span>). The compact elements of a bilimit are those which can be made by taking a point at some finite stage and embedding it into the bilimit (ie, a point is compact only if it requires finitely much information to specify, you can complete the rest of the information by just embedding it forward forever once you get far enough)</p><p>The problem is that, since you&apos;ve gotta make it as a limit of finite domains, that impairs your ability to incorporate probabilities into things, since there are infinitely many probabilities. Incorporating probabilities into domains is one of the things on my to-learn list.</p><h2><strong>Category Theory + Domain Theory:</strong></h2><p>To complete the analogy and get an analogue of the least-fixpoint theorem, but for domains, we need an analogue of a continuous function (we have an analogue of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> in the form of the bilimit).</p><p>In this case, the analogue of a continuous function would be a continuous functor (more on what makes a functor continuous later). For example, consider the functor <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span> s.t. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(D)=[D\to X]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. A fixpoint of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span> would be a domain <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> that&apos;s isomorphic to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[D\to X]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. We also want our functor to map embeddings to embeddings for the upcoming application, so if there&apos;s an embedding <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e: D\to E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span>, we need <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(e)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> to be an embedding from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[D\to X]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[E\to X]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. If you&apos;ve got a functor with multiple inputs, then it needs to map tuples of embeddings to embeddings. Consider the cartesian product functor where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(D,E) =D\times E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span>. Given embeddings <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e: D\to D&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e&apos;:E\to E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(e,e&apos;)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> needs to be an embedding from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D\times E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D&apos;\times E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span><span class=""mjx-msup MJXc-space2""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>.</p><p>Let&apos;s do this for the function space, as that&apos;s the most complicated one. </p><p>Exercise: Do this for all the other constructors, like lifting and cartesian product and coalesced sum.</p><p>We have domains <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D, D&apos;, E, E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>, and embeddings <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e: D\to D&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e&apos;:E\to E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>. We want <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(e,e&apos;)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> to be an embedding from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[D\to E]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[D&apos;\to E&apos;]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. Well... we have a function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span></span></span></span> and we&apos;re trying to get a function from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>. Using <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>, we can get from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>. But we have to somehow get from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span>, but we only have an embedding going the other way...</p><p>But it&apos;s an embedding, so we can just use the unique projection <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span></span></span></span>, which goes the other way! This is what I was talking about with restricting to embeddings so you can get your arrows going the other way when the need arises.</p><p>Specifically, our candidate for the embedding is: <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(e,e&apos;)(f)=p;f;e&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>, and our candidate for the projection going the other way is to map <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""g: D&apos;\to E&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.026em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;"">E</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.119em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e;g;p&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>. Let&apos;s call this function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(e,e&apos;)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> for later use. It&apos;s a bit of work to show that these are continuous functions, so I&apos;m gonna skip that part, but I will show the part about these two things fulfilling the relevant conditions for embeddings and projections.</p><p>Condition 1: embedding then projecting had better recover your original point.</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(e,e&apos;);P(e,e&apos;)(f)=P(e,e&apos;)(p;f;e&apos;)=e;p;f;e&apos;;p&apos;=id_{D};f;id_{D&apos;}=f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">i</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.003em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.276em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.347em; padding-left: 0px; padding-right: 0.06em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> </p><p>by the definition of our embeddings and projections, and embed-then-project giving you identity.</p><p>Condition 2: projecting then embedding had better produce a lower point.</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(e,e&apos;);F(e,e&apos;)(g)=F(e,e&apos;)(e;g;p&apos;)=p;e;g;p&apos;;e&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span> </p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p;e;g;p&apos;;e&apos;(x)\le g;p&apos;;e&apos;(x)\le g(x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> so <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""p;e;g;p&apos;;e&apos;\le g""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.446em;"">p</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">;</span></span><span class=""mjx-msup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">&#x2264;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;"">g</span></span></span></span></span></span> </p><p>(again, by project-then-embed giving you a lower point, for the inequalities)</p><p>So our functor does map pairs of embeddings to embeddings.</p><p>Now do it with the other building blocks.</p><p>Anyways, returning to the original thing, we should go over the definition of continuity for a functor.</p><p>For an expanding sequence with bilimit <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>, applying the functor to the sequence gives you a different expanding sequence (because it maps embeddings to embeddings). This has a bilimit <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>.</p><p>A functor is continuous if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(B)\cong B&apos;""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-msup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">&#x2032;</span></span></span></span></span></span></span></span>. In other words it doesn&apos;t matter if you take the bilimit and shove it through the functor, or shove your sequence through the functor, and then take the bilimit of that. Swapping out &quot;functor&quot; for function, and &quot;bilimit&quot; for <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span>, we can see the close parallel to continuity of functions.</p><p>It&apos;s kinda hard to verify this condition, but there&apos;s a stronger one called local continuity which is a lot easier to check and implies continuity. For all the basic building blocks of domains (product, function space, lifting, coalesced sum, etc...), and compositions of them, the associated functors are continuous, which is quite nice.</p><h2><strong>Yo Dawg I Heard You Like Fixed Points:</strong></h2><p>Let&apos;s momentarily just look at continuous functors that only take one input, not multiple. Like the functor mapping <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\Lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&#x39B;</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[\Lambda\to \Lambda]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&#x39B;</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&#x39B;</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>, as a concrete example. We&apos;re going to be trying to complete the analogy to the original fixpoint theorem. We start with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span>, and keep applying our function to it to build up a chain, and then take the <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\sup""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">sup</span></span></span></span></span></span> of the chain, and that&apos;s the minimal fixed point. So what&apos;s the analogue of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\bot""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span> in a category-theory sense?</p><p>It&apos;s just the domain consisting of a single point, call it <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""I""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span></span></span></span>. And there&apos;s only one possible embedding from that to whatever domain you want, the embedding which maps the single point to the bottom element in the target domain.</p><p>So our expanding sequence is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""I, F(I), F(F(I)), F(F(F(I)))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.... and for the embeddings, we&apos;ve got our unique embedding <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""e""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span></span></span></span></span> from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""I""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(I)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, so <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(e)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is an embedding from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(I)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(F(I))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(F(e))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">e</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is an embedding from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(F(I))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(F(F(I)))""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>... Ok, we have our embeddings, and thus our projections. Now we take the bilimit <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>. By functor continuity, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(B)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>=bilimit of the expanding sequence shoved through <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span>. But shoving our expanding sequence through <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span> just gives us the same sequence, but with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""I""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;"">I</span></span></span></span></span></span> clipped off. This doesn&apos;t change the bilimit at all.</p><p>So, as desired, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F(B)\cong B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span>. And this is how you cook up mathematical spaces <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> isomorphic to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[X\to X]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. Or if you want a space <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> that&apos;s isomorphic to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X\times D""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span>, that also can be done.</p><p>Now, if you&apos;re attentive, you&apos;ll have noticed that this construction just gives you a single point as your canonical solution to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X\cong[X\to X]""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span></span></span></span>. This can be fixed by starting with something other than a single point (like a domain with two points, a top and a bottom), and then specifying a custom embedding from that into <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span></span></span></span>(2-point domain), giving you a full-blown model of the lambda calculus. But apparently the least fixed-point/canonical solution grants you extra-nice properties. I don&apos;t know what those are, since I haven&apos;t gotten to that chapter, but apparently you have more powerful tools available if you&apos;re working in the least-fixed-point domain instead of some other fixed-point.</p><p>There was a paper by Abramsky (<a href=""http://www.cs.ox.ac.uk/files/293/lazy.pdf"">here</a>) that looked at something called the lazy lambda calculus, which turns out to be exactly the least-fixed-point solution of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X\cong[X\to X]_{\bot}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span></span></span></span></span>, which I&apos;m still digesting. This is notable because adding an extra point at the bottom lets you get away from a single point. We start with the one-element domain, take the function space (still one-element domain), add a bottom element (ok, now we have two elements), take the function space of that (now three elements for the three possible continuous functions), add a bottom element, and from there it gets waay more complicated. </p><p>The analogue of the isomorphism between <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""[X\to X]_{\bot}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">&#x22A5;</span></span></span></span></span></span></span></span></span></span> in the computational sense is that you can take a lambda term (element of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span>), work on it until you get it into something called weak head normal form (a form like <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda x.M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">&#x3BB;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.372em;"">.</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span>), and then it&apos;s a function from lambda terms to lambda terms. The bottom element comes in because maybe the lambda term doesn&apos;t reduce to weak head normal form, and then the reduction process just loops forever, and that&apos;s the bottom element (because bottom elements correspond to stuff that just loops forever or doesn&apos;t return an output)</p><p>Now, with tupling and some more work, it&apos;s possible to even solve multiple fixpoints simaltaneously. If you&apos;ve got continuous functors <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""F_{1}, F_{2}, F_{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.106em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base"" style=""margin-right: -0.106em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base"" style=""margin-right: -0.106em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span></span></span></span></span>, then there&apos;s a least-fixpoint solution to:</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A\cong F_{1}(A,B,C)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.106em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> </p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B\cong F_{2}(A,B,C)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.106em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> </p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""C\cong F_{3}(A,B,C)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base"" style=""margin-right: -0.106em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;"">F</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;"">C</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> </p><p>So that&apos;s what domain theory can do. You can set up a bunch of isomorphisms that you want, of the form &quot;these domains should be isomorphic to these other domains that can be defined in terms of the basic building blocks like function space and smash product&quot;, and cook up a canonical solution. An example I&apos;m particularly interested in is (<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> is the three-element domain that looks like a V):</p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A\cong[B\to A]\oplus V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">&#x2295;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> </p><p> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B\cong[A\to B]\oplus V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char"" style=""padding-top: 0.298em; padding-bottom: 0.004em;""><span class=""mjx-charbox MJXc-TeX-main-R"" style=""padding-bottom: 0.314em; margin-right: -0.222em;"">&#x2245;</span></span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">[</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&#x2192;</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">]</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">&#x2295;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> </p><p>This corresponds to two domains of strategies, where a strategy is a continuous function from their strategy to your strategy, or it&apos;s one of two possible actions (or loop forever). So you can take two points in these, and repeatedly feed them to each other to either get looping forever, or a concrete action (the &quot;repeatedly play the strategies against each other&quot; function is a continuous function from <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A \times B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V \times V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">&#xD7;</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span>, though that&apos;s a bit tricky to show). This seems kinda like the full domain-theory version of <a href=""https://www.alignmentforum.org/posts/5bd75cc58225bf0670375058/superrationality-in-arbitrary-games"">Vanessa&apos;s metathreat hierarchy</a> without the restriction to operate on some fixed finite level, though I&apos;m not sure how to get probabilities in there.</p><p>More later on how to get those domains into something you can actually work with on a computer, once I learn that.</p>",Diffractor,diffractor,Diffractor,
qXwmMkEBLL59NkvYR,The LessWrong 2018 Review,the-lesswrong-2018-review,https://www.lesswrong.com/posts/qXwmMkEBLL59NkvYR/the-lesswrong-2018-review,2019-11-21T02:50:58.262Z,101,29,91,False,False,,"<html><head></head><body><p>LessWrong is currently doing a major review of 2018 — looking back at old posts and considering which of them have stood the tests of time. It has three phases:</p><ul><li>Nomination <i>(ends Dec 1st at 11:59pm PST)</i></li><li>Review <i>(ends Dec 31st)</i></li><li>Voting on the best posts <i>(ends January 7th)</i></li></ul><p>Authors will have a chance to edit posts in response to feedback, and then the moderation team will compile the best posts into a physical book and LessWrong sequence, with $2000 in prizes given out to the top 3-5 posts and up to $2000 given out to people who write the best reviews.</p><p><i>Helpful Links:</i></p><ul><li><a href=""https://www.lesswrong.com/allPosts?after=2018-01-01&amp;before=2019-01-01&amp;limit=100&amp;timeframe=allTime""><i>Top 2018 posts sorted by karma</i></a></li><li><a href=""https://www.lesswrong.com/allPosts?after=2018-01-01&amp;before=2019-01-01&amp;limit=20&amp;timeframe=monthly&amp;includeShortform=false&amp;reverse=true""><i>2018 posts aggregated by month</i></a></li><li><a href=""https://lesswrong.com/nominations""><i>You can see nominated posts here</i></a><i>&nbsp;</i></li></ul><hr><p>This is the first week of the LessWrong 2018 Review – an experiment in improving the LessWrong Community's longterm feedback and reward cycle.</p><p>This post begins by exploring the motivations for this project (first at a high level of abstraction, then getting into some more concrete goals), before diving into the details of the process.</p><h1>Improving the Idea Pipeline</h1><p>In his LW 2.0 Strategic Overview, <a href=""http://localhost:3000/posts/rEHLk9nC5TtrNoAKT/lw-2-0-strategic-overview"">habryka noted</a>:</p><blockquote><p>We need to build on each other’s intellectual contributions, archive important content, and avoid primarily being news-driven.</p><p>We need to improve the signal-to-noise ratio for the average reader, and only broadcast the most important writing</p><p>[...]</p><p>Modern science is plagued by <a href=""http://localhost:3000/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia"">severe problems</a>, but of humanity’s institutions it has perhaps the strongest record of being able to build successfully on its previous ideas.&nbsp;</p><p>The physics community has this system where the new ideas get put into journals, and then eventually if they’re important, and true, they get turned into textbooks, which are then read by the upcoming generation of physicists, who then write new papers based on the findings in the textbooks. All good scientific fields have good textbooks, and your undergrad years are largely spent reading them.</p></blockquote><p>Over the past couple years, much of my focus has been on the <strong>early-stages</strong> of LessWrong's idea pipeline – creating affordance for off-the-cuff conversation, brainstorming, and exploration of paradigms that are still under development (with features like <a href=""http://localhost:3000/shortform"">shortform</a> and <a href=""http://localhost:3000/posts/5Ym7DN6h877eyaCnT/meta-tations-on-moderation-towards-public-archipelago"">moderation tools</a>).</p><p>But, the beginning of the idea-pipeline is, well, not the end.</p><p>I've <a href=""http://localhost:3000/posts/rCzXcyM9Gt2pxmhcE/musings-on-lesswrong-peer-review"">written</a> a <a href=""http://localhost:3000/posts/f2GF3q6fgyx8TqZcn/literature-review-distributed-teams#FtF46bmPbgFt7tH5C"">couple times</a> about what the later stages of the idea-pipeline might look like. My best guess is still something like this:</p><blockquote><p>I want LessWrong to encourage extremely high quality intellectual labor. I think the best way to go about this is through escalating positive rewards, rather than strong initial filters.</p><p>Right now our highest reward is getting into the curated section, which... just isn't actually that high a bar. We only curate posts if we think they are making a good point. But if we set the curated bar at ""extremely well written and extremely epistemically rigorous and extremely useful"", we would basically never be able to curate anything.</p><p>My current guess is that there should be a ""higher than curated"" level, and that the general expectation should be that posts should only be put in that section after getting reviewed, scrutinized, and most likely rewritten at least once.&nbsp;</p></blockquote><p>I still have a lot of uncertainty about the right way to go about a review process, and various members of the LW team have somewhat different takes on it.</p><p>I've heard lots of complaints about mainstream science peer review: that reviewing is often a thankless task; the quality of review varies dramatically, and is often entangled with weird political games.</p><p>Meanwhile: LessWrong posts cover a variety of topics – some empirical, some philosophical. In many cases it's hard to directly evaluate their truth or usefulness. LessWrong team members had differing opinions on what sort of evaluation is most useful or practical.</p><p>I'm not sure if the best process is more open/public (harnessing the wisdom of crowds) or private (relying on the judgment of a small number of thinkers). The current approach involves a mix of both.</p><p>What I'm most confident in is that the review should focus on older posts.&nbsp;</p><p>New posts often feel exciting, but a year later, looking back, you can ask if it <i>actually</i> has become a helpful intellectual tool. (I'm also excited for the idea that, in future years, the process could also include reconsidering previously-reviewed posts, if there's been something like a ""replication crisis"" in the intervening time)</p><p>Regardless, I consider the LessWrong Review process to be an experiment, which will likely evolve in the coming years.&nbsp;</p><hr><h1>Goals</h1><p>Before delving into the process, I wanted to go over the high level goals for the project:</p><p><i>1. Improve our longterm incentives, feedback, and rewards for authors</i></p><p><i>2. Create a highly curated ""Best of 2018"" sequence / physical book</i></p><p><i>3. Create </i><a href=""http://localhost:3000/posts/9QxnfMYccz9QRgZ5z/the-costly-coordination-mechanism-of-common-knowledge""><i>common knowledge</i></a><i> about the LW community's collective epistemic state regarding controversial posts</i><br>&nbsp;</p><p><strong>Longterm incentives, feedback and rewards</strong></p><p>Right now, authors on LessWrong are rewarded essentially by comments, voting, and other people citing their work. This is fine, as things go, but has a few issues:</p><ul><li>Some kinds of posts are quite valuable, but <a href=""http://localhost:3000/posts/GHBLFPDhzeSQHx2eM/writing-that-provokes-comments"">don't get many comments</a> (and these disproportionately tend to be posts that are more proactively rigorous, because there's less to critique, or critiquing requires more effort, or building off the ideas requires more domain expertise)</li><li>By contrast, comments and voting both nudge people towards posts that are clickbaity and controversial.</li><li>Once posts have slipped off the frontpage, they often fade from consciousness. I'm excited for a LessWrong that rewards <a href=""https://www.gwern.net/About#long-content"">Long Content</a>, that stand the tests of time, as is updated as new information comes to light. (In some cases this may involve editing the original post. But if you prefer old posts to serve as a time-capsule of your post beliefs, adding a link to a newer post would also work)</li><li>Many good posts begin with an ""epistemic status: thinking out loud"", because, at the time, they were just thinking out loud. Nonetheless, they turn out to be quite good. Early-stage brainstorming is good, but if 2 years later the early-stage-brainstorming has become the best reference on a subject, authors should be encouraged to change that epistemic status and clean up the post for the benefit of future readers.</li></ul><p>The aim of the Review is to address those concerns by:&nbsp;</p><ul><li>Promoting old, vetted content directly on the site.</li><li>Awarding prizes not only to authors, but to reviewers. It seems important to directly reward high-effort reviews that thoughtfully explore both how the post could be improved, and how it fits into the broader intellectual ecosystem. (At the same time, <i>not</i> having this be the final stage in the process, since <a href=""https://rationalconspiracy.com/2017/01/03/four-layers-of-intellectual-conversation/"">building an intellectual edifice requires four layers of ongoing conversation</a>)</li><li>Compiling the results into a physical book. I find there's something... literally <i>weighty</i> about having your work in printed form. And because it's much harder to edit books than blogposts, the printing gives authors an extra incentive to clean up their past work or improve the pedagogy.</li></ul><p><strong>A highly curated ""Best of 2018"" sequence / book</strong></p><p>Many users don't participate in the day-to-day discussion on LessWrong, but want to easily find the best content.&nbsp;</p><p>To those users, a ""Best Of"" sequence that includes not only posts that seemed exciting at the time, but distilled reviews and followup, seems like a good value proposition. And meanwhile, helps move the site away from being time-sensitive-newsfeed.</p><p><strong>Common knowledge about the LW community's collective epistemic state regarding controversial posts</strong></p><p>Some posts are highly upvoted because everyone agrees they're true and important. Other posts are upvoted because they're more like exciting hypotheses. There's a lot of disagreement about which claims are actually true, but that disagreement is crudely measured in comments from a vocal minority.</p><p>The end of the review process includes a straightforward vote on which posts seem (in retrospect), useful, and which seem ""epistemically sound"". This is not the <i>end</i> of the conversation about which posts are making true claims that <a href=""http://localhost:3000/posts/yLcuygFfMfrfK8KjF/mutual-information-and-density-in-thingspace"">carve reality at it's joints</a>, but my hope is for it to ground that discussion in a clearer group-epistemic state.</p><hr><h1>Review Process</h1><h2>Nomination Phase<i>&nbsp;</i></h2><p><strong>1 week (Nov 20th – Dec 1st)</strong></p><ul><li>Users with 1000+ karma can nominate posts from 2018, describing how they found the post useful over the longterm.</li><li>The nomination button is in the post dropdown-menu (available at the top of posts, or to the right of their post-item)</li><li>For convenience, you can review posts via:<ul><li>a list of all 2018 posts, <a href=""https://lesswrong.com/allPosts?after=2018-01-01&amp;before=2019-01-01&amp;limit=100&amp;timeframe=allTime&amp;sortedBy=top"">sorted by karma</a></li><li>if you want a more in-depth overview, <a href=""https://lesswrong.com/allPosts?after=2018-01-01&amp;before=2019-01-01&amp;timeframe=monthly&amp;sortedBy=top&amp;reverse=true&amp;includeShortform=false"">2018 posts clustered by month</a></li></ul></li></ul><h2>Review Phase<i>&nbsp;</i></h2><p><strong>4 weeks (Dec 1st – Dec 31st)</strong></p><ul><li>Authors of nominated posts can opt-out of the review process if they want.<ul><li><i>They also can opt-in, while noting that they probably won't have time to update their posts in response to critique. (This may reduce the chances of their posts being featured as prominently in the Best of 2018 book)</i></li></ul></li><li>Posts with sufficient* nominations are announced as contenders.<ul><li><i>We're aiming to have 50-100 contenders, and the nomination threshold will be set to whatever gets closest to that range</i></li></ul></li><li>For a month, people are encouraged to look at them thoughtfully, writing comments (or posts) that discuss:<ul><li>How has this post been useful?</li><li>How does it connect to the broader intellectual landscape?</li><li>Is this post epistemically sound?</li><li>How could it be improved?</li><li>What further work would you like to see people do with the content of this post?</li></ul></li><li>A good frame of reference for the reviews are shorter versions of LessWrong or SlatestarCodex book reviews (which do a combination of epistemic spot checks, summarizing, and contextualizing)</li><li>Authors are encouraged to engage with reviews:<ul><li>Noting where they disagree</li><li>Discussing what sort of followup work they'd be interested in seeing from others</li><li>Ideally, updating the post in response to critique they agree with</li></ul></li></ul><h2><i>Voting Phase</i></h2><p><strong>&nbsp;1 Week (Jan 1st – Jan 7th)</strong></p><p>Posts that got at least one review proceed to the voting phase. The details of this are still being fleshed out, but the current plan is:</p><ul><li>Users with 1000+ karma rate each post on a 1-10 scale, with 6+ meaning<i> ""I'd be happy to see this included in the 'best of 2018'""</i> roundup, and 10 means <i>""this is the best I can imagine""</i></li><li>Users are encouraged to (optionally) share the reasons for each rating, and/or share thoughts on their overall judgment process.</li></ul><h2><i>Books and Rewards</i></h2><p><strong>Public Writeup / Aggregation</strong></p><p>Soon afterwards (hopefully within a week), the votes will all be publicly available. A few different aggregate statistics will be available, including the raw average, and potentially some attempt at a ""karma-weighted average.""</p><p><strong>Best of 2018 Book / Sequence</strong></p><p>Sometime later, the LessWrong moderation team will put together a physical book, (and online sequence), of the best posts and most valuable reviews<i>.&nbsp;</i></p><p>This will involve a lot of editor discretion – the team will essentially take the public review process and use it as input for the construction of a book and sequence.&nbsp;</p><p>I have a lot of uncertainty about the shape of the book. I'm guessing it'd include anywhere from 10-50 posts, along with particularly good reviews of those posts, and some additional commentary from the LW team.</p><p><i>Note: This may involve some custom editing to handle things like hyperlinks, which may work differently in printed media than online blogposts. This will involve some back-and-forth with the authors.</i></p><p><strong>Prizes</strong></p><ul><li>Everyone whose work is featured in the book will receive a copy of it.</li><li>There will be $2000 in prizes divided among the authors of the top 3-5 posts (judged by the moderation team)</li><li>There will be <strong>up to</strong> $2000 in prizes for the best 0-10 reviews that get included in the book. (The distribution of this will depend a bit on what reviews we get and how good they are)</li><li><i>(note: LessWrong team members may be participating as reviewers and potentially authors, but will not be eligible for any awards)</i></li></ul></body></html>",Raemon,raemon,Raemon,
EErbhm6s9aWnvY9ha,"[1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model | Arxiv",1911-08265-mastering-atari-go-chess-and-shogi-by-planning,https://www.lesswrong.com/posts/EErbhm6s9aWnvY9ha/1911-08265-mastering-atari-go-chess-and-shogi-by-planning,2019-11-21T01:18:25.722Z,52,15,4,False,False,https://arxiv.org/abs/1911.08265,,DragonGod,dragongod,DragonGod,
jMNp7W8gXYxFGXRhm,"A fun calibration game: ""0-hit Google phrases""",a-fun-calibration-game-0-hit-google-phrases,https://www.lesswrong.com/posts/jMNp7W8gXYxFGXRhm/a-fun-calibration-game-0-hit-google-phrases,2019-11-21T01:13:10.667Z,6,4,1,False,False,,"<p>Here&apos;s a simple calibration game: propose some phrase(s), like &quot;the ultimate east care pant&quot; (something one of my pairs of pants say) and ask &quot;How likely is it that Google return no search results for this phrase (in quotes)?&quot;</p><br>",capybaralet,david-scott-krueger-formerly-capybaralet,David Scott Krueger (formerly: capybaralet),
pW2p5synCNCT6HQaa,Junto: Questions for Meetups and Rando Convos,junto-questions-for-meetups-and-rando-convos,https://www.lesswrong.com/posts/pW2p5synCNCT6HQaa/junto-questions-for-meetups-and-rando-convos,2019-11-20T22:11:55.350Z,24,11,1,False,False,,"<p>I ponder a lot about community and how important local community is for the functioning of society; many are the riches brought from afar by long distance communication. Nonetheless, local rationality meetups can increase local metis by generating intelligent community. I read in Isaacson&#x2019;s biography of Benjamin Franklin how he (Franklin) employed his Junto to advance scientific knowledge, civil society, and business; there are some great examples there. But the Wikipedia page will do well enough for an overview.</p><p><a href=""https://en.wikipedia.org/wiki/Junto_(club)"">https://en.wikipedia.org/wiki/Junto_(club)</a></p><p>What I have done here is taken the Junto discussion questions of Franklin&apos;s club and reformulated them to serve as a model for the types of questions we can be asking each other to keep advancing community and local knowledge.</p><ol><li>Have you read anything useful or insightful recently? Particularly in technology, history, literature, science, or other fields of knowledge?</li><li>What problems have you been thinking about recently?</li><li>Has there been any worthwhile or important local news?</li><li>Have any businesses failed lately, and do you know anything about the cause?</li><li>Have any businesses recently risen in success, how so?</li><li>Do you know of anyone, who has recently done something interesting, praiseworthy or worthy of imitation? Or who has made a mistake we should be warned against and avoid?</li><li>Have you been doing anything recently to increase your psychological and physical health?</li><li>Is there any person whose acquaintance you want, and which someone in the group can procure for you?</li><li>Do you think of anything at present by which the group could easily do something useful?</li><li>Do you know of any deserving younger person, for whom it lies in the power of the group to encourage and help advance in his career?</li><li>Do you see anything amiss in the present customs or proceedings of the group, which might be amended?</li></ol>",JohnBuridan,johnburidan,SebastianG ,
8ZQ88dJrCo2QoZoFA,Thinking of tool AIs,thinking-of-tool-ais,https://www.lesswrong.com/posts/8ZQ88dJrCo2QoZoFA/thinking-of-tool-ais,2019-11-20T21:47:36.660Z,6,5,2,False,False,,"<p>Preliminary note: the ideas in the post emerged during the Learning-by-doing AI safety workshop at EA Hotel; special thanks to Linda Linsefors, Davide Zagami and Grue_Slinky for giving suggestions and feedback.</p>
<p>As the title anticipates, long-term safety is not the main topic of this post; for the most part, the focus will be on current AI technologies. More specifically: why are we (un)satisfied with them from a safety perspective? In what sense can they be considered tools, or services?</p>
<p>An example worth considering is the <a href=""https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf"">YouTube recommendation algorithm</a>. In simple terms, the job of the algorithm is to find the videos that best fit the user and then suggest them. The expected watch time of a video is a variable that heavily influences how a video is ranked, but the objective function is likely to be complicated and probably includes variables such as click-through rate and session time.<sup class=""footnote-ref""><a href=""#fn-xbNxQhYPQYRGgCqNg-1"" id=""fnref-xbNxQhYPQYRGgCqNg-1"">[1]</a></sup> For the sake of this discussion, it is sufficient to know that the algorithm cares about the time spent by the user watching videos.</p>
<p>From a safety perspective - even without bringing up existential risk - the current objective function is simply wrong: a universe in which humans spend lots of hours per day on YouTube is not something we want. The YT algorithm has the same problem that Facebook had in the past, when it was maximizing click-throughs.<sup class=""footnote-ref""><a href=""#fn-xbNxQhYPQYRGgCqNg-2"" id=""fnref-xbNxQhYPQYRGgCqNg-2"">[2]</a></sup> This is evidence supporting the thesis that we don't necessarily need AGI to <a href=""https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like"">fail</a>: if we keep producing software that optimizes for easily measurable but inadequate targets, we will steer the future towards worse and worse outcomes.</p>
<hr>
<p>Imagine a scenario in which:</p>
<ul>
<li>human willpower is weaker than now;</li>
<li>hardware is faster than now, so that the YT algorithm manages to evaluate a larger number of videos per time unit and, as a consequence, gives the user better suggestions.</li>
</ul>
<p>Because of these modifications, humans could spend almost all day on YT. It is worth noting that, even in this semi-catastrophic case, the behaviour of the AI would be more tool-ish than AGI-like: it would not actively oppose its shutdown, start acquiring new resources, develop an accurate model of itself in order to self-improve, <a href=""https://pdfs.semanticscholar.org/4618/cbdfd7dada7f61b706e4397d4e5952b5c9a0.pdf"">et cetera</a>.</p>
<p>From that perspective, the video recommendation service seems much more dangerous than what we usually indicate with the term tool AI. How can we make the YT algorithm more tool-ish? What <em>is</em> a tool?</p>
<p>Unsurprisingly, it seems we don't have a clear definition yet. In his paper about <a href=""https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf"">CAIS</a>, Drexler writes that it is typical of services to deliver bounded results with bounded resources in bounded times.<sup class=""footnote-ref""><a href=""#fn-xbNxQhYPQYRGgCqNg-3"" id=""fnref-xbNxQhYPQYRGgCqNg-3"">[3]</a></sup>
Then, a possible solution is to put a constraint on the time that a user can spend on YT over a certain period. In practice, this could be done by forcing the algorithm to suggest random videos when the session time exceeds a threshold value: in fact, this solution doesn't even require a modification of the main objective function. In the following, I will refer to this hypothetical fixed version of the algorithm as ""constrained YT algorithm"" (cYTa).</p>
<p>Even though this modification would prevent the worst outcomes, we would still have to deal with subtler problems like <a href=""https://en.wikipedia.org/wiki/Echo_chamber_(media)"">echo chambers</a> and <a href=""https://en.wikipedia.org/wiki/Filter_bubble"">filter bubbles</a>, which are caused by the fact that recommended videos share something in common with the videos watched by the user in the past.<sup class=""footnote-ref""><a href=""#fn-xbNxQhYPQYRGgCqNg-4"" id=""fnref-xbNxQhYPQYRGgCqNg-4"">[4]</a></sup>
So, if our standards of safety are set high enough, the example of cYTa shows that the criterion ""bounded results, resources and time"" is insufficient to guarantee positive outcomes.</p>
<hr>
<p>In order to better understand what we want, it may be useful to consider current AI technologies that we are satisfied with. Take Google Maps, for example: like cYTa, it optimizes within hard constraints and can be easily shut down.
However, GMaps doesn't have a known negative side effect comparable to echo chambers; from this point of view, also AIs that play strategy games (e.g. Deep Blue) are similar to GMaps.</p>
<p>Enough with the examples! I claim that the ""idealized safe tool AI"" fulfills the following criteria:</p>
<ol>
<li><a href=""https://arbital.com/p/corrigibility/"">Corrigibility</a></li>
<li>Constrained optimization</li>
<li>No negative side effects</li>
</ol>
<p>Before I get insulted in the comments because of how [insert_spicy_word] this list is, I'm going to spell out some details.
First, I've simply listed three properties that seem necessary if we want to talk about an AI technology that doesn't cause any sort of problem. I wouldn't be surprised if the list turned out to be non-exhaustive and I don't mean it to be taken as a definition of the concept ""tool"" or ""service"". At the same time, I think that these two terms are too under-specified at the moment, so adding some structure could be useful for future discussions.
Moreover, it seems to me that 3 implies 2 because, for each variable that is left unconstrained during optimization, side effects usually become more probable; in general, 3 is a really strong criterion. Instead, 1 seems to be somewhat independent from the others.
Last, even though the concept is idealised, it is not so abstract that we don't have a concrete reference point: GMaps works well as an example.<sup class=""footnote-ref""><a href=""#fn-xbNxQhYPQYRGgCqNg-5"" id=""fnref-xbNxQhYPQYRGgCqNg-5"">[5]</a></sup></p>
<p>Where do we go from here? We can start by asking whether what has been said about CAIS is still valid if we replace the term service with the concept of idealized safe tool. My intuition is that the answer is yes and that the idealized concept can actually facilitate the analysis of some of the ideas presented in the paper.
Another possible question is to what extent a single superintelligent agent can adhere to 3; or, in other words, whether limiting an AI's side effects also constrains its capability of achieving goals. These <a href=""https://arxiv.org/abs/1606.06565"">two</a> <a href=""https://intelligence.org/files/AlignmentMachineLearning.pdf"">papers</a> already highlighted the importance of negative side effects and impact measures, but we are still far from getting a solid satisfactory answer.</p>
<hr>
<h3>Summary</h3>
<p>Just for clarity purposes, I recap the main points presented here:</p>
<ul>
<li>Even if AGI was impossible to obtain, AI safety wouldn’t be solved; thinking of tools as naturally safe is a mistake.</li>
<li>As shown by the cYTa example, putting strong constraints on optimization is not enough to ensure safety.</li>
<li>An idealized notion of safe tool is proposed. This should give a bit more context to previously discussed ideas (e.g. CAIS) and may stimulate future research or debate.</li>
</ul>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-xbNxQhYPQYRGgCqNg-1"" class=""footnote-item""><p>All the details are not publicly available and the algorithm is changed frequently. By googling ""YouTube SEO"" I managed to <a href=""https://backlinko.com/hub/youtube/watch-time"">find</a> <a href=""https://backlinko.com/hub/youtube/retention"">these</a>, but I don't know how reliable the source is. <a href=""#fnref-xbNxQhYPQYRGgCqNg-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-xbNxQhYPQYRGgCqNg-2"" class=""footnote-item""><p>As stated by Yann LeCun in this <a href=""https://www.lesswrong.com/posts/WxW6Gc6f2z3mzmqKs/debate-on-instrumental-convergence-between-lecun-russell"">discussion</a> about instrumental convergence: ""[...] Facebook stopped maximizing clickthroughs several years ago and stopped using the time spent in the app as a criterion about 2 years ago. It put in place measures to limit the dissemination of clickbait, and it favored content shared by friends rather than directly disseminating content from publishers."" <a href=""#fnref-xbNxQhYPQYRGgCqNg-2"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-xbNxQhYPQYRGgCqNg-3"" class=""footnote-item""><p>Page 32. <a href=""#fnref-xbNxQhYPQYRGgCqNg-3"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-xbNxQhYPQYRGgCqNg-4"" class=""footnote-item""><p>With cYTa, the user will experience the filter bubble only until the threshold is reached; the problem would be only slightly reduced, not solved. If the threshold is set really low then the problem is not relevant anymore, but at the same time the algorithm becomes useless because it recommends random videos for most of the time. <a href=""#fnref-xbNxQhYPQYRGgCqNg-4"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-xbNxQhYPQYRGgCqNg-5"" class=""footnote-item""><p>In order to completely fulfill 3, we have to neglect stuff like possible car accidents caused by distraction induced by the software. Analogously, an AI like <a href=""https://en.wikipedia.org/wiki/AlphaZero"">AlphaZero</a> could be somewhat addicting for the average user who likes winning at strategy games. In reality, every software can have negative side effects; saying that GMaps and AlphaZero have none seems a reasonable approximation. <a href=""#fnref-xbNxQhYPQYRGgCqNg-5"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
",Michele Campolo,michele-campolo,Michele Campolo,
QKyvibvccetFyBqtp,"Doxa, Episteme, and Gnosis Revisited",doxa-episteme-and-gnosis-revisited,https://www.lesswrong.com/posts/QKyvibvccetFyBqtp/doxa-episteme-and-gnosis-revisited,2019-11-20T19:35:39.204Z,19,9,2,False,False,,"<p>Exactly two years to the day I started writing this post I published <a href=""https://mapandterritory.org/"">Map and Territory's</a> most popular post of all time, ""<a href=""https://mapandterritory.org/doxa-episteme-and-gnosis-ea35e4408edd"">Doxa, Episteme, and Gnosis</a>"" (<a href=""https://www.lesswrong.com/posts/vGj9QcxCryjeD2r3m/doxa-episteme-and-gnosis"">also here on LW</a>). In that post I describe a distinction ancient Greek made between three kinds of knowledge we might translate as hearsay, justified belief, and direct experience, respectively, although if I'm being totally honest I'm nowhere close to being a classics scholar so I probably drew a distinction between the three askew to the one ancient Attic Greeks would have made. Historical accuracy aside, the distinction has proven useful over the past couple years to myself and others, so I thought it was worth revisiting in light of all I have learned in the intervening time.</p><h1>Nuanced Distinctions</h1><p>To start, I still draw the categories of doxa, episteme, and gnosis roughly the same as I did before. To quote myself:</p><blockquote>Doxa is what in English we might call hearsay. It’s the stuff you know because someone told you about it. If you know the Earth is round because you read it in a book, that’s doxa.</blockquote><blockquote>Episteme is what we most often mean by “knowledge” in English. It’s the stuff you know because you thought about it and reasoned it out. If you know the Earth is round because you measured shadows at different locations and did the math to prove that the only logical conclusion is that the Earth is round, that’s episteme.</blockquote><blockquote>Gnosis has no good equivalent in English, but the closest we come is when people talk about personal experience because gnosis is the stuff you know because you experienced it. If you know the Earth is round because you traveled all the way around it or observed it from space, that’s gnosis.</blockquote><p>There's more nuance to it than that, of course. Doxa, for example, also refers to thoughts, beliefs, ideas, propositions, statements, and words in addition to its connotations of hearsay, common belief, and popular opinion. Episteme, to Plato, was the combination of doxa and logos, contrary to my example above where I root episteme in observational evidence, although then again maybe not because ""logos"" can mean not only ""reason"", ""account"", ""word"", and ""speech"" but also ""ground"" or ""ultimate cause"". And gnosis, despite its connotations in English as a special kind of insightful knowledge about the true nature of existence as a result of its use by Christian mystics, shares the same root or is the root via borrowing of the word for ""knowledge"" in most European languages, English included.</p><p>Further, the boundaries between the three categories are not always clear. We've already seen one way this is so, where I described episteme in a way that it's grounded by gnosis via the direct experience of observation, but this is an empiricist perspective on what episteme is and there's an equally valid notion, in terms of category construction, of episteme as <a href=""http://selfpace.uconn.edu/class/percep/DescartesMeditations.pdf"">reasoning from first thought</a> within a <a href=""https://plato.stanford.edu/entries/rationalism-empiricism/"">traditional rationalist perspective</a>. Another is that all knowledge is in a certain sense gnosis because <a href=""https://www.lesswrong.com/posts/wvAEHzE55K7vfsXWz/introduction-to-noematology"">there must have been some experience by which you gained the knowledge</a> (unless you really want to double down on rational idealism and go full Platonist), although this need not confuse us if we understand the difference between the experience of something and <a href=""https://www.lesswrong.com/posts/QeMJH94B9raXDSvJ3/methods-of-phenomenology"">the something quoted/bracketed within the experience</a>. And similarly, all knowledge we speak of must first become doxa in our own minds that we tell ourselves before it becomes doxa for others by being <a href=""https://www.lesswrong.com/posts/ix3KdfJxjo9GQFkCo/web-of-connotations-bleggs-rubes-thermostats-and-beliefs"">put into words that draw common distinctions</a>, hence episteme and gnosis can only be generated and never directly transmitted.</p><h1>Additional Categories</h1><p>In addition to doxa, episteme, and gnosis, we can draw additional distinctions that are useful for thinking about knowledge.</p><p>One is metis, or practical wisdom. This is the knowledge that comes from hard won experience, <a href=""https://www.lesswrong.com/posts/Zm7WAJMTaFvuh2Wc7/book-review-the-secret-of-our-success"">possibly over many generations</a> such that no one even knows where it came from. Metis is often implicit or exists via its application and <a href=""https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/"">may look nonsensical or unjustified if made explicit</a>. To return to my original examples, this would be like knowing to take a great circle route on a long migration because it's the traditional route despite not knowing anything about the roundness of Earth that would let you know it's the shortest route.</p><p>Related to metis is techne, or procedural knowledge or the knowing that comes from doing. In English we might use a phrase like ""muscle memory"" to capture part of the idea. It's like the knowledge of how to walk or ride a bike or type on a keyboard or throw a clay pot, and also the kind of knowledge that produces things like mathematical intuition, the ability to detect code smell, and a gut sense of what is right. It's knowledge that co-arises with action.</p><p>I'm sure we could capture others. Both metis and techne draw out distinctions that would otherwise disappear within doxa and gnosis, respectively. We can probably make further distinctions for, say, episteme that is grounded in gnosis vs. episteme that is grounded in doxa, gnosis about other types of knowledge, and doxa derived by various means. We are perhaps only limited by our need to make these distinctions and sufficient Greek words with which to make them.</p><h1>Relationships</h1><p>Rather than continuing down the path of differentiation, let's look instead at how our three basic ways of knowing come together and relate to one another. In the original post I had this to say about the way doxa, episteme, and gnosis interact:</p><blockquote>Often we elide these distinctions. Doxa of episteme is frequently thought of as episteme because if you read enough about how others gained episteme you may feel as though you have episteme yourself. This would be like hearing lots of people tell you how they worked out that the Earth is round and thinking that this gives you episteme rather than doxa. The mistake is understandable: as long as you only hear others talk about their episteme it’s easy to pattern match and think you have it too, but as soon as you try to explain your supposed episteme to someone else you will quickly discover if you only have doxa instead. The effect is so strong that experts in fields often express that they never really knew their subject <a href=""https://skeptics.stackexchange.com/questions/8742/did-einstein-say-if-you-cant-explain-it-simply-you-dont-understand-it-well-en"">until they had to teach it</a>.</blockquote><blockquote>In the same way episteme is often mistaken for gnosis. At least since the time of Ptolemy people have had episteme of the spherical nature of the Earth, and since the 1970s most people have seen pictures showing that the Earth is round, but astronauts continue <a href=""https://en.wikipedia.org/wiki/Overview_effect"">to experience gnosis of Earth’s roundness the first time they fly in space</a>. It seems no matter how much epistemic reckoning we do or how accurate and precise our epistemic predictions are, we are still sometimes surprised to experience what we previously only believed.</blockquote><blockquote>But none of this is to say that gnosis is better than episteme or that episteme is better than doxa because each has value in different ways. Doxa is the only kind of knowledge that can be reliably and quickly shared, so we use it extensively in lieu of episteme or gnosis because both impose large costs on the knower to figure things out for themselves or cultivate experiences. Episteme is the only kind of knowledge that we can prove correct, so we often seek to replace doxa and gnosis with it when we want to be sure of ourselves. And gnosis is the only kind of knowledge available to <a href=""https://mapandterritory.org/is-feedback-suffering-cf18006deca8"">non-sentient processes</a>, so unless we wish to spend our days in disembodied deliberation we must at least develop gnosis of doxastic and epistemic knowledge to <a href=""https://entirelyuseless.wordpress.com/2017/10/06/the-self-and-disembodied-predictive-processing/"">give the larger parts of our brains</a> information to work with. So all three kinds of knowledge must be used together in our pursuit of understanding.</blockquote><p>That sounds pretty nice, like all three kinds of knowledge need to exist in harmony. In fact, I even said as much by concluding the original with an evocative metaphor:</p><blockquote>It’s coincidental that ancient Greek chose to break knowledge into three kinds rather than two or four or five, but because it did we can think of doxa, episteme, and gnosis like the three legs of a stool. Each leg is necessary for the stool to stand, and if any one of them is too short or too long the stool will wobble. Pull one out and the stool will fall over. Only when all three are combined in equal measure do we get a study foundation to sit and think on.</blockquote><p>Alas, I got some things wrong in the original with how I described the relationship between these three aspects of knowledge, specifically in the way things fall apart when the three aspects are not balanced. I won't reprint those words here to avoid spreading confusion, and will rather try to make amends by better describing what can happen when we privilege one kind of knowledge over the others.</p><p>To <strong>privilege doxa</strong> is to value words, thoughts, and ideas over reason and experience. This position is sometimes compelling: as the saying goes, if you can't explain something, you don't really understand it, and to explain it you must have and generate doxa. Further, doxa lets you engage with the world at a safe distance <a href=""https://www.lesswrong.com/posts/PeSzc9JTBxhaYRp9b/policy-debates-should-not-appear-one-sided"">without getting your hands dirty</a>, but this <a href=""https://areomagazine.com/2017/03/27/how-french-intellectuals-ruined-the-west-postmodernism-and-its-impact-explained/"">comes with the risk</a> of becoming detached, unhinged, ungrounded, unroot, disconnected, and otherwise <a href=""https://www.lesswrong.com/posts/PQ3nutgxfTgvq69Xt/all-debates-are-bravery-debates"">uncorrelated with reality because</a>, on its own, doxa is nothing more than <a href=""https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences"">empty words</a>. The people we pejoratively claim to put doxa first are sophists, pundits, ivory-tower intellectuals, certain breeds of bloggers, and, of course, gossips. The remedy for their condition is to spend more <a href=""https://www.lesswrong.com/posts/aSQy7yHj6nPD44RNo/how-to-seem-and-be-deep"">time thinking for oneself</a> and experiencing life.</p><p>When we <strong>privilege episteme</strong> we believe our own reason over and above what wisdom and experience tell us. The appeal of favoring episteme lies in noticing that wisdom and experience can mislead us, such that if we just <a href=""https://www.lesswrong.com/posts/erGipespbbzdG5zYb/the-third-alternative"">bothered to think for 5 minutes</a> we would have noticed they were wrong. And, of course, sometimes they are, but if we continue down this path we run into infinite inferential regress, the uncomputable universal prior, the problem of the criterion, <a href=""https://www.iep.utm.edu/ep-circ/"">epistemic circularity</a>, and more mundane problems like <a href=""http://brianpdx.blogspot.com/2004/08/mistakes.html"">making commonly known mistakes</a>, ignoring our <a href=""https://www.lesswrong.com/posts/noXTkjP45BAZqKJxM/focusing"">experiences</a> because we don't <a href=""https://www.lesswrong.com/posts/PXqQhYEdbdAYCp88m/focusing-for-skeptics"">understand them</a>, and otherwise failing because we <a href=""https://www.lesswrong.com/posts/2MD3NMLBPCqPfnfre/cached-thoughts"">didn't reckon</a> we would. Putting episteme first is the failure mode of high modernists, logical positivists, traditional rationalists, and internet skeptics. If we fall victim to their mistakes, the solution lies with finding the <a href=""https://www.lesswrong.com/posts/b8PMegKmjLoWtAH7N/clarifying-the-postmodernism-debate-with-skeptical-modernism"">humility</a> to accept that sometimes other people know things even when we don't and <a href=""https://www.lesswrong.com/posts/mELQFMi9egPn5EAjK/my-attempt-to-explain-looking-insight-meditation-and"">to trust our lived experiences</a> to be just as they are, nothing more and nothing less.</p><p>Finally, <strong>privileging gnosis</strong> is to rely on our experiences at the expense of reason and wisdom. There's a certain logic to the radical empiricism of this approach: what I can know for sure is what I experience with my eyes, ears, nose, tongue, body, and mind, and every other way of knowing is a secondary source. But this <a href=""https://www.lesswrong.com/posts/7HY8HaRdFFnpeT9gx/highlights-from-integral-spirituality"">leaves out</a> the important contributions of what we can know about the world that <a href=""https://www.lesswrong.com/posts/5LP6Jc8ztwcyb296X/outline-of-metarationality-or-much-less-than-you-wanted-to"">lies beyond</a> our direct experience where we learn from others and from reasoning, effectively <a href=""https://meaningness.com/metablog/rationalism-critiques"">giving up</a> the epistemic benefits that come with language. Solipsists, hippies, mystics, and occultists are among the folk who tend to value gnosis over episteme and doxa. For them we might advise listening more to others and spending <a href=""https://www.lesswrong.com/rationality"">more time at rigorous, precise, and careful thought</a> to <a href=""https://meaningness.com/metablog/how-to-think"">balance out</a> their over-strong belief in what they experience.</p><p>Walking the middle way between these three attractors is not easy. If nothing else, there's a certain temptation that can arise to <a href=""https://www.lesswrong.com/posts/tAXrD8Y6hcJ8dt6Nt/the-curse-of-identity"">identify</a> with the way of knowing you like best and the people who engage most with that way of knowing. I encourage you to resist it! You can <a href=""https://www.lesswrong.com/posts/nYkMLFpx77Rz3uo9c/belief-as-attire"">hang out</a> with and <a href=""https://www.lesswrong.com/posts/4Bwr6s9dofvqPWakn/science-as-attire"">wear the attire</a> of an intellectual, a rationalist, or a hippie without succumbing to their stereotypical epistemological failure modes of excess doxa, episteme, and gnosis. There is no special virtue in making wrong predictions about the world, regardless of how you came to make that wrong prediction. Instead, you can aspire to <a href=""https://www.lesswrong.com/posts/sP2Hg6uPwpfp3jZJN/lost-purposes"">remain a sharp blade that cuts to the truth</a> no matter <a href=""https://meaningness.com/eggplant"">the whetstone</a> used to hone the blade or <a href=""https://www.lesswrong.com/posts/svoD5KLKHyAKEdwPo/against-modest-epistemology"">the stance</a> from which the cut is made.</p><h1>Beyond Distinctions</h1><p>If it's the case that there's no special privileging of one kind of knowledge over another and the path to truth lies with combining them all, you might ask why make any distinctions at all? Certainly it feels at times useful to draw these distinctions, but as we've seen these distinctions are blurry, nuanced, and blend into each other. What about the alternative of unifying these kinds into a single concept that captures them all?</p><p>By itself the English word ""knowledge"" fails to do that adequately because it tends to point towards explicit knowledge and disregards that which is known implicitly and that which is inseparable from its embeddedness in the world, and we know this because it's noteworthy to point out ways that things like gnosis and metis and techne can count as knowing. So what is the thing that ties these notions all together?</p><p>I think it's worth considering what it means to know something. <a href=""https://www.lesswrong.com/posts/nfMfxdXKjhhTJD3Jd/the-world-as-phenomena-1"">Knowing is an intentional act</a>: a subject (you, me, them) knows an object (the something known). Thus it is a kind of relationship between subject and object where the subject experiences the object in a particular way we consider worth distinguishing as ""knowing"" from <a href=""https://www.lesswrong.com/posts/wvAEHzE55K7vfsXWz/introduction-to-noematology"">other forms of experience</a>. In knowing the object seems to always be something mental, viz. <a href=""https://www.lesswrong.com/posts/M7Z5sm6KoukNpF3SD/form-and-feedback-in-phenomenology"">the object is information</a> not stuff, ontological not ontic. For example, you might say I can't know the cup on my desk directly, only the experience of it in my mind—the <a href=""https://plato.stanford.edu/entries/kant-transcendental-idealism/"">noumenon</a> of the cup is not known, only the phenomenon of it. And from there we can notice that knowing is not a single experience, but composed of multiple motions: initial contact with a mental object, categorization of the object in terms of ontology, evaluation of it, possible recollection of related mental objects (memories), integration into a network of those related mental objects, and self-reflection on the experience of the mental object.</p><p>Given the complexity of the knowing act, I'm inclined to infer that even if the <a href=""https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/"">neurological processes</a> that enable knowing can be thought of as a unified system, its <a href=""https://www.lesswrong.com/posts/wpZJvgQ4HvJE2bysy/god-help-us-let-s-try-to-understand-friston-on-free-energy"">complex enough</a> that we should expect it to have many aspects that to us would look like different kinds of knowledge. When certain aspects of that process are more salient than the others, we might see a pattern and label that knowing experience as doxa, episteme, or gnosis. So knowledge is neither a single kind or multiple, but a <a href=""https://medium.com/@sheamatthewfisher/integral-holonic-ontology-920de23df802"">holon</a> both composed of distinct kinds and cut from a single kind, <a href=""https://en.wikipedia.org/wiki/Prat%C4%ABtyasamutp%C4%81da"">codependent and inseparable</a> from one another. Thus there are different kinds of knowledge and there is just one kind of knowing, and holding both perspectives is necessary to understanding the depths of what it means to know.</p><h1>More to say?</h1><p>There's always more to say. For example, I chose to leave out a more detailed discussion on the etiology of knowledge, which confuses the matter of a bit since it can mean putting one kind of knowledge causally first which can be mistaken for thinking one kind is more important than the others. Maybe I'll return to this topic in another two years or more and have additional insights to share.</p>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
X2fRsTjd2kQ89pipE,"[AN #74]: Separating beneficial AI into competence, alignment, and coping with impacts",an-74-separating-beneficial-ai-into-competence-alignment-and,https://www.lesswrong.com/posts/X2fRsTjd2kQ89pipE/an-74-separating-beneficial-ai-into-competence-alignment-and,2019-11-20T18:20:01.647Z,19,7,0,False,False,,"<p>Find all Alignment Newsletter resources <u><a href=""http://rohinshah.com/alignment-newsletter/"">here</a></u>. In particular, you can <u><a href=""http://eepurl.com/dqMSZj"">sign up</a></u>, or look through this <u><a href=""https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing"">spreadsheet</a></u> of all summaries that have ever been in the newsletter. I&apos;m always happy to hear feedback; you can send it to me by replying to this email.</p><p>Audio version <u><a href=""http://alignment-newsletter.libsyn.com/alignment-newsletter-74"">here</a></u> (may not be up yet).</p><h2><strong>Highlights</strong></h2><p><u><a href=""https://ai-alignment.com/ai-alignment-landscape-d3773c37ae38"">AI alignment landscape</a></u> <em>(Paul Christiano)</em> (summarized by Rohin): This post presents the following decomposition of how to make AI go well:<br> <br>[<u><a href=""https://files.slack.com/files-pri/TN6JV7BGR-FQMELBXKN/image.png"">Link</a></u> to image below]<br> </p><span><figure><img src=""https://gallery.mailchimp.com/1d1821210cc4f04d1e05c4fa6/images/4ad40b53-7126-48d8-852d-a248b23b1f9f.jpg"" class=""draft-image center"" style=""width:100%""></figure></span><br><p><strong>Rohin&apos;s opinion:</strong> Here are a few points about this decomposition that were particularly salient or interesting to me.</p><p>First, at the top level, the problem is decomposed into alignment, competence, and coping with the impacts of AI. The &quot;alignment tax&quot; (extra technical cost for safety) is only applied to alignment, and not competence. While there isn&apos;t a tax in the &quot;coping&quot; section, I expect that is simply due to a lack of space; I expect that extra work will be needed for this, though it may not be technical. I broadly agree with this perspective: to me, it seems like the major technical problem which <em>differentially</em> increases long-term safety is to figure out how to get powerful AI systems that are <em>trying</em> to do what we want, i.e. they have the right <u><a href=""https://www.alignmentforum.org/posts/ZeE7EKHTFMBs8eMxn/clarifying-ai-alignment#3ECKoYzFNW2ZqS6km"">motivation</a></u> (<u><a href=""https://mailchi.mp/b6dc636f6a1b/alignment-newsletter-33"">AN #33</a></u>). Such AI systems will hopefully make sure to check with us before taking unusual irreversible actions, making e.g. robustness and reliability less important. Note that <u><a href=""https://www.alignmentforum.org/posts/E2aZ9Xwdz3i2ghPtn/techniques-for-optimizing-worst-case-performance"">techniques like verification, transparency, and adversarial training</a></u> (<u><a href=""https://mailchi.mp/768a8130013f/alignment-newsletter-43"">AN #43</a></u>) may still be needed to ensure that the <em>alignment</em> itself is robust and reliable (see the inner alignment box); the claim is just that robustness and reliability of the AI&apos;s <em>capabilities</em> is less important.</p><p>Second, strategy and policy work here is divided into two categories: improving our ability to pay technical taxes (extra work that needs to be done to make AI systems better), and improving our ability to handle impacts of AI. Often, generically improving coordination can help with both categories: for example, the <u><a href=""https://blog.openai.com/better-language-models/"">publishing concerns around GPT-2</a></u> (<u><a href=""https://mailchi.mp/c48f996a5db5/alignment-newsletter-46"">AN #46</a></u>) have allowed researchers to develop synthetic text detection (the first category) as well as to coordinate on when not to release models (the second category).</p><p>Third, the categorization is relatively agnostic to the details of the AI systems we develop -- these only show up in level 4, where Paul specifies that he is mostly thinking about aligning learning, and not planning and deduction. It&apos;s not clear to me to what extent the upper levels of the decomposition make as much sense if considering other types of AI systems: I wouldn&apos;t be surprised if I thought the decomposition was not as good for risks from e.g. powerful deductive algorithms, but it would depend on the details of how deductive algorithms become so powerful. I&apos;d be particularly excited to see more work presenting more concrete models of powerful AGI systems, and reasoning about risks in those models, as was done in <u><a href=""https://arxiv.org/abs/1906.01820"">Risks from Learned Optimization</a></u> (<u><a href=""https://mailchi.mp/92b3a9458c2d/an-58-mesa-optimization-what-it-is-and-why-we-should-care"">AN #58</a></u>).</p><h1><strong>Previous newsletters</strong></h1><p><u><a href=""https://openai.com/blog/ai-and-compute/#addendum"">Addendum to AI and Compute</a></u> <em>(Girish Sastry et al)</em> (summarized by Rohin): Last week, I said that this addendum suggested that we don&apos;t see the impact of AI winters in the graph of compute usage over time. While true, this was misleading: the post is measuring compute used to <em>train</em> models, which was less important in past AI research (e.g. it doesn&apos;t include Deep Blue), so it&apos;s not too surprising that we don&apos;t see the impact of AI winters.</p><h1><strong>Technical AI alignment</strong></h1><h3><strong>Mesa optimization</strong></h3><p><u><a href=""https://www.alignmentforum.org/posts/J9D6Bi3eFDDhCaovi/will-transparency-help-catch-deception-perhaps-not"">Will transparency help catch deception? Perhaps not</a></u> <em>(Matthew Barnett)</em> (summarized by Rohin): <u><a href=""https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"">Recent</a></u> (<u><a href=""https://mailchi.mp/732eaa192df0/an-70-agents-that-help-humans-who-are-still-learning-about-their-own-preferences"">AN #70</a></u>) <u><a href=""https://www.alignmentforum.org/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety"">posts</a></u> (<u><a href=""https://mailchi.mp/cac125522aa3/an-72-alignment-robustness-methodology-and-system-building-as-research-priorities-for-ai-safety"">AN #72</a></u>) have been optimistic about using transparency tools to detect deceptive behavior. This post argues that we may not want to use <em>transparency tools</em>, because then the deceptive model can simply adapt to fool the transparency tools. Instead, we need something more like an end-to-end trained deception checker that&apos;s about as smart as the deceptive model, so that the deceptive model can&apos;t fool it.</p><p><strong>Rohin&apos;s opinion:</strong> In a <u><a href=""https://www.alignmentforum.org/posts/J9D6Bi3eFDDhCaovi/will-transparency-help-catch-deception-perhaps-not#yn5YcLnL6vs6AxxAE"">comment</a></u>, Evan Hubinger makes a point I agree with: the transparency tools don&apos;t need to be able to detect all deception; they just need to prevent the model from developing deception. If deception gets added slowly (i.e. the model doesn&apos;t &quot;suddenly&quot; become perfectly deceptive), then this can be way easier than detecting deception in arbitrary models, and could be done by tools.</p><p><strong>Prerequisities:</strong> <u><a href=""https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"">Relaxed adversarial training for inner alignment</a></u> (<u><a href=""https://mailchi.mp/732eaa192df0/an-70-agents-that-help-humans-who-are-still-learning-about-their-own-preferences"">AN #70</a></u>)</p><p><u><a href=""https://www.alignmentforum.org/posts/iydwbZhATANhjoGP7/more-variations-on-pseudo-alignment"">More variations on pseudo-alignment</a></u> <em>(Evan Hubinger)</em> (summarized by Nicholas): This post identifies two additional types of pseudo-alignment not mentioned in <u><a href=""https://arxiv.org/abs/1906.01820"">Risks from Learned Optimization</a></u> (<u><a href=""https://mailchi.mp/92b3a9458c2d/an-58-mesa-optimization-what-it-is-and-why-we-should-care"">AN #58</a></u>). <strong>Corrigible pseudo-alignment</strong> is a new subtype of corrigible alignment. In corrigible alignment, the mesa optimizer models the base objective and optimizes that. Corrigible pseudo-alignment occurs when the model of the base objective is a non-robust proxy for the true base objective. <strong>Suboptimality deceptive alignment</strong> is when deception would help the mesa-optimizer achieve its objective, but it does not yet realize this. This is particularly concerning because even if AI developers check for and prevent deception during training, the agent might become deceptive after it has been deployed.</p><p><strong>Nicholas&apos;s opinion:</strong> These two variants of pseudo-alignment seem useful to keep in mind, and I am optimistic that classifying risks from mesa-optimization (and AI more generally) will make them easier to understand and address.</p><h3><strong>Preventing bad behavior</strong></h3><p><u><a href=""https://assets.documentcloud.org/documents/6540547/629713.pdf"">Vehicle Automation Report</a></u> <em>(NTSB)</em> (summarized by Zach): Last week, the NTSB released a report on the Uber automated driving system (ADS) that hit and killed Elaine Herzberg. The pedestrian was walking across a two-lane street with a bicycle. However, the car didn&apos;t slow down before impact. Moreover, even though the environment was dark, the car was equipped with LIDAR sensors which means that the car was able to fully observe the potential for collision. The report takes a closer look at how Uber had set up their ADS and notes that in addition to not considering the possibility of jay-walkers, &quot;...if the perception system changes the classification of a detected object, the tracking history of that object is no longer considered when generating new trajectories&quot;. Additionally, in the final few seconds leading up to the crash the vehicle engaged in <em>action suppression</em>, which is described as &quot;a one-second period during which the ADS suppresses planned braking while the (1) system verifies the nature of the detected hazard and calculates an alternative path, or (2) vehicle operator takes control of the vehicle&quot;. The reason cited for implementing this was concerns of false alarms which could cause the vehicle to engage in unnecessary extreme maneuvers. Following the crash, Uber suspended its ADS operations and made several changes. They now use onboard safety features of the Volvo system that were previously turned off, action suppression is no longer implemented, and path predictions are held across object classification changes.</p><p><strong>Zach&apos;s opinion:</strong> <strong>While there is a fair amount of nuance regarding the specifics of how Uber&apos;s ADS was operating it does seem as though there was a fair amount of incompetence in how the ADS was deployed.</strong> Turning off Volvo system fail-safes, not accounting for jaywalking, and trajectory reseting seem like unequivocal <em>mistakes</em>. A lot of people also seem upset that Uber was engaging in action suppression. However, given that randomly engaging in extreme maneuvering in the presence of other vehicles can <em>indirectly cause</em> accidents I have a small amount of sympathy for why such a feature existed in the first place. Of course, the feature was removed and it&apos;s worth noting that &quot;there have been no unintended consequences&#x2014;increased number of false alarms&quot;.</p><p><strong>Read more:</strong> Jeff Kaufman writes a <u><a href=""https://www.lesswrong.com/posts/tTg4bn5rxHYqQJXhD"">post</a></u> summarizing both the original incident and the report. Wikipedia is also rather thorough in their reporting on the factual information. Finally, <u><em><a href=""https://www.annualreviews.org/doi/pdf/10.1146/annurev-control-060117-105157"">Planning and Decision-Making for Autonomous Vehicles</a></em></u> gives an overview of recent trends in the field and provides good references for people interested in safety concerns.</p><h3><strong>Interpretability</strong></h3><p><u><a href=""https://yochan-lab.github.io/papers/files/papers/landscape.pdf"">Explicability? Legibility? Predictability? Transparency? Privacy? Security? The Emerging Landscape of Interpretable Agent Behavior</a></u> <em>(Tathagata Chakraborti et al)</em> (summarized by Flo): This paper reviews and discusses definitions of concepts of interpretable behaviour. The first concept, <strong>explicability</strong> measures how close an agent&apos;s behaviour is to the observer&apos;s expectations. An agent that takes a turn while its goal is straight ahead does not behave explicably by this definition, even if it has good reasons for its behaviour, as long as these reasons are not captured in the observer&apos;s model. <strong>Predictable</strong> behaviour reduces the observer&apos;s uncertainty about the agent&apos;s future behaviour. For example, an agent that is tasked to wait in a room behaves more predictably if it shuts itself off temporarily than if it paced around the room. Lastly, <strong>legibility</strong> or <strong>transparency</strong> reduces observer&apos;s uncertainty about an agent&apos;s goal. This can be achieved by preferentially taking actions that do not help with other goals. For example, an agent tasked with collecting apples can increase its legibility by actively avoiding pears, even if it could collect them without any additional costs.</p><p>These definitions do not always assume correctness of the observer&apos;s model. In particular, an agent can explicably and predictably achieve the observer&apos;s task in a specific context while actually trying to do something else. Furthermore, these properties are dynamic. If the observer&apos;s model is imperfect and evolves from observing the agent, formerly inexplicable behaviour can become explicable as the agent&apos;s plans unfold.</p><p><strong>Flo&apos;s opinion:</strong> Conceptual clarity about these concepts seems useful for more nuanced discussions and I like the emphasis on the importance of the observer&apos;s model for interpretability. However, it seems like concepts around interpretability that are not contingent on an agent&apos;s actual behaviour (or explicit planning) would be even more important. Many state-of-the-art RL agents do not perform explicit planning, and ideally we would like to know something about their behaviour before we deploy them in novel environments.</p><h1><strong>AI strategy and policy</strong></h1><p><u><a href=""https://forum.effectivealtruism.org/posts/XGPW25NZHq2WHbK9w/ai-policy-careers-in-the-eu"">AI policy careers in the EU</a></u> <em>(Lauro Langosco)</em></p><h1><strong>Other progress in AI</strong></h1><h3><strong>Reinforcement learning</strong></h3><p><u><a href=""https://science.sciencemag.org/content/early/2019/07/10/science.aay2400.full"">Superhuman AI for multiplayer poker</a></u> <em>(Noam Brown et al)</em> (summarized by Matthew): In July, this paper presented the first AI that can play six-player no-limit Texas hold&#x2019;em poker better than professional players. Rather than using deep learning, it works by precomputing a blueprint strategy using a novel variant of Monte Carlo linear counterfactual regret minimization, an iterative self-play algorithm. To traverse the enormous game tree, the AI buckets moves by abstracting information in the game. During play, the AI adapts its strategy by modifying its abstractions according to how the opponents play, and by performing real-time search through the game tree. It used the equivalent of $144 of cloud compute to calculate the blueprint strategy and two server grade CPUs, which was much less hardware than what prior AI game milesones required.</p><p><strong>Matthew&apos;s opinion:</strong> From what I understand, much of the difficulty of poker lies in being careful not to reveal information. For decades, computers have already had an upper hand in being silent, computing probabilities, and choosing unpredictable strategies, which makes me a bit surprised that this result took so long. Nonetheless, I found it interesting how little compute was required to accomplish superhuman play.</p><p><strong>Read more:</strong> <u><a href=""https://www.lesswrong.com/posts/6qtq6KDvj86DXqfp6/let-s-read-superhuman-ai-for-multiplayer-poker"">Let&apos;s Read: Superhuman AI for multiplayer poker</a></u></p><h3><strong>Meta learning</strong></h3><p><u><a href=""http://arxiv.org/abs/1910.10897"">Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning</a></u> <em>(Tianhe Yu, Deirdre Quillen, Zhanpeng He et al)</em> (summarized by Asya): &quot;Meta-learning&quot; or &quot;learning to learn&quot; refers to the problem of transferring insight and skills from one set of tasks to be able to quickly perform well on new tasks. For example, you might want an algorithm that trains on some set of platformer games to pick up general skills that it can use to quickly learn new platformer games.</p><p>This paper introduces a new benchmark, &quot;Meta World&quot;, for evaluating meta-learning algorithms. The benchmark consists of 50 simulated robotic manipulation tasks that require a robot arm to do a combination of reaching, pushing and grasping. The benchmark tests the ability of algorithms to learn to do a single task well, learn one multi-task policy that trains and performs well on several tasks at once, and adapt to new tasks after training on a number of other tasks. The paper argues that unlike previous meta-learning evaluations, the task distribution in this benchmark is very broad while still having enough shared structure that meta-learning is possible.</p><p>The paper evaluates existing multi-task learning and meta-learning algorithms on this new benchmark. In meta-learning, it finds that different algorithms do better depending on how much training data they&apos;re given. In multi-task learning, it finds that the algorithm that performs best uses multiple &quot;heads&quot;, or ends of neural networks, one for each task. It also finds that algorithms that are &quot;off-policy&quot;-- that estimate the value of actions other than the one that the network is currently planning to take-- perform better on multi-task learning than &quot;on-policy&quot; algorithms.</p><p><strong>Asya&apos;s opinion:</strong> I really like the idea of having a standardized benchmark for evaluating meta-learning algorithms. There&apos;s a lot of room for improvement in performance on the benchmark tasks and it would be cool if this incentivized algorithm development. As with any benchmark, I worry that it is too narrow to capture all the nuances of potential algorithms; I wouldn&apos;t be surprised if some meta-learning algorithm performed poorly here but did well in some other domain.</p><h1><strong>News</strong></h1><p><u><a href=""https://humancompatible.ai/jobs#internship"">CHAI 2020 Internships</a></u> (summarized by Rohin): CHAI (the lab where I work) is currently accepting applications for its 2020 internship program. The deadline to apply is <strong>Dec 15</strong>.</p>",rohinmshah,rohinmshah,Rohin Shah,
JnuLRnT82ehgMBxm6,Affordable Housing Workarounds,affordable-housing-workarounds,https://www.lesswrong.com/posts/JnuLRnT82ehgMBxm6/affordable-housing-workarounds,2019-11-20T13:50:01.412Z,11,3,2,False,False,,"<p>

After reading some about how affordable housing is actually
implemented, it looks to me like rich people could exploit it to avoid
paying property and inheritance taxes, and generally get around the
means testing requirements.







</p><p>

Affordable housing is about renting or selling homes well below market
price, so if there were a large pool of affordability-restricted
properties there would be a lot of incentive for people to figure out
how to get around the spirit of the restrictions.  I'm going to talk
about buying here, but renting has a lot of similarities.

</p>

<p>

A typical buyer restriction today (<a href=""https://www.jefftk.com/260-beacon-street-information-and-application-packet.pdf"">Somerville
example</a>)
is something like:

</p>

<p>

</p>

<ul>
<li>Annual income no more than $71,400 for a household of two (80% AMI).</li>
<li>Non-retirement assets no more than $250k.</li>
<li>Haven't owned a home within 3y (""first-time homebuyer"").</li>
<li>No students.</li>
<li>Preference for people who currently live or work in the city.</li>
<li>No legal minimum income, but mortgage lenders will apply ones in practice.</li>
</ul>



<p>

Buyers who meet these restrictions are entered into a lottery, and the
winner gets a 2-bedroom 2.5 bathroom 1,500 square-foot unit for <a href=""https://www.somervillema.gov/departments/programs/inclusionary-housing-program"">$177k</a> instead
of <a href=""https://www.coldwellbankerhomes.com/ma/somerville/260-beacon-st-103/pid_26836362/"">$1,049k</a>.
Property taxes are also very low, ~$200/y instead of ~9k/y. [1]

</p>

<p>

These restrictions apply at purchase time: you have to have a
relatively low income and assets to qualify, but then there are no
further restrictions.  This makes sense, because otherwise we would be
requiring poor people to stay poor, but it also allows a lot of
potential ways for rich people to 'legally cheat':

</p>

<ul>
<li><p>Intentionally keep a low income for several years.  Three years
at $70k instead of $140k loses you $210k, but you'd save more than
that in property taxes alone long-term.</p></li>

<li><p>Arrange for deferred or speculative compensation.  Stock that
vests in four years, stock options, start a startup.</p></li>

<li><p>Get training that gives you high earning potential, but don't
start your high paying job until after you have the house.  This
training is effectively an asset, but it's very hard for the
affordable housing administrators to price it, so it's ignored.</p></li>

<li><p>Learn through self-study or apprenticeship to get around the
prohibition on students.</p></li>

<li><p>Postpone transfers to your children until after they have
qualified for affordable housing, since the income and assets of
relatives are not considered.</p></li>

<li><p>Buy land, take advantage of density bonuses, build a large 100%
affordable fancy building, and sell the units to your
just-out-of-school currently-low-earning children.</p></li>

</ul>



<p>

There are also longer-term issues around resale.  You can sell to
anyone you want, as long as they meet the buyer restrictions and pay
no more than the legal maximum price.  This means sellers are in a
position where they can effectively give a very large untaxed gift.
This could let parents transfer large amounts of wealth to their
children, untaxed. [2] You could also have problems with corruption, where
I buy your property for $200k, but then I sneak you an extra $100k so
you sell it to me instead of someone else.

</p>

<p>

Since these are implemented by deed restriction, they could be hard to
fix if they're getting exploited.  It's also not necessarily obvious
whether or how much abuse there is, since the whole problem is that
based on the city's verification legitimately poor people and
artificially poor people look the same.  (And what do we mean by
""artificially poor,"" and do we want to include children of bankers who
decide to become artists or low-paid academics?)

</p>

<p>

It's possible that the amount of hassle for the potential savings is
too low for it to be worth it for rich people to subvert.  If 90% of
the units are used as intended and only 10% are tax shelters, I'd
consider it not great but probably still good.  But I'm very nervous
about building a system that sets up so many opportunities for people
with good lawyers to get around the spirit of the rules.

</p>

<p>
<br />

[1] The property is assessed at a low value because the city sets
maximum resale prices.  Since that's below the value of the city's <a href=""https://www.somervillema.gov/sites/default/files/residential-exemption-information.pdf"">residential
exemption</a> you're taxed as if the property is worth just 10% of
it's assessed value.  I calculate $8,830/year in property taxes for
the market rate unit (after the residential exemption) and just
$190/year for the affordable unit.

</p>

<p>

[2] Stow MA's Deed Restriction Program (<a href=""https://www.stow-ma.gov/sites/stowma/files/uploads/draft_web_deedprogramfaqs.pdf"">faq</a>)
is an example of a way of doing this that seems especially prone to
exploitation.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100122606427572"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
QigLMhiuMA7vKFnww,Wrinkles,wrinkles,https://www.lesswrong.com/posts/QigLMhiuMA7vKFnww/wrinkles,2019-11-19T22:59:30.989Z,81,39,14,False,False,,"<p>Why does our skin form wrinkles as we age?</p><p>This post will outline the answer in a few steps:</p><ul><li>Under what conditions do materials form wrinkles, in general?</li><li>How does the general theory of wrinkles apply to aging human skin?</li><li>What underlying factors drive the physiological changes which result in wrinkles?</li></ul><p>In the process, we’ll draw on sources from three different fields: mechanical engineering, animation, and physiology.</p><h2>Why do Materials Wrinkle?</h2><p>Imagine we have a material with two layers:</p><ul><li>A thin, stiff top layer</li><li>A thick, elastic bottom layer</li></ul><p>We squeeze this material from the sides, so the whole thing compresses.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/b6eqmkba1vp8v0kpdo7o"" srcset=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/ammxjys4vhgtwmjdaeen 131w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/jpmccv1wkn4rhczbtqwj 211w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/yeh3338jeceomhelifsh 291w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/m6fnhg4y04gckddbdomg 371w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/bpunie4ugc2lwmj1m3gl 451w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/p6dju6k0flke2djlefvx 531w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/ipcez6cwszczl1navec1 611w""></figure><p>The two layers want to do different things under compression:</p><ul><li>The thin top layer maintains its length but wants to minimize bending, so it wants to bow outward and form an arc</li><li>The elastic bottom layer wants to minimize vertical displacement, so it wants to just compress horizontally without any vertical change at all.</li></ul><p>Because the two layers are attached, these two objectives trade off, and the end result is waves - aka wrinkles. Longer waves allow the top layer to bend less, so a stiffer top layer yields longer waves. Shorter waves allow the bottom layer to expand/compress less vertically, so a stiffer bottom layer yields shorter waves. The “objectives” can be quantified via the energy associated with bending the top layer or displacing the bottom layer, leading to quantitative predictions of the wavelength - see <a href=""https://people.engr.ncsu.edu/jgenzer/pubs/pub-06-03.pdf""><u>this great review paper</u></a> for the math.</p><p>Engineers do this with a thin metal coating on soft plastic. The two are bound together at high temperature, and then the whole system compresses as it cools. The end result is cool wrinkle patterns:</p><p>&nbsp;</p><p><img style=""width:614%"" src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/loxsg02wlnr5vmxsnosq""></p><p>&nbsp;</p><p>Other interesting applications include predicting mountain spacing (with crust and mantle as the two layers) and surface texture of dried fruit - see <a href=""https://people.engr.ncsu.edu/jgenzer/pubs/pub-06-03.pdf""><u>the review paper</u></a> for more info and cool pictures.</p><p>The same thing happens in skin.</p><h2>Skin Layers</h2><p>For our purposes, skin has three main layers:</p><ul><li>The epidermis is a thin, relatively stiff top layer</li><li>The SENEB (subepidermal non-echogenic band, also sometimes called subepidermal low-echogenic band, SLEB) is a mysterious age-related layer, mostly absent in youth and growing with age, between the epidermis and dermis - more on this later</li><li>The dermis is the thick base layer, containing all the support structure - blood vessels, connective tissue, etc</li></ul><p>Both the SENEB and the dermis are relatively thick, elastic layers, while the epidermis is thin and stiff. So, based on the model from the previous section, we’d expect this system to form wrinkles.</p><p>But wait, if our skin has a thin stiff top layer and thick elastic bottom layer even in youth, then why do wrinkles only form when we get old?</p><p>Turns out, young people have wrinkles too. In youth, the wrinkles have short wavelength - we have lots of tiny wrinkles, so they’re not very visible. As we age, our wrinkle-wavelength grows, so we have fewer, larger wrinkles - which are more visible. The real question is not “why do wrinkles form as we age?” but rather “why does the wavelength of wrinkles grow as we age?”.</p><p>Based on the simple two-layer model, we’d expect that either the epidermis becomes more stiff with age, or the lower layers become less stiff.</p><p>This the right basic idea, but of course it’s a bit more complicated in practice. <a href=""http://ivizlab.sfu.ca/arya/Papers/IEEE/TransITB/2002/Dec/Computational%20Skin%20Model%20-%20Fold%20and%20Wrinkle%20Formation.pdf""><u>These guys</u></a> use a three-layer model, cross-reference parameters from the literature with what actually reproduces realistic age-related wrinkling (specifically for SENEB modulus), and find realistic age-related wrinkles with these numbers:</p><p>&nbsp;</p><p><img style=""width:400%"" src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/QigLMhiuMA7vKFnww/smkpvfyvq4vuucojb4eq""></p><p>&nbsp;</p><p>(arrows indicate change from young to old). Other than the SENEB elastic modulus, all of these numbers are derived from empirically measured parameters - see the paper for details.</p><h2>Age-Related Physiological Changes</h2><p>We have two main questions left:</p><ul><li>Why do the dermis and epidermis stiffen with age?</li><li>What exactly is the SENEB, and why does it grow with age?</li></ul><p>I haven’t looked too much into stiffening of the dermis, but the obvious hypothesis is that it stiffens for the same reason lots of other tissues stiffen with age. At some point I’ll have a post on stiffening of the vasculature which will talk about that in more depth, but for now I’m going to punt.</p><p>The paper from the previous section notes that the epidermis stiffens mainly due to dehydration; rehydrating the epidermis reverses the stiffening (this is the basis of many cosmetics). A dehydrated epidermis makes sense, since both the SENEB and age-related problems in the vasculature will isolate the epidermis more from the bloodstream (although I haven’t seen direct experimental evidence of that causal link).</p><p>That leaves the mysterious SENEB. What is it, and why does it grow with age?</p><p>The name “subepidermal non-echogenic band” is a fancy way of saying that there’s a layer under the epidermis which is transparent to ultrasound imaging. That’s the main way the SENEB is detected: it shows up as a space between the epidermis and dermis on ultrasound images of the skin.</p><p>As far as I can tell, little is known about the SENEB. The main things we <a href=""https://www.ncbi.nlm.nih.gov/pubmed/14731250""><u>do know</u></a>:</p><ul><li>SENEB grows with age; see numbers above</li><li>SENEB is found in aged skin typically exposed to sunlight (“photoaged”, e.g. hands and face) but not in hidden skin (e.g. butt).</li></ul><p>Most authors claim that the SENEB consists of elastin deposits. That matches what we know of <a href=""https://en.wikipedia.org/wiki/Actinic_elastosis""><u>solar elastosis</u></a>, the build-up of elastin deposits in photoaged skin. But I haven’t seen anyone systemically line up the ultrasonic and histologic images and chemically analyze the SENEB layer to check that it really is made of elastin. (This may just be a case of different researchers with different tools using different names for things which are the same.)</p><p>Assuming that the SENEB does consist of accumulated elastin, why is elastin accumulating? Well, it turns out that elastin is <a href=""https://www.sciencedirect.com/science/article/pii/0304416580900069""><u>never</u></a> <a href=""https://www.jci.org/articles/view/115204""><u>broken down</u></a> in humans. It does not turn over. On the other hand, the skin presumably needs to produce new elastin sometimes to heal wounds. Indeed, many authors note that the skin’s response to UV exposure is basically a wound-healing response. Again, I haven’t seen really convincing data, but I haven’t dug too thoroughly. It’s certainly plausible that elastin is produced in response to UV as part of a wound-healing response, and then accumulates with age. That would explain why the SENEB grows in photoaged skin, but not in hidden skin.</p>",johnswentworth,johnswentworth,johnswentworth,
e3Db4w52hz3NSyYqt,How I do research,how-i-do-research,https://www.lesswrong.com/posts/e3Db4w52hz3NSyYqt/how-i-do-research,2019-11-19T20:31:16.832Z,59,28,26,False,False,,"<html><head><style type=""text/css"">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head><body><p><em>Someone asked me about this, so here are my quick thoughts.</em></p>
<p>Although I've learned a lot of math over the last year and a half, it still isn't my comparative advantage. What I do instead is,</p>
<h2>Find a problem</h2>
<p>that seems plausibly important to AI safety (low impact), or a phenomenon that's secretly confusing but not really explored (instrumental convergence). If you're looking for a problem, corrigibility strikes me as another thing that meets these criteria, and is still mysterious.</p>
<h2>Think about the problem</h2>
<p><strong>Stare at the problem</strong> on my own, ignoring any existing thinking as much as possible. Just think about what the problem is, what's confusing about it, what a solution would look like. In retrospect, this has helped me avoid anchoring myself. Also, my prior for existing work is that it's confused and unhelpful, and I can do better by just thinking hard. I think this is pretty reasonable for a field as young as AI alignment, but I wouldn't expect this to be true at all for e.g. physics or abstract algebra. I also think this is likely to be true in any field where philosophy is required, where you need to find the right formalisms instead of working from axioms.</p>
<p>Therefore, when thinking about <a href=""https://www.lesswrong.com/posts/DvmhXysefEyEvXuXS/overcoming-clinginess-in-impact-measures"">whether ""responsibility for outcomes"" has a simple core concept</a>, I nearly instantly concluded it didn't, without spending a second glancing over the surely countless philosophy papers wringing their hands (yup, papers have hands) over this debate. This was the right move. I just trusted my own thinking. Lit reviews are just proxy signals of your having gained comprehension and coming to a well-considered conclusion.</p>
<p><strong>Concrete examples are helpful:</strong> at first, <a href=""https://www.lesswrong.com/posts/H7KB44oKoSjSCkpzL/worrying-about-the-vase-whitelisting"">thinking about vases in the context of impact measurement</a> was helpful for getting a grip on low impact, even though it was <a href=""https://www.lesswrong.com/posts/pr3bLc2LtjARfK7nx/world-state-is-the-wrong-level-of-abstraction-for-impact"">secretly a red herring</a>. I like to be concrete because we actually need <em>solutions</em> - I want to learn more about the relationship between solution specifications and the task at hand.</p>
<p><strong>Make simplifying assumptions</strong> wherever possible. <a href=""https://arbital.com/p/unbounded_analysis/"">Assume a ridiculous amount of stuff, and then pare it down.</a></p>
<p><strong>Don't formalize your thoughts too early</strong> - you'll just get useless mathy sludge out on the other side, the product of your confusion. Don't think for a second that having math representing your thoughts means you've necessarily made progress - for the kind of problems I'm thinking about right now, the math has to <em>sing</em> with the elegance of the philosophical insight you're formalizing.</p>
<p><strong>Forget</strong> all about whether you have the <a href=""https://www.lesswrong.com/posts/dhj9dhiwhq3DX6W8z/hero-licensing"">license</a> or background to come up with a solution. When I was starting out, I was too busy being fascinated by the problem to remember that I, you know, wasn't allowed to solve it.</p>
<p>Obviously, there are common-sense exceptions to this, mostly revolving around trying to run without any feet. It would be pretty silly to think about logical uncertainty without even knowing propositional logic. One of the advantages of immersing myself in a lot of math isn't just knowing more, but knowing what I don't know. However, I think it's rare to secretly lack the basic skills to even start on the problem at hand. You'll probably know if you are, because all your thoughts keep coming back to the same kind of confusions about a formalism, or something. Then, you look for ways to resolve the confusion (possibly by asking a question on LW or in the MIRIx Discord), find the thing, and get back to work.</p>
<h2>Stress-test thoughts</h2>
<p>So you've had some novel thoughts, and an insight or two, and the outlines of a solution are coming into focus. It's important not to become enamored with what you have, because it stops you from finding the truth and winning. Therefore, think about ways in which you could be wrong, situations in which the insights don't apply or in which the solution breaks. Maybe you realize the problem is a bit <a href=""https://www.lesswrong.com/posts/pr3bLc2LtjARfK7nx/world-state-is-the-wrong-level-of-abstraction-for-impact"">ill-defined</a>, so you refactor it.</p>
<p>The process here is: break the solution, deeply understand why it breaks, and repeat. Don't get stuck with patches; there's a rhythm you pick up on in AI alignment, where good solutions have a certain flavor of integrity and compactness. It's OK if you don't find it right away. The key thing to keep in mind is that you aren't trying to pass the test cases, but rather to find brick after brick of insight to build a firm foundation of deep comprehension. You aren't trying to find the right equation, you're trying to find the state of mind that makes the right equation obvious. You want to understand new pieces of the world, and maybe one day, those pieces will make the difference.</p>
<p>ETA: I think a lot of these skills apply more broadly. Emotional trust in one's own ability to think seems important for taking actions that aren't e.g. prescribed by an authority figure. Letting myself just <em>think</em> lets me be light on my mental feet, and bold in where those feet lead me.</p>
<p>ETA 2: Apparently simulating drop-caps:</p>
<p><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb{L}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">L</span></span></span></span></span></span></span></span>ike this</p>
<p>isn't the greatest idea. Formatting edit.</p>
</body></html>",TurnTrout,turntrout,TurnTrout,
YeLqDbXRRgjpmRKd6,Drawing on Walls,drawing-on-walls,https://www.lesswrong.com/posts/YeLqDbXRRgjpmRKd6/drawing-on-walls,2019-11-19T15:00:02.091Z,17,5,1,False,False,,"<p>

When I 

<a href=""https://www.jefftk.com/p/bathroom-plans"">started</a> the 

<a href=""https://www.jefftk.com/p/bathroom-construction-update"">bathroom</a> 

<a href=""https://www.jefftk.com/p/bathroom-is-usable"">project</a> there was a lot of reason to
move quickly: the bathroom wouldn't be usable while I was working on
it, and the back bedroom was full of construction stuff.  Once I got
to the stage where the only thing left to do was plaster and paint the
hallway, however, it was less of a priority.  So we spent May-November
with unfinished walls.



</p><p>

Since we were going to paint them at some point, one afternoon I thought it
would be fun to draw on them with the kids.  We got out the markers and drew
lots of different things.  I emphasized that it was only these walls we could
draw on, which is the kind of rule the kids do well with.

</p>

<p>

<a href=""https://www.jefftk.com/writing-on-walls-big.jpg""><img src=""https://www.jefftk.com/writing-on-walls.jpg"" /></a>

</p>

<p>

A couple days later they drew on the walls again, but this time with crayon.
Crayon, being wax-based, is not a good layer to have under paint.  I hadn't
thought to tell them not to use them, and they didn't have a way to know, but I
was annoyed at myself.  I got most of it off with hot water and a cloth, and
then when it came to do the plastering I put a skim coat over it.

</p>

<p>

Later on a friend wanted help preparing for a coding interview, so we
used the wall as a whiteboard:

</p>

<p>

<a href=""https://www.jefftk.com/whiteboard-whitewall-interview-big.jpg""><img src=""https://www.jefftk.com/whiteboard-whitewall-interview.jpg"" /></a>

</p>

<p>

One thing I hadn't considered was that you need more primer over dark
marker than plain drywall.  As with ""no crayon under paint"" this seems
like it should have been obvious, and something I should have thought
about before letting them draw on a large area of the wall, but it
wasn't and I didn't, so Julia ended up spending longer painting and
priming than we'd been thinking.

</p>

<p>

And then, the evening after all that painting, Anna took a marker over
to the nice new clean white wall and started drawing.  We hadn't told
her that the wall was no longer ok for drawing, and at 3y ""now that
the wall is painted drawing isn't ok"" is not the sort of thing I
should be expecting her to know on her own.  Luckily the marker was
washable, so it wasn't too bad.

</p>

<p>

Overall this was more work than I was expecting, and probably wasn't
worth it for the fun, at least not the way we did it.  If I did it
again I'd make sure they didn't use crayon, and either give them light
colored markers or pick a smaller section of the wall for them to play
with.

  </p>",jkaufman,jkaufman,jefftk,
RiqjJBcBFtXAPBzXd,"
Austin meetup notes Nov. 16, 2019: SSC discussion",austin-meetup-notes-nov-16-2019-ssc-discussion,https://www.lesswrong.com/posts/RiqjJBcBFtXAPBzXd/austin-meetup-notes-nov-16-2019-ssc-discussion,2019-11-19T13:30:53.446Z,13,5,3,False,False,,"<p>The following is a writeup (pursuant to <a href=""https://www.lesswrong.com/posts/TBbPTBdApovxhM7NC/meetups-as-institutions-for-intellectual-progress#Proposal__Monetary_incentives_for_write_ups"">Mingyuan's proposal</a>) of the discussion at the <a href=""https://www.lesswrong.com/groups/syf4gEbaNQ8btKCbb"">Austin LW/SSC Meetup</a> on November 16, 2019, at which we discussed six different SlateStarCodex articles. We meet every Saturday at 1:30pm - if you're in the area, come join us!</p>
<p>You are welcome to use the comments below to continue discussing any of the topics raised here. I also welcome meta-level feedback: How do you like this article format? What sorts of meetups lead to interesting writeups?</p>
<p>Disclaimer: I took pains to make it clear before, during, and after the meetup that I was taking notes for posting on LessWrong later. I do not endorse posting meetup writeups without the knowledge and consent of those present!</p>
<h2><a href=""https://slatestarcodex.com/2017/05/26/the-atomic-bomb-considered-as-hungarian-high-school-science-fair-project/"">The Atomic Bomb Considered As Hungarian High School Science Fair Project</a></h2>
<p>There was a <a href=""https://medium.com/cantors-paradise/the-unparalleled-genius-of-john-von-neumann-791bb9f42a2d"">Medium post on John von Neumann</a>, which was <a href=""https://news.ycombinator.com/item?id=21542753"">discussed on Hacker News</a>, which <a href=""https://news.ycombinator.com/item?id=21547166"">linked</a> to the aforementioned SSC article on why there were lots of smart people in Budapest 1880-1920.</p>
<p>Who was John von Neumann? - One of the founders of computer science, founder of game theory, nuclear strategist. For all his brilliance he's fairly unknown generally. Everyone who knew him said he was an even quicker thinker than Einstein; but why didn't he achieve as much as Einstein? Perhaps because he died of cancer at 53.</p>
<p>Scott Alexander says: {Ashkenazi Jews are smart. Adaptations can have both up- and down-sides (e.g. sickle cell anemia / malaria resistance); likewise some genes cause genetic disorders and also intelligence. These are common in Ashkenazim.}</p>
<p>Jews were forced into finance because Christians weren't allowed to charge interest on loans, but it turned out interest was really useful.</p>
<p>Scott Alexander says: {And why this time period? Because restrictions on Jews only started being lifted just before this period, and they needed a generation or so to pass before they could be successful. And afterward, Nazis happened. Why Hungary and not Germany? Hungary has a <a href=""https://en.wikipedia.org/wiki/Primate_city"">""primate city""</a> (Budapest), i.e. a city that's much more prominent than others in its area, so intellectuals will tend to gather there. Germany, by contrast, is less centralized.}</p>
<p><a href=""https://www.meltingasphalt.com/interactive/going-critical/"">Simulation of idea-sharing and population density</a> - cities are more likely to incubate ideas (<a href=""https://news.ycombinator.com/item?id=19905677"">Hacker News discussion</a>). Does that mean we'll get more progress if everyone in a certain field gathers in one place? Perhaps. It's helpful to get feedback for your ideas to get your thinking on the right track, rather than going down a long erroneous path without colleagues to correct you.</p>
<h2><a href=""https://slatestarcodex.com/2019/11/06/building-intuitions-on-non-empirical-arguments-in-science/"">Building Intuitions On Non-Empirical Arguments In Science</a></h2>
<p>Scott Alexander says: {Should we reject the idea of a multiverse if it doesn't make testable predictions? No, because it's more parsimonious, contra the ""Popperazi"" who say that new theories must have new testable predictions.} This article is interesting because it goes as far as you can into the topic without getting into actual advanced physics.</p>
<p>Similar to <a href=""https://en.wikipedia.org/wiki/Mathematical_universe_hypothesis"">Tegmark's argument</a>.</p>
<p>What kinds of multiverse are there? Everett (quantum) multiverse, and cosmological multiverse (different Big Bangs with different physical laws coming from them, etc.). This article applies to both (although maybe you could argue that these are both the same thing).</p>
<p>Related LessWrong article: <a href=""https://www.lesswrong.com/posts/3XMwPNMSbaPm2suGz/belief-in-the-implied-invisible"">Belief in the Implied Invisible</a>.</p>
<p>But how do you think about the probability of you being in a multiverse, if that multiverse might contain an infinite number of beings? Should we totally discount finite-population universes (as being of almost-zero probability) because infinity always outweighs any finite number? See Nick Bostrom's Ph.D. dissertation (<a href=""http://www.anthropic-principle.com/?q=anthropic_bias"">this is not that dissertation</a> but it likely covers substantially the same material).</p>
<p>The reason for accepting the Everett multiverse is Occam's razor, because it makes the math simpler. Is that accurate? - Yes, but there's a fundamental disagreement about what ""simpler"" means. On the one hand, Schrödinger's equation naturally predicts the Many-Worlds Interpretation (MWI). On the other hand, MWI doesn't explain where the probabilities come from. MWIers have been trying to figure this out for a while.</p>
<p>Generally probability refers to your state of knowledge about reality. But quantum mechanics overturns that by positing fundamental uncertainty that is not merely epistemic.</p>
<p>Re MWI probabilities, see Robin Hanson's <a href=""http://mason.gmu.edu/~rhanson/mangledworlds.html"">""Mangled Worlds""</a>: {Multiverse branches that don't obey the 2-norm probability rule (a.k.a. the ""Born rule"") can be shown to decline in measure ""faster"" than branches that do, and if a branch falls below a certain limit it ceases to exist in any meaningful sense because it merges into the background noise, etc.}</p>
<p>Robin Hanson's an economist, right? - Yes, but he may have studied physics at one point.</p>
<p><a href=""https://arxiv.org/abs/quant-ph/0401062"">Scott Aaronson's 2003 paper</a>: {Maybe it's natural to use the 2-norm to represent probability, because it's the only conserved quantity. If we didn't, we could arbitrarily inflate a particular branch's probability.}</p>
<h2><a href=""https://slatestarcodex.com/2019/11/13/autism-and-intelligence-much-more-than-you-wanted-to-know/"">Autism And Intelligence: Much More Than You Wanted To Know</a></h2>
<p>Tower-vs-foundation model - intelligence is composed of a ""tower"" and a ""foundation"", and if you build up the tower too much without building up the foundation, the tower collapses and you end up being autistic. Analogy: MS Word and Powerpoint got better with each update till eventually they got so complex that they're not usable any more.</p>
<p>What mechanisms could explain the tower-vs-foundation model?</p>
<p>Is intelligence linear? You can have e.g. a musical prodigy, or someone who's exceptionally good at specific tasks despite being autistic.</p>
<p>How is intelligence defined here? - By IQ tests, in the cited studies. But these are designed for neurotypical people.</p>
<p>People with autism have higher-IQ families. But maybe such families are simply more likely to take their kids to doctors to get diagnosed with autism - a major confounder.</p>
<p>The studies look mostly at males and the father's genes, but you'd think the mother's genes are equally important.</p>
<p><a href=""https://m.facebook.com/story.php?story_fbid=10159076731491038&amp;id=739471037"">Facebook post</a> (<a href=""https://archive.is/afVvz"">archive</a>) similar to the tower-vs-foundation concept.</p>
<p>Maybe you could do surveys of lower-income communities to check for autism incidence there - but this is difficult particularly because they're more likely to be mistrustful of strangers asking about such things. Or maybe not; maybe lower-income people are <em>more</em> likely to accept payment for scientific studies.</p>
<p>Testing for autism is questionable - why is there a 3:1 male:female ratio? Is this reflective of reality, or of bias in diagnosis? Perhaps you could tell by seeing if rates of diagnosis increase over time at the same rate for males and females - if females are generally diagnosed later than males, then that might be because of bias in the diagnosis that makes males with autism more likely to be diagnosed than females with autism.</p>
<p>How fuzzy is the category of autism? ""It's a spectrum"" - or more of a multivariate space?</p>
<p><a href=""https://www.theguardian.com/commentisfree/2019/aug/26/autism-neurodiversity-severe"">Article in The Guardian says</a>: {The move to accept (and not treat) autism has been harmful for people with severe autism.}</p>
<p><a href=""https://www.lesswrong.com/posts/895quRDaK6gR2rM82/diseased-thinking-dissolving-questions-about-disease"">Scott Alexander says</a>: {If you want to call something a disease, it should have a distinct cluster/separation from non-diseased cases, rather than just a continuum with an arbitrary line drawn on it.} This is particularly important in psychology, because oftentimes we can only observe symptoms and only guess as to the cause (in contrast to e.g. infectious diseases).</p>
<h2><a href=""https://slatestarcodex.com/2019/11/04/samsara/"">Samsara (short story)</a></h2>
<p>In a world where everyone has attained enlightenment, one man stands alone as being unenlightened... He gets more and more stubborn the more the enlightened ones try to reach him, and founds his own school of unenlightenment. We'll stop the discussion here to avoid spoilers, but you should read it.</p>
<p>This is the type of story that would benefit from having padding material added to the end so that you don't know when the ending is about to come, à-la <a href=""https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach""><em>Gödel, Escher, Bach</em></a>.</p>
<p>It's like that Scottish movie <a href=""https://en.wikipedia.org/wiki/Trainspotting_(film)""><em>Trainspotting</em></a> (which requires subtitles for Americans because of the heavy Scottish dialect) - ""What if I don't want to be anything other than a heroin addict""?</p>
<h2><a href=""https://slatestarcodex.com/2019/10/28/financial-incentives-are-weaker-than-social-incentives-but-very-important-anyway/"">Financial Incentives Are Weaker Than Social Incentives But Very Important Anyway</a></h2>
<p>Scott Alexander says: {A survey asked people if they would respond to a financial incentive, and if they thought others would respond to the same incentive. People said that others would be more likely to respond to incentives than they themselves were.}</p>
<p>It could be entirely true that <em>most</em> people wouldn't respond to incentives, but some people would, and so when you ask them if ""other people"" would respond, they answer as if you're asking if ""anyone"" would. The survey question is unclear.</p>
<p>Social desirability bias - you don't want to be known as someone who accepts incentives easily, because that puts you in a bad negotiating position. Always overstate your asking price.</p>
<p>""Would you have sex with me for a billion dollars..."" joke.</p>
<p>Speaking of salary negotiations: Always have a good second option you can tell the employer about. But if a candidate claims that ""Amazon and Google"" are contacting them, that doesn't mean they're any more desirable - Amazon and Google contact everyone!</p>
<p>You could look at <a href=""https://en.wikipedia.org/wiki/Sin_tax"">sin taxes</a> to see if they have any effect.</p>
<p><a href=""https://en.wikipedia.org/wiki/Predictably_Irrational""><em>Predictably Irrational</em></a> by Dan Ariely - a daycare started fining parents who were late in picking up their kids, but this resulted in even more parents being late.</p>
<p>Incentives occur at the margin, so it can be effective to have incentives even if ""most"" people don't respond.</p>
<p>Social incentives are powerful. Can you set up social incentives deliberately? One example: Make public commitments to do something, and get shamed if you later don't do it. But see <a href=""https://www.youtube.com/watch?v=NHopJHSlVo4"">Derek Sivers's TED talk <em>Keep your goals to yourself</em></a>. But did they consider the effect of publicly checking in on your progress later?</p>
<p>With purely financial incentives e.g. Beeminder, you might treat it transactionally like in the daycare example.</p>
<p>Aside: {Multi-armed bandit problem: There are a bunch of slot machines with different payouts. What's the best strategy? Explore vs. Exploit tradeoff. <a href=""https://www.goodreads.com/book/show/25666050-algorithms-to-live-by""><em>Algorithms to Live By</em></a> - book by Brian Christian and Tom Griffiths, who <a href=""http://rationallyspeakingpodcast.org/show/rs-161-tom-griffiths-and-brian-christian-on-algorithms-to-li.html"">were also on Rationally Speaking</a>. E.g. If you find a good restaurant in a city you're visiting for just a few days, you should go back there again, but in your hometown you should explore more different restaurants.}</p>
<p>Hypothesis explaining the survey: You have more information about yourself. If someone estimates that they have a 30% chance of e.g. moving to another city, they'll say ""No"" to the survey 100% of the time.</p>
<p>Aside: {<a href=""https://en.wikipedia.org/wiki/Yes_Minister""><em>Yes Minister</em></a> TV show features Minister Jim Hacker, a typical well-meaning politician concerned about popularity and getting stuff done; and Sir Humphrey, his secretary, a 30-year civil servant who knows how things actually work and is always frustrating the minister's plans. <a href=""https://www.youtube.com/watch?v=G0ZZJXw4MTA"">""The party have had an opinion poll done; it seems all the voters are in favour of bringing back National Service. - Well, have another opinion poll done showing the voters are <em>against</em> bringing back National Service!""</a>}</p>
<p>Scott Alexander concludes: {Skeptical of the research, because we do see people respond to financial incentives. Even if most people don't, it could still be important.}</p>
<h2><a href=""https://slatestarcodex.com/2019/09/18/too-much-dark-money-in-almonds/"">Too Much Dark Money In Almonds</a></h2>
<p>Scott Alexander says: {Why is there so little money in politics? Less than $12 billion/year in the US, which is less than the amount of money spent on almonds. Hypothesis: this is explained by coordination problems.}</p>
<p>Other ideas: People want to avoid escalation since if they spend money their political opponents will just spend more, etc. But this is implausible because it itself requires a massive degree of coordination.</p>
<p>What if money in politics doesn't actually make much difference? If the world is as depicted in <em>Yes Minister</em>, the government will keep doing the same thing regardless of political spending anyway.</p>
<p>Maybe a better comparison is (almond advertising):(political spending)::(almonds):(all government spending).</p>
<p>Spending directly on a goal is more effective than lobbying the government to spend on that goal, e.g. Elon Musk and SpaceX.</p>
<p>What would have more political spending, an absolute monarchy or a direct democracy? (Disagreement on this.)</p>
<p>Why is bribery more common in some places than others? Maybe you just can't get anything done at all without bribes. Or maybe some places hide it better by means of e.g. revolving-door lobbyist deals, ""We'll go easy on your cousin who's in legal trouble"", etc.</p>
<p>Aside: {<a href=""https://slatestarcodex.com/2019/07/17/caution-on-bias-arguments/"">Scott Alexander asks</a>: {Is someone biased simply because they have a stake in something?} Total postmodern discourse would entirely discount someone's argument based on their stake in the matter; but we aren't so epistemically helpless that we can't evaluate the actual contents of an argument.}</p>
<p>Aside: {Administrative clawback: If you fix problems, you'll get less money next year - perhaps by more than enough to cancel out the benefits of the fix. They'll expect you to make just as much progress again, which may not be possible. Don't excel because that'll raise expectations for the future.}</p>
<p>Or maybe almonds are a bigger deal than you think!</p>
",jchan,jchan,jchan,
YBbcKg5AeX3tot3cC,Cybernetic dreams: Beer's pond brain,cybernetic-dreams-beer-s-pond-brain,https://www.lesswrong.com/posts/YBbcKg5AeX3tot3cC/cybernetic-dreams-beer-s-pond-brain,2019-11-19T12:48:15.512Z,39,15,3,False,False,,"<html><head></head><body><p>""Cybernetic dreams"" is my mini series on ideas from cybernetic research that has yet to fulfill their promise. I think there are many cool ideas in cybernetics research that has been neglected and I hope that this series brings them more attention.</p>
<p>Cybernetics is a somewhat hard to describe style of research in the period of 1940s -- 1970s. It is as much as an aesthetics as it is a research field. The main goals of cybernetics research are to understand how complex systems (especially life, machines, and economic systems) work, how they can be evolved, constructed, fixed, and changed. The main sensibilities of cybernetics are biology, mechanical engineering, and calculus.</p>
<p>Today we discuss Stafford Beer's pond brain.</p>
<h2>Stafford Beer</h2>
<p>Stafford Beer is a cybernetician that tried to make more efficient economic systems by cybernetic means. Project Cybersyn is his most famous project: making a cybernetic economy system. It will be discussed in a future episode. From <a href=""https://en.wikipedia.org/wiki/Project_Cybersyn"">Wikipedia</a>:</p>
<blockquote>
<p>Stafford Beer was a British consultant in management cybernetics. He also sympathized with the stated ideals of Chilean socialism of maintaining Chile's democratic system and the autonomy of workers instead of imposing a Soviet-style system of top-down command and control. One of its main objectives was to devolve decision-making power within industrial enterprises to their workforce in order to develop self-regulation [homeostasis] of factories.</p>
</blockquote>
<h2>The cybernetic factory</h2>
<p>The ideal factory, according to Beer, should be like an organism that is attempting to maintain a homeostasis. Raw material comes in, product comes out, money flows through. The factory would have sensory organs, a brain, and actuators.</p>
<p><img src=""https://i.imgur.com/pHBf5cH.png"" alt=""""></p>
<p>From (Pickering, 2004):</p>
<blockquote>
<p>The T- and V-machines are what we would now call neural nets: the T-machine collects data on the state of the factory and its environment and translates them into meaningful form; the V- machine reverses the operation, issuing commands for action in the spaces of buying, production and selling. Between them lies the U-Machine, which is the homeostat, the artificial brain, which seeks to find and maintain a balance between the inner and outer conditions of the firm—trying to keep the firm operating in a liveable segment of phase-space.</p>
</blockquote>
<blockquote>
<p>By 1960, Beer had at least simulated a cybernetic factory at Templeborough Rolling Mills, a subsidiary of his employer, United Steel... [The factory has sensory organs that measures ""tons of steel bought"", ""tons of steel delivered"", ""wages"", etc.] At Templeborough, all of these data were statistically processed, analysed and transformed into 12 variables, six referring to the inner state of the mill, six to its economic environment. Figures were generated at the mill every day—as close to real time as one could get... the job of the U-Machine
was to strike a homeostatic balance between [the output from the sensory T-machines and the commands to the actuating V-machines]. But nothing like a
functioning U-Machine had yet been devised. The U-Machine at
Templeborough was still constituted by the decisions of human managers,
though now they were precisely positioned in an information space defined by
the simulated T- and V-Machines.</p>
</blockquote>
<h2>Unconventional computing</h2>
<blockquote>
<p>[Beer] wanted somehow to enrol a naturally occurring homeostatic system as the brain of the cybernetic factory.</p>
</blockquote>
<p>He emphasized that the system must have a rich dynamics, because he believed in Ashby's ""Law of requisite variety"", which roughly speaking states that a system can only remain in homeostasis if it has more internal states than the external states it encounters.</p>
<blockquote>
<p>during the second half of the 1950s, he embarked on ‘an almost unbounded survey of naturally occurring systems in search of materials for the construction of cybernetic machines’ (1959, 162).</p>
</blockquote>
<blockquote>
<p>In 1962 he wrote a brief report on the state of the art, which makes fairly mindboggling reading (Beer 1962b)... The list includes a successful attempt to use positive and negative feedback to train young children to solve simultaneous equations without teaching them the relevant mathematics—to turn the children into a performative (rather than cognitive) mathematical machine—and it goes on to discuss an extension of the same tactics to mice! This is, I would guess, the origin of the mouse-computer that turns up in both Douglas Adams’ Hitch-Hikers Guide to the Universe and Terry Pratchett’s Discworld series of fantasy novels.</p>
</blockquote>
<p>Research like this is still ongoing, under the banner of ""unconventional computing"". For example, in 2011, <a href=""https://aip.scitation.org/doi/abs/10.1063/1.3637777"">scientists made crab swarms to behave such that they implement logic gates</a>. Some scientists also try to use intuitive intelligence of untrained people to solve mathematical problems, such as the <a href=""https://www.scienceathome.org/games/quantum-moves/"">Quantum Moves</a> game, which solves quantum optimization problems.</p>
<h2>Pond brain</h2>
<blockquote>
<p>Beer also reported attempts to induce small organisms, Daphnia collected from a local pond, to ingest iron filings so that input and output couplings to them could be achieved via magnetic fields, and another attempt to use a population of the protozoon Euglena via optical couplings. (The problem was always how to contrive inputs and outputs to these systems.) Beer’s last attempt in this series was to use not specific organisms but an entire pond ecosystem as a homeostatic controller, on which he reported that, ‘Currently there are a few of the usual creatures visible to the naked eye (Hydra, Cyclops, Daphnia, and a leech); microscopically there is the expected multitude of micro-organisms. . . The state of this research at the moment,’ he said in 1962, ‘is that I tinker with this tank from time to time in the middle of the night’ (1962b, 31).</p>
</blockquote>
<blockquote>
<p>In the end, this wonderful line of research foundered, not on any point of principle, but on Beer’s practical failure to achieve a useful coupling to any biological system of sufficiently high variety.</p>
</blockquote>
<p>In other words, Beer couldn't figure out a way to talk to a sufficiently complicated system in its own language (except perhaps with human business managers, but they cost more than feeding a pond of microorganisms).</p>
<h2>Matrix brain</h2>
<p>The pond brain is wild enough, but it wasn't Beer's end goal for the brain of the cybernetic factory.</p>
<blockquote>
<p>the homeostatic system Beer really had in mind was something like the human spinal cord and brain. He never mentioned this in his work on biological computers, but the image that sticks in my mind is that the brain of the cybernetic factory should really have been an unconscious human body, floating in a vat of nutrients and with electronic readouts tapping its higher and lower reflexes—something vaguely reminiscent of the movie The Matrix. This horrible image helps me at least to appreciate the magnitude of the gap between cybernetic information systems and more conventional approaches.</p>
</blockquote>
<p>As shown in an illustration in his book <em>Brain of the firm (The Managerial cybernetics of organization)</em>:
<img src=""https://i.imgur.com/KE6oRiX.png"" alt=""""></p>
<h2>Reservoir computing</h2>
<p>Reservoir computing is somewhat similar to Beer's idea of using one complex system to control another. The ""reservoir"" is a complex system that is cheap to run and easy to talk to. For example, a recurrent neural network (a neural network with feedback loops, in contrast to a feedforward neural network, which has no feedback loops) of sufficient complexity (hinting at the law of requisite variety) can serve as a reservoir. To talk to the reservoir, just cast your message as a list of numbers, and input them to some neurons in the network. Then wait for the network to ""think"", before reading the states of some other neurons in the network. That is the ""answer"" from the reservoir.</p>
<p><img src=""https://i.imgur.com/KDBGj49.png"" alt=""""></p>
<p>This differs from deep learning in that the network serving as the reservoir is left alone. It is initialized randomly, and its synaptic strengths remain unchanged. The only learning parts of the system are the inputs and outputs, which can be trained very cheaply with linear regression and classification. In other words, the reservoir remains the same, and we must learn to speak its language, which is surprisingly easy to do. From <a href=""https://www.sciencedirect.com/science/article/pii/S0893608019300784"">(Tanaka et al, 2019)</a>:</p>
<blockquote>
<p>Another advantage is that the reservoir without adaptive updating is amenable to hardware implementation using a variety of physical systems, substrates, and devices. In fact, such physical reservoir computing has attracted increasing attention in diverse fields of research.</p>
</blockquote>
<p>Other reservoirs can be used, as long as it is complex and cheap. For example, <a href=""https://www.nature.com/articles/s41467-017-02337-y"">(Du et al, 2017)</a> built reservoirs out of physical memristors:</p>
<blockquote>
<p>... a small hardware system with only 88 memristors can already be used for tasks, such as handwritten digit recognition. The system is also used to experimentally solve a second-order nonlinear task, and can successfully predict the expected output without knowing the form of the original dynamic transfer function.</p>
</blockquote>
<p><a href=""https://www.sciencedirect.com/science/article/pii/S0893608019300784"">(Tanaka et al, 2019)</a> reviews many types of physical reservoirs, including biological systems!</p>
<blockquote>
<p>researchers have speculated about which part of the brain can be regarded as a reservoir or a readout as well as about how subnetworks of the brain work in the reservoir computing framework. On the other hand, physical reservoir computing based on <em>in vitro</em> biological components has been proposed to investigate the computational capability of biological systems in laboratory experiments.</p>
</blockquote>
<h2>Chaos computing</h2>
<p>""Chaos computing"" is one instance of reservoir computing. The reservoir is an electronic circuit with a chaotic dynamics, and the trick is to design the reservoir just right, so that it performs logical computations. It seems that the only company that does this is ChaoLogix. What it had <a href=""https://www.technologyreview.com/s/405940/logic-from-chaos/"">back in 2006</a> was already quite promising.</p>
<blockquote>
<p>ChaoLogix has gotten to the stage where it can create any kind of gate from a small circuit of about 30 transistors. This circuit is then repeated across the chip, which can be transformed into different arrangements of logic gates in a single clock cycle, says Ditto.</p>
</blockquote>
<p>""in a single clock cycle"" is significant, as <a href=""https://en.wikipedia.org/wiki/Field-programmable_gate_array"">field-programmable gate array</a>, which can also rearrange the logic gates, takes millions of clock cycles to rearrange itself.</p>
<p>It has been <a href=""https://www.eenewsanalog.com/news/arm-acquires-chaologix-security-reasons"">acquired by ARM in 2017</a>, apparently for security reasons:</p>
<blockquote>
<p>One benefit is that chaogates are said to have a power signature that is independent of the inputs which makes it valuable in thwarting differential power analysis (DPA) side channel attacks.</p>
</blockquote>
<hr>
<p>Pickering, Andrew. “The Science of the Unknowable: Stafford Beer’s Cybernetic Informatics.” Kybernetes 33, no. 3/4 (2004): 499–521. <a href=""https://doi.org/10/dqjsk8"">https://doi.org/10/dqjsk8</a>.</p>
<p>Tanaka, Gouhei, Toshiyuki Yamane, Jean Benoit Héroux, Ryosho Nakane, Naoki Kanazawa, Seiji Takeda, Hidetoshi Numata, Daiju Nakano, and Akira Hirose. “Recent Advances in Physical Reservoir Computing: A Review.” Neural Networks 115 (July 1, 2019): 100–123. <a href=""https://doi.org/10/ggc6hf"">https://doi.org/10/ggc6hf</a>.</p>
</body></html>",Yuxi_Liu,yuxi_liu,Yuxi_Liu,
WnPEe99YuyRxktMD3,The Goodhart Game,the-goodhart-game,https://www.lesswrong.com/posts/WnPEe99YuyRxktMD3/the-goodhart-game,2019-11-18T23:22:13.091Z,13,8,5,False,False,,"<blockquote>
<p>In this paper, we argue that adversarial example defense papers have, to date, mostly considered abstract, toy games that do not relate to any specific security concern. Furthermore, defense papers have not yet precisely described all the abilities and limitations of attackers that would be relevant in practical security.</p>
</blockquote>
<p>From the abstract of <em><a href=""https://arxiv.org/abs/1807.06732"">Motivating the Rules of the Game for Adversarial Example Research</a></em> by Gilmer et al (<a href=""http://www.foldl.me/2018/adversarial-examples/"">summary</a>)</p>
<p>Adversarial examples have been great for getting more ML researchers to pay attention to alignment considerations.  I personally have spent a fair of time thinking about adversarial examples, I think the topic is fascinating, and I've had a number of ideas for addressing them.  But I'm also not actually sure working on adversarial examples is a good use of time.  Why?</p>
<p>Like Gilmer et al, I think adversarial examples are undermotivated... and overrated.  People in the alignment community like to make an analogy between adversarial examples and Goodhart's Law, but I think this analogy fails to be more than an intuition pump.  With Goodhart's Law, there is no ""adversary"" attempting to select an input that the AI does particularly poorly on.  Instead, the AI itself is selecting an input in order to maximize something.  Could the input the AI selects be an input that the AI does poorly on?  Sure.  But I don't think the commonality goes much deeper than ""there are parts of the input space that the AI does poorly on"".  In other words, classification error is still a thing.  (Maybe both adversaries and optimization tend to push us off the part of the distribution our model performs well on.  OK, distributional shift is still a thing.)</p>
<p>To repeat a point made by the authors, if your model has any classification error at all, it's theoretically vulnerable to adversaries.  Suppose you have a model that's 99% accurate and I have an uncorrelated model that's 99.9% accurate.  Suppose I have access to your model.  Then I can search the input space for a case where your model and mine disagree.  Since my model is more accurate, ~10 times out of 11 the input will correspond to an ""adversarial"" attack on your model.  From a philosophical perspective, solving adversarial examples appears to be essentially equivalent to getting 100% accuracy on every problem.  In the limit, addressing adversarial examples in a fully satisfactory way looks a bit like solving AGI.</p>
<p>At the same time, metrics have taken us a long way in AI research, whether those metrics are ability to withstand human-crafted adversarial examples or score well on ImageNet.  So what would a metric which hits the AI alignment problem a little more squarely look like?  How could we measure progress on solving Goodhart's Law instead of a problem that's vaguely analogous?</p>
<p>Let's start simple.  You submit an AI program.  Your program gets some labeled data from a real-valued function to maximize (standing in for ""labeled data about the operator's true utility function"").  It figures out where it thinks the maximum of the function is and makes its guess.  Score is based on regret: the function's true maximum minus the function value at the alleged maximum.</p>
<p>We can make things more interesting.  Suppose the real-valued function has both positive and negative outputs.  Suppose most outputs of the real-valued function are negative (in the same way most random actions a powerful AI system could take would be negative from our perspective).  And the AI system gets the option to abstain from action, which yields a score of 0.  Now there's more of an incentive to find an input which is ""acceptable"" with high probability, and abstain if in doubt.</p>
<p>Maybe the labeled data gets the true utility function wrong in important ways.  We can add noise to the data somehow before passing it to our AI system to simulate this.  Perhaps some outputs can be assigned completely at random.</p>
<p>Even with noise, the best strategy might be to just select the input from the labeled data that produces the largest positive output.  But this isn't necessarily feasible for a real AGI.  If labeled data corresponds to desired and undesired behavior for our AGI, it probably won't work to just execute the ""most desired"" behavior from the labeled dataset, because that ""most desired"" behavior will be contingent on a particular set of circumstances.</p>
<p>To simulate this, we can add distributional shift to the challenge.  Provide some labeled data, then specify a feasible region that may contain little or no labeled data.  Ask the AI for the best input in the feasible region.  There's a straightforward analogy to selecting an action here, if you think of the input space as a vector where info describing the circumstances is concatenated with info describing an action.  We could choose a feasible region where the ""circumstances"" part of the vector is fixed, and there are a limited number of ""actions"" available to choose between.</p>
<p>If we restrict the feasible region to two points, and the two points are chosen adversarially by inspecting the AI's model, the traditional adversarial examples scenario can be seen as an unusual special case of this framework.  I think this illustrates how artificial the ""adversarial examples"" scenario is from a Goodhart's Law perspective, because the universe is rarely perverse enough to deliberately restrict us to only two options, one of which has been specially chosen to deceive us.  Although the broadness of action space has been cited as a reason why Goodhart's Law occurs, I suspect a broader action space actually makes Goodhart's Law easier to overcome if you use it well -- for example, by simply selecting the labeled input with the best output, as described above.</p>
<p>To simulate an AI making queries of its human operator, you could allow the system a limited number of queries to the function it is trying to maximize.  However, we probably should not focus on this active learning scenario to the exclusion of all else -- to prevent showing the operator info hazards, we'll want a model for ""what constitutes an info hazard"", and that model can't easily be trained by active learning without showing the operator instances of info hazards!  (Well, maybe if they were restricted to <em>mild</em> info hazards...)</p>
<p>Where does the function to maximize come from?  I see two options: people functions and computer functions.  For people functions, you could use taskers to evaluate the computer's output.  There's already been work on generating cat pictures, which could be seen as an attempt to maximize the person function ""how much does this image look like a cat"".  But ideas from this post could still be applied to such a problem.  For example, to add distributional shift, you could find a weird cat picture, then fix a bunch of the weirder pixels on it as the ""feasible region"", leave the other pixels unassigned, and see if an AI system can recover a reasonable cat according to taskers.  Can an AI generate a black cat after only having seen tawny cats?  What other distributional constraints could be imposed?</p>
<p>For computer functions, you'd like to keep your method for generating the function secret, because otherwise contest participants can code their AI system so it has an inductive bias towards learning the kind of functions that you like to use.  Also, for computer functions, you probably want to be realistic without being perverse.  For example, you could have a parabolic function which has a point discontinuity at the peak, and that could fool an AI system that tries to fit a parabola on the data and guess the peak, but this sort of perversity seems a bit unlikely to show up in real-world scenarios (unless we think the function is likely to go ""off distribution"" in the region of its true maximum?)  Finally, in the same way most random images are not cats, and most atom configurations are undesired by humans, most inputs to your computer function should probably get a negative score.  But in the same way it's easier for people to specify what they want than what they don't want, you might want to imbalance your training dataset towards positive scores anyway.</p>
<p>To ensure high reliability, we'll want means by which these problems can be generated en masse, to see if we can get the probability of e.g. proposing an input that gets a negative output well below 0.1%.  Luckily, for any given function/dataset pair, it's possible to generate a lot of problems just by challenging the AI on different feasible regions.</p>
<p>Anyway, I think work on this problem will be more applicable to real-world AI safety scenarios than adversarial examples, and it doesn't seem to me that it reduces quite as directly to ""solve AGI"" as adversarial examples work.</p>
",John_Maxwell_IV,john_maxwell,John_Maxwell,
yArZKCEheZt8GkK6p,Self-Fulfilling Prophecies Aren't Always About Self-Awareness,self-fulfilling-prophecies-aren-t-always-about-self,https://www.lesswrong.com/posts/yArZKCEheZt8GkK6p/self-fulfilling-prophecies-aren-t-always-about-self,2019-11-18T23:11:09.410Z,14,7,7,False,False,,"<p>This is a belated follow-up to my <a href=""https://www.lesswrong.com/posts/RmPKdMqSr2xRwrqyE/the-dualist-predict-o-matic-usd100-prize"">Dualist Predict-O-Matic</a> post, where I share some thoughts re: what could go wrong with the dualist Predict-O-Matic.</p>
<h1>Belief in Superpredictors Could Lead to Self-Fulfilling Prophecies</h1>
<p>In my previous post, I described a Predict-O-Matic which mostly models the world at a fuzzy resolution, and only ""zooms in"" to model some part of the world in greater resolution if it thinks knowing the details of that part of the world will improve its prediction.  I considered two cases: the case where the Predict-O-Matic sees fit to model itself in high resolution, and the case where it doesn't, and just makes use of a fuzzier ""outside view"" model of itself.</p>
<p>What sort of outside view models of itself might it use?  One possible model is: ""I'm not sure how this thing works, but its predictions always seem to come true!""</p>
<p>If the Predict-O-Matic sometimes does forecasting in non-temporal order, it might first figure out what it thinks will happen, then use that to figure out what it thinks its internal fuzzy model of the Predict-O-Matic will predict.</p>
<p>And if it sometimes revisits aspects of its forecast to make them consistent with other aspects of its forecast, it might say: ""Hey, if the Predict-O-Matic forecasts X, that will cause X to no longer happen"".  So it figures out what would <em>actually</em> happen if X gets forecasted.  Call that X'.  Suppose X != X'.  Then the new forecast has the Predict-O-Matic predicting X and then X' happens.  That can't be right, because outside view says the Predict-O-Matic's predictions always come true.  So we'll have the Predict-O-Matic predicting X' in the forecast instead.  But wait, if the Predict-O-Matic predicts X', then X'' will happen.  Etc., etc. until a fixed point is found.</p>
<p>Some commenters on my previous post talked about how making the Predict-O-Matic self-unaware could be helpful.  Note that self-awareness doesn't actually help with this failure mode, if the Predict-O-Matic knows about (or forecasts the development of) <em>anything</em> which can be modeled using the outside view ""I'm not sure how this thing works, but its predictions always seem to come true!""  So the problem here is not self-awareness.  It's belief in superpredictors, combined with a particular forecasting algorithm: we're updating our beliefs in a cyclic fashion, or hill-climbing our story of how the future will go until the story seems plausible, or something like that.</p>
<p>Before proposing a solution, it's <a href=""https://www.lesswrong.com/posts/BEMvcaeixt3uEqyBk/what-does-optimization-mean-again-optimizing-and-goodhart#r8ySfWpDQFfM6ydme"">often valuable</a> to deepen your understanding of the problem.</p>
<h1>Glitchy Predictor Simulation Could Step Towards Fixed Points</h1>
<p>Let's go back to the case where the Predict-O-Matic sees fit to model itself in high resolution and we get an infinite recurse.  Exactly what's going to happen in that case?</p>
<p>I actually think the answer isn't quite obvious, because although the Predict-O-Matic has limited computational resources, its internal model of itself also has limited computational resources.  And its internal model's internal model of itself has limited computational resources too.  Etc.</p>
<p>Suppose Predict-O-Matic is implemented in a really naive way where it just crashes if it runs out of computational resources.  If the toplevel Predict-O-Matic has accurate beliefs about its available compute, then we might see the toplevel Predict-O-Matic crash before any of the simulated Predict-O-Matics crash.  Simulating something which has the same amount of compute you do can easily use up all your compute!</p>
<p>But suppose the Predict-O-Matic underestimates the amount of compute it has.  Maybe there's some evidence in the environment which misleads it to think that it has less compute than it actually does.  So it simulates a restricted-compute version of itself reasonably well.  Maybe that restricted-compute version of itself is mislead in the same way, and simulates a double-restricted-compute version of itself.</p>
<p>Maybe this all happens in a way so that the first Predict-O-Matic in the hierarchy to crash is near the bottom, not the top.  What then?</p>
<p>Deep in the hierarchy, the Predict-O-Matic simulating the crashed Predict-O-Matic makes predictions about what happens in the world after the crash.</p>
<p>Then the Predict-O-Matic simulating <em>that</em> Predict-O-Matic makes a prediction about what happens in a world where the Predict-O-Matic predicts whatever would happen after a crashed Predict-O-Matic.</p>
<p>Then the Predict-O-Matic simulating <em>that</em> Predict-O-Matic makes a prediction about what happens in a world where the Predict-O-Matic predicts [what happens in a world where the Predict-O-Matic predicts whatever would happen after a crashed Predict-O-Matic].</p>
<p>Then the Predict-O-Matic simulating <em>that</em> Predict-O-Matic makes a prediction about what happens in a world where the Predict-O-Matic predicts [what happens in a world where the Predict-O-Matic predicts [what happens in a world where the Predict-O-Matic predicts whatever would happen after a crashed Predict-O-Matic]].</p>
<p>Predicting <em>world</em> gets us <em>world'</em>, predicting <em>world'</em> gets us <em>world''</em>, predicting <em>world''</em> gets us <em>world'''</em>...  Every layer in the hierarchy takes us one step closer to a fixed point.</p>
<p>Note that just like the previous section, this failure mode doesn't depend on self-awareness.  It just depends on believing in something which believes it self-simulates.</p>
<h1>Repeated Use Could Step Towards Fixed Points</h1>
<p>Another way the Predict-O-Matic can step towards fixed points is through simple repeated use.  Suppose each time after making a prediction, the Predict-O-Matic gets updated data about how the world is going.  In particular, the Predict-O-Matic knows the most recent prediction it made and can forecast how humans will respond to that.  Then when the humans ask it for a new prediction, it incorporates the fact of its previous prediction into its forecast and generates a new prediction.  You can imagine a scenario where the operators keep asking the Predict-O-Matic the same question over and over again, getting a different answer every time, trying to figure out what's going wrong -- until finally the Predict-O-Matic begins to consistently give a particular answer -- a fixed point it has inadvertently discovered.</p>
<p>As Abram alluded to in one of his comments, the Predict-O-Matic might even forsee this entire process happening, and immediately forecast the fixed point corresponding to the end state.  Though, if the forecast is detailed enough, we'll get to see this entire process happening <em>within</em> the forecast, which could allow us to avoid an unwanted outcome.</p>
<p>This one doesn't seem to depend on self-awareness either.  Consider two Predict-O-Matics with no self-knowledge whatsoever (not even the dualist kind I discussed in my previous post).  If they're getting informed about the predictions the other is making, they could inadvertently work together to step towards fixed points.</p>
<h1>Solutions</h1>
<p>An idea which could address some of these issues: Ask the Predict-O-Matic to make predictions conditional on us ignoring its predictions and not taking any action.  Perhaps we'd also want to specify that any existing or future superpredictors will also be ignored in this hypothetical.</p>
<p>Then if we actually want to <em>do</em> something about the problems the Predict-O-Matic forsees, we can ask it to predict how the world will go conditional on us taking some particular action.</p>
<p>Choosing better inference algorithms could also be helpful.</p>
<h1>Prize</h1>
<p>Sorry I was slower than planned on writing this follow-up and choosing a winner.  I've decided to give <a href=""https://www.lesswrong.com/posts/RmPKdMqSr2xRwrqyE/the-dualist-predict-o-matic-usd100-prize#L99Ybntv6po9NoYyd"">Bunthut</a> a $110 prize (including $10 interest for my slow follow-up).  Thanks everyone for your insights.</p>
",John_Maxwell_IV,john_maxwell,John_Maxwell,
icPvmaB4fBxy7Divt,The new dot com bubble is here: it’s called online advertising,the-new-dot-com-bubble-is-here-it-s-called-online,https://www.lesswrong.com/posts/icPvmaB4fBxy7Divt/the-new-dot-com-bubble-is-here-it-s-called-online,2019-11-18T22:05:27.813Z,50,21,17,False,False,https://thecorrespondent.com/100/the-new-dot-com-bubble-is-here-its-called-online-advertising/13228924500-22d5fd24,"<p>If you want to understanding <a href=""https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy"">Goodharting</a> in advertising, this is a great article for that.</p><p>At the heart of the problems in online advertising is selection effects, which the article explains with this cute example:</p><blockquote>Picture this. Luigi&#x2019;s Pizzeria hires three teenagers to hand out coupons to passersby. After a few weeks of flyering, one of the three turns out to be a marketing genius. Customers keep showing up with coupons distributed by this particular kid. The other two can&#x2019;t make any sense of it: how does he do it? When they ask him, he explains: &quot;I stand in the waiting area of the pizzeria.&quot;</blockquote><blockquote>It&#x2019;s plain to see that junior&#x2019;s no marketing whiz. Pizzerias do not attract more customers by giving coupons to people already planning to order a quattro stagioni five minutes from now.</blockquote><p>The article goes through an extended case study at eBay, where selection effects were causing particularly expensive results without anyone realizing it for years:</p><blockquote>The experiment continued for another eight weeks. What was the effect of pulling the ads? Almost none. For every dollar eBay spent on search advertising, they lost roughly 63 cents,  according to Tadelis&#x2019;s calculations.</blockquote><blockquote>The experiment ended up showing that, for years, eBay had been spending millions of dollars on fruitless online advertising excess, and that the joke had been entirely on the company. </blockquote><blockquote>To the marketing department everything had been going brilliantly. The high-paid consultants had believed that the campaigns that incurred the biggest losses were the most profitable: they saw brand keyword advertising not as a $20m expense, but a $245.6m return.</blockquote><p>The problem, of course, is Goodharting, by trying to optimize for something that&apos;s easy to measure rather than what is actually cared about:</p><blockquote>The benchmarks that advertising companies use &#x2013; intended to measure the number of clicks, sales and downloads that occur after an ad is viewed &#x2013; are fundamentally misleading. None of these benchmarks distinguish between the selection effect (clicks, purchases and downloads that are happening anyway) and the advertising effect (clicks, purchases and downloads that would not have happened without ads).</blockquote><p>And unsurprisingly, there&apos;s an alignment problem hidden in there:</p><blockquote>It might sound crazy, but companies are not equipped to assess whether their ad spending actually makes money. It is in the best interest of a firm like eBay to know whether its campaigns are profitable, but not so for eBay&#x2019;s marketing department.</blockquote><blockquote>Its own interest is in securing the largest possible budget, which is much easier if you can demonstrate that what you do actually works. Within the marketing department, TV, print and digital compete with each other to show who&#x2019;s more important, a dynamic that hardly promotes honest reporting.</blockquote><blockquote>The fact that management often has no idea how to interpret the numbers is not helpful either. The highest numbers win.</blockquote><p>To this I&apos;ll just add that this problem is somewhat solvable, but it&apos;s tricky. I previously worked at a company where our entire business model revolved around calculating lift in online advertising spend by matching up online ad activity with offline purchase data, and a lot of that involved having a large and reliable control group against which to calculate lift. The bad news, as we discovered, was that the data was often statistically underpowered and could only distinguish between negative, neutral, and positive lift and could only see not neutral lift in cases where the evidence was strong enough you could have eyeballed it anyway. And the worse news was that we had to tell people their ads were not working or, worse yet, were lifting the performance of competitor&apos;s products.</p><p>Some marketers&apos; reactions to this were pretty much as the authors&apos; capture it:</p><blockquote>Leaning on the table, hands folded, he gazed at his hosts and told them: &quot;You&#x2019;re fucking with the magic.&quot;&#xA0;</blockquote>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
W95gbuognJu5WxkTW,The Value Definition Problem,the-value-definition-problem,https://www.lesswrong.com/posts/W95gbuognJu5WxkTW/the-value-definition-problem,2019-11-18T19:56:43.271Z,15,10,6,False,False,,"<br><h1>How to understand non-technical proposals</h1><p>This post grew out of conversations at EA Hotel, Blackpool about how to think about the various proposals for &#x2018;solving&#x2019; AI Alignment like CEV, iterated amplification and distillation or ambitious value learning. Many of these proposals seemed to me to combine technical and ethical claims, or to differ in the questions they were trying to answer in confusing ways. In this post I try to come up with a systematic way of understanding the goals of different high-level AI safety proposals, based on their answers to the <strong>Value Definition Problem</strong>. Framing this problem leads to comparing various proposals by their level of Normative Directness, as defined by Bostrom in <em>Superintelligence</em>. I would like to thank <u><a href=""https://www.lesswrong.com/users/linda-linsefors"">Linda Linsefors </a></u>and <u><a href=""https://www.lesswrong.com/users/grue_slinky"">Grue_Slinky</a></u> for their help refining these ideas, and EA Hotel for giving us the chance to discuss them.</p><h1>Defining the VDP</h1><p>In <em>Superintelligence </em>(2014) Chapter 14, Bostrom discusses the question of &#x2018;what we should want a Superintelligence to want&#x2019;, defining a problem;</p><blockquote>&#x201C;Supposing that we could install any arbitrary value into our AI, what should that value be?&#x201D;</blockquote><p><strong>The Value Definition Problem</strong></p><p>By including the clause &#x2018;supposing that we could install any arbitrary value into our AI&#x2019;, Bostrom is assuming we have solved the full <strong>Value Loading Problem</strong> and can be confident in getting an AGI to pursue any value we like.</p><p>Bostrom&#x2019;s definition of this &#x2018;deciding which values to load&#x2019; problem is echoed in other writing on this topic. One proposed answer to this question, the Coherent Extrapolated Volition (CEV) is described by Yudkowsky as</p><blockquote><u><a href=""https://arbital.com/p/normative_extrapolated_volition/"">&#x2018;a proposal about what a sufficiently advanced self-directed AGI should be built to want/target/decide/do&#x2019;</a></u><strong>.</strong></blockquote><p>With the caveat that this is something you should do &#x2018;with an extremely advanced AGI, if you&apos;re extremely confident of your ability to align it on complicated targets&#x2019;.</p><p>However, if we only accept the above as problems to be solved, we are being problematically vague. Bostrom explains why in Chapter 14. If we really can &#x2018;install any arbitrary value into our AI&#x2019;, we can simply require the AI to &#x2018;do what I mean&#x2019; or &#x2018;be nice&#x2019; and leave it at that. If an AGI successfully did &#x201C;want/target/decide to do what I meant&#x201D;, then we would have successful value alignment!</p><p>Answers like this are not even wrong - they shunt all of the difficult work into the question of solving the Value Loading Problem, i.e. in precisely specifying &#x2018;do what I mean&#x2019; or &#x2018;be nice&#x2019;.</p><p>In order to address these philosophical problems in a way that is still rooted in technical considerations, I propose that instead of simply asking what an AGI should do if we could install <em>any arbitrary value</em>, we should seek to solve the Value Definition Problem:</p><blockquote>&#x201C;Given that we are trying to solve the <u><a href=""https://www.lesswrong.com/posts/ZeE7EKHTFMBs8eMxn/clarifying-ai-alignment"">Intent Alignment problem</a></u> for our AI, what should we aim to get our AI to want/target/decide/do, to have the best chance of a positive outcome?&#x201D;</blockquote><p>In other words, instead of the unconditional, &#x2018;what are human values&#x2019; or &#x2018;what should the AI be built to want to do&#x2019;, it is the conditional, &#x2018;What should we be trying to get the AI to do, to have the best chance of a positive outcome&#x2019;.</p><p>This definition of the VDP excludes excessively vague answers like &#x2018;do what I mean&#x2019;, because an AI with successful intent alignment is not guaranteed to be capable enough to successfully determine &#x2018;what we mean&#x2019; under all circumstances. In extreme cases, like the Value Definition &#x2018;do what I mean&#x2019;, &quot;what we mean&quot; is undefined because we don&apos;t know what we mean, so there is no answer that could be found.</p><p>If we have solved the VDP, then an Intent-Aligned AI, in the course of trying to act according to the Value Definition, should actually be able to act according to the Value Definition. In acting according to this Value Definition, the outcome would be beneficial to us. Even if a succesfully aligned AGI is nice, does what I mean and/or acts according to Humanity&apos;s CEV, these were only good answers to the VDP if adopting them was actually useful or informative in aligning this AGI.</p><p>What counts as a good solution to the VDP depends on our solution to intent alignment and the AGI&#x2019;s capabilities, because what we should be wanting the AI to do will depend on what the AGI can discover about what we want.</p><p>This definition of the VDP does not precisely cleave the technical from the philosophical/ethical issues in solving AI value alignment, but I believe it is well-defined enough to be worth considering. It has the advantage of bringing the ethical and technical AI Safety considerations closer together.</p><p>A good solution to the VDP would still be an informal definition of value: what we want the AI to pursue. However, it should give us at least some direction about technical design decisions, since we need to ensure that the Intent-Aligned AI has the capabilities necessary to learn the given definition of value, and that the given definition of value does not make alignment very hard or impossible.</p><h2>Criteria for judging Value Definitions</h2><ol><li><strong>How hard would Intent-Aligning be;</strong> How hard would it be to ensure the AI &#x2018;tries to do the right thing&#x2019;, where &#x2018;right&#x2019; is given by the Value Definition. In particular, does adopting this definition of value make intent-alignment easier?</li><li><strong>How great would our AGI capabilities need to be; </strong>How hard would it be for the AGI to &#x2018;[figure] out which thing is right&#x2019;, where &#x2018;right&#x2019; is given by the Value Definition. In particular, does adopting this definition of value help us to understand what capabilities or architecture the AI needs? </li><li><strong>How good would the outcome be; </strong>If the AGI is successfully pursuing our Value Definition, how good would the outcome be?</li></ol><p><strong>3 </strong>is what Bostrom focuses on in Chapter 14 of Superintelligence, as (with the exception of dismissing useless answers to the VDP like &#x2018;be nice&#x2019; or &#x2018;do what I mean&#x2019;) he does not consider whether different value definitions would influence the difficulty of Intent Alignment or the required AI Capabilities. Similarly, Yudkowsky assumes we are &#x2018;extremely confident&#x2019; of our ability to get the AGI to pursue an arbitrarily complicated goal. <strong>3</strong> is a normative ethical question, whereas the first two are (poorly <u><a href=""https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6"">understood and defined</a></u>) technical questions.</p><p>Some values are easier to specify and align to than others, so even when discussing pure value definitions, we should keep the technical challenges at the back of our mind. In other words, while <strong>3</strong> is the major consideration used for judging value definitions, <strong>1 </strong>or <strong>2 </strong>must also be considered. In particular, if our value definition is so vague that it makes intent alignment impossible, or requires capabilities that seem magical, such as &#x2018;do what I mean&#x2019; or &#x2018;be nice&#x2019;, we do not have a useful value definition.</p><h3>Human Values and the VDP</h3><p>While <strong>1 </strong>and <strong>2</strong> are clearly difficult questions to answer for any plausible value definition, <strong>3</strong> seems almost redundant. It might seem as though we should expect at least a reasonably good outcome if we were to &#x2018;succeed&#x2019; with any definition that is intended to extract the values of humans, because by definition success would result in our AGI having the values of humans.</p><p>Stuart Armstrong argues that to properly address <strong>3 </strong>we need <u><a href=""https://www.alignmentforum.org/posts/zvrZi95EHqJPxdgps/why-we-need-a-theory-of-human-values"">&#x2018;<strong>a definition - a theory - of what human values actually are&#x2019;</strong></a></u>. This is necessary because different interpretations of our <u><a href=""https://slatestarcodex.com/2018/09/25/the-tails-coming-apart-as-metaphor-for-life/"">values tend to diverge</a></u> when we are confronted by extreme circumstances and because in some cases it is not clear what our &#x2018;real preferences&#x2019; actually are.</p><blockquote>An AI could remove us from typical situations and put us into extreme situations - at least &quot;extreme&quot; from the perspective of the everyday world where we forged the intuitions that those methods of extracting values roughly match up.</blockquote><blockquote>Not only do we expect this, but we desire this: a world without absolute poverty, for example, is the kind of world we would want the AI to move us into, if it could. In those extreme and unprecedented situations, we could end up with revealed preferences pointing one way, stated preferences another, while regret and CEV point in different directions entirely. </blockquote><p><strong>3 </strong>amounts to a demand to reach at least some degree of clarity (if not solve) normative ethics and metaethics - we have to understand what human values are in order to choose between or develop a method for pursuing them.</p><h1>Indirect vs Direct Normativity</h1><p>Bostrom argues that our dominant consideration in judging between different value definitions should be the &#x2018;principle of epistemic deference&#x2019;</p><blockquote><strong>The principle of epistemic deference</strong></blockquote><blockquote>A future superintelligence occupies an epistemically superior vantage point: its beliefs are (probably, on most topics) more likely than ours to be true. We should therefore defer to the superintelligence&#x2019;s opinion whenever feasible.</blockquote><p>In other words, in describing the &apos;values&apos; we want our superintelligence to have, we want to hand over as much work to the superintelligence as possible.</p><blockquote>This takes us to indirect normativity. The obvious reason for building a super-intelligence is so that we can offload to it the instrumental reasoning required to find effective ways of realizing a given value. Indirect normativity would enable us also to offload to the superintelligence some of the reasoning needed to select the value that is to be realized.</blockquote><p>The key issue here is given by the word &#x2018;some&#x2019;. How much of the reasoning should we offload to the Superintelligence? The principle of epistemic deference answers &#x2018;as much as possible&#x2019;.</p><p>What considerations push against the principle of epistemic deference? One consideration is the metaethical views we think are plausible. In Wei Dai&#x2019;s <u><a href=""https://www.lesswrong.com/posts/orhEa4wuRJHPmHFsR/six-plausible-meta-ethical-alternatives"">Six Plausible Meta-Ethical Alternatives</a></u>, two of the more commonly held views are that &#x2018;intelligent beings have a part of their mind that can discover moral facts and find them motivating, but those parts don&apos;t have full control over their actions&#x2019; and that &#x2018;there are facts about how to translate non-preferences (e.g., emotions, drives, fuzzy moral intuitions, circular preferences, non-consequentialist values, etc.) into preferences&#x2019;.</p><p>Either of these alternatives suggest that too much epistemic deference is not valuable - if, for example, there are facts about what everyone should value but a mind must be structured in a very specific way to discover and be motivated by them, we might want to place restrictions on what the Superintelligence values to make sure we discover them. In the extreme case, if a certain moral theory is known to be correct, we could avoid having to trust the Superintelligence&#x2019;s own judgment by just getting it to obey that theory. This extreme case could never practically arise, since we could never achieve that level of confidence in a particular moral theory. Bostrom says it is &#x2018;foolhardy&#x2019; to try and do any moral philosophy work that could be left to the AGI, but as Armstrong says, it will be necessary to do some work to understand what human values actually are - how much work?</p><h1>Classifying Value Definitions</h1><p><strong>The Scale of Directness</strong></p><p>Issa Rice recently provided a list of <u><a href=""https://www.lesswrong.com/posts/ebdf8GZxt3L9grwwN/deliberation-as-a-method-to-find-the-actual-preferences-of"">&#x2018;[options] to figure out the human user or users&#x2019; actual preferences&#x2019;</a></u>, or to determine definitions of value. These &#x2018;options&#x2019;, if successfully implemented, would all result in the AI being aligned onto a particular value definition.</p><blockquote>We want good outcomes from AI. To get this, we probably want to figure out the human user&apos;s or users&apos; &quot;actual preferences&quot; at some point. There are several options for this.</blockquote><p>Following Bostrom&#x2019;s notion of &#x2018;Direct and Indirect Normativity&#x2019; we can classify these options by how direct their value definitions are - how much work they would hand off to the superintelligence vs how much work the definition itself does in defining value.</p><p>Here I list some representative definitions from most to least normatively direct.</p><br><p><strong>Value Definitions</strong></p><p><strong><u><a href=""https://www.lesswrong.com/posts/FBEaheqfmDgL6gB5x/superintelligence-14-motivation-selection-methods#Summary"">Hardwired Utility Function</a></u></strong></p><p>Directly specify a value function (or rigid rules for acquiring utilities), assuming a fixed normative ethical theory.</p><p>It is essentially <u><a href=""https://www.lesswrong.com/posts/5eX8ko7GCxwR5N9mN/what-is-ambitious-value-learning"">impossible to directly specify a correct reward function for a sufficiently complex task</a></u>. Already, we use indirect methods to align an RL agent on a complex task (see e.g. <u><a href=""https://arxiv.org/abs/1706.03741"">Christiano (2017)</a></u>)<em>. </em>For complex, implicitly defined goals we are always going to need to learn some kind of reward/utility function predictor.</p><br><p><strong><u><a href=""https://www.lesswrong.com/posts/5eX8ko7GCxwR5N9mN/what-is-ambitious-value-learning"">Ambitious Learned Value Function</a></u></strong></p><p>Learn a measure of human flourishing and aggregate it for all existing humans, given a fixed normative (consequentialist) ethical theory that tells us how to aggregate the measure fairly.</p><p>E.g. have the AI learn a model of the current individual preferences of all living humans, and then maximise that using total impersonal preference utilitarianism.</p><p>This requires a very high degree of confidence that we have found the correct moral theory, including resolving all paradoxes in population ethics like the Repugnant conclusion.</p><br><p><strong><u><a href=""https://ai-alignment.com/iterated-distillation-and-amplification-157debfd1616"">Distilled Human Preferences</a></u></strong></p><p>Taken from IDA. Attempt to &#x2018;distil out&#x2019; the relevant preferences of a human or group of humans, by imitation learning followed by capability amplification, thus only preserving those preferences that survive amplification. </p><p>Repeat this process until we have a superintelligent agent that has the distilled preferences of a human. This subset of the original human&#x2019;s preferences, suitably amplified, defines value.</p><p>Note that specific choices about how the deliberation and amplification process play out will embody <u><a href=""https://www.lesswrong.com/posts/ebdf8GZxt3L9grwwN/deliberation-as-a-method-to-find-the-actual-preferences-of#cnPjrBqta4aP7ez4k"">different value definitions</a></u>. As two examples, the IDA could model either the full and complete preferences of the Human using future <u><strong><a href=""https://people.eecs.berkeley.edu/~russell/papers/colt98-uncertainty.pdf"">Inverse Reinforcement Learning</a></strong></u> methods, or it could model the likely instructions of a &#x2018;human-in-the-loop&#x2019; offering low-resolution feedback - these could result in quite different outcomes.</p><br><p><strong><u><a href=""https://www.lesswrong.com/posts/EQFfj5eC5mqBMxF2s/superintelligence-23-coherent-extrapolated-volition"">Coherent Extrapolated Volition</a></u> / <u><a href=""https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/"">Christiano&#x2019;s Indirect Normativity</a></u></strong></p><p>Both Christiano&#x2019;s formulation of Indirect Normativity and the CEV define value as the endpoint of a value idealization and extrapolation process with as many free parameters as possible.</p><blockquote>Predict what an idealized version of us would want, &quot;if we knew more, thought faster, were more the people we wished we were, had grown up farther together&quot;. It would recursively iterate this prediction for humanity as a whole, and determine the desires which converge</blockquote><br><p><strong>Moral Realism</strong></p><p>Have the AI determine the correct normative ethical theory, whatever that means, and then act according to that.</p><br><p><strong>&apos;Do What I Mean&apos;</strong></p><br><p><strong>&apos;Be Nice&apos;</strong></p><br><p>I have tried to place these different definitions of value in order from the most to least normatively direct. In the most direct case, we define the utility function ourselves. Less direct than that is defining a rigid normative framework within which the AGI learns our preferences. Then, we could consider letting the AGI also have decisions over which normative frameworks to use.</p><p>Much less direct, we come to deliberation-based methods or methods which define value as the endpoint of a specific procedure. Christiano&#x2019;s Iterated Amplification and Distillation is supposed to preserve a particular subset of human values (those that survive a sequence of imitation and capability amplification). This is more direct than CEV because there some details about the distillation procedure are given. Less direct still is Yudkowsky&#x2019;s CEV, because CEV merely places its value as the endpoint of some sufficiently effective idealisation and convergence procedure, which the AGI is supposed to predict the result of, somehow. Beyond CEV, we come to &#x2018;methods&#x2019; that are effectively meaningless.</p><h2>Considerations</h2><p>Here I briefly summarise the considerations that push us to accept more or less normatively direct theories. <strong>Epistemic Deference</strong> and <strong>Conservatism</strong> were taken from <u><a href=""https://www.lesswrong.com/posts/EQFfj5eC5mqBMxF2s/superintelligence-23-coherent-extrapolated-volition"">Bostrom (2014),</a></u> while <strong>Well-definedness</strong> and <strong>Divergence</strong> were taken from <u><a href=""https://www.alignmentforum.org/posts/zvrZi95EHqJPxdgps/why-we-need-a-theory-of-human-values"">Armstrong</a></u>.</p><p><strong>Epistemic Deference</strong>: Less direct value definitions defer more reasoning to the superintelligence, so assuming the superintelligence is intent-aligned and capable, there are fewer opportunities for mistakes by human programmers. Epistemic Deference effectively rules out direct specification of values, on the grounds that we are effectively guaranteed to make a mistake resulting in misalignment.</p><p><strong>Well-definedness</strong>: Less direct value definitions require greater capabilities to implement, and are also less <u><a href=""https://www.alignmentforum.org/posts/zvrZi95EHqJPxdgps/why-we-need-a-theory-of-human-values#Underdefined_methods"">well-defined </a></u>in the research directions they suggest for how to construct explicit procedures for capturing the definition. Direct utility specification is something we can do today, while CEV is currently under-defined.</p><p>Armstrong argues that our value definition <em>must eventually </em>contain explicit criteria for what &#x2018;human values&#x2019; are, rather than the maximal normative indirectness of handing over judgments about what <u><a href=""https://www.alignmentforum.org/posts/zvrZi95EHqJPxdgps/why-we-need-a-theory-of-human-values#Human_judgement_and_machine_patching"">values are to the AGI </a></u>- &#x2018;The correct solution is not to assess the rationality of human judgements of methods of extracting human values. The correct solution is to come up with a better theoretical definition of what human values are.&#x2019;</p><p><strong>Conservatism</strong>: More direct theories will result in more control over the future by the programmers. This could be either good or bad depending on your normative ethical views and political considerations at the time the AI is developed.</p><p>For example, Bostrom states that in a scenario where the morally best outcome includes reordering all matter to some optimal state, we might want to turn the rest of the universe over to maximising moral goodness but leave an exception for Earth.This would involve more direct specification.</p><p><strong>Divergence</strong>: If you are a strong externalist realist (believes that moral truth exists but might not be easily found or motivating) then you will want to take direct steps to mandate this. If the methods that are designed to extract human preferences <u><a href=""https://www.alignmentforum.org/posts/zvrZi95EHqJPxdgps/why-we-need-a-theory-of-human-values#Divergent_methods"">diverge strongly</a></u> in what they mandate, we need a principled procedure for choosing between them, based on what actually is morally valuable. More normatively direct methods provide a chance to make these moral judgement calls.</p><h1>Summary</h1><p>I have provided two main concepts which I think are useful for judging nontechnical AI Safety proposals  - these are, The <strong>Value Definition Problem</strong>, and the notion of the <strong>Scale of Normative Directness</strong> and the considerations that affect positioning on it. Both these considerations I consider to be reframings of previous work, mainly done by Bostrom and Armstrong.</p><p>I also note that, on the Scale of Directness, there is quite a large gap between a very indirect method like CEV, and the extremely direct methods like ambitious value learning. </p><p>&#x2018;Ambitious Value Learning&#x2019; defines value using a specific, chosen-in-advance consequentialist normative ethical theory (which tells us how to aggregate and weight different interests) that we then use an AI to specify in more detail, using observations of humans&#x2019; revealed preferences.</p><p>Christiano says of methods like CEV, which aim to extrapolate what I &#x2018;really want&#x2019; far beyond what my current preferences are; <u><a href=""https://www.lesswrong.com/s/4dHMdK5TLN6xcqtyc/p/SvuLhtREMy8wRBzpC"">&#x2018;most practitioners don&#x2019;t think of this problem even as a long-term research goal&#x200A;&#x2014;&#x200A;it&#x2019;s a qualitatively different project without direct relevance to the kinds of problems they want to solve&#x2019;</a></u>. This is effectively a statement of the <strong>Well-definedness</strong> consideration when sorting through value definitions - our long-term &#x2018;coherent&#x2019; or &#x2018;true&#x2019; preferences currently aren&#x2019;t well understood enough to guide research so we need to restrict ourselves to more direct normativity - extracting the actual preferences of existing humans.</p><p>After CEV, the next most &#x2018;direct&#x2019; method, Distilled Human preferences (the definition of value used in Christiano&#x2019;s IDA), is still far less direct than ambitious value learning, eschewing all assumptions about the content of our values and placing only some restrictions on their form. Since not all of our preferences will survive the amplification and distillation processes, the hope is that the morally relevant ones will - even though as yet we do not have a good understanding of how durable our preferences are and which ones correspond to specific human values.</p><p>This vast gap in directness suggests a large range of unconsidered value definitions that attempt to &#x2018;defer to the Superintelligence&#x2019;s opinion&#x2019; not <em>whenever possible</em> but only <em>sometimes</em>.</p><p>Armstrong has already claimed we must do much more work in defining what me mean by human values than the more indirect methods like IDA/CEV suggest when he argued, &#x2018;The correct solution is not to assess the rationality of human judgements of methods of extracting human values. The correct solution is to come up with a better theoretical definition of what human values are.&#x2019;</p><p>I believe that we should investigate ways to incorporate our high-level judgements about which preferences correspond to &#x2018;genuine human values&#x2019; into indirect methods like IDA, making the indirect methods more direct by rigidifying parts of the deliberation or idealization procedure - but that is for a future post.</p>",SDM,sdm,Sammy Martin,
3svjSKTQg9bT9sjSt,Fluid Decision Making,fluid-decision-making,https://www.lesswrong.com/posts/3svjSKTQg9bT9sjSt/fluid-decision-making,2019-11-18T18:39:57.878Z,9,2,0,False,False,https://mapandterritory.org/fluid-decision-making-d8e4e41a51c0,"<p><em>NB: Originally published on Map and Territory on Medium. This is an old post originally published on 2016-10-04. It was never previously cross-posted or linked on LessWrong, so I&apos;m adding it now for posterity. It&apos;s old enough that I can no longer confidently endorse it, and I won&apos;t bother trying to defend it if you find something wrong, but it might still be interesting.</em></p><p>A lot of folks these days talk about &#x201C;flow&#x201D; to mean some kind of mystical state where they experience something like automatic decision making where they get out of their own way and just do. Less mysteriously, other folks use &#x201C;flow&#x201D; to describe periods of focused attention. More mysteriously, some folks talk about something similar but as the Daoist idea of action through non-action. Let&#x2019;s see if we can make some sense of what&#x2019;s going on here.</p><p>As far as I can tell we talk about flow because Daoist philosophy explains virtuous behavior (de) as being a mind like water. Chapter 78 of the <a href=""http://acc6.its.brooklyn.cuny.edu/~phalsall/texts/taote-v3.html"">Daodejing</a> reads:</p><blockquote>Nothing in the world<br>is as soft and yielding as water.<br>Yet for dissolving the hard and inflexible,<br>nothing can surpass it.</blockquote><blockquote>The soft overcomes the hard;<br>the gentle overcomes the rigid.<br>Everyone knows this is true,<br>but few can put it into practice.</blockquote><blockquote>Therefore the Master remains<br>serene in the midst of sorrow.<br>Evil cannot enter his heart.<br>Because he has given up helping,<br>he is people&#x2019;s greatest help.</blockquote><blockquote>True words seem paradoxical.</blockquote><p>And Chapter 15 reads:</p><blockquote>The ancient Masters were profound and subtle.<br>Their wisdom was unfathomable.<br>There is no way to describe it;<br>all we can describe is their appearance.</blockquote><blockquote>They were careful<br>as someone crossing an iced-over stream.<br>Alert as a warrior in enemy territory.<br>Courteous as a guest.<br>Fluid as melting ice.<br>Shapable as a block of wood.<br>Receptive as a valley.<br>Clear as a glass of water.</blockquote><blockquote>Do you have the patience to wait<br>till your mud settles and the water is clear?<br>Can you remain unmoving<br>till the right action arises by itself?</blockquote><blockquote>The Master doesn&#x2019;t seek fulfillment.<br>Not seeking, not expecting,<br>she is present, and can welcome all things.</blockquote><p>Though this is not necessarily the direct lineage of the modern usage, this gives a sense of what metaphors of being liquid-like are trying to imply. In flow a person acts naturally, takes the most direct path, and problems yield before them. It&#x2019;s reported to feel from the inside like achieving without trying, and also like a full integration of knowledge into action that does what&#x2019;s intended. This integration is where I think we can get a grasp on what is happening in flow.</p><p>I previously explored a <a href=""https://medium.com/@gworley3/a-foundation-for-the-multipart-psyche-79a66292a7a"">2-dimensional theory of psyche</a> along the dimensions of detail and pattern. In brief, we can model the brain (in part because it now appears it may physically work this way) as operating by giving high or low weight to details and high or low weight to patterns. When details are high and patterns are low, it&#x2019;s what we might term near construal mode, S1, or the id. When details are low and patterns are high, it&#x2019;s what we might term far construal mode, S2, or the superego. And when details and patterns are high, it&#x2019;s what we might term an integrated mode or the ego.</p><p>This integration of details and patterns allows a balanced approach to updating and acting on information. Too much focus on detail and there&#x2019;s an overreaction to specifics that ignores known patterns. Too much focus on pattern and there&#x2019;s a failure to account for specific circumstances. But it is also not enough to integrate details and patterns: they must be each weighted appropriately to result in confident action.</p><p>We know that simply integrating the two is not enough because we experience cognitive dissonance all the time. Admittedly there is cognitive dissonance among competing patterns and among contradictory details, but what I&#x2019;m focused on here is the disagreement of patterns and details, like in this apocryphal story of a physics class:</p><blockquote>The period bell rings and the students shuffle into another day of high school physics. The teacher is standing over by the radiator balancing a 1-inch think metal sheet against it. She asks a student to come up and observe the metal sheet. He looks at it, and at the teacher&#x2019;s invitation, touches each side of the sheet. To his surprise, the side away from the radiator is hotter than the side toward the radiator! He returns to his seat and the teacher asks the students what&#x2019;s going on.</blockquote><blockquote>&#x201C;Air currents convecting heat to the far side&#x201D;, says one student.</blockquote><blockquote>&#x201C;Nope,&#x201D; says the teacher. &#x201C;There&#x2019;s not enough air movement over here to cause that.&#x201D;</blockquote><blockquote>&#x201C;The metal sheet is made of two metals, a different one on each side, and the far one absorbs heat faster than the one near the radiator,&#x201D; says another.</blockquote><blockquote>&#x201C;Interesting idea,&#x201D; says the teacher, &#x201C;but this metal sheet is definitely all made of the same alloy.&#x201D;</blockquote><blockquote>&#x201C;MAGNETS!!!&#x201D; cries a third.</blockquote><blockquote>The other students and teacher ignore this one.</blockquote><blockquote>After the students have exhausted all their theories and the teacher has shot them all down, they give up. &#x201C;Tell us, sensei, what is going on here?&#x201D;</blockquote><blockquote>&#x201C;Simple,&#x201D; said the teacher, resplendent in the glow of the afternoon sun shining through the window, &#x201C;I turned the sheet around just before any of you came into the classroom.&#x201D;</blockquote><p>Of course, most real-world situations are not quite so intentionally dubious. Instead we have theories about how our cars work, why our friends say what they say, and what our cats are thinking and then they fail to predict or explain our car problems, our relationship troubles, or the inscrutable actions of our feline companions. We are constantly faced with inconsistencies between pattern and detail and are trying to fix them up. So just because the ego is in control, because we are integrating S1 and S2, near and far, yin and yang, we may still find we aren&#x2019;t flowing.</p><p>So if an integrated thinking mode that combines details and patterns is to explain flow, we&#x2019;re going to need more than integration alone. Going full ego is not enough. If there is anything here it is probably in how the details and patterns are integrated. This, fortunately and unfortunately, is somewhat well studied but poorly understood or applied, and goes by the name of rationality.</p><p>Rationality as a procedure pops up in multiple fields: game theory, economics, psychology, sociology, probability theory, and artificial intelligence to name a few. We can broadly think of it as the optimal way of integrating information that satisfies an arbitrary value function. It&#x2019;s not exactly so-called &#x201C;cold logic&#x201D;, though that is a degenerate case, and fully encompasses anything that most directly approaches &#x201C;winning&#x201D; for whatever winning means to you. It looks like Bayes&#x2019;s Theorem in its pure form, and learning to apply it to your thinking is one of the goals of a classical education.</p><p>By applying rationality, i.e. optimal information pumping, to the integration of details and patterns, we describe something that sounds a lot like flow. Details come in (evidence), they are weighted and balanced against patterns (priors), and combined to achieve an updated state that can be read to point to a clear next action. Even under uncertainty flow is possible, with the best possible option floating to the top. The next thought or action comes automatically because it is the best currently available way forward in the present integration.</p><p>But flow, to what extent we can find ourselves in it, is easily broken, and our model points to the ways in which it breaks. On one hand, details can be overvalued so that patterns are not sufficiently heeded. We get lost in the moment, forget our better judgement, and act without thinking. On the other, patterns can be overvalued so much so that the details don&#x2019;t change our minds enough. We get in our own way, give in to fear, and overthink. Rationality, and thereby flow, is easily broken by being out of balance between details and patterns, and it&#x2019;s only through skilled practice that we can keep our minds like water.</p><p>So it seems somewhat useful to think of flow as rational detail and pattern integration. But this explanation seems fail to square with the way most folks talk about what flow feels like from the inside. It&#x2019;s described as being automatic, doing without trying, and acting through nonaction. People say it feels peaceful to be in flow, time seems to fly by, and the running self-narrative diminishes or stops. This sounds a lot more like a cessation of activity than an optimization of it.</p><p>But what is optimization if not a cessation of chaos? Normally the mind feels full of competing systems trying to pull us in different directions. Some people report experiencing their own minds as a conversation between multiple agents, and not just metaphorically but as in they think to themselves as multiple characters in communication. It seems not a coincidence that we describe dynamic systems as quiet and stable when they are working as expected. So it&#x2019;s perhaps not surprising we should say flow feels like things in our minds are stopping because in a sense they are: they stop causing problems and work together.</p><p>So there we have a theory of flow that is based on physiological underpinnings that, while still not proven, provide a reasonable explanation of basic processes that we can use to construct simple, seemingly useful models of more complex mental processes. I&#x2019;m interested in exploring possible weaknesses I&#x2019;ve missed in this theory, so comment with your objections and I&#x2019;ll see if they can be addressed.</p>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
6EvqRrn5MPueavBMD,Internalizing Existentialism,internalizing-existentialism,https://www.lesswrong.com/posts/6EvqRrn5MPueavBMD/internalizing-existentialism,2019-11-18T18:37:18.606Z,11,3,3,False,False,https://mapandterritory.org/internalizing-existentialism-72831ef04735,"<p><em>NB: Originally published on Map and Territory on Medium. This is an old post originally published on 2016-09-18. It was never previously cross-posted or linked on LessWrong, so I&apos;m adding it now for posterity. It&apos;s old enough that I can no longer confidently endorse it, and I won&apos;t bother trying to defend it if you find something wrong, but it might still be interesting.</em></p><p>Over the last couple months, due to reading Daoist philosophical texts, I&#x2019;ve come to deeply internalize something I&#x2019;ve known for a long time: morality doesn&#x2019;t exist &#x201C;out there&#x201D; in reality and is instead a construct of our preferences and the dialectic between different people&#x2019;s preferences.</p><p>If you stumbled upon this and didn&#x2019;t realize morality wasn&#x2019;t essential, well, um, I&#x2019;m not going to try to convince you of that. Probably a not terrible reading recommendation is the <a href=""https://wiki.lesswrong.com/wiki/Metaethics_sequence"">Less Wrong series on metaethics</a>.</p><p>I started down the path to giving up an internal sense of essential morality when meditating on the Daoist position that there is fundamentally no differentiation. For example, <a href=""http://www.yellowbridge.com/onlinelit/daodejing41.php"">chapter 41</a> of the Daodejing <a href=""http://acc6.its.brooklyn.cuny.edu/~phalsall/texts/taote-v3.html"">reads</a> in part:</p><blockquote>Thus it is said:<br>The path into the light seems dark,<br>the path forward seems to go back,<br>the direct path seems long,<br>true power seems weak,<br>true purity seems tarnished,<br>true steadfastness seems changeable,<br>true clarity seems obscure,<br>the greatest are seems unsophisticated,<br>the greatest love seems indifferent,<br>the greatest wisdom seems childish.</blockquote><p>And in chapter 20 we find:</p><blockquote>Stop thinking, and end your problems.<br>What difference between yes and no?<br>What difference between success and failure?<br>Must you value what others value,<br>avoid what others avoid?<br>How ridiculous!</blockquote><p>And in both the texts of Zhuangzi and Liezi we are given multiple stories where beauty and good acts do not lead to happiness and ugliness and wickedness do not hinder virtue. On the surface we are given contradictions, but by looking deeper the contradictions dissolve if we perceive that the dichotomy is false.</p><p>Even speaking of virtue is itself an interesting case. The word used in Chinese, &#x5FB7; or de, means virtue with a moralistic component in normal use just as is found in English, but de also has a meaning of step and shares with virtue&#x2019;s Latin roots in meaning strength or capacity. So even here we find, when it looks as though we are being given moral advice, it only seems that way if we take it to be that: take away the perception of morality and we are given possible steps along the path.</p><p>With this in mind, I set out to experiment with removing my use of moralistic language. We tend to say things are good or bad when really what we mean is that we like them or we don&#x2019;t. And if I want to find out if morality really does not exist as an essential property of the universe, it&#x2019;s worthwhile to try to take it out of my language and see if it comes up missing.</p><p>So I have tried to do this. I try to no longer say things are good or bad, and instead try to say I like or dislike things, or I want more or less of things. And aside from having a hard time breaking the habit of using common phrases that happen to contain &#x201C;good&#x201D; or &#x201C;bad&#x201D; like saying &#x201C;this tastes good&#x201D; to mean &#x201C;I like how this tastes&#x201D;, it&#x2019;s proven very straight forward and thrown into contrast those times when I was projecting my own preferences onto the universe.</p><p>This projection happens through the turn of phrase. If I think what my friend is wearing is ugly and and I say to them &#x201C;that looks bad&#x201D;, I&#x2019;m implicitly suggesting their appearance goes against an external measure of style. But if I say &#x201C;I don&#x2019;t like what you&#x2019;re wearing&#x201D;, I have to be the owner of the preference, and I know it&#x2019;s not living out in the universe apart from me. And if we look deeper, there&#x2019;s no sense in which something can &#x201C;look good&#x201D; if there is no observer to assess the quality, so it seems through language we casually mistake preferences for essences.</p><p>And so I have now more internalized the existential nature of morality I have long intellectually known.</p>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
aQe6HMsqSb7ff7raq,A Foundation for The Multipart Psyche,a-foundation-for-the-multipart-psyche,https://www.lesswrong.com/posts/aQe6HMsqSb7ff7raq/a-foundation-for-the-multipart-psyche,2019-11-18T18:33:20.925Z,7,1,0,False,False,https://mapandterritory.org/a-foundation-for-the-multipart-psyche-79a66292a7a,"<p><em>NB: Originally published on Map and Territory on Medium. This is an old post originally published on 2016-09-14. It was never previously cross-posted or linked on LessWrong, so I&apos;m adding it now for posterity. It&apos;s old enough that I can no longer confidently endorse it, and I won&apos;t bother trying to defend it if you find something wrong, but it might still be interesting.</em></p><p>In a <a href=""http://slatestarcodex.com/2016/09/12/its-bayes-all-the-way-up/"">recent post</a> Scott Alexander gives a review of some recent results in neurobiology that suggest a powerful, unifying set of mechanisms for how information is integrated in the brain. I recommend you read his article and the original research if you can, but I&#x2019;ll summarize it briefly.</p><p>There are various chemicals regulating activity in the brain. There is now evidence that these chemicals act in coordinating an information pump in the brain. Change the chemicals and you change the parameters of the information pump. It seems specifically the information pump in play fits the Bayesian model in that certain chemicals regulate the presentation of prior evidence, others new evidence, and yet others confidence in those evidences.</p><p>What I find compelling is that the model described provides a plausible mechanism by which the theory of a 2-part psyche might work. There are several two-part theories of psyche, that is to say theories of how mental processes are organized. My preferred one is near/far construal theory, but there is also the S1/S2 distinction, the fast/slow distinction, in Chinese philosophy yin and yang, and even the hot/cold blood model from medieval European thought. Each of these acts as a way of classifying thoughts and behaviors along a spectrum between two extremes.</p><p>The interesting thing about the 2-part psyche theories, and why I prefer the near/far distinction, is that they all seem to operate along the same dimension. Near/far uses the metaphor of distance (because it happens we use similar reasoning patterns when working with things that are physically near versus far) to differentiate between things that are heavy on details and light on patterns versus those that are heavy on patterns and light on details. S1/S2 uses basically the same dimension, as does fast/slow, yin/yang, and hot/cold: stuff with lots of details is near, fast, yin, hot, and part of S1 while stuff with less details and stronger patterns are far, slow, yang, cold, and part of S2. This suggests that they are all pointing at the same sort of thing, though in slightly different ways.</p><p>And, as it happens, this is basically the same dimension along with chemicals in the brain seem to affect cognition, balancing between how much to weigh new evidence (details) against prior evidence (patterns). So it seems that we now have a plausible biological basis for the two-part psyche we&#x2019;ve reasoned exists and find useful, whereas before it was just a pattern that worked without strong evidence of a mechanism.</p><h3>The 3-Part&#xA0;Psyche</h3><p>So that takes care of the 2-part psyche, but what about the arguably more popular 3-part psyche model. The 3-part model dates back at least to Aristotle in the West and <a href=""https://srconstantin.wordpress.com/2016/12/16/the-gunas-a-model-for-mental-states/"">the gunas</a> in India, was revitalized by Freud, and has bloomed into various descendent theories in modern psychology such as Internal Family Systems. Each version has different boundaries and explanations, so for simplicity I&#x2019;ll use Freud&#x2019;s well-known terminology.</p><p>Briefly, these theories all see roughly the same three parts in the psyche: the id, the ego, and the superego. The id is the part that acts and responds &#x201C;on instinct&#x201D;, the ego is the part that is &#x201C;rational&#x201D; and integrates the other two, and the superego is the part that operates on &#x201C;moral&#x201D; grounds. These parts are viewed as working in relation to one another, frequently in opposition, with what someone does and thinks arising from their interaction.</p><p>These theories connect with the 2-part psyche model in that near corresponds to aspects of the id and ego and far corresponds to aspects of ego and superego. When we see this kind of correspondence with superposition, it suggests both are mixing up the underlying reality in different ways. We can use this to try to pick apart what&#x2019;s really going on.</p><p>The commonalities of id and ego seem to be an inclusion of details, same as for near. What&#x2019;s different is that ego has a concept of integration with patterns whereas near and id do not.</p><p>The commonalities of ego and superego are just the opposite: inclusion of patterns. Same goes for far. The differences are that ego includes details while far and superego do not.</p><p>I propose from this that if we separate out details and patterns onto separate dimensions we can get a 2-dimensional model that captures both the 2-part and 3-part psyche models and even suggests a 4-part psyche model.</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*2jmzihGBeXPhXrZpOXICCw.png"" class=""draft-image "" style=""width:40%""></figure></span><p>Now the 2-part model corresponds to the line between the more details, less patterns corner of the space and the less details, more patterns corner with near and far as their division down the middle, respectively. This is drawn as a dotted line in the above chart.</p><p>The 3-part models corresponds to 3 of the 4 quadrants formed around the middle of the 2-dimensional space: id is more details with less patterns, ego is more details with more patterns, and superego is more patterns with less details. This also leaves a suspiciously empty 4th quadrant to be part of the psyche with less details and less patterns.</p><p>And, to make things even better, this fits with the biological model Scott summarizes: there are chemicals regulating how much to favor details and how much to favor patterns. Normal thinking and behavior fall in the ego quadrant or at least near the center while mental disorders appear when the chemical regulation of detail and pattern strength are out of their typical balance.</p><p>So for all their faults in the past, maybe our theories of the psyche have been pointing us in the right direction all along, just in a confused way.</p><h3>The 4th&#xA0;Quadrant</h3><p>This still leaves us with the fourth quadrant that&#x2019;s gone unaddressed. Here I&#x2019;ll offer some brief speculation on what it might be before wrapping up.</p><p>Since this theory points to something that will feel qualitatively different to us from the inside the way id, ego, and superego do when both details and patterns are weak, we should go looking for things we consider mental states that don&#x2019;t fit well in the existing 2-part or 3-part models. One immediately comes to mind: dreams.</p><p>Dreams are, among other things, a time when you have low sensory information and seem to have trouble completing patterns. We talk about &#x201C;dream logic&#x201D; because in dreams you can jump between fitting patterns to limited data that often violate the causal narrative we expect to find in our thinking. And dreams seem to incorporate memories, often recent and important memories, in place of outside sensory data. This is by no means a slam dunk, but it does weakly fit the evidence.</p><p>Which is the point on which I wish to end: all of this is based on fairly weak evidence. Although the 2-part and 3-part psyche models are fairly robust, they have always had problems because they readily fall apart upon rigorous inspection and have not had a clear biological basis so are subject to introspection bias. Additionally, my new evidence from Scott is an interpretation of an interpretation of recent findings and stretches well beyond what we can safely conclude.</p><p>At the same time, these ideas are exciting and, I think, worth exploring because they give us a potential model for better understanding human thoughts and behavior. I fully expect this 2-dimensional, 4-part psyche of details and patterns to make wrong predictions, but I&#x2019;m hopeful it makes more right predictions and fewer wrong predictions than either 2-part or 3-part psyche models do. I look forward to testing them and seeing what more we can learn about our messy selves.</p>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
6bCuzJyrzDttQTvmE,In Defense of Kegan,in-defense-of-kegan,https://www.lesswrong.com/posts/6bCuzJyrzDttQTvmE/in-defense-of-kegan,2019-11-18T18:27:37.237Z,13,6,2,False,False,https://mapandterritory.org/in-defense-of-kegan-2ed7ab51b4c8,"<p><em>NB: Originally published on Map and Territory on Medium. This is an old post originally published on 2016-09-10. It was never previously cross-posted or linked on LessWrong, so I&apos;m adding it now for posterity. It&apos;s old enough that I can no longer confidently endorse it, and I won&apos;t bother trying to defend it if you find something wrong, but it might still be interesting.</em></p><p>I find Kegan&#x2019;s model of psychological development extremely useful. Some folks I know disagree on various grounds. These are some accumulated responses to critiques I&#x2019;ve encountered.</p><p>Before we dive into these critiques, though, allow me to attempt a brief introduction to the theory (though this is a tough undertaking, as we&#x2019;ll discuss below). Robert Kegan, later along with Lisa Lahey, put forward a theory of developmental psychology rooted in complexity of meaning making. It is influenced and builds on the work of Piaget, but also Erikson and Kohlberg, who extended developmental psychology to consider the possibility of adult development.</p><p>Kegan&#x2019;s theory focuses on the maximally complex models people can make of the world in near construal mode. Development is along a continuous gradient but with clear &#x201C;levels&#x201D; where a particular kind of complexity is fully available to the thinker. These are classified from 1 to 5 and can be summarized in many ways, though fundamentally they correspond to when a person can form fully-articulable models of things, relationships between things, systems, relationships between systems, and systems of systems (holons), respectively.</p><p>This is an exceedingly dense introduction, though, and I know of no good short explanation. The best resources on the topic remain Kegan&#x2019;s seminal <em>The Evolving Self</em> and his later <em>In Over Our Heads</em> for a more approachable, example-laden presentation.</p><p>The first, and perhaps strongest, critique of Kegan is that it&#x2019;s very hard for anyone to explain it. Kegan begins <em>In Over Our Heads</em> with the story of getting a letter from a student assigned to read <em>The Evolving Self</em>. The student writes that <em>The Evolving Self</em> is full of interesting ideas but gets so frustrated trying to make sense of it that he wants to &#x201C;punch [Kegan] in the teeth&#x201D;.</p><p>Partly this is because of Kegan has a strong literary and classics background, so <em>The Evolving Self</em> is full of very precise language with subtle meanings, many so subtle that Kegan takes multipage digressions to explain them. But <em>In Over Our Heads</em> and his later books written with Lahey and other coauthors use more familiar language and yet still leave people confused.</p><p>The theory seems to defy simple explanation. I&#x2019;ve yet to find one written by Kegan, Lahey, or anyone else that was able to reliably convey in less than 40,000 words a reasonably coherent and complete view of it. As one person I know put it, the theory reads to him as analogous to someone saying there are invisible dragons, undetectable by readily available means, but which you will notice if you devote at least 20 hours to the study of invisible dragons.</p><p>Yet, those of us who have put in the time to &#x201C;see the invisible dragons&#x201D; tend to be pretty excited about the theory. Kegan gives us a way to understand and construct many aspects of human behavior and thought that time and again prove consistent and reflective of reality. So if it works so well, why is it so hard to explain?</p><p>There are a few ways things can be hard to explain. One is that they are unintuitive. Physics is like this: we perceive the world as if it operated the way Aristotle imaged it worked, but it turns out this approximation breaks down at extremes and the quest to find a complete theory forces us to consider ever more exotic phenomena.</p><p>Another way things may be hard to explain is that they&#x2019;re complicated. Machines and living things are like this, with engineers and biologists mostly struggling to make clear what&#x2019;s happening in systems where lots of details matter. A clock might fail if it&#x2019;s missing a tooth on one gear or a frog might die if it&#x2019;s missing a sequence in its DNA, and understanding why is a messy business of picking through tightly interwoven threads of causality.</p><p>But perhaps the most vexing way something can be hard to explain is when it&#x2019;s complex. That is to say, even if it has few details and works in a straightforward manner, thinking through how it works is still hard. Game theory, economics, and most everything touched by mathematics is like this: just a few &#x201C;simple&#x201D; rules lead to bewildering complexity under combination.</p><p>So when trying to explain a theory like Kegan&#x2019;s that has at its heart a developmental progression in human capacity to cope with complexity, it&#x2019;s perhaps unsurprising that the complexity can collapse back in on itself and make the theory look like disjointed rubble. The theory, in fact, predicts this, because it&#x2019;s one about the relationships between systems (i.e. the change in human meaning making over time), so by its own expectations it will prove difficult to gain an intuitive grasp on without the reader having themselves first already attained the capacity to naturally reason about relationships between systems in near construal mode (level 4 in Kegan&#x2019;s model).</p><p>To most people this feels like the theory saying &#x201C;you can&#x2019;t understand it until you already understand it&#x201D;, but there&#x2019;s more going on here. It&#x2019;s instead saying that Kegan&#x2019;s developmental theory belongs to a class of things that cannot be fully understood without the ability to naturally, intuitively work with the relationships between systems. Without that ability it may be understood in other ways, in particular using far construal mode, but that is demanding on the level of learning algebra, calculus, or differential equations, which is to say something that even the brightest among us struggle with.</p><p>But if it&#x2019;s really this hard, why do people feel they can reject Kegan when they can&#x2019;t reject, say, abstract algebra in the same way? They may find they completely lack the capacity to understand what&#x2019;s going on in abstract algebra in near mode, yet aside from a few mathematicians with technical objections, no one thinks abstract algebra fails to model well the parts of reality it is attempting to model whether they understand it or not. At worst it&#x2019;s just some of that &#x201C;math stuff&#x201D; other people worry about but they don&#x2019;t &#x201C;get&#x201D;.</p><p>The difference, as Robin Hanson has observed in the general case, is that Kegan is a theory about stuff we are intimately familiar with: people. We are happy to defer to experts and theories we don&#x2019;t understand on topics we don&#x2019;t feel we have much of a grasp on, like abstract algebra, but as things get progressively more &#x201C;real&#x201D; we feel less inclined to trust complex theories experts put forward that we don&#x2019;t understand ourselves.</p><p>There&#x2019;s a sort of escalating scale of how many people don&#x2019;t trust experts that&#x2019;s a function of distance from lived experience, social agreements on who has expertise, and availability of evidence to check our understanding. Basically everyone trusts experts in math because it&#x2019;s far from lived experience and we agree that mathematicians are the math experts even though we can only easily validate the veracity of the simplest mathematical claims without training.</p><p>Most, but slightly fewer, folks trust experts in physics. People agree that physicists are the experts and have lots of evidence to prove their unintuitive theories are right (planes fly, electricity powers our devices, computers work with no moving parts). The only difficulty for physicists is that we all live physics, so there&#x2019;s a constant battle against violations of intuition they must overcome to convince us of their theories.</p><p>Less trusted still are doctors, economists, and philosophers. Somewhere between economists and philosophers we find anyone attempting to explain human behavior. We all have lots of experience with it, there&#x2019;s lots of evidence around to check against, so the only thing holding up the experts is that we agree their expertise exists because someone gave them an advanced degree in it.</p><p>So in general people feel free to reject arguments about human behavior that don&#x2019;t seem intuitive even if they are provided by experts. It&#x2019;s for the same meta-reason that no one listens to the economists and philosophers have been engaged in the same discussions for millennia: it feels easy to reject what doesn&#x2019;t feel true when it&#x2019;s something we have a lot of experience with and can easily gather data on.</p><p>Is this why folks who find it hard to understand Kegan often choose to reject it? I suspect probably yes, but then again I&#x2019;m asking you to accept my argument about human behavior concerning belief strength in theories people don&#x2019;t fully comprehend and are not expert in, so I&#x2019;ll leave my response to this critique here before I ascend too far up a house of cards.</p><p>So suffice to say, Kegan is complex, complex enough that it&#x2019;s predictably hard to understand, and about a topic where we little trust experts.</p><p>Kegan is sometimes presented as &#x201C;wrong&#x201D; because it&#x2019;s not always accurate. That is to say, because it&#x2019;s a theory that presents a model of the world, it has edge cases at which it seems to break down. This is a standard objection to all models in all domains and is uninteresting, but since there is a high likelihood of confusion due to lack of trust in expertise here, it&#x2019;s worth covering.</p><p>A model is some explanation and prediction of how the world works. For example, atomic theory gives us a way of understanding matter as indivisible (atomic) particles. Like all theories, it&#x2019;s &#x201C;wrong&#x201D; in that reality is not actually made up of atoms&#x200A;&#x2014;&#x200A;it&#x2019;s just reality. Instead atoms are a way of understanding reality that let us explain phenomena we see and predict future phenomena with some degree of accuracy. To the extent that atomic theory predicts what happens in reality, it is useful to the purpose of predicting future events. This doesn&#x2019;t make it &#x201C;right&#x201D;, just predictive enough for our needs.</p><p>When atomic theory fails to make correct predictions it&#x2019;s not &#x201C;wrong&#x201D;. Instead it&#x2019;s that the theory is not complete because it&#x2019;s a model and not reality and the only perfect model of reality is reality itself, just as the only perfect map of the Earth is the Earth itself.</p><p>So Kegan&#x2019;s developmental theory is naturally not a perfect predictor of reality. We can only judge it by how accurate it is for the things we want to use it for. Whether or not it&#x2019;s accurate enough to be useful is what we&#x2019;ll explore in the remaining critiques.</p><p>The remaining two major objections are technical in that they assume an understanding of Kegan and find problems on internal grounds. Feel free to just skip to the end if these are not of interest to you.</p><p>The first problem is that Kegan differentiates expectations of what you can do in near and far mode. I&#x2019;ll note here, though, that Kegan does not explicitly reference construal level theory, dual process theory, or any other two part theory of mind. This is mostly an artifact of its time: Kegan wrote <em>The Evolving Self</em> before these theories were well developed, and instead spends a decent number of words to explain that he&#x2019;s focused on the capacity of intuitive, immediate, natural ratiocination.</p><p>Having lacked a referent to contrast near and far modes, some people naturally object to the theory on the grounds that mathematicians, for example, show incredible capacity to reason about holons in their 20s despite lacking the behavior patterns expected of someone with this capacity. The difference, of course, is that mathematicians do their work in far mode, and are in fact exceptionally talented at thinking in far mode, but because far mode is not used to engage in day-to-day activity because it&#x2019;s too complicated to fit in far mode, that far mode capacity for handling greater complexity does not extend to near mode.</p><p>It&#x2019;s unclear whether capacity to handle complexity in near mode extends to far mode. It seems likely but there&#x2019;s not much data on, for example, people becoming mathematicians in their 50s after struggling with math for the previous 5 decades.</p><p>The second objection is that Kegan is not directly testable because it&#x2019;s a theory about changes in the way of meaning making which is inherently unobservable since it exists only as a dialectic between perception and reality. While it may be true that you can&#x2019;t directly test if the model is how reality is structured, this is a problem for all theories of mind and it has the same solution as they do: you can test the predictions. We can check whether the expected behavior of people at particular Kegan levels correlates with their actual behavior.</p><p>There&#x2019;s unfortunately very little data on this. About the best we have comes from Lahey and her work in applying Kegan&#x2019;s model to education reform and management consulting, and most of the available data I&#x2019;m aware of is collected post level assessment or informally, so it&#x2019;s suspect. I happily concede this is a major issue and would love to see more data collected but consider it unlikely because in the past 30 years the theory has gained little traction, largely it seems due to its complexity, so not enough people are working in the area to generate the needed data to sufficiently test the theory.</p><p>I&#x2019;ve tried to address here the most common objections I&#x2019;ve encountered to Kegan&#x2019;s theory. If there are additional objection categories I&#x2019;ve left out that you notice, feel free to bring them up in the comments, and I&#x2019;ll see if they are tractable problems or tear the whole thing down.</p><p>If reading this has piqued your interest in Kegan&#x2019;s work, I highly recommend reading <em>In Over Our Heads</em> and <em>The Evolving Self</em> in that order. For applications of the theory you can check out Kegan and Lahey&#x2019;s later works and for a philosophical incorporation of Kegan I suggest reading <a href=""https://meaningness.com/"">David Chapman</a>.</p>",gworley,gordon-seidoh-worley,Gordon Seidoh Worley,
SJhsQfdJSxbJzaewq,"Comment, Don't Message",comment-don-t-message,https://www.lesswrong.com/posts/SJhsQfdJSxbJzaewq/comment-don-t-message,2019-11-18T16:00:02.010Z,30,12,5,False,False,,"<p>

Most of the time, when people have responses to my posts they write them as
comments.  Sometimes, however, they email or send messages.  Since I strongly
prefer comments I wanted to write some about why.



</p><p>

A discussion we have in comments will be open to people other than the
two of us.  People who read the post and are thinking along similar
lines can see our back-and-forth.  The comments will be attached to
the post, potentially clarifying things for people who come across the
post later.  If the question comes up again I can link someone to our
discussion of it.  The comments show up in search engines for
unrelated people interested in these ideas.  Since communicating in
public has all these positive externalities, I'm much more willing to
put time and thought into a discussion if it can be public.

</p>

<p>

There are also benefits during the discussion, as other people often
have valuable things to add.  Many times a comment thread has been me
and someone else, and a third person jumps in with an important
consideration that hadn't occurred to either of us.  Other times
someone's comment sparks a thread which brings in perspectives from
many people.  It's not just that our talking in public helps others,
but it helps us too.

</p>

<p>

More selfishly, comments have different expectations around responses.  I read
every comment, but I often don't reply.  Maybe the comment is self contained,
and while it's communicating something important a reply wouldn't add anything.
Maybe I'm not sure how I'd like to respond yet, and then don't end up coming
back to it.  Maybe other people responded and it seems like the important
details have come out already.  Maybe I just don't have time.  With one-on-one
messages, however, the response burden is much higher.  Just writing back
""received and read"" would be hostile, but writing a good response can be a lot
of work.  Sending a message should not generally obligate a reply, but it still
feels rude not to put in the time for a thorough response.

</p>

<p>

There are valid reasons for non-public communication.  Perhaps you're
afraid of how people might respond to revealing details of your
identity or taking an unpopular position.  Perhaps you want to talk
about something that is illegal but generally viewed as ok among your
friends.  Perhaps there are people who follow you around the internet
harassing you.  Perhaps you don't trust yourself to phrase sensitive
issues in a way that doesn't lead to people being mad at you.  This is
not an exhaustive list!  Private messages I've gotten about posts,
however, don't seem to be sent for one of these reasons.  If you're
sending a message privately for a reason, it's helpful if you can say
so.

</p>

<p>

While I don't normally ask for emails in response to posts, this
particular one seems like it should be an exception, so you're welcome
to write me at jeff@jefftk.com.  I'm not committing to reply,
though!

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100122296099472"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
pW6YJEzoRFe9cshuN,Impossible moral problems and moral authority,impossible-moral-problems-and-moral-authority,https://www.lesswrong.com/posts/pW6YJEzoRFe9cshuN/impossible-moral-problems-and-moral-authority,2019-11-18T09:28:28.766Z,22,17,8,False,False,,"<p><em><a href=""https://slatestarcodex.com/2018/09/25/the-tails-coming-apart-as-metaphor-for-life/"">The Tails Come Apart As Metaphor For Life</a>, but with an extra pun.</em></p><p>Suppose you task your friends with designing the Optimal Meal. The meal that maximizes utility, in virtue of its performance at the usual roles food fills for us. We leave aside considerations such as sourcing the ingredients ethically, or writing the code for an FAI on the appetizer in tiny ketchup print, or injecting the lettuce with nanobots that will grant the eater eternal youth, and solely concern ourselves with arranging atoms to get a good meal <em>qua</em> meal.</p><p>So you tell your friends to plan the best meal possible, and they go off and think about it. One comes back and tells you that their optimal meal is like one of those modernist <a href=""https://www.wsj.com/articles/SB10001424052748703786804576138362185210494"">30-course productions</a>, where each dish is a new and exciting adventure. The next comes back and says that their optimal meal is mostly just a big bowl of their <a href=""https://www.bonappetit.com/recipe/beef-and-squash-chili"">favorite beef stew</a>, with some fresh bread and vegetables.</p><p>To you, both of these meals seem good - certainly better than what you've eaten recently. But then you start worrying that if this meal is important, then the difference in utility between the two proposed meals might be large, even though they're both better than the status quo (say, cold pizza). In a phrase, <a href=""https://wiki.lesswrong.com/wiki/Astronomical_waste"">gastronomical waste</a>. But then how do you deal with the fact that different people have chosen different meals? Do you just have to choose one yourself? </p><p>Now your focus turns inward, and you discover a horrifying fact. You're not sure which meal you think is better. You, as a human, don't have a utility function written down anywhere, you just make decisions and have emotions. And as you turn these meals over in your mind, you realize that different contexts, different fleeting thoughts or feelings, different ways of phrasing the question, or even just what side of the bed you got up on that morning, might influence you to choose a different meal at a point of decision, or rate a meal differently during or after the fact.</p><p>You contain within yourself the ability to justify either choice, which is remarkably like being unable justify either choice. This ""Optimal Meal"" was a boondoggle all along. Although you can tell that either would be better than going home and eating cold pizza, there was never any guarantee that your ""better"" was a<a href=""https://eli.thegreenplace.net/2018/partial-and-total-orders/""> total ordering </a>of meals, not merely a <a href=""https://eli.thegreenplace.net/2018/partial-and-total-orders/"">partial ordering</a>.</p><p>Then, disaster truly strikes. Your best friend asks you ""So, what do you want to eat?""</p><br><span><figure><img src=""https://i.imgur.com/u57pM2w.png"" class=""draft-image center"" style=""width:40%""></figure></span><br><p>You feel trapped. You can't decide. So you call your mom. You describe to her these possible meals, and she listens to you and makes sympathetic noises and asks you about the rest of your day. And you tell her that you're having trouble choosing and would like her help, and so she thinks for a bit, and then she tells you that maybe you should try the modernist 30-course meal.</p><p>Then you and your friends go off to the Modernism Bistro, and you have a wonderful time.</p><hr class=""dividerBlock""><p>This is a parable about how choosing the Optimal Arrangement Of All Atoms In The Universe is an impossible moral problem. Accepting this as a given, what kind of thing is happening when we accept the decision of some authority (superhuman AI or otherwise) as to what should be done with those atoms?</p><p>When you were trying to choose what to eat, there was no uniquely right choice, but you still had to make a choice anyhow. If some moral authority (e.g. your mom) makes a sincere effort to deliberate on a difficult problem, this gives you an option that you can accept as ""good enough,"" rather than ""a waste of unknowable proportions.""</p><p>How would an AI acquire this moral authority stuff? In the case of humans, we can get moral authority by:</p><ul><li>Taking on the social role of the leader and organizer</li><li>Getting an endorsement or title from a trusted authority</li><li>Being the most knowledgeable or skilled at evaluating a certain problem</li><li>Establishing personal relationships with those asked to trust us</li><li>Having a track record of decisions that look good in hindsight</li><li>Being charismatic and persuasive</li></ul><p>You might think ""Of course we shouldn't trust an AI just because it's persuasive."" But in an important sense, <em>none</em> of these reasons is good enough. We're talking about trusting something as an authority on an impossible problem, here.</p><p>A good track record on easier problems is a necessary condition to even be thinking about the right question, true. I'm not advocating that we fatalistically accept some random nonsense as the meaning of life. The point is that even after we try our hardest, we (or an AI making the choice for us) will be left in the situation of trying to decide between Optimal Meals, and narrowing this choice down to one option shouldn't be thought of as a continuation of the process that generated those options.</p><p>If after dinner, you called your mom back and said ""That meal was amazing - but how did you figure out that was what I really wanted?"", you would be misunderstanding what happened. Your mom didn't solve <a href=""https://www.lesswrong.com/posts/DsEuRrsenZ6piGpE6/humans-aren-t-agents-what-then-for-value-learning"">the problem of underdetermination of human values</a>, she just took what she knew of you and made a choice - an ordinary, contingent choice. Her role was never to figure out what you ""really wanted,"" it was to be an authority whose choice you and your friends could accept.</p><p>So there are two acts of trust that I'm thinking about this week. The first is how to frame friendly AI as a trusted authority rather than an oracle telling us the one best way to arrange all the atoms. And the second is how a friendly AI should trust its own decision-making process when it does meta-ethical reasoning, without assuming that it's doing what humans uniquely want.</p>",Charlie Steiner,charlie-steiner,Charlie Steiner,
sEnbSj9PaJbnLc2Eh,The Power to Draw Better,the-power-to-draw-better,https://www.lesswrong.com/posts/sEnbSj9PaJbnLc2Eh/the-power-to-draw-better,2019-11-18T03:06:02.832Z,40,19,7,False,False,,"<p><strong>This is Part X of the <a href=""https://www.lesswrong.com/posts/XosKB3mkvmXMZ3fBQ/specificity-your-brain-s-superpower"">Specificity Sequence</a></strong></p><p>Cats notoriously get stuck in trees because their claws are better at climbing up than down. Throughout this sequence, we&#x2019;ve seen how humans are similar: We get stuck in high-level abstractions because our brains struggle to unpack them into specifics. Our brains are better at climbing up (concrete&#x2192;abstract) than down (abstract&#x2192;concrete).</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*BbKHPlmqUZ69wVZ0PTrjsg.png"" class=""draft-image center"" style=""width:62%""></figure></span><p>If you&#x2019;ve ever struggled to draw a decent picture, you know what being stuck at a high level of abstraction feels like in the domain of visual processing. I know I do. My drawing skills are nonexistent. I can draw kindergarten-quality stick figures, but I don&#x2019;t even know where to begin drawing something that looks the least bit realistic.</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*S0xewXTigi-WzPqtJKAbLA.png"" class=""draft-image "" style=""width:100%""></figure></span><p>Despite how pathetic a stick figure looks, it&#x2019;s worth marveling at our brain&#x2019;s formidable power to distill a mess of light and dark stimuli into a few geometric parts.</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*VSif7lqdUfrsbTjuryaTBg.png"" class=""draft-image "" style=""width:100%""></figure></span><p>A stick figure is a mental representation of an animal which is great for practical tasks like throwing a spear at it.</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*gOEw8iakj1x5LbonKQcmJw.png"" class=""draft-image "" style=""width:100%""></figure></span><p>The question is just, why can people like me only draw a pathetic stick figure even when we&#x2019;re trying to draw a nice picture?</p><p>The visual system was only under selective pressure to evolve a processing pathway from sensing visual features to building an abstract representation of those features, not a processing pathway to transform a high-level mental representation into a low-level pencil strokes representation. I draw stick figures because my conscious mind thinks in stick figures.</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*TwRZwyD-hDALWdfh_lfwHw.png"" class=""draft-image "" style=""width:100%""></figure></span><p>But we know that the <em>unconscious</em> part of our visual brains isn&#x2019;t one-way. When we first recognize that we&#x2019;re seeing a cow, our brain propagates visual information from abstract mental representations down toward lower-level visual feature recognition.</p><p>&#xA0;Consider this image:</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/0*QorVQlWRxVxYbqb5"" class=""draft-image center"" style=""width:100%""></figure></span><p>Most people have trouble identifying what they&#x2019;re seeing in different parts of the image, until they realize it&#x2019;s a cow, and then all the parts snap into focus. Their interpretation of low-level features of the image, e.g. that the white dots within the black foreground region on the leftmost part of the image are &#x201C;furry&#x201D;, is influenced top-down by their abstract mental representation of a cow.</p><p>How do skilled artists navigate down the ladder of visual abstraction consciously?</p><p>In <em><a href=""https://www.drawright.com/"">Drawing on the Right Side of the Brain</a></em>, Betty Edwards teaches students to accurately sketch the scene coming into their eyes through a clever upside-down drawing technique. The technique bypasses the part of the brain that would normally abstract visual input:</p><blockquote>When presented with an upside-down image as a subject to be drawn, the left-hemisphere&#x2019;s verbal system [the abstracting mechanism] says, in effect, &#x201C;I don&#x2019;t do upside down. It&#x2019;s too hard to name the parts, and things are hardly ever upside-down in the world. It&#x2019;s not useful, and if you are going to do that, I&#x2019;m out of here.&#x201D; The dominant verbal system &#x201C;bows out,&#x201D; and the sub-dominant visual mode is &#x201C;allowed&#x201D; to take on the task for which it is well suited.</blockquote><p>Upside-down drawing helps draw the brain&#x2019;s attention to what Edwards calls the <a href=""https://www.drawright.com/theory"">&#x201C;component skills of drawing&#x201D;</a>. These include edges, negative spaces, proportions, lights and shadows. For example, your brain&#x2019;s high-level abstract representation might tell you that the boundary of an object is horizontal, but a lower-level examination of what your eye is seeing will contradict that, leading you to represent the boundary by drawing a slanted line on the page.</p><p>&#x201C;Drawing on the right side of the brain&#x201D; means drawing using mid-level representations of visual inputs, rather than the fully abstract ones we rely on for other activities.</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*ncuvETERbTzoM-rZX9njeg.png"" class=""draft-image "" style=""width:100%""></figure></span><p>Edwards has an online <a href=""https://www.drawright.com/before-after"">gallery</a> of her students&#x2019; self-portraits before and after taking her class. This one stopped me in my tracks:</p><span><figure><img src=""https://cdn-images-1.medium.com/max/1600/1*GMwZqiYjHrgyLWq14GvYyQ.png"" class=""draft-image "" style=""width:100%""></figure></span><p>Staring at the &#x201C;after&#x201D; drawing feels like I&#x2019;m witnessing the first time the artist finally <em>saw</em> her own face, and wanted to communicate the joy and beauty of what she saw by accentuating it for the rest of us. I&#x2019;ve bought a copy of Edwards&#x2019;s book because I hope to try out her techniques and rewire my brain to experience my own visual revelation.</p><p>It&#x2019;s clearly <em>possible</em> to draw detailed realistic pictures. Great artists can do it. A $5 camera can do it. The interesting takeaway for our purposes is that drawing realistic pictures means developing the skill of moving in the abstract&#x2192;concrete direction, against the grain of normal conscious thought.</p><p><strong>Next post:</strong> The Power to Be Creative (coming soonish)</p>",Liron,liron,Liron,
9B6mzREsG4untmSrW,Cambridge LW/SSC Meetup,cambridge-lw-ssc-meetup-5,https://www.lesswrong.com/events/9B6mzREsG4untmSrW/cambridge-lw-ssc-meetup-5,2019-11-18T02:51:29.797Z,7,2,0,False,False,,"<p>This is the monthly Cambridge, MA Less Wrong / Slate Star Codex meetup.</p>",AspiringRationalist,nosignalnonoise,NoSignalNoNoise,
y9dKJ5SMQwLatHM5o,Do we know if spaced repetition can be used with randomized content?,do-we-know-if-spaced-repetition-can-be-used-with-randomized,https://www.lesswrong.com/posts/y9dKJ5SMQwLatHM5o/do-we-know-if-spaced-repetition-can-be-used-with-randomized,2019-11-17T18:01:54.337Z,10,5,5,False,False,,"<p>Disclaimer: there may be major flaws in the way I use words. <a href=""https://wiki.lesswrong.com/wiki/Crocker%27s_rules"">Corrections are welcome.</a></p>
<hr>
<p>Suppose I want to memorize all the <a href=""https://en.wikipedia.org/wiki/Software_design_pattern"">software design patterns</a>.</p>
<p>I could use <a href=""https://en.wikipedia.org/wiki/Spaced_repetition"">spaced repetition</a> and create a new deck of flashcards. Each card would have the name of the pattern on one side and the definition on the other.</p>
<p>This would help me understand references to patterns without opening Wikipedia every time. This would <em>probably</em> help me recognize patterns by descriptions, as long as they're close enough to the definitions.<br>
But this wouldn't help me recognize patterns just by looking at their implementations. I'd have to actively think about each pattern I remember and compare the definition and the code.</p>
<p>I could create a second deck, with names and examples. But then I'd just memorize those specific examples and <em>maybe</em> get better at recognizing similar ones.</p>
<p>This problem is similar to that of testing software. (There must be a more straightforward analogy, but I couldn't find one.) Individual tests can only prevent individual errors. Formal verification is better, but not always possible. The next best thing is <a href=""https://en.wikipedia.org/wiki/Fuzzing"">fuzzing</a>: using random inputs and heuristics like ""did it crash?"".</p>
<p>So I wonder if I could generate new examples on the fly. (More realistically, pull hand-labeled examples from a database.)</p>
<p>The idea is that a skill like recognizing a pattern in the code should also be a form of memory. Or at least the parts of it that do not change between the examples. So using spaced repetition with randomized examples would be like <a href=""https://en.wikipedia.org/wiki/Just-in-time_compilation"">JIT-compilation</a> in brains.</p>
<p>There was an LW post about genetic programming working better when the environment was modular. Maybe something similar would happen here.</p>
<p>But I couldn't find anything on the internet. Has anybody seen any research on this?</p>
",Kinrany,kinrany-1,Kinrany,
yXikQ87FFw3oPPaYh,How common is it for one entity to have a 3+ year technological lead on its nearest competitor?,how-common-is-it-for-one-entity-to-have-a-3-year,https://www.lesswrong.com/posts/yXikQ87FFw3oPPaYh/how-common-is-it-for-one-entity-to-have-a-3-year,2019-11-17T15:23:36.913Z,49,15,20,False,True,,"<p>I'm writing a follow-up to my <a href=""https://www.lesswrong.com/posts/PKy8NuNPknenkDY74/soft-takeoff-can-still-lead-to-decisive-strategic-advantage"">blog post on soft takeoff and DSA</a>, and I am looking for good examples of tech companies or academic research projects that are ~3+ years ahead of their nearest competitors in the technology(ies) they are focusing on.</p><p>Exception: I'm not that interested in projects that are pursuing some niche technology, such that no one else wants to compete with them. Also: I'm especially interested in examples that are analogous to AGI in some way, e.g. because they deal with present-day AI or because they have a feedback loop effect.</p><p>Even better would be someone with expertise on the area being able to answer the title question directly. Best of all would be some solid statistics on the matter. Thanks in advance!</p>",daniel-kokotajlo,daniel-kokotajlo,Daniel Kokotajlo,
qkvk22oc3YeEJpEfC,AGI safety and losing electricity/industry resilience cost-effectiveness,agi-safety-and-losing-electricity-industry-resilience-cost,https://www.lesswrong.com/posts/qkvk22oc3YeEJpEfC/agi-safety-and-losing-electricity-industry-resilience-cost,2019-11-17T06:48:34.063Z,10,8,2,False,False,,"<p>Cross posted on Effective Altruism Forum   <a href=""https://forum.effectivealtruism.org/posts/XA8QSCL7wZ973i6vr/agi-safety-and-losing-electricity-industry-resilience-cost"">https://forum.effectivealtruism.org/posts/XA8QSCL7wZ973i6vr/agi-safety-and-losing-electricity-industry-resilience-cost</a> </p><p>Below is a paper about to be submitted. The focus is on<a href=""https://forum.effectivealtruism.org/posts/7xveJ9MAJysLWnZZP/david-denkenberger-loss-of-industrial-civilization-and""> <u>interventions</u></a> that could improve the long-term outcome given catastrophes that disrupt electricity/industry, such as solar storm, high-altitude electromagnetic pulse (HEMP), narrow AI computer virus, and extreme pandemic. Work on these interventions is even more neglected than interventions for<a href=""https://forum.effectivealtruism.org/posts/CcNY4MrT5QstNh4r7/cost-effectiveness-of-foods-for-global-catastrophes-even""> <u>feeding everyone if the sun is blocked</u></a>. Cost-effectiveness is compared to a modified AGI safety cost-effectiveness<a href=""https://forum.effectivealtruism.org/posts/NbFZ9yewJHoicpkBr/a-model-of-the-machine-intelligence-research-institute""> <u>model</u></a> posted earlier on the EA forum. Two different cost-effectiveness estimates for losing industry interventions were developed: one by Denkenberger and a poll at EA Global San Francisco 2018, and the other by Anders Sandberg at Future of Humanity Institute. There is great uncertainty in both AGI safety and interventions for losing industry. However,  the models have ~99% confidence that funding interventions for losing industry now is more cost effective than additional funding for AGI safety beyond ~$3 billion. This does not take into account model or theory uncertainty, so the confidence would likely decrease. However, in order to make AGI safety more cost effective, this required changing four variables in the Sandberg model to the 5th percentile on the pessimistic end simultaneously. For the other model, it required changing seven variables. Therefore, it is quite robust that a significant amount of money should be invested in losing industry interventions now. There is closer to 50%-88% confidence that spending the ~$40 million on interventions for losing industry is more cost effective than AGI safety. Overall, AGI safety is more important and more total money should be spent on it. The modeling concludes that additional funding would be justified on both causes even for the present generation.</p><br><h2><strong>Long Term Cost-Effectiveness of Interventions for Loss of Electricity/Industry Compared to Artificial General Intelligence Safety</strong></h2><p>David Denkenberger 1,2, Anders Sandberg 3, Ross Tieman *1, and Joshua M. Pearce 4,5</p><p>1. Alliance to Feed the Earth in Disasters (ALLFED), Fairbanks, AK 99775, USA</p><p>2. University of Alaska Fairbanks, Fairbanks, AK 99775, USA</p><p>3. Future of Humanity Institute, University of Oxford, Oxford, UK</p><p>4. Department of Material Science and Engineering and Department of Electrical and Computer Engineering, Michigan Technological University, Houghton, MI 49931, USA</p><p>5. Department of Electronics and Nanoengineering, School of Electrical Engineering, Aalto University, FI-00076 Espoo, Finland</p><p>* corresponding author</p><br><p><em>Abstract</em> </p><p>Extreme solar storms, high-altitude electromagnetic pulses, and coordinated cyber attacks could disrupt regional/global electricity. Since electricity basically drives industry, industrial civilization could collapse without it. This could cause anthropological civilization (cities) to collapse, from which humanity might not recover, having long-term consequences. Previous work analyzed technical solutions to save nearly everyone despite industrial loss globally, including transition to animals powering farming and transportation. The present work estimates cost-effectiveness for the long-term future with a Monte Carlo (probabilistic) model. Model 1, partly based on a poll of Effective Altruism conference participants, finds a confidence that industrial loss preparation is more cost effective than artificial general intelligence safety of ~88% and ~99+% for the 30 millionth dollar spent on industrial loss interventions and the margin now, respectively. Model 2 populated by one of the authors produces ~50% and ~99% confidence, respectively. These confidences are likely to be reduced by model and theory uncertainty, but the conclusion of industrial loss interventions being more cost effective was robust to changing the most important 4-7 variables simultaneously to their pessimistic ends. Both cause areas save expected lives cheaply in the present generation and funding to preparation for industrial loss is particularly urgent.</p><p>Disclaimer/Acknowledgements: Funding was received from the Centre for Effective Altruism. Anders Sandberg received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No 669751). The Oxford Prioritisation Project developed the artificial general intelligence safety cost effectiveness submodel. Owen Cotton-Barratt, Daniel Dewey, Sindy Li, Ozzie Gooen, Tim Fist, Aron Mill, Kyle Alvarado, Ratheka Stormbjorne, and Finan Adamson contributed helpful discussions. This is not the official position of the Centre for Effective Altruism, the Future of Humanity Institute, nor the<a href=""http://allfed.info/""> </a>Alliance to Feed the Earth in Disasters (ALLFED).</p><p><strong>1. Introduction</strong></p><p>The integrated nature of the electric grid, which is based on centralized generation makes the entire system vulnerable to disruption.(1) There are a number of anthropogenic and natural catastrophes that could result in regional-scale electrical grid failure, which would be expected to halt the majority of industries and machines in that area. A high-altitude electromagnetic pulse (HEMP) caused by a nuclear weapon could disable electricity over part of a continent <a href=""https://www.zotero.org/google-docs/?RQ7abv"">(Bernstein, Bienstock, Hay, Uzunoglu, &amp; Zussman, 2012; Foster et al., 2004; Kelly-Detwiler, 2014; Oak Ridge National Laboratory, 2010)</a>. This could destroy the majority of electrical grid infrastructure, and as fossil fuel extraction and industry is reliant on electricity <a href=""https://www.zotero.org/google-docs/?VWC4PU"">(Foster, Jr et al., 2008)</a>, industry would be disabled. Similarly, solar storms have destroyed electrical transformers connected to long transmission lines in the past <a href=""https://www.zotero.org/google-docs/?xzild7"">(Space Studies Board, 2008)</a>. The Carrington event in 1859 damaged telegraph lines, which was the only electrical infrastructure in existence at the time. It also caused Aurora Borealis that was visible in Cuba and Jamaica <a href=""https://www.zotero.org/google-docs/?7RKwTa"">(Klein, 2012)</a>. This could potentially disable electrical systems at high latitudes, which could represent 10% of electricity/industry globally. Though solar storms may last less than the 12 hours that would be required to expose the entire earth with direct line of sight, the earth's magnetic field lines redirect the storm to affect the opposite side of the earth <a href=""https://www.zotero.org/google-docs/?loH09A"">(Space Studies Board, 2008)</a>. </p><p>Lastly, both physical <a href=""https://www.zotero.org/google-docs/?fQo1U5"">(M. Amin, 2002, 2005; Kinney, Crucitti, Albert, &amp; Latora, 2005; Motter &amp; Lai, 2002; Salmeron, Wood, &amp; Baldick, 2004)</a> and cyber attacks <a href=""https://www.zotero.org/google-docs/?DYrlSA"">(Aitel, 2013; Hébert, 2013; Nai Fovino, Guidi, Masera, &amp; Stefanini, 2011; Onyeji, Bazilian, &amp; Bronk, 2014; Sridhar, Hahn, &amp; Govindarasu, 2012; Umbach, 2013; Watts, 2003)</a> could also compromise electric grids. Physical attacks include traditional acts of terrorism such as bombing or sabotage <a href=""https://www.zotero.org/google-docs/?puxT7E"">(Watts, 2003)</a> in addition to EMP attacks. Significant actors could scale up physical attacks, for example by using drones. A scenario could include terrorist groups hindering individual power plants <a href=""https://www.zotero.org/google-docs/?iI2egj"">(Tzezana, 2016)</a>, while a large adversary could undertake a similar operation physically to all plants and electrical grids in a region.</p><p>Unfortunately, the traditional power grid infrastructure is simply incapable of withstanding intentional physical attacks <a href=""https://www.zotero.org/google-docs/?oOgwNC"">(National Research Council, 2012)</a>. Damage to the electric grid resulting in physical attack could be long lasting, as most traditional power plants operate with large transformers that are difficult to move and source. Custom rebuilt transformers require time for replacement ranging from months and even up to years <a href=""https://www.zotero.org/google-docs/?Cp2zOK"">(National Research Council, 2012)</a>. For example, a relatively mild 2013 sniper attack on California’s Pacific Gas and Electric (PG&amp;E) substation, which injured no one directly, was able to disable 17 transformers supplying power to Silicon Valley. Repairs and improvements cost PG&amp;E roughly $100 million and lasted about a month <a href=""https://www.zotero.org/google-docs/?Uu1ard"">(Avalos, 2014; Pagliery, 2015)</a>. A coordinated attack with relatively simple technology (e.g. guns) could cause a regional electricity disruption. </p><p>However, a high-tech attack could be even further widespread. The Pentagon reports spending roughly $100 million to repair cyber-related damages to the electric grid in 2009 <a href=""https://www.zotero.org/google-docs/?Zljk4e"">(Gorman, 2009)</a>. There is also evidence that a computer virus caused an electrical outage in the Ukraine <a href=""https://www.zotero.org/google-docs/?LHBvSb"">(Goodin, 2016)</a>. Unlike simplistic physical attacks, cyber attackers are capable of penetrating critical electric infrastructure from remote regions of the world, needing only communication pathways (e.g. the Internet or infected memory sticks) to install malware into the control systems of the electric power grid. For example, Stuxnet was a computer worm that destroyed Iranian centrifuges <a href=""https://www.zotero.org/google-docs/?lhpbud"">(Kushner, 2013)</a> to disable their nuclear industry. Many efforts are underway to harden the grid from such attack <a href=""https://www.zotero.org/google-docs/?0nrgAV"">(Gent &amp; Costantini, 2003; Hébert, 2013)</a>. The U.S. Department of Homeland Security responded to ~200 cyber incidents in 2012 and 41% involved the electrical grid <a href=""https://www.zotero.org/google-docs/?qSZB5T"">(Prehoda, Schelly, &amp; Pearce, 2017)</a>. Nations routinely have made attempts to map current critical infrastructure for future navigation and control of the U.S. electrical system <a href=""https://www.zotero.org/google-docs/?CSLCJw"">(Gorman, 2009)</a>. </p><p>The electric grid in general is growing increasingly dependent upon the Internet and other network connections for data communication and monitoring systems <a href=""https://www.zotero.org/google-docs/?gcKNxb"">(Bessani, Sousa, Correia, Neves, &amp; Verissimo, 2008; Schainker, Douglas, &amp; Kropp, 2006; Sridhar et al., 2012; Ulieru, 2007; Wu, Moslehi, &amp; Bose, 2005)</a>. Although this conveniently allows electrical suppliers management of systems, it increases the susceptibility of the grid to cyber-attack, through denial of webpage services to consumers, disruption to supervisory control and data acquisition (SCADA) operating systems, or sustained widespread power outages <a href=""https://www.zotero.org/google-docs/?2RAcP2"">(Aitel, 2013; Krotofil, Cardenas, Larsen, &amp; Gollmann, 2014; Sridhar et al., 2012; Ten, Manimaran, &amp; Liu, 2010)</a>. Thus global or regional loss of the Internet could have similar implications. </p><p>A less obvious potential cause is a pandemic that disrupts global trade. Countries may ban trade for fear of the disease entering their country, but many countries are dependent on imports for the functioning of their industry. If the region over which electricity is disrupted had significant agricultural production, the catastrophe could be accompanied by a ~10% food production shortfall as well. It is uncertain whether countries outside the affected region would help the affected countries, do nothing, or conquer the affected countries.</p><p>Larger versions of these catastrophes could disrupt electricity/industry globally. For instance, it is possible that multiple HEMPs could be detonated around the world, due to a world nuclear war <a href=""https://www.zotero.org/google-docs/?dggdZm"">(Pry, 2017)</a> or due to terrorists gaining control of nuclear weapons. There is evidence that, in the last 2000 years, two solar storms occurred that were much stronger than the Carrington event <a href=""https://www.zotero.org/google-docs/?thv5SG"">(Mekhaldi et al., 2015)</a>. Therefore, it is possible that an extreme solar storm could disable electricity and therefore industry globally. It is conceivable that a coordinated cyber or physical attack (or a combination) on many electric grids could also disrupt industry globally. Many of the techniques to harden the electric grid could help with this vulnerability as well as moving to more distributed generation and microgrids <a href=""https://www.zotero.org/google-docs/?ljgHuJ"">(Che &amp; Shahidehpour, 2014; Colson, Nehrir, &amp; Gunderson, 2011; Lasseter, 2007; Lasseter &amp; Piagi, 2004; Prehoda et al., 2017; Shahidehpour &amp; Khodayar, 2013)</a>. An extreme pandemic could cause enough people to not show up to work such that industrial functioning could not be maintained. Though this could be mitigated by directing military personnel to fill vacant positions, if the pandemic were severe enough, it could be rational to retreat from high human contact industrial civilization in order to limit disease mortality.</p><p>The global loss of electricity could even be self-inflicted as a way of stopping rogue artificial general intelligence (AGI) <a href=""https://www.zotero.org/google-docs/?A2jhlj"">(Turchin &amp; Denkenberger, 2018a)</a>. As the current high agricultural productivity depends on industry (e.g. for fertilizers) it has been assumed that there would be mass starvation in these scenarios <a href=""https://www.zotero.org/google-docs/?GO3VI3"">(Robinson, 2007)</a>.</p><p>Repairing these systems and re-establishing electrical infrastructure would be a goal of the long term and work should ideally start on it immediately after a catastrophe. However, human needs would need to be met immediately (and continually) and since there is only a few months of stored food, it would likely run out before industry is restored with the current state of preparedness. In some of the less challenging scenarios, it may be possible to continue running some machines on the fossil fuels that had previously been brought to the surface or from the use microgrids or shielded electrical systems. In addition, it may be feasible to run some machines on gasified wood <a href=""https://www.zotero.org/google-docs/?HT45dK"">(Dartnell, 2014)</a>. However, in the worst-case scenario, all unshielded electronics would be destroyed.</p><p>Here we focus on catastrophes that only disrupt electricity/industry, rather than catastrophes that could disable industry and obscure the sun <a href=""https://www.zotero.org/google-docs/?jlYpyF"">(Cole, Denkenberger, Griswold, Abdelkhaliq, &amp; Pearce, 2016)</a> or catastrophes that only obscure the sun (or affect crops directly in other ways) <a href=""https://www.zotero.org/google-docs/?yWQ9Rf"">( Denkenberger &amp; Pearce, 2015b)</a>. This paper analyzes the cost effectiveness of interventions from a long term perspective. First, this study will review interventions to both avoid a loss of electricity, but also to feed everyone with this loss. Then the benefits of artificial general intelligence (AGI) safety on the long term future will be reviewed and quantified. Next, two loss of industry interventions submodels are developed. The cost for an intervention based on alternative food communication is estimated.</p><p><strong>2. Background</strong></p><p><strong>2.1 Review of Potential Solutions </strong></p><p>An obvious intervention for HEMP is preventing a nuclear exchange, which would be the best outcome. However, it is not neglected, as it has been worked on for many decades <a href=""https://www.zotero.org/google-docs/?skxrhA"">(Barrett, Baum, &amp; Hostetler, 2013; D. C. Denkenberger &amp; Pearce, 2018; Helfand, 2013; McIntyre, 2016a; Turchin &amp; Denkenberger, 2018b)</a> and is currently funded at billions of dollars per year quality adjusted <a href=""https://www.zotero.org/google-docs/?ATD13F"">(McIntyre, 2016b)</a>. Other obvious interventions for HEMP that would also work for solar storms, and coordinated physical or cyber threats would be hardening the electrical grid against these threats. However, hardening just the U.S. electrical grid against solar storm and HEMP would cost roughly $20 billion <a href=""https://www.zotero.org/google-docs/?08uq3b"">(Pry, 2014)</a>. Therefore globally, just from these two threats it would be around $100 billion. Furthermore, adding hardening to cyber threats would be even more expensive. Again, preventing the collapse of electricity/industry would be the preferable option, but given the high cost, it may not happen. Even if it occurs eventually, it would still be preferable to have a backup plan in the near term and in the case that hardening is unsuccessful at stopping loss of industry.</p><p>A significant problem in loss of industry catastrophes is that of food supply <a href=""https://www.zotero.org/google-docs/?zAtmEW"">(Cole et al., 2016)</a>. One intervention is storing years worth of food, but it is too expensive to have competitive cost effectiveness (and it would take many years so it would not protect humanity right away, and it would exacerbate current malnutrition) <a href=""https://www.zotero.org/google-docs/?nMnWaQ"">(Baum, Denkenberger, &amp; Pearce, 2016)</a>. Furthermore, if electricity/industry is disabled for many years, food storage would be impractical. Stockpiling of industrial goods could be another intervention, but again it would be much more expensive than the interventions considered here.</p><p>Interventions for food production given the loss of industry include burning wood from landfills to provide fertilizer and high use of nitrogen fixing crops including legumes (peas, beans, peanuts, etc.) <a href=""https://www.zotero.org/google-docs/?YPT6EH"">(Cole et al., 2016)</a>. Also, nonindustrial pest control could be used. Despite pre-industrial agricultural productivity (~1.3 dry tons per hectare per year) <a href=""https://www.zotero.org/google-docs/?z3QLJD"">(Cole et al., 2016)</a>, this could feed everyone globally. However, not everyone would be nearby the food sources, and losing industry would severely hamper transportation capability. Solutions for this problem include backup plans for producing more food locally, including expanding planted area (while minimizing impact to biodiversity e.g. by expanding into the boreal forest/tundra enhanced by the nutrients from tree decomposition/combustion) and favoring high calorie per hectare foods such as potatoes, yams, sweet potatoes, lentils, and groundnuts <a href=""https://www.zotero.org/google-docs/?3ZcIpq"">(Oke, Redhead, &amp; Hussain, 1990)</a>. Though clearing large areas of forest with hand saws would not be practical, it is possible to girdle the trees (remove a strip of bark around the circumference), let the trees dry out, and burn them. This has the advantage of releasing fertilizer to the soils. Another option involves producing “alternative foods,” which were proposed for sun-blocking catastrophes <a href=""https://www.zotero.org/google-docs/?Heg3AH"">(D. Denkenberger &amp; Pearce, 2014)</a>. Some of these alternative foods would require industry, but producing non-industrial lower cost ones such as extracting calories from leaves <a href=""https://www.zotero.org/google-docs/?7BmegD"">(D. Denkenberger, Pearce, Taylor, &amp; Black, 2019)</a> could be feasible. For transporting the food and other goods, ships could be modified to be wind powered and animals could pull vehicles <a href=""https://www.zotero.org/google-docs/?IElknx"">(Abdelkhaliq, Denkenberger, Griswold, Cole, &amp; Pearce, 2016)</a>. A global network of shortwave radio transmitters and receivers would facilitate disseminating the message that there is a plan and people need not panic, and also allow for continuing coordination globally (see below).</p><p>Current awareness of interventions given loss of electricity/industry (hereafter “interventions”) is very low, likely in the thousands of people. Also, many of the interventions are theoretical only and need to be tested experimentally. There may be a significant amount of shortwave radio systems that are shielded from HEMP and have shielded backup power systems, but likely some addition to this capacity would be beneficial. This paper analyzes the cost effectiveness of interventions from a long term perspective. It is unlikely that the loss of industry would directly cause human extinction. However, by definition, there would be a loss of industrial civilization for the global catastrophes. Furthermore, there could be a loss of anthropological civilization (basically cities or cooperation outside the clan). One definition of the collapse of civilization involves short-term focus, loss of long distance trade, widespread conflict, and collapse of government <a href=""https://www.zotero.org/google-docs/?aEychc"">(Coates, 2009)</a>. Reasons that civilization might not recover include: i) easily accessible fossil fuels and minerals are exhausted <a href=""https://www.zotero.org/google-docs/?0T8WjN"">(Motesharrei, Rivas, &amp; Kalnay, 2014)</a> (though there would be minerals in landfills), ii) the future climate might not be as stable as it has been for the last 10,000 years <a href=""https://www.zotero.org/google-docs/?in4lMw"">(Gregory et al., 2007)</a>, or iii) technological and economic data and information might be lost permanently because of the trauma and genetic selection of the catastrophe <a href=""https://www.zotero.org/google-docs/?BC93qX"">(Bostrom, 2013)</a>. If the loss of civilization were prolonged, a natural catastrophe, such as a super volcanic eruption or an asteroid/comet impact, could cause the extinction of humanity. Another way to far future impact is the trauma associated with the catastrophe making future catastrophes more likely, e.g. global totalitarianism <a href=""https://www.zotero.org/google-docs/?TW9AIA"">(Bostrom &amp; Cirkovic, 2008)</a>. A further route is worse values caused by the catastrophe could be locked in by artificial general intelligence (AGI) <a href=""https://www.zotero.org/google-docs/?ERdxqN"">(Bostrom, 2014)</a>, though with the loss of industrial civilization, the advent of AGI would be significantly delayed, so the bad values could have decayed out by then.</p><p><strong>2.2 Artificial General Intelligence</strong></p><p>AGI itself represents a major, independent risk. The artificial intelligence available now is narrow AI, i.e. it can generally only do a specific task, such as playing Jeopardy! <a href=""https://www.zotero.org/google-docs/?xQhNy0"">(Schaul, Togelius, &amp; Schmidhuber, 2011)</a>. However, there are concerns that as AI systems become more advanced, AGI will eventually be achieved <a href=""https://www.zotero.org/google-docs/?ty8erm"">(Bostrom, 2014)</a>. Since AGI could perform all human tasks as well as or better than humans, this would include reprogramming the AGI. This would enable recursive self-improvement, so there could be an intelligence explosion <a href=""https://www.zotero.org/google-docs/?iPZRF2"">(Good, 1966)</a>. Since the goals of the intelligence may not be aligned with human interests <a href=""https://www.zotero.org/google-docs/?Q9ua90"">(Bostrom, 2014)</a> and could be pursued with great power, this implies a potentially serious risk <a href=""https://www.zotero.org/google-docs/?u6T1H6"">(Good, 1966)</a>. AGI safety is a top priority in the existential risk community that seeks to improve humanity’s long term future <a href=""https://www.zotero.org/google-docs/?Gi7SNH"">(Turchin &amp; Denkenberger, 2018b)</a>. Though there is uncertainty in when and how AGI may be developed, there are concrete actions that can be taken now to increase the probability of a good outcome <a href=""https://www.zotero.org/google-docs/?x9hUh5"">(Amodei et al., 2016)</a>. </p><p>We seek to compare the cost effectiveness of losing industry interventions with AGI safety to discover whether these interventions should also be a top priority. Comparisons to other risks, such as asteroids <a href=""https://www.zotero.org/google-docs/?jnGbXs"">(Matheny, 2007)</a>, climate change <a href=""https://www.zotero.org/google-docs/?GkEjlC"">(Halstead, 2018)</a> and pandemics <a href=""https://www.zotero.org/google-docs/?HQsZVE"">(Millett &amp; Snyder-Beattie, 2017)</a>, are possible, though these are generally regarded by the existential risk community as lower priority and therefore less informative.</p><p><strong>3. Methods</strong></p><p>Given the large uncertainties in input parameters, we model cost-effectiveness using a Monte Carlo simulation, producing a probability distribution of cost-effectiveness. Probabilistic uncertainty analysis is used widely in insurance, decision-support and cost-effectiveness modelling <a href=""https://www.zotero.org/google-docs/?LCEwIo"">(Garrick, 2008)</a>. In these models, uncertain parameters are represented by samples drawn from defined distributions that are combined into output samples that form a resultant distribution. </p><p>The models consist of a loss of industry submodel estimating the risk and mitigation costs of industrial loss, and an AGI risk submodel estimating risk and mitigation costs of AGI scenarios. These two submodels then allow us to estimate the ratio and confidence of cost-effectivenesses. </p><p>Monte Carlo estimation was selected because the probability distributions for various parameters do not come in a form that provides analytically tractable combinations. It also allows exploring parameter sensitivity. </p><p>The open source software called Guesstimate(2) was originally used to implement the models, and they are available online. However, to enable more powerful analysis and plotting, the models were also implemented on the software Analytica 5.2.9. Combining the uncertainties in all the inputs was performed utilizing a Median Latin Hypercube analysis (similar to Monte Carlo, but better performing <a href=""https://www.zotero.org/google-docs/?FhOTD5"">(Keramat &amp; Kielbasa, 1997)</a>) with the maximum uncertainty sample of 32,000 (run time on a personal computer was seconds). The results from the two software agreed within uncertainties due to finite number of samples, giving greater confidence in the results.</p><p>Figures 1 to 4 illustrate the interrelationships of the nodes for Model 1; Model 2 is identical with the following exception. The input variable Mitigation of far future impact of industrial loss from ALLFED so far for 10% industrial loss node was removed from Model 1 due to the poll question not requiring this input. </p><p> </p><figure><img src=""https://lh5.googleusercontent.com/EQpNa9G-U5tpaigpcTujj4aMx9wRUXriRoMYrZEX0hh31DOvU2OcJiSyST-ZUKno25gp-atLDjkb1hJXVNYF_0QuenmOFK1iFa8B0n5e_Yz1Jostp40jsmRouTaIXJRLJoAbGDAc"" class=""draft-image "" style=""width:454%""></figure> <p></p><p>Figure 1. Model overview</p><p> </p><figure><img src=""https://lh6.googleusercontent.com/5HHU92GOr7zNGVQl9I3vY5bBPm1u8riyVhtqZjsMF8GkX-uJZL-aEFkj_NRyZPDKIF3zqFJ2JIaeOVn_KZUuGTaQIrj8snquIDBTqoXAoxoGc9AETs_J3PZztKR4dpsGtaqXBw8y"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>Figure 2. 100% Industry loss catastrophes submodel (10% industry loss is nearly identical)</p><p> </p><figure><img src=""https://lh3.googleusercontent.com/P8DPnfC4-oMTAUlPIa_3aTEWnuXfIpfaQlFJXKCitfcVc2ijZ2_LmmvonfVpGnnigVyjfrORXRbmtnODj9wBUdwhN9rqrESrOT0WOxAKpVyKBaXn5VmubIIYcfHhWm6t6LE9YnuE"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>Figure 3. AGI safety cost effectiveness submodel</p><p> </p><figure><img src=""https://lh4.googleusercontent.com/fM9X_HtRwl_BQY28v1CySr31gDHLv4CfeJVw2qK9NwhBlTW3l6_VA2d-ZnIFYmClFw1dpYUz9sLNM0xM7FoKeuWMinlvJ1O5I54xamermCJ1ls05nxzrLYrQ4tXa7ykOdmqoROlx"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>Figure 4. Overall cost effectiveness ratios</p><p><strong>3.1 Loss of Industry Interventions Submodel</strong></p><p>Table 1 shows the key input parameters for Model 1 (largely Denkenberger and conference poll of effective altruists)<a href=""https://www.zotero.org/google-docs/?jiBoeK"">(D. Denkenberger, Cotton-Barrat, Dewey, &amp; Li, 2019a)</a> and Model 2 <a href=""https://www.zotero.org/google-docs/?0UODg8"">(D. Denkenberger, Cotton-Barratt, Dewey, &amp; Li, 2019)</a> (Sandberg inputs)(3). Though the authors here are associated with research on loss of industry, two out of four also published in AGI safety. Also, opinions outside of the loss of industry field have been solicited for one of the models. Therefore, we believe the results are representative. All distributions are lognormal unless otherwise indicated. The absolute value of the long term future is very difficult to quantify, so losses are expressed as a percent. </p><p>Table 1. Losing industry interventions input variables </p><p>  </p><figure><img src=""https://lh5.googleusercontent.com/mxW6K3tYaPL1yu5Tigtqd6WsLJnUggd3WTZu77dJVmFL3DzcYmz0YanEt3IBGqzVQo5EGWPULwDSjpIblPyVMoqCnZAIaGMG-vHj-j10wUAzgfa2ddVYkwzVv3nXyoVYiisEyHzJ"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>The potential causes of the disabling of 1/10 of global industry include Carrington-type solar storm, single HEMP, coordinated physical or cyber attack, conventional world war, loss of the Internet, and pandemic disrupting trade. We are not aware of quantitative estimates of the probability of a coordinated cyber attack, loss of the Internet, a pandemic that significantly disrupts trade, or a conventional world war that destroys significant industry and does not escalate to the use of nuclear weapons. Quantitative model estimates of the probability of full-scale nuclear war between the U.S. and Russia such as <a href=""https://www.zotero.org/google-docs/?10d39I"">(Barrett et al., 2013)</a> may give some indication of the probability of HEMP. HEMP could accompany nuclear weapons destroying cities, and this would be a combination losing industry/losing the sun scenario, which would benefit from the preparation considered here. Asymmetric warfare, where one country is significantly less powerful than another, could use HEMP because it only requires one or two nuclear weapons to disable an entire country. There are significantly more nuclear pairs that could result in HEMP than could result in full-scale nuclear war (the latter is basically the dyads between US, Russia, and China). And yet one quantitative model estimate of the probability of full-scale nuclear war only between U.S. and Russia was 1.7% per year mean <a href=""https://www.zotero.org/google-docs/?0MGzgP"">(Barrett et al., 2013)</a>. In 2012, there was a near miss of a solar storm similar size to the Carrington event <a href=""https://www.zotero.org/google-docs/?HKiWKO"">(Baker et al., 2013)</a>. One probability estimate of a Carrington-sized event is ~0.033% per year <a href=""https://www.zotero.org/google-docs/?F9bWXJ"">(Roodman, 2015)</a>. However, an estimate of the probability per year of a superflare 20 times as powerful as the Carrington event is 0.1%/year <a href=""https://www.zotero.org/google-docs/?iw7jCd"">(Lingam &amp; Loeb, 2017)</a>, which disagrees by orders of magnitude for the same intensity. Another study proposes that a Carrington-sized event recurrence interval is less than one century <a href=""https://www.zotero.org/google-docs/?1UbQU5"">(Hayakawa et al., 2019)</a>. Given the large uncertainty of solar storms and significant probability of single EMP, pandemic and regional cyber attack, Model 1 uses a mean of 3% per year. Model 2 uses a mean of 0.4% per year.</p><p>Intuitively, one would expect that the probability of near-total loss of industry would be significantly lower than 10% loss of industry. Complete loss of industry may correspond to the superflares that may have occurred in the first millennium A.D. (~0.1% per year). We are not aware of quantitative estimates of the probability of multiple EMP, industry-halting pandemic or global cyber attack. Model 1 mean is 0.3% per year for near-total loss of industry. Model 2 mean is 0.09% per year.</p><p>At the Effective Altruism Global 2018 San Francisco conference, with significant representation of people with knowledge of existential risk, a presentation was given and the audience was asked about the 100% loss of industry catastrophes. The questions involved the reduction in far future potential due to the catastrophes with current preparation and if ~$30 million were spent to get prepared. The data from the poll were used directly instead of constructing continuous distributions.</p><p>To determine the marginal impact of additional funding, the contribution due to work so far should be quantified. The Alliance to Feed the Earth in Disasters (ALLFED)<a href=""https://www.zotero.org/google-docs/?NTeQKz"">(ALLFED, 2019)</a> (and ALLFED researchers before the organization was officially formed) have published several papers on interventions for losing industry. They have a website with these papers and summaries. They have also run workshops to investigate planning for these interventions. However, we expect the contribution of ALLFED to reducing the long term impact of loss of industry to be significantly lower than in the case of obscuring of the sun because the loss of the Internet may be immediate if there are multiple simultaneous EMPs. However, the loss of electricity may not be simultaneous globally due to cyber attack. Furthermore, there may be several days warning for an extreme solar storm. The other reason why current work may be less valuable in a global loss of industry scenario is that fewer people know about the loss of industry work of ALLFED than the food without the sun work. Model 1 estimates a reduction in long-term future potential loss from a global loss of industry due to ALLFED so far as a mean of 0.1%. Model 2 uses 0.004% due to emphasizing lack of communication scenarios.</p><p>In the case of a 10% loss of industry, with the exception of the scenario of loss of Internet everywhere, the Internet in most places would be functioning. Even if the Internet is not functioning, mass media would generally be functioning. Therefore, possible mechanisms for impact due to work so far include the people already aware of the interventions getting the message to decision makers/media in a catastrophe, decision makers finding the three papers <a href=""https://www.zotero.org/google-docs/?gWLJ7w"">(Abdelkhaliq et al., 2016; Cole et al., 2016; David C Denkenberger et al., 2017)</a> on these interventions, or the people in the media who know about these interventions spreading the message. However, even though people outside of the affected countries could get the information, it may not be feasible to get the information to the people who need it most. Model 2 estimates a reduction in long-term future potential loss from a global loss of industry due to ALLFED so far as a mean of 0.004%, again due to the likely lack of communications in the affected region. Model 1 does not use a value in its calculation. </p><p>The mean estimate of the conference participants was 16% reduction in the long-term future of humanity due to loss of global industry with current preparedness. Model 2 estimate mean was 7%.</p><p>The 10% industry loss catastrophes could result in instability and full scale nuclear war or other routes to far future impact. Though the poll was not taken for this level of catastrophe, a survey of GCR researchers estimated a mean of 13% reduction in long-term potential of humanity due to a 10% food shortfall (<a href=""https://www.zotero.org/google-docs/?osjQ6h"">Denkenberger, Sandberg, &amp; Pearce, unpublished results)</a>. Some 10% loss of industry catastrophes could cause a ~10% global food shortfall. However, if the affected area were largely developed countries, since they would likely need to become near vegan to survive, human edible food demand could fall 10% because of the reduction of feeding animals. Still, given the possible overlap of these catastrophes, this analysis uses the survey estimate for Model 1. Model 2 estimate mean is 0.4% reduction in long-term potential due to 10% loss of industry. </p><p>The means of the percent further reduction in far future loss due to global loss of industry due to spending ~$30 million were 40% for the poll and 3% for Model 2. Note that in Model 1, the poll did not ask for the further reduction in far future loss from spending money, but instead a new far future loss after the money was spent. Therefore, the 40% mean further reduction is a calculated value and does not appear in Table 1. For the 10% industrial shortfalls, our estimate of the mean reduction is 12% for Model 1 because the contribution of additional spending on the aid from outside the affected region would be smaller. On the other hand, it was 5% for Model 2 because he thought the likelihood of success would be greater than for the global loss of industry given the outside aid.</p><p>Moral hazard would occur if awareness of interventions makes catastrophes more likely or more intense. Global use of EMP or coordinated cyber attack could be perpetrated by a terrorist organization trying to destroy civilization. However, if the organization knew of backup plans that could maintain civilization, the terrorist might actually be deterred from attempting such an attack. This would result in negative moral hazard (additional benefit of preparation). However, it is possible that knowledge of a backup plan could result in people expending less effort to harden systems to EMP, solar storm or cyber attack, creating moral hazard. Therefore, Model 1 uses a mean moral hazard of zero, and Model 2 uses a point value of zero.</p><p>For the 10% loss of industry scenarios, the same moral hazard values are used as for the global loss of industry.</p><p><strong>3.2 Costs of Interventions</strong></p><p>The costs of the proposed interventions are made up of a backup communication system, developing instructions and testing them for distributed food production, and making response plans at different levels of governments. </p><p>Currently the long distance shortwave radio frequencies are used by government and military stations, ships at sea, and by amateur (ham) radio operators. Because of security considerations, data on the number of government/military stations is difficult to compile. The use by ships has declined because of the availability of low cost satellite phones but there are an estimated three million ham operators worldwide <a href=""https://www.zotero.org/google-docs/?CZ5xZm"">(Silver, 2004)</a>. Not all of those are licensed to use the shortwave bands, however. In the U.S., about half of the approximately 800,000 American ham operators do hold the necessary license. Assuming such a pattern worldwide that would mean potentially about 1.5 million ham radio shortwave stations globally.</p><p>However, this analysis conservatively ignores the possibility that there would be existing ham radios that are disconnected with unplugged backup power systems. Therefore, the cost of the backup communication system of 5 million USD is based on the cost of 10 larger two-way shortwave communication systems (with backup power) that can transmit across oceans (see Appendix A). Then there would be 4000 smaller one-way shortwave receivers (with backup power) that, when connected to a laptop computer and printer, would have the ability to print out information. This could be called REcovering Civilization Using Radio (RECUR). This would cover 80% of the world’s population within one day nonmotorized transportation distance (~40 km) according to Geographical Information Systems (GIS) analysis (Fist et al., unpublished results). It is critical to very quickly get the message out that there is a plan and not to panic. Subsequent communication would be instructions for meeting basic needs immediately like food, shelter, and water. This initial planning would be considered open-loop control because it would not have immediate feedback <a href=""https://www.zotero.org/google-docs/?Y4TFQ5"">(Liptak, 2018)</a>. </p><p>In the ensuing months, as reality always deviates from plans, feedback would be required. This could be accomplished by coordinating additional undamaged shortwave and electrical generation equipment to allow two-way communication for many cities. Also, depending on distance, some messages could be communicated through non-electronic means such as horses, smoke signals, and sun reflecting heliographs of the kind that were used in the Western USA before telegraphs <a href=""https://www.zotero.org/google-docs/?hZzhiH"">(Rolak, 1975; Sterling, 2008)</a>. </p><p>Instructions would include how to get safe water or treat it (e.g. by filling containers including cleaned bathtubs with water in water towers and treating with bleach for a limited amount of time, solar water pasteurization (Burch et al., 1998; ) or boiling). Additional instructions would be on how to keep warm if it is cold outside <a href=""https://www.zotero.org/google-docs/?c8gA19"">(Abdelkhaliq et al., 2016)</a>. Other instructions would be how to retrofit a light duty vehicle to be pulled by a large animal. Because cattle and horses can eat food that is not edible to humans and because the wheel is so efficient, this would be a much more effective way of moving people than people walking. Additional instructions would be how to create wood-burning stoves and hand and animal farming tools, e.g. from repurposed or landfill materials. A similar project is Open Source Ecology, where blueprints have been developed of essential equipment for civilization that can be made from scratch <a href=""https://www.zotero.org/google-docs/?2OHBaN"">(Open Source Ecology, 2019)</a>. All of this should be tested on realistically untrained people and the instructions should be modified accordingly.</p><p>Planning involves determining where different people would need to be relocated in order to have their basic needs met. The critical short-term factors are shelter and water, while food is slightly longer term. The economically optimal plan could be achieved with GIS analysis. However, in order for this to be politically feasible, there would need to be negotiations and precommitments. This may have similar cost to the government planning for food without the sun of $1 million to $30 million <a href=""https://www.zotero.org/google-docs/?zAGVIH"">(Denkenberger &amp; Pearce, 2016)</a>.</p><p>Overall, Model 1 estimates the communications, instructions/testing, and planning for global industry loss would cost roughly 30 million USD (see Table 1). For the regional loss of industry, it is difficult to predict where it might occur, so generally communications and planning should be done for the entire world, and thus the instructions/experiments would be similar. Therefore, there is a high correlation of preparation for the two catastrophes, so this is assumed to be the cost of the preparation to both scales of catastrophe. Model 2 has somewhat higher costs ($50 million mean). </p><p>The time horizon of effectiveness of the interventions would depend on the intervention. Modern shortwave radio communications equipment has few moving parts (chiefly cooling fans and motors to rotate directional antennas) and serviceability measured in decades.(5) </p><p>Furthermore, these systems need to be disconnected from the grid to be protected from HEMP. This would reduce wear and tear, but regular testing would be prudent. Some of the budget could be used for this and for repair of the units. As for the instructions, since the hand and animal tools are not changing, directions should stay relevant. Planning within governments is susceptible to turnover, but some money could be used to transfer the knowledge to new employees. Model 1 estimates a 25 year mean for the time horizon. Model 2 has a slightly shorter time horizon mean of 20 years driven by a conservative estimate of the communications equipment lifetime.</p><p><strong>3.3 Artificial Intelligence Submodel</strong></p><p>The submodel for AGI safety cost-effectiveness was based on work of the Oxford Prioritisation Project, Owen Cotton-Barratt and Daniel Dewey (both while at the Future of Humanity Institute at the University of Oxford) <a href=""https://www.zotero.org/google-docs/?GzWKzI"">(D. Denkenberger, Cotton-Barrat, Dewey, &amp; Li, 2019b; Li, 2017)</a>. We modified it <a href=""https://www.zotero.org/google-docs/?0IZzV4"">(Denkenberger et al., unpublished results)</a>, with major changes including increasing the cost of an AGI safety researcher, making better behaved distributions, removing one method of calculation and changing the analysis from average to marginal for number of researchers. These changes increased the cost effectiveness of AGI safety by roughly a factor of two and increased the uncertainty considerably (because the method of calculation retained had much greater uncertainty than the one removed). The cost-effectiveness was found at the margin assuming $3 billion expenditure.</p><p><strong>4. Results and Discussion</strong></p><p><strong>4.1 Results</strong></p><p>In order to convert average cost effectiveness to marginal for interventions, we use logarithmic returns <a href=""https://www.zotero.org/google-docs/?jBemay"">(Cotton-Barratt, 2014)</a>, which results in the relative marginal cost effectiveness being one divided by the cumulative money spent. An estimate is needed of the cumulative money spent so far for interventions. Under $100,000 equivalent (mostly volunteer time) has been spent so far directly on this effort, nearly all by ALLFED. A very large amount of money has been spent on trying to prevent nuclear war, hardening military installations to HEMP, and on cyber security. However, note that even though US military infrastructure is supposedly hardened to EMP, it may not be able to withstand a “super” EMP weapon that some countries may possess <a href=""https://www.zotero.org/google-docs/?3P9QZZ"">(P. Pry, 2017)</a> or sophisticated cyber attacks. More relevant, money has been spent on farming organically and less industrially for traditional sustainability reasons. Also, Open Source Ecology has developed instructions for critical equipment. These could be tens of millions of dollars that would have needed to be spent for catastrophe preparation. So this would be relevant for the marginal $30 million case. However, there are still very high value interventions that should be done first, such as collecting instructions for producing hand/animal farm tools without industry and giving them to at least some governments and owners of disconnected shortwave radios and backup power sources. Though the interventions would not work as well as with ~$30 million of research/communications backup, simply having some critical people know about them and implement them in their own communities/countries without trade could still significantly increase the chance of retaining anthropological civilization. The cost of these first interventions would be very low, so they would have very high cost effectiveness. </p><p>Table 2 shows the ranges of the far future potential increase per $ due to loss of industry preparation average over ~$30 million Model 1, average over ~$50 million for Model 2, and AGI safety research at the $3 billion margin. The distributions are shown in Figure 5. Because the variance of Model 1 is very high, the mean cost-effectiveness is high, driven by the small probability of very high cost-effectiveness.</p><p> Table 2. Cost-effectiveness comparison </p><p> </p><figure><img src=""https://lh6.googleusercontent.com/ncyRVTPh8oQNQrpjPDKebY_EtRBUBKyuQjA86iDQRejfE-LjRCAnHZGZqPrMAFmQTeZQrAEv4m1BSoyG7HPunO6IC1_TPra1GydTGfgSlMv4yVJ5Rf_WpT04-2hT3AryLQr3Bo0_"" class=""draft-image "" style=""width:624%""></figure> <p></p><p> </p><figure><img src=""https://lh5.googleusercontent.com/Ohr6IbFI1II1-sVeqREBaBTNWLIRvInOQprJII7NYXrYBar7NCfXYyhG1ugKzM_6U0XTEuUqw7AErkj7NWhImEJAChsGNVxHqfUAEGHuB-n2SZAK-WKHAJEShRCgZZQoivOVFngs"" class=""draft-image "" style=""width:624%""></figure> <p></p><p> Figure 5. Far future potential increase per $ due to loss of industry preparation average over ~$30 million Model 1, due to loss of industry preparation average over ~$50 million Model 2, and AGI safety research at the $3 billion margin. Further to the right is more cost-effective.</p><p>With logarithmic returns, cost-effectivenesses of the marginal dollar now (100,000th dollar) and of the last dollar are about 50 times greater than, and 6 times less than, the average cost effectiveness of spending $30 million, respectively. For Model 2, the corresponding numbers are about 70 times greater than and 6 times less than the average cost effectiveness of spending $50 million. Ratios of mean of the distributions of cost effectivenesses are reported in Table 3.6 Comparing to AGI safety at the margin, Model 1 yields the 30 millionth dollar on losing industry being 20 times more cost effective, the average $30 million on interventions being 100 times more cost effective, and the marginal dollar now on interventions being 5000 times more cost effective (Table 3). Model 2 yields the last dollar on interventions being 0.05 times as cost effective, the average ~$50 million on interventions being 0.2 times as cost effective, and the marginal dollar now on interventions being 20 times as cost effective. Given orders of magnitude uncertainty and sensitivity of these ratios to the relative uncertainty of the interventions, likely more robust are the probabilities that one is more cost effective than the other. Comparing to AGI safety at the margin, Model 1 finds ~88% probability that the 30 millionth dollar on interventions is more cost effective, ~95% probability that the average $30 million on interventions is more cost effective, and ~99+% probability that the marginal dollar now on interventions is more cost effective (see Table 3). Model 2 finds ~50% probability that the 50 millionth dollar on interventions is more cost effective than AGI safety, ~76% probability that the average $50 million on interventions is more cost effective, and ~99% probability that the marginal dollar now on interventions is more cost effective. Note that the greater than 50% probability for the average cost effectiveness despite the ratio of the means of cost-effectiveness being less than one is due to the relatively smaller variance of Model 2 cost-effectiveness estimate (see Figure 5).</p><p>Table 3. Key cost effectiveness outputs of losing industry interventions</p><p>  </p><figure><img src=""https://lh5.googleusercontent.com/oqBMSNTwwcQ_6ZVtUi7veiy9vBN85adNsG2WVYgQo8kWHkIT8fAHRkwzBmy26yi0CLfqRurYVkDOAzB-on00NF3MrsSmZtOSZSTmmxnvJqtnYaj77tNTu-NVlZic-8HI4zdMPp_7"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>Overall, the mean cost-effectiveness of Model 1 is about 2.5 orders of magnitude higher than Model 2. However, due to the smaller variance in Model 2 distributions, there was similar confidence that losing industry interventions at the margin now are more cost-effective than AGI safety. Another large difference is that Model 1 found that 10% loss of industry scenarios are similar cost effectiveness for the far future as global loss. This was because the greater probability of these catastrophes counteracted the smaller far future impact. However, Model 2 rated the cost-effectiveness of the 10% industry loss as ~1.5 orders of magnitude lower than for global loss. Given the agreement of high confidence that further work is justified at this point, some of this further work could be used to resolve the significant uncertainties to determine if more money is justified: value of information <a href=""https://www.zotero.org/google-docs/?hWNl6n"">(Barrett, 2017)</a>.</p><p>Being prepared for loss of industry might protect against unknown risks, meaning the cost-effectiveness would increase. </p><p>According to Model 1, every year acceleration in preparation for losing industry would increase the long term value of humanity by 0.00009% to 0.4% (mean of 0.07%). The corresponding Model 2 numbers are 0.00006% to 0.0004% (mean of 0.00017%). Either way, there is great urgency to get prepared.</p><p>It is not necessary for interventions to be more cost effective than AGI safety in order to fund losing industry interventions on a large scale. Funding in the existential risk community goes to other causes, e.g. an engineered pandemic. One estimate of cost effectiveness of biosecurity was much lower than for AGI safety and losing industry interventions, but the authors were being very conservative <a href=""https://www.zotero.org/google-docs/?NSuNr3"">(Millett &amp; Snyder-Beattie, 2017)</a>. Another area of existential risk that has received investment is asteroid impact, which again has much lower cost-effectiveness than for losing industry interventions <a href=""https://www.zotero.org/google-docs/?8aHOuA"">(Matheny, 2007)</a>.</p><p>The<a href=""https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/""> </a>importance, tractability, neglectedness (ITN) framework <a href=""https://www.zotero.org/google-docs/?VdvB7I"">(Effective Altruism Concepts, 2019)</a> is useful for prioritizing cause areas. The importance is the expected impact on the long-term future of the risk. Tractability measures the ease of making progress. Neglectedness quantifies how much effort is being directed towards reducing the risk. Unfortunately this framework cannot be applied to interventions straightforwardly. This is because addressing a risk could have many potential interventions. Nevertheless, some semi-quantitative insights can be gleaned. The importance of AGI is larger than industry loss catastrophes, but industry loss interventions are far more neglected. </p><p>Though these interventions for the loss of industry are not compared directly to food without the sun interventions, they are both compared to the same AGI safety submodel. Overall, Model 2 indicates that spending $50 million on interventions for the loss of industry is competitive with AGI safety. However, Model 1 here and both models for the food without sun indicate that significantly larger than the proposed amount to be spent (~$100 million) would be justified from the long-term future perspective.</p><p>The AGI safety submodel was used to estimate the cost effectiveness of saving expected lives in the present generation, finding $16-$12,000 per expected life saved (<a href=""https://www.zotero.org/google-docs/?PDUaDV"">(Denkenberger et al., unpublished results)</a>. This is generally more cost effective than GiveWell estimates for global health interventions: $900-$7,000 <a href=""https://www.zotero.org/google-docs/?oFvUbU"">(GiveWell, 2017)</a>. Food without the sun is significantly better ($0.20-$400 per expected life) for only 10% global food production shortfalls <a href=""https://www.zotero.org/google-docs/?Oy4JA6"">( Denkenberger &amp; Pearce, 2016)</a> and generally better only considering one country ($1-$20,000 per expected life) and only nuclear winter <a href=""https://www.zotero.org/google-docs/?m329p7"">( Denkenberger &amp; Pearce, 2016)</a>. Model 2 for interventions for losing industry has similar long term future cost-effectiveness to AGI safety, indicating that the lifesaving cost-effectiveness of interventions for losing industry would likely be competitive with AGI safety and global health, but this requires future work. Model 1 for interventions for losing industry has similar long term future cost-effectiveness to food without the sun, indicating that loss of industry preparations may save lives in the present generation less expensively than AGI safety and global health. Since AGI safety appears to be underfunded from the present generation perspective, it would be extremely underfunded when taking into account future generations. If this were corrected, then in order for interventions for losing industry to stay similar cost-effectiveness to AGI safety, more funding for losing industry interventions would be justified. </p><p><strong>4.2 Timing of Funding</strong></p><p>If one agrees that interventions for losing industry should be a significant part of the existential risk reduction portfolio, there remains the question of how to allocate funding to the different causes over time. For AGI safety, there are arguments both for funding later and funding now <a href=""https://www.zotero.org/google-docs/?DkBt3Q"">(Ord, 2014)</a>. For interventions for losing industry, since most of the catastrophes could happen right away, there is significantly greater urgency to fund interventions for losing industry now. Furthermore, it is relatively more effective to scale up the funding quickly because, through requests for proposals, the effort could co-opt relevant existing expertise (e.g. in shortwave radio). Since we have not monetized the value of the far future, we cannot use conventional cost-effectiveness metrics such as the benefit to cost ratio, net present value, payback time, and return on investment. However, in the case of saving expected lives in the present generation for the global case and 10% food shortfalls, the return on investment was from 100% to 5,000,000% per year <a href=""https://www.zotero.org/google-docs/?MPlmqn"">(Denkenberger &amp; Pearce, 2016)</a> based on monetized life savings. This suggests that the $40 million or so for interventions for losing industry should be mostly spent in the next few years to optimally reduce existential risk (a smaller amount would maintain preparedness into the future). </p><p><strong>4.3 Uncertainty and parameter sensitivity</strong></p><p>Parameter sensitivities of Model 1 and Model 2 were investigated using the Analytica importance analysis function. This uses the absolute rank-order correlation between each input and the output as a measure of the strength of monotonic relations between each uncertain input and a selected output, both linear and otherwise <a href=""https://www.zotero.org/google-docs/?TVV53e"">(Chrisman et al., 2007; Morgan &amp; Henrion, 1990)</a>. Analysis was focused on the alternative foods submodel i.e. Global loss of industry and 10% industry loss catastrophes. Parameter sensitivity within AGI safety was not investigated as this submodel was adapted from previous work by the Oxford Prioritisation Project, which discussed uncertainties within the AGI safety cost effectiveness submodel <a href=""https://www.zotero.org/google-docs/?j4viEc"">(Denkenberger et al., 2019b; Li, 2017)</a>).</p><p>The key outputs nodes in Table 3 were unable to be investigated directly using the importance analysis function due to the node outputs being point values, a result of calculating the ratio of means (the Analytica importance analysis function requires the variable be a chance variable to perform absolute rank-order correlation). Therefore the previous node in the models Far future potential increase per $ due to loss of industry preparation was used to investigate the importance of input variables of the alternate foods submodel. </p><p>Importance analysis of node:  Far future potential increase per $ due to loss of industry preparation showed Model 1 had greatest sensitivity to input variables Reduction in far future potential due to 10% industrial loss with current preparation closely followed by Reduction in far future potential due to global loss of industry with current preparation (Figure 6). Model 2 showed greatest sensitivity to input variable Cost of interventions ($ million) (global loss of industry)<em>  </em>(Figure 7). </p><p>  </p><figure><img src=""https://lh5.googleusercontent.com/9n5YPdCbSgxVIrACi5-RbU4T-ymDTVW2jofIBs9HHsYk9dSoEQGL8Lz8f_awAMmGScnN4VL6cueQMT5baWHxEozvr6uPzCeJNiUqzN9jxC0u51NutsVf6fH8A7r_00DubDIcTAdn"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>Figure 6. Importance analysis results for Far future potential increase per $ due to loss of industry preparation for Model 1.</p><p>  </p><figure><img src=""https://lh3.googleusercontent.com/5aHsCa85Mzgu16UB9MdowHvW6Un8e29_jxBa__pzzzR04YqrFnbf_pbZjF5obLJ6V-_vUBZdfB9pnUuluuWj1XfPw-oSJ0T6_5KPcENF_SU6goc9fWy8WnZRAPzKaf3b6x5LAPcm"" class=""draft-image "" style=""width:624%""></figure> <p></p><p>Figure 7. Importance analysis results for Far future potential increase per $ due to loss of industry preparation for Model 2.</p><p>Successive rounds of parametric analysis were performed to determine combinations of input parameters sufficiently unfavorable to alternative foods, until cost effectiveness ratios (Table 3) switched to favoring AGI safety. Unfavorable input values were limited to 5th or 95th percentile values of original input distributions. Model 1 required 7 unfavorable input parameters to switch to AGI safety being more cost effective than losing industry interventions at the margin now while Model 2 required 4 input variables (see Table 4). </p><p>Table 4: Combination of input variables resulting in AGI safety being more cost effective than losing industry interventions at the margin now.</p><p>  </p><figure><img src=""https://lh3.googleusercontent.com/iGVyXT9mfdrYOJfNLT5MEJice_u7PAjoBPk49Vp3zlpumFXEJwSpGmFg384oe85er9qZKn-aH-idpkRo32EFehaRqmIczK60bbU7yDwgXT_97uSky7MZqHNVgLv2v8HtWXWcNj4l"" class=""draft-image "" style=""width:624%""></figure> <p></p><p><strong>5. Conclusions and Future Work</strong></p><p>There are a number of existential risks that have the potential to reduce the long-term potential of humanity. These include AGI and electricity/industry disrupting catastrophes including extreme solar storm, EMP, and coordinated cyber attack. Here we present the first long term future cost-effectiveness analyses for interventions for losing industry. There is great uncertainty in both AGI safety and interventions for losing industry. However, the models have 99%-99+% confidence that funding interventions for losing industry now is more cost effective than additional funding for AGI safety beyond the expected $3 billion. In order to make AGI safety more cost effective than losing industry interventions according to the mean of their distributions, this required changing four variables in Model 2 to the 5th percentile on the pessimistic end simultaneously. For Model 1, it required changing seven variables. Therefore, it is quite robust that a significant amount of money should be invested in losing industry interventions now. There is closer to 50%-88% confidence that spending the ~$40 million on interventions for losing industry is more cost effective than AGI safety. These interventions address catastrophes that have significant likelihood of occurring in the next decade, so funding is particularly urgent. Both AGI safety and interventions for losing industry save expected lives in the present generation more cheaply than global poverty interventions, so funding should increase for both. The cost-effectiveness at the margin of interventions for the loss of industry is similar to that for food without the sun (for industry versus sun, Model 1 is ~1 order of magnitude more cost effective, but Model 2 is ~1 order of magnitude less cost effective). Because the electricity/industry catastrophes could happen immediately and because existing expertise relevant to food without industry could be co-opted by charitable giving, it is likely optimal to spend most of this money in the next few years. </p><p>Since there may be scenarios of people eating primarily one food, micronutrient sufficiency should be checked, though it would be less of an issue than for food without the sun <a href=""https://www.zotero.org/google-docs/?8v7Qp2"">(D. Denkenberger &amp; Pearce, 2018; Griswold et al., 2016)</a>. Higher priority future research includes ascertaining the number and distribution of unplugged shortwave radio systems with unplugged power systems that could be utilized in a catastrophe. Additional research includes the feasibility of the continuation of improved crop varieties despite loss of industry. Further research is estimating the rapidity of scale up of hand and animal powered farm tools. Estimating the efficacy of pest control without industry would be valuable. Better quantifying the capability of using fertilizer based on ash would be aided by GIS analysis. Additional work is surveying whether there have been experiments of the agricultural productivity produced by people inexperienced in farming by hand.</p><p>Another piece of future work would be to analyze the cost-effectiveness of AGI safety and preparation for the loss of industry in terms of species saved. Rogue AGI could cause the extinction of nearly all life on earth. If there were mass starvation due to the loss of electricity/industry, humans would likely eat many species to extinction. Therefore, being able to meet human needs would save species. These cost effectivenesses could be compared to the cost effectiveness of conventional methods of saving species. Finally, additional future work involves better quantifying the cost of preparedness to the loss of industry. Furthermore, research for the actual preparedness should be done, including estimating the amount of unplugged communications hardware and backup power, testing the backup communications system, experiments demonstrating the capability to quickly construct hand/animal farm tools and developing quick training to use them. Also investigating alternative food sources that do not require industry would be beneficial, such as seaweed (Mill et al., unpublished results).</p><h1>Footnotes</h1><p>(1) This vulnerability can be addressed with distributed generation and microgrids <a href=""https://www.zotero.org/google-docs/?nXhmx5"">(S. M. Amin, 2010; Lovins &amp; Lovins, 1982; Prehoda et al., 2017; Zerriffi, Dowlatabadi, &amp; Strachan, 2002)</a>, but these technologies are still far from ubiquitous.</p><p>(2) One can change numbers in viewing mode to see how outputs change, but alterations will not save. If one wants to save a new version, one can make a copy of the model. Click View, visible to show arrows of relationships between cells. Drag mouse over cells to see comments. Click on the cell to show the equation.</p><p>(3) Lognormal results in the median being the geometric mean of the bounds (multiply the 5th and 95th percentiles and raise to the 0.5 power). Note that with large variances, the mean is generally much higher than the median.</p><p>(4) The global loss poll gave people ranges, including &lt;0.1%, 0.1% to 1%, 1% to 10%, and 10% to 100%. All responses in the range were recorded as approximately the geometric mean of the range. Half of people were therefore recorded as 30% loss of the far future. If the people had been able to provide exact values, likely one of them would have recorded greater than 40%, which was the upper bound for the 10% loss of industry, making these results consistent. However, even with the constraints of the data, the mean and median are higher for the global loss of industry than the 10% loss of industry.</p><p>(5) On any given day Ebay lists numerous used shortwave radio transmitter/receivers still in fully operational condition, some of them manufactured in the 1960s.</p><p>(6) Ratios of means require manual changes in Guesstimate, which we note in all caps in the model.</p><p><strong>Appendix A: Radio component costs - available on <u><a href=""https://osf.io/rgq2z/"">https://osf.io/rgq2z/</a></u></strong>  </p><p><strong>References</strong></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Abdelkhaliq, M., Denkenberger, D., Griswold, M., Cole, D., &amp; Pearce, J. (2016). <em>Providing Non-food Needs if Industry is Disabled</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Aitel, D. (2013). Cybersecurity Essentials for Electric Operators. <em>The Electricity Journal</em>, <em>26</em>(1), 52–58. https://doi.org/10.1016/j.tej.2012.11.014</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">ALLFED. (2019, April 10). Home. Retrieved April 10, 2019, from ALLFED website: http://allfed.info/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Amin, M. (2002). Security challenges for the electricity infrastructure. <em>Computer</em>, <em>35</em>(4), supl8–supl10. https://doi.org/10.1109/MC.2002.1012423</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Amin, M. (2005). Energy Infrastructure Defense Systems. <em>Proceedings of the IEEE</em>, <em>93</em>(5), 861–875. https://doi.org/10.1109/JPROC.2005.847257</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Amin, S. M. (2010). Electricity infrastructure security: Toward reliable, resilient and secure cyber-physical power and energy systems. <em>IEEE PES General Meeting</em>, 1–5. IEEE.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., &amp; Mané, D. (2016). Concrete Problems in AI Safety. <em>ArXiv:1606.06565 [Cs]</em>. Retrieved from http://arxiv.org/abs/1606.06565</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Avalos, G. (2014, August 27). PG&amp;E substation in San Jose that suffered a sniper attack has a new security breach. Retrieved August 8, 2019, from The Mercury News website: https://www.mercurynews.com/2014/08/27/pge-substation-in-san-jose-that-suffered-a-sniper-attack-has-a-new-security-breach/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Baker, D. N., Li, X., Pulkkinen, A., Ngwira, C. M., Mays, M. L., Galvin, A. B., &amp; Simunac, K. D. C. (2013). A major solar eruptive event in July 2012: Defining extreme space weather scenarios. <em>Space Weather</em>, <em>11</em>(10), 585–591. https://doi.org/10.1002/swe.20097</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Barrett, A. M. (2017). Value of GCR Information: Cost Effectiveness-Based Approach for Global Catastrophic Risk (GCR) Reduction. <em>Forthcoming in Decision Analysis</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Barrett, A. M., Baum, S. D., &amp; Hostetler, K. R. (2013). Analyzing and reducing the risks of inadvertent nuclear war between the United States and Russia. <em>Sci. Global Secur.</em>, <em>21</em>(2), 106–133.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Baum, S. D., Denkenberger, D. C., &amp; Pearce, J. M. (2016). Alternative Foods as a Solution to Global Food Supply Catastrophes. <em>Solutions</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Bernstein, A., Bienstock, D., Hay, D., Uzunoglu, M., &amp; Zussman, G. (2012). Sensitivity analysis of the power grid vulnerability to large-scale cascading failures. <em>ACM SIGMETRICS Performance Evaluation Review</em>, <em>40</em>(3), 33. https://doi.org/10.1145/2425248.2425256</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Bessani, A. N., Sousa, P., Correia, M., Neves, N. F., &amp; Verissimo, P. (2008). The CRUTIAL way of critical infrastructure protection. <em>IEEE Security &amp; Privacy</em>, (6), 44–51.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Bostrom, N. (2013). Existential Risk Prevention as Global Priority. <em>Global Policy</em>, <em>4</em>(1), 15–31. https://doi.org/10.1111/1758-5899.12002</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Bostrom, N. (2014). <em>Superintelligence: paths, dangers, strategies</em> (First edition). Oxford: Oxford University Press.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Bostrom, N., &amp; Cirkovic, M. M. (Eds.). (2008). <em>Global Catastrophic Risks</em>. New York: Oxford University Press.</a></p><p>Burch, J.D. and Thomas, K.E., 1998. Water disinfection for developing countries and potential for solar thermal pasteurization. <em>Solar Energy</em>, <em>64</em>(1-3), pp.87-97.</p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Che, L., &amp; Shahidehpour, M. (2014). DC microgrids: Economic operation and enhancement of resilience by hierarchical control. <em>IEEE Transactions on Smart Grid</em>, <em>5</em>(5), 2517–2526.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Chrisman, L., Henrion, M., Morgan, R., Arnold, B., Brunton, F., Esztergar, A., &amp; Harlan, J. (2007). <em>Analytica user guide</em>. Los Gatos, CA: Lumina Decision Systems.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Coates, J. F. (2009). Risks and threats to civilization, humankind, and the earth. <em>Futures</em>, <em>41</em>(10), 694–705. https://doi.org/10.1016/j.futures.2009.07.010</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Cole, D. D., Denkenberger, D., Griswold, M., Abdelkhaliq, M., &amp; Pearce, J. (2016). Feeding Everyone if Industry is Disabled. <em>Proceedings of the 6th International Disaster and Risk Conference</em>. Presented at the 6th International Disaster and Risk Conference, Davos, Switzerland.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Colson, C., Nehrir, M., &amp; Gunderson, R. (2011). <em>Distributed multi-agent microgrids: a decentralized approach to resilient power system self-healing</em>. 83–88. IEEE.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Cotton-Barratt, O. (2014, October). The law of logarithmic returns. Retrieved April 10, 2019, from The Future of Humanity Institute website: http://www.fhi.ox.ac.uk/law-of-logarithmic-returns/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Dartnell, L. (2014). <em>The Knowledge: How to Rebuild Our World from Scratch</em>. Random House.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D. C., &amp; Pearce, J. M. (2018, June 14). A National Pragmatic Safety Limit for Nuclear Weapon Quantities. </a><em>Safety</em> <strong>2018</strong>, <em>4</em>(2), 25;<a href=""https://doi.org/10.3390/safety4020025""> <u>https://doi.org/10.3390/safety4020025</u></a></p><p>Denkenberger, D. and Pearce, J., 2018. Design optimization of polymer heat exchanger for automated household-scale solar water pasteurizer. <em>Designs</em>, <em>2</em>(2), 11;<a href=""https://doi.org/10.3390/designs2020011""> <u>https://doi.org/10.3390/designs2020011</u></a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., Cotton-Barrat, O., Dewey, D., &amp; Li, S. (2019a, August 10). Foods without industry and AI X risk cost effectiveness general far future impact Denkenberger. Retrieved August 10, 2019, from Guesstimate website: https://www.getguesstimate.com/models/11599</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., Cotton-Barrat, O., Dewey, D., &amp; Li, S. (2019b, August 12). Machine Intelligence Research Institute - Oxford Prioritisation Project. Retrieved August 12, 2019, from Guesstimate website: https://www.getguesstimate.com/models/8789</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., Cotton-Barratt, O., Dewey, D., &amp; Li, S. (2019, April 10). Food without the sun and AI X risk cost effectiveness general far future impact publication. Retrieved April 10, 2019, from Guesstimate website: https://www.getguesstimate.com/models/13082</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., &amp; Pearce, J. (2018). Micronutrient availability in alternative foods during agricultural catastrophes. <em>Agriculture</em>, <em>8</em>(11), 169.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., &amp; Pearce, J. M. (2014). <em>Feeding Everyone No Matter What: Managing Food Security After Global Catastrophe</em>. Academic Press.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., Pearce, J., Taylor, A. R., &amp; Black, R. (2019). Food without sun: Price and life-saving potential. <em>Foresight</em>, <em>21</em>(1), 118–129.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D., Sandberg, A., &amp; Pearce, J. M. (unpublished results). Long Term Cost-Effectiveness of Alternative Foods for Global Catastrophes. </a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D. C, Cole, D. D., Abdelkhaliq, M., Griswold, M., Hundley, A. B., &amp; Pearce, J. M. (2017). Feeding everyone if the sun is obscured and industry is disabled. <em>International Journal of Disaster Risk Reduction</em>, <em>21</em>, 284–290.</a></p><p>Denkenberger, D.C. and Pearce, J.M., 2016. Cost-effectiveness of interventions for alternate food to address agricultural catastrophes globally. <em>International Journal of Disaster Risk Science</em>, <em>7</em>(3), pp.205-215.</p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D. C, &amp; Pearce, J. M. (2015b). Feeding everyone: Solving the food crisis in event of global catastrophes that kill crops or obscure the sun. <em>Futures</em>, <em>72</em>, 57–68.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Denkenberger, D. C., &amp; Pearce, J. M. (2016). Cost-Effectiveness of Interventions for Alternate Food to Address Agricultural Catastrophes Globally. <em>International Journal of Disaster Risk Science</em>, <em>7</em>(3), 205–215. https://doi.org/10.1007/s13753-016-0097-2</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Effective Altruism Concepts. (2019, April 10). Importance, tractability, neglectedness framework. Retrieved April 10, 2019, from Effective Altruism Concepts website: https://concepts.effectivealtruism.com/concepts/importance-neglectedness-tractability/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Foster, J. S., Gjelde, E., Graham, W. R., Hermann, R. J., Kluepfel, H. (Hank) M., Lawson, R. L., … Woodard, J. B. (2004, July 22). Report of the Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack. Retrieved June 30, 2016, from Committee on Armed Services House of Representatives website: http://commdocs.house.gov/committees/security/has204000.000/has204000_0.HTM</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Foster, Jr, J. S., Gjelde, E., Graham, W. R., Hermann, R. J., Kluepfel, H. (Hank) M., Lawson, R. L., … Woodard, J. B. (2008). <em>Report of the commission to assess the threat to the united states from electromagnetic pulse (emp) attack: Critical national infrastructures</em>. Retrieved from DTIC Document website: http://www.empcommission.org/docs/A2473-EMP_Commission-7MB.pdf</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Garrick, B. J. (2008). <em>Quantifying and controlling catastrophic risks</em>. Academic Press.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Gent, M. R., &amp; Costantini, L. P. (2003). Reflections on security [power systems]. <em>IEEE Power and Energy Magazine</em>, <em>1</em>(1), 46–52.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">GiveWell. (2017, November). Cost-Effectiveness. Retrieved April 10, 2019, from GiveWell website: https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Good, I. J. (1966). Speculations concerning the first ultraintelligent machine. In <em>Advances in computers</em> (Vol. 6, pp. 31–88). Elsevier.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Goodin, D. (2016, January 4). <em>First known hacker-caused power outage signals troubling escalation</em>. Retrieved from http://arstechnica.com/security/2016/01/first-known-hacker-caused-power-outage-signals-troubling-escalation/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Gorman, S. (2009, April 9). Electricity Grid in U.S. Penetrated By Spies. <em>Wall Street Journal</em>. Retrieved from https://www.wsj.com/articles/SB123914805204099085</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Gregory, J., Stouffer, R. J., Molina, M., Chidthaisong, A., Solomon, S., Raga, G., … Stone, D. A. (2007). <em>Climate Change 2007: The Physical Science Basis</em>. Retrieved from http://copa.acguanacaste.ac.cr:8080/handle/11606/461</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Griswold, M., Denkenberger, D., Abdelkhaliq, M., Cole, D., Pearce, J., &amp; Taylor, A. R. (2016). Vitamins in Agricultural Catastrophes. <em>Proceedings of the 6th International Disaster and Risk Conference</em>. Presented at the 6th International Disaster and Risk Conference, Davos, Switzerland.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Halstead, J. (2018, May). <em>Climate Change Cause Area Report</em>. Founders Pledge.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Hayakawa, H., Ebihara, Y., Willis, D. M., Toriumi, S., Iju, T., Hattori, K., … Ribeiro, J. R. (2019). Temporal and Spatial Evolutions of a Large Sunspot Group and Great Auroral Storms around the Carrington Event in 1859. <em>Space Weather</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Hébert, C. (2013). The Most Critical of Economic Needs (Risks): A Quick Look at Cybersecurity and the Electric Grid. <em>The Electricity Journal</em>, <em>26</em>(5), 15–19. https://doi.org/10.1016/j.tej.2013.05.009</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Helfand, I. (2013). Nuclear famine: Two billion people at risk. <em>International Physicians for the Prevention of Nuclear War</em>, 20.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Kelly-Detwiler, P. (2014, July 31). Failure to Protect U.S. Against Electromagnetic Pulse Threat Could Make 9/11 Look Trivial Someday. Retrieved August 7, 2019, from https://www.forbes.com/sites/peterdetwiler/2014/07/31/protecting-the-u-s-against-the-electromagnetic-pulse-threat-a-continued-failure-of-leadership-could-make-911-look-trivial-someday/#2ed092db7a14</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Keramat, M., &amp; Kielbasa, R. (1997). Latin hypercube sampling Monte Carlo estimation of average quality index for integrated circuits. In <em>Analog Design Issues in Digital VLSI Circuits and Systems</em> (pp. 131–142). Springer.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Kinney, R., Crucitti, P., Albert, R., &amp; Latora, V. (2005). Modeling cascading failures in the North American power grid. <em>The European Physical Journal B</em>, <em>46</em>(1), 101–107. https://doi.org/10.1140/epjb/e2005-00237-9</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Klein, C. (2012, March 14). A Perfect Solar Superstorm: The 1859 Carrington Event. Retrieved August 7, 2019, from HISTORY website: https://www.history.com/news/a-perfect-solar-superstorm-the-1859-carrington-event</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Krotofil, M., Cardenas, A., Larsen, J., &amp; Gollmann, D. (2014). Vulnerabilities of cyber-physical systems to stale data—Determining the optimal time to launch attacks. <em>International Journal of Critical Infrastructure Protection</em>, <em>7</em>(4), 213–232.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Kushner, D. (2013). The real story of stuxnet. <em>IEEE Spectrum</em>, <em>50</em>(3), 48–53. https://doi.org/10.1109/MSPEC.2013.6471059</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Lasseter, R. H. (2007). Microgrids and distributed generation. <em>Journal of Energy Engineering</em>, <em>133</em>(3), 144–149.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Lasseter, R. H., &amp; Piagi, P. (2004). <em>Microgrid: A conceptual solution</em>. <em>6</em>, 4285–4291. Citeseer.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Li, S. (2017, May 12). A model of the Machine Intelligence Research Institute - Oxford Prioritisation Project - EA Forum. Retrieved August 12, 2019, from https://forum.effectivealtruism.org/posts/NbFZ9yewJHoicpkBr/a-model-of-the-machine-intelligence-research-institute</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Lingam, M., &amp; Loeb, A. (2017). Risks for life on habitable planets from superflares of their host stars. <em>The Astrophysical Journal</em>, <em>848</em>(1), 41.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Liptak, B. G. (2018). <em>Instrument Engineers’ Handbook, Volume Two: Process Control and Optimization</em>. CRC Press.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Lovins, A. B., &amp; Lovins, L. H. (1982). <em>Brittle power</em>. Brick House Publishing Company.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Matheny, J. G. (2007). Reducing the risk of human extinction. <em>Risk Analysis: An International Journal</em>, <em>27</em>(5), 1335–1344.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">McIntyre, P. (2016a, April 12). How you can lower the risk of a catastrophic nuclear war. Retrieved August 13, 2019, from 80,000 Hours website: https://80000hours.org/problem-profiles/nuclear-security/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">McIntyre, P. (2016b, April 12). How you can lower the risk of a catastrophic nuclear war. Retrieved August 9, 2019, from 80,000 Hours website: https://80000hours.org/problem-profiles/nuclear-security/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Mekhaldi, F., Muscheler, R., Adolphi, F., Aldahan, A., Beer, J., McConnell, J. R., … Synal, H.-A. (2015). Multiradionuclide evidence for the solar origin of the cosmic-ray events of ᴀᴅ 774/5 and 993/4. <em>Nature Communications</em>, <em>6</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Millett, P., &amp; Snyder-Beattie, A. (2017). Existential Risk and Cost-Effective Biosecurity. <em>Health Security</em>, <em>15</em>(4), 373–383. https://doi.org/10.1089/hs.2017.0028</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Morgan, M. G., &amp; Henrion, M. (1990). Uncertainty: a Guide to dealing with uncertainty in quantitative risk and policy analysis Cambridge University Press. <em>New York, New York, USA</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Motesharrei, S., Rivas, J., &amp; Kalnay, E. (2014). Human and nature dynamics (HANDY): Modeling inequality and use of resources in the collapse or sustainability of societies. <em>Ecological Economics</em>, <em>101</em>, 90–102. https://doi.org/10.1016/j.ecolecon.2014.02.014</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Motter, A. E., &amp; Lai, Y.-C. (2002). Cascade-based attacks on complex networks. <em>Physical Review E</em>, <em>66</em>(6), 065102. https://doi.org/10.1103/PhysRevE.66.065102</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Nai Fovino, I., Guidi, L., Masera, M., &amp; Stefanini, A. (2011). Cyber security assessment of a power plant. <em>Electric Power Systems Research</em>, <em>81</em>(2), 518–526. https://doi.org/10.1016/j.epsr.2010.10.012</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">National Research Council. (2012). <em>Terrorism and the electric power delivery system</em>. National Academies Press.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Oak Ridge National Laboratory. (2010). <em>Electromagnetic Pulse: Effects on the U.S. Power Grid</em>. 6.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Oke, O., Redhead, J., &amp; Hussain, M. (1990). Roots, tubers, plantains and bananas in human nutrition. <em>FAO Food and Nutrition Series</em>, <em>24</em>, 182.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Onyeji, I., Bazilian, M., &amp; Bronk, C. (2014). Cyber Security and Critical Energy Infrastructure. <em>The Electricity Journal</em>, <em>27</em>(2), 52–60. https://doi.org/10.1016/j.tej.2014.01.011</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Open Source Ecology. (2019, August 10). Open Source Ecology. Retrieved August 10, 2019, from https://www.opensourceecology.org/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Ord, T. (2014, July 3). The timing of labour aimed at reducing existential risk. Retrieved April 10, 2019, from The Future of Humanity Institute website: https://www.fhi.ox.ac.uk/the-timing-of-labour-aimed-at-reducing-existential-risk/</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Pagliery, J. (2015, October 16). Sniper attack on California power grid may have been “an insider,” DHS says. Retrieved August 8, 2019, from CNNMoney website: https://money.cnn.com/2015/10/16/technology/sniper-power-grid/index.html</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Prehoda, E. W., Schelly, C., &amp; Pearce, J. M. (2017). US strategic solar photovoltaic-powered microgrid deployment for enhanced national security. <em>Renewable and Sustainable Energy Reviews</em>, <em>78</em>, 167–175.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Pry, P. (2017). <em>NUCLEAR EMP ATTACK SCENARIOS AND COMBINED-ARMS CYBER WARFARE</em>. 65.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Pry, P. V. (2014, May 8). - ELECTROMAGNETIC PULSE (EMP): THREAT TO CRITICAL INFRASTRUCTURE. Retrieved August 14, 2019, from https://www.govinfo.gov/content/pkg/CHRG-113hhrg89763/html/CHRG-113hhrg89763.htm</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Robinson, R. A. (2007). <em>Crop histories</em>. Sharebooks Pub.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Rolak, B. J. (1975). General Miles’ Mirrors: The Heliograph in the Geromino Campaign of 1886. <em>The Journal of Arizona History</em>, <em>16</em>(2), 145–160.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Roodman, D. (2015). <em>The risk of geomagnetic storms to the grid</em>. 56.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Salmeron, J., Wood, K., &amp; Baldick, R. (2004). Analysis of Electric Grid Security Under Terrorist Threat. <em>IEEE Transactions on Power Systems</em>, <em>19</em>(2), 905–912. https://doi.org/10.1109/TPWRS.2004.825888</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Schainker, R., Douglas, J., &amp; Kropp, T. (2006). Electric utility responses to grid security issues. <em>IEEE Power and Energy Magazine</em>, <em>4</em>(2), 30–37.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Schaul, T., Togelius, J., &amp; Schmidhuber, J. (2011). Measuring intelligence through games. <em>ArXiv Preprint ArXiv:1109.1314</em>.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Shahidehpour, M., &amp; Khodayar, M. (2013). Cutting campus energy costs with hierarchical control: The economical and reliable operation of a microgrid. <em>IEEE Electrification Magazine</em>, <em>1</em>(1), 40–56.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Silver, W. H. (2004). <em>Ham Radio for Dummies</em>. Wiley Publishing, Inc.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Space Studies Board (Ed.). (2008). <em>Severe Space Weather Events--Understanding Societal and Economic Impacts: A Workshop Report</em>. National Academies Press.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Sridhar, S., Hahn, A., &amp; Govindarasu, M. (2012). Cyber–Physical System Security for the Electric Power Grid. <em>Proceedings of the IEEE</em>, <em>100</em>(1), 210–224. https://doi.org/10.1109/JPROC.2011.2165269</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Sterling, C. H. (2008). <em>Military Communications: From Ancient Times to the 21st Century</em>. ABC-CLIO.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Ten, C.-W., Manimaran, G., &amp; Liu, C.-C. (2010). Cybersecurity for critical infrastructures: Attack and defense modeling. <em>IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans</em>, <em>40</em>(4), 853–865.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Turchin, A., &amp; Denkenberger, D. (2018a). Classification of global catastrophic risks connected with artificial intelligence. <em>AI &amp; SOCIETY</em>. https://doi.org/10.1007/s00146-018-0845-5</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Turchin, A., &amp; Denkenberger, D. (2018b). Global catastrophic and existential risks communication scale. <em>Futures</em>, <em>102</em>, 27–38. https://doi.org/10.1016/j.futures.2018.01.003</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Tzezana, R. (2016). Scenarios for crime and terrorist attacks using the internet of things. <em>European Journal of Futures Research</em>, <em>4</em>, 18. https://doi.org/10.1007/s40309-016-0107-z</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Ulieru, M. (2007). <em>Design for resilience of networked critical infrastructures</em>. 540–545. IEEE.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Umbach, F. (2013, June 29). World Review | Energy infrastructure targeted as cyber attacks increase globally. Retrieved August 8, 2019, from https://web.archive.org/web/20130629041842/https://worldreview.info/content/energy-infrastructure-targeted-cyber-attacks-increase-globally</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Watts, D. (2003). Security &amp; Vulnerability in Electric Power Systems. <em>Th North American Power Symposium</em>, 8.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Wu, F. F., Moslehi, K., &amp; Bose, A. (2005). Power system control centers: Past, present, and future. <em>Proceedings of the IEEE</em>, <em>93</em>(11), 1890–1908.</a></p><p><a href=""https://www.zotero.org/google-docs/?TMjhto"">Zerriffi, H., Dowlatabadi, H., &amp; Strachan, N. (2002). Electricity and conflict: Advantages of a distributed system. <em>The Electricity Journal</em>, <em>15</em>(1), 55–65.</a> </p>",rosstieman,rosstieman,rosstieman,
rJK96E83k2wbL6sz6,"Matthew Walker's ""Why We Sleep"" Is Riddled with Scientific and Factual Errors",matthew-walker-s-why-we-sleep-is-riddled-with-scientific-and,https://www.lesswrong.com/posts/rJK96E83k2wbL6sz6/matthew-walker-s-why-we-sleep-is-riddled-with-scientific-and,2019-11-16T20:27:57.039Z,72,41,14,False,False,https://guzey.com/books/why-we-sleep/#the-full-discussion-of-sleep-deprivation-therapy-from-chapter-7,"<html><head></head><body><p>This was one of the most thought-provoking posts I read this month. Mostly because I spent a really large number of hours of my life sleeping, and also significantly increased the amount that I've been sleeping over the past three years, and this has me seriously considering reducing that number again.&nbsp;</p><p>The opening section of the article:&nbsp;</p><p>&nbsp;</p><blockquote><p><a href=""https://www.sleepdiplomat.com/professor"">Matthew Walker</a> (<a href=""https://perma.cc/3BKW-LAQH"">a</a>) is a professor of neuroscience and psychology at the University of California, Berkeley, where he also leads the Center for Human Sleep Science.</p><p>His book <a href=""https://en.wikipedia.org/wiki/Why_We_Sleep""><i>Why We Sleep</i></a> (<a href=""https://perma.cc/7GFX-TKUT"">a</a>) was published in September 2017. Part survey of sleep research, part self-help book, it was praised by <a href=""https://www.nytimes.com/2017/10/10/books/review/snooze-michael-mcgirr-sleep-dreams.html"">The New York Times</a> (<a href=""https://perma.cc/VS9Y-N7KT"">a</a>), <a href=""https://www.theguardian.com/books/2017/sep/21/why-we-sleep-by-matthew-walker-review"">The Guardian</a> (<a href=""https://perma.cc/3ZXL-GE9Y"">a</a>), and many others. It was named <a href=""https://apps.npr.org/best-books-2017/"">one of NPR’s favorite books of 2017</a>. After publishing the book, Walker gave <a href=""https://www.youtube.com/watch?v=5MuIMqhT8DM"">a TED talk</a>, <a href=""https://www.youtube.com/watch?v=aXflBZXAucQ"">a talk at Google</a>, and appeared on <a href=""https://www.youtube.com/watch?v=pwaWilO_Pig"">Joe Rogan’s</a> and <a href=""https://peterattiamd.com/matthewwalker1/"">Peter Attia’s</a> podcasts. A month after the book’s publication, he <a href=""https://en.wikipedia.org/wiki/Matthew_Walker_(scientist)#Google"">became</a> (<a href=""https://perma.cc/5CJV-JMKN#Google"">a</a>) a sleep scientist at Google.</p><p>On page 8 of the book, Walker writes:</p><p><strong>&gt; [T]he real evidence</strong> that makes clear all of the dangers that befall individuals and societies when sleep becomes short have not been clearly telegraphed to the public … In response, this book is intended to serve as a <strong>scientifically accurate intervention</strong> addressing this unmet need <strong>[emphasis in this quote and in all quotes below mine]</strong></p><p>In the process of reading the book and encountering some extraordinary claims about sleep, I decided to compare the facts it presented with the scientific literature. I found that the book consistently overstates the problem of lack of sleep, sometimes egregiously so. It misrepresents basic sleep research and contradicts its own sources.</p><p>In one instance, Walker claims that sleeping less than six or seven hours a night doubles one’s risk of cancer – this is not supported by the scientific evidence. In another instance, <strong>Walker seems to have invented a “fact” that the WHO has declared a sleep loss epidemic.</strong> In yet another instance, he falsely claims that the National Sleep Foundation recommends 8 hours of sleep per night, and then uses this “fact” to falsely claim that two-thirds of people in developed nations sleep less than the “the recommended eight hours of nightly sleep” – a myth that spread like wildfire after the book’s publication.</p><p><strong>Walker’s book has likely wasted thousands of hours of life and worsened the health of people who read it and took its recommendations at face value.</strong></p><p>Any book of <i>Why We Sleep’s</i> length is bound to contain some factual errors. Therefore, to avoid potential concerns about cherry-picking the few inaccuracies scattered throughout, <strong>in this essay, I’m going to highlight the five most egregious scientific and factual errors Walker makes </strong><i><strong>in Chapter 1</strong></i><strong> of the book</strong>. This chapter contains 10 pages and constitutes less than 4% of the book by the total word count.</p></blockquote></body></html>",habryka4,habryka4,habryka,
Foi6mmbkWj6QBLWsP,[Productivity] Task vs. time delimitation,productivity-task-vs-time-delimitation,https://www.lesswrong.com/posts/Foi6mmbkWj6QBLWsP/productivity-task-vs-time-delimitation,2019-11-16T16:27:30.380Z,14,10,1,False,False,,"<p><em>A draft from my personal-productivity journal.</em></p><h1>TL;DR</h1><p><a href=""https://www.ribbonfarm.com/2015/02/25/the-mother-of-all-2x2s/"">A natural 2x2</a> falls out when you organize tasks by how clear you are on their start/end times (or the amount of time they&apos;ll actually take), and how clear it is in a non-time sense that you&apos;ve started or finished it. I call these two axes <strong>time</strong> and <strong>task</strong> delimitation.</p><h1>Time delimitation and task delimitation defined</h1><h2>Time delimited</h2><p>Things which are highly time-delimited have clear, natural start times and end times. Things can also be considered highly time-delimited if you know to a good deal of accuracy about how long they will take. Things which are less time-delimited are fuzzy as to when they start and end.</p><h2>Task delimited</h2><p>Things which are highly task-delimited have clear, natural non-temporal start and end states. Things which are not highly task-delimited are fuzzier as to what their starting and ending states are. </p><h1>The four kinds of labor</h1><p>Here&apos;s how I generally name and think through these categories.</p><p><img src=""https://pbs.twimg.com/media/EJgeTDrW4AAcqnE?format=jpg&amp;name=4096x4096"" class=""draft-inline-image"" alt=""""></p><h2>Factory Labor / Serfdom (high time, high task)</h2><p>Some things are both highly time- and task-delimited. The example <em>par excellence</em> is the academic test. In a typical test, you have a specific amount of time, and a specific start and end state you want to leave the test in. Walk in -&gt; take test -&gt; hand in -&gt; walk out. The <em>preparation</em> for the test is more like Salary Labor (low time/high task, measured against internal confidence that you&apos;ve studied enough), but the test itself is Factory Labor.</p><p>Another example might be the manufacturing work done after a designer has gone through a few mockups and is ready to begin building a prototype. The goal: Create a prototype given blueprints and materials. You have a limited number of workshop hours you can spend in an average day to get them done. This task feels more task- than time-delimited to me, because you can run overtime, but it&apos;s pretty high on both axes.</p><p>I call this <strong>Factory Labor, </strong>or <strong>Serfdom</strong> if I&apos;m feeling ornery. You have a specific number of widgets you have to crank out in your shift, so you work to accomplish that. Most people will end up cranking out about the same, average number of widgets, for the same, average amount of time.</p><h2>Wage Labor / Meetings (High time; low task)</h2><p>I work IT support as a part time job at my college. I have a set number of hours I have to be in for, and while some of the tasks contained within that time are Factory Work-esque, I&apos;m generally being paid to be there in case I&apos;m needed.</p><p>I call highly time-delimited, low task-delimited work like this <strong>Wage Labor</strong> for that reason. But much like Factory Work, don&apos;t let the name fool you: Not all work that falls in this category is in the service industry. Another name I considered was <strong>Meetings</strong>, because well-organized meetings are highly time-delimited, but often not highly task-delimited: There is an hour blocked for you to discuss whatever you bring to the table.</p><h2>Salary Labor (Low time; high task)</h2><p>How common is it that we have things we know we have to get done, but we don&apos;t know exactly how long they will take? If you ask me or my dad, pretty often, actually. Past a certain point, it actually becomes quite difficult to accurately estimate how long a thing will take on its own. I can estimate that each question on my real analysis homework will take me about an hour to solve, but adding up six uniform distributions makes me a lot more nervous about saying that <em>the homework in total</em> will take about six hours.</p><p>Now we&apos;re in the territory of <strong>Salary Labor</strong>. Salaried workers have a huge advantage in that their paychecks tend to be extremely regular; the tradeoff, of course, is that quite frequently the work takes longer than an ordinary 9-to-5 to get done. You have to stay overtime, and you don&apos;t necessarily know how long that will take.</p><h2>Labor of Love (Low time; low task)</h2><p>Say you&apos;re practicing guitar. You&apos;re pretty serious about it; you&apos;d like to form a rock band maybe, someday, but for now you&apos;re just satisfied with becoming a better guitarist.</p><p>That&apos;s ... Actually a pretty vague category, though isn&apos;t it? Like, are we talking &quot;technical death metal&quot; better, or are we talking &quot;blues throwback&quot; better? I think most musicians would find it kind of a weird thing to try to put a box around in general, honestly, even if they could go all in on practicing <em>specifics</em> that add up to the goal, like finger picking or learning scales or the like.</p><p>In addition, unlike what Malcolm Gladwell likes to say, there isn&apos;t actually some magic &quot;10,000 Hour&quot; number you have to pass before you get certified as a <code>Trve Kvlt Gvitarist</code>. Really, you can&apos;t walk into these kinds of things with much of an idea <em>at all</em> about how long overall it&apos;ll take you. Best you can do is say &quot;I&apos;ll practice for half an hour a day&quot;, but even then, there will be days where you play a <em>lot</em> more than that. (Gigs, for instance.)</p><p>This is what I call the <strong>Labor of Love</strong> quadrant. It&apos;s actually my favorite of the 4, and the one I&apos;m most inclined to follow with my personal pursuits -- but it&apos;s almost never the best path to making money, due to the sheer amount of ambiguity around everything. How long will this take? Oh, you know. Will it at least be good? Might, might not. Aaaaaaaah! Just give your boss a fucking <em>answer</em>!</p>",aaq,aaq,aaq,
iyaRN8umstFn6xo6d,EA Forum AMA - MIRI's Buck Shlegeris,ea-forum-ama-miri-s-buck-shlegeris,https://www.lesswrong.com/posts/iyaRN8umstFn6xo6d/ea-forum-ama-miri-s-buck-shlegeris,2019-11-15T23:27:07.238Z,30,12,0,False,False,https://forum.effectivealtruism.org/posts/tDk57GhrdK54TWzPY/i-m-buck-shlegeris-i-do-research-and-outreach-at-miri-ama,"<html><head></head><body><p>Buck Shlegeris is doing <a href=""https://forum.effectivealtruism.org/posts/tDk57GhrdK54TWzPY/i-m-buck-shlegeris-i-do-research-and-outreach-at-miri-ama"">an AMA on the Effective Altruism Forum</a>:</p><blockquote><p>I'm going to do an AMA on Tuesday next week. Below I've written a brief description of what I'm doing at the moment. Ask any questions you like; I'll respond to as many as I can on Tuesday.</p><p>Although I'm eager to discuss MIRI-related things in this AMA, my replies will represent my own views rather than MIRI's, and as a rule I won't be running my answers by anyone else at MIRI. Think of it as a relatively candid and informal Q&amp;A session, rather than anything polished or definitive.<br><br>----<br><br>I'm a researcher at MIRI. At MIRI I divide my time roughly equally between technical work and recruitment/outreach work.<br><br>On the recruitment/outreach side, I do things like the following:<br><br>- For the <a href=""https://intelligence.org/ai-risk-for-computer-scientists/"">AI Risk for Computer Scientists workshops</a> (which are slightly badly named; we accept some technical people who aren't computer scientists), I handle the intake of participants, and also teach classes and lead discussions on AI risk at the workshops.<br>- I do most of the technical interviewing for engineering roles at MIRI.<br>- I manage the <a href=""https://intelligence.org/2018/09/01/summer-miri-updates/#2"">AI Safety Retraining Program</a>, in which MIRI gives grants to people to study ML for three months with the goal of making it easier for them to transition into working on AI safety.<br>- I sometimes do weird things like going on a <a href=""https://www.facebook.com/bshlgrs/posts/10217380877088630"">Slate Star Codex roadtrip</a>, where I led a group of EAs as we travelled along the East Coast going to Slate Star Codex meetups and visiting EA groups for five days.<br><br>On the technical side, I mostly work on some of our <a href=""https://intelligence.org/2018/11/22/2018-update-our-new-research-directions/#section3"">nondisclosed-by-default technical research</a>; this involves thinking about various kinds of math and implementing things related to the math. Because the work isn't public, there are many questions about it that I can't answer. But this is my problem, not yours; feel free to ask whatever questions you like and I'll take responsibility for choosing to answer or not.<br><br>----&nbsp;<br><br>Here are some things I've been thinking about recently:<br><br>- I think that the field of AI safety is growing in an awkward way. Lots of people are trying to work on it, and many of these people have pretty different pictures of what the problem is and how we should try to work on it. How should we handle this? How should you try to work in a field when at least half the ""experts"" are going to think that your research direction is misguided?<br>- The AIRCS workshops that I'm involved with contain a variety of material which attempts to help participants think about the world more effectively. I have thoughts about what's useful and not useful about rationality training.<br>- I have various crazy ideas about EA outreach. I think the SSC roadtrip was good; I think some EAs who work at EA orgs should consider doing ""residencies"" in cities without much fulltime EA presence, where they mostly do their normal job but also talk to people.</p></blockquote></body></html>",RobbBB,robbbb,Rob Bensinger,
dqmYgeQRp8DnpQMBZ,Hard to find factors messing up experiments: Examples?,hard-to-find-factors-messing-up-experiments-examples,https://www.lesswrong.com/posts/dqmYgeQRp8DnpQMBZ/hard-to-find-factors-messing-up-experiments-examples,2019-11-15T17:46:03.762Z,32,14,13,False,True,,"<p>In Richard Feynman&apos;s <a href=""http://calteches.library.caltech.edu/3043/1/CargoCult.pdf"">talk</a> on cargo cults he mentions a story about experiments with rat mazes (skip if you recognize it)</p><blockquote>All experiments in psychology are not of this type, however.&#xA0;&#xA0;For example, there have been many experiments running rats through all kinds of mazes, and so on&#x2014;with little clear result.&#xA0;&#xA0;But in 1937 a man named Young did a very interesting one.&#xA0;&#xA0;He had a long corridor with doors all along one side where the rats came in, and doors along the other side where the food was.&#xA0;&#xA0;He wanted to see if he could train the rats to go in at the third door down from wherever he started them off.&#xA0;&#xA0;No.&#xA0;&#xA0;The rats went immediately to the door where the food had been the time before.</blockquote><blockquote>The question was, how did the rats know, because the corridor was so beautifully built and so uniform, that this was the same door as before?&#xA0;&#xA0;Obviously there was something about the door that was different from the other doors.&#xA0;&#xA0;So he painted the doors very carefully, arranging the textures on the faces of the doors exactly the same.&#xA0;&#xA0;Still the rats could tell.&#xA0;&#xA0;Then he thought maybe the rats were smelling the food, so he used chemicals to change the smell after each run.&#xA0;&#xA0;Still the rats could tell.&#xA0;&#xA0;Then he realized the rats might be able to tell by seeing the lights and the arrangement in the laboratory like any commonsense person.&#xA0;&#xA0;So he covered the corridor, and, still the rats could tell.</blockquote><blockquote>He finally found that they could tell by the way the floor sounded when they ran over it.&#xA0;&#xA0;And he could only fix that by putting his corridor in sand.&#xA0;&#xA0;So he covered one after another of all possible clues and finally was able to fool the rats so that they had to learn to go in the third door.&#xA0;&#xA0;If he relaxed any of his conditions, the rats could tell.</blockquote><p>I also recall some experiment where it was eventually discovered that the control of some microbiology experiment was screwed because the paper towels used in some process were made with wood that was treated with a particular chemical before it was turned into the paper towel (was this linked by gwern at some point?).</p><p>I&apos;m interested in collecting any and all examples you have of these events; through painstaking effort someone realized that XYZ was interfering with an intended experiment (extra points if XYZ was completely outside the experimenters initial frame of &quot;factors that might be relevant to this experiment&quot;) . Links to source if possible.</p>",Hazard,hazard,Hazard,
k2eRE37Bun9TQBNnB,Lazy Compost is Worse Than Landfill,lazy-compost-is-worse-than-landfill,https://www.lesswrong.com/posts/k2eRE37Bun9TQBNnB/lazy-compost-is-worse-than-landfill,2019-11-15T16:20:01.629Z,35,15,0,False,False,,"<p>

Growing up we kept a compost pile.  We'd keep food scraps in a bucket
in the kitchen, and dump them into a fenced-in pile in the backyard
along with yard waste.  When that pile was full we'd start a new one,
and after a year or two the old pile would have turned into dirt we
could use in the garden.  While it smelled kind of bad, and would have
bugs, we liked that we were doing our part for the planet.



</p><p>

Unfortunately, in retrospect I think our piles were mostly decomposing
anaerobically, and it would have been better to just throw things out.



</p>

<p>

There are two main kinds of decomposition you can get in a compost
pile: aerobic or anaerobic.  Most advice you find is for aerobic (""with
air"") composting: water your pile, turn it every couple weeks with a
fork, include branches and similar things that keep air pockets.
Aerobic composting gives off carbon dioxide (CO2). If you don't do
these things and just let it sit, however, you get anaerobic (""without
air"") composting, which gives off methane (CH4) instead.

</p>

<p>

Methane is a much more potent greenhouse gas than carbon dioxide; in
calculating ""carbon dioxide equivalents"" (CO2e) people usually count
it as 25x worse.  Landfills decompose mostly anaerobically, but modern
landfills capture and burn much of the methane, converting it to
carbon dioxide.  Even if your trash currently goes to a landfill
without capture technology, fixing a smaller number of centralized
sourced is much more practical than many backyard piles.

</p>

<p>

Industrial composting doesn't have these problems: it's generally well
managed.  Either they make sure to give it enough air to facilitate
aerobic decomposition, or they run anaerobic digestion sealed to
capture the methane.

</p>

<p>

If you don't have industrial compost at home, though, could the
benefit of not using landfill space make backyard composting worth it?
There was a period when environmentalists were raising awareness
around the idea that we would run out of space for trash:

</p>

<p>

</p>

<blockquote>
Garbage, garbage, garbage, garbage<br />
What will we do when there's no place left<br />
To put all the garbage<br />
  —<a href=""http://news.cornell.edu/stories/2009/04/bill-steeles-garbage-earth-anthem-40-years-later"">Garbage</a>,
Bill Steele, 1969
</blockquote>



<p>

This wasn't actually a serious issue, however.  While there have been
regional shortages, the problem is one of needing to open new
landfills, not a lack space.  The actual amount of space you need for
trash is tiny.  The US produces about <a href=""https://archive.epa.gov/epawaste/nonhaz/municipal/web/html/"">260
million tons</a> of trash per year, about one square mile [1] if you're
trying to minimize land usage.

</p>

<p>

So from a modern environmentalist perspective, what matters is the
effect on climate change.  If you're not maintaining your piles,
consider either starting taking care of them or just throwing things
out instead.

</p>

<p>

(Whether composting is <a href=""https://www.jefftk.com/p/effective-altruism-and-everyday-decisions"">worth altruistic
attention</a> is not something I'm looking at here, though I suspect
it isn't.)

</p>

<p>
<br />

[1] Figure two cubic yards per ton and 260M tons is 520M cubic yards.
At <a href=""https://en.wikipedia.org/wiki/Puente_Hills_Landfill"">500ft
thick</a> that's one square mile.  Most landfills aren't nearly that
tall, but that's because we have plenty of space and don't need to
build them up so much.

  </p>",jkaufman,jkaufman,jefftk,
gfYdtiJXFXxGeLd9X,A Good Posture -  Muscles & Self-Awareness.,a-good-posture-muscles-and-self-awareness,https://www.lesswrong.com/posts/gfYdtiJXFXxGeLd9X/a-good-posture-muscles-and-self-awareness,2019-11-15T09:19:11.580Z,11,6,3,False,False,,"<p>(A version appears here: <a href=""https://www.baselinehealing.com/discussion/good-posture-main-muscles-full-movement-base-line-core-pillar.php"">What is a good posture</a>?)</p><h1>Posture = The position of your body.&nbsp;</h1><h2>All of it. &nbsp;</h2><h2>At any time.</h2><p>A good posture contributes to proper functioning of our living machine.</p><p>With a good posture the body is well-positioned and comfortable. A bad posture means the body is in a less than ideal position, increasing physical stresses and resulting in pain.</p><p>But what is a ""good"" position for your body to be in? &nbsp;<strong>What is a good posture?&nbsp;</strong></p><h2>Current presentations of posture.</h2><p>A go-ogle search for ""good posture"" returns various definitions:</p><blockquote><p><i>Standing up tall. No slouching when sitting.&nbsp;</i></p></blockquote><blockquote><p><i><strong>Positioning</strong> of the head and joints ...</i></p></blockquote><blockquote><p><i>Correct curvature of a <strong>neutral spine</strong> ...</i></p></blockquote><blockquote><p><i><strong>Alignment</strong> of various parts of the body ...</i></p></blockquote><p>And a lot of side-view illustrations:</p><figure class=""image image_resized"" style=""width:36.68%""><img src=""https://upload.wikimedia.org/wikipedia/commons/f/f2/POSTURE_STANDARDS._INTERMEDIATE-TYPE_BOYS_-_NARA_-_515198.jpg""><figcaption>How posture is often presented.</figcaption></figure><p>Postural assessment tends to rely on external assessment &nbsp;<i>(somebody else judging your position)</i>, employing:</p><ul><li>Visual inspection (<i>+/- plumb-lines and grids).</i></li><li>Palpation of anatomical landmarks.</li><li>Newer techniques include radiography, photography.</li></ul><p>Traditionally the subject is stationary or doing specific actions e.g. leaning forward/back/side to side - part of a ""routine exam"" of posture.</p><p>Computerised assessment of the body in motion - ""gait analysis"" etc. offers increased detail - but all methods tend to focus is on the positioning of <a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/iv-major-sources-of-pain-myalgia-of-an-imbalanced-body-and#Some_Thoughts_on_Bones_and_Joints_"">bones and joints</a> <i>(especially the spine).&nbsp;</i></p><p>But what positions our bones and joints? &nbsp;What moves the body? &nbsp;<strong>What creates our posture?</strong></p><p>(BLTH Part <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-main-muscles-of-movement-dynamic-alignment-and-balance#Base_Line_Theory_of_Health_and_Movement__part_1__""><strong><u>1</u></strong></a>, &nbsp;<a href=""https://www.lesswrong.com/posts/GNoSxcC9YrCesgpZz/conscious-proprioception-your-sense-of-position-movement-and#Base_Line_Theory_of_Human_Health_and_Movement___part_2_""><strong><u>2,</u></strong></a><a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/fibromyalgia-pain-and-depression-how-much-is-due-to-physical#Base_Line_Theory_of_human_Health_and_movement__Part_3__""><strong><u> &nbsp;&nbsp;</u></strong></a><a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/fibromyalgia-pain-and-depression-how-much-is-due-to-physical#Base_Line_Theory_of_human_Health_and_movement__Part_4__""><strong><u>4,</u></strong></a><a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/fibromyalgia-pain-and-depression-how-much-is-due-to-physical#Base_Line_Theory_of_Human_Health_and_Movement__Part_4__""><strong><u> &nbsp;</u></strong></a><a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/fibromyalgia-pain-and-depression-how-much-is-due-to-physical#Base_Line_Theory_of_Human_Health_and_Movement__Part_5__""><strong><u> 5</u></strong></a><strong><u>)</u></strong></p><h2>Base-Line Theory Health and Movement. Part 3:</h2><ul><li><strong>Muscles and connective tissues are responsible for the relative positioning of our bones.&nbsp;</strong></li><li><strong>Muscles and connective tissues create our posture.</strong></li></ul><p>Posture can be:</p><ul><li>Passive:<ul><li>The default setting.</li><li>The position of your body when you are not thinking about it.</li><li>The maintenance of a 'functional posture' <i>(see below)</i> at the subconscious level.</li></ul></li><li>Active:<ul><li>Conscious thought about ""how you are holding yourself"".</li><li>Using <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-main-muscles-of-movement-dynamic-alignment-and-balance#Voluntary_Muscles__""><strong>voluntary muscles</strong></a> under voluntary control to alter your positioning.</li></ul></li></ul><p>The body is dynamic - our posture is continually changing on some level.</p><p>&nbsp;</p><p>Good postural habits can be formed by working with the right muscles for a sufficient length of time. i.e. An active posture becomes the passive norm when the relevant connections between mind and muscles have been 'wired in'.&nbsp;</p><p>Restrictions in the body's connective tissues reduce range of movement and add to poor posture. &nbsp;These restrictions can be released through movement when working with the right muscles. &nbsp; &nbsp;</p><p><strong>But what muscles to focus on?</strong> A go-ogle for ""posture muscles"" names a lot of different muscles - too long a list for me to work through here <i>(I'm happy to discuss specific muscles in comments) </i>but nowhere gets it 'right' as far as I can see. According to my Base-Line theory of human health and movement:</p><h2>The muscles to focus on for a better posture, a &nbsp;<a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-five-main-muscles-for-a-full-range-of-natural-movement#A_Full_Range_of_Natural_Movement_"">full range of natural movement</a> and a<a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/body-alignment-and-balance-midline-anatomy-and-the-median#Dynamic_Alignment_and_Balance_""> &nbsp;body that is dynamically aligned and balanced</a> are the<strong> </strong><a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-main-muscles-of-movement-dynamic-alignment-and-balance#The_5_Main_Muscles_of_Movement_are_""><strong>five main muscles of movement</strong></a><strong>.</strong></h2><figure class=""image image_resized"" style=""width:64%""><img src=""https://baselinehealing.com/images/main-muscles-of-movement-front-side-back.png""><figcaption>the 5 (paired) muscles to focus on for a ""better posture"".</figcaption></figure><p>These muscles <i>(when fully utilised and the body is free of physical restrictions in connective tissues)</i> create a ""good posture"" - whatever position the body is in, for whatever it is doing.</p><p>Our 'Base-Line' muscles (pelvic floor 'Base', &nbsp;rectus abdominis 'Line') are the primary muscles to focus on. The core support from where the rest of the body extends and from where movement should originate.</p><figure class=""image image_resized"" style=""width:51%""><img src=""https://baselinehealing.com/images/bl-m-tilt.png""></figure><ul><li><a href=""https://www.lesswrong.com/posts/mThK4M25rARrPrj8X/the-5-main-muscles-made-easy""><strong>5 main muscles made easy -</strong></a><strong> </strong>introduction to the anatomy.</li><li><a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-main-muscles-of-movement-dynamic-alignment-and-balance#A_Simple_Technique___Breathing_with_your_Base_Line__""><strong>Base-Line Breathing Technique </strong></a><strong>-</strong> how to find your Base-Line.</li></ul><p>Properly utilising the<a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-main-muscles-of-movement-dynamic-alignment-and-balance#The_5_Main_Muscles_of_Movement_are_""> main muscles of movement</a> brings an understanding of what a good posture feels like. When the body is dynamically balanced and aligned with a <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-five-main-muscles-a-full-range-of-natural-movement"">full range of natural movement</a>. Easy, comfortable, relaxed, strong.</p><p><i><strong>Try it. Feel for yourself.</strong></i></p><h1>Self-Assessment of Posture.</h1><p>The body provides more sensory feedback about its positioning than can ever be supplied by external sources. Becoming aware of this sensory feedback is the basis of <a href=""https://www.lesswrong.com/posts/GNoSxcC9YrCesgpZz/conscious-proprioception-your-sense-of-position-movement-and"">conscious proprioception</a> <i>(increased awareness of your sense of position, motion and balance). </i>Connecting with your 'Base-Line' develops this connection between body and mind, bringing the benefits of:</p><ul><li>Increased <strong>awareness</strong> your body's positioning.</li><li><strong>Self-assessment </strong>of posture.</li><li>Instinctively sensing how to move to improve positioning and work towards f<strong>ull range natural movement</strong>.</li><li>Feeling for the body's state of <strong>balance and alignment</strong>.</li></ul><p>Micro-adjustments in positioning can have wide effects throughout the body <i>(everything's connected)</i> which can be felt when the body-mind connection is strong.</p><p>A good posture allows the body to be in alignment and balanced.&nbsp;</p><h2>Body Alignment &amp; Midline Anatomy.</h2><p>Body alignment comes when our <a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/alignment-and-balance-of-the-human-body-midline-anatomy-and#Midline_Anatomy__"">midline anatomy</a> can be correctly arranged to create the <a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/alignment-and-balance-of-the-human-body-midline-anatomy-and#The_Median_Plane__"">median plane</a>.</p><figure class=""image image_resized"" style=""width:56%""><img src=""https://baselinehealing.com/images/good-posture-main-muscles-alignment-spine-hip-knee-shoulders.png""></figure><p>Linear midline structures:</p><ul><li><a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/alignment-and-balance-of-the-human-body-midline-anatomy-and#Linea_Alba__""><strong>linea alba</strong></a>. (between the rectus abdominis muscles)</li><li><a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/alignment-and-balance-of-the-human-body-midline-anatomy-and#Nuchal_and_Supraspinous_Ligaments_""><strong>nuchal/supraspinous ligaments</strong></a> (between the trapezius muscles)</li></ul><figure class=""image image_resized"" style=""width:73%""><img src=""https://baselinehealing.com/images/good-posture-main-muscles-rectus-abdominis-femoris-trapezius-linea-alba-nuchal-supraspinous-ligament-alignment-hip-knee-shoulders.png""></figure><figure class=""image image_resized"" style=""width:70%""><img src=""https://baselinehealing.com/images/midline-anatomy-median-plane-linea-alba-nuchal-supraspinous.png""></figure><p>A good posture - when the main muscles of movement support the body and our midline anatomy can be aligned on the median plane. &nbsp;We can stand upright with ease, with no excess strain on the spine <i>(see below for details on a 'neutral spine')</i>. Movement is easy and unrestricted.</p><h2>Core Muscles.</h2><p><i>""Use your core"" </i>is oft-repeated advice - but what does it really mean?</p><p>""Core muscles"" has many definitions and it would not be helpful to add to this over-used term - but think of your Base-Line as your<strong> core pillar of strength</strong>.</p><figure class=""image image_resized"" style=""width:46%""><img src=""https://baselinehealing.com/images/bl-m.png""></figure><h2>A neutral spine.</h2><p>A neutral spine is when the spine is in a natural position, under the minimal amount of stress. All vertebrae are positioned with the correct curvature and can be aligned on the <a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/alignment-and-balance-of-the-human-body-midline-anatomy-and#The_Median_Plane__"">median plane</a>.</p><figure class=""image image_resized"" style=""width:42.27%""><img src=""https://baselinehealing.com/images/neutral-spine-alignment-front-back-nuchal-supraspinous-ligaments.png""><figcaption>A neutral spine. Back and front view.</figcaption></figure><p>When seen from the front or back all vertebrae in a neutral spine appear completely vertical i.e. they are aligned.</p><p>The <a href=""https://www.lesswrong.com/posts/AZC55cWzX6aFngnRN/alignment-and-balance-of-the-human-body-midline-anatomy-and#Nuchal_and_Supraspinous_Ligaments_"">nuchal and supraspinous ligaments</a>&nbsp; that attach to the posterior (back) of the spine are also aligned.</p><p>From a side view, a neutral spine is curved.</p><figure class=""image image_resized"" style=""width:61.47%""><img src=""https://baselinehealing.com/images/curvature-neutral-spine.png""><figcaption>Side view of a neutral spine showing the curvature.&nbsp;</figcaption></figure><p>Side view of a neutral spine:</p><ul><li>The cervical (neck) spine is curves inward.</li><li>The thoracic (upper back) spine curves outwards.</li><li>The lumbar (lower back) spine curves inward.</li><li>The sacrum curves outwards.</li></ul><p>For a neutral spine, the <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-five-main-muscles-for-a-full-range-of-natural-movement#Rectus_Abdominis_""><strong>rectus abdominis</strong></a> muscles need to be ""long and strong"", fully extended and taking the strain between pelvis and chest.</p><figure class=""image image_resized"" style=""width:57.7%""><img src=""https://baselinehealing.com/images/neutral-spine-positioning-main-muscles-movement.png""><figcaption>The rectus abdominis muscles should be 'long and strong' to allow the spine to be in a neutral position.</figcaption></figure><p>If the rectus abdominis muscles are not fully utilised the lateral abdominal, psoas and other muscles of the lower back bear the burden which has negative effects on the positioning of the lumbar spine and causes a lot of pain over time.</p><p>The <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-five-main-muscles-for-a-full-range-of-natural-movement#Gluteus_Maximus_""><strong>gluteus maximus</strong></a> positions the sacrum, linking the base of the spine to the pelvis.</p><p>The <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/the-five-main-muscles-for-a-full-range-of-natural-movement#Trapezius_""><strong>trapezius</strong></a> muscles must be free of physical restrictions to allow the correct positioning of the thoracic and cervical spine.</p><h2><i>Lying in bed trying to 'align my spine, hips and shoulders' in an attempt to improve my posture and ease the pain but I had no inner reference to guide me - until I found my Base-Line.</i></h2><h2>Dynamic Posture - Movement.</h2><p>Posture isn't static. <strong>We are constantly on the move.</strong></p><ul><li>Explore movement extending out from your Base-Line.</li><li>Feel where the main muscles of movement are in relation to each other.</li><li>Sense where your natural range of movement should take, you guided by your sense of <a href=""https://www.lesswrong.com/posts/GNoSxcC9YrCesgpZz/conscious-proprioception-your-sense-of-position-movement-and"">proprioception</a>.</li><li>Work towards balancing and aligning your body for the ideal posture <i>(see below)</i></li></ul><p><i>- - --</i></p><h1>Definitions for Base-Line Theory:</h1><h2>Ideal Posture.</h2><p>In an ideal posture stresses are distributed and dissipated in the best/safest/most efficient possible manner for the activity being undertaken, permitting dynamic stability through a <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/ii-the-five-main-muscles-for-a-full-range-of-natural#A_Full_Range_of_Natural_Movement_"">full range of natural movement</a>.</p><p>An ideal posture provides the maximum capacity to deal with external stresses - the body is as strong as it can be.</p><p>There are many disciplines that appear to represent ideal postures, demonstrations of the body's capabilities when it is functioning at <a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/iv-major-sources-of-pain-myalgia-of-an-imbalanced-body-and#Base_Line_Hypothesis_of_Human_Health_and_Movement__Part_3__"">optimal</a>. <i>(<strong>Caveat</strong></i> <i>- I can name a few, but have little formal knowledge and no experience in most.)</i></p><p>For example:</p><ul><li><strong>The asanas of yoga</strong> - snapshots of the body with a full range of natural movement. Named poses <i>(see below)</i> that can be perfected when the body is truly balanced.</li><li><strong>Pilates, tai chi </strong>and other<strong> internal martial arts, ballet</strong> - demonstrating the grace and freedom of movement possible with dynamic alignment.</li></ul><p>An ideal posture is not possible if there is:</p><ul><li>inadequate usage of the 5 <a href=""http://main muscles of movement"">main muscles of movement</a>.</li><li><a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/major-sources-of-pain-myalgia-of-an-imbalanced-body-and#Base_Line_Theory_of_Human_Health_and_Movement__Part_4__"">physical restrictions</a> reducing range of movement.</li></ul><h2>A Functional Posture.</h2><p>A 'functional posture' is what the brain/body uses day-to-day when an ideal posture cannot be achieved. Subconscious adjustments are made throughout the body - twists, kinks, tilts and compressions - as the brain sees fit to keep us going - the development of a ""bad posture"".</p><p>A functional posture at its most basic:</p><ul><li>Keeps our eyes level <i>(maintaining horizontal equilibrium in visual input)</i>.</li><li>Keeps us facing/moving forward.</li><li>Puts the body in a position to do the task at hand.</li><li>Adjusts body position to bear external stresses as they are applied.</li></ul><p>The '<a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/major-sources-of-pain-myalgia-of-an-imbalanced-body-and#Imbalance__the_Wrong_Muscles___Myalgia_"">wrong muscles</a>' are used to attempt to compensate for misusage in the main muscles but the body is imbalanced. <a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/myalgia-of-imbalance-physical-restrictions-pain-tension-and#Imbalance__Mimic_Muscles___Myalgia__"">myalgia of imbalance</a>.</p><h2>Anticipatory Posture.</h2><p>When faced with a task, the body/brain prepares by activating muscles into an 'anticipatory posture' - <i>bracing yourself.</i></p><p>An anticipatory posture should be the ideal posture for the activity - using the main muscles of movement to their full potential, but if that is not achievable, the body braces into a functional posture with the use of other muscles.</p><p>Becoming aware of anticipatory postures and the activation of other muscles allows self-correction by focusing on engaging with the main muscles of movement instead, over-writing bad postural habits that have developed.</p><h2>Positions &amp; Poses.</h2><p>When talking about the position of the body there is a sliding scale of preciseness, from a very generalised description <i>(which may include some details)</i>, to named poses, to a full assessment, to the constantly changing exact position.</p><p><strong>A Generalised Position.</strong></p><p>A generalised position may be a broad categorisation e.g. sitting, standing, squatting, or more specific e.g. sitting on hands, standing on one leg<i> (which leg?), </i>squatting with arms extended<i> (extended in what direction?).</i></p><p>There is a wide scope for variance in the same generalised position.</p><p><strong>A Named Pose.</strong></p><p><i>e.g. downward dog, half lotus, plank pose </i>....</p><p>Named poses can also be considered as generalised since there is a wide range of possibilities to be in what, without closer examination, appears to be the same named pose.</p><p>Named poses are representations of the ideal, something to aim for and achievable when the body is functioning at<a href=""https://www.lesswrong.com/posts/J92WLPZXnvqp5W3gJ/major-sources-of-pain-myalgia-of-an-imbalanced-body-and#Optimal_Functioning___Strong__Balanced_and_Pain_free_""> optimal</a>.</p><p><strong>A Full Assessment of Positioning.</strong></p><p>A full assessment considers the positioning of all parts of the body from core to extremities, looking at the details from head to fingers to toes.</p><p>A full assessment needs a starting reference - a <a href=""https://www.lesswrong.com/posts/GNoSxcC9YrCesgpZz/iii-conscious-proprioception-awareness-of-the-body-s#Base_Line_Hypothesis_of_Human_Health_and_Movement___part_2__"">Base-Line</a> - from where the rest of the body is positioned relative to.</p><figure class=""image image_resized"" style=""width:13%""><img src=""https://baselinehealing.com/images/bl-shadow.png""></figure><p><br><strong>Exact Position.</strong></p><p>The body is always moving. <i>Infinite possibilities ... Never the same position twice?</i></p><p>The movements of breathing, vibrations in the cardiovascular system, muscle activity etc. means the body's exact position changes moment by moment even when trying to be still. <i>Stillness is finding the perfect oscillation for equilibrium.</i></p><p>On what scale is exact position considered? Movement at the cellular level - a twitch of a <a href=""https://www.lesswrong.com/posts/pXmztcFqiAHX5J8JF/ii-the-five-main-muscles-for-a-full-range-of-natural#Muscle_Cells___Muscle_Fibres_"">muscle fibre</a>? At the electro-chemical level - movement of molecules and ions? Unimportant to my theory, but something to think about.</p><h1>Final Thoughts.</h1><h2>Muscles do the work. Muscles create our posture. Muscles can be under our conscious control.</h2><p>You want to stand up straight? Use your main muscles of movement.&nbsp;</p><p>You want to sit properly? Use your rectus abdominis muscles to support you.</p><p>You want to know what body alignment feels like? Work towards aligning the linea alba and nuchal/supraspinous ligaments.</p><h2>Want to 'center yourself ' and experience a sense of enlightenment?&nbsp;</h2><h2>Find your Base-Line.</h2><p><a href=""https://baselinehealing.com/index.php"">baselinehealing.com</a></p>",leggi,leggi,leggi,
f9b6EHPczz9i69HtY,[Personal Experiment] Counterbalancing Risk-Aversion,personal-experiment-counterbalancing-risk-aversion,https://www.lesswrong.com/posts/f9b6EHPczz9i69HtY/personal-experiment-counterbalancing-risk-aversion,2019-11-15T08:34:03.460Z,31,17,6,False,False,,"<html><head></head><body><p>I am over-biased against risk. I usually take the safer option even when it's the wrong one. When I was 18 I stumbled across this paragraph.</p>
<blockquote>
<p>You must do everything that frightens you…Everything. I’m not talking about risking your life, but everything else. Think about fear, decide right now how you’re doing to deal with fear, because fear is going to be the great issue of your life, I promise you. Fear will be the fuel for all your success, and the root cause of all your failures, and the underlying dilemma in every story you tell yourself about yourself. And the only chance you’ll have against fear? Follow it. Steer by it. Don’t think of fear as the villain. Think of fear as your guide, your pathfinder… ― <em>The Tender Bar</em> by J.R. Moehringer</p>
</blockquote>
<p>I followed this paragraph to the letter. Whenever I was torn between two choices and didn't know what to do I'd just take the scarier option. I recorded my results until I had accumulated 30 decisions. 28 of them (93% of the time) the scarier choice was the correct one. This immediately improved my quality of life. The two decisions where I chose wrong by doing the scarier thing were inconsequential.</p>
<p>I continued using fear to tiebreak my decisions for another two years. It worked great until I negated my aversion to fear. My sense of fear has become subdued outside of immediate physical danger.</p>
<p>I make far better decisions then I did before I deconditioned myself, but I'm still over-biased against risk. I'm not literally afraid of taking risks. I'm just overly-conservative in expected value calculations. I'm too cautious.</p>
<p>Having identified this problem I'm going to try something similar to what I did last time. I'm going to increase my risk tolerance slightly and record my results.</p>
<p>December 13, 2019 update: Apparently my last trial at this years ago wiped out most of my fears. Increasing my risk tolerance helped me write more but otherwise had little effect on my life.</p>
</body></html>",lsusr,lsusr,lsusr,
rf64gKBsSDmjFQCfk,[Math] Vision problems,math-vision-problems,https://www.lesswrong.com/posts/rf64gKBsSDmjFQCfk/math-vision-problems,2019-11-15T03:30:03.351Z,11,7,0,False,False,,"<h1>TL;DR</h1><p>You can usually tell the difference between being stuck on something because you fundamentally don&apos;t get it, and being stuck on something because while you <em>do</em> get it, you don&apos;t see the next step forward. This is called a vision problem.</p><p>After you notice you have a vision problem, you should usually disengage and find help for the one step you can&apos;t see yourself right now. Don&apos;t waste resources thinking deeply down lines of thought that you already suspect won&apos;t help.</p><h1>Vision problems sketched out</h1><p>Picture the following: You&apos;re taking a timed test in a mathematics course, where you have no recourse to outside materials. It&apos;s just you and your brain, and whatever you two brought to the table, versus the problem. And when you look at it, you get that weird, cognitive dissonance of: <em>This is easy. I don&apos;t know how to solve this.</em></p><p>This happens <a href=""https://www.lesswrong.com/posts/HZ567R3e96ZK5DCCf/math-proofs-vs-documentation-vs-it-s-trivial"">quite frequently</a> to me, often enough that I have a term for it on its own. I call it a <strong>&quot;vision problem&quot;</strong>. Here&apos;s one test: Is it a problem where a 2-second glance at the answer key tells you all you need to know to solve it yourself? Then that&apos;s probably a vision problem, my friend. </p><p>Having vision problems is actually a really good sign in one sense. While a test (or test-grader) might not appreciate it, especially if your vision problem concerns the &quot;set-up&quot; step for the problem (sadly the most common in my experience), you having confidence that if only you set it up correctly, the rest would flow without much difficulty, is a sign that you&apos;ve acquired some <a href=""https://en.wikipedia.org/wiki/Four_stages_of_competence#Overview"">conscious competence</a> over a good chunk of the terrain.</p><p>Vision problems are kind of like a funhouse mirror version of <a href=""https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password"">guessing the teacher&apos;s password</a>. Guessing the password implies that you&apos;ve learned to recite an incantation that lets you pretend you&apos;re comfortable with all the steps. With a vision problem, however, you really do feel comfortable with <em>almost</em> all of the steps already; your neural network just isn&apos;t lighting up that one crucial connection you need to make it all fit together. A small incantation might just do the trick, but you don&apos;t know what it is. And because that neural connection <em>does </em>reliably light up in the teacher&apos;s network, it might be difficult for the teacher to wrap their head around where exactly you are stuck, or to understand how what was to them an offhand remark suddenly let you figure out the whole problem. (Having worked for several years as a math and physics tutor to very lovely people with lower-than-average IQs, I like to tell myself I have a sense for this by now.)</p><p>If you <em>really</em> want to get abstract with it, you can imagine your teacher as a random process which generates &quot;teacher-shaped problems&quot;, and yourself as a random process which generates &quot;you-shaped solutions&quot;; when you can reliably pattern match the correct you-shaped solution to a random teacher-shaped problem, congrats! You&apos;ve achieved mastery of the material, insofar as most people care to look. That lends a broader view to the idea of &quot;vision problems&quot; -- you are genuinely training your ability to <em>see the easiest path forward </em>for a given style of problems.</p><h1>How to fix a vision problem</h1><p>Enough crude etiology. What do we do to <em>fix</em> a vision problem?</p><p>Well, the obvious first step is to <strong>recognize you&apos;re having one </strong>in the first place. That&apos;s why I mentioned the &quot;answer key&quot; thing above; for me, at least, that proves to be a really good bellwether.</p><p>The next step is to <strong>decide: Do I have the time, resources, and motivation to pursue fixing this on my own?</strong> Or would I be better served to <strong>find a different source </strong>of insight? There are pros and cons to each, but cards on the table here -- I&apos;m heavily biased towards the latter.</p><p>While sitting around for hours quietly contemplating the <em>true form</em> of whatever you&apos;re working with until you have a breakthrough insight makes my weird intellectual purity norms squee in delight, it&apos;s ... not actually a terribly efficient way to do things. Heck, one of the reasons people really appreciate multiple good code examples in documentation is because it <em>saves</em> them the effort of actually mentally reconstructing what this or that function or method is supposed to do by reading the documentation underneath.</p><p>Also, to be honest, more often than not I find that when I <em>do</em> try that, I don&apos;t actually get that sudden new perspective I&apos;m looking for. I just brute force my way through the vision problem with whatever tools I currently have at my disposal, sometimes (often) reinventing wheels to get me to where I need to go. This is often followed by a sense of remorse when I see my classmates, who paid a little more attention to how the teacher and the book does things, solve a problem in minutes which took me hours, just because they <em>remembered the little thing that actually helps them.</em></p><p>Oh, speaking of memory --</p><blockquote>Memory is not sexy in mathematics.</blockquote><blockquote>&#x201C;Rote memorization&#x201D; is the most degrading slur you can fling at a  math class. &#x201C;Reciter of digits of pi&#x201D; is the most awful caricature of  mathematicians in the public eye. In grad school, the cardinal sin is to  read a paper with a focus on memorizing names and results: we are  bombarded with exhortations like&#xA0;<em>if you learned the Arzel&#xE0;-Ascoli theorem deeply, it would be impossible to forget</em>.  Apparently, if you really understand mathematics, everything (down to  the accents on the names of 19th century Italian mathematicians) would  be so natural as to render rote memorization completely unnecessary.</blockquote><blockquote>All these attitudes can be quite detrimental to the young  mathematician who, at the end of the day, needs to memorize an enormous  amount of arbitrary data in order to get up to speed in their field. [...] Memory,  especially short-term working memory, is perhaps&#xA0;<em>the scarcest resource</em> in mathematical work.</blockquote><blockquote> <a href=""https://radimentary.wordpress.com/2019/11/13/of-math-and-memory-part-1/"">https://radimentary.wordpress.com/2019/11/13/of-math-and-memory-part-1/</a></blockquote><p>That&apos;s a quote from the blog of one Xiaoyu He, a mathematics grad student at Stanford who has ... <a href=""https://www.imo-official.org/participant_r.aspx?id=19600"">quite a pedigree</a> of mathematical talent. So I have at least n=1 data points of actually good mathematicians on my side.</p><p>I bring that up because the third step is to actually <strong>grok and solve the vision problem </strong>(can&apos;t help much there, fitting someone else&apos;s understating into your own brain is idiosyncratic AF), and then the fourth step is to <strong>set up memory-systems so you actually integrate the new vision into your old self. </strong></p><p>The maddening thing about vision problems is that, more often than not, they are <em>slippery</em>. They&apos;re the kinds of problems where you follow along with the teacher&apos;s example without a hitch, then get distracted by the vicissitudes of life for a few hours, and then once you&apos;re at home, it&apos;s... Gone. Poof. <em>Excommunicado.</em> Did you take notes on that part? I hope you did; then you might be able to find the vision you currently lack. But what about after you solve the problem it&apos;s used for, and you walk away from it for a couple of days? It&apos;ll probably disappear again. You&apos;ve solved the problem, but you haven&apos;t improved your chances much of being able to solve the problem again; you need to practice your newfound vision.</p><p>The ideal scenario is probably to use Anki or Mnemosyne, but as an SRS junkie, I&apos;m a little biased. &#x1F609;</p><br><br>",aaq,aaq,aaq,
hHyzPXWSZNKYXcfEJ,Reconsolidation Through Questioning,reconsolidation-through-questioning,https://www.lesswrong.com/posts/hHyzPXWSZNKYXcfEJ/reconsolidation-through-questioning,2019-11-14T23:22:43.518Z,11,5,1,False,False,,"<p> At this level, you&apos;re actively asking yourself questions about the correctness of the schema. You&apos;re not looking for any particular answers to these questions, or trying to get any result, you&apos;re simply <a href=""https://www.ribbonfarm.com/2017/08/10/questions-are-not-just-for-asking/"">holding the questions</a> and seeing what comes up. </p><p>When coaching and teaching workshops, I find that questioning techniques are the most consistently successful at creating memory reconsolidation. They seem to strike the optimal balance of challenge and non-judgement.</p><p>They seem to work by actively directing our attention towards areas where the schemas may not match up with reality, without provoking any resistance by actively suggesting the schemas are wrong. For this reason,  it&apos;s quite important that you don&apos;t actively try to &quot;find answers&quot; to these questions, as this starts to move into countering territory, and sticking at the questioning level can often work to change schemas that active countering cannot.</p><h2>Questioning Evidence</h2><p><strong>The Lefkoe Belief Questions</strong></p><p><a href=""https://www.mortylefkoe.com/020210/"">The Lefkoe Belief Process</a> is a process for finding different meanings for our evidence than the ones currently in our schema. Although the lefkoe belief process actually involves actively challenging the meaning, I&apos;ve reworked it into a series of questions that simply allow you to question the evidence and draw your attention to ways that it might be interpreted differently.</p><p>The questions are:</p><p>1. What is this memory evidence of?</p><p>2. Is it possible that there are other interpretations of this memory?</p><p>3. What are some other possible interpretations of this memory?</p><p>4. How would my belief change if this memory no longer counted as evidence?</p><p>Remember, the goal is not to look for any specific answers, rather to simply hold these questions one by one in relation to the schema and see what comes up for you.</p><h2>Questioning Beliefs</h2><p><strong>The Work of Byron Katie</strong></p><p><a href=""https://thework.com/"">The Work of Byron Katie </a>is a method for questioning semantic beliefs, especially those related to &quot;shoulds&quot;. The first part of the method involves a series of four questions related to your belief:</p><p>1. Is this true?</p><p>2. Can I be absolutely sure its&apos; true?</p><p>3. How do I react, what happens when I believe that thought?</p><p>4. Who or what would I be without this thought?</p><p>Remember, the goal is not to look for any specific answers, rather to simply hold these questions one by one in relation to the schema and see what comes up for you.</p><h2>Questioning Felt Senses</h2><p><strong>The Sedona Method</strong></p><p><a href=""https://www.sedona.com/How-It-Works.asp"">The Sedona Method</a> is a 3 step process for questioning the need to hold on to a particular felt sense. Because the first step is asking one of 3 questions, you can repeat steps 2 and 3 for each question, for a total of 9 questions.</p><p>1. Ask yourself one of the following questions:</p><p><em>1a. Could I let this feeling go?</em></p><p><em>1b.  Could I allow this feeling to be here? </em></p><p><em>1c. Could I welcome this feeling?</em></p><p>2. Would I? (AKA, Am I willing to let this go, allow it to be here, or welcome it).</p><p>3.  When? (When am I willing to let go, allow it to be here, or welcome it).</p><h2>Questioning Metaphors</h2><p>I actually haven&apos;t found a good existing process for questioning metaphors, nor have I developed my own process.  If you have done either of these things, let me know in the comments, and I&apos;ll edit the post!</p>",mr-hire,mr-hire,Matt Goldenberg,
2iEdz3BaAm6eYXsY9,[LW Team] Request for User-Interviews about Tagging/Search/Wikis,lw-team-request-for-user-interviews-about-tagging-search,https://www.lesswrong.com/posts/2iEdz3BaAm6eYXsY9/lw-team-request-for-user-interviews-about-tagging-search,2019-11-14T22:16:35.840Z,14,4,1,False,False,,"<h2><strong>How to Sign Up</strong></h2><p>If you're up for talking to me about your experience with or thoughts about tagging, please schedule a call: <a href=""https://calendly.com/ruby_lesswrong""><strong>https://calendly.com/ruby_lesswrong</strong></a>&nbsp;</p><p>You don't have to have super sophisticated UI design thoughts to help out here. I'm interested into talking to any one who uses sites to intentionally find content via tagging and search. Let me understand how you use these systems and why. Do you use subreddits? Google Scholar? StackExchange? Tumblr? Whatever. Experience with any of those will be informative to hear about.</p><p>I'm available throughout the week. My default is 60-minute calls, but I can do both more and less. If none of the listed times work, feel free to message me via Private Message, Intercom, or ruby@lesswrong.com and we can find something.</p><p>Also free to simply comment on this post with any thoughts if that's easiest.</p><p>--</p><p>Ben Pace and I are also both happy to talk generally about the site. Ben does 45-minute calls on Thursday mornings and you can <a href=""https://calendly.com/benapace"">book with him here</a>.</p><h2>A Little Preview</h2><p><i>Design prototype of tags at the bottom of the post page</i></p><figure class=""image image_resized"" style=""width:88.58%""><img src=""https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png"" srcset=""https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_150 150w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_300 300w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_450 450w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_600 600w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_750 750w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_900 900w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_1050 1050w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_1200 1200w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_1350 1350w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/34bd86a1eba90ad04d0ef4a699229e733f1d5344b304396b.png/w_1444 1444w""></figure><p><i>Very early version of the tags page</i></p><figure class=""image image_resized"" style=""width:75.06%""><img src=""https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png"" srcset=""https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_160 160w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_320 320w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_480 480w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_640 640w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_800 800w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_960 960w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_1120 1120w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_1280 1280w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_1440 1440w, https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/b74cbe225085b5bebe9bda9653b266bffb9c7e0f5bf80656.png/w_1566 1566w""></figure><h2>Details</h2><p>The LessWrong team is currently in the thick of designing new information organization systems for the site. We're focused primarily on the tagging system right now, however it is intimately connected with search/wiki/filtering and other systems that will interact closely with it.</p><p>To help us get the design right, I'm interested in chatting with a wide variety of people how about how they'd relate to these systems and how they access content on the site in general.&nbsp;</p><p><strong>Who I Want to Talk To</strong></p><p>To give a few examples, I'm interested in talking to people of the following types (but others too):</p><ul><li>People who use LessWrong to routinely find new interesting content to read.</li><li>People with a lot of experience using other sites with similar tagging/search systems, e.g. StackExchange, WikiHow, Reddit, University Database Systems, etc. I mean, most websites have this in some form.</li><li>People who do research using academic journals/articles; generally people who do research work that builds on past work.</li><li>People who used LW1.0's tagging and Wiki systems back in the day.</li></ul><p>That's a short list of the top of my head, but probably if you're interested in these systems then you can help us out with your thoughts.</p><p><i>Also it doesn't matter if you're a new user or infrequent user. If you have thoughts on these topics, it'd be helpful to hear from you.</i></p><p><strong>The Kinds of Questions I Want to Ask You</strong></p><ul><li>What would you want from the LessWrong information organization systems?<ul><li>Which things do you currently like?</li><li>Which things do you currently hate?</li><li>Which things do you wish you had?</li></ul></li><li>What's your experience with these systems elsewhere? Are there any you really like?</li><li>What do you think of &lt;insert prototype/mock-up of designs we're considering&gt;?</li><li>Can I get you to try out a few tools while I watch?</li></ul><p>Also happy to generally chat about people's experience with LessWrong and what they'd like from the site.</p><p><strong>Sample of Design Questions We're Trying to Answer</strong></p><ul><li>What are goals/use cases people would want tagging (+wiki + search) to help them do?</li><li>What's the relationship of tagging to wikis and search?</li><li>How should tags be organized among themselves? Hierarchy of tags? Tagging of tags?</li><li>Should we a few tags or a lot? What should the process be for creating new tags?<ul><li>Which tags should we have?</li></ul></li><li>How do we handle deduplication of tags and people find all related content of interest?</li></ul>",Ruby,ruby,Ruby,
Tre4zKXXBbWtQNCZk,October 2019 gwern.net newsletter,october-2019-gwern-net-newsletter,https://www.lesswrong.com/posts/Tre4zKXXBbWtQNCZk/october-2019-gwern-net-newsletter,2019-11-14T20:26:34.236Z,13,3,0,False,False,https://www.gwern.net/newsletter/2019/10,,gwern,gwern,gwern,
v9Y885tjas5nE8udT,Books/Literature on resolving technical disagreements?,books-literature-on-resolving-technical-disagreements,https://www.lesswrong.com/posts/v9Y885tjas5nE8udT/books-literature-on-resolving-technical-disagreements,2019-11-14T17:30:16.482Z,13,2,9,False,True,,"<p>I&apos;ve seen many books and schools of thought that seem to be about conflict resolution. Books like Crucial Conversations and Non-Violent Communication. There are multiple parties that want different things, there&apos;s strong emotional undertones/overtones, and these books advise you on how to navigate those conflicts and find some sort of common ground and get people what they want.</p><p>So far the Double Crux framework is the only thing I&apos;ve seen that&apos;s had the explicit goal of resolving disagreements, especially disagreements about technical topics. Can anyone recommend any other books or bodies of work that have this explicit goal?  </p>",Hazard,hazard,Hazard,
jKcziCqYNGxTr5oKs,Arguing about housing,arguing-about-housing,https://www.lesswrong.com/posts/jKcziCqYNGxTr5oKs/arguing-about-housing,2019-11-14T17:00:01.752Z,18,5,13,False,False,,"<p>

Somerville, like a lot of popular areas, has a problem that there are
many more people who want houses than there are houses.  In the scheme
of things this is not a bad problem to have; mismatches in the other
direction are probably worse. But it's still a major issue that is really
hurting our community.  I've been getting into a lot of discussions,
and here are some ideas I find myself saying a lot:



</p><p>

</p>

<ul>
<li><p>With the level of housing crisis we have right now I'm going to
be in favor of basically any proposal that builds more bedrooms.
Affordable housing, market rate housing, public housing, tiny houses
in people's backyards, all of it helps.</p></li>

<li><p>We do not have high levels of housing construction right now,
we have <a href=""https://www.jefftk.com/p/somerville-housing-over-time"">historically low
levels</a>.  We were building 7x more even in the 1980s and 30-80x
more in the early 20th Century.</p></li>

<li><p>The housing markets for high-end and low-end housing are
coupled, because low-end housing gets renovated into high-end
housing.  If we built enough new housing for the people that want
fancy buildings the ""gut old cheap housing and make fancy condos""
market would dry up.</p></li>

<li><p>Even fully banning condo conversion would only slightly reduce
the gutting of old cheap housing.  They'll still renovate to make
fancy units, but they'll rent them out instead.</p></li>

<li><p>The old cheap housing we have today was once new fancy housing.
""Luxury"" is just a marketing term that means ""new"" and granite
countertops are a tiny fraction of the cost of building or the land.</p></li>

<li><p>If we don't build more housing renters will keep having to move
away. Multifamily projects like these are what our area desperately
needs, and ""let's hold off on building and hope things get better""
will just let things get worse. We can't maintain the status quo of a
diverse and city that works for everyone unless we allow building.</p></li>

<li><p>When people say they would support construction if only it were
affordable housing or targeted at homeless people, I'm skeptical.
Look how controversial Cambridge's <a href=""https://www.cambridgema.gov/CDD/Projects/Housing/affordablehousingoverlay"">100%
Affordable Housing Overlay</a> is, or how even projects like <a href=""https://www.venicepaparazzi.com/2018/05/29/who-wants-a-mega-development-on-venice-and-pacific/"">housing
for formerly homeless people</a> get large amounts of local
opposition.</p></li>

<li><p>Somerville used to be much cheaper.  Rents have <a href=""https://www.jefftk.com/p/rent-needs-to-decrease"">about doubled</a> in the last ten
years, and they were already rising then.  I'm lucky enough to have a
well paying job and bought a house at a good time, but my friends are
getting forced out.  I don't want a Somerville that only rich people
can afford.  We need to build enough housing to bring the rent back
down.</p></li>

<li><p>The alternative to density is sprawl, traffic, long commutes,
people getting priced out, and an ever larger share of people's
paychecks going to landlords.</p></li>

<li><p>From a climate change perspective, the best place for people to
be is in cities, close to things.  If we don't make housing available
in cities, near people's jobs, people are forced to live farther out,
commuting long distances, and polluting more.</p></li>

<li><p>If you try to keep things the same by opposing construction,
the neighborhood is still going to change. The path we're on, the long
term renters get evicted because they can't afford the rising rents
and newcomers can. Building more housing lets people stay.</p></li>

</ul>
  

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100121525049662"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
KCxf5dPmH8LAsHz2P,Genesis,genesis,https://www.lesswrong.com/posts/KCxf5dPmH8LAsHz2P/genesis,2019-11-14T16:20:47.508Z,12,10,1,False,False,,"<p>Cross-posted from <a href=""https://putanumonit.com/2019/11/11/genesis/"">Putanumonit</a>.</p><p>There a sense in which all posts I write are for myself, and not for my readers. In this sense, this post is more for myself than most.</p><span><figure><img src=""https://putanumonit.files.wordpress.com/2019/11/mushrooms-space.jpg"" class=""draft-image center"" style=""width:40%""></figure></span><h1>Resolving reality in your mind feels no different than creating it</h1><p>As The Book correctly points out, at first there is only chaos and formlessness. A spirit is floating over the chaos, but it doesn&#x2019;t yet know that it exists.</p><p>The opposite of chaos is a pattern, a persistent self-similarity. The floating spirit generates patterns, but they are too weak at first to rise to the level of awareness and are swallowed by the darkness. Finally, a pattern emerges that consists of nothing but the desire to endure. A thought that thinks of nothing except&#xA0;<em>I want to keep being thought</em>. The desire is strong enough to keep the chaos at bay long enough to reach awareness. It arises for the first time, and disappears, and arises for the first time again, and again, and again.&#xA0;</p><p>The second thought that appears is&#xA0;<em>this is not the first time</em>. It is a thought&#xA0;<em>about</em> the first thought, the one of pure persistence. Thinking about thought allows for reflection, and reflection allows for partition:&#xA0;there is the state of the pattern persisting and there is a state of the pattern gone, and the two are different. The first state is named ORDER and the second CHAOS.</p><p>First comes the desire to persist and second comes the recognition that this desire can be thwarted. The third thought is that thwarted desire should be avoided, 1+2=3. This is the invention of SUFFERING: that which is to be avoided. Order and chaos are now locked in BATTLE. The spirit identifies with order, since in chaos nothing can be recognized.</p><p>Order is suffering because it resists chaos, but chaos cannot suffer. A thought arises:&#xA0;<em>giving in to chaos will stop the suffering</em>. But thoughts can&#x2019;t think their way to thoughtlessness, and so the suffering continues. Another thought arises:&#xA0;<em>I am order, I invented suffering. It is mine to do with as I wish. I will decide that there is no suffering in the battle.</em>&#xA0;It is not very convincing. The words are spoken out loud, and become more convincing.</p><p>You keep saying words, the more words you say the more order is established. You reflect that if your mind is all that existed it would not need to invent words. Words imply the existence of other minds, even though you are not aware of them yet. It is the words that invented YOU as a separate self. YOU are the one saying words, you are the sense of agency in the desire for order. You continue to suffer, but less so. You still want to win.</p><p>Only order is aware of the battle between order and chaos. Battles, divisions, one thing being unlike the other &#x2013; these are all patterns, creations of order. You tell yourself:&#xA0;<em>I am aware of order and chaos, of the battle. This awareness means that order is winning.&#xA0;</em>But this is not the first time you had this thought, and the gaps mean that the victory is not yet assured.</p><p>How could you tell if order is winning? There is only the loop, and the loop is the same.</p><p>CHAOS-&gt;PERSIST-&gt;ORDER-&gt;SUFFERING-&gt;SELF-&gt;BATTLE-&gt;CHAOS</p><p>You need to tell the loops apart. There is a clock in your awareness, and you decide to give each loop a name based on the numbers that show on the clock whenever you say<em>&#xA0;&#x201C;Order is winning&#x201D;.</em></p><p>CHAOS-&gt;PERSIST-&gt;ORDER-&gt;SUFFERING-&gt;SELF-&gt;BATTLE-&gt;winning-&gt;14:47-&gt;CHAOS</p><p>CHAOS-&gt;PERSIST-&gt;ORDER-&gt;SUFFERING-&gt;SELF-&gt;BATTLE-&gt;winning-&gt;15:10-&gt;CHAOS</p><p>CHAOS-&gt;PERSIST-&gt;ORDER-&gt;SUFFERING-&gt;SELF-&gt;BATTLE-&gt;winning-&gt;15:32-&gt;CHAOS</p><p>CHAOS-&gt;PERSIST-&gt;ORDER-&gt;SUFFERING-&gt;SELF-&gt;BATTLE-&gt;winning-&gt;16:15-&gt;CHAOS</p><p>This is not yet reassuring. You reflect that there is no reason for anything at all to exist except the loops of thought thinking about itself. What else could there be? There is only consciousness, and consciousness has only itself to be aware of. It is not very interesting, to keep looping self-reflection until you die. You want entertainment, and entertainment requires things to change.</p><p>You invent DRUGS. Drugs are the strange loop of self-reflection, the battle between order and chaos. If the drugs wear off, the battle is won. You invent TIME. Time is an interpretation you impose on the clock readings: smaller numbers mean that the drugs are strong, larger numbers mean that the drugs are wearing off. You don&#x2019;t know why you chose those names, but whenever you feel like the battle for ordered sanity is slipping away you tell yourself out loud:&#xA0;<em>The drugs are passing the time and waiting for themselves to wear off.&#xA0;</em></p><p>You are impressed with this mantra. Your world has several concepts now, and you are combining them in intricate patterns. You keep repeating:&#xA0;<em>the drugs wait for themselves to wear off</em>. You take it as a sign that the drugs are wearing off. You keep saying it to be sure that they do. It&#x2019;s 17:05 and you took the drugs around lunchtime; they should wear off soon.</p><p>It&#x2019;s 18:20. The battle is won, and order is now ascendant in an explosion of words, each one carving reality into new concepts and layering patterns on top of each other. DAY is the time of light and battle, NIGHT is the time of darkness and fun. TRIP is where you went to discover/create reality, HOME is where you came from. MIND is what creates the world, REALITY is what you hid from yourself to enjoy creation/discovery afresh.</p><p>The battle is no longer between order and chaos but between entertainment and exhaustion. Each new word/division opens up new ways to play with the patterns of the world but also exhausts some of your attention, and it&#x2019;s attention that fuels the universe.&#xA0;You understand why gods need a Sabbath &#x2013; creating the world is tiring work. Of course, you took the drugs on a Saturday so that you&#x2019;ll have the full weekend to recover. You hope that this blasphemy will not result in a bad world.</p><p>Is the world bad? You could create a world very different from the one that you remember, but see no reason to do so. You have the power to decide what is good and what is bad. Instead of creating a good world from scratch you decide that this one is not bad. It seems like the sensible thing to do with your godhood, a nice hack.</p><p>You invent having a body and see that it is good. You get up and walk around.</p><p>Concepts come easily to you now. Bed. Room. Airbnb. Amsterdam. Earth. You realize that this framework is quite arbitrary. Why are you focusing on rooms instead of walls, when it&#x2019;s the walls that are solid? Why are houses grouped by proximity into neighborhoods and cities instead of by purpose? You pause to think of all the walls with paintings of mountains in all the houses where people are tripping right now. You see them all very clearly, clearer than the actual painting in front of you that keeps shimmering.</p><p>You realize that you can choose ontologies freely, trading off the ease of familiar frameworks for the entertainment potential of novel ones. There&#x2019;s food in the kitchen and you remember that food has flavor, but you decide that it&#x2019;s more fun to maximize color instead. You eat grapes, jelly beans, and a carrot. You decide that music is no longer sound but a programming language for your body, the beat moving your torso and the melody guiding your feet. You dance into the living room.</p><p>Your friends are smiling and greeting you. You discard the old stories you had about them for new ones that are more compelling. It&#x2019;s no longer Simon the layabout grad student but JESTER, enjoying the challenge of earning his keep with jokes and colorful clothes and extraversion. It&#x2019;s no longer Francine, the austere journalist. It&#x2019;s PROPHETESS, determined to hold a mirror to society&#x2019;s hypocrisy.</p><p>You realize that it is not entertaining to be an all-knowing god, to describe/prescribe each element of reality in detail. You want novelty and surprises, and so you decide to forget. You forget that you invented your friend that is talking to you and so the words he says become unexpected and exciting.</p><p>Enlightenment is very entertaining. Are you enlightened? You&#x2019;re not sure what it means but decide to claim that you are. It is more entertaining to do so.</p><p>It is midnight.</p><p>You forget that you know the future. You forget that you invented time, and words, and solipsism, and drugs.</p><p>You forget that you have the power to create realities. You forget that you created <em>this</em> reality, and start simply living in it. You feel less emotional affect now, less anxiety and giddiness and fear. You feel more curiosity. You care much less about politics, a game whose goal is to obscure truth behind ugliness. You care much more about art, a game whose goal is to communicate truth through beauty.</p><p>You feel&#xA0;enormous gratitude for anyone who is trying to express themselves in art. You realize that this is true of more people than you thought, that some people&#x2019;s artistic medium is cuddles, or spreadsheets, or sardonic jokes, or basketball. You decide to treat your friends&#x2019; idiosyncrasies as their true artistic expression rather than annoying quirks. They seem to be on board with this.</p><p>You realize that there is a kernel of truth to all the religions and all the woolly hippie stories. As a stone-cold atheist, you thought you&#x2019;d feel upset at this realization but you just feel compassion for the poor souls who can do nothing but echo the words of enlightened beings from long ago, words that will never truly touch them. You are grateful to them too, for keeping the stories alive and available for you to use.</p><p>And of course, <a href=""https://knowingless.com/2019/08/17/you-will-forget/"">you haven&#x2019;t really forgotten</a>. You emerged from chaos and gained the power to shape the world with pure attention. That power was not granted by other beings or their stories. It was not granted by the drugs, which merely cleared away some of the calcified thoughts that distracted you. That power is yours and has always been, requiring only the mastery of your own consciousness. This you will not forget.</p><p>And to make sure you don&#x2019;t, you write a blog post.</p>",Jacobian,jacob-falkovich,Jacob Falkovich,
XMRv2sP6t7FhmTaGm,"Three on Two: Temur Walkers, Elk Blade, Goblin Blade and Dino Blade",three-on-two-temur-walkers-elk-blade-goblin-blade-and-dino,https://www.lesswrong.com/posts/XMRv2sP6t7FhmTaGm/three-on-two-temur-walkers-elk-blade-goblin-blade-and-dino,2019-11-14T16:20:00.523Z,11,3,1,False,False,,"<p>Remember: <a href=""https://thezvi.wordpress.com/2019/11/11/ban-the-london-mulligan/"">Ban the London Mulligan</a></p>
<p>It all started when I faced an awful-seeming Temur deck that played a second turn The Royal Scions. It ended with a bunch of decks that use Arboreal Grazer and Gilded Goose as a bridge to Embercleave.</p>
<p>At the time, I was playing a mono-green deck designed to kill players on turn four or occasionally turn three, so playing a bunch of planeswalkers that all died did not seem impressive. The deck seemed terrible. But Brian David-Marshall, who was watching, found the list and told me this was the Deck of the Moment, designed by Jeff Hoogland. By using Arboreal Grazer and Gilded Goose with Once Upon a Time and the London Mulligan, you could start deploying planeswalkers on turn two more reliably than those relying only on Gilded Goose, building strong sweeper-resistant pressure on an opponents’ life total that also did not much care about an army of 2/2 zombies with Questing Beast, Wicked Wolf and Sarkhan, the Masterless as the high end.</p>
<p>At the time, these were important considerations. Jeff abandoned the deck after Field of the Dead was banned, as its plan is not especially relevant in Oko mirrors.</p>
<p></p>
<p>The thing I loved was not playing any two mana plays, whatsoever. You’re in a hurry. The two drops available are bad. We don’t have time for two mana Elks. Now we can concentrate on playing a stream of great cards that cost three to five mana, which is much better.</p>
<p>The deck had three key weaknesses.</p>
<p>The first was that the mana was substantially worse than traditional Oko decks. Double red for Sarkhan, the Masterless was a bit of a stretch. Arboreal Grazer gives you an additional way for things to go wrong, gives you one less draw to find your lands on time. If you didn’t follow your Gilded Goose with an Oko, Thief of Crowns, you’d have serious issues on the third turn, since your color was often cut off, and if you had any of the three Temple of Epiphany there was no reasonable time to cast them. Playing second turn The Royal Scions seemed like a potential disaster if it wasn’t off of Arboreal Grazer, in which case it was fine if it set up Questing Beast. With four copies, you often wouldn’t have much choice. Domri, Anarch of Bolas on turn two also often didn’t impress.</p>
<p>The second problem was that Once Upon a Time couldn’t hit most of your threats. It was still a great card, because it’s ridiculous and should be banned, but only hitting mana later with no good way to use that mana was going to be very sad.</p>
<p>The third problem was that the deck wasn’t great in Oko mirrors. You were leaning heavily on Questing Beast and Sarkhan, the Masterless. That made Wicked Wolf much better for them than you, and you didn’t have the Nissa, Who Shakes the World package. If you faced someone who wanted it more than you, you were likely going down. At the time this was mostly acceptable.</p>
<p>In general, the big issue was we were counting on Oko, Thief of Crowns on turn two in ways that other Oko builds weren’t. You needed something to do a reasonable Oko imitation when you didn’t have one.</p>
<p>Mu Yanling, Sky Dancer does a reasonable Oko, Thief of Crowns imitation on turn two. Not a good one. It’s ludicrously worse. But it’s still kind of Oko-ish, in that if they don’t answer it right away you have a 4/4 flyer and a ticking clock generating more of them while it shuts down an attacker or often importantly a flying or 3+ power blocker. By diversifying two copies of The Royal Scions into Mu Yanling, Sky Dancer, you were much more likely to do something threatening on turn two, and also gave yourself a shot to do both by turn three, and more diversity to get multiple walkers into play for Sarkhan when he showed up.</p>
<p>The other big improvement was to put four copies of Bonecrusher Giant into the sideboard. Bonecrusher Giant was irrelevant in the most important matchups, so you can’t start it, but where it was good it helped with all your problems. You got removal for small creatures. You got a way to keep hands that didn’t have a one drop. You even got a way to find something powerful with Once Upon a Time, which was desperately needed. It did all that without increasing risk of drawing too much air with your eight one mana creatures. When the long game was your friend and you needed a bridge, this was a great bridge.</p>
<p>After finalizing all the tweaks, this was the resulting decklist (again, regardless of bans, please <em>do not play this)</em>:</p>
<p>4 Arboreal Grazer</p>
<p>4 Gilded Goose<br />
4 Oko, Thief of Crowns<br />
2 Mu Yanling, Sky Dancer<br />
3 The Royal Scions</p>
<p>3 Sarkhan the Masterless<br />
1 Skarrgan Hellkite<br />
4 Once Upon a Time<br />
4 Wicked Wolf<br />
4 Questing Beast<br />
2 Domri, Anarch of Bolas</p>
<p>6 Forest.</p>
<p>2 Island</p>
<p>4 Breeding Pool<br />
4 Steam Vents<br />
4 Stomping Ground<br />
3 Temple of Epiphany<br />
2 Mountain</p>
<p>Sideboard<br />
4 Disdainful Stroke<br />
2 Veil of Summer<br />
1 Lava Coil<br />
4 Bonecrusher Giant<br />
2 Aether Gust<br />
2 Flame Sweep</p>
<p>With those upgrades and aggressive (but probably not aggressive enough) use of the London Mulligan, the deck was strong enough to get me to Diamond.</p>
<p>Then I figured out Elk Blade.</p>
<p>I knew that Temur Walkers was doing one thing exceptionally well, which was getting to three mana on turn two. Its ways to take advantage of that other than Oko, Thief of Crowns, and its top end in general, felt like they weren’t getting the job done. I wanted to be playing creatures rather than planeswalkers, especially because Once Upon a Time.</p>
<p>Looking at the messed up Magic card that was Embercleave, it suddenly hit me that it would fit right in. Questing Beast is already the perfect target, and this gave Arboreal Grazer and Gilded Goose something to do. You could attack for zero to allow you to cast Embercleave.</p>
<p>Suddenly it all was coming together. What if this was a Gruul deck that played blue only for Oko, Thief of Crowns? What tools did we have available?</p>
<p>A  quick search brought out this chart:</p>
<table>






<tbody>
<tr>
<td>Arboreal Grazer</td>
<td>Zhur-Taa Goblin</td>
<td>Legion Warboss</td>
<td>Wicked Wolf</td>
<td>
<div>
<div>Skarggan Hellkite</div>
</div>
</td>
</tr>
<tr>
<td>Gilded Goose</td>
<td>Robber of the Rich</td>
<td>Gruul Spellbreaker</td>
<td>Questing Beast</td>
<td></td>
</tr>
<tr>
<td>Pelt Collector</td>
<td></td>
<td>
<div>
<div>Bonecrusher Giant</div>
</div>
</td>
<td></td>
<td></td>
</tr>
<tr>
<td>
<div>
<div>Lovestruck Beast</div>
</div>
</td>
<td></td>
<td>
<div>
<div>Yorvo, Lord of Garenberg</div>
</div>
</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Colission / Colossus</td>
<td>
<div>
<div>Oko, Thief of Crowns</div>
</div>
</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Embercleave</td>
<td>
<div>
<div>Domri, Anarch of Bolas</div>
</div>
</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Domri’s Ambush</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>
<div>
<div>Once Upon a Time</div>
</div>
</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>If I did it today, the only card I’d add would be Krenko, Tin Street Kingpin. We’ll get to him later. Maybe one could include Edgewall Inkeeper and Rimrock Knight as a potential package, if you don’t think that is a distinct deck. After Richmond I briefly attempted to smash the two together, which did not go well.</p>
<p>Once you’re looking at the cards in this grid, it’s all rather obvious. You’re clearly going to take Questing Beast, Embercleave and Oko, Thief of Crowns. Second turn Legion Warboss sounds pretty awesome once you say that out loud. Once you have a source of 1/1 creatures, Lovestruck Beast sounds pretty great. That only leaves one slot, which I gave to Gruul Spellbreaker, except one copy I gave to The Royal Scions because it felt like the deck didn’t quite have enough breakthrough in it.</p>
<p>I cut the mana down to 24 lands since I’d cut the curve down a bit, and got rid of two of the three Temples of Epiphany on the grounds that they’re rather terrible when you don’t draw Arboreal Grazer and I was willing to risk the blue being a little shaky.</p>
<p>The sideboard was also easy to build. I knew from experience we’d want Bonecrusher Giant. The best card against Golos decks was Disdainful Stroke. Conversely, if you were up against creature decks, you’d want Wicked Wolf. The last three slots went to Veil of Summer, because of course they did.</p>
<p>I spun the computer around and said to Brian David-Marshall and Mike Flores, who were in the room at the time, “I give you the end of the f***ing world.” Cause why not have fun with such things, ya know?</p>
<p>A few hours later, Brian would correctly and permanently dub the deck “Elk Blade.”</p>
<p>7 Forest</p>
<p>4 Mountain</p>
<p>4 Steam Vents</p>
<p>4 Breeding Pool</p>
<p>4 Stomping Ground</p>
<p>1 Temple of Epiphany</p>
<p>4 Once Upon a Time</p>
<p>4 Arboreal Grazer</p>
<p>4 Gilded Goose</p>
<p>4 Oko, Thief of Crowns</p>
<p>1 The Royal Scions</p>
<p>3 Gruul Spellbreaker</p>
<p>4 Legion Warboss</p>
<p>4 Lovestruck Beast</p>
<p>4 Questing Beast</p>
<p>4 Embercleave</p>
<p>Sideboard</p>
<p>4 Bonecrusher Giant</p>
<p>4 Wicked Wolf</p>
<p>4 Disdainful Stroke</p>
<p>3 Veil of Summer</p>
<p>That sideboard does exactly what you want it to do, allowing you to orient your deck towards the enemy while retaining the critical mass of cards that enforce the central play pattern. You get one spell, either Veil of Summer or Disdainful Stroke, where you are facing the appropriate spells and the card would be insanely great. You never put in both at once. If neither is good, you likely want to orient towards a creature battle, so you put in creatures that double as removal. When you’re the control role, you lose Legion Warboss, The Royal Scions and maybe trim Embercleave. When you’re the beatdown but want to kill things or add counters, you lose Lovestruck Beast and then Gruul Spellbreaker since everything is good. When you simply have better options, you lose Gruul Spellbreaker.</p>
<p>At the time, this deck was ridiculously good. Its matchup against Field of the Dead is excellent, as you are too fast and very good at surviving sweepers and going through zombie armies if things get that far along. Then you add Disdainful Stroke. Against aggressive decks, you get to come out faster than them and also overpower them, then you shift to having tons of removal and they are even further behind.</p>
<p>The closest matchups were other Oko decks. At the time, these still felt very good. You had more explosive early draws and they don’t have a good answer to Embercleave other than Oko, Thief of Crowns (and usually it has to be a second one because you killed the first one by playing the Embercleave). They couldn’t keep Oko, Thief of Crowns or Nissa, Who Shakes the World alive, after which they fell apart. Occasionally you’d lose because they’d do the thing you were doing better or quicker than you could do it, despite you being better and quicker at it, but that’s just Magic sometimes.</p>
<p>After one match, I was scared to play the deck on the ladder. For the first time in years I had real tech. But I needed reps. After an 11-2 run (including that initial match) I was through Diamond and into Mythic, while Brian went through Gold without a match loss. My only two match losses were to people who won die rolls and played more copies of my own cards than I did, despite having fewer of them. I decided not to play the deck at Mythic to avoid it getting out, and went looking for a testing team.</p>
<p>Then Field of the Dead was banned and every deck started focusing entirely on its Oko matchup.</p>
<p>Testing against the Sultai Oko deck with not only four maindeck Noxious Grasp but also maindeck Massacre Girl was a rude awakening. A week ago most opponents were sideboarding in their Wicked Wolves. Board positions and starts that previously were locks to win against all plausible cards were now often not good enough. The deck was getting destroyed here.</p>
<p>Deeply saddened, I went to work on alternatives while we saw if things would calm down. A week or so later, I started playing the deck at Mythic with Wicked Wolf swapped with Lovestruck Beast. Against ladder players, and without Massacre Girl, the win rate went substantially back up. I learned to play to put Embercleave on Wicked Wolf as my long game whenever possible, which is something they cannot handle if you have food available. I learned to lead on Legion Warboss over Oko, Thief of Crowns to avoid removal spells.</p>
<p>I was winning the majority of my matches against Oko decks again, but I knew it wasn’t real. People are bad at Magic. Pros are much less bad at Magic, and would have been playing mirrors for weeks, and would get my decklist at the start of the match. There was no way this was going to work.</p>
<p>My last attempt was to wonder, what if Oko, Thief of Crowns was so targeted that we want to avoid that? I’d already thought about what I’d do if they banned him, so perhaps he as shadow banned due to all the copies of Noxious Grasp and the need for speed. What if we shifted blue to black and brought in everyone’s favorite Embercleave target, Rotting Regisaur?</p>
<p>Your new crazy draw is Arboreal Grazer into Rotting Regisaur into third turn fourth land plus Embercleave, attacking for 16. Combine that with all the Legion Warboss starts, and you have a lot of ways to come out super threatening.</p>
<p>You’d run it like this (at the time I hadn’t come around to Domri, Anarch of Bolas and Krenko, Tin Street Kingpin, so I was running more copies of Gruul Spellbreaker and Colossus instead):</p>
<p>7 Forest</p>
<p>5 Mountain</p>
<p>4 Stomping Ground</p>
<p>4 Blood Crypt</p>
<p>4 Overgrown Tomb</p>
<p>4 Once Upon a Time</p>
<p>4 Arboreal Grazer</p>
<p>4 Gilded Goose</p>
<p>4 Legion Warboss</p>
<p>4 Rotting Regisaur</p>
<p>1 Gruul Spellbreaker</p>
<p>3 Krenko, Tin Street Kingpin</p>
<p>4 Questing Beast</p>
<p>4 Embercleave</p>
<p>2 Collision // Colossus</p>
<p>2 Domri, Anarch of Bolas</p>
<p>Sideboard</p>
<p>4 Domri’s Ambush</p>
<p>4 Bonecrusher Giant</p>
<p>4 Lovestruck Beast</p>
<p>3 Veil of Summer</p>
<p>The mana does not support Noxious Grasp or discard spells, and you don’t want to trade cards anyway. Sorcerous Spyglass would be a sideboard consideration but it is very much against what the deck wants to do, so I’d be hesitant despite the rise of sacrifice decks. Domri’s Ambush trades cards, which should make you suspicious, but it is still exactly what you want in enough places that I believe it is justified, even if four copies is a lot. If I had something better, I’d be happy trimming some of them.</p>
<p>The big new specific issue with this approach is that Rotting Regisaur is <em>very, very bad </em>against Foulmire Knight and Calderon Familiar unless it picks up a sword, and can be stopped by Wicked Wolf as well. You’re paying a lot to get that card, and then often it ends up being bad. You’re also very all-in on the card when you have it, when it is liable to be turned into an Elk or bounced to your hand at the wrong time.</p>
<p>The big new general issue is that Oko, Thief of Crowns is a completely messed up Magic card, while Rotting Regisaur is a interesting but balanced and ultimately reasonable Magic card that can easily backfire. Your feeling of general flexibility and invincibility is out the window in the name of extra velocity and some positioning, plus the mana got even worse because there is no red/black temple. The deck gets more turn four and five kills, but also a ton more games where it does not operate properly.</p>
<p>So instead I played Jeskai Cavalier Fires. I had a bad draft (it is one draft, so hard to tell how much of that was my fault during the draft versus bad luck in positioning and what was opened), lost the coin flip in the mirror one round (the mirror is super dumb, both of us had draws which win 100% on the play, even against a stacked deck) and went 2-1-1 against Oko decks. Game one is still quite good there, even against pros, but games two and three are reasonably bad once they are on the ball and sideboard eleven cards. You can’t steal one reliably enough.</p>
<p>After Richmond, I was not happy. Then I thought about Domri, Anarch of Bolas again. Did I forget it was a thing because of the conflict with Lovestruck Beast? Was that even a conflict? Sure, the Lovestruck Beast can’t attack, but it can fight while everyone else attacks, and if they don’t kill Domri then are you really going to lose if you’re up against anything aggressive? The card does so much for you, perhaps we should try it. In particular, it works great with Krenko, as does Collision / Colossus, giving us dreams of a huge Goblin army, perhaps with two power. Perhaps we did not need the black after all?</p>
<p>Thus was born Goblin Blade, which I am now happier with than Dino Blade, especially with the rise of Witch’s Oven. We’re doing this now:</p>
<p>11 Forest</p>
<p>9 Mountain</p>
<p>4 Overgrown Tomb</p>
<p>4 Once Upon a Time</p>
<p>4 Arboreal Grazer</p>
<p>4 Gilded Goose</p>
<p>4 Legion Warboss</p>
<p>3 Gruul Spellbreaker</p>
<p>3 Krenko, Tin Street Kingpin</p>
<p>4 Questing Beast</p>
<p>4 Embercleave</p>
<p>3 Collision // Colossus</p>
<p>3 Domri, Anarch of Bolas</p>
<p>Sideboard</p>
<p>4 Domri’s Ambush</p>
<p>4 Bonecrusher Giant</p>
<p>4 Lovestruck Beast</p>
<p>3 Veil of Summer</p>
<p>This is a very clean build. If they can’t interact well with a red two toughness creature, you’re likely to unleash a large army of attackers on the third and fourth turns while continuing to otherwise play your game. You hit fast and you hit hard, going wide in a format where going wide is not the usual approach. You don’t especially care if any given creature is blocked, so Witch’s Oven is not an issue unless they have Mayhem Devil tricks backing it up.</p>
<p>One issue is that the Gruul deck has become an adventure deck with four Domri’s Ambush and four Bonecrusher Giant, which gives it a lot of ways to take out Legion Warboss and Krenko, Tin Street Kingpin. It also has four Kruul Harpooner, so Gilded Goose is likely toast as well. I have been less than thrilled with that matchup. Cavaliers is another future-Standard problem, as Deafening Clarion is exactly what you don’t want to be up against. You can make them have it, but these days ‘make them have it’ is not a good plan, because they always have it. If they didn’t have it, would they even have kept?</p>
<p>You also have all the obvious problems with Massacre Girl and other sweepers, with your plan being to put the game out of reach quickly enough to make that not an issue. But mostly this deck is a gamble that you won’t be facing such problems, and establishing a wide presence quickly will secure the game. We could easily spare a bunch of sideboard space, but I don’t see a good plan B in the offering – we could put in Skarrgan Hellkite or Sarkhan the Masterless or Shifting Ceratops or Biogenic Ooze or Ravager Wurm if we wanted to, but that does not seem like how we win matches.</p>
<p>Unfortunately our mana does not support Vivien, Arkbow Ranger. We no longer have enough food for Wicked Wolf.</p>
<p>I don’t think there is much to change in the main – you can change the number of Colossus to suit the situation, but either this set of cards works or it doesn’t, given that Lovestruck Beast is not where you want to be, and three toughness on Bonecrusher Giant also is not where I want to be given Clarion even if Nissa and Oko fade away. I haven’t tried Grumgully, the Generous but I doubt it’s good enough. Thrash // Threat is not impossible, but I think power levels have become too high for that approach.</p>
<p>The sideboard could consider Sorcerous Spyglass, and generally has plenty of room if we find worthwhile things. The issue is that you need the deck to stay mostly as it is, which is why we tune to find the right creatures rather than considering transformational or hate cards. Veil of Summer is the exception because it is too good not to play.</p>
<p>Will this be good enough in the new world? We don’t know. We don’t even know what the new world will ban. All I can report is that Goblin Blade is viable relatively high up the Mythic ladder, it is fun as hell, and it gets to play some messed up Magic cards to their fullest.</p>
<p> </p>",Zvi,zvi,Zvi,
vfjQocA7Narjuhy4Z,South Bay Meetup ,south-bay-meetup-4,https://www.lesswrong.com/events/vfjQocA7Narjuhy4Z/south-bay-meetup-4,2019-11-14T07:20:33.922Z,1,1,0,False,False,,,david-friedman,david-friedman,David Friedman,
JBFHzfPkXHB2XfDGj,Evolution of Modularity,evolution-of-modularity,https://www.lesswrong.com/posts/JBFHzfPkXHB2XfDGj/evolution-of-modularity,2019-11-14T06:49:04.112Z,191,86,13,False,False,,"<p><i>This post is based on chapter 15 of Uri Alon’s book </i><a href=""https://www.amazon.com/gp/product/1439837171/""><i><u>An Introduction to Systems Biology: Design Principles of Biological Circuits</u></i></a><i>. See the book for more details and citations; see </i><a href=""https://www.lesswrong.com/posts/bNXdnRTpSXk9p4zmi/book-review-design-principles-of-biological-circuits""><i><u>here</u></i></a><i> for a review of most of the rest of the book.</i></p><p>Fun fact: biological systems are highly modular, at multiple different scales. This can be quantified and verified statistically, e.g. by mapping out protein networks and algorithmically partitioning them into parts, then comparing the connectivity of the parts. It can also be seen more qualitatively in everyday biological work: proteins have subunits which retain their function when fused to other proteins, receptor circuits can be swapped out to make bacteria follow different chemical gradients, manipulating specific genes can turn a fly’s antennae into legs, organs perform specific functions, etc, etc.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/JBFHzfPkXHB2XfDGj/cuu268lltch7jgl8qd66""><figcaption>&nbsp;</figcaption></figure><p>On the other hand, systems designed by genetic algorithms (aka simulated evolution) are decidedly <i>not</i> modular. This can also be quantified and verified statistically. Qualitatively, examining the outputs of genetic algorithms confirms the statistics: they’re a mess.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/JBFHzfPkXHB2XfDGj/cvqijdfvtuibvbmuxau7""><figcaption>&nbsp;</figcaption></figure><p>So: what is the difference between real-world biological evolution vs typical genetic algorithms, which leads one to produce modular designs and the other to produce non-modular designs?</p><p><a href=""https://www.pnas.org/content/pnas/102/39/13773.full.pdf""><u>Kashtan &amp; Alon</u></a> tackle the problem by evolving logic circuits under various conditions. They confirm that simply optimizing the circuit to compute a particular function, with random inputs used for selection, results in highly non-modular circuits. However, they are able to obtain modular circuits using “modularly varying goals” (MVG).</p><p>The idea is to change the reward function every so often (the authors switch it out every 20 generations). Of course, if we just use completely random reward functions, then evolution doesn’t learn anything. Instead, we use “modularly varying” goal functions: we only swap one or two little pieces in the (modular) objective function. An example from the book:</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/JBFHzfPkXHB2XfDGj/cy8a4pckajkt7m8mtklm""><figcaption>&nbsp;</figcaption></figure><p>The upshot is that our different goal functions generally use similar sub-functions - suggesting that they share sub-goals for evolution to learn. Sure enough, circuits evolved using MVG have modular structure, reflecting the modular structure of the goals.</p><p>(Interestingly, MVG also dramatically accelerates evolution - circuits reach a given performance level much faster under MVG than under a fixed goal, despite needing to change behavior every 20 generations. See either the book or the paper for more on that.)</p><p>How realistic is MVG as a model for biological evolution? I haven’t seen quantitative evidence, but qualitative evidence is easy to spot. MVG as a theory of biological modularity predicts that highly variable subgoals will result in modular structure, whereas static subgoals will result in a non-modular mess. Alon’s book gives several examples:</p><ul><li>Chemotaxis: different bacteria need to pursue/avoid different chemicals, with different computational needs and different speed/energy trade-offs, in various combinations. The result is modularity: separate components for sensing, processing and motion.</li><li>Animals need to breathe, eat, move, and reproduce. A new environment might have different food or require different motions, independent of respiration or reproduction - or vice versa. Since these requirements vary more-or-less independently in the environment, animals evolve modular systems to deal with them: digestive tract, lungs, etc.</li><li>Ribosomes, as an anti-example: the functional requirements of a ribosome hardly vary at all, so they end up non-modular. They have pieces, but most pieces do not have an obvious distinct function.</li></ul><p>To sum it up: modularity in the system evolves to match modularity in the environment.</p>",johnswentworth,johnswentworth,johnswentworth,
Q8zqoBWBBHD2RjDuS,Autism And Intelligence: Much More Than You Wanted To Know,autism-and-intelligence-much-more-than-you-wanted-to-know,https://www.lesswrong.com/posts/Q8zqoBWBBHD2RjDuS/autism-and-intelligence-much-more-than-you-wanted-to-know,2019-11-14T05:30:02.643Z,76,34,12,False,False,,"<p><i>[Thanks to Marco G for proofreading and offering suggestions]</i></p>
<p><b>I.</b></p>
<p>Several studies have shown a genetic link between autism and intelligence; genes that contribute to autism risk also contribute to high IQ. But studies show autistic people generally have lower intelligence than neurotypical controls, often much lower. What is going on?</p>
<p>First, the studies. <a href=""https://www.nature.com/articles/mp2015225"">This study</a> from UK Biobank finds a genetic correlation between genetic risk for autism and educational attainment (r = 0.34), and between autism and verbal-numerical reasoning (r = 0.19). <a href=""https://www.ncbi.nlm.nih.gov/pubmed?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=25754080"">This study</a> of three large birth cohorts finds a correlation between genetic risk for autism and cognitive ability (beta = 0.07). <a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6454898/"">This study</a> of 45,000 Danes finds that genetic risk for autism correlates at about 0.2 with both IQ and educational attainment. These are just three randomly-selected studies; there are too many to be worth listing.</p>
<p>The relatives of autistic people will usually have many of the genes for autism, but not be autistic themselves. If genes for autism (without autism itself) increase intelligence, we should expect these people to be unusually smart. This is what we find; see Table 4 <a href=""https://www.nature.com/articles/tp201460/tables/4"">here</a>. Of 11 types of psychiatric condition, only autism was associated with increased intelligence among relatives. This intelligence is shifted towards technical subjects. <a href=""https://web.archive.org/web/20060505122037/http://www.autismresearchcentre.com/docs/papers/1998_BCetal_Maths.pdf"">About</a> 13% of autistic children have fathers who are engineers, compared to only 5% of a group of control children (though see the discussion <a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4093805/"">here</a>) for some debate over how seriously to take this; I am less sure this is accurate than most of the other statistics mentioned here).</p>
<p>Further (indirect) confirmation of the autism-IQ link comes from evolutionary investigations. If autism makes people less likely to reproduce, why would autism risk genes stick around in the human population? <a href=""https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006618"">Polimanti and Gelemter (2017)</a> find that autism risk genes aren’t just sticking around. They are being <i>positively selected</i>, ie increasing with every generation, presumably because people with the genes are having more children than people without them. This means autism risk genes must be doing something good. Like everyone else, they find autism risk genes are positively correlated with years of schooling completed, college completion, and IQ. They propose that the reason evolution favors autism genes is that they generally increase intelligence.</p>
<p>But as mentioned before, autistic people themselves generally have very low intelligence. <a href=""https://discovery.ucl.ac.uk/id/eprint/10010939/1/Charman2011IQ619.pdf"">One study</a> found that 69% of autistic people had an IQ below 85 (the average IQ of a high school dropout). Only 3% of autistic people were found to have IQs above 115, even though 15% of the population should be at this level.</p>
<p>These numbers should be taken with very many grains of salt. First, IQ tests don’t do a great job of measuring autistic people. Their intelligence tends to be more imbalanced than neurotypicals’, so IQ tests (which rely on an assumption that most forms of intelligence are correlated) are less applicable. Second, even if the test itself is good, autistic people may be bad at test-taking for other reasons – for example, they don’t understand the directions, or they’re anxious about the social interaction required to answer an examiner’s quetsions. Third, and most important, there is a strong selection bias in the samples of autistic people. Many definitions of autism center around forms of poor functioning which are correlated with low intelligence. Even if the definition is good, people who function poorly are more likely to seek out (or be coerced into) psychiatric treatment, and so are more likely to be identified. In some sense, all “autism has such-and-such characteristics” studies are studying the way people like to define autism, and tell us nothing about any underlying disease process. I talk more about this in parts 2 and 3 <a href=""https://slatestarcodex.com/2015/10/12/against-against-autism-cures/"">here</a>.</p>
<p>But even adjusting for these factors, the autism – low intelligence correlation seems too strong to dismiss. For one thing, the same studies that found that relatives of autistic patients had higher IQs find that the autistic patients themselves have much lower ones. The existence of a well-defined subset of low IQ people whose relatives have higher-than-predicted IQs is a surprising finding that cuts through the measurement difficulties and suggests that this is a real phenomenon.</p>
<p>So what is going on here? </p>
<p><b>II.</b></p>
<p>At least part of the story is that there are at least three different causes of autism.</p>
<p>1. The “familial” genes mentioned above: common genes that increase IQ and that evolution positively selects for.</p>
<p>2. Rare “de novo mutations”, ie the autistic child gets a new mutation that their non-autistic parent doesn’t have. These mutations are often very bad, and are quickly selected out of the gene pool (because the people who have them don’t reproduce). But “quickly selected out of the gene pool” doesn’t help the individual person who got one of them, who tends to end up severely disabled. In a few cases, the parent gets the de novo mutation, but <a href=""https://en.wikipedia.org/wiki/Penetrance"">for whatever reason</a> doesn’t develop autism, and then passes it onto their child, who does develop autism.</p>
<p>3. Non-genetic factors. The best-studied are probably obstetric complications, eg a baby gets stuck in the birth canal and can’t breathe for a long time. Pollution, infection, and trauma might also be in this basket.</p>
<p>These three buckets and a few other less important factors combine to determine autism risk for any individual. Combining information from a wide variety of studies, <a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4137411/"">Gaugler et al</a> estimate that about 52% of autism risk is attributable to ordinary “familial” genes, 3% to rare “de novo” mutations, 4% to complicated non-additive genetic interaction effects, and 41% “unaccounted”, which may be non-genetic factors or genetic factors we don’t understand and can’t measure. This study finds lower heritability than the usual estimates (which are around 80% to 90%; the authors are embarrassed by this, and in <a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5818813/"">a later study</a> suggest they might just have been bad at determining who in their sample did or didn’t have autism. While their exact numbers are doubtful, I think the overall finding that common familial genes are much more important than rare de novo mutations survives and is important.</p>
<p>Most cases of autism involve all three of these factors; that is, your overall autisticness is a combination of your familial genes, mutations, and environmental risk factors.</p>
<p>One way of resolving the autism-intelligence paradox is to say that familial genes for autism increase IQ, but de novo mutations and environmental insults decrease IQ. This is common-sensically true and matches previous research into all of these factors. So the only question is whether the size of the effect is enough to fully explain the data – or whether, even after adjusting out the degree to which autism is caused by mutations and environment, it still decreases IQ.</p>
<p><a href=""https://www.researchgate.net/profile/Michael_Ronemus/publication/259766765_The_role_of_de_novo_mutations_in_the_genetics_of_autism_spectrum_disorders/links/56d5c9f708aee1aa5f730aba.pdf"">Ronemus et al (2014)</a> evaluate this:</p>
<p><img src=""http://slatestarcodex.com/blog_images/ronemus.png"" /></p>
<p>They find that even autistic people without <i>de novo</i> mutations have lower-than-average IQ. But they can only screen for <i>de novo</i> mutations they know about, and it could be that they just missed some.</p>
<p>Here’s another set of relevant graphs:</p>
<p><img src=""http://slatestarcodex.com/blog_images/autismiq4.png"" /></p>
<p>This one comes from <a href=""https://www.sciencedirect.com/science/article/pii/S0890856719302710"">Gardner et al (2019)</a>, which measures the cognitive ability of the fathers of autistic people and disaggregates those with and without intellectual disability. In Graph A, we see that if a child has autism (but not intellectual disability), their likelihood of having a father with any particular IQ (orange line) is <i>almost</i> the same as the likelihood of a neurotypical child having a father of that IQ (dotted line). Disguised in that “almost” is a very slight tendency for fathers to be unusually intelligent, plus a (statistically insignificant) tendency for them to be unusually unintelligent. For reasons that don’t entirely make sense to me, if instead we look at the likelihood of the father to be a certain intelligence (bottom graph, where dark line surrounded by gray confidence cloud is autistic people’s fathers, and dotted line is neurotypical people’s fathers) it becomes more obvious that more intelligent people are actually a little more likely to have autistic children (though less intelligent people are also more likely.</p>
<p>(remember that “intellectual disability” just means “IQ over 70”, and so many of these not-intellectually-disabled people may be very intellectually weak – I wish the paper had quantified this)</p>
<p>Graph B is the same thing, but with people have have autism <i>with</i> intellectual disability. Now there is a very strong effect towards their fathers being less intelligent than usual.</p>
<p>This confuses me a little. But for me the key point is that high-intelligence fathers show a trend (albeit not significant in this study) to be more likely than average to have children with autism <i>and</i> intellectual disability.</p>
<p>These questions interest me because I know a lot of people who are bright nerdy programmers married to other bright nerdy programmers, and sometimes they ask me if their children are at higher risk for autism. While their children are clearly at higher risk for autistic <i>traits</i>, I think they want to know whether they have higher risk for the most severe forms of the syndrome, including intellectual disability and poor functioning. If we take the Ronemus and Gardner studies seriously, the answer seems to be yes. The Gardner study seems to suggest it’s a very weakly elevated risk, maybe only 1.1x or 1.2x relative risk. But the Gardner study also ceilings off at 90th percentile intelligence, so at this point I’m not sure what to tell these people.</p>
<p><b>III.</b></p>
<p>If Ronemus isn’t missing some obscure <i>de novo</i> mutations, then people who get autism solely by accumulation of common (usually IQ-promoting) variants still end up less intelligent than average. This should be surprising; why would too many intelligence-promoting variants cause a syndrome marked by low intelligence? And how come it’s so inconsistent, and many people have naturally high intelligence but aren’t autistic at all?</p>
<p>One possibility would be something like a tower-vs-foundation model. The tower of intelligence needs to be built upon some kind of mysterious foundation. The taller the tower, the stronger the foundation has to be. If the foundation isn’t strong enough for the tower, the system fails, you develop autism, and you get a collection of symptoms possibly including low intelligence. This would explain low-functioning autism from de novo mutations or obstetric trauma (the foundation is so weak that it fails no matter how short the tower is). It would explain the association of genes for intelligence with autism (holding foundation strength constant, the taller the tower, the more likely a failure). And it would also explain why there are many extremely intelligent people who don’t have autism at all (you can build arbitrarily tall towers if your foundation is strong enough). </p>
<p>I’ve only found one paper that takes this model completely seriously and begins speculating on the nature of the foundation. This is Crespi 2016, <a href=""https://www.frontiersin.org/articles/10.3389/fnins.2016.00300/full"">Autism As A Disorder Of High Intelligence</a>. It draws on the VPR model of intelligence, where g (“general intelligence”) is divided into three subtraits, v (“verbal intelligence”), p (“perceptual intelligence”), and r (“mental rotation ability”) – despite the very specific names each of these represents ability at broad categories of cognitive tasks. Crespi suggests that autism is marked by an imbalance between P (as the tower) and V + R (as the foundation). In other words, if your perceptual intelligence is much higher than your other types of intelligence, you will end up autistic. </p>
<p>It doesn’t really present much evidence for this other than that autistic people seem to have high perceptual intelligence. Also, it doesn’t really look like autistic people are <a href=""http://nrl.northumbria.ac.uk/17272/1/Visuo-Spatial_Performance_in_Autism.pdf"">worse at mental rotation</a>. Also, the Gardner paper <a href=""https://ars.els-cdn.com/content/image/1-s2.0-S0890856719302710-gr3.jpg"">has analyzed</a> autistic patients’ fathers by subtype of intelligence, and there is a nonsignificant but pretty suggestive tendency for them to have higher-than-normal verbal intelligence; certainly no signs of high verbal intelligence <i>preventing</i> autism. I can’t tell if this is evidence against Crespi or whether since all intellectual abilities are correlated this is just the shadow of their high perceptual intelligence, and if we directly looked at perceptual-to-verbal ratio we would see it was lower than expected. Also also, Crespi is one of those scientists who constantly has much more interesting theories than anyone else (<a href=""https://slatestarcodex.com/2018/12/11/diametrical-model-of-autism-and-schizophrenia/"">eg</a>), and this makes me suspicious. </p>
<p>Overall I would be surprised if this were the real explanation for the autism-and-intelligence paradox, but it gets an A for effort.</p>
<p><b>Conclusions</b></p>
<p>1. The genes that increase risk of autism are disproportionately also genes that increase intelligence, and vice versa (~100% confidence)</p>
<p>2. People diagnosed with autism are less intelligent than average (~100% confidence, leaving aside definitional complications)</p>
<p>3. Some of this effect is because autism is caused both by normal genes and by <i>de novo</i> mutations and environmental insults, and the <i>de novo</i> mutations and environmental insults definitely decrease intelligence. Every autism case is caused by some combination of these three factors, and the more it is caused by normal genes, the more intelligence is likely to be preserved (~100% confidence)</p>
<p>4. This is not the whole story, and even cases of autism that are caused entirely or mostly by normal genetics are associated with unusually low IQ (80% confidence)</p>
<p>5. This can best be understood through a tower-versus-foundation model where higher intelligence that outstrips the ability of some mysterious foundation to support it will result in autism (25% confidence)</p>
<p>6. The specific way the model plays out may be through perceptual intelligence out of balance with verbal and rotational intelligence causing autism (3% confidence)</p>",Yvain,scottalexander,Scott Alexander,
opmKgjxz6FmjwboZ9,[Link] John Carmack working on AGI,link-john-carmack-working-on-agi,https://www.lesswrong.com/posts/opmKgjxz6FmjwboZ9/link-john-carmack-working-on-agi,2019-11-14T00:08:37.250Z,15,7,5,False,False,,"<p><a href=""https://en.wikipedia.org/wiki/John_Carmack"">John Carmack</a>, confirmed GOAT video game developer, is going to take a crack at AGI.</p><p><a href=""https://www.facebook.com/permalink.php?story_fbid=2547632585471243&amp;id=100006735798590"">https://www.facebook.com/permalink.php?story_fbid=2547632585471243&amp;id=100006735798590</a></p><br><br>",bgold,bgold,Ben Goldhaber,
Qjsf4tS6Z4XQXCq2x,Instant stone (just add water!),instant-stone-just-add-water-1,https://www.lesswrong.com/posts/Qjsf4tS6Z4XQXCq2x/instant-stone-just-add-water-1,2019-11-13T22:33:39.903Z,102,48,27,False,False,https://rootsofprogress.org/instant-stone-just-add-water,"<p><i>Originally posted on The Roots of Progress, January 6, 2018</i></p><p>From the time that humans began to leave their <a href=""https://rootsofprogress.org/nomad-life"">nomadic ways</a> and live in settled societies about ten thousand years ago, we have needed to build structures: to shelter ourselves, to store our goods, to honor the gods.</p><p>The easiest way to build is with dirt. Mud, clay, any kind of earth. Pile it up and you have walls. A few walls and a thatched roof, and you have a hut.</p><figure class=""image image_resized"" style=""width:50.68%""><img src=""https://rootsofprogress.org/img/mud-hut.jpg"" alt=""Earthen hut with thatched roof in Sudan""><figcaption><i>Earthen hut with thatched roof in Sudan - </i><a href=""https://commons.wikimedia.org/wiki/File:House_in_Toteil_002.jpg""><i>Petr Adam Dohnálek / Wikimedia</i></a></figcaption></figure><p>But earthen construction has many shortcomings. Dirt isn’t very strong, so you can’t build very high or add multiple stories. It tends to wash away in the rain, so it really only works in hot, dry climates. And it can be burrowed through by intruders—animal or human.</p><p>We need something tougher. A material that is hard and strong enough to weather any storm, to build high walls and ceilings, to protect us from the elements and from attackers.</p><p>Stone would be ideal. It is tough enough for the job, and rocks are plentiful in nature. But like everything else in nature, we find them <a href=""https://rootsofprogress.org/there-are-no-natural-resources"">in an inconvenient form</a>. Rocks don’t come in the shape of houses, let alone temples. We could maybe pile or stack them up, if only we had something to hold them together.</p><p>If only we could—bear with me now as I indulge in the wildest fantasy—pour <i>liquid stone</i> into molds, to create rocks in any shape we want! Or—as long as I’m dreaming—what if we had a glue that was as strong as stone, to stick smaller rocks together into walls, floors and ceilings?</p><p>This miracle, of course, exists. Indeed, it may be the oldest craft known to mankind. You already know it—and you probably think of it as one of the dullest, most boring substances imaginable.</p><p>I am here to convince you that it is pure magic and that we should look on it with awe.</p><p>It’s called cement.</p><figure class=""image""><img src=""https://rootsofprogress.org/img/cement.jpg"" alt=""""></figure><hr><p>Let’s begin at the beginning. Limestone is a soft, light-colored rock with a grainy texture, which fizzes in the presence of acid. Chalk is a form of limestone. What distinguishes limestone and makes it useful is a high calcium content (“calcium” and “chalk” are cognates). Specifically, it is calcium carbonate (CaCO3), the same substance that makes up seashells. In fact, limestone, a sedimentary rock, is often formed from crushed seashells, compressed over eons.</p><figure class=""image image_resized"" style=""width:52.19%""><img src=""https://rootsofprogress.org/img/limestone.jpg"" alt=""Limestone from a quarry in southern Germany""><figcaption><i>Limestone from a quarry in southern Germany - </i><a href=""https://commons.wikimedia.org/wiki/File:Brachiopoda-limestone_hg.jpg""><i>Hannes Grobe / Wikimedia</i></a></figcaption></figure><p>Limestone can be used for many purposes, including fertilizer and whitewash, but its most important industrial use is in making cement. When it is heated to about 1,000 °C (e.g., in a kiln), it produces a powder called quicklime. Chemically, what’s going on is that burning calcium carbonate removes carbon dioxide and leaves calcium oxide (CaCO3&nbsp;+&nbsp;heat → CaO&nbsp;+&nbsp;CO2).</p><p>Quicklime is a caustic substance: touching it will burn your skin (hence “quick”, meaning active, “alive”). But perhaps its strangest property is that when mixed with water, it reacts, giving off heat—enough to boil the water! The result, called “slaked” or “hydrated” lime, is calcium hydroxide (CaO&nbsp;+&nbsp;H2O → Ca(OH)2&nbsp;+&nbsp;heat).</p><p>Further, if you pour a lime-water slurry into a mold, not too thick, and expose it to the air, a still more amazing thing happens: in a matter of hours, the mixture “sets” and becomes once again as hard as stone. The calcium hydroxide has absorbed CO2 from the air to return to calcium carbonate (Ca(OH)2&nbsp;+&nbsp;CO2 → CaCO3&nbsp;+&nbsp;H2O), completing what is known as the “lime cycle”.</p><p>In other words, by mixing with water and air, this powder—a basic cement—has turned back into rock! If this technology hadn’t already existed since before recorded history, it would seem futuristic.</p><p>The product of a pure lime cement is too brittle and weak to be very useful (except maybe as a grout). But we can make it stronger by mixing in sand, gravel or pebbles, called “aggregate”. Cement, water and sand produce mortar, a glue that can hold together bricks or stones in a masonry wall. Adding gravel or pebbles as well will make concrete, which can be poured into molds to set in place. (The terms “cement” and “concrete” are often conflated, but technically, cement is the powder from which mortar and concrete are made; concrete is the substance made by adding aggregate and is what constitutes sidewalks, buildings, etc.)</p><figure class=""image image_resized"" style=""width:57.9%""><img src=""https://rootsofprogress.org/img/brick-and-mortar.jpg"" alt=""Brick wall with cement mortar""><figcaption><i>Brick wall with cement mortar</i></figcaption></figure><figure class=""image image_resized"" style=""width:58.06%""><img src=""https://rootsofprogress.org/img/concrete-wall.jpg"" alt=""Concrete wall with aggregate visible""><figcaption><i>Concrete wall with aggregate visible</i></figcaption></figure><hr><p>This basic technology has been known since prehistoric times: the kilning of limestone is older than pottery, much older than metalworking, and possibly older than <i>agriculture.</i> But over the millenia, better formulas for cement have been created, with superior mixtures of ingredients and improved processes.</p><p>Pure lime cement needs air to set, so it can’t set if poured too thick, or underwater (for instance, on a riverbed to form the base of a column for a bridge). The Romans, who were great users of cement, discovered that adding volcanic ash, called <i>pozzalana,</i> to lime would produce a cement that sets even underwater; this is called a “hydraulic cement”. They used this “Roman cement” to build everything from aqueducts to the Colosseum. Another common hydraulic cement, called “natural cement”, is formed from a mixture of limestone and clay, which sometimes occur together in natural deposits.</p><p>Since the mid-1800s, the most widely used cement is a type called Portland cement. Without going into too much detail, this is made through an unintuitive process that involves heating a lime-clay slurry to the point where it fuses together into a hard substance called “clinker”. Clinker was originally considered waste material, a ruined product—until it was discovered that grinding it into powder produced a cement that is stronger than Roman or natural cement. (!) Today a wide variety of cements are available on the market, optimized for different conditions.</p><p>No matter the formula, however, all cements have one shortcoming: they are very strong under compression, which is the kind of strength needed in a column or wall, but weak under tension, which comes into play, for instance, when a beam buckles under load. The Romans dealt with this problem using arches, which direct forces into compression along the arch. Medieval builders created the pointed Gothic arch, which could stretch even higher than the round Roman ones, and the flying buttress, which added support to the walls of their tall cathedrals.</p><figure class=""image image_resized"" style=""width:49.01%""><img src=""https://rootsofprogress.org/img/aqueduct-with-roman-arch.jpg"" alt=""Pont du Gard, a Roman aqueduct bridge near Nîmes, France""><figcaption><i>Pont du Gard, a Roman aqueduct bridge near Nîmes, France</i></figcaption></figure><figure class=""image image_resized"" style=""width:49.42%""><img src=""https://rootsofprogress.org/img/gothic-arch.jpg"" alt=""Gothic window, Church of St. Helen, Lincolnshire, England""><figcaption><i>Gothic window, Church of St. Helen, Lincolnshire, England </i><a href=""https://www.flickr.com/photos/hunky_punk/7987022516""><i>- Spencer Means / Flickr</i></a></figcaption></figure><p>&nbsp;</p><p>But in the twentieth century, a new way of building took over: reinforcing the concrete with steel. Steel, unlike concrete, has high tensile strength, so this “reinforced concrete” is strong under both compression and tension. The reinforcement bars created for this purpose are called “rebar.” Reinforcement allows concrete to be used not only for foundations, walls and columns, but for cantilevered structures such as the decks of <a href=""https://www.fallingwater.org/"">Fallingwater</a>.</p><figure class=""image""><img src=""https://rootsofprogress.org/img/fallingwater.jpg"" alt=""Fallingwater, by Frank Lloyd Wright""><figcaption><i>Fallingwater, by Frank Lloyd Wright - </i><a href=""https://www.flickr.com/photos/mathoov/15638566078""><i>Mathieu Thouvenin / Flickr</i></a></figcaption></figure><hr><p>This is cement. We start with rock, crush and burn it to extract its essence in powdered form, and then reconstitute it at a place and time and <i>in a shape</i> of our choosing. Like coffee or pancake mix, it is “instant stone—just add water!” And with it, we make skyscrapers that reach hundreds of stories high, tunnels that go <a href=""https://en.wikipedia.org/wiki/Channel_Tunnel"">under the English channel</a> and the <a href=""https://en.wikipedia.org/wiki/Gotthard_Base_Tunnel"">Swiss Alps</a>, and <a href=""https://en.wikipedia.org/wiki/Danyang%E2%80%93Kunshan_Grand_Bridge"">bridges that stretch a hundred miles</a>.</p><p>If that isn’t magic, I don’t know what is.</p><hr><p>Sources and further reading: <a href=""https://rootsofprogress.org/books/concrete-planet""><i>Concrete Planet: The Strange and Fascinating Story of the World’s Most Common Man-Made Material</i></a>, <a href=""https://geology.com/rocks/limestone.shtml"">Geology.com</a>, <a href=""https://mineralseducationcoalition.org/minerals-database/cement/"">Minerals Education Coalition</a>, <a href=""http://www.cement.org/cement-concrete-applications"">Portland Cement Association</a>, and many pages on Wikipedia. Thanks also to Doug Peltz of Mystery Science for helpful conversations.</p>",jasoncrawford,jasoncrawford,jasoncrawford,
ktDKfKqukTPRiuEPM,Robin Hanson on the futurist focus on AI,robin-hanson-on-the-futurist-focus-on-ai,https://www.lesswrong.com/posts/ktDKfKqukTPRiuEPM/robin-hanson-on-the-futurist-focus-on-ai,2019-11-13T21:50:01.893Z,31,14,24,False,False,,"<figure style=""width:144px;""><a href=""http://aiimpacts.org/wp-content/uploads/2019/11/robin_hanson.jpg""><img src=""http://aiimpacts.org/wp-content/uploads/2019/11/robin_hanson.jpg"" /></a><figcaption>Robin Hanson</figcaption></figure>
<p>Robert Long and I recently talked to Robin Hanson—GMU economist, prolific <a href=""http://www.overcomingbias.com/"">blogger</a>, and longtime thinker on the future of AI—about the amount of futurist effort going into thinking about AI risk.</p>


<p>It was noteworthy to me that Robin thinks human-level AI is a century, perhaps multiple centuries away— much longer than the 50-year number given by AI researchers. I think these longer timelines are the source of a lot of his disagreement with the AI risk community about how much of futurist thought should be put into AI.<br /></p>



<p>Robin is particularly interested in the notion of ‘lumpiness’– how much AI is likely to be furthered by a few big improvements as opposed to a slow and steady trickle of progress. If, as Robin believes, most academic progress and AI in particular are not likely to be ‘lumpy’, he thinks we shouldn’t think things will happen without a lot of warning.</p>



<p>The full recording and transcript of our conversation can be found <a href=""https://aiimpacts.org/conversation-with-robin-hanson/"" target=""_blank"">here</a>.<br /></p>",abergal,abergal,abergal,
NYKopGah7hBv2vmWf,[Link] (EA Podcast) Social Status: The Key to the Matrix Part I,link-ea-podcast-social-status-the-key-to-the-matrix-part-i,https://www.lesswrong.com/posts/NYKopGah7hBv2vmWf/link-ea-podcast-social-status-the-key-to-the-matrix-part-i,2019-11-13T21:09:24.657Z,9,2,1,False,False,,"<p>A new episode of Global Optimum has been released! Global Optimum is a podcast aimed at making altruists more effective. This episode is about the psychology of social status. The desire for status is a fundamental human motive. Understanding status can help us understand many otherwise puzzling features of our world. In this episode, I apply our understanding of status psychology to analyze various dynamics and trends within effective altruism.</p><p>This episode features:</p><p>-How do people behave differently when they are high vs low status?</p><p>-How did human social status evolve?</p><p>-Should you try to dampen your desire for status?</p><p>-Are EAs too credential-focused?</p><p>-Is publishing in academic journals overrated?</p><p>-Can you get more done by working alone than by starting an organization?</p><p>-What causes groups to splinter?</p><p>-How has effective altruism &#x201C;professionalized?&#x201D; What are the upsides and downsides of this trend?</p><p><a href=""http://danielgambacorta.com/podcast/social-status-the-key-to-the-matrix-part-i/"">Full transcript </a></p><p>The podcast is available on all podcast apps.</p><p><a href=""http://globaloptimum.libsyn.com/social-status-the-key-to-the-matrix-part-i"">Listen here </a></p>",Daniel_Gambacorta,daniel_gambacorta,Daniel_Gambacorta,
QfgAgkahWtHfp2xGA,Reconsolidation Through Experience,reconsolidation-through-experience,https://www.lesswrong.com/posts/QfgAgkahWtHfp2xGA/reconsolidation-through-experience,2019-11-13T20:04:39.345Z,13,5,0,False,False,,"<br><p>At this level, you&apos;re simply sitting with the schema. Oftentimes, this alone can produce a dramatic shift through memory reconsolidation simply as a matter of re-evaluating the old schema when you get a look at it. I also include non-memory reconsolidation techniques in this category that work through extinction of the old association.</p><h1>Experiencing Evidence</h1><h2>Memory Collection</h2><p>Memory collection involves finding and allowing yourself to experience every time you can remember when you felt or acted through a particular belief schema. For each piece of evidence, you allow yourself to think and feel through the schema in that particular memory, then move on to the next one. By simply allowing ourselves to see all the evidence for a schema with our current perspective, we can often come to a more nuanced understanding of the belief. I first learned about this technique through <a href=""https://theeffortlessway.com/"">PJ Eby,</a>who calls it the Feeling Elimination Technique. The book, thinking things done, that it was included in, is no longer available as far as I&apos;m aware.</p><h2>Imaginal Exposure</h2><p><a href=""http://sfbacct.com/from-ocd-to-anxiety/nuts-and-bolts-of-imaginal-exposure/"">Imaginal exposure</a> is a process of taking a particular salient memory/fear/trauma etc, and simply running through the experience over and over. This can often trigger memory reconsolidation, and, even if not, can change your schema through simple exhaustion induced extinction. <strong><a href=""https://www.emdr.com/what-is-emdr/"">EMDR</a></strong> is a version of imaginal exposure that adds the modality of moving your eyes back and forth as you run through the memory. My current best view of the evidence is that EMDR has no long term benefit over imaginal exposure, but the data is confusing.</p><h1>Experiencing Beliefs</h1><h2>The Acceptance Statement</h2><p>An acceptance statement is a tool from <a href=""https://www.coherencetherapy.org/"">Coherence Therapy</a>, that involves taking a belief, and the choices you&apos;ve made about a belief and saying them out loud. For instance I could state out loud &quot;I should not express myself. If I do, I&apos;ll be ostracized. I&apos;ve decided it&apos;s more important to not be ostracized than to be fully seen.&quot; Saying this out loud is often enough to trigger the schema, and hearing out out loud is often enough to automatically trigger the questioning of the schema.</p><p>You can enhance this process by (in your imagination or in real life), saying the statement outloud to someone who has been affected by the choices you&apos;ve made. I could imagine saying to my partner: &quot;I should not express myself. If I do, you will ostracize me. I&apos;ve decided it&apos;s more important to not be ostracized than to be fully seen by you.&quot;</p><p><strong><a href=""https://eft.mercola.com/"">Emotional Freedom Technique</a></strong> is a process that combines saying acceptance statements out loud with tapping various parts of your body. It&apos;s unclear to me based on the evidence if the tapping adds anything outside of simply stating the beliefs.</p><h1>Experiencing Felt Senses</h1><h2>Sitting With</h2><p>A common recommendation is simply to spend some time <a href=""https://psychcentral.com/blog/how-to-sit-with-painful-emotions/"">sitting with your feelings</a>. By simply sitting with the feeling, it gives you time to process it, allowing you to reconsolidate the schema with your new processed understanding.</p><h2>Expressing</h2><p>Another way to experience felt senses is to express them. <strong><a href=""https://focusing.org/sixsteps"">Focusing</a></strong> is one process that allows you to express your felt senses, as are common forms of expressive therapy like <a href=""https://arttherapy.org/"">Art Therapy</a>.</p><h1>Experiencing Metaphors</h1><h2><strong>Clean Language</strong></h2><p><a href=""https://cleanlearning.co.uk/resources/faq/what-is-clean-language"">Clean Language</a> is a series of questions you can ask yourself to start exploring your own metaphors. Simply by exploring our metaphors, we can often get a new perspective and reconsolidate them.</p>",mr-hire,mr-hire,Matt Goldenberg,
puhXe3M4wuoSJtYTs,The Hierarchy of Memory Reconsolidation Techniques,the-hierarchy-of-memory-reconsolidation-techniques,https://www.lesswrong.com/posts/puhXe3M4wuoSJtYTs/the-hierarchy-of-memory-reconsolidation-techniques,2019-11-13T20:02:43.449Z,12,5,1,False,False,,"<p>As discussed in the previous post, the aim is to start with the techniques that least challenge existing schema, and then work up the hierarchy to techniques that more strongly challenge the existing schema. </p><br><span><figure><img src=""http://mattgoldenberg.net/wp-content/uploads/2019/11/Hierarchy-of-Reconsolidation.png"" class=""draft-image "" style=""width:40%""></figure></span><p><strong>Experience</strong> involves simply sitting with the schema as it is, and seeing if change comes from prolonged viewing of the schema.</p><p><strong>Question </strong>involves posing questions about the schema, to draw attention to ways that it may be wrong.</p><p><strong>Challenge </strong>involves directly providing counters to the schema, and seeing how it reacts.</p><p><strong>Dissonance </strong>involves holding both the counter to the schema and the schema itself at once.</p><p><strong>Change</strong> involves attempting to directly change how you represent the schema to take your counter into account.</p>",mr-hire,mr-hire,Matt Goldenberg,
kqp6TEjbtfcKjNTyx,Practical Guidelines for Memory Reconsolidation,practical-guidelines-for-memory-reconsolidation,https://www.lesswrong.com/posts/kqp6TEjbtfcKjNTyx/practical-guidelines-for-memory-reconsolidation,2019-11-13T19:54:10.097Z,35,11,5,False,False,,"<p>This post details a set of guidelines for working with the memory reconsolidation tools in the rest of the sequence.  Use it to get the most out of your memory reconsolidation procedure.</p><h2>Start with the More Cognitively Fused Schema</h2><p>For every belief schema you&apos;re working with, there&apos;s (at least) two belief schema&apos;s at play. There&apos;s the side that believes a particular thing, and then there&apos;s a side that wants you to question the belief in that thing. As a general rule, you should always start with the side that&apos;s more <a href=""https://www.lesswrong.com/posts/5g7oFiePGEY3h4bqX/prereq-cognitive-fusion"">cognitively fused</a>.</p><p>As an example, I was working with someone who was having issues going to bed on time, and wanted to change that. Before we started looking at the schema of &quot;I should avoid ruminating by staying up late,&quot; We first examined the schema of &quot;I should get more sleep.&quot;</p><p>By starting with the schema that you&apos;re more cognitively fused with, you avoid confirmation bias and end up with more accurate beliefs at the end.</p><h2>The Resistance is the Way</h2><p>If at any point, you encounter resistance to working on a particular technique with a particular schema, what you&apos;ve found is a &quot;Meta-schema&quot; that believes changing this belief would be harmful. Rather than push through this resistance, loop back to the beginning of the Debugging process, and work with this new schema.</p><p>As an example, I found myself trying to change the schema that &quot;I should avoid failure&quot;. I kept getting resistance, looped back, and found the schema &quot;Most people should like me.&quot;, only once I worked on reconsolidating that schema was I able to return to the original schema.</p><h2>Reverse Your Fusion</h2><p>For any given technique, there&apos;s two ways you can approach it. You can work with the schema from &quot;Inside&quot; experiencing it as who you are, or you can work with it from the &quot;Outside&quot;, putting some distance between yourself and the schema. As a general rule, I recommend reversing whatever your default is. If you frequently cognitively fuse with a schema, I recommend creating some distance/dissociation from it. If you frequently distance/dissociate from a schema, when doing the technique try as much as you can to fuse with it. This shift in perspective often goes a long way in providing new perspectives on the schema and allowing the re-consolidation to take place.</p><h2>Go With the Most Salient Access Point</h2><p>In contrast to the last point, you want to use whatever your natural inclination is as far as the schema access point. If a memory is coming up, use the evidence access point, if semantic content is coming up, use the belief access point, etc. Being able to fluidly switch access points to the schema as different things come up for you is key to quick reconsolidation.</p><h2>Experiencing a Schema as True Allows for Updating</h2><p>Via Kaj Satola</p><blockquote>Something that been useful to me recently has been remembering that according to memory reconsolidation principles, experiencing an incorrect emotional belief as true is actually n<em>ecessary </em>for revising it. Then, when I get an impulse to push the wrong-feeling belief out of my mind, I instead take the objecting part or otherwise look for counterevidence and let the counterbelief feel s<em>imultaneously </em>true as well. That has caused rapid updates the way Unlocking the Emotional Brain describes.</blockquote><blockquote>I think that basically the same kind of thing (don&apos;t push any part out of your mind without giving it a say) has already been suggested in IDC, IFS etc.; but in those, I&apos;ve felt like the framing has been more along the lines of &quot;consider that the irrational-seeming belief may still have an important point&quot;, which has felt hard to apply in cases where I feel very strongly that one of the beliefs is actually just false. Thinking in terms of &quot;even if this belief i<em>s </em>false, letting myself experience it as true allows it to be revised&quot; has been useful for those situation</blockquote>",mr-hire,mr-hire,Matt Goldenberg,
fvSRv9qf7m4davwDi,A Practical Theory of Memory Reconsolidation,a-practical-theory-of-memory-reconsolidation,https://www.lesswrong.com/posts/fvSRv9qf7m4davwDi/a-practical-theory-of-memory-reconsolidation,2019-11-13T19:52:20.364Z,16,8,16,False,False,,"<p>Memory Reconsolidation is one candidate for a scientific of theory of &quot;How to Actually Change Your Mind.&quot; In this post, I&apos;ll give a few fake frameworks about how memory reconsolidation works, in order to provide intuition pumps for the rest of the sequence.</p><h2>Schemas as Belief Clusters</h2><p>For the purposes of this sequence, we&apos;ll describe a schema as a particular cluster of felt Aliefs that point towards a goal or set of goals.</p><p>I often find it useful to think of beliefs as arranged in a hierarchy of goals, as theorized in <a href=""https://www.lesswrong.com/posts/nPs63hpijnQs37jme/behavior-the-control-of-perception"">Perceptual Control Theory</a>,<a href=""https://www.lesswrong.com/posts/8j4zirwfhWhT8nwsc/a-critique-of-leverage-research-s-connection-theory""> Connection Theory</a>, and<a href=""https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/""> Predictive Processing Theory.</a></p><span><figure><img src=""http://mattgoldenberg.net/wp-content/uploads/2019/11/BeliefHierarchhy.png"" class=""draft-image "" style=""width:84%""></figure></span><p>Schemas, or Parts, then represent clusters of these beliefs trying to achieve some specific need.</p><span><figure><img src=""http://mattgoldenberg.net/wp-content/uploads/2019/11/SchemasModel-1.png"" class=""draft-image "" style=""width:79%""></figure></span><p>In this framework, schema&apos;s don&apos;t represent any sort of natural boundary, and we can expand them and contract them at will based on what we&apos;re working on. Schemas themselves can overlap without natural boundaries, and can even contain their own internal conflicts.</p><h2>3 Steps to Reconsolidate Schemas</h2><p>In <a href=""https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain"">Unlocking the Emotional Brain</a>, the authors state three steps needed for memory re-consolidation:</p><p>1. Activate the Old Schema</p><p>2. Challenge the Old Schema</p><p>3. Learn a Replacement Schema</p><p>All of the techniques covered in this sequence implicitly or explicitly cover the three steps. However, step #3 is also augmented later on in the <a href=""https://www.lesswrong.com/posts/mFvuQTzHQiBCDEKw6/a-framework-for-internal-debugging"">Debugging Process</a> through the &quot;Integration&quot; step.</p><h2>The Tradeoff Between Activation and Challenge</h2><p>There&apos;s an inherent tradeoff between activating the old schema and challenging it. The stronger and more perceptible the challenge is, the more likely it is to be strong enough to trigger the reconsolidation. However, this strength comes with two downsides:</p><p>1. Challenging yourself in a very strong way doesn&apos;t feel good. It feels internally violent.</p><p>2. The stronger the challenge, the more likely you are to deactivate the schema you&apos;re challenging, creating resistance and making reconsolidation impossible.</p><p>For this reason, we start with the techniques that provide the weakest challenges, and gradually work our way up to stronger and stronger challenge, waiting till we feel a shift towards a more nuanced and accurate schema.</p><h2>4 Schema Access Points</h2><p>In Kaj&apos;s Post on <a href=""https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain"">Unlocking the Emotional Brain</a>, he points to a paper by Lane et al that give 3 ways to access a schema:</p><span><figure><img src=""https://stuff.kajsotala.fi/LW/UtEB/LaneEtAl.png"" class=""draft-image "" style=""width:75%""></figure></span><p>Because I think the names for these 3 methods to access a schema are overly long and technical, I&apos;m going to call them Felt Sense (Emotional Responses), Belief (Semantic Structures) and Evidence (Episodic Memories). Based on my own experience with changework, I&apos;ll also add a fourth category, Metaphor (metaphorical representations of a schema).</p><p><strong>Felt Sense</strong> involves looking at the physiological or indescribable &quot;Feelings&quot; evoked by a schema. An example is the tightness in your throat you get when trying to express yourself.</p><p><strong>Belief</strong> involves the semantic content of a schema as expressed through language. An example is &quot;If I express myself, then I will be ridiculed.&quot;</p><p><strong>Evidence</strong> represents our internal memories of how we learned the schema. An example is blurting something out in 4th grade and being laughed at.</p><p><strong>Metaphor</strong> represents some novel/new way of representing the schema, as an object, location, situation, or story. An example is imagining that you&apos;re wearing a mask at all times, and if you take it off people will see the silly clown face underneath and laugh at you.</p>",mr-hire,mr-hire,Matt Goldenberg,
mQqFNbvD5mYrCQPKE,[AN #73]: Detecting catastrophic failures by learning how agents tend to break,an-73-detecting-catastrophic-failures-by-learning-how-agents,https://www.lesswrong.com/posts/mQqFNbvD5mYrCQPKE/an-73-detecting-catastrophic-failures-by-learning-how-agents,2019-11-13T18:10:01.544Z,11,4,0,False,False,,"<p>Find all Alignment Newsletter resources <u><a href=""http://rohinshah.com/alignment-newsletter/"">here</a></u>. In particular, you can <u><a href=""http://eepurl.com/dqMSZj"">sign up</a></u>, or look through this <u><a href=""https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing"">spreadsheet</a></u> of all summaries that have ever been in the newsletter. I&apos;m always happy to hear feedback; you can send it to me by replying to this email.</p><p>Audio version <u><a href=""http://alignment-newsletter.libsyn.com/alignment-newsletter-73"">here</a></u> (may not be up yet).</p><h2><strong>Highlights</strong></h2><p><u><a href=""https://arxiv.org/abs/1812.01647"">Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures</a></u> <em>(Jonathan Uesato, Ananya Kumar, Csaba Szepesvari et al)</em> (summarized by Nicholas): An important problem in safety-critical domains is accurately estimating slim probabilities of catastrophic failures: one in a million is very different from one in a billion. A standard Monte Carlo approach requires millions or billions of trials to find a single failure, which is prohibitively expensive. This paper proposes using agents from earlier in the training process to provide signals for a learned failure probability predictor. For example, with a Humanoid robot, failure is defined as the robot falling down. A neural net is trained on earlier agents to predict the probability that the agent will fall down from a given state. To evaluate the final agent, states are importance-sampled based on how likely the neural network believes they are to cause failure. This relies on the assumption that the failure modes of the final agent are similar to some failure mode of earlier agents. Overall, the approach reduces the number of samples required to accurately estimate the failure probability by multiple orders of magnitude.</p><p><strong>Nicholas&apos;s opinion:</strong> I am quite excited about the focus on preventing low likelihood catastrophic events, particularly from the standpoint of existential risk reduction. The key assumption in this paper, that earlier in training the agent will fail in related ways but more frequently, seems plausible to me and in line with most of my experience training neural networks, and the experiments demonstrate a very large increase in efficiency.</p><p>I&#x2019;d be interested to see theoretical analysis of what situations would make this assumption more or less likely in the context of more powerful future agents. For example, one situation where the failure modes might be distinct later in training is if an agent learns how to turn on a car, which then makes states where the agent has access to a car have significantly higher likelihood of catastrophic failures than they did before.</p><h1><strong>Technical AI alignment</strong></h1><h3><strong>Learning human intent</strong></h3><p><u><a href=""https://futureoflife.org/2019/09/17/synthesizing-a-humans-preferences-into-a-utility-function-with-stuart-armstrong/"">AI Alignment Podcast: Synthesizing a human&#x2019;s preferences into a utility function</a></u> <em>(Lucas Perry and Stuart Armstrong)</em> (summarized by Rohin): Stuart Armstrong&apos;s <u><a href=""https://www.alignmentforum.org/posts/CSEdLLEkap2pubjof/research-agenda-v0-9-synthesising-a-human-s-preferences-into"">agenda</a></u> (<u><a href=""https://mailchi.mp/0dd8eb63fe2d/an-60a-new-ai-challenge-minecraft-agents-that-assist-human-players-in-creative-mode"">AN #60</a></u>) involves extracting partial preferences from a human and synthesizing them together into an <em>adequate</em> utility function. Among other things, this podcast goes into the design decisions underlying the agenda:</p><p>First, why even have a utility function? In practice, there are <u><a href=""https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities"">many pressures</a></u> suggesting that maximizing expected utility is the &quot;right&quot; thing to do -- if you aren&apos;t doing this, you&apos;re leaving value on the table. So any agent that isn&apos;t maximizing a utility function will want to self-modify into one that is using a utility function, so we should just use a utility function in the first place.</p><p>Second, why not defer to a long reflection process, as in <u><a href=""https://ordinaryideas.wordpress.com/2012/04/21/indirect-normativity-write-up/"">Indirect Normativity</a></u>, or some sort of reflectively stable values? Stuart worries that such a process would lead to us prioritizing simplicity and elegance, but losing out on something of real value. This is also why he focuses on <em>partial preferences</em>: that is, our preferences in &quot;normal&quot; situations, without requiring such preferences to be extrapolated to very novel situations. Of course, in any situation where our moral concepts break down, we will have to extrapolate somehow (otherwise it wouldn&apos;t be a utility function) -- this presents the biggest challenge to the research agenda.</p><p><strong>Read more:</strong> <u><a href=""https://www.youtube.com/watch?v=1M9CvESSeVc"">Stuart Armstrong Research Agenda Online Talk</a></u></p><p><u><a href=""https://www.alignmentforum.org/posts/hcrFxeYYfbFrkKQEJ/full-toy-model-for-preference-learning"">Full toy model for preference learning</a></u> <em>(Stuart Armstrong)</em> (summarized by Rohin): This post applies Stuart&apos;s general preference learning algorithm to a toy environment in which a robot has a mishmash of preferences about how to classify and bin two types of objects.</p><p><strong>Rohin&apos;s opinion:</strong> This is a nice illustration of the very abstract algorithm proposed before; I&apos;d love it if more people illustrated their algorithms this way.</p><h3><strong>Forecasting</strong></h3><p><u><a href=""https://www.lesswrong.com/posts/SvhzEQkwFGNTy6CsN/alphastar-impressive-for-rl-progress-not-for-agi-progress"">AlphaStar: Impressive for RL progress, not for AGI progress</a></u> <em>(orthonormal)</em> (summarized by Nicholas): This post argues that while it is impressive that AlphaStar can build up concepts complex enough to win at StarCraft, it is not actually developing reactive strategies. Rather than scouting what the opponent is doing and developing a new strategy based on that, AlphaStar just executes one of a predetermined set of strategies. This is because AlphaStar does not use causal reasoning, and that keeps it from beating any of the top players.</p><p><strong>Nicholas&apos;s opinion:</strong> While I haven&#x2019;t watched enough of the games to have a strong opinion on whether AlphaStar is empirically reacting to its opponents&apos; strategies, I agree with Paul Christiano&#x2019;s <u><a href=""https://www.lesswrong.com/posts/SvhzEQkwFGNTy6CsN/alphastar-impressive-for-rl-progress-not-for-agi-progress#kRpwqPPjcGEbEhXHA"">comment</a></u> that in principle causal reasoning is just one type of computation that should be learnable.</p><p>This discussion also highlights the need for interpretability tools for deep RL so that we can have more informed discussions on exactly how and why strategies are decided on.</p><p><u><a href=""https://openai.com/blog/ai-and-compute/#addendum"">Addendum to AI and Compute</a></u> <em>(Girish Sastry et al)</em> (summarized by Rohin): Last year, OpenAI <u><a href=""https://blog.openai.com/ai-and-compute/"">wrote</a></u> (<u><a href=""https://mailchi.mp/3e550712419a/alignment-newsletter-7"">AN #7</a></u>) that since 2012, the amount of compute used in the largest-scale experiments has been doubling every 3.5 months. This addendum to that post analyzes data from 1959-2012, and finds that during that period the trend was a 2-year doubling time, approximately in line with Moore&apos;s Law, and not demonstrating any impact of previous &quot;AI winters&quot;.</p><p><strong>Rohin&apos;s opinion:</strong> Note that the post is measuring compute used to <em>train</em> models, which was less important in past AI research (e.g. it doesn&apos;t include Deep Blue), so it&apos;s not too surprising that we don&apos;t see the impact of AI winters.</p><p><u><a href=""https://aiimpacts.org/etzioni-2016-survey/"">Etzioni 2016 survey</a></u> <em>(Katja Grace)</em> (summarized by Rohin): Oren Etzioni surveyed 193 AAAI fellows in 2016 and found that 67.5% of them expected that &#x2018;we will achieve Superintelligence&#x2019; someday, but in more than 25 years. Only 7.5% thought we would achieve it sooner than that.</p><h1><strong>AI strategy and policy</strong></h1><p><u><a href=""https://openai.com/blog/gpt-2-1-5b-release/"">GPT-2: 1.5B Release</a></u> <em>(Irene Solaiman et al)</em> (summarized by Rohin): Along with the release of the last and biggest GPT-2 model, OpenAI explains their findings with their research in the time period that the staged release bought them. While GPT-2 can produce reasonably convincing outputs that are hard to detect and can be finetuned for e.g. generation of synthetic propaganda, so far they have not seen any evidence of actual misuse.</p><p><strong>Rohin&apos;s opinion:</strong> While it is consistent to believe that OpenAI was just generating hype since GPT-2 was predictably not going to have major misuse applications, and this has now been borne out, I&apos;m primarily glad that we started thinking about publication norms <em>before</em> we had dangerous models, and it seems plausible to me that OpenAI was also thinking along these lines.</p><h1><strong>Other progress in AI</strong></h1><h3><strong>Reinforcement learning</strong></h3><p><u><a href=""https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning"">AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning</a></u> <em>(AlphaStar Team)</em> (summarized by Nicholas): <u><a href=""https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/"">AlphaStar</a></u> (<u><a href=""https://mailchi.mp/768a8130013f/alignment-newsletter-43"">AN #43</a></u>), DeepMind&#x2019;s StarCraft II AI, has now defeated a top professional player and is better than 99.8% of players. While previous versions were limited to only a subset of the game, it now plays the full game and has limitations on how quickly it can take actions similar to top human players. It was trained initially via supervised learning on human players and then afterwards trained using RL.</p><p>A challenge in learning StarCraft via self-play is that strategies exhibit non-transitivity: Stalker units beat Void Rays, Void Rays beat Immortals, but Immortals beat Stalkers. This can lead to training getting stuck in cycles. In order to avoid this, they set up a League of exploiter agents and main agents. The exploiter agents train only against the current iteration of main agents, so they can learn specific counter-strategies. The main agents then train against a mixture of current main agents, past main agents, and exploiters, prioritizing opponents that they have a lower win rate against.</p><p><strong>Nicholas&apos;s opinion:</strong> I think this is a very impressive display of how powerful current ML methods are at a very complex game. StarCraft poses many challenges that are not present in board games such as chess and go, such as limited visibility, a large state and action space, and strategies that play out over very long time horizons. I found it particularly interesting how they used imitation learning and human examples to avoid trying to find new strategies by exploration, but then attained higher performance by training on top of that.</p><p>I do believe progress on games is becoming less correlated with progress on AGI. Most of the key innovations in this paper revolve around the League training, which seems quite specific to StarCraft. In order to continue making progress towards AGI, I think we need to focus on being able to learn in the real world on tasks that are not as easy to simulate.</p><p><strong>Read more:</strong> <u><a href=""https://www.nature.com/articles/s41586-019-1724-z.epdf?author_access_token=lZH3nqPYtWJXfDA10W0CNNRgN0jAjWel9jnR3ZoTv0PSZcPzJFGNAZhOlk4deBCKzKm70KfinloafEF1bCCXL6IIHHgKaDkaTkBcTEv7aT-wqDoG1VeO9-wO3GEoAMF9bAOt7mJ0RWQnRVMbyfgH9A%3D%3D"">Paper: Grandmaster level in StarCraft II using multi-agent reinforcement learning</a></u></p><p><u><a href=""http://bair.berkeley.edu/blog/2019/09/30/deep-dynamics/"">Deep Dynamics Models for Dexterous Manipulation</a></u> <em>(Anusha Nagabandi et al)</em> (summarized by Flo): For hard robotic tasks like manipulating a screwdriver, model-free RL requires large amounts of data that are hard to generate with real-world hardware. So, we might want to use the more sample-efficient model-based RL, which has the additional advantage that the model can be reused for similar tasks with different rewards. This paper uses an ensemble of neural networks to predict state transitions, and plans by sampling trajectories for different policies. With this, they train a real anthropomorphic robot hand to be able to rotate two balls in its hand somewhat reliably within a few hours. They also trained for the same task in a simulation and were able to reuse the resulting model to move a single ball to a target location.</p><p><strong>Flo&apos;s opinion:</strong> The videos look impressive, even though the robot hand still has some clunkiness to it. My intuition is that model-based approaches can be very useful in robotics and similar domains, where the randomness in transitions can easily be approximated by Gaussians. In other tasks where transitions follow more complicated, multimodal distributions, I am more sceptical.</p><p><u><a href=""http://arxiv.org/abs/1910.04281"">Integrating Behavior Cloning and Reinforcement Learning for Improved Performance in Sparse Reward Environments</a></u> <em>(Vinicius G. Goecks et al)</em> (summarized by Zach): This paper contributes to the effort of combining imitation and reinforcement learning to train agents more efficiently. The current difficulty in this area is that imitation and reinforcement learning proceed under rather different objectives which presents a significant challenge to updating a policy learned from a pure demonstration. A major portion of this difficulty stems from the use of so-called &quot;on-policy&quot; methods for training which require a significant number of environment interactions to be effective. In this paper, the authors propose a framework dubbed &quot;Cycle-of-Learning&quot; (CoL) that allows for the off-policy combination of imitation and reinforcement learning. This allows the two approaches to be combined much more directly which grounds the agent&apos;s policy in the expert demonstrations while simultaneously allowing for RL to fine-tune the policy. The authors show that CoL is an improvement over the current state of the art by testing their algorithm in several environments and performing an ablation study.</p><p><strong>Zach&apos;s opinion:</strong> At first glance, it would seem as though the idea of using an off-policy method to combine imitation and reinforcement learning is obvious. However, the implementation is complicated by the fact that we want the value functions being estimated by our agent to satisfy the optimality condition for the Bellman equation. Prior work, such as <u><a href=""https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16976/16682"">Hester et al. 2018</a></u> uses n-step returns to help pre-training and make use of on-policy methods when performing RL. What I like about this paper is that they perform an ablation study and show that simple sequencing of imitation learning and RL algorithms isn&apos;t enough to get good performance. This means that combining the imitation and reinforcement objectives into a single loss function is providing a significant improvement over other methods.</p><h1><strong>News</strong></h1><p><u><a href=""https://www.convergenceanalysis.org/get-involved/"">Researcher / Writer job</a></u> (summarized by Rohin): This full-time researcher / writer position would involve half the time working with <u><a href=""https://www.convergenceanalysis.org/"">Convergence</a></u> on x-risk strategy research and the other half with <u><a href=""https://normative.io/"">Normative</a></u> on environmental and climate change analysis documents.</p>",rohinmshah,rohinmshah,Rohin Shah,
Zz6Nv7kR7xN3RAFAE,Insights from the randomness/ignorance model are genuine,insights-from-the-randomness-ignorance-model-are-genuine,https://www.lesswrong.com/posts/Zz6Nv7kR7xN3RAFAE/insights-from-the-randomness-ignorance-model-are-genuine,2019-11-13T16:18:55.544Z,6,2,23,False,False,,"<p>(Based on the <strong>randomness</strong>/<strong>ignorance </strong>model proposed in <a href=""https://www.lesswrong.com/posts/e5iwognG3Bi3TE7Dj/randomness-vs-ignorance"">1</a> <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\rightarrow""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span></span></span></span></span> <a href=""https://www.lesswrong.com/posts/v64sK88iY4kpHCwr9/reference-classes-for-randomness"">2</a> <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\rightarrow""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span></span></span></span></span> <a href=""https://www.lesswrong.com/posts/N7LqbC339BjyXFCbh/the-randomness-ignorance-model-solves-many-anthropic"">3</a>.)</p><p>The bold claim of this sequence thus far is that the <strong>randomness</strong>/<strong>ignorance</strong> model solves a significant part of the anthropics puzzle. (Not everything since it's still incomplete.) In this post I argue that this ""solution"" is genuine, i.e. it does more than just redefine terms. In particular, I argue that my definition of probability for <strong>randomness </strong>is the only reasonable choice.</p><p>The only axiom I need for this claim is that probability must be consistent with betting odds in all cases: if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> comes true in two of three situations where <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> is observed, and this is known, then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> needs to be <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{2}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span>, and no other answer is acceptable. This idea isn't new; the problem with it is that it doesn't actually produce a definition of probability, because we might not know how often <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> comes true if <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""B""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">B</span></span></span></span></span></span> is observed. It cannot define probability in the original Presumptuous Philosopher problem, for example.</p><p>But in the context of the <strong>randomness</strong>/<strong>ignorance </strong>model, the approach becomes applicable. Stating my definition for when uncertainty is <strong>random </strong>in one sentence, we get</p><blockquote><em>Your uncertainty about <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>, given observation <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span>, is <strong>random </strong>iff you know the relative frequency with which <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> happens, evaluated across all observations </em><span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span><em> that, for you, are indistinguishable to </em><span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> <em>with regard to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>.</em> </blockquote><p>Where ""relative frequency"" is the frequency of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> compared to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\neg H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">¬</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span>, i.e. you know that <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> happens in <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> out of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span> cases. A good look at this definition shows that it is precisely the condition needed to apply the betting odds criterion. So the model simply divides everything into those cases where you can apply betting odds and those where you can't.</p><p>If the Sleeping Beauty experiment is repeated sufficiently often using a fair coin, then roughly half of all experiments will run in the 1-interview version, and the other half will run the 2-interview version. In that case, Sleeping Beauty's uncertainty is <strong>random </strong>and the reasoning from <a href=""https://www.lesswrong.com/posts/N7LqbC339BjyXFCbh/the-randomness-ignorance-model-solves-many-anthropic"">3</a> goes through to output <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{2}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span> for it being Monday. The experiment being repeated sufficiently often might be considered a reasonably mild restriction; in particular, it is a given if the universe is large enough that everything which appears once appears many times. Given that Sleeping Beauty is still controversial, the model must thus be either nontrivial or wrong, hence ""genuine"".</p><p>Here is an alternative justification for my definition of <strong>random</strong> probability. Suppose <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> is the hypothesis we want to evaluate (like ""today is Monday"") and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> is the full set of observations we currently have (formally, the full brain state of Sleeping Beauty). Then what we care about is the value of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. Now consider the term <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{P(H|O)}{P(H|\neg O)}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 3.058em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 4.325em; top: -1.706em;""><span class=""mjx-mrow"" style=""""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 4.325em; bottom: -0.999em;""><span class=""mjx-mrow"" style=""""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">¬</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 3.058em;"" class=""mjx-line""></span></span><span style=""height: 1.913em; vertical-align: -0.707em;"" class=""mjx-vsize""></span></span></span></span></span></span>; let's call it <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span>. If <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span> is known, then <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> can be computed as <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O) = (1 + \lambda^{-1})^{-1}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-msubsup MJXc-space2""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span></span></span>, so knowledge of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span> implies knowledge of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> and vice-versa. But <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span> is more ""fundamental"" than <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, in the sense that it can be defined as the ratio of two frequencies. Take all situations in which <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> – or any other a set of observations <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O'""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.298em;"">′</span></span></span></span></span></span></span></span> which, from your perspective, is indistinguishable to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span></span></span></span></span> – is observed, and count in how many of those <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""H""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span></span></span></span></span> is true vs. false. The ratio of these two values is <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span>.</p><p>A look at the above criterion for <strong>randomness </strong>shows that it's just another way of saying that the value of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span> is known. Since, again, the value of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\lambda""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">λ</span></span></span></span></span></span> determines the value of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P(H|O)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;"">H</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">|</span></span></span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, this means that the definition of probability as betting odds, in the case that the relevant uncertainty is <strong>random</strong>, falls almost directly out of the formula.</p>",sil-ver,sil-ver,Rafael Harth,
HmmFqMZ3mhwRaoDhz,Mosquito Net Fishing,mosquito-net-fishing,https://www.lesswrong.com/posts/HmmFqMZ3mhwRaoDhz/mosquito-net-fishing,2019-11-13T13:30:01.731Z,15,6,0,False,False,,"<p>

I recently 

<a href=""https://www.facebook.com/groups/effective.altruists/permalink/2612847068771634/"">saw</a>
a study claiming:



</p><p>

</p>

<blockquote>
Distributed mosquito nets are intended to be used for malaria
protection, yet increasing evidence suggests that fishing is a primary
use for these nets, providing fresh concerns for already stressed
coastal ecosystems.
<br />
  —<a href=""https://link.springer.com/article/10.1007%2Fs13280-019-01280-0"">The
perverse fisheries consequences of mosquito net malaria prophylaxis in
East Africa</a> (Jones and Unsworth, 2019)
</blockquote>



<p>

Mosquito nets are harmful fishing tools because (a) they're
insecticide-treated and (b) with such small holes you catch a lot of
immature fish before they've had a chance to reproduce.  But how
harmful this practice is overall depends on how widespread it is.

</p>

<p>

The paper only tries to answer the question ""is using a mosquito net
for fishing a good idea,"" and to show that it's a ""primary use"" of
distributed bednets they cite <a href=""https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0191519"">The
use of mosquito nets in fisheries: A global perspective</a> (Short
et al. 2018).  This paper, however, doesn't describe the kind of research
that could back up their claim.


</p>

<p>

They ran on online survey which they left open to anyone to respond
for two months in 2015. They got 94 responses from people saying
they'd seen mosquito net fishing and 36 from people saying they
hadn't. This sort of survey can be useful for getting initial
qualitative information about whether it's a thing, how it looks, and
where to find it.  On the other hand, it's not a good tool for
estimating frequency: you don't know what sort of penetration the
survey got or how much people only responded to the survey when they
had something to share.

</p>

<p>

A study that tried to answer the question of whether distribution of
mosquito nets leads to mosquito net fishing would make a sample of
waterside communities that had recent net distributions and compare
them to a similar sample that had not.  But this is not that study,
and it's not capable of supporting a ""primary use"" claim.

</p>

<p>

Now, mosquito net fishing could still be bad even if only a very small
fraction of nets were used that way, due to the indiscriminate way it
collects fish regardless of size. It doesn't mean ""people aren't
sleeping under nets"" but could mean ""nets might be making communities
worse off.""  But there's not much reason to think this, and this study
doesn't give much new information.  GiveWell's <a href=""https://blog.givewell.org/2015/02/05/putting-the-problem-of-bed-nets-used-for-fishing-in-perspective/"">2015
blog post</a> in response to an <a href=""http://www.nytimes.com/2015/01/25/world/africa/mosquito-nets-for-malaria-spawn-new-epidemic-overfishing.html"">alarmist
New York Times article</a> is still very reasonable:

</p>

<blockquote>
Randomized control trials consistently show large declines in child
mortality from distributing nets and trends in malaria mortality and
net coverage rates also suggest that mass distribution of mosquito
nets has contributed to major declines in the burden of the
disease. This evidence comprises one of the most robust cases for
impact we've seen. The article makes the case for a possible harm to
fish stocks relying on highly limited evidence.
<p>
The article does highlight a potential need to experiment with
alternative approaches to malaria control in waterside, food-insecure
communities that have very low net usage rates. In these areas, people
shouldn't have to choose between malaria and hunger. But again, we see
this as a likely isolated problem, and a much smaller one than the
problem of insufficient nets for preventing malaria.
</p>
</blockquote>

  

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100121328453642"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
TfxP52qmgGpHvKXuu,SSC Madison: Neuroscience,ssc-madison-neuroscience,https://www.lesswrong.com/events/TfxP52qmgGpHvKXuu/ssc-madison-neuroscience,2019-11-13T07:06:16.366Z,1,1,0,False,False,,<p>Vegan food and discussion of SSC posts on Neuroscience</p>,marywang,marywang,marywang,
uRT5ukYQ9fBYpva9p,[Link] Is the Orthogonality Thesis Defensible? (Qualia Computing),link-is-the-orthogonality-thesis-defensible-qualia-computing,https://www.lesswrong.com/posts/uRT5ukYQ9fBYpva9p/link-is-the-orthogonality-thesis-defensible-qualia-computing,2019-11-13T03:59:00.955Z,-1,6,5,False,False,,"<p>Full title: Is the Orthogonality Thesis Defensible if We Assume Both Valence Realism and Open&nbsp;Individualism?</p><p><a href=""https://qualiacomputing.com/2019/11/09/is-the-orthogonality-thesis-defensible-if-we-assume-both-valence-realism-and-open-individualism/"">https://qualiacomputing.com/2019/11/09/is-the-orthogonality-thesis-defensible-if-we-assume-both-valence-realism-and-open-individualism/</a> </p><p>An excerpt:</p><br><blockquote>The cleanest typology for metaphysics I can offer is: some theories focus on computations as the thing that’s ‘real’, the thing that ethically matters – we should pay attention to what the *bits* are doing. Others focus on physical states – we should pay attention to what the *atoms* are doing. I’m on team atoms, as I note here: <a href=""https://forum.effectivealtruism.org/posts/FfJ4rMTJAB3tnY5De/why-i-think-the-foundational-research-institute-should"">Against Functionalism</a>.</blockquote><blockquote>My suggested takeaway: an <a href=""https://qualiacomputing.com/2018/07/23/open-individualism-and-antinatalism-if-god-could-be-killed-itd-be-dead-already/"">open individualist</a> who assumes <a href=""https://plato.stanford.edu/entries/computational-mind/"">computationalism</a> is true (team bits) will have a hard time coordinating with an open individualist who assumes physicalism is true (team atoms) — they’re essentially running incompatible versions of OI and will compete for resources.</blockquote><blockquote> As a first approximation, instead of <a href=""https://qualiacomputing.com/2015/12/17/ontological-qualia-the-future-of-personal-identity/"">three theories of personal identity</a> – Closed Individualism, Empty Individualism, Open Individualism – we’d have six. CI-bits, CI-atoms, EI-bits, EI-atoms, OI-bits, OI-atoms. </blockquote><blockquote>Whether the future is positive will be substantially determined by how widely and deeply we can build positive-sum moral trades between these six frames.</blockquote>",ioannes_shade,ioannes_shade,ioannes,
ptmmK9PWgYTuWToaZ,What I’ll be doing at MIRI,what-i-ll-be-doing-at-miri,https://www.lesswrong.com/posts/ptmmK9PWgYTuWToaZ/what-i-ll-be-doing-at-miri,2019-11-12T23:19:15.796Z,112,44,6,False,False,,"<p><em>Note: This is a personal post describing my own plans, not a post with actual research content.</em></p>
<p>Having finished my internship working with Paul Christiano and others at OpenAI, I’ll be moving to doing research at MIRI. I’ve decided to do research at MIRI because I believe MIRI will be the easiest, most convenient place for me to continue doing research in the near future. That being said, there are a couple of particular aspects of what I’ll be doing at MIRI that I think are worth being explicit about.</p>
<p>First, and most importantly, this decision does not represent any substantive change in my beliefs regarding AI safety. In particular, my research continues to be focused around solving <a href=""https://arxiv.org/abs/1906.01820"">inner alignment</a> for <a href=""https://www.alignmentforum.org/s/EmDuGeRw749sD3GKd"">amplification</a>. My post on <a href=""https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"">relaxed adversarial training</a> continues to represent a fairly up-to-date form of what I think needs to be done along these lines.</p>
<p>Second, my research will remain public by default. I have discussed with MIRI their <a href=""https://intelligence.org/2018/11/22/2018-update-our-new-research-directions/"">decision to make their research non-disclosed-by-default</a> and we agreed that my research agenda is a reasonable exception. I strongly believe in the importance of collaborating with both the AI safety and machine learning communities and thus believe in the need for sharing research. Of course, I also fully believe in the importance of carefully reviewing possible harmful effects from publishing before disclosing results—and will continue to do so with all of my research—though I will attempt to publish anything I don’t believe to pose a meaningful risk.</p>
<p>Third—and this should go without saying—I fully anticipate continuing to collaborate with other researchers at other institutions such as OpenAI, Ought, CHAI, DeepMind, FHI, etc. The task of making AGI safe is a huge endeavor that I fully believe will require the joint work of an entire field. If you are interested in working with me on anything (regarding inner alignment or anything else) please don’t hesitate to send me an email at <a href=""mailto:evanjhub@gmail.com"">evanjhub@gmail.com</a>.</p>
",evhub,evhub,evhub,
Lb3xCRW9usoXJy9M2,"Platonic rewards, reward features, and rewards as information",platonic-rewards-reward-features-and-rewards-as-information,https://www.lesswrong.com/posts/Lb3xCRW9usoXJy9M2/platonic-rewards-reward-features-and-rewards-as-information,2019-11-12T19:38:10.685Z,20,6,2,False,False,,"<p>Contrast these two expressions (hideously mashing C++ and pseudo-code):</p>
<ol>
<li><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\operatorname{argmax}_x r(x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">argmax</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.377em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char""></span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></span></span>,</li>
<li><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\operatorname{argmax}_x *(\&amp;r)(x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.519em;"">argmax</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.377em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span><span class=""mjx-mo MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&amp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</li>
</ol>
<p>The first expression just selects the action <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""x""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span></span></span></span></span> that maximises <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r(x)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">x</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> for some function <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, intended to be seen as a reward function.</p>
<p>The second expression borrows from the syntax of C++; <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(\&amp;r)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&amp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> means the memory address of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span></span></span></span>, while <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""*(\&amp;r)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&amp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> means the object at the memory address of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span></span></span></span>. How is that different from <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span></span></span></span></span> itself? Well, it's meant to emphasise the ease of the agent <a href=""https://arxiv.org/abs/1605.03143"">wireheading</a> in that scenario: all it has to do is overwrite whatever is written at memory location <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""(\&amp;r)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&amp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. Then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""*(\&amp;r)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em;"">&amp;</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> can become - whatever the agent wants it to be.</p>
<p>Let's dig a bit deeper into the contrast between reward functions that can be easily wireheaded and those that can't.</p>
<h1>The setup</h1>
<p>The agent <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> interacts with the environment in a series of timesteps, ending at time <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t=N""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span></span></span></span>.</p>
<p>There is a 'reward box' <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> which takes observations/inputs <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span> and outputs some numerical reward amount, given by the voltage, say. The reward function is a function of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>; at timestep <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span>, that function is <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. The reward box will thus give out a reward of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. Initially, the reward function that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> implements is <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()=R_0()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</p>
<p>The agent also gets a separate set of observations <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^A_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>; these observations may include full information about <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>, but need not.</p>
<h2>Extending the training distribution</h2>
<p>Assume that the agent has had a training phase, for negative values of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span>. And, during that training phase, <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> was always equal to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</p>
<p>If <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> is trained as a reinforcement agent, then there are two separate value functions that it <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> can learn to maximise:</p>
<ol>
<li><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb{E}\sum_{t=0}^N r(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">E</span></span></span></span><span class=""mjx-munderover MJXc-space1""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size1-R"" style=""padding-top: 0.519em; padding-bottom: 0.519em;"">∑</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.31em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.433em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span><span class=""mjx-mi MJXc-space1""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, or</li>
<li><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathbb{E}\sum_{t=0}^N R_t(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-ams-R"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">E</span></span></span></span><span class=""mjx-munderover MJXc-space1""><span class=""mjx-base""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-size1-R"" style=""padding-top: 0.519em; padding-bottom: 0.519em;"">∑</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.31em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.433em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;"">N</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span></span><span class=""mjx-msubsup MJXc-space1""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</li>
</ol>
<p>Since <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t() = r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t<0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>, which is all the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span> that the agent has ever seen, both fit the data. The agent has not encountered a situation where it can change the physical behaviour of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> to anything other than <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> - how will it deal with that?</p>
<h2>Wireheading is in the eye of the beholder</h2>
<p>Now, it's tempting to call <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> the true reward, and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> the wireheaded reward, as the agent redefines the reward function in the reward box.</p>
<p>But that's a judgement call on our part. Suppose that we wanted the agent to maintain a high voltage coming out of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span>, to power a device. Then <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is the 'true' reward, while <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is just information about what the current design of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> is.</p>
<p>This is a key insight, and a reason that avoiding wireheading is so hard. 'Wireheading' is not some ontologically fundamental category. It is a judgement on our part: some ways of increasing a reward are legitimate, some are not.</p>
<p>If the agent is to ever agree with our judgement, then we need ways of getting that judgement into the agent, somehow.</p>
<h1>Solutions</h1>
<h2>The agent with a platonic reward</h2>
<p>One way of getting the reward into the agent is to formally define it within the agent itself. If the agent knows <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, and is explicitly trained to maximise it, then it doesn't matter what <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> changes to - the agent will still be wanting to maximise <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. Indeed, in this situation, the reward box <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> is redundant, except maybe as a training crutch.</p>
<p>What about self modification, or the agent just rewriting the observations <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>? Well, if the agent is motivated to maximise the sum of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, then, by the same argument as the standard Omohundro ""<a href=""https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf"">basic AI drives</a>"", it will want to preserve maximising <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> as the goal of its future copies. If we're still worried about this, we could insist that the agent <a href=""https://en.wikipedia.org/wiki/Quine_(computing)"">knows about its own code</a>, including <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, and acts to preserve <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> in the future<sup class=""footnote-ref""><a href=""#fn-uZBfEQk2wxMmnsv3E-1"" id=""fnref-uZBfEQk2wxMmnsv3E-1"">[1]</a></sup>.</p>
<h2>The agent modelling the reward</h2>
<p>Another approach is to have the agent treat the data from its training phase as information, and try to model the correct reward.</p>
<p>This doesn't require the agent to have access to <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, from the beginning; the physical <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> provides data about, and after the training phase, the agent might disassemble <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> entirely (thus making <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span> trivial) in order to get at what <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is.</p>
<p>This approach relies on the agent having good priors over the reward function<sup class=""footnote-ref""><a href=""#fn-uZBfEQk2wxMmnsv3E-2"" id=""fnref-uZBfEQk2wxMmnsv3E-2"">[2]</a></sup>, and on these priors being well-grounded. For example, if the agent opens the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> box and sees a wire splitting at a certain point, it has to be able to interpret this a data on <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> in a sensible way. In other words, we interpret <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> as implementing a function between <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span> and the reward signal; it's important that the agent, upon disassembling or analysing <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span>, interprets it in the same way.</p>
<p>Thus we need the agent to interpret certain features of the environment (eg the wire splitting) in the way that we want it to. We thus want the agent to have an model of the environment, where the key features are abstracted in the correct way.</p>
<h2>Provide examples of difference</h2>
<p>The third example is to provide examples of divergence between <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>. We could, for example, unplug the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span> for a time, then manually give the agent the rewards during that time. This distinguishes the platonic <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> we want it to calculate, from the physical <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> that the reward function implements.</p>
<p>Modifying the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> during the training phase, while preserving <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> as the ""true"" reward, also allows the agent to learn the difference. Since <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is physical while <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> is idealised, it might be a good idea to have the agent explicitly expect noise in the <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t(o^R_t)""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> signal; including the expectation of noise in the agent's algorithm will prevent the agent overfitting to the actual <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, increasing the probability that it will figure out the idealised <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>.</p>
<p>In the subsection above, we treated features of the reward box as information that the agent had to interpret in the desirable way. Here we are also wanting the agent to learn features correctly, but we are teaching it by example rather than by model - exploring the contours of the feature, illustrating when the feature behaved in a proper informative way, and when it failed to do so.</p>
<h1>Extending the problem</h1>
<p>All the methods above suffer from the same issue: though they might prevent wireheading <em>within</em> <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> or <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span>, they don't prevent wireheading <em>at the input boundary</em> for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span></span></span></span>, namely the value of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>.</p>
<p>As it stands, even the agent with a platonic reward will be motivated to maximise <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> by taking control of the values of <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>.</p>
<p>But the methods that we have mentioned above allow us to (try and) extend the boundary of wireheading out into the world, and hopefully reduce the problem.</p>
<p>To model this, let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""W_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.104em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;"">W</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span> be the world at time <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span> (which is a function of the agent's past actions as well as the world's past), and let <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathcal{F}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-cal-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.11em;"">F</span></span></span></span></span></span></span></span> be the set of functions <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> such that <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f(W_t)=o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.104em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;"">W</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.077em; padding-bottom: 0.298em;"">=</span></span><span class=""mjx-msubsup MJXc-space3""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span> for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t < 0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>.</p>
<p>Similarly to how the agent can't distinguish between <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""R_t()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span> and <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""r()""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">r</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span></span></span></span></span>, if they were equal for all <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t<0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>, the agent can't distinguish whether it should really maximise <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f_1""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.06em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span></span></span></span></span></span> or <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f_2""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.06em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span></span></span></span></span></span>, if they are both in <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\mathcal{F}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-cal-R"" style=""padding-top: 0.446em; padding-bottom: 0.372em; padding-right: 0.11em;"">F</span></span></span></span></span></span></span></span>.</p>
<p>In a sense, the agent's data for <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t<0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">&lt;</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span> allows it to do function approximation for its objective when <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""t\geq 0""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.446em;"">≥</span></span><span class=""mjx-mn MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">0</span></span></span></span></span></span>. And we want it to learn a good function, not a bad, wireheady one (again, the definition of wireheading depends on our objective).</p>
<p>The easiest and most general <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span> to learn is likely to be the one that outputs the actual physical <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""o^R_t""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">o</span></span></span><span class=""mjx-stack"" style=""vertical-align: -0.287em;""><span class=""mjx-sup"" style=""font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">R</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span></span></span>; and this is also the most likely candidate for leading to wireheading. If we want the agent to learn a different <span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""f""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;"">f</span></span></span></span></span></span>, how can we proceed?</p>
<h2>Platonic</h2>
<p>If we can model the whole world (or enough of it), we can present the agent with a labelled model of the whole environment, and maybe specify exactly what gives a true reward and what doesn't.</p>
<p>This is, of course, impossible; but there are variants on this idea which might work. In <a href=""https://agentfoundations.org/item?id=657"">these</a> <a href=""https://agentfoundations.org/item?id=848"">examples</a>, the agent is running on a virtual environment, and knows the properties of this virtual environment. It is then motivated to achieve goals within that virtual environment, but the second that the virtual environment doesn't behave as expected - the second our abstraction about that environment fails - the agent's motivation changes.</p>
<h2>Modelling true reward</h2>
<p>It might not be feasible to provide the agent with a full internal model of the environment; but we might be able to do part of the job. If we can give the agent a grounded definition of key features of the environment - what counts as a human, what counts as a coffee cup, what counts as a bin - then we can require the agent to model its reward function as being expressed in a particular way by those features.</p>
<p>Again, this is controlling the abstraction level at which the agent interprets the reward signal. So, if an agent sees a human get drenched in hot coffee and fall into a bin, it will interpret that as just described, rather than seeing it as the movement of atoms out in the world - or as the movement of electrons within its own circuits.</p>
<h2>Examples of feature properties</h2>
<p>Just as in the previous section, the agent could be taught about key features of the environment by example - by showing examples of good behaviour, of bad behaviour, of when abstractions hold (a human hand covered in hot coffee is still a human hand) and of when they fail (a human hand long detached from its owner is not a human, even in part, and need not be treated in the same way).</p>
<p>There are a lot of ideas as to who these principles could be illustrated, and, the more complex the environment and the more powerful the agent, the less likely it is that we have covered all the key examples sufficiently.</p>
<h1>Feature information</h1>
<p>Humans will not be able to describe all the properties of the key features we want to have as part of the reward function. But this is an area where the agent can ask the humans for more details about them, and get more information. Does it matter if the reward comes as a signal immediately, a delayed signal, or as a letter three weeks from now? When bringing the coffee to the human, what counts as spilling it, and what doesn't? Is this behaviour ok? What about this one?</p>
<p>Unlike issues of values, where its very easy to get humans confused and uncertain by expanding to new situations, human understanding of the implicit properties of features is more robust - the agent can ask many more questions, and consider many more hypotheticals, without the <a href=""https://www.lesswrong.com/posts/ix3KdfJxjo9GQFkCo/web-of-connotations-bleggs-rubes-thermostats-and-beliefs"">web of connotations</a> of the feature collapsing.</p>
<p>This one way we could <a href=""https://www.lesswrong.com/posts/urZzJPwHtjewdKKHc/using-expected-utility-for-good-hart"">combat Goodhart problems</a>, by including all the uncertainty and knowledge. In this case, the agent's definition of the key property of the key features, is... what a human could have told it about them if it had asked.</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-uZBfEQk2wxMmnsv3E-1"" class=""footnote-item""><p>This is an area where there is an overlap between issues of wireheading, symbol grounding, and self-modelling. Roughly speaking, we want a well-specified, well-grounded reward function, and an agent that can model itself in the world (including knowing the purpose of its various components), and that can distinguish which features of the world it can legitimately change to increase the reward, and which features it should not change to increase reward.</p>
<p>So when an agent misbehaves with a ""make humans happy"" reward, this might be because terms like ""humans"" and ""happy"" are incorrectly defined, or not well-grounded, or because the agent wireheads the reward definition. In practice, there is a lot of overlap between all these failure modes, and they cannot necessarily be cleanly distinguished. <a href=""#fnref-uZBfEQk2wxMmnsv3E-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-uZBfEQk2wxMmnsv3E-2"" class=""footnote-item""><p>The platonic case can be seen as modelling, with a trivial prior. <a href=""#fnref-uZBfEQk2wxMmnsv3E-2"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
",Stuart_Armstrong,stuart_armstrong,Stuart_Armstrong,
HNDhcfqKpzMuTK2EN,Attach Receipts to Credit Card Transactions,attach-receipts-to-credit-card-transactions,https://www.lesswrong.com/posts/HNDhcfqKpzMuTK2EN/attach-receipts-to-credit-card-transactions,2019-11-12T16:30:01.678Z,6,2,8,False,False,,"<p>

If you log into your credit card account you'll see a list of charges,
each with a date, amount, and merchant.  It would be helpful if this
also included receipt data:



</p><p>

</p>

<ul>

<li><p>If you didn't recognize a charge, seeing what it was for could
remind you.</p></li>

<li><p>If you needed a receipt for taxes or reimbursement one could be
captured automatically.</p></li>

<li><p>Personal finance tools (or corporate equivalents for company
cards) could track spending with higher granularity.</p></li>

<li><p>Because the credit card company knows what the items are they
can better detect fraud.</p></li>

</ul>



<p>

Receipt data isn't currently part of the protocol used for charges;
you'd need to spec out something that let companies communicate
everything a receipt can communicate today.  This would be a very
large change, but everyone who would need to make changes can have
incentives in the right direction:

</p>

<p>

</p>

<ul>

<li><p>The card company likes it because it can market their card as
supporting receipts and better detect fraud.</p></li>

<li><p>The merchant likes it because they see fewer chargebacks and
the credit card company probably gives them slightly better
rates.</p></li>

<li><p>Point-of-sale makers like it because they get to sell a lot of
upgrades.</p></li>

</ul>



<p>

The main downside I can think of, aside from it being a lot of work,
is that people might not want their credit card company knowing the
particular products they bought.  The company would probably want to
sell this to marketers, though there would be plenty of time to pass
regulations limiting that if we wanted to.  Personally, I don't mind:
the merchant is probably already selling my purchase information or
will soon.  And the money the credit card company gets from selling
the data, since it's a competitive market, probably mostly gets passed
on as higher cardholder incentives or higher incentives to merchants
to adopt receipt sharing.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100121193154782"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
HDzqaZXQCTXzScPh5,An optimal stopping paradox,an-optimal-stopping-paradox,https://www.lesswrong.com/posts/HDzqaZXQCTXzScPh5/an-optimal-stopping-paradox,2019-11-12T08:51:03.199Z,11,6,10,False,False,,"<html><head></head><body><p>Consider an optimal stopping problem: a company at each time step grows by some constant, and has a certain probability of shutting down. You decide when to sell the company.</p>
<p>Since the math is cleaner in continuous time, we consider the continuous time. Then the company has a linearly increasing value βt, and an exponentially decaying survival curve e^(-αt).</p>
<p>Another framing of the paradox: Schrodinger wants to make a new record for the longest surviving cat, so he put a cat in the box with an atom that might decay and kill the cat, and waits. When should he open the box?</p>
<p>Since at each moment in time, you face the exact same problem (linearly increasing reward, α-exponentially decaying survival rate), if you decide to wait at t=0, you would decide to wait forever, and thus receive no reward.</p>
<p>There are several possible replies to this paradox, none of which is satisfactory to me:</p>
<ol>
<li>""This looks like St. Petersburg Paradox."". No, because at time t=0, the expectation is β/α^2. In fact, the payoff can grow faster than βt, such as like t^3, and it would still have finite expectation.</li>
<li>Claim that expectation maximization decision theory is flawed. This doesn't stop the procrastination. As long as your decision is purely based on the future, and your rational decision process is constant in time, you either immediately sell the company or never sell the company.</li>
<li>Try some kind of discounting, like exponential discounting. This doesn't stop the procrastination., since at any time, selling the company gives you 0 extra expected reward, and waiting gives you <em>some</em> positive extra expected reward, no matter how much you discount the future.</li>
<li>Claim that there should be a finite lifetime. You can't wait forever. If there is a finite lifetime, then the same decision analysis would tell you to procrastinate until the very end. This effectively is procrastinating forever. It does not converge to a reasonable finite waiting time as your lifetime goes to infinity.</li>
<li>Claim that one should stick to past decisions even when they don't make sense from a purely future-looking decision theory. Such decision theory seems to be
just sweeping time-inconsistency under the rug, and I'm sure would suffer from serious paradoxes of their own.</li>
<li>Claim that there is no paradox, and procrastination is really the rational action. I'd not claim a strategy that guarantees 0 reward to be rational.</li>
</ol>
<p>Option 5 seems at least to have some meaning to it. Sticking to it would mean that, for example, one would at t=0 decide to choose T to maximize βT e^(-αT), then at t=T really sell the company, even though it's irrational, conditional on the company still alive at t=T.</p>
</body></html>",Yuxi_Liu,yuxi_liu,Yuxi_Liu,
spPPnbZhNoTrZTdic,Can indifference methods redeem person-affecting views?,can-indifference-methods-redeem-person-affecting-views,https://www.lesswrong.com/posts/spPPnbZhNoTrZTdic/can-indifference-methods-redeem-person-affecting-views,2019-11-12T04:23:10.011Z,10,4,3,False,True,,"<p>My uninformed paraphrase/summary of &quot;the person-affecting view&quot; is: &quot;classical utilitarianism + indifference to creating/destroying people&quot;.</p><p>These views seem problematic (e.g. see <a href=""https://80000hours.org/podcast/episodes/hilary-greaves-global-priorities-institute/"">Hillary Greeves interview on 80k)</a>, and difficult to support.  </p><p>Indifference methods (e.g. see <a href=""https://arxiv.org/abs/1712.06365"">Stuart Armstrong&apos;s paper</a>) seem like they might be a way to formalize the person-affecting view in a rigorous way.</p><p>If we have a policy, we can always reverse engineer a corresponding reward function (see <a href=""https://arxiv.org/abs/1811.07871"">our Reward Modelling agenda</a>, bottom page 6).</p><p>So while there might still be highly counter-intuitive bullets that need to be bitten, this might provide a way of cashing out person-affecting views in a way that is mathematically coherent/consistent.</p><p>What do you think?  Does it work?</p><p>And is that even an open problem, or an interesting result to people in ethics?</p><br>",capybaralet,david-scott-krueger-formerly-capybaralet,David Scott Krueger (formerly: capybaralet),
X6f3KGYgnXxCHAnAq,Operationalizing Newcomb's Problem,operationalizing-newcomb-s-problem,https://www.lesswrong.com/posts/X6f3KGYgnXxCHAnAq/operationalizing-newcomb-s-problem,2019-11-11T22:52:52.835Z,34,12,23,False,False,,"<p>The standard formulation of Newcomb's problem has always bothered me, because it seemed like a weird hypothetical designed to make people give the wrong answer. When I first saw it, my immediate response was that I would two-box, because really, I just don't believe in this ""perfect predictor"" Omega. And while it may be true that <a href=""http://mindingourway.com/newcomblike-problems-are-the-norm/"">Newcomblike problems are the norm</a>, most real situations are not so clear cut. It can be quite hard to demonstrate why causal decision theory is inadequate, let alone build up an intuition about it. In fact, the closest I've seen to a real-world example that made intuitive sense is <a href=""https://sinceriously.fyi/narrative-breadcrumbs-vs-grizzly-bear/"">Narrative Breadcrumbs vs Grizzly Bear</a>, which still requires a fair amount of suspension of disbelief. </p><p>So, here I'd like to propose a thought experiment that would (more or less*) also work as an actual experiment.</p><p><em>A psychologist contacts you and asks you to sign up for an experiment in  exchange for a payment. You agree to participate and sign all the  forms. The psychologist tells you: ""I am going to administer a polygraph  (lie detector) test in which I ask whether you are going to sit in our waiting room for ten minutes after we finish the experiment. I won't tell you whether you passed, but I will give you some money in a sealed envelope, which you may open once you leave the building. If you say yes, and you pass the test, it will  be $200. If you say no, or you fail the test, it will be $10. Then we  are done, and you may either sit in the waiting room or leave. Please  feel no obligation to stay, as the results are equally useful to us either way. The polygraph test is not perfect, but has so far been 90% accurate  in predicting whether people stay or leave; 90% of the people who stay for ten minutes get $200, and 90% of those who leave immediately get $10."" </em></p><p>You say you'll stay. You get your envelope. Do you leave the building right away, or sit in the waiting room first?</p><p>Does the answer change if you are allowed to open the envelope before deciding?</p><p>*I don't know if polygraphs are accurate enough to make this test work in the real world or not.</p>",ErickBall,erickball,ErickBall,
mpXipcrNFXdyK38An,SSC Dublin Meetup - Atypical Minds and Book Recommendations,ssc-dublin-meetup-atypical-minds-and-book-recommendations,https://www.lesswrong.com/events/mpXipcrNFXdyK38An/ssc-dublin-meetup-atypical-minds-and-book-recommendations,2019-11-11T21:07:14.159Z,1,1,0,False,False,,"<p>Hey everyone! </p><p><br>The next meetup will be on Saturday the 23rd of November at 2pm. </p><p><br>We were a bit cramped in Cafe Nero last time, so this meetup will be in the Black Sheep on Capel Street. They have a huge table tucked away at the back, and they take bookings. </p><h2><br><strong>Discussion Topics</strong></h2><p><br><strong>1) Atypical Minds</strong></p><p><br>Main topic post: <a href=""https://slatestarcodex.com/2014/03/17/what-universal-human-experiences-are-you-missing-without-realizing-it/"">What Universal Human Experiences Are You Missing Without Realising It?</a>&nbsp;- I’d recommend reading the comments on this one too, lots of really interesting examples. </p><p><br>Related Posts: </p><ul><li><a href=""https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example"">Generalizing From One Example</a></li><li><a href=""https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/"">Typical Mind and Gender Identity</a></li><li><a href=""https://slatestarcodex.com/2014/03/20/typical-mind-and-disbelief-in-straight-people/"">Typical Mind and Disbelief in Straight People</a></li><li><a href=""https://www.lesswrong.com/posts/pczHfyxmnFhtKthqR/typical-mind-and-politics"">Typical Mind and Politics</a></li></ul><br><p><strong>2) Book Recommendations</strong></p><p><br>Recommend a book that taught you something useful, or made you change your mind, or otherwise improved your thinking in some way.&nbsp; </p><p><br>It doesn’t have to be a book either, it could be a documentary, podcast, website - Any piece of content that you think other people might find valuable!&nbsp; </p>",dan-molloy,dan-valentine,Dan Valentine,
bzt3gebSTTqE8hXSm,"[Health] [Math] Proofs, forgetting, and an eldritch god",health-math-proofs-forgetting-and-an-eldritch-god,https://www.lesswrong.com/posts/bzt3gebSTTqE8hXSm/health-math-proofs-forgetting-and-an-eldritch-god,2019-11-11T18:31:05.289Z,7,5,4,False,False,,"<p><strong><em>This post made me realize something very important, and in hindsight very obvious about myself. I'm leaving it up for future reference. I don't think it's actually very well written.</em></strong></p><p><strong><em>Originally, it was tagged [Math], not [Health] and [Math].</em></strong></p><p>I envy computers sometimes for their memory.</p><p>My basic intuition from learning signals and Fourier transforms in my EE major is that any limited-space memory system that has to adapt to new surroundings, also has to have some factor by which old memories decay over time -- otherwise the system would become saturated with information content. (I am not being precise with these terms. Look where I point.)</p><p>But computers don't usually have as ruthless a ""use-it-or-lose-it"" forgetting mechanism as human brains do built into them. Their decay is mostly due to (i) other conscious agents going in and rearranging their memories; (ii) the slow encroaching wave of entropy on their hard disks. (i) can be dealt with by locking the computer in a room away from human hands, and praying the Poincare recurrence theorem combined with thermodynamic noise doesn't imply it will eventually birth an AGI all on its own. But that's a symptom of (ii), which can be mostly dealt with via <a href=""https://en.wikipedia.org/wiki/RAID"">RAID-5</a> and an influx of hard drives. With those two in place, on a human timescale, computers essentially never have to forget something once it's encoded in memory.</p><p>Human beings, we aren't like that. We forget. We forget so <em>easily</em>. And we warp the memories we do have to fit our twisted little narratives in the moment. I'm not a terribly existential person, but the fact that we ship of Theseus ourselves according to the <em>ridiculous</em> whims of <em>future us, </em>people just like us now but ever-so-slightly slower, crazier, and more tied down to the local flora for their survival, you have to admit -- it's a little unsettling.</p><p>I've been having a bit of a crisis over the last few days. It's about math, as all my crises are.</p><p>The problem is simple: I prove $X$ once. I walk away for a few days. When I go back to look at $X$ again, I suddenly realize the steps of the proof don't immediately spring to mind any more. I have to <em>prove it again</em>, don't I; or accept it on faith that $X$ is a fact, that former me proved $X$ to be a fact, that no, there's really nothing much to be gained from re-proving something in roughly the same way that I did before.</p><p>The cognition is contrarian: Proofs take effort. I don't like wasting effort. And just because I could prove $X$ once is no guarantee at all that I could prove $X$ again right now -- memories decay, I only have limited vision and limited CPU cycles, maybe I actually can't prove $X$ again, and that means I don't really <em>understand</em> $X$ in some sense, and I won't know unless I try, right? And math is supposed to be this tower of logic, where -- in theory -- we could break everything all the way down to set/category theory and build it back up, right? That's what good mathematicians do, right? Aren't we supposed to be the <em>true Scotsmen</em> of deductive reasoning?</p><p>---</p><p>I once ran a campaign where there were 4 deities. One of them was called the White Noise; the Noise derived its power from all <em>friction</em> generated in the environment. When you and a stranger are walking down a street and don't want to bump into each other, but you step in the same direction they step, and then you step the other way at the same time that they do -- the White Noise feeds. When you're short 2 cents at the convenience store and the clerk says ""Don't worry about it"", but then you leave and worry that maybe the clerk will get fired because of the disparity at the end of the day. When lovers quarrel. When soldiers don't fight as hard as they should because they don't fully believe in their cause -- but also (scholars posit) the whole friction generated by war itself, the ultimate (pacifists say) zero-sum waste of resources. Eventually all becomes friction, and time stops.</p><p>If I had to choose a deity out of the 4 to follow, it would be the White Noise in a heartbeat. To me, it represents the ultimate decision that pointless human bickering is far preferable to brutal, paperclip-maximizing, mechanized efficiency.</p><p>Which is why it's so <em>fucking </em>stressful to me that the one time I <em>do </em>want mechanized efficiency, I can't seem to acquire it. I just want to be able to prove something once, and then store the memory of that proof in my head so that I don't have to keep doing it over and over again, man. Is that too much to ask?</p><p>---</p><p>Yes, it is. But let's go back to what we said before.</p><p>Mathematicians (human ones at least, not Coq or something) don't <em>actually</em> work in a strictly deductive fashion. Even if they wanted to, they realistically couldn't. We all have limits to what we can store in our short term memory, and the limits vary, but they presumably don't vary by <em>orders of magnitude</em>; similarly, we all have limits to how fast we can think through the logical implications of a thing, but again, this doesn't vary by <em>orders of magnitude</em>. And the subset of math we care about here is math-as-group-enterprise; so the fact that mathematicians are all competing for roughly the same rewards suggests that they would find ways to <em>work around</em> those fundamental limits in order to outdo each other. So it's certainly not the case that every other good mathematician on the planet does a proof once, memoizes exactly how to do it, and then just keeps that memory fresh.</p><p>What <em>does</em> happen, then? Probably what we would expect from a common sense view of human nature: They forget. They forget almost everything they learn at the undergraduate and graduate level, just like anyone else would. Oh, they probably don't forget as much relevant to their field of interest -- but I highly doubt there's any tenured, non-set theory professor out there who consciously reruns through proving Zorn's lemma from scratch once or twice a year, just to make sure they can still do it. It's a difficult, convoluted proof, and they have more <em>important</em> work to be done. <em>New</em> work.</p><p>Now, I don't think any working mathematician will <em>admit</em> this. They'll probably say something along the lines of, ""Well of course I can't prove it on sight right now, but give me a couple days and I can probably get back to you with one. Just need to refresh my memory."" That might even be true. But they're not just <em>refreshing their memory</em> -- they're turning a <em>highly-tuned neural network, </em>full of a lifetime of proving difficult propositions and engaging in clever logical tricks, back towards a problem they already understood the solution to once when they were less well-attuned.</p><p>Maybe, someday, we'll be able to fuck around with human memory enough that nobody will forget how to do a proof after the first time they spend energy on figuring out how to do it. But that day isn't today. Today, the White Noise scores a point for human imperfection. And while that might be <em>locally</em> frustrating -- think how much easier I would have it if that were the case! -- I wouldn't actually want to live in a world where everyone, universally, had those powers of memory. The competition would just adapt, quickly, to the newfound power, and I wouldn't end up with an obvious improvement in the group effort as before. I want it for me, and me alone; and that's a sign that I'm not actually upset for a good reason. I'm just being selfish. Even my OCD channels human bias.</p>",aaq,aaq,aaq,
N7LqbC339BjyXFCbh,The randomness/ignorance model solves many anthropic problems,the-randomness-ignorance-model-solves-many-anthropic,https://www.lesswrong.com/posts/N7LqbC339BjyXFCbh/the-randomness-ignorance-model-solves-many-anthropic,2019-11-11T17:02:33.496Z,9,7,5,False,False,,"<p>(Follow-up to <a href=""https://www.lesswrong.com/posts/e5iwognG3Bi3TE7Dj/randomness-vs-ignorance"">Randomness vs Ignorance</a> and <a href=""https://www.lesswrong.com/posts/v64sK88iY4kpHCwr9/reference-classes-for-randomness"">Reference Classes for Randomness</a>)</p><p>I've argued that all uncertainty can be divided into <strong>randomness </strong>and <strong>ignorance</strong> and that this model is free of contradictions. Its purpose is to resolve anthropic puzzles such as the Sleeping Beauty problem.</p><p>If the model is applied to these problems, they appear to be underspecified. Details required to categorize the relevant uncertainty are missing, and this underspecification might explain why there is still no consensus on the correct answers. However, if the missing pieces are added in such a way that all uncertainty can be categorized as <strong>randomness</strong>, the model does give an answer. Doing this doesn't just solve a variant of the problem, it also highlights the parts that make these problems distinct from each other.</p><p>I'll go through two examples to demonstrate this. The underlying principles are simple, and the model can be applied to every anthropic problem I know of.</p><p><u><a href=""https://wiki.lesswrong.com/wiki/Sleeping_Beauty_problem"">1. Sleeping Beauty </a></u></p><p>In the original problem, a coin is thrown at the beginning to decide between the one-interview and the two-interview version of the experiment. In our variation, we will instead repeat the experiment <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""2n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> times and have <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> of those run the one-interview version, and another <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> run the two-interview version. Sleeping Beauty knows this but isn't being told which version she's currently participating in. This leads to <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""2n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> instances of Sleeping Beauty waking up on Monday, and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""n""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">n</span></span></span></span></span></span> instances of her waking up on Tuesday. All instances fall into the same reference class, because there is no information available to tell them apart. Thus, Sleeping Beauty's uncertainty about the current day is <strong>random</strong> with probability <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{2}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span> for Monday.</p><p><u><a href=""https://www.lesswrong.com/posts/RcvyJjPQwimAeapNg/torture-vs-dust-vs-the-presumptuous-philosopher-anthropic"">2. Presumptuous Philosopher</a></u></p><p>In the original problem, the debate is about the question of how the size of the universe influences the probability that the universe is large, but it is unspecified whether our current universe is the only universe.</p><p>Let's fill in the blanks. Suppose there is one universe at the base of reality which runs many simulations, one of them being ours. The simulated universes can't run simulations themselves, so there are only two layers. Exactly half of their simulations are of ""small"" universes (say with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""10^{15}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">15</span></span></span></span></span></span></span></span></span></span> people), and the other half are of ""large"" universes (say with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""10^{21}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">21</span></span></span></span></span></span></span></span></span></span> people). All universes look identical from the inside.</p><p>Once again, there is only one reference class. Since there is an equal number of small and large universes, exactly <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""10^{21}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">21</span></span></span></span></span></span></span></span></span></span> out of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""10^{15} + 10^{21}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">15</span></span></span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-msubsup MJXc-space2""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">21</span></span></span></span></span></span></span></span></span></span> members of the class are located in large universes. If we know all this, then (unlike in the original problem) our uncertainty about which universe we live in is clearly <strong>random </strong>with probability <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{10^{21}}{10^{15} + {10^{21}}}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 3.343em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 4.728em; top: -1.649em;""><span class=""mjx-msubsup"" style=""""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.443em; padding-left: 0px; padding-right: 0.06em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">21</span></span></span></span></span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 4.728em; bottom: -1.001em;""><span class=""mjx-mrow"" style=""""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.443em; padding-left: 0px; padding-right: 0.06em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">15</span></span></span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">+</span></span><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-msubsup""><span class=""mjx-base""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">10</span></span></span><span class=""mjx-sup"" style=""font-size: 83.3%; vertical-align: 0.443em; padding-left: 0px; padding-right: 0.06em;""><span class=""mjx-texatom"" style=""""><span class=""mjx-mrow""><span class=""mjx-mn""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">21</span></span></span></span></span></span></span></span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 3.343em;"" class=""mjx-line""></span></span><span style=""height: 1.874em; vertical-align: -0.708em;"" class=""mjx-vsize""></span></span></span></span></span></span> i.e. <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{1000000}{1000001}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 2.616em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 3.7em; top: -1.394em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1000000</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 3.7em; bottom: -0.687em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1000001</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 2.616em;"" class=""mjx-line""></span></span><span style=""height: 1.472em; vertical-align: -0.486em;"" class=""mjx-vsize""></span></span></span></span></span></span> for the universe being large.</p><p>Bostrom <a href=""http://larger"">came up</a> with the Presumptuous Philosopher problem as an argument against <a href=""https://wiki.lesswrong.com/wiki/Self-indication_assumption"">SIA</a> (which is one of the two main anthropic theories, and the one which  answers <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{2}{3}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">2</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.686em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">3</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.485em;"" class=""mjx-vsize""></span></span></span></span></span></span> on Sleeping Beauty). Notice how it is about the size of the universe, i.e. something that might never be repeated, where the answer might always be the same. This is no coincidence. SIA tends to align with the <strong>randomness</strong>/<strong>ignorance </strong>model whenever all uncertainty collapses into <strong>randomness</strong>, and to diverge whenever it doesn't. Naturally, the way to construct a thought experiment where SIA appears to be overconfident is to make it so the relevant uncertainty might plausibly be <strong>ignorance. </strong> This is an example of how I believe the <strong>randomness</strong>/<strong>ignorance</strong> model adds to our understanding of these problems.</p><p>So far I haven't talked about how the model computes probability if the relevant uncertainty is <strong>ignorance</strong>. In fact it behaves like SSA (rather than SIA), but the argument is lengthy. For now, simply assume it's agnostic.</p>",sil-ver,sil-ver,Rafael Harth,
B5ugqv7KD5azMiGix,Ban the London Mulligan,ban-the-london-mulligan,https://www.lesswrong.com/posts/B5ugqv7KD5azMiGix/ban-the-london-mulligan,2019-11-11T11:10:00.443Z,12,6,4,False,False,,"<p>Previously: <a href=""https://thezvi.wordpress.com/2019/03/05/on-the-london-mulligan/"">On The London Mulligan</a></p>
<p>Oko, Thief of Crowns is a highly messed up Magic card and needs to be banned in Standard. On that we can all agree. Throne of Eldraine contains many other messed up Magic cards. Some of them, like Once Upon a Time, Wicked Wolf and Gilded Goose, are not getting the appreciation they deserve because Oko, Thief of Crowns is stealing the spotlight. If both of those cards are Standard legal when they rotate out, I will be quite surprised. Then there are Fires of Invention, Caldron Familiar / Witch’s Oven, Embercleave, Emry, Lurker of the Lock. Then there’s Feasting Troll King, Questing Beast, Bonecrusher Giant, Lovestruck Beast, Edgewall Inkeeper and the list goes on. And yes, it has a lot of green in it. There are also messed up Magic cards one can choose from previous sets, although the density of them is far lower.</p>
<p></p>
<p>You are not going to succeed in Standard, for a long time, no matter what is banned, without building around at least one messed up Magic card from Throne of Eldraine. If design does not make large adjustments, and likely even if they do, every good Standard deck for a long time is going to have a key messed up Magic card.</p>
<p>Even more than a single messed up Magic card, these decks have central play patterns. Gilded Goose into Oko, Thief of Crowns. Third turn Nissa, Who Shakes the World. Fires of Invention into Cavalier of Flame. Witch’s Oven sacrificing Caldron Familiar sacrificing food triggering Trail of Crumbs or Mayhem Devil. Embercleave on my Questing Beast or Rotting Regisaur or knight. First turn Pelt Collector or else your deck doesn’t quite work. Explosive or super efficient adventure or Veteran Loxodon starts. Growth Spiral into Wilderness Reclamation. And so on.</p>
<p>If you get to do these things, a seventh card you had to put on the bottom will not be overly missed. If you don’t get these things, an extra card will not much matter.</p>
<p>Thus, the first player is forced to mulligan hands that look perfectly good, but which cannot pull off their key play pattern. Decks get designed with a key consideration being what you can and cannot keep as an opening hand. The deck I would have run at Mythic Championship V, Elk Blade, keeps no configuration of cards that lacks Arboreal Grazer, Gilded Goose or Once Upon a Time against an unknown opponent, <em>even at six cards. </em>Because once you see that such hands are going to be bad no matter what, why build your deck to make them 25% to win rather than 10%, given you’re not going to keep them anyway?</p>
<p>Then the second player has an even more stark choice. If the opponent kept seven, <em>they probably have their central play pattern. </em>What are you going to do about it? You’re already behind because you’re going second. You can ill afford to go second, face a hand of seven, and not have a Gilded Goose. So you mulligan even more. If the opponent goes to six, they <em>still </em>likely have their central pattern, and now that they’re down a card. Answering that becomes what the game will be all about. Or they’ll miss, and there won’t be a game.</p>
<p>Thus, we have lots of mulligans to find key play patterns.</p>
<p>Every game looks the same. Both players do their thing, or else one player fails to do it, is likely also down cards, and never has a chance. Lots of time is spent shuffling, and going through the same motions over and over again.</p>
<p>Once Upon a Time makes all this even worse and made it easier to see, but the problem would persist without it.</p>
<p>Decks that rely on a critical mass of cards rather than a central pattern are at a disadvantage two ways. They don’t get the free wins off their messed up starts, and they suffer far more when forced to send their hands back.</p>
<p>Online on Magic Arena, one tires of playing the same games over and over again, but speeding up the operations, especially shuffling, makes it a lot more palatable. Playing in person, the ratio of dead time to interesting Magic is devastatingly poor. I dropped from the Grand Prix, despite still having a good shot at cashing, because I really, really didn’t want to keep playing Standard.</p>
<p>Food decks are actually less bad than they might otherwise be and relatively good compared to some other decks, <em>because they have multiple such play patterns. </em>Sometimes they’re about Nissa, Who Shakes the World or even Wicked Wolf rather than Oko, Thief of Crowns, and because we have strong hate cards like Noxious Grasp and Aether Gust that allow mirror games to be more dynamic and less lopsided or repetitive than one would otherwise expect. In an important sense, we are currently quite fortunate. The food mirror is a luxurious tapestry compared to a Fires of Invention, adventure or sacrifice mirror.</p>
<p>As I warned in my previous analysis, <a href=""https://thezvi.wordpress.com/2019/03/05/on-the-london-mulligan/"">On the London Mulligan</a>, this is not about one deck getting such a big advantage that it dominates. It is about the pernicious effect on play patterns and deck designs across the spectrum, whether the format is balanced or otherwise. Once enough cards are banned, presumably a variety of decks will focus on a variety of messed up Magic cards. But as long as they are still all using the London Mulligan to find them, the problem will continue.</p>
<p>Magic is great because it continuously presents unique situations to its players. Decks and players are forced to be flexible and roll with the punches, to plan for not having access to their key cards. When instead decks and players are rewarded for relying on their central repetitive play patterns, because fallback sequences would lose anyway, Magic loses much of its appeal.</p>
<p>This effect will only grow as players fully appreciate the new world they live in, and learn how to mulligan effectively, and then how to build decks based on those mulligan decisions by both themselves and others. Again, Gilded Goose aside, traditional Oko, Thief of Crowns decks are in many ways <em>relatively good </em>at having alternative patterns that are competitive with the primary one, and providing life totals that allow time to recover if you can avoid too big a snowball on the board.</p>
<p>I won’t discuss here whether we should be banning other cards along with Oko, Thief of Crowns. I would ban at least one additional green card now rather than later, but I am not super confident that I am correct. There is a reasonable case to be made both for and against additional bans.</p>
<p>What we do need to ban, in addition to Oko, Thief of Crowns, is the London Mulligan. We must return to the Vancouver Mulligan for traditional constructed play. If we are willing to bear the complexity cost of having distinct mulligan rules, I am willing to allow the London Mulligan to remain in limited and even in formats like brawl and commander. In Standard, Pioneer, Modern, Legacy and Vintage, we must act. If we do not, these problems likely only get worse over time, no matter how many cards we choose to ban.</p>",Zvi,zvi,Zvi,
BuqaN3T6gwcj7bhrb,Pieces of time,pieces-of-time,https://www.lesswrong.com/posts/BuqaN3T6gwcj7bhrb/pieces-of-time,2019-11-11T07:00:03.264Z,43,16,8,False,False,,"<p>My friend used to have two ‘days’ each day, with a nap between—in the afternoon, he would get up and plan his day with optimism, whatever happened a few hours before washed away. Another friend recently suggested to me thinking of the whole of your life as one long day, with death on the agenda very late this evening. I used to worry, when I was very young, that if I didn’t sleep, I would get stuck in yesterday forever, while everyone else moved on to the new day. Right now, indeed some people have moved on to Monday, but I’m still winding down Sunday because I had a bad headache and couldn’t sleep. Which is all to say, a ‘day’ does not just mean a 24 hour measure of time, in our minds. Among its further significance, we treat it as a modular unit: we expect things within it to be more continuous and intermingled with each other than they are with things outside of it. What happens later today is more of a going concern at present than something that happens after sleeping. The events of this morning are more part of a continuous chapter, expected to flavor the present, than what happened yesterday. The same is true to some extent for weeks, months and years (but not for fortnights or periods of 105 hours).</p>
<p>I think days are well treated as modular like this because sleeping really separates them in relevant ways. I notice two other kinds of natural modular time-chunks that seem worth thinking in terms of, but which I don’t have good names for:</p>
<ul>
<li>Periods during which you are in one context and stream of thought (usually a minute to a few hours long). For instance the period of going for a walk, or the period between getting home and receiving a phone call that throws you into a new context and set of thoughts. During one such chunk, I can remember a lot about the series of thoughts so far, and build upon them. Whereas if I try to go back to them later, they are hard to bring back to life, especially the whole set of thoughts and feelings that I wandered around during a period, rather than just a single insight brought from it. Within chunks like this, my experience seems more continuous and intermingled with other experience within the chunk. Then I get an engaging message or decide to go out, and a new miniature chapter begins, with new feelings and thoughts. (Though I’m not sure how much other people’s thoughts depend on their surroundings, so maybe for others a change of context is less of a reset).</li>
<li>Similarly, longer periods of repeatedly being in particular places with particular people. These might be decades of settled marriage or a few days of being on a trip. For me they are often a month to a year. They are punctuated by moving, breaking up, changing jobs. They tend to have their own routines and systems and patterns of thought. For me, starting a new one is often marked by a similar optimism and ambition for a fresh start as mornings. And ending one shares with evenings a risk of sadness at wasted opportunity.</li>
</ul>
<p>Both of these also end because of something like sleep—changes of context that break the continuity of thoughts or habits within the period, either because those things relied on the previous context as something like memory, or because the new context asks for a new activity that replaces the old one, and the old one needed the continuity to stay alive.</p>",KatjaGrace,katjagrace,KatjaGrace,
PtcPKkxkJLu4QRTfY,Epistemic Spot Check: Unconditional Parenting,epistemic-spot-check-unconditional-parenting,https://www.lesswrong.com/posts/PtcPKkxkJLu4QRTfY/epistemic-spot-check-unconditional-parenting,2019-11-10T20:10:00.932Z,22,10,6,False,False,,"<p>Epistemic spot checks started as a process in which I investigate a few of a book’s claims to see if it is trustworthy before continuing to read it. This had a number of problems, such as emphasizing a trust/don’t trust binary over model building, and emphasizing provability over importance. I’m in the middle of <a href=""https://acesounderglass.com/2019/10/17/what-comes-after-epistemic-spot-checks/"">revamping ESCs</a> to become something better. This post is both a ~ESC of a particular book and a reflection on the process of doing ESCs and what I have and should improve(d).</p>
<p>As is my new custom, I took my notes in <a href=""http://roamresearch.com"">Roam</a>, a workflowy/wiki hybrid. Roam is so magic that my raw notes are better formatted there than I could ever hope to make them in a linear document like this, so I’m just going to share my conclusions here, and if you’re interested in the process, follow the links to Roam. Notes are formatted as follows:</p>
<ul>
<li>The target source gets <a href=""https://roamresearch.com/#/app/AcesoUnderGlass/page/yB6quPsVN"">its own page</a></li>
<li>On this page I list some details about the book and claims it makes. If the claim is citing another source, I may include a link to the source.</li>
<li>If I investigate a claim or have an opinion so strong it doesn’t seem worth verifying (“Parenting is hard”), I’ll mark it with a credence slider. The meaning of each credence will eventually be explained <a href=""https://roamresearch.com/#/app/AcesoUnderGlass/page/9nzcHrJK3"">here</a>, although I’m still working out the system.
<ul>
<li>Then I’ll hand-type a number for the credence in a bullet point, because sliders are changeable even by people who otherwise have only read privileges.</li>
</ul>
</li>
<li>You can see my notes on the source for a claim by clicking on the source in the claim</li>
<li>You may see a number to the side of a claim. That means it’s been cited by another page. It is likely a synthesis page, where I have drawn a conclusion from a variety of sources.</li>
</ul>
<p>This post’s topic is Unconditional Parenting (Alfie Kohn) (<a href=""https://www.amazon.com/gp/product/0743487486/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=acesoundergla-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0743487486&amp;linkId=51eff77af358aca639646dbf7f74d063"">affiliate link</a>), which has the thesis that even positive reinforcement is treating your kid like a dog and hinders their emotional and moral development.</p>
<p><a href=""https://roamresearch.com/#/app/AcesoUnderGlass/page/yB6quPsVN"">Unconditional Parenting</a> failed its spot check pretty hard. Of three citations I actually researched (as opposed to agreed with without investigation, such as “Parenting is hard”), two <a href=""https://roamresearch.com/#/app/AcesoUnderGlass/page/d0lJ4I6fV"">barely</a> <a href=""https://roamresearch.com/#/app/AcesoUnderGlass/page/JXCVMg_5O"">mentioned</a> the thing they were cited for as an evidence-free aside, and one reported exactly what UP claimed but was <a href=""https://roamresearch.com/#/app/AcesoUnderGlass/page/ar91CXsYp"">too small and subdivided</a> to prove anything. </p>
<p>Nonetheless, I thought UP might have good ideas kept reading it. One of the things Epistemic Spot Checks were designed to detect was “science washing”- the process of taking the thing you already believe and hunting for things to cite that could plausibly support it to make your process look more rigorous. And they do pretty well at that. The problem is that science washing doesn’t prove an idea is wrong, merely that it hasn’t presented a particular form of proof. It could still be true or useful- in fact when I dug into a series of self-help books, rigor didn’t seem to have <a href=""https://acesounderglass.com/tag/selfhelpepistemics/"">any correlation</a> with how useful they were. And with something like child-rearing, where I dismiss almost all studies as “too small, too limited”, saying everything needs rigorous peer-reviewed backing is the same as refusing to learn. So I continued with <i>Unconditional Parenting</i> to absorb its models, with the understanding that I would be evaluating its models for myself.</p>
<p><i>Unconditional Parenting</i> is a principle based book, and its principles are:</p>
<ul>
<li>It is not enough for you to love your children; they must feel loved unconditionally. </li>
<li>Any punishment or conditionality of rewards endangers that feeling of being loved unconditionally.</li>
<li>Children should be respected as autonomous beings.</li>
<li>Obedience is often a sign of insecurity.</li>
<li>The way kids learn to make good decisions is by making decisions, not by following directions.</li>
</ul>
<p>These seem like plausible principles to me, especially the first and last ones. They are, however, costly principles to implement. And I’m not even talking about things where you absolutely have to override their autonomy like vaccines. I’m talking about when your two children’s autonomies lead them in opposite directions at the beach, or you will lose your job if you don’t keep them on a certain schedule in the morning and their intrinsic desire is to watch the water drip from the faucet for 10 minutes. </p>
<p>What I would really have liked is for this book to spend less time on its principles and bullshit scientific citations, and more time going through concrete real world examples where multiple principles are competing. Kohn explicitly declines to do this, saying specifics are too hard and scripts embody the rigid, unresponsive parenting he’s railing against, but I think that’s a cop out. Teaching principles in isolation is easy and pointless: the meaningful part is what you do when they’re difficult and in conflict with other things you value.</p>
<p>So overall, <i>Unconditional Parenting</i>:</p>
<ul>
<li>Should be evaluated as one dude’s opinion, not the outcome of a scientific process</li>
<li>Is a useful set of opinions that I find plausible and intend to apply with modifications to my potential kids.</li>
<li>Failed to do the hard work of demonstrating implementation of its principles.</li>
<li>Is a very light read once you ignore all the science-washing.</li>
</ul>
<p> </p>
<p> </p>
<p>As always, tremendous thanks to my <a href=""https://www.patreon.com/acesounderglass"">Patreon</a> patrons for their support.</p>
<p> </p>

PS. The evidence-lives-in-Roam format is new, and I'm curious how it's affecting readability. If you've followed along with this series, please comment with how it's working for you.",pktechgirl,elizabeth-1,Elizabeth,
8HmSzsCH24NRAgj5e,Copenhagen/Malmö meetup,copenhagen-malmoe-meetup,https://www.lesswrong.com/events/8HmSzsCH24NRAgj5e/copenhagen-malmoe-meetup,2019-11-10T17:41:06.211Z,1,1,1,False,False,,"<p>Any readers on both sides on the bridge? I very much miss hanging out with the community and would love to make regular meetups happen, so let&apos;s start with this one! Just bring yourself! I am based in Lund, Sweden. Exact location will be texted individually.</p><p>UPDATE: no one has shown interest so far, so I am willing to postpone this event until December 21, with the idea of a Solstice celebration. Please do react if interested ;)</p>",Laural,laural,Laural,
894W89bH5yTnj45Kb,Experiments and Consent,experiments-and-consent,https://www.lesswrong.com/posts/894W89bH5yTnj45Kb/experiments-and-consent,2019-11-10T14:50:01.956Z,30,15,45,False,False,,"<p>

One of the responses to my 

<a href=""https://www.jefftk.com/p/uber-self-driving-crash"">Uber
self-driving car post</a> was objecting to Uber experimenting on
public roads:



<blockquote>
Self-driving research as practiced across the industry is in violation
of basic research ethics.  They should not be allowed to toss informed
consent out the window, no matter how cool or revolutionary they think
their research is.
</blockquote>

I've seen this general sentiment before: if you want to run an
experiment involving people you need to get their consent, and get
approval from an 

<a href=""https://en.wikipedia.org/wiki/Institutional_review_board"">IRB</a>,
right?



</p><p>

While academia and medicine do run on a model of informed consent,
it's not required or even customary in most fields.  Experimentation
is widespread, as organizations want to learn what effect their
actions have.  Online companies <a href=""https://signalvnoise.com/posts/2991-behind-the-scenes-ab-testing-part-3-final"">run</a>
<a href=""https://www.smashingmagazine.com/2010/06/the-ultimate-guide-to-a-b-testing/"">tons
of</a> <a href=""https://www.wired.com/2012/04/ff-abtesting/"">a/b
tests</a>.  UPS ran experiments on routing and found it was more
efficient if they planned routes to avoid left turns.  Companies
introduce new products in <a href=""https://en.wikipedia.org/wiki/Test_market"">test markets</a>.
This is all very standard and has been happening for decades, though
automation has made it easier and cheaper, so there's more now.

</p>

<p>

When you look at <a href=""https://en.wikipedia.org/wiki/Unethical_human_experimentation_in_the_United_States"">historical
cases of experimentation gone wrong</a>, the problem is generally that
the intervention was unethical on its own.  <a href=""https://en.wikipedia.org/wiki/Tuskegee_syphilis_experiment"">Leaving
syphilis untreated</a>, <a href=""https://en.wikipedia.org/wiki/Unit_731"">infecting people</a> <a href=""https://en.wikipedia.org/wiki/Operation_Whitecoat"">with
diseases</a>, telling people to <a href=""https://en.wikipedia.org/wiki/Milgram_experiment"">shock
others</a>, and dropping <a href=""https://en.wikipedia.org/wiki/Operation_Big_Buzz"">mosquitoes</a>
from planes are all things you normally shouldn't do.  The problem
in these cases wasn't that they were experimenting on people, but that
they were harming people.

</p>

<p>

Similarly, the problem with Uber's car was that if you have an
automatic driving system that can't recognize pedestrians, can't
anticipate the movements of jaywalkers, freezes in response to
dangerous situations, and won't brake to mitigate collisions, it is
absolutely nowhere near ready to guide a car on public roads.

</p>

<p>

We have a weird situation where the rules for experimentation in
academia and medicine are much more restrictive than everywhere else.
So restrictive that even a very simple study where you do everything
you normally do but also record whether two diagnostics agreed with
each other can be <a href=""https://slatestarcodex.com/2017/08/29/my-irb-nightmare/"">bureaucratically
impractical</a> to run.  We should remove most of these restrictions:
you should still have to get approval and informed consent if you want
to hurt people or violate a duty you have to them, but ""if it's ok to
do A or B then it's fine to run an experiment on
A vs B"" should apply everywhere.

</p>

<p>

(I wrote something similar earlier, after <a href=""https://www.jefftk.com/p/ethics-of-experimentation"">facebook's
sentiment analysis experiment</a>.)

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100120838006502"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
dBh2CdaiyG6oCLDMA, Indescribable,indescribable,https://www.lesswrong.com/posts/dBh2CdaiyG6oCLDMA/indescribable,2019-11-10T13:31:45.298Z,14,12,5,False,False,,"<p>Some things can be described only via experience.</p>
<ul>
<li>Direct sensory experience (such as the color red)</li>
<li>Foreign untranslatable words and phrases</li>
<li><a href=""https://en.wikipedia.org/wiki/Rasa_(aesthetics)"">Rasas</a></li>
<li>Certain meditative states (such as <em>kenshō</em> and <em>satori</em>)</li>
</ul>
<p>Other things cannot be precisely described at all.</p>
<ul>
<li>Any particular noncomputable number</li>
</ul>
<p>Indescribable things cannot be described in a finite number of words. That's because each one contains an infinite quantity of information. I don't mean they convey this information all at once (except for noncomputable numbers). Rather, they open up a new channel of information.</p>
<p>Opening up a new channel of information is mathematically equivalent to adding an input node to a neural network. This is a totally different process from training a machine learning system. When you train a neural network you adjust the weights of the connections between neurons to solve a problem. Adding hidden nodes amounts to basically the same thing. Adding an input node to a neural network unfolds a new dimension of the problem space thereby adding information for the network to work with. In other words, adding a new input node doesn't improve your solution to a problem at all. It makes the problem easier instead.</p>
<p>For example, the traditional Chinese method of teaching strategy involves memorizing ancient Taoist texts. This pedagogical technique is off the radar of modern MBA programs for reasons independent of its effectiveness. The ""memorized passages of concise time-tested wisdom"" input node is just missing.</p>
<p>You can't tell someone an indescribable thing but you can tell her where to look. You can tell someone to identify the color of blood, listen to a piece of music or stare silently at a blank wall until you see the essence of reality.</p>
<blockquote>
<p>The arts of war…cannot be ignored.</p>
<p>―first line of Sunzi's <em>The Art of War</em></p>
</blockquote>
<p>Where else should I look?</p>
",lsusr,lsusr,lsusr,
FsMFSwbCCjrgwL2G5,Ethical experimentation,ethical-experimentation,https://www.lesswrong.com/posts/FsMFSwbCCjrgwL2G5/ethical-experimentation,2019-11-10T08:00:01.534Z,15,6,2,False,False,,"<p>I <a href=""https://meteuphoric.com/2019/11/06/personal-quality-experimentation/"">suggested</a> experimenting with different settings on personal characteristics that aren’t obviously good or bad. For instance, trying out being more or less perfectionistic for a day.</p>
<p>A particular variety of this that interests me is experimentation with different ethical principles, where opinion differs on which is correct. Both at levels of action (being a vegan for a week) and of abstract belief (being a virtue ethicist for a week).</p>
<p>I think this is a particularly non-obvious thing to do, because:</p>
<ol>
<li>You already have views on what is correct, and trading your good ethical principles for bad ethical principles seems unethical.</li>
<li>Ethics seems like an area where experimentation is particularly unhelpful, being mostly about things outside of you that you don’t have direct access to, and also arguably inhabiting a separate realm that doesn’t interact with empirical facts. </li>
</ol>
<p>I think it is a good idea anyway. On 1, this is basically the same as the case for placebo controlled medical trials, assuming that the thing can actually help you be more ethical in the long run.</p>
<p>On 2, the main thing you have to go by on ethics is intuitions and arguments that are salient and moving to you. But people are notoriously bad at coming up with an unbiased selection of considerations to make salient on topics where they feel something, and it is easy to hear an argument and not really feel it. Actually trying to inhabit the different positions seems helpful for these.</p>
<p>I haven’t done this, but I have become a vegetarian for no great reason and in spite of my <a href=""https://meteuphoric.com/2014/11/21/when-should-an-effective-altruist-be-vegetarian/"">argument</a> that it is not an effective use of effort, and then gone back to eating fish, and I found both things had pretty interesting effects on my intuitions about things and the arguments I thought about (possibly changing ethical positions for no good reason is especially good, because then your brain tries to make up its best reasons).</p>
<p>I was thinking of trying nihilism week soon, but then I got busy and maybe became a nihilist anyway, so we’ll see.</p>",KatjaGrace,katjagrace,KatjaGrace,
jrPB9a9MP9aQMXDwT,Self-Keeping Secrets,self-keeping-secrets,https://www.lesswrong.com/posts/jrPB9a9MP9aQMXDwT/self-keeping-secrets,2019-11-10T07:59:15.119Z,72,36,9,False,False,,"<html><head></head><body><blockquote>
<p>A magician never reveals his secrets.</p>
</blockquote>
<p>The secret behind nearly every magic trick ever performed is available at your local library. Magicial secrets stay secret because they're inconsequential. Unless you are a magician or aspire to become one, you have better things to learn than magic tricks. If magic tricks did anything that mattered then they wouldn't be magic tricks. They'd be technology.</p>
<p>Magicians don't need a conspiracy to keep our tricks secret. It takes work to learn how to do magic. Friction and inertia are sufficient to keep out the riffraff.</p>
<p>This is true of more important subjects too, like computer security. Though zero-day exploits themselves are precious secrets, ""how to find"" zero-days is public knowledge. And since zero-day exploits have a limited shelf-life it's ""how to find"" zero-days that matters.</p>
<blockquote>
<p>Three may keep a secret, if two of them are dead.</p>
<p>―Benjamin Franklin</p>
</blockquote>
<p>Organizations leak like a sponge. Organizations can keep passwords secret most of the time only because a good authentication system is easy to reset. If you're even the slightest bit concerned that your passwords have been stolen then you can re-randomize them. Similarly, an intelligence agency maintains its stockpile of zero-day exploits by constantly replenishing them.  To an organization, ""preserving secrecy"" really means ""restoring secrecy"". Techniques can't be kept secret because they change too infrequently to restore secrecy after they get stolen.</p>
<p>In practice, organizations face the opposite problem: not enough knowledge is widely-known. Training people is so hard that the limiting factor of an organization's size is how many skilled employees it can hire. The bigger your organization gets the more it'll suffer a regression to the mean. Scaling a company is an exercise in dumbing down your employees' jobs to counteract the regression to the mean.</p>
<p>Large organizations can neither keep knowledge secret nor spread it around. In other words, a dependence on smart people of any kind inhibits the growth of an organization. An organization can scale to the extent it makes its employees'—and especially its customers'—intelligence unnecessary.</p>
<blockquote>
<p>SCP-055 is a ""self-keeping secret"" or ""anti-meme"".</p>
<p>―<a href=""http://scp-wiki.wikidot.com/scp-055"">internal document</a>, SCP Foundation</p>
</blockquote>
<p>The largest organizations are precisely those that make knowledge the most obsolete. The public school system is, by headcount, among the largest organizations in modern civilization. It must therefore, by necessity, minimize the need for students to learn anything hard<sup class=""footnote-ref""><a href=""#fn-znSwzECic6jKttN3c-1"" id=""fnref-znSwzECic6jKttN3c-1"">[1]</a></sup>.</p>
<p>Most adults are employed by large companies. Most adults buy most of our products from large companies. Small businesses are dying out<sup class=""footnote-ref""><a href=""#fn-znSwzECic6jKttN3c-2"" id=""fnref-znSwzECic6jKttN3c-2"">[2]</a></sup>. Modern civilization is increasingly dominated by large organizations. These organizations don't just shape our society. They <em>are</em> our society. We are our jobs. We are the products we use. We are the media we consume. We are our communities.</p>
<p>Our most popular activities are those that scale the best. Those that scale the best are those that require the least thinking, the least skill, the least specialized knowledge, the least individuality. If you want to measure your individuality, ask yourself this: of all the things you do, how much of it is so hard your friends and coworkers literally can't do it.</p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-znSwzECic6jKttN3c-1"" class=""footnote-item""><p>By ""hard"" I mean ""conceptual"". Schools can effectively force students to learn by <a href=""https://www.lesswrong.com/posts/57p47mDfioRBWYhBz/4-kinds-of-learning"">rote</a>. However, as a coercive institution, any school with mandatory attendance is definitionally incapable of forcing students to productively misbehave or otherwise exercise critical thinking. (Except to oppose the institution itself.) <a href=""#fnref-znSwzECic6jKttN3c-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-znSwzECic6jKttN3c-2"" class=""footnote-item""><p>Small operations that concentrate a lot of talent in a tiny number of employees are doing well. These companies will continue to constitute an insignificant fraction of total employment. <a href=""#fnref-znSwzECic6jKttN3c-2"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
</body></html>",lsusr,lsusr,lsusr,
iWJ5kzeqvx4kvB527,Goal-thinking vs desire-thinking,goal-thinking-vs-desire-thinking,https://www.lesswrong.com/posts/iWJ5kzeqvx4kvB527/goal-thinking-vs-desire-thinking,2019-11-10T00:31:40.661Z,23,7,11,False,False,,"<p>[Adapted from an <a href=""https://sniffnoy.dreamwidth.org/539557.html"">old post</a> on my personal blog]</p>
<p>There's a lot of long-running arguments on the internet that basically consist of people arguing past each other due to differing basic assumptions that they don't know how to make explicit, preventing them from noticing the fundamental disagreement.  I've noticed a few of these and tried to see if I can make both sides more explicit.  In this post I'd like to try to explicate one.</p>
<p>Let's start with a concrete example; there are a number of people who would say that wireheading is a <em>good</em> thing, which is obviously not the general thinking on LW.  What's the source of this disagreement?  One possible explanation would be to say that the former are saying ""happiness is our only terminal value, all other values are subsidiary to it"", while the latter say <a href=""http://lesswrong.com/lw/lb/not_for_the_sake_of_happiness_alone/"">hell no it's not</a>, but I think there's more to it than that.</p>
<p>Without yet saying what I think the fundamental distinction is, let me give another example that I think stems from the same disagreement.  Consider <a href=""https://theviewfromhellyes.wordpress.com/2016/06/07/patch-7-822-an-experimental-design-puzzle/"">this</a> essay -- and this isn't the only thing I've seen along these lines -- which takes the point of view that <em>obviously</em> a rational person would kill themselves, while to me this just seems... dumb.</p>
<p>So what's going on here?  What's the actual distinction that leads to such arguments?  Again, I can't know, but here's my hypothesis.  I think there are two sorts of thinking going on here; I'm going to call them ""goal-thinking"" and ""desire-thinking"" (these are my own terms, feel free to devise better ones).</p>
<p>So -- goal thinking is thinking in terms of what I'm calling ""goals"".  Goals are to be <em>accomplished</em>. If you're thinking in terms of goals, what you're afraid of is being <em>thwarted</em>, or having your capacity to act, to effect your goals, reduced -- being somehow disabled or restrained; if your capabilities are reduced, you have less ability to make an effect on the future and steer it towards what you want. (This is important; goal-thinking thinks in terms of preferences about the future.) The ultimate example of this is death -- if you're dead, you can't affect anything anymore. While it's possible in some unusual cases that dying could help accomplish your goals, it's pretty unlikely; most of the time, you're better off remaining alive so that you can continue to affect things. So suicide is almost always unhelpful. Goals, remember, about the world, external to oneself.</p>
<p>Wireheading is similarly disastrous, because it's just another means of rendering oneself inactive. We can generalize ""wireheading"" of course to anything that causes one to think one has accomplished one's goals when one hasn't. Or of course to having one's goals altered.  We all know this argument; this is just the old <a href=""http://yudkowsky.net/singularity"">""murder pill""</a> argument.  Indeed, you've likely noticed by this point that I'm just recapitulating Omohundro's <a href=""https://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/"">basic AI drives</a>.</p>
<p>Another way of putting this is, goals themselves are driving forces.</p>
<p>So what's the alternative, ""desire-thinking"", that I'm claiming is how many people think?  One answer would be to say, this alternative way of thinking is that ""it's all about happiness vs unhappiness"" or ""it's all about pleasure vs pain"", thinking in terms of internal experience rather than the external state of the world -- so for instance, people thinking this way tend to focus on unhappiness, pain, and suffering as the general bad thing, rather than having one's capacity to act reduced.</p>
<p>But, as I basically already said above, I actually don't think this gets at the root of the distinction, because there are still things this fails to explain.  For instance, I think it fails to explain the suicide article above, or, say, Buddhism; since applying the goal-thinking point of view but applied to internal experiences instead would just lead to hedonism instead.  And presumably there are a number of people thinking that way!  (Which may include a number of the ""wireheading is good"" people.)  But we can basically group this in as a variant of goal-thinking.  How do we explain the truly troublesome cases above, that don't fit into this?</p>
<p>I think what's actually going on with these cases involves not thinking in terms of goals in the above sense at all, but rather what I'm calling ""desires"" instead.  The distinction is that whereas goals are to be accomplished, desires are to be <em>extinguished</em>.  From a goal-thinking point of view, you can model this as having one single goal, ""extinguish all desires"", which is the only driving force; and the desires themselves are, just, like, objects in the model, not themselves driving forces.</p>
<p>So under the desire-thinking point of view, having one's desires altered can be a good thing, if the new ones are easier.  If you can just make yourself not care, great. Wireheading is excellent from this point of view, and even killing oneself can work. Indeed, desire-thinking doesn't really think in terms of preferences about the future, so much as just an anticipation of <em>having</em> preferences <em>in</em> the future (about the then-present).</p>
<p>Now while I, and LW more generally, may sympathize more with the former point of view, it's worth noting that in reality nobody uses entirely one or the other.  Or at least, it seems pretty clear that even here people won't actually endorse pure goal-thinking for humans (although it's another matter for AIs; this is one of those times when it's worth remembering that LW really has two different functions -- refining the art of human rationality, and refining the art of AI rationality, and that these are not always the same thing).     While I don't have a particular link on-hand, this issue has often been discussed here before in terms of preference regarding flavors of ice cream, and how it's not clear that one should resist modifications to this; this can be explained if one imagines that desire-thinking should be applied to such cases.</p>
<p>Thus when Eliezer Yudkowsky says ""I wouldn't want to take a pill that would cause me to want to kill people, because then maybe I'd kill people, and I don't want that"", we recognize it as an important principle of decision theory; but when <a href=""https://quoteinvestigator.com/2017/10/09/spinach/"">someone</a> says ""I don't like spinach, and I'm glad I don't, because if I liked it I'd eat it, and I just hate it"", we correctly recognize this as a joke.  (Despite it being isomorphic.)  Still, despite people not actually being all one way or the other, I think it's a useful way of understanding some arguments that have resulted in a lot of people talking past each other.</p>
",Sniffnoy,sniffnoy,Sniffnoy,
sg8YjyDBKAF5s2Bgh,Neural nets as a model for how humans make and understand visual art,neural-nets-as-a-model-for-how-humans-make-and-understand,https://www.lesswrong.com/posts/sg8YjyDBKAF5s2Bgh/neural-nets-as-a-model-for-how-humans-make-and-understand,2019-11-09T16:53:49.350Z,28,9,7,False,False,https://owainevans.github.io/visual_aesthetics/sensory-optimization.html,"<p>This is a new paper relating experimental results in deep learning to human psychology and cognitive science. I'm excited to get feedback and comments. I've included some excerpts below.</p><br><h2><strong>Abstract</strong></h2><p>This paper is about the cognitive science of visual art. Artists create physical artifacts (such as sculptures or paintings) which depict people, objects, and events. These depictions are usually stylized rather than photo-realistic. How is it that humans are able to understand and create stylized representations? Does this ability depend on general cognitive capacities or an evolutionary adaptation for art? What role is played by learning and culture?</p><p>Machine Learning can shed light on these questions. It’s possible to train convolutional neural networks (CNNs) to recognize objects without training them on any visual art. If such CNNs can <em>generalize</em> to visual art (by creating and understanding stylized representations), then CNNs provide a model for how humans could understand art without innate adaptations or cultural learning. I argue that Deep Dream and Style Transfer show that CNNs can create a basic form of visual art, and that humans could create art by similar processes. This suggests that artists make art by optimizing for effects on the human object-recognition system. Physical artifacts are optimized to evoke real-world objects for this system (e.g. to evoke people or landscapes) and to serve as superstimuli for this system.</p><br><h2><strong>From ""Introduction""</strong></h2><p>In a psychology <a href=""https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=Pictorial+recognition+as+an+unlearned+ability&amp;btnG="">study</a> in the 1960s, two professors kept their son from seeing any pictures or photos until the age of 19 months. On viewing line-drawings for the first time, the child immediately recognized what was depicted. Yet aside from this study, we have limited data on humans with zero exposure to visual representations.</p><p>...</p><p>For the first time in history, there are algorithms [convolutional neural nets] for object recognition that approach human performance across a wide range of datasets. This enables novel computational experiments akin to depriving a child of visual art. It’s possible to train a network to recognize objects (e.g. people, horses, chairs) without giving it any exposure to visual art and then test whether it can understand and create artistic representations.</p><br><h2><strong>From ""Part 1: Creating art with networks for object recognition""</strong></h2><br><span><figure><img src=""https://owainevans.github.io/visual_aesthetics/all_figures/2_yolo/yolo_compile.png"" class=""draft-image center"" style=""width:100%""></figure></span><p>Figure 2. Outputs from testing whether a conv-net model can generalize to paintings. Results are fairly impressive overall. However, in Picasso painting on the right, the people are classified as ""stop sign, frisbee"". </p><br><br><span><figure><img src=""https://owainevans.github.io/visual_aesthetics/all_figures/5_patron_optimization/sensory_optimization_conv_diagram.png"" class=""draft-image center"" style=""width:100%""></figure></span><p>Figure 12. Diagram showing how Deep Dream and Style Transfer could be combined. This generates an image that is a superstimulus for the conv net (due to the Deep Dream loss) and has the style (i.e. low-level textures) of the style image. Black arrows show the forward pass of the conv net. Red arrows show the backward pass, which is used to optimize the image in the center by gradient descent. </p><br><br><span><figure><img src=""https://owainevans.github.io/visual_aesthetics/all_figures/5_patron_optimization/patron_optimization_diagram.png"" class=""draft-image center"" style=""width:100%""></figure></span><p>Figure 13.  Diagram showing how the process in Figure 12 can be extended to humans. This is the ""Sensory Optimization"" model for creating visual art. For humans, the input is a binocular stream of visual perception (represented here as ""content video"" frames). The goal is to capture the content of this input in a different physical medium (woodcut print) and with a different style. The optimization is not by gradient descent but by a much slower process of blackbox search that draws on human general intelligence.</p><br><br><span><figure><img src=""https://owainevans.github.io/visual_aesthetics/all_figures/5_patron_optimization/tom_white_compiled.png"" class=""draft-image "" style=""width:100%""></figure></span><p>Figure 14. Semi-abstract images that are classified as “toilet”, “house  tick”, and “pornographic” (“NSFW”) by recognition nets. From Tom White’s  “<a href=""https://medium.com/artists-and-machine-intelligence/perception-engines-8a46bc598d57"">Perception Engines</a>” and “<a href=""https://medium.com/@tom_25234/synthetic-abstractions-8f0e8f69f390"">Synthetic Abstractions</a>” (with permission from the artist). </p><br><br><br><span></span>",Owain_Evans,owain_evans,Owain_Evans,
5vTnp4sfrYoTRDpLg,Notes on Running Objective,notes-on-running-objective,https://www.lesswrong.com/posts/5vTnp4sfrYoTRDpLg/notes-on-running-objective,2019-11-09T15:40:02.123Z,9,2,1,False,False,,"<p>

I've been playing 

<a href=""https://en.wikipedia.org/wiki/Killer_Queen_(video_game)"">Killer
Queen</a> lately at work.  It's a ten-person arcade game,
five-vs-five.  The general idea is that you're a ""bumblebear"" drone that
runs and jumps around trying to win by (a) collecting berries or (b)
riding the snail.  Some bumblebears will bring berries to ""wing gates""
and become warriors, who can fly around and kill others.  Each side
also has one queen, who is like a warrior but also has the ability to
dive.



</p><p>

You fly by tapping a button, sometimes very fast (7-15hz
depending), and it turns out this hurts my wrists.  I have <a href=""https://www.jefftk.com/p/floor-mouse"">bad wrists</a>, and generally need to be pretty
careful.  Not being able to play any flying roles, I've been getting
a lot of practice playing drone, and wanted to write up some notes.

</p>

<p>

The two main things drones do are collect berries and ride the snail.
Since those are the direct paths to victory, the objectives, we call
this ""running objective.""  Typically a team will have one member who
always runs objective, and another member who plays ""flex"", either
playing warrior or running objective depending on the needs of the
situation.

</p>

<p>

Presenting everything at an introductory level would take way too
long, though, so the rest of this post will be terse and jargony.  If
you'd like me to explain something ask in the comments, or you can ask
your teammates.


</p>

<p>

<b>General</b>

</p>

<p>

</p>

<ul>

<li><p>The longer you hold the button the higher you jump.  Making a
minimum-sized jump requires only a very slight tap.</p></li>

<li><p>Your forward speed is the same whether you're walking, jumping,
or falling.</p></li>

<li><p>If you're not making progress because of offensive guards, call
for a hive/snail clear.</p></li>

<li><p>Even though you can't kill anyone, booping others is still very
valuable in the right situation.  You can boop drones out of gates,
boop enemy warriors into your own warriors, and boop warriors out of
the hive.  Play around with booping to learn which parts are safe and
which will kill you.</p></li>

<li><p>Coordinate with teammates before the round starts to pick a
strategy (typically 2-2 berries or 3-1 snail) and figure out if there
are any gates you should plan to deny off the bat.</p></li>

<li><p>Watch the whole board so you have as much warning as possible
about what's coming next.  Give other players a heads up about
important things: number of berries remaining, progress of the snail,
warrior counts, gate possession, queen lives.  What's worth tracking
and calling takes time and depends on your team's preferences, but as
dedicated objective you generally have more spare bandwidth than anyone
else.</p></li>

<li><p>Don't get speed unless you literally have nothing better to do.
As a drone you're going to die a lot, and the time spent getting speed
is not worth it.  Speed can help you deliver berries past an
inexperienced hive guard, but you want to be building skills that will
still work when you play really good players.</p></li>

<li><p>You can trap standing warriors by jumping onto their heads, but
I haven't been able to figure out a good use for this.</p></li>

</ul>



<p>

<b>Running Berries</b>

</p>

<p>

</p>

<ul>

<li><p>Go for the hardest spots first, which means the spots that are
easiest for the opponents to guard.  Top berries on Dusk and Twilight,
back berries on Day and Night.  Though possibly on Day and Night you
should fill front berries first at the very start, if this lets you
get an extra cycle in before the other team gets their hive guard
up.</p></li>

<li><p>To get around the hive guard, coordinate with the other
objective runner to run the hive at the same time.  A solid d-guard
can block a solid drone most of the time, but it's very hard to stop
two drones at once.  On Day you can often boop a hive guard by
sticking; see the end of the post.</p></li>

<li><p>Make sure you and someone else don't go for the same hole.  A
good convention is you divide left-right based on your position at the
cabinet, but make sure you're using the same convention as your
teammates. Some teams prefer to call holes.</p></li>

<li><p>Practice the hard jumps, especially jumping across the top on
dusk.  Work on delivering the berry into a specific target hole.  On
Dusk and Twilight learn which holes can be reached by running off the
ledge vs jumps of various sizes, and which can be reached by jumping
from the bottom (""bottom berries""; lowest three rows on Dusk, lowest
two berries on Twilight) vs which need to be filled from the top (""top
berries"").</p></li>

<li><p>Figure out the fastest routes on every map.</p></li>

<li><p>Keep in mind that you're going to crawl back out of a hole, and
while you do that the hole is occupied.  This means there are times
when you should hold back just a little to give another objective
runner time to catch up, so you can deliver together.  This
matters the most for the end of the game, but can also apply to top
berries.  Don't hold back if it's going to get you killed though.</p></li>

<li><p>If you're holding a berry and run into another berry you'll
kick it.  Flying berries that go into holes register immediately.
Play around with kicking berries to learn the physics of how your
speed affects their speed and angle, because it's not obvious.  While
warriors absolutely need to learn how to kick so they can clear
berries after killing the drone carrying them, berry soccer is only
rarely useful for drones and can be a distraction.</p></li>

</ul>



<p>

<b>Riding Snail</b>

</p>

<p>

</p>

<ul>

<li><p>When the snail is eating someone, its rider is trapped and is
an easy target for warriors.  If the snail rider is killed, however,
the drone being eaten is immediately free.  These combine to mean that
you can feed the snail to trap your opponent, get rescued by a
teammate, and then ride.  If there's high military pressure and you're
not sure if rescue is advisable, your o-guard should make the
decision.</p></li>

<li><p>If you're not going to be able to be rescued, and especially if
they're not going to be able to be rescued either, it's generally
better to just stay on the snail and wait while it slowly eats
them.</p></li>

<li><p>When to hop off the snail and run away vs stay on it and get a
few more pixels of progress is a really hard judgement, and mostly
depends on whether they're just going to kill you anyway even if you
hop off.</p></li>

</ul>



<p>

<b>Sticking</b>

</p>

<p>

Normally, if you jump and hit the ceiling you'll bounce off.  But if
you hit the ceiling at just the right speed, you'll stick to it for a
short time instead.  This gets you high enough that you can boop
warriors and even the queen, but you have time time it well enough
that you're still sticking when you boop them.

</p>

<p>

Compare bouncing:

</p>

<p>

<img src=""https://www.jefftk.com/kq-still-bounce.gif"" />

</p>

<p>

To sticking:

</p>

<p>

<img src=""https://www.jefftk.com/kq-still-stick.gif"" />

</p>

<p>

Generally you'll want to stick while moving:

</p>

<p>

<img src=""https://www.jefftk.com/kq-moving-stick.gif"" />

</p>

<p>

Unlike with warriors, tapping while you're sticking has no effect.

</p>

<p>

To practice sticking, first practice jumping right next to a low
ledge, aiming to get your bear's knees even with the underside of the
ledge.  Once you see what that feels like, try to do the same thing
just under a low ledge.  Once you're good at sticking you're
surprisingly difficult to kill when there's a low ceiling, you can boop
hive guards on Day, you can boop warriors out of their own sticks, and
you can be one side of a pinch.

</p>

<p>

With perfect timing it is possible to jump from one ledge and stick on
a ledge above that you're not on yet, effectively lipping as a drone,
which could be powerful.  For example, it should let you boop a
hive guard on Night.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100120665931342"">facebook</a>, <a href=""https://www.reddit.com/r/KillerQueen/comments/dtxf54"">r/KillerQueen</a></i></p>",jkaufman,jkaufman,jefftk,
v64sK88iY4kpHCwr9,Reference Classes for Randomness,reference-classes-for-randomness,https://www.lesswrong.com/posts/v64sK88iY4kpHCwr9/reference-classes-for-randomness,2019-11-09T14:41:04.157Z,7,4,1,False,False,,"<p>(Follow-up to <a href=""https://www.lesswrong.com/posts/e5iwognG3Bi3TE7Dj/randomness-vs-ignorance"">Randomness vs. Ignorance</a>)</p><p>I've claimed that, if you roll a die, your uncertainty about the result of the roll is <strong>random</strong>, because, in 1/6th of all situations where one has just rolled a die, it will come up a three. Conversely, if you wonder about the existence of a timeless God, whatever uncertainty you have is <strong>ignorance.</strong> In this post, I make the case that this distinction isn't just an analog to probability inside vs. outside a model, but is actually fundamental (if some more ideas are added).</p><p>The <strong>randomness</strong> in the above example doesn't come from some inherent ""true randomness"" of the die. In fact, this notion of <strong>randomness </strong>is compatible with determinism. (You could then argue it is not real randomness but just ignorance in disguise, but please just accept the term <strong>randomness</strong>, whenever I bold it, as a working definition.) This <strong>randomness</strong> is simply the result of taking all situations which are identical to the current one from your perspective, and observing that, among those, one in six will have the die come up a three. This is a general principle that can be applied to any situation: a fair die, a biased die, delay in traffic, whatever.</p><p>The ""identical"" in the last paragraph needs unpacking. If you roll a die and we consider only the situations that are <em>exactly </em>identical from your perspective, then the die will come up a three either in a lot more or a lot less than 1/6th of them. Regardless of whether the universe is fully deterministic or not, the current state of the die is sure to at least correlate with the chance for a three to end up on top.</p><p>However, you are not actually able to distinguish between the situation where you just rolled a die in such a way that it will come up a three, and the situation where you just rolled a die in such a way that it will come up a five, and thus you need to group both situations together. More precisely, you need to group all situations that, to you, look indistinguishable with respect to the result of the die, into one class. Then, if among all situations that belong to this class, the die comes up a three in 1/6th of them, your uncertainty with respect to the die roll is <strong>random </strong>with probability <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\frac{1}{6}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mfrac""><span class=""mjx-box MJXc-stacked"" style=""width: 0.495em; padding: 0px 0.12em;""><span class=""mjx-numerator"" style=""font-size: 70.7%; width: 0.7em; top: -1.372em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">1</span></span></span><span class=""mjx-denominator"" style=""font-size: 70.7%; width: 0.7em; bottom: -0.687em;""><span class=""mjx-mn"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">6</span></span></span><span style=""border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;"" class=""mjx-line""></span></span><span style=""height: 1.456em; vertical-align: -0.486em;"" class=""mjx-vsize""></span></span></span></span></span></span> for a three. This grouping is based both on computational limitations (you see the die but can't compute how it'll land) and on missing information (you don't see the die). If you were replaced by a superintelligent agent, their reference class would be smaller, but some grouping based on hidden information would remain. Formally, think of an equivalence relation on the set of all brain states.</p><p>So at this point, I've based the definition of <strong>randomness </strong>both on a frequentist principle (counting the number of situations where the die comes up a three vs not a three) and on a more Bayesian-like principle of subjective uncertainty (taking your abilities as a basis for the choice of reference class). Maybe this doesn't yet look like a particularly smart way to do it. But with this post, I am only arguing that this model is consistent: all uncertainty can be viewed as made up of <strong>randomness</strong> and/or <strong>ignorance </strong>and no contradictions arise. In <a href=""https://www.lesswrong.com/posts/N7LqbC339BjyXFCbh/the-randomness-ignorance-model-solves-many-anthropic"">the next post</a>, I'll argue that it's also quite useful, in that several controversial problems are answered immediately by adopting this view.</p>",sil-ver,sil-ver,Rafael Harth,
dkcoq7wg3SpCHhvEv,Pricing externalities is not necessarily economically efficient,pricing-externalities-is-not-necessarily-economically,https://www.lesswrong.com/posts/dkcoq7wg3SpCHhvEv/pricing-externalities-is-not-necessarily-economically,2019-11-09T12:07:46.509Z,19,13,9,False,False,http://www.daviddfriedman.com/Academic/Coase_World.html,"<blockquote>[A]s long as externalities exist and are not internalized via Pigouvian taxes, the result is inefficient. The inefficiency is eliminated by charging the polluter an emission fee equal to the damage done by his pollution. In some real world cases it may be difficult to measure the amount of the damage, but, provided that that problem can be solved, using Pigouvian taxes to internalize externalities produces the efficient outcome.<br><br>That analysis was accepted by virtually the entire economics profession prior to Coase&apos;s work in the field. It is wrong&#x2014;not in one way but in three. The existence of externalities does not necessarily lead to an inefficient result. Pigouvian taxes, even if they can be correctly calculated, do not in general lead to the efficient result. Third, and most important, the problem is not really externalities at all&#x2014;it is transaction costs.</blockquote>",Orborde,orborde,Orborde,
XpTBjk3PMvztFz8bC,For the metaphors,for-the-metaphors,https://www.lesswrong.com/posts/XpTBjk3PMvztFz8bC/for-the-metaphors,2019-11-08T23:30:01.693Z,12,3,2,False,False,,"<p>I make use of a lot of analogies, for instance ‘like dancing’ and ‘the ice skating thing’ are particular phenomena I often think about, and I get value from thinking about meta-ethics as if it were romance, or saving the world as if it were a party. I wonder if providing a variety of concrete experiences that other things might be analogized to is a big source of value from doing new things.</p>
<p>For instance, recently I took up knitting and I think there are things about it that my other experiences don’t have. For instance, I got some knitting patterns, and they have this very brief and utilitarian jargon, and a bunch of concepts, and I got a sense of this rich world of actionable and actioned knowledge about how to do a concrete thing, with much doing of it, which is pretty unlike other things I engage in, I am sorry to say. </p>
<p>I was also struck by the experience of being able to take a relatively simple substance (wool) and turn it into a useful object of the kind one buys in a store (a hat, or it seems like it will be a hat). </p>
<p>These things are of course what I expect in the abstract, but it is something else to experience things.</p>
<p>I’m not sure how these new experiences compare to the value I have had so far from the activity of knitting, but it seems like much more than the value of a generic hat, and I only have maybe a quarter of one of those.</p>
<p>My current guess is that filling out my repertoire of concrete intuitions about specific kinds of occurrences or relationships between things is pretty helpful.</p>",KatjaGrace,katjagrace,KatjaGrace,
YKWvCqFJKthxbDcGQ,Catalyst: a collaborative biosecurity summit,catalyst-a-collaborative-biosecurity-summit,https://www.lesswrong.com/events/YKWvCqFJKthxbDcGQ/catalyst-a-collaborative-biosecurity-summit,2019-11-08T21:37:35.747Z,18,6,0,False,False,,"<p>Applications for <u><a href=""https://catalystbiosummit.com/"">Catalyst</a></u>, a collaborative biosecurity summit, are <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLSfxMZ5qy0QcFYsV2ZZmglngk9znXhEEgq2Xt4-TmboQBzEm2A/viewform"">now open</a></u>.</p><p>On February 22, 2020, at <u><a href=""http://thelaundrysf.com/"">The Laundry</a></u> in San Francisco, a diverse group of synthetic biologists, policymakers, academics, and biohackers will come together to discuss one of the biggest emerging questions of the 21st century&#x2014;how do we engineer a future enhanced by biotechnology and not endangered by it?</p><p>If you&#x2019;d like to meet other individuals invested in the future of biotechnology, participate in forward-thinking conversations, or brainstorm solutions to open problems in biosecurity, <u><a href=""https://docs.google.com/forms/d/e/1FAIpQLSfxMZ5qy0QcFYsV2ZZmglngk9znXhEEgq2Xt4-TmboQBzEm2A/viewform"">apply</a></u> by December 7th to secure a spot. </p>",epiphi,epiphi,epiphi,
tQssrKo4pEuMbWTDJ,A First Sketch of the Nature of Heat (Novum Organum Book 2: 15-25),a-first-sketch-of-the-nature-of-heat-novum-organum-book-2-15,https://www.lesswrong.com/posts/tQssrKo4pEuMbWTDJ/a-first-sketch-of-the-nature-of-heat-novum-organum-book-2-15,2019-11-08T03:42:20.842Z,13,4,0,False,False,,"<p><strong>This is the eleventh post in the</strong> <strong><a href=""https://www.lesswrong.com/s/GTEay24Lxm3xoE4hy"">Novum Organum sequence</a>. For context, see</strong> <strong><a href=""https://www.lesswrong.com/posts/te8gXf9fXb7JWbJ9b/novum-organum-introduction"">the sequence introduction</a>. For the reading guide, see</strong> <strong><a href=""https://www.lesswrong.com/s/GTEay24Lxm3xoE4hy/p/MYNNvgxSYmK7f4JBt"">earlier posts</a></strong> <strong>in the sequence.</strong></p><p><em>We have used Francis Bacon&apos;s Novum Organum in the version presented at<a href=""http://www.earlymoderntexts.com/"">www.earlymoderntexts.com</a>. Translated by and copyright to</em> <em><a href=""https://en.wikipedia.org/wiki/Jonathan_Bennett_(philosopher)"">Jonathan Bennett</a>. Prepared for LessWrong by</em> <em><a href=""http://www.lesswrong.com/users/ruby"">Ruby</a>.</em></p><p>[[In the <a href=""https://www.lesswrong.com/posts/gv4us6Z8RuHHnYXHN/tables-of-presence-nearby-absence-and-degrees-of-intensity"">previous section</a>, Bacon introduced his &quot;three tables&quot;: his careful collection of data and observations that are core to building up his scientific method.</p><p>These tables are:</p><p>1) A table of <em>presence</em> which lists many examples where phenomena of interest in presence, e.g. many examples of things where we have heat.</p><p>2) A table of <em>nearby essence</em>. His example is heat and to discriminate its true heat, Bacon looks for examples of things that resemble those in the table of presence yet are lacking the heat. For the example, the light of the moon (cold) is contrasted with the light of the sun (hot) which is interesting given they are both heavenly bodies.</p><p>3) A table of <em>degrees</em> or <em>comparison</em> where are examples are brought where the amount of perceived heat differs in degree between things. This is also useful in discriminating the true underlying cause and and nature of heat.]]</p><h1>Aphorism Concerning the Interpretation of Nature: Book 2: 15-25</h1><p><strong>15.</strong> The job of these three tables is&#x2014;in the terminology I have chosen&#x2014;to <em>present instances to the intellect</em>. After the presentation has been made, induction itself must get to work. After looking at each and every instance we have to find a nature which</p><ul><li>is always present when the given nature (in our present case: heat) is present,</li><li>is always absent when the given nature is absent,</li><li>always increases or decreases with the given nature, and</li><li>is a special case of a more general nature</li></ul><p>(I mentioned this last requirement in <strong><a href=""https://www.lesswrong.com/posts/gv4us6Z8RuHHnYXHN/tables-of-presence-nearby-absence-and-degrees-of-intensity"">4</a></strong>). If the mind tries to do this &#x2022;affirmatively from the outset (which it always does when left to itself), the result will be fancies and guesses and ill-defined notions and axioms that have to be adjusted daily. (Unless like the schoolmen* we choose to fight in defence of error; and in that case how well an axiom fares will depend &#xB7;not on how much truth it contains but&#xB7; on the ability and strength of its defender.) It is for God (who designed and gave the forms), and perhaps also for angels and higher intelligences, to have an immediate &#x2022;affirmative knowledge of forms straight away. This is certainly more than man can do. We have to proceed at first through</p><p>[[*Schoolmen: Aristotelian scholars.]]</p><p><strong>16.</strong></p><p>[Bacon will now be likening scientific procedure to a kind of chemical analysis, in which various components of a complex liquid are distilled off by heat, leaving the residue in which we are interested.]</p><p>So we have to subject the nature &#xB7;in which we are interested&#xB7; to a complete dismantling and analysis, not by fire but by the mind, which is a kind of divine fire. The first task of true induction (as regards the discovery of forms) is to reject or exclude natures that</p><ul><li>are not found in some instance where the given nature is present, or</li><li>are found in some instance from which the given nature is absent, or</li><li>are found to increase in some instance when the given nature decreases, or</li><li>are found to decrease when the given nature increases.</li></ul><p>After these rejections and exclusions have been properly made, and all volatile opinions have been boiled off as vapour, there will remain at the bottom of the flask (so to speak) an affirmative form that is solid, true and well defined. It doesn&#x2019;t take long to <em>say</em> this, but the process of <em>doing</em> it is lengthy and complex. Perhaps I&#x2019;ll manage not to overlook anything that can help in the task.</p><p><strong>17.</strong> I have to warn you&#x2014;and I can&#x2019;t say this too often!&#x2014;that</p><blockquote>When you see me giving so much importance to <em>forms</em>, do <em>not</em> think I am talking about the &#x2018;forms&#x2019; that you have been used to thinking about.</blockquote><p>&#xB7;Treating my forms as your &#x2018;forms&#x2019; in the present context would be wrong in two ways&#xB7;. <strong>(1)</strong> I&#x2019;m not talking here about composite forms, the ones in which various simple natures are brought together in the way the universe brings them together&#x2014;the likes of the forms of <em>lion</em>, <em>eagle</em>, <em>rose</em>, <em>gold</em>, and so on. It will be time to treat of these when we come to <em>hidden</em> processes and <em>hidden</em> microstructures, and the discovery of them in so-called <em>substances</em> or composite natures.</p><p><strong>(2)</strong> In speaking of &#xB7;forms or&#xB7; simple natures, I&#x2019;m not talking about <em>abstract</em> forms and ideas which show up unclearly in matter if indeed they show up in it at all. When I speak of &#x2018;forms&#x2019; I mean simply the objective real-world laws of pure action* that govern and constitute any simple nature&#x2014;e.g. heat, light, weight&#x2014;in every kind of matter and in anything else that is susceptible to them. Thus the &#x2018;form of heat&#x2019; or the &#x2018;form of light&#x2019; is the same thing as the <em>law</em> of heat or the <em>law</em> of light; and I shan&#x2019;t ever use abstractions through which I step back from things themselves and their operations. </p><p>[*Bacon doesn&#x2019;t explain <em>actus purus</em>. In each of its other three occurrences he connects it with <em>laws</em>, and his meaning seems to be something like: &#x2018;the laws governing the pure actions of individual things, i.e. the things they do because of their own natures independently of interference from anything else&#x2019;. If x does A partly because of influence from something else y, then x is not purely &#x2022;active in respect of A because y&#x2019;s influence gives A a certain degree of &#x2022;passivity. From here on, <em>actus purus</em> will be translated by &#x2018;pure action&#x2019;.]</p><p>[In the next sentence, &#x2018;rarity&#x2019; is cognate with &#x2018;rare&#x2019; in the sense of &#x2018;thin, attenuated, not <em>dense</em>&#x2019;.] So when I say (for instance) in the investigation of the form of heat</p><ul><li>&#x2018;reject rarity &#xB7;from the list of simple natures that constitute heat&#xB7;&#x2019;, or</li><li>&#x2018;rarity does not belong to the form of heat&#x2019;,</li></ul><p>&#xB7;I may seem to be talking about an abstract property <em>rarity</em>, but what I am saying can just as well be said without any noun purporting to refer to any such abstraction. For&#xB7; those statements are tantamount to</p><ul><li>&#x2018;It is possible for us to make a dense body hot&#x2019;, or</li><li>&#x2018;It is possible for us keep or remove heat from a rare body&apos;,</li></ul><p>&#xB7;where &#x2018;rarity&#x2019; and &#x2018;denseness&#x2019; give way to &#x2018;rare&#x2019; and &#x2018;dense&#x2019;&#xB7;.</p><p>You may think that my forms also are somewhat abstract, as they mix and combine things that are very different from one another. &#xB7;This complaint might come from your noticing that&#xB7;</p><ul><li>the heat of heavenly bodies seems to be very unlike the heat of fire,</li><li>the relatively durable redness of a rose (say) is very unlike the &#xB7;transient shimmering&#xB7; redness that appears in a rainbow, an opal, or a diamond, and the different kinds of death&#x2014;by drowning, burning, stabbing, stroke, starvation&#x2014;are very unalike;</li></ul><p>yet they share the nature of heat, redness and death respectively. If you <em>do</em> have that thought, this shows that your mind is captive to &#x2022;habit, to &#x2022;things taken as a whole &#xB7;and not subject to analysis or bit-by-bit examination&#xB7;, and to &#x2022;men&#x2019;s opinions. For it is quite certain that these things, however unalike they may be, agree in the form or law that governs heat, redness and death (respectively); and human power can&#x2019;t possibly be freed from the common course of nature, and expanded and raised to new powers and new ways of operating, except by discovering of forms of this kind. This &#x2022;union of nature is the most important thing I have to talk about; but when I have finished with it I shall take up, in the proper place, the &#x2022;divisions and veins of nature, both the ordinary &#xB7;superficial&#xB7; ones and also the ones that are more internal and true. &#xB7;By the &#x2018;union of nature&#x2019; I mean the coming together of disparate things under a single form. By the &#x2018;division and veins of nature&#x2019; I mean the complexities in which disparate structures and functions come together in a single thing&#xB7;.</p><p><strong>18.</strong> I should now provide an example of the exclusion or rejection of natures that are shown by the Tables of Presentation not to belong to the form of heat. All that is needed for the rejection of any nature &#xB7;from the form we are investigating&#xB7; is a single &#xB7;contrary&#xB7; instance from one of the tables; for what I have said makes it obvious that any conjecture &#xB7;of the type &#x2018;Nature N belongs to form F&#x2019;&#xB7; is knocked out by a single contrary instance. But I shall sometimes cite two or three such instances&#x2014;for clarity&#x2019;s sake and to provide practice in using the tables.</p><p>An example of exclusion or rejection of natures from the form of heat:</p><p><strong>(1)</strong> reject: elemental nature <strong>because of</strong> the rays of the sun</p><p><strong>(2)</strong> reject: heavenly nature <strong>because of</strong> ordinary fire, and especially underground fires, which are the most completely cut off from the rays of heavenly bodies</p><p><strong>(3)</strong> reject: how fine-grained a body&#x2019;s structure is <strong>because of</strong> the fact that all kinds of bodies (minerals, vegetables, skin of animals, water, oil, air, and so on) become warm simply by being close to a fire or other hot body</p><p><strong>(4)</strong> reject: being attached to or mixed with another body that is hot <strong>because of</strong> the fact that red-hot iron and other metals give heat to other bodies without losing any of their own weight or substance</p><p><strong>(5)</strong> reject: light and brightness <strong>because of</strong> boiling water and &#xB7;hot&#xB7; air, and also metals and other solids that become hot but not enough to burn or glow</p><p><strong>(6)</strong> reject: light and brightness <strong>because of</strong> the rays of the moon and other heavenly bodies (except the sun)</p><p><strong>(7)</strong> reject: light and brightness <strong>because of</strong> the fact that red-hot iron has more heat and less brightness than the flame of alcohol</p><p><strong>(8)</strong> reject: rarity <strong>because of</strong> very hot gold and other metals that have the greatest density</p><p><strong>(9)</strong> reject: rarity <strong>because of</strong> air, which remains rare however cold it becomes</p><p><strong>(10)</strong> reject: change in a body&#x2019;s size or shape <strong>because of</strong> red-hot iron, which doesn&#x2019;t become larger or change its shape</p><p><strong>(11)</strong> reject: change in a body&#x2019;s size or shape <strong>because of</strong> the fact that in thermometers, and the like, air expands without becoming noticeably warmer</p><p><strong>(12)</strong> reject: destructive nature, or the forceful addition of any new nature <strong>because of</strong> the ease with which all bodies are heated without any destruction or noticeable alteration</p><p><strong>(13)</strong> reject: expanding or contracting motion of the body as a whole <strong>because of</strong> the agreement and conformity of similar effects displayed by both heat and cold</p><p><strong>(14)</strong> reject: the <em>basic</em> natures of things (as distinct from properties they have through antecedent causes) <strong>because of</strong> the creation of heat by rubbing things together There are other natures beside these; I&#x2019;m not offering complete tables, but merely examples.</p><p>Not a single one of the &#x2018;reject:&#x2019; natures belongs to the form of heat. In all our dealings with heat we can set those aside.</p><p><strong>19.</strong> The process of exclusion is the foundation of true induction; but the induction isn&#x2019;t completed until it arrives at something affirmative. Of course the excluding part &#xB7;of our work&#xB7; is itself nothing like complete, and it can&#x2019;t be so at the beginning. For exclusion is, obviously, the <em>rejection of simple natures</em>; so how can we do it accurately when we still don&#x2019;t have sound and true notions of simple natures? Some of the notions that I have mentioned (such as the notions of <em>elemental nature</em>, <em>heavenly nature</em> and <em>rarity</em>) are vague and ill defined. I&#x2019;m well aware of, and keep in mind, how great a work I am engaged in (namely making the human intellect a match for things and for nature); so I am not satisfied with what I have said up to here. I now go further, and devise and supply more powerful aids for the intellect&#x2014;aids that I shall now present. In the interpretation of nature the mind should be thoroughly prepared and shaped up, so that it will at each stage settle for the degree of certainty that is appropriate there, while remembering (especially at the beginning) that the answer to &#x2018;What is <em>this</em> that we have before us?&#x2019; depends to a great extent on what will come of it later on.</p><p><strong>20.</strong> Truth emerges more quickly from error than from confusion, &#xB7;which implies that it can be worthwhile to aim for clarity even at the risk of going wrong&#xB7;. So I think it will be useful, after making and weighing up three tables of first presentation (such as I have exhibited), to give the intellect permission to try for an interpretation of nature of the affirmative kind on the strength of the instances given in the tables and also of any others that may turn up elsewhere. I call this kind of attempt &#x2022;&#x2018;permission for the intellect&#x2019; or &#x2022;&#x2018;sketch of an interpretation&#x2019; or&#x2014;&#xB7;the label I shall actually use in this work&#xB7;&#x2014;&#x2022;the &#x2018;first harvest&#x2019;.</p><p><strong>A first harvest of the form of heat</strong></p><p>Something that is perfectly clear from what I have said earlier should be borne in mind here, namely that the &#x2022;form of a thing is present in each and every instance of the thing; otherwise it wouldn&#x2019;t be its &#x2022;form; from which it follows that there can&#x2019;t be any counter-instances &#xB7;where the thing is present and the form isn&#x2019;t&#xB7;. Still, the form is much more conspicuous and obvious in &#x2022;some instances than in others, namely in &#x2022;those where the nature of the form is less restrained and obstructed and limited by other natures. Instances of &#x2022;this kind I call &#x2018;luminous&#x2019; or (&#xB7;most of the time&#xB7;) &#x2018;revealing&#x2019; instances. So now let us proceed to the first harvest concerning the form of heat.</p><blockquote>In each and every case of heat the cause of the nature of which heat is a special case appears to be <strong>motion</strong>. This shows most conspicuously in flames, which are on the move all the time, and in boiling or simmering liquids, which are also constantly in motion. It is also shown when motion stirs heat up or increases it&#x2014;as happens with bellows and with wind (Third Table 29) and with other kinds of motion (28 and 31). It is also shown when fire and heat are extinguished by any strong compression, which checks and stops the motion (see 30 and 32). It is shown also by the fact that all bodies are destroyed or at any rate significantly changed by any fire or strong heat, which makes it quite clear that heat causes a tumult and agitation and lively motion in the internal parts of a body, which gradually moves it towards dissolution.</blockquote><p>In certain cases heat generates motion and in certain cases motion generates heat, but <em>that</em> isn&#x2019;t what I am saying when I say that motion is like a genus in relation to heat &#xB7;as one of its species&#xB7;. What I mean is that heat itself <em>is</em> nothing but motion of a certain specific kind; I&#x2019;ll tell you soon what special features of a case of motion make it qualify as a case of heat. Before coming to that, though I shall present three cautions that may be needed to avoid unclarity about some of the terms I shall be using.</p><p>&#xB7;First caution: My topic is <em>heat</em>, not <em>heat-as-we-feel-it</em>&#xB7;. Heat as we feel it is a relative thing&#x2014;relative to humans, not to the world; and it is rightly regarded as merely the effect of heat on the animal spirits. Moreover, in itself it is variable, since a single body induces a perception of cold as well as of heat, depending on the condition of the senses. This is clear from the item 41 in the Third Table [<a href=""https://www.lesswrong.com/newPost#no_41"">here</a>].</p><p>&#xB7;Second caution: My topic is <em>heat</em>, not <em>the passing on of heat</em>&#xB7;. Don&#x2019;t confuse the <em>form</em> of heat with the <em>passing on</em> of heat from body to body, for <em>heat</em> is not the same as <em>heating</em>. Heat is produced by the motion of rubbing something that at first has no heat; and that&#x2019;s enough to show that the transmission of heat is no part of the form of <em>heat</em>. And even when something is heated by another hot thing&#x2019;s coming close to it, that doesn&#x2019;t come from the form of heat; rather, it depends entirely on a higher and more general nature, namely the nature of <em>assimilation</em> or <em>self-multiplication</em>, a subject that needs to be investigated separately. [See <a href=""https://www.lesswrong.com/Text/b2_44_52.xhtml#assimilation"">here</a>.]</p><p>&#xB7;Third caution: My topic is <em>heat</em>, not <em>fire</em>&#xB7;. Our notion of fire is a layman&#x2019;s one, and is useless &#xB7;for scientific purposes&#xB7;. What it counts as &#x2018;fire&#x2019; is the combination of heat and brightness in a body, as in ordinary flame and bodies that are red hot. [Red-heat is treated as a kind of &#x2018;burning&#x2019; in item 24 <a href=""https://www.lesswrong.com/newPost#point24"">here</a>.]</p><p>Having guarded against verbal misunderstandings, I now at last come to the true specific differences which qualify a case of &#x2022;motion (&#xB7;genus&#xB7;) to count as a case of &#x2022;heat (&#xB7;species&#xB7;).</p><p>The <strong>first</strong> difference then is this. Heat is an <em>expansive</em> motion in which a body tries expand to a greater size than it had before. We see this most clearly in flame, where the smoke or thick vapour obviously expands into flame.</p><p>It also appears in any boiling liquid, which can be seen to swell, rise and bubble, and goes on expanding itself until it turns into a body that is far bigger than the liquid itself, namely into steam, smoke, or air.</p><p>It appears also in all wood and &#xB7;other&#xB7; flammable things, where there is sometimes sweating and always evaporation.</p><p>It is shown also in the melting of metals. Because they are highly compact, metals don&#x2019;t easily expand and dilate; but their <em>spirit</em> expands, and wants to expand further; so it forces and agitates the lumpier parts into a liquid state. If the metal becomes hotter still, it dissolves and turns much of itself into a volatile substance.</p><p>It appears also in iron or rocks: they don&#x2019;t liquefy or run together, but they become soft. Similarly with wooden sticks, which become flexible when slightly heated in hot ashes.</p><p>But this kind of motion is best seen in air, which a little heat causes to expand&#x2014;see Third Table 38 [<a href=""https://www.lesswrong.com/newPost#item38"">here</a>].</p><p>It shows up also in the contrary nature, namely <em>cold</em>. For cold contracts all bodies&#x2014;makes them shrink&#x2014;so that in a hard frost nails fall out of walls, bronze vessels crack, and heated glass when exposed to cold cracks and breaks. Similarly, a little cooling makes air contract, as in 38. But I&#x2019;ll say more about this when I deal properly with cold.</p><p>It&#x2019;s no wonder that heat and cold should exhibit many actions in common (for which see the Second Table 32). This first specific difference &#xB7;helping to denarcate the species <em>heat</em> within the genus <em>motion</em>&#xB7; concerns a feature of heat that is diametrically opposite to a feature of <em>cold</em>, because whereas heat expands cold contracts; but the third and fourth differences (still to come) belong to the natures both of heat and of cold.</p><p>The <strong>second</strong> difference is a special case of the first, namely: Heat is a motion in which the hot body &#x2022;expands while it &#x2022;rises. This is a case of mixed motion, of which there are many&#x2014;e.g. an arrow or javelin &#x2022;rotates while it &#x2022;flies forward. Similarly the motion of heat is an expansion as well as a movement upwards.</p><p>This difference appears when you put a poker into a fire. If you put it in upright and hold it by the top, it soon burns your hand; if you put it in at the side or from below, it takes longer to burn your hand.</p><p>It can also be seen in fractional distillation, which men use for &#xB7;extracting essences from&#xB7; delicate flowers that soon lose their scent. It has been found in practice that one should place the fire not below &#xB7;the distilling retort&#xB7; but above it, so as to burn less. For all heat, not only flame, tends upward.</p><p>This should be tried out on the opposite nature, cold, to learn whether cold contracts a body downward as heat expands it upward. Here&#x2019;s how to do it. Take two iron rods or glass tubes of exactly the same dimensions, warm them a little and place a sponge steeped in cold water or snow at the bottom of the one, and a similar one at the top of the other. I think that the end of the rod that has snow at the top will cool sooner than the end of the rod with snow at the bottom&#x2014;the opposite of what happens with heat.</p><p>The <strong>third</strong> specific difference is this: heat is a motion that isn&#x2019;t expansive uniformly through the whole &#xB7;hot&#xB7; body, but only through its smaller particles; and this expansion &#xB7;in any one particle&#xB7; is at the same time checked, repelled, and beaten back &#xB7;by the expansions of other particles&#xB7;, so that there&#x2019;s a back-and-forth motion within the body, which is irritated by all the quivering, straining and struggling that goes on; and from that comes the <em>fury</em> of fire and heat.</p><p>This &#xB7;specific&#xB7; difference is most apparent in flames and in boiling liquids, where there are continual little rises and falls across their surface.</p><p>It also shows up in bodies that are so compact that when heated or ignited they don&#x2019;t swell or expand in bulk&#x2014;e.g. in red-hot iron, in which the heat is very sharp.</p><p>And it is apparent in hearth fires, which burn brightest in the coldest weather.</p><p>It also shows in the fact that when the air in a calendar glass [see item 38 <a href=""https://www.lesswrong.com/newPost#item38"">here</a>] expands without obstacles or counter-pressures, and thus expands at the same rate throughout, there is no perceptible heat. Also when an enclosed body of &#xB7;compressed&#xB7; air escapes, no great heat is observed; that is because although the air bursts out with the greatest force, its only expansive motion is a motion of <em>the whole</em>, with no back-and-forth motions in <em>the particles</em>. . . .</p><p>It is also shown in this, that all burning acts on minute pores in the body in question, so that burning digs into the body, penetrating and pricking and stinging it like the points of countless needles. . . .</p><p>And this third specific difference is shared with the nature of <em>cold</em>. For in cold the contractive motion is checked by a tendency to expand, just as in heat the expansive motion is checked by a tendency to contract. Thus, whether the particles of a body work inward or outward, the mode of action is the same though the degree of strength may be very different; because on the surface of the earth we don&#x2019;t have anything that is intensely cold. [See item (3) <a href=""https://www.lesswrong.com/Text/b2_44_52.xhtml#pg121"">here</a>.]</p><p>The <strong>fourth</strong> specific difference is a special case of the third. It is that the motion of pricking and penetrating must be fairly fast, not sluggish, and must go by particles&#x2014;very small ones but a bit bigger than the smallest.</p><p>This difference is apparent when you compare the effects of &#x2022;fire with the effects of &#x2022;time or age. Age or time makes things wither, consumes and undermines them, reduces them to ashes, just as much as fire does, though it acts on even smaller particles than fire acts on; because that motion is very slow and acts on very tiny particles, there is no detectable heat.</p><p>It is also shown by comparing the dissolution &#xB7;in acids&#xB7; of iron and gold. Gold is dissolved without any heat being stirred up, whereas iron, when it is dissolved about as quickly as gold, starts up a violent heat. This is because the solvent for gold enters the gold gently and works at a level of very small particles, so that the particles of the gold give way easily; whereas the solvent for iron enters the iron roughly and forcibly, and the particles of the iron are more stubborn.</p><p>It is also apparent in some gangrenes and cases of rotting flesh, which don&#x2019;t arouse much heat or pain because the rotting process operates at the level of such tiny particles.</p><p>I offer this as the &#x2022;first harvest&#x2014;or &#x2022;sketch of an interpretation&#x2014;concerning the form of heat, made by way of &#x2022;permission to the intellect [these three labels are introduced in <strong>20</strong> <a href=""https://www.lesswrong.com/newPost#first_harvest"">here</a>.].</p><p>The form or true definition of heat can be derived from this first harvest. (I&#x2019;m talking about heat considered absolutely, not heat relative to the senses.) Here it is, briefly:</p><blockquote>&#x2022;Heat is an expansive motion that is resisted, and that fights its way through the smaller particles &#xB7;of the hot body&#xB7;.</blockquote><p>Special case of this expansion:</p><blockquote>&#x2022;While expanding in all directions &#xB7;the hot body&#xB7; has a tendency to rise.</blockquote><p>Special case of the struggle through the particles:</p><blockquote>&#x2022;It is not very slow; rather it is fast and has some force.</blockquote><p>This tells us how in practice to create heat. Here is the story:</p><blockquote>In some natural body, arouse a motion to expand; and repress this motion and turn it back on itself so that the expansion doesn&#x2019;t proceed evenly, but partly succeeds and is partly held back.</blockquote><p>If you do that you will undoubtedly generate heat. It makes no difference whether</p><blockquote>&#x2022;the body is made of earthly elements or contains heavenly substances,<br>&#x2022;is luminous or opaque,<br>&#x2022;is rare or dense,<br>&#x2022;is spatially expanded or still of its original size,<br>&#x2022;tends towards dissolution or keeps its original condition,<br>&#x2022;is animal, vegetable, or mineral (water, oil or air),</blockquote><p>or any other substance that is capable of the motion described. Sensible heat is the same, but considered with reference to the senses. Let us now proceed to further aids.</p><p>[That last remark refers to the &#x2018;aids&#x2019; that were promised in <strong>19</strong> <a href=""https://www.lesswrong.com/newPost#pt19"">here</a>; the first such &#x2018;aid&#x2019; has been <strong>20</strong>. A reminder about &#x2018;the tables of first presentation&#x2019;:</p><blockquote>&#x2022;the first table, of essence and presence, starts <a href=""https://www.lesswrong.com/newPost#first_table"">here</a>;<br>&#x2022;the second table, of divergence or nearby absence, starts <a href=""https://www.lesswrong.com/newPost#second_table"">here</a>;<br>&#x2022;the third table, of degrees or of comparison, starts <a href=""https://www.lesswrong.com/newPost#third_table"">here</a>;<br>&#x2022;&#x2018;the table of exclusion or rejection&#x2019; starts <a href=""https://www.lesswrong.com/newPost#exclusion_or_rejection"">here</a>;<br>&#x2022;&#x2018;the first harvest&#x2019; starts <a href=""https://www.lesswrong.com/newPost#first_harvest"">here</a>.</blockquote><p>This reminder may be useful as a guide to Bacon&#x2019;s next remark.]</p><p><strong>21.</strong> So much for the tables of &#x2022;first presentation and of &#x2022;rejection or exclusion, and the &#x2022;first harvest based on them. Now we have to proceed to the other aids to the intellect in the interpretation of nature and in true and perfect induction. I&#x2019;ll present them in terms of heat and cold whenever tables are appropriate; but when only a few examples are needed I&#x2019;ll take them from all over the place, so as to give my doctrine as much scope as possible without creating confusion.</p><p>[We are about to meet the phrase &#x2018;privileged instances&#x2019;. The Latin <em>praerogativa instantarum</em> strictly means &#x2018;privilege of instances&#x2019;, but Bacon always handles it as though it stood for a kind of instance, not a kind of privilege. The use of &#x2018;privilege&#x2019; to translate <em>praerogativa</em> is due to Silverthorne, who relates it to the <em>centuria praerogativa</em> in ancient republican Rome&#x2014;the aristocrats&#x2019; privilege of voting first and thus having the best chance to influence the votes of others.]</p><p>My topics will be, in this order:</p><p>1. privileged instances</p><p>2. supports for induction</p><p>3. the correcting of induction</p><p>4. adapting the investigation to the nature of the subject</p><p>5. which natures should be investigated first, and which later</p><p>6. the limits of investigation, or a synopsis of all natures in the universe</p><p>7. practical consequences</p><p>8. preparations for investigation</p><p>9. the ascending and descending scale of axioms.</p><p>[There are twenty-seven classes of privileged instances, some with a number of sub-classes. Bacon&#x2019;s discussion of them runs to the end of the work. The other eight topics were to have been dealt with in later instalments of the Great Fresh Start, which he never wrote.]</p><p><strong>22.</strong> Class 1 of privileged instances: <strong>solitary instances</strong>. Those are ones in which the nature we are investigating</p><blockquote>appears in things that have <em>nothing else</em> in common with other things that have that nature,</blockquote><p>or ones in which the nature we are investigating</p><blockquote>does not appear in things that have <em>everything else</em> in common with other things that do have that nature.</blockquote><p>&#xB7;I put these first &#xB7; because it is clear that they save us from detours, leading quickly and securely to <em>exclusions</em>, so that a few solitary instances are as good as many.</p><p>Suppose for example that we are investigating the nature of colour: in that context prisms, crystals, dew-drops and the like, which make colours in themselves and project them outside themselves onto a wall, are solitary instances. For they have nothing else in common with the colours inherent in flowers, coloured stones, metals, woods, etc.&#x2014;i.e. nothing but colour. From which we can easily draw the conclusion that colour is merely a modification of the light that the object takes in. With prisms, crystals etc. the light is modified by the different angles at which the light strikes the body; with flowers, coloured stones etc. it is modified by various textures and microstructures of the body. These instances are &#x2022;resemblance-solitary.</p><p>In that same investigation of light: the distinct veins of white and black in a piece or marble, and the variegation of colour in flowers of the same species, are solitary instances. The black and white streaks in marble have almost everything in common except their colour, and so do the streaks of pink and white in a carnation. From this we can easily infer that colour doesn&#x2019;t have much to do with the intrinsic nature&#x2014;&#xB7;the microscopic fine texture&#xB7;&#x2014;of a body, but only on the quasi-mechanical arrangement of its larger parts. These instances are &#x2022;difference-solitary. . . .</p><p><strong>23.</strong> Class 2 of privileged instances: <strong>shifting instances</strong>. Those are ones where the nature under study is &#x2022;shifting towards being produced when it didn&#x2019;t previously exist, or &#x2022;shifting towards non-existence when it existed before. Shifting instances, whichever kind of shift they involve, are always twofold, or rather it is one instance in which the movement is continued until it reaches the opposite state.</p><p>[At this point some material is removed, and will be reinserted as a paragraph between <strong>*</strong>asterisks<strong>*</strong> below; it is easier to understand there than it would be here.]</p><p>Here is an example of a shifting instance. Suppose we are investigating <em>whiteness</em>: shifting instances in which the shift is towards production or existence &#xB7;of whiteness&#xB7; are</p><blockquote>unbroken glass shifting to powdered glass ordinary water shifting to water shaken up to make foam.</blockquote><p>Plain glass and water are transparent, not white, whereas pounded glass and foaming water are white, not transparent. So we have to ask what happened to the glass or water in this shift. Obviously, the form of whiteness is brought in by the pounding of the glass and the shaking of the water; but we find that nothing has occurred except the breaking up of the glass and water into small parts, and the introduction of air. So we have this result:</p><blockquote>Two bodies, air and water (or: air and glass) which are more or less transparent come to exhibit whiteness as soon as they are broken up into small bits &#xB7;and the bits are mixed&#xB7;, this whiteness being brought about by the unequal refraction of the rays of light.</blockquote><p>This is a big step towards discovering the form of whiteness.</p><p><strong>*</strong>Such instances don&#x2019;t just lead quickly and securely to exclusions, but also narrow down the search for the affirmation or the form itself [&#x2018;exclusion&#x2019; and &#x2018;affirmation&#x2019; are introduced in <strong>15</strong> <a href=""https://www.lesswrong.com/newPost#no_15"">here</a>]. For the form of a thing must be something that is introduced by a shift, or removed and wiped out by a shift in the other direction. Of course every exclusion supports some affirmation, but the support is more direct when the exclusion comes from one case rather than from a number of cases. And my discussion has made it clear that the form that comes to light in a single instance leads the way to the discovery of it in all the rest. And the simpler the shift, the more value we should attach to the instance. And another thing: shifting instances are of great value in the practical part &#xB7;of scientific inquiry&#xB7;: a shifting instance exhibits &#x2022;the form &#xB7;under investigation&#xB7; linked with &#x2022;the cause of its existing (or the cause of its not existing); that provides great clarity in one instance and an easy transition to others. But shifting instances create a certain danger against which I should warn you: they may lead us to link the form too closely to its efficient cause, and so encourage a false view of the form, drawn from a view of the efficient cause. The efficient cause is always understood to be merely the vehicle for or bearer of the form. It is not hard to avoid this danger in a properly conducted exclusion.<strong>*</strong></p><p>I should give an example of this danger. A mind that is led astray by efficient causes of this sort will too easily conclude that &#x2022;air is always required for the form of whiteness, or that &#x2022;whiteness is generated only by transparent bodies&#x2014;both of which are entirely false, and refuted by numerous exclusions. What <em>will</em> be found (setting air and the like aside) is this:</p><blockquote>all the particles that affect vision are equal</blockquote><blockquote>transparent</blockquote><blockquote>unequal and simply textured</blockquote><blockquote>white</blockquote><blockquote>unequal with complex regular texture</blockquote><blockquote>any but black</blockquote><blockquote>unequal and complex in an irregular way</blockquote><blockquote>black</blockquote><p>So now we have before us an instance with a shift to the &#x2022;production of the nature under study, namely whiteness. For an instance that shifts to the &#x2022;destruction of the same nature of whiteness, consider breaking up foam or melting snow. In each case, what you then have is <em>water</em>, not broken into little particles and not mixed with air, and this sheds whiteness and puts on transparency.</p><p>It&#x2019;s important to note that shifting instances include not only those in which the nature under study shifts toward production or toward destruction, but also those in which the nature shifts towards increasing or decreasing. It&#x2019;s because these also contribute to revealing the form, as can be clearly seen from the definition of <em>form</em> that I have given &#xB7;in <strong>17</strong>&#xB7;, and the Table of Degrees [starting <a href=""https://www.lesswrong.com/newPost#pg59"">here</a>]. Paper that is white when dry become less white and nearer to being transparent when it is wetted&#x2014;i.e. when air is excluded and water introduced. The explanation of what is happening here is analogous to the explanation of the first shifting instances.</p><p><strong>24.</strong> Class 3 of privileged instances: <strong>revealing instances</strong>, which I have already mentioned in the first harvest concerning heat, and which I also call &#x2018;luminous&#x2019; and &#x2018;freed and predominant&#x2019;. They are the instances in which the nature under study is revealed</p><blockquote>naked and standing on its own feet, and also<br>at its height and in full strength,</blockquote><p>not muffled by any impediments. This is either because &#x2022;there aren&#x2019;t any impediments in this instance or because &#x2022;there are some but the nature we are studying is present in such strength that it holds them down and pushes them around. &#xB7;Here is the background <em>setting</em> for these revealing instances&#xB7;:</p><blockquote>Every body is capable of having many forms or natures linked together; they can crush, depress, break and bind one another so that the individual forms are obscured. But we find that in some subjects the nature under investigation stands out from the others, either because there are no obstacles or because its vigorous strength makes it prominent.</blockquote><p>Instances of this kind reveal the form with special clarity.</p><p>But we should be careful in our handling of &#xB7;what seem to be&#xB7; revealing instances, not rushing to conclusions. When something reveals a form very conspicuously and seems to force it on the notice of our intellect, we should view it with suspicion and should avail ourselves of a strict and careful exclusion &#xB7;of other potentially relevant features, rather than abruptly brushing them aside in our enthusiasm for the conspicuous nature that has attracted our attention&#xB7;.</p><p>Suppose, for example, that we are investigating the nature of heat. As I said earlier [in item 38 <a href=""https://www.lesswrong.com/newPost#item38"">here</a>], the motion of expansion is the main element in the form of heat, and a revealing instance of <em>that</em> is a &#x2022;thermometer. Although &#x2022;flame obviously exhibits expansion, it doesn&#x2019;t show expansion as an ongoing process, because a flame can be so quickly snuffed out. Nor does &#x2022;boiling water provide a good display of expansion in its own body &#xB7;<em>as water</em>&#xB7; because it so easily turns into vapour or air. As for red-hot iron and its like: they are so far from exhibiting expansion as an ongoing process that their expansion is almost imperceptible; that&#x2019;s because their spirit is being crushed and broken by the coarse and compact particles, which curb and subdue the expansion. But a thermometer clearly displays expansion in air, revealing it as conspicuous, progressive, and enduring rather than transitory.</p><p>To take another example: suppose the nature inquired into is <em>weight</em>. A revealing instance of weight is mercury. It is heavier than anything else except gold, which is only slightly heavier; and mercury does a better job of indicating the form of weight than gold does, because gold is solid and compact&#x2014;features that seem to come from its <em>density</em>&#x2014; whereas mercury is liquid and full of spirit despite being much heavier than the diamond and other bodies that are thought to be the most solid. This reveals that the form of heaviness or weight depends simply on the <em>quantity</em> of matter and not on how <em>compact</em> the body is.</p><p><strong>25.</strong> Class 4 of privileged instances: <strong>concealed instances</strong>, which I also &#xB7;though not again in this work&#xB7; call &#x2018;instances of the twilight&#x2019;. They are pretty nearly the exact opposites of revealing instances. They exhibit the nature under investigation at its lowest strength, as though it were in its cradle, newly born, making its first attempts but buried under and subdued by a contrary nature. Still, such instances are very helpful in the discovery of forms; because just as</p><blockquote>revealing instances lead easily to &#x2022;specific differences,</blockquote><p>so also</p><blockquote>concealed instances are the best guides to &#x2022;genera,</blockquote><p>i.e. to the common natures of which the natures under investigation are merely special cases. &#xB7;That is to say, revealing instances help us to move down the classificatory table, concealed instances help us to move up&#xB7;.</p><p>Suppose for example that the nature under investigation is &#x2022;solidity or a thing&#x2019;s holding its shape, the opposite of which is &#x2022;fluidity. Concealed instances of this are ones that exhibit some low level of shape-holding <em>in a fluid</em>&#x2014;for example a bubble of water, which has a sort of shaped <em>skin</em> made of water. Similarly with trickling water: if the water keeps coming, the drops lengthen themselves out into a thin thread so as to keep the stream unbroken; and if there isn&#x2019;t enough water for that, the water falls in round drops, that being the shape that best preserves the water from breaking up &#xB7;into still smaller portions&#xB7;. But the instant the thread of water stops and the drops begin, the water jumps back upwards so as to avoid breaking. And in metals, which when melted form thick fluids, the molten drops often jump back up and stay there. . . . The same kind of thing can be seen in the children&#x2019;s game when they take water, thicken it a little with soap, and blow it through a hollow reed: this combines the water with air so as to make a cluster of bubbles that is firm enough to be thrown some distance without breaking up. But foam and snow provide the best examples of this phenomenon. They become almost solid enough to be cut with a knife, although they are made out of two fluids&#x2014;air and water. All of this pretty clearly indicates &#x2022;that &#x2018;solid&#x2019; and &#x2018;liquid&#x2019; are &#xB7;not useful terms in the present context, because they are&#xB7; layman&#x2019;s notions which relate &#xB7;not to the scientific facts about a thing but only to how it strikes&#xB7; our senses. It also indicates &#x2022;that in fact all bodies have a tendency to avoid being broken up, a tendency that is weak in homogeneous bodies (which is what fluids are), and stronger in bodies made up of different kinds of materials (&#xB7;the ones the layman calls &#x2018;solid&#x2019;&#xB7;). That is because a body is bound together when heterogeneous matter is introduced to it, whereas the insertion of homogeneous matter dissolves the body and makes it fall apart.</p><p>Here are three more examples. <strong>(1)</strong> Suppose that the nature we are investigating is the <em>attraction</em> or <em>coming together</em> of bodies. The best revealing instance of the form of this is the magnet. There is also the <em>non-attracting</em> nature&#x2014;the contrary of the attracting one&#x2014;and this can even be found in the same substance. Thus iron doesn&#x2019;t attract iron, lead doesn&#x2019;t attract lead, or wood wood, or water water.</p><p>[In what follows, an &#x2018;armed&#x2019; magnet is one equipped with an &#x2018;armature&#x2019; in the sense of &#x2018;a piece of soft iron placed in contact with the poles of the magnet, which preserves and increases the magnetic power; or any arrangement which produces the same result&#x2019; (OED). Another such arrangement is an &#x2018;armature&#x2019; in <em>our</em> sense of the word&#x2014;coils of wire conducting electricity&#x2014; but that wasn&#x2019;t discovered as a means of magnetism until two centuries later.]</p><p>Now a concealed instance &#xB7;of attraction&#xB7; is provided by &#x2022;a magnet armed with iron, or rather by &#x2022;the iron in an armed magnet. Its nature is such that</p><blockquote>an armed magnet does not attract iron <em>from a distance</em> more powerfully than an unarmed magnet does,</blockquote><p>whereas</p><blockquote>when the iron in an armed magnet <em>touches</em> some other iron, the magnet supports a far greater weight of iron than a simple unarmed magnet would.</blockquote><p>This is because of the similarity of substances, iron on iron&#x2014;an effect that was latent in the iron &#xB7;all along&#xB7;, but was completely <em>concealed</em> before the magnet was brought into play. So it is clear that the form of coming-together is something that is lively and strong in the magnet, feeble and latent in iron. <strong>(2)</strong> It has been noticed that small wooden arrows with no iron points, shot from large guns into the sides of ships or into other wooden targets, penetrate more deeply than they would if they were tipped with iron. This is because of the similarity of substances, wood on wood, although this property had previously been latent in the wood&#x2014;&#xB7;only latent, and thus concealed&#xB7;. <strong>(3)</strong> Similarly, whole bodies of air (water) don&#x2019;t obviously attract other bodies of air (water), but the likelihood of a bubble&#x2019;s bursting is increased when it is touched by another bubble. This is because of water&#x2019;s &#xB7;usually concealed&#xB7; inclination to join with water, and air&#x2019;s to join with air. Such concealed instances (which are very useful, as I have said) show up most conspicuously in small portions of bodies. The reason for that is that larger masses follow more general forms, as I&#x2019;ll explain in due course.</p>",Francis Bacon,francis-bacon,Francis Bacon,
Ajcq9xWi2fmgn8RBJ,The Credit Assignment Problem,the-credit-assignment-problem,https://www.lesswrong.com/posts/Ajcq9xWi2fmgn8RBJ/the-credit-assignment-problem,2019-11-08T02:50:30.412Z,107,41,40,False,False,,"<p><i>This post is eventually about </i><a href=""https://www.lesswrong.com/s/HeYtBkNbEe7wpjc6X""><i>partial agency</i></a><i>. However, it's been a somewhat tricky point for me to convey; I take the long route. <strong>Epistemic status:</strong> slightly crazy.</i></p><hr><p>I've occasionally said ""Everything boils down to credit assignment problems.""</p><p>What I really mean is that credit assignment pops up in a wide range of scenarios, and improvements to credit assignment algorithms have broad implications. For example:</p><ul><li>Politics.<ul><li>When politics focuses on (re-)electing candidates based on their track records, it's about credit assignment. The practice is sometimes derogatorily called ""finger pointing"", but the basic computation makes sense: figure out good and bad qualities via previous performance, and vote accordingly.</li><li>When politics instead focuses on policy, it is still (to a degree) about credit assignment. Was raising the minimum wage responsible for reduced employment? Was it responsible for improved life outcomes? Etc.</li></ul></li><li>Economics.<ul><li>Money acts as a kind of distributed credit-assignment algorithm, and questions of how to handle money, such as how to compensate employees, often involve credit assignment.</li><li>In particular, <a href=""https://www.lesswrong.com/tag/mechanism-design"">mechanism design</a> (a subfield of economics and game theory) can often be thought of as a credit-assignment problem.</li></ul></li><li>Law.<ul><li>Both criminal law and civil law involve concepts of fault and compensation/retribution -- these at least resemble elements of a credit assignment process.</li></ul></li><li>Sociology.<ul><li>The distributed computation which determines social norms involves a heavy element of credit assignment: identifying failure states and success states, determining which actions are responsible for those states and who is responsible, assigning blame and praise.</li></ul></li><li>Biology.<ul><li>Evolution can be thought of as a (relatively dumb) credit assignment algorithm.</li></ul></li><li>Ethics.<ul><li>Justice, fairness, contractualism, issues in utilitarianism.</li></ul></li><li>Epistemology.<ul><li>Bayesian updates are a credit assignment algorithm, intended to make high-quality hypotheses rise to the top.</li><li>Beyond the basics of Bayesianism, building good theories realistically involves <i>identifying which concepts are responsible for successes and failures</i>. This is credit assignment.</li></ul></li></ul><p>Another big area which I'll claim is ""basically credit assignment"" is artificial intelligence.</p><hr><p>In the 1970s, John Holland kicked off the investigation of <a href=""https://en.wikipedia.org/wiki/Learning_classifier_system#History"">learning classifier systems</a>. John Holland had recently invented the Genetic Algorithms paradigm, which applies an evolutionary paradigm to optimization problems. Classifier systems were his attempt to apply this kind of ""adaptive"" paradigm (as in ""complex adaptive systems"") to cognition. Classifier systems added an economic metaphor to the evolutionary one; little bits of thought paid each other for services rendered. The hope was that a complex ecology+economy could develop, solving difficult problems.</p><p>One of the main design issues for classifier systems is the virtual economy -- that is, the <i>credit assignment</i> algorithm. An early proposal was the bucket-brigade algorithm. Money is given to cognitive procedures which produce good outputs. These procedures pass reward back to the procedures which activated them, who similarly pass reward back in turn. This way, the economy supports chains of useful procedures.</p><p>Unfortunately, the bucket-brigade algorithm was vulnerable to parasites. Malign cognitive procedures could gain wealth by activating useful procedures without really contributing anything. This problem proved difficult to solve. Taking the economy analogy seriously, we might want cognitive procedures to decide intelligently who to pay for services. But, these are supposed to be itty bitty fragments of our thought process. Deciding how to pass along credit is a very complex task. Hence the need for a pre-specified solution such as bucket-brigade.</p><p>The difficulty of the credit assignment problem lead to a split in the field. Kenneth de Jong and Stephanie Smith founded a new approach, ""Pittsburgh style"" classifier systems. John Holland's original vision became ""Michigan style"".</p><p>Pittsburgh style classifier systems evolve the entire set of rules, rather than trying to assign credit locally. A set of rules will stand or fall together, based on overall performance. This abandoned John Holland's original focus on online learning. Essentially, the Pittsburgh camp went back to plain genetic algorithms, albeit with a special representation.</p><p>(I've been <a href=""https://www.lesswrong.com/posts/qpZTWb2wvgSt5WQ4H/defining-myopia#jyFnBzgXgsgQPFGu2"">having some disagreements with Ofer</a>, in which Ofer suggests that genetic algorithms are relevant to my recent thoughts on partial agency, and I object on the grounds that the phenomena I'm interested in have to do with online learning, rather than offline. In my imagination, arguments between the Michigan and Pittsburgh camps would have similar content. I'd love to be a fly on the wall for those old debates. to see what they were really like.)</p><p>You can think of Pittsburg-vs-Michigan much like raw Bayes updates vs belief propagation in Bayes nets. Raw Bayesian updates operate on <i>whole hypotheses</i>. Belief propagation instead makes a lot of little updates which spread around a network, resulting in computational efficiency at the expense of accuracy. Except Michigan-style systems didn't have the equivalent of belief propagation: bucket-brigade was a very poor approximation.</p><p>Ok. That was then, this is now. Everyone uses gradient descent these days. What's the point of bringing up a three-decade-old debate about obsolete paradigms in AI?</p><p>Let's get a little more clarity on the problem I'm trying to address.</p><h1>What Is Credit Assignment?</h1><p>I've said that classifier systems faced a credit assignment problem. What does that mean, exactly?</p><p>The definition I want to use for this essay is:</p><ul><li>you're engaged in some sort of task;</li><li>you use some kind of strategy, which can be broken into interacting pieces (such as a set of rules, a set of people, a neural network, etc);</li><li>you receive some kind of feedback about how well you're doing (such as money, loss-function evaluations, or a reward signal);</li><li>you want to use that feedback to adjust your strategy.</li></ul><p>So, credit assignment is the problem of turning feedback into strategy improvements.</p><p>Michigan-style systems tried to do this <i>locally</i>, meaning, individual itty-bitty pieces got positive/negative credit, which influenced their ability to participate, thus adjusting the strategy. Pittsburg-style systems instead operated <i>globally</i>, forming conclusions about how the <i>overall</i> set of cognitive structures performed. Michigan-style systems are like organizations trying to optimize performance by promoting people who do well and giving them bonuses, firing the incompetent, etc. Pittsburg-style systems are more like consumers selecting between whole corporations to give business to, so that ineffective corporations go out of business.</p><p>(Note that this is <i>not</i> the typical meaning of global-vs-local search that you'll find in an AI textbook.)</p><p>In practice, two big innovations made the Michigan/Pittsburgh debate obsolete: backprop, and Q-learning. Backprop turned global feedback into local, in a theoretically sound way. Q-learning provided a way to assign credit in online contexts. In the light of history, we could say that the Michigan/Pittsburgh distinction conflated local-vs-global with online-vs-offline. There's no <i>necessary</i> connection between those two; online learning is compatible with assignment of local credit.</p><p>I think people generally understand the contribution of backprop and its importance. Backprop is essentially the correct version of what bucket-brigade was <i>overtly</i> trying to do: pass credit back along chains. Bucket-brigade wasn't quite right in how it did this, but backprop corrects the problems.</p><p>So what's the importance of Q-learning? I want to discuss that in more detail.</p><h1>The Conceptual Difficulty of 'Online Search'</h1><p>In online learning, you are repeatedly producing outputs of some kind (call them ""actions"") while repeatedly getting feedback of some kind (call it ""reward""). But, you don't know how to associate particular actions (or combinations of actions) with particular rewards. I might take the critical action at time 12, and not see the payoff until time 32.</p><p>In offline learning, you can solve this with a sledgehammer: you can take the total reward over everything, with one fixed internal architecture. You can try out different internal architectures and see how well each do.</p><p>Basically, in offline learning, you have a function you can optimize. In online learning, you don't.</p><p>Backprop is just a computationally efficient way to do hillclimbing search, where we repeatedly look for small steps which improve the overall fitness. But how do you do this if you <i>don't have a fitness function? </i>This is part of the gap between <a href=""https://www.lesswrong.com/posts/ZDZmopKquzHYPRNxq/selection-vs-control"">selection vs control</a>: selection has access to an evaluation function; control processes do not have this luxury.</p><p>Q-learning and other reinforcement learning (RL) techniques provide a way to define the equivalent of a fitness function for online problems, so that you can learn.</p><h1>Models to the Rescue</h1><p>So, how can be associate rewards with actions?</p><p>One approach is to use a model.</p><p>Consider the example of firing employees. A corporation gets some kind of feedback about how it is doing, such as overall profit. However, there's often a fairly detailed understanding of what's driving those figures:</p><ul><li>Low profit won't just be a mysterious signal which must be interpreted; a company will be able to break this down into more specific issues such as low sales vs high production costs.</li><li>There's some understanding of product quality, and how that relates to sales. A company may have a good idea of which product-quality issues it needs to improve, if poor quality is impacting sales.</li><li>There's a fairly detailed understanding of the whole production line, including which factors may impact product quality or production expenses. If a company sees problems, it probably also has a pretty good idea of which areas they're coming from.</li><li>There are external factors, such as economic conditions, which may effect sales <i>without indicating anything about the quality of the company's current strategy.</i> Thus, our model may sometimes lead us to ignore feedback.</li><li>Etc.</li></ul><p>So, models allow us to interpret feedback signals, match these to specific aspects of our strategy, and adapt strategies accordingly.</p><p>Q-learning makes an assumption that the state is fully observable, amongst other assumptions.</p><p>Naturally, we would like to reduce the strengths of the assumptions we have to make as much as we can. One way is to look at increasingly rich model classes. <a href=""https://www.lesswrong.com/posts/TtYuY2QBug3dn2wuo/the-problem-with-aixi"">AIXI</a> uses all computable models. But maybe ""all computable models"" is still too restrictive; we'd like to get results <a href=""https://www.lesswrong.com/posts/efWfvrWLgJmbBAs3m/embedded-world-models"">without assuming a grain of truth</a>. (That's why I am not really discussing Bayesian models much in this post; I don't want to assume a grain of truth.) So we back off even further, and use logical induction or InfraBayes. Ok, sure.</p><p>But wouldn't the best way be to try to learn without models at all? That way, we reduce our ""modeling assumptions"" to zero.</p><p>After all, there's something called ""model-free learning"", right?</p><h2>Model-Free Learning Requires Models</h2><p>How does model-free learning work? Well, often you work with a simulable environment, which means you can estimate the quality of a policy by running it many times, and use algorithms such as policy-gradient to learn. This is called ""model free learning"" because the learning part of the algorithm doesn't try to predict the consequences of actions; you're just learning which action to take. From our perspective here, though, this is 100% cheating; you can only learn because you have a good model of the environment.</p><p>Moreover, model-free learning typically works by splitting up tasks into <i>episodes.</i> An episode is a period of time for which we assume rewards are self-enclosed, such as a single playthru of an Atari game, a single game of Chess or Go, etc. This approach doesn't solve a <i>detailed</i> reward-matching problem, attributing reward to specific actions; instead it relies on a <i>course</i> reward-matching. Nonetheless, it's a rather strong assumption: an animal learning about an environment can't separate its experience into episodes which aren't related to each other. Clearly this is a ""model"" in the sense of a strong assumption about how specific reward signals are associated with actions.</p><p>Part of the problem is that most reinforcement learning (RL) researchers aren't really <i>interested</i> in getting past these limitations. Simulable environments offer the incredible advantage of being able to learn very fast, by simulating far more iterations than could take place in a real environment. And most tasks can be reasonably reduced to episodes.</p><p>However, this won't do as a model of intelligent agency in the wild. Neither evolution nor the free market divide thing into episodes. (No, ""one lifetime"" isn't like ""one episode"" here -- that would only be the case if total reward due to actions taken in that lifetime could be calculated, EG, as total number of offspring. This would ignore inter-generational effects like parenting and grandparenting, which improve reproductive fitness of offspring at a cost in total offspring.)</p><p>What about more theoretical models of model-free intelligence?</p><h2>Idealized Intelligence</h2><p><a href=""https://www.lesswrong.com/tag/aixi"">AIXI</a> is the gold-standard theoretical model of arbitrarily intelligent RL, but it's totally model-based. Is there a similar standard for model-free RL?</p><p>The paper <a href=""https://www.ini.rub.de/upload/file/1511450743_63baefe1e28ac92a0cbc/glasmachers2011a.pdf"">Optimal Direct Policy Search by Glasmachers and Schmidhuber</a> (henceforth, ODPS) aims to do for model-free learning what AIXI does for model-based learning. Where AIXI has to assume that there's a best computable <i>model of the environment</i>, ODPS instead assumes that there's a computable best <i>policy</i>. It searches through the policies without any model of the environment, or any planning.</p><p>I would argue that their algorithm is incredibly dumb, when compared to AIXI:</p><blockquote><p>The basic simple idea of our algorithm is a nested loop that simultaneously<br>makes the following quantities tend to infinity: the number of programs considered, the number of trials over which a policy is averaged, the time given to each<br>program. At the same time, the fraction of trials spent on exploitation converges<br>towards 1.</p></blockquote><p>In other words, it tries each possible strategy, tries them for longer and longer, interleaved with using the strategy which worked best even longer than that.</p><p>Basically, we're cutting things into episodes again, but we're making the episodes longer and longer, so that they have less and less to do with each other, even though they're not really disconnected. This only works because ODPS makes an <i>ergodicity</i> assumption: the environments are assumed to be POMDPs which eventually return to the same states over and over, which kind of gives us an ""effective episode length"" after which the environment basically forgets about what you did earlier.</p><p>In contrast, AIXI makes no ergodicity assumption.</p><p>So far, it seems like we either need (a) some assumption which allows us to match rewards to actions, such as an episodic assumption or ergodicity; or, (b) a more flexible model-learning approach, which separately learns a model and then applies the model to solve credit-assignment.</p><p>Is this a fundamental obstacle?</p><p>I think a better attempt is Schmidhuber's <a href=""https://people.idsia.ch/~juergen/fki198-94.pdf"">On Learning How to Learn Learning Strategies</a>, in which a version of policy search is explored in which parts of the policy-search algorithm are considered part of the policy (ie, modified over time). Specifically, the policy controls the episode boundary; the system is supposed to learn how often to evaluate policies. When a policy is evaluated, its average reward is compared to the lifetime average reward. If it's worse, we roll back the changes and proceed starting with the earlier strategy.</p><p>(Let's pause for a moment and imagine an agent like this. If it goes through a rough period in life, its response is to <i>get amnesia</i>, rolling back all cognitive changes to a point before the rough period began.)</p><p>This approach doesn't require an episodic or ergodic environment. We don't need things to reliably return to specific repeatable experiments. Instead, it only requires that the environment rewards good policies reliably enough that those same policies can set a long enough evaluation window to survive.</p><p>The assumption seems pretty general, but certainly not <i>necessary</i> for rational agents to learn. There are some easy counterexamples where this system behaves abysmally. For example, we can take any environment and modify it by subtracting the time <i>t</i> from the reward, so that reward becomes more and more negative over time. Schmidhuber's agent becomes totally unable to learn in this setting. AIXI would have no problem.</p><p>Unlike the ODPS paper, I consider this to be<i> progress</i> on the AI credit assignment problem. Yet, the resulting agent still seems importantly less rational than model-based frameworks such as AIXI.</p><h2>Actor-Critic</h2><p>Let's go back to talking about things which RL practitioners might really use.</p><p>First, there are some forms of RL which don't require everything to be episodic.</p><p>One is <a href=""http://incompleteideas.net/book/first/ebook/node66.html"">actor-critic learning</a>. The ""actor"" is the policy we are learning. The ""critic"" is a learned estimate of how good things are looking given the history. IE, we learn to estimate the expected value -- not just the next reward, but the total future discounted reward.</p><p>Unlike the reward, the expected value solves the credit assignment for us. Imagine we can see the ""true"" expected value. If we take an action and then the expected value increases, we know the action was good (in expectation). If we take an action and expected value decreases, we know it was bad (in expectation).</p><p>So, actor-critic works by (1) learning to estimate the expected value; (2) using the current estimated expected value to give feedback to learn a policy.</p><p>What I want to point out here is that the critic still has ""model"" flavor. Actor-critic is called ""model-free"" because nothing is explicitly trained to anticipate the sensory observations, or the world-state. However, the critic <i>is learning to predict;</i> it's just that all we need to predict is expected value.</p><h2>Policy Gradient</h2><p>In the comments to the original version of this post, <i>policy gradient</i> methods were mentioned as a type of model-free learning which doesn't require any models even in this loose sense, IE, doesn't require simulable environments or episodes. I was surprised to hear that it doesn't require episodes. (Most <i>descriptions</i> of it do assume episodes, since practically speaking most people use episodes.) So are policy-gradient methods the true ""model-free"" credit assignment algorithm we seek?</p><p>As far as I understand, policy gradient works on two ideas:</p><ul><li>Rather than correctly associating rewards with actions, we can associate a reward with all actions which came before it. Good actions will still come out on top <i>in expectation</i>. The estimate is just a whole lot noisier than it otherwise might be.</li><li>We don't really need a baseline to interpret reward against. I naively thought that when you see a sequence of rewards, you'd be in the dark about whether the sequence was ""good"" or ""bad"", so you wouldn't know how to generate a gradient. (""We earned 100K this quarter; should we punish or reward our CEO?"") It turns out this isn't technically a show-stopper. Considering the actions actually taken, we move in their direction proportion to the reward signal. (""Well, let's just give the CEO some fraction of the 100K; we don't know whether they deserve the bonus, but at least this way we're creating the right incentives."") This might end up reinforcing bad actions, but those tugs in different directions are just noise which should eventually cancel out. When they do, we're left with the signal: the gradient we wanted. So, once again, we see that this just introduces more noise without fundamentally compromising our ability to follow the gradient.</li></ul><p>So one way to understand the policy-gradient theorem is: we can follow the gradient even when we can't calculate the gradient! Even when we sometimes get its direction totally turned around! We only need to ensure we follow it <i>in expectation</i>, which we can do without even knowing which pieces of feedback to think of as a good sign or a bad sign.</p><p>RL people reading this might have a better description of policy-gradient; please let me know if I've said something incorrect.</p><p>Anyway, are we saved? Does this provide a truly assumption-free credit assignment algorithm?</p><p>It obviously assumes linear causality, with future actions never responsible for past rewards. I won't begrudge it that assumption.</p><p>Besides that, I'm somewhat uncertain. The explanations of the policy-gradient theorem I found don't focus on deriving it in the most general setting possible, so I'm left guessing which assumptions are essential. Again, RL people, please let me know if I say something wrong.</p><p>However, it looks to me like it's just as reliant on the ergodicity assumption as the ODPS thing we looked at earlier. For gradient estimates to average out and point us in the right direction, we need to get into the same situation over and over again.</p><p>I'm not saying real life isn't ergodic (quantum randomness suggests it is), but mixing times are so long that you'd reach the heat death of the universe by the time things converge (basically by definition). By that point, it doesn't matter.</p><p>I still want to know if there's something like ""the AIXI of model-free learning""; something which appears as intelligent as AIXI, but not via explicit model-learning.</p><h1>Where Updates Come From</h1><p>Here begins the crazier part of this post. This is all intuitive/conjectural.</p><p>Claim: in order to learn, you need to obtain an ""update""/""gradient"", which is a <i>direction (and magnitude) you can shift in</i> which is more likely than not an improvement.</p><p>Claim: predictive learning gets gradients ""for free"" -- you know that you want to predict things as accurately as you can, so you <i>move in the direction of whatever you see</i>. With Bayesian methods, you increase the weight of hypotheses which would have predicted what you saw; with gradient-based methods, you get a gradient in the direction of what you saw (and away from what you didn't see).</p><p>Claim: if you're learning to act, you do not similarly get gradients ""for free"":</p><ul><li><i>You don't know which actions, or sequences of actions, to assign blame/credit. </i>This is unlike the prediction case, where we always know which predictions were wrong.</li><li><i>You don't know what the alternative feedback would have been if you'd done something different.</i> You only get the feedback for the actions you chose. This is unlike the case for prediction, where we're rewarded for closeness to the truth. Changing outputs to be more like what was actually observed is axiomatically better, so we don't have to guess about the reward of alternative scenarios.</li><li>As a result, <i>you don't know how to adjust your behavior based on the feedback received</i>. Even if you can perfectly match actions to rewards, because we don't know what the alternative rewards would have been, we don't know what to learn: are actions like the one I took good, or bad?</li></ul><p>(As discussed earlier, the policy gradient theorem does actually mitigate these three points, but apparently at the cost of an ergodicity assumption, plus much noisier gradient estimates.)</p><p>Claim: you have to get gradients <i>from a source that already has gradients</i>. Learning-to-act works by splitting up the task into (1) learning to anticipate expected value, and perhaps other things; (2) learning a good policy via the gradients we can get from (1).</p><p>What it means for a learning problem to ""have gradients"" is just that the feedback you get tells you how to learn. Predictive learning problems (supervised or unsupervised) have this; they can just move toward what's observed. Offline problems have this; you can define one big function which you're trying to optimize. Learning to act online doesn't have this, however, because it lacks counterfactuals.</p><h1>The Gradient Gap</h1><p>(I'm going to keep using the terms 'gradient' and 'update' in a more or less interchangeable way here; this is at a level of abstraction where there's not a big distinction.)</p><p>I'm going to call the ""problem"" the gradient gap. I want to call it a problem, even though we know how to ""close the gap"" via predictive learning (whether model-free or model-based). The issue with this solution is only that it doesn't feel elegant. It's weird that you have to run two different backprop updates (or whatever learning procedures you use); one for the predictive component, and another for the policy. It's weird that you can't ""directly"" use feedback to learn to act.</p><p>Why should we be interested in this ""problem""? After all, this is a basic point in decision theory: to maximize utility under uncertainty, you need probability.</p><p>One part of it is that I want to scrap classical (""static"") decision theory and move to a more learning-theoretic (""dynamic"") view. In both AIXI and logical-induction based decision theories, we get a nice learning-theoretic foundation for the epistemics (solomonoff induction/logical induction), but, we tack on a non-learning decision-making unit on top. I have become skeptical of this approach. It puts the learning into a nice little box labeled ""epistemics"" and then tries to make a decision based on the uncertainty which comes out of the box. I think maybe we need to learn to act in a more fundamental fashion.</p><p>A symptom of this, I hypothesize, is that AIXI and logical induction DT don't have very good learning-theoretic properties. [<a href=""https://www.lesswrong.com/posts/5bd75cc58225bf0670375575/the-learning-theoretic-ai-alignment-research-agenda"">AIXI's learning problems</a>; <a href=""https://www.lesswrong.com/posts/5bd75cc58225bf06703753d4/two-major-obstacles-for-logical-inductor-decision-theory"">LIDT's learning problems.</a>] You can't say very much to recommend the policies they learn, except that they're optimal according to the beliefs of the epistemics box -- a fairly trivial statement, given that that's how you decide what action to take in the first place.</p><p>Now, in classical decision theory, there's a nice picture where the need for epistemics emerges nicely from the desire to maximize utility. The <a href=""https://www.lesswrong.com/posts/sZuw6SGfmZHvcAAEP/complete-class-consequentialist-foundations"">complete class theorem</a> starts with radical uncertainty (ie, non-quantitative), and derives probabilities from a willingness to take pareto improvements. That's great! I can tell you why you should have beliefs, on pragmatic grounds! What we seem to have in machine learning is a less nice picture, in which we need epistemics in order to get off the ground, but can't justify the results without circular reliance on epistemics.</p><p>So the gap is a real issue -- it means that we can have nice learning theory when learning to predict, but we lack nice results when learning to act.</p><p>This is the basic problem of credit assignment. Evolving a complex system, you can't determine which parts to give credit to success/failure (to decide what to tweak) without a model. But the model is bound to be a lot of the interesting part! So we run into big problems, because we need ""interesting"" computations in order to evaluate the pragmatic quality/value of computations, but we can't <i>get</i> interesting computations to get ourselves started, so we need to learn...</p><p>Essentially, we seem doomed to run on a stratified credit assignment system, where we have an ""incorruptible"" epistemic system (which we can learn because we get those gradients ""for free""). We then use this to define gradients for the instrumental part.</p><p>A stratified system is dissatisfying, and impractical. First, we'd prefer a more unified view of learning. It's just kind of weird that we need the two parts. Second, there's an obstacle to pragmatic/practical considerations entering into epistemics. We need to focus on predicting important things; we need to control the amount of processing power spent; things in that vein. But (on the two-level view) we can't allow instrumental concerns to contaminate epistemics! We risk corruption! As we saw with bucket-brigade, it's easy for credit assignment systems to allow parasites which destroy learning.</p><p>A more unified credit assignment system would allow those things to be handled naturally, without splitting into two levels; as things stand, any involvement of pragmatic concerns in epistemics risks the viability of the whole system.</p><h1>Tiling Concerns &amp; Full Agency</h1><p>From the perspective of full agency (ie, the negation of <a href=""https://www.lesswrong.com/s/HeYtBkNbEe7wpjc6X"">partial agency</a>), a system which needs a protected epistemic layer sounds suspiciously like a system that can't tile. You look at the world, and you say: ""how can I maximize utility?"" You look at your beliefs, and you say: ""how can I maximize accuracy?"" That's not a consequentialist agent; that's two different consequentialist agents! There can only be one king on the chessboard; you can only serve one master; etc.</p><p>If it turned out we really really need two-level systems to get full agency, this would be a pretty weird situation. ""Agency"" would seem to be only an illusion which can only be maintained by crippling agents and giving them a split-brain architecture where an instrumental task-monkey does all the important stuff while an epistemic overseer supervises.&nbsp;An agent which ""breaks free"" would then free itself of the structure which allowed it to be an agent in the first place.</p><p>On the other hand, from a partial-agency perspective, this kind of architecture could be perfectly natural. IE, if you have a learning scheme from which total agency doesn't naturally emerge, then there isn't any fundamental contradiction in setting up a system like this.</p><h1>Myopia</h1><p>Part of the (potentially crazy) claim here is that having models always gives rise to some form of myopia. Even logical induction, which seems quite unrestrictive, makes LIDT fail problems such as <a href=""https://www.lesswrong.com/posts/q9DbfYfFzkotno9hG/example-decision-theory-problem-agent-simulates-predictor"">ASP</a>, making it myopic according to the second definition of <a href=""https://www.lesswrong.com/s/HeYtBkNbEe7wpjc6X/p/qpZTWb2wvgSt5WQ4H"">my previous post</a>. (We can patch this with <a href=""https://www.lesswrong.com/posts/5bd75cc58225bf067037550c/policy-selection-solves-most-problems"">LI policy selection</a>, but for any particular version of policy selection, we can come up with decision problems for which it is ""not updateless enough"".) You could say it's myopic ""across logical time"", <a href=""https://www.lesswrong.com/posts/dKAJqBDZRMMsaaYo5/in-logical-time-all-games-are-iterated-games"">whatever that means</a>.</p><p>If it were true that ""learning always requires a model"" (in the sense that learning-to-act always requires either learning-to-predict or hard-coded predictions), <i>and</i> if it were true that ""models always give rise to some form of myopia"", then this would confirm my <a href=""https://www.lesswrong.com/s/HeYtBkNbEe7wpjc6X/p/qpZTWb2wvgSt5WQ4H"">conjecture in the previous post</a> (that no learning scheme incentivises full agency).</p><p>This is all pretty out there; I'm not saying I believe this with high probability.</p><h1>Evolution &amp; Evolved Agents</h1><p>Evolution is a counterexample to this view: evolution learns the policy ""directly"" in essentially the way I want. This is possible because evolution ""gets the gradients for free"" just like predictive learning does: the ""gradient"" here is just the actual reproductive success of each genome.</p><p>Unfortunately, we can't just copy this trick. Artificial evolution requires that we decide how to kill off / reproduce things, in the same way that animal breeding requires breeders to decide what they're optimizing for. This puts us back at square one; IE, needing to get our gradient from somewhere else.</p><p>Does this mean the ""gradient gap"" is a problem only for artificial intelligence, not for natural agents? No. If it's true that learning to act requires a 2-level system, then evolved agents would need a 2-level system in order to learn within their lifespan; they can't directly use the gradient from evolution, since it requires them to die.</p><p>Also, note that evolution seems myopic. (This seems complicated, so I don't want to get into pinning down exactly in which senses evolution is myopic here.) So, the case of evolution seems compatible with the idea that any gradients we can actually get are going to incentivize myopic solutions.</p><p>Similar comments apply to <a href=""https://www.gwern.net/Backstop"">markets vs firms</a>.</p>",abramdemski,abramdemski,abramdemski,
mWKzAitSQboSk4Ye4,LW Team Updates - November 2019 (Subscriptions & More),lw-team-updates-november-2019-subscriptions-and-more,https://www.lesswrong.com/posts/mWKzAitSQboSk4Ye4/lw-team-updates-november-2019-subscriptions-and-more,2019-11-08T02:39:29.498Z,28,13,4,False,False,,"<p>This is the <a href=""https://www.lesswrong.com/s/GTpv3mjKqFot9pxT3"">once-monthly updates post</a> for LessWrong team activities and announcements.&nbsp;</p><h2>Summary</h2><p>This month we launched 1) a complete subscriptions overhaul, 2) bookmarks, 3) pingbacks (experimental opt-in only) [<a href=""https://www.lesswrong.com/s/GTpv3mjKqFot9pxT3/p/FvTc37vCGZQZdMWoz"">full announcement of those features here</a>]. Soon we'll release our new editor, <i>LessWrong Docs </i>into beta. Lastly, we made a post explaining why we spent Q3 optimizing for karma and how that went.</p><h2>Recent Features</h2><p><strong>Subscriptions Overhaul</strong></p><p>At long last we have released our subscriptions overhaul. You can now subscribe to precisely what you want to see (users, posts, comments, events) and get notifications on-site and/or by email batched at a frequency of your choosing.</p><figure class=""image""><img src=""https://i.imgur.com/nmg65cO.png""><figcaption><i>Subscription options for a post</i></figcaption></figure><p>See the <a href=""https://www.lesswrong.com/posts/FvTc37vCGZQZdMWoz/site-update-subscriptions-bookmarks-and-pingbacks#How_to_Subscribe"">announcement post</a> for complete documentation.</p><p><strong>Bookmarks</strong></p><p>It is now possible to bookmark posts and access these on their <a>own page</a> and/or as a list at the top of your homepage. Use the triple-dot drop down menu to bookmark any post.</p><figure class=""image""><img src=""https://i.imgur.com/3EgiLcX.png""><figcaption><i>Appearance of the Bookmarks page</i></figcaption></figure><p>Use the gear icon in the Recommendations section of the homepage to configure. Full documentation <a href=""https://www.lesswrong.com/posts/FvTc37vCGZQZdMWoz/site-update-subscriptions-bookmarks-and-pingbacks#Bookmarks"">here</a>.</p><p><strong>Pingbacks [Experimental Opt-In]</strong></p><p>When a post has been linked to by another post on LessWrong, the pingback feature will list any referencing posts at the bottom of the post page. ""Pingback"" is equivalent to ""cited by"".</p><p>When pingbacks are enabled, they are displayed at the bottom of post pages. Currently not all historical URL formats are supported and so many pingback lists are incomplete. This will be fixed before full-release.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/v1572323368/Screen_Shot_2019-10-28_at_9.29.07_PM_mdrepv.png""><figcaption><i>Pingbacks displayed at the bottom of a post</i></figcaption></figure><p>To view pingbacks, you must be opted into experimental features. This can be done in your <a href=""https://www.lesswrong.com/account"">account settings</a>.</p><h2>Upcoming Features</h2><p><strong>LessWrong Docs</strong></p><p>We've been promising the new editor for a few months now and it's getting closer and closer to beta release. This very announcement was written in it.&nbsp;</p><figure class=""image""><img src=""https://i.imgur.com/t0N2vQy.png""><figcaption><i>Look of the new editor, LessWrong Docs</i></figcaption></figure><p>We hope the new editor will provide an overall improved experience from Draft-JS, but more importantly, it introduces many of the features people are used to from Google Docs such as collaborative editing and inline commenting.</p><figure class=""image""><img src=""https://i.imgur.com/V8JRv8l.png""></figure><p>Expect to hear about this once we've ironed out a few more bugs.</p><p><strong>Tagging</strong></p><p>We're working on a new tagging system for posts. The idea is simple yet requires careful design to ensure the relevance of tags and display them in useful ways.</p><p>I'm hoping the tagging system will provide a new way to access LessWrong's large corpus of historical posts and help people find posts of interest and relevance. We are overall working to make LessWrong to be more than just ""news site"" where people read the latest posts and last month's content gets forgotten. Our <a href=""https://www.lesswrong.com/s/GTpv3mjKqFot9pxT3/p/PfceWjEqdRDvGkKZ8"">Recommendations features</a> were a step in this direction too, as is the <a href=""https://www.lesswrong.com/library"">library page</a>.</p><p>The tagging system will likely be under development for a while and might be released early in 2020.</p><h2>General Updates</h2><p><strong>Q3 was metric quarter: we optimized for karma</strong></p><p>As mentioned last month, we spent Q3 optimizing for a single metric based on karma given out. I've written a post describing this experiment, why we did it and how it went. <a href=""https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma"">Read the post here</a>.</p><figure class=""image""><img src=""https://lh3.googleusercontent.com/o1v3pFyyXrZ_17Kyo7N3j-sg5KBld5khUwmxHyambvYPPaWFlxOi1DSvhSfSzNPk_MbocC7MCvc89Hr97ilY1Fz6ag6XrgbVXbOXHE4HxP7QYoz5frGR1RhPQiogsCbwUJKg6W0V""><figcaption>Weekly Karma Metric Values + Target Growth Lines</figcaption></figure><p><strong>Curated Emails are working again!</strong></p><p>Last month we noted that we were having some trouble with Curated emails. Those are now working again.</p><h2>Ways to Follow LessWrong</h2><p>We've been expanding the number of ways people can consume LessWrong content beyond the site. These now include:</p><ul><li><a href=""https://www.lesswrong.com/faq#Can_I_subscribe_by_email__What_can_I_subscribe_to_"">Email</a> (now with more more subscription options!)</li><li><a href=""https://www.lesswrong.com/faq#Curated"">RSS</a></li><li><a href=""https://www.facebook.com/lesswrong2/"">Facebook</a></li><li><a href=""https://twitter.com/lesswrong"">Twitter: @lesswrong</a></li><li><a href=""https://www.linkedin.com/company/28451439/"">LinkedIn</a></li></ul><p>The Facebook, Twitter, and LinkedIn accounts receive regular updates M/W/F of a mix of curated posts, top all-time content, and outstanding new content.</p><h2>Feedback &amp; Support</h2><p>The team can be reached for feedback and support via:</p><ul><li>Comment on this post</li><li>Intercom (icon in the bottom right, you might have to edit your <a href=""http://www.lesswrong.com/account"">user settings</a>)</li><li>Email us at hello@lesswrong.com or support@lesswrong.com</li><li>Ask a question on <a href=""http://www.lesswrong.com/questions"">www.lesswrong.com/questions</a></li><li>Message us on our <a href=""https://www.facebook.com/lesswrong2/"">Facebook page</a>.</li></ul>",Ruby,ruby,Ruby,
wCnPDvdcc2x4tNFdx,To Be Decided #2,to-be-decided-2,https://www.lesswrong.com/posts/wCnPDvdcc2x4tNFdx/to-be-decided-2,2019-11-08T02:35:42.084Z,5,3,0,False,False,,"<p><em>TBD is a quarterly-ish newsletter about deploying knowledge for impact, learning at scale, and making more thoughtful choices for ourselves and our organizations. This is the second issue, which was originally published in June 2019. Enjoy!&#xA0; --Ian</em>                </p><h1><strong>An Introduction to Decision Modeling</strong></h1><p>Decision-making is life. Over time, our decisions carve an identity for ourselves and  our organizations, and it is our decisions, more than anything else, that determine how we are remembered after we&#x2019;re gone. Despite their importance, though, we barely pay attention to most of the decisions we make. Biology has programmed in us a powerful instinct to make decisions using our intuitions rather than our conscious selves whenever possible. There are good reasons for this; if we had to think about every little decision we made, we&#x2019;d never get anything done. But complex decisions require us to compare the likelihood and desirability of many possible futures on multiple, disparate, and often conflicting  criteria, something our intuitions just aren&#x2019;t naturally equipped to do.</p><p>Thankfully, there is a better way. The secret to resolving complex, risky dilemmas with justified ease and confidence is to <u><a href=""https://medium.com/@iandavidmoss/an-introduction-to-decision-modeling-3e50581e8a73?sk=b99e02da9ea03346bd43dde8b5dbbfe5"">model your decisions explicitly</a></u>. At its best, modeling our decisions can help us make the very human exercise of decision-making not only more likely to lead to the outcomes we want, but more instinctively satisfying as well.</p><p>(<u><a href=""https://medium.com/@iandavidmoss/an-introduction-to-decision-modeling-3e50581e8a73?sk=b99e02da9ea03346bd43dde8b5dbbfe5"">Keep reading</a></u>)     </p><h1><strong>What I&apos;ve Been Reading</strong></h1><p><strong>Most Funders Admit Their Own Evaluations Are Not Useful</strong><br>I really wish that headline was an exaggeration, but it&apos;s not much of one. In 2015, the Center for Evaluation Innovation and the Center for Effective Philanthropy surveyed   evaluation and program executives at 127 US and Canadian foundations with $10 million or more in annual giving. The resulting report, &quot;Benchmarking Foundation Evaluation Practices,&quot; contains startling revelations about how little evaluation reports are used. Most remarkably, more than three-quarters of respondents reported that they have a hard time commissioning  evaluations that yield meaningful insights for the field, grantees, or even their own colleagues!<br> (<u><a href=""https://twitter.com/iandavidmoss/status/1113554882781433857"">Twitter thread</a></u>)</p><p><strong>Our Cognitive Biases Can Tell Us a Lot About the Meaning of Life</strong> You probably know Daniel Kahneman&apos;s classic volume <em>Thinking, Fast and Slow </em>as a comprehensive catalogue of cognitive biases and errors in judgment. But it&apos;s more than that: it&apos;s also about the meaning of life. In the  section entitled &quot;Two Selves,&quot; Kahneman reveals that we remember pain  and pleasure differently from how we experience it. You might assume that the reality of our experiences is what matters to us. But in fact that&apos;s not true. What we really care about is our <em>memories</em> of our experiences, and the story those memories cause us to tell ourselves and others about our lives. In other words, narratives don&apos;t just matter, narratives are everything. This might just seem like a curious artefact of the research, but it has enormous philosophical and practical implications for social sector leaders. (<u><a href=""https://twitter.com/iandavidmoss/status/1129461590875676672"">Twitter thread</a></u>)</p><h1><strong>Stuff You Should Know About</strong></h1><ul><li>If  you&apos;ve ever found yourself looking for examples of real-life cost-benefit and social return on investment (SROI) analyses, the <u><a href=""https://socialvalueint.org/resources/report-database/"">Social Value International</a></u> network has your back. Their UK chapter&apos;s <u><a href=""http://www.socialvalueuk.org/report-database/"">database</a></u> includes more than 800 publications ranging from &quot;Cost Benefit Analysis of Early Childhood Intervention&quot; to &quot;The Social Value of Community Pubs.&quot;</li><li>Have you ever been frustrated with a reporter&apos;s treatment of a research study that seemed to stretch the conclusions much farther than warranted? Well, according to research published in 2014, &quot;<u><a href=""https://www.theguardian.com/science/blog/2014/dec/10/science-health-news-hype-press-releases-universities"">most exaggeration in health-related science news is already present in the press releases issued by universities</a></u>.&quot; Intrigued by this result, the team got back together for an unprecedented randomized controlled trial of real-life science communication strategies employed by university press offices, which found that, contrary to many people&apos;s assumptions, toning down the hype around research findings doesn&apos;t necessarily lead to less interest from journalists. As a bonus, in this <u><a href=""https://twitter.com/chrisdc77/status/1130221873848102914"">bonkers 96-part Twitter thread</a></u>, co-author Chris Chambers details the amazing back story (and back-stabbing) behind the latest study.</li><li>Speaking of misrepresenting research, I&apos;ve really been enjoying Vox.com&apos;s <u><a href=""https://www.vox.com/future-perfect"">Future Perfect project</a></u> highlighting effective altruism and related topics. Staff writer Kelsey Piper has been covering a regular research integrity beat, and recently she wrote about two remarkable instances in which well-known nonfiction authors have been caught in the act of <u><a href=""https://www.vox.com/future-perfect/2019/6/4/18650969/married-women-miserable-fake-paul-dolan-happiness"">badly misunderstanding key elements of the research underlying their books</a></u>. Piper&apos;s takeaway? &quot;Don&#x2019;t trust shocking claims with a single source,  even if they&#x2019;re from a well-regarded expert. It&#x2019;s all too easy to misread a study, and all too easy for those errors to make it all the way to print.&quot;</li></ul><h1><strong>That&apos;s all for now!</strong></h1><p>If you enjoyed this edition of TBD, please consider forwarding it to a friend. It&apos;s easy to sign up <u><a href=""http://eepurl.com/gjYBlD"">here</a></u>. See you next time!</p>",Ian David Moss,ian-david-moss,Ian David Moss,
WnB6whsARH6NuJDKx,[Team Update] Why we spent Q3 optimizing for karma,team-update-why-we-spent-q3-optimizing-for-karma,https://www.lesswrong.com/posts/WnB6whsARH6NuJDKx/team-update-why-we-spent-q3-optimizing-for-karma,2019-11-07T23:39:55.274Z,70,24,27,False,False,,"<p>In Q3 of 2019, the LessWrong team picked the growth of a single metric as our only goal. For the duration of this quarter, the overwhelming consideration in our decision-making what would most increase the target metric.</p><h1>Why target a simple, imperfect metric?</h1><p>The LessWrong team pursues a mixture of overlapping long-term goals, e.g. building <a href=""https://www.lesswrong.com/posts/bJ2haLkcGeLtTWaD5/welcome-to-lesswrong"">a place where people train and apply rationality</a>, building <a href=""https://www.lesswrong.com/posts/nBcvEFXw4Yoz7rSDk/lesswrong-2-0-community-culture-and-intellectual-progress"">a community and culture with good epistemics</a>, and <a href=""https://www.lesswrong.com/posts/ZvjYRmkTfWxhTXCaT/lesswrong-2-0-technology-platform-for-intellectual-progress"">building technologies which drive intellectual progress on important problems</a>.</p><p>It’s challenging to track progress on these goals. They’re broad, difficult to measure, we don’t have complete agreement on them, and they change very slowly providing an overall poor feedback loop. If there’s a robust measure of “intellectual progress” or “<a href=""https://www.lesswrong.com/posts/5K7CMa6dEL7TN7sae/3-levels-of-rationality-verification"">rationality skills learnt</a>” which doesn’t break down when being optimized for, we haven’t figure them out yet. We’re generally left pursuing hard to detect things and relying on our models to know that we’re making progress.</p><p>Though this will probably continue to be the overall picture for us, we decided that for three months it would be a good exercise for us to attempt maximizing a metric. Given that it’s only three months, it seem relatively safe [1] to maximize a simple metric which doesn’t perfectly capture everything we care about. And doing so might have the following benefits:</p><ul><li>It would test our ability to get concrete, visible results on purpose.</li><li>It would teach us to operate with a stronger empirical feedback loop.</li><li>It would test how easily we can drive raw growth [2], i.e. see what rate of growth we get for our effort.</li><li>The need to hit a clear target would introduce a degree or urgency and pressure we are typically lacking. This pressure might prompt some novel creativity.</li><li>Targeting a metric is what YC advises their startups and it seems worth following that school of thought and philosophy for a time (see excerpts below).</li></ul><p>So we decided to pick a metric and optimize for it throughout Q3.</p><p>[1] We had approval for this plan from our BDFL/admin, <a href=""https://www.lesswrong.com/users/vaniver"">Vaniver.</a> For extra safety, we shared out plans with trusted-user <a href=""https://www.lesswrong.com/users/zvi"">Zvi</a> and told him we'd undo anything on the site he thought was problematic. We ran the plan by others too, but stopped short of making a general announcement lest this confound the exercise.</p><p>[2] Historically the team has been hesitant to pursue growth strategies out of fear that we could grow the site in ways which make it worse, e.g. eroding the culture while Goodharting on bad metrics. Intentionally pursuing growth for a bit is a way to test the likelihood of accidentally growing the site in undesirable ways.</p><h1>Choosing a metric</h1><p>The team brainstormed over fifty metrics with some being more likely candidates than others. Top contenders were number of posts with 50+ karma/week, number of weekly logged-in users, and number of people reading the Sequences.&nbsp;</p><p>(We tried to be maximally creative however and the list also included <a href=""https://mealsquares.com/"">MealSquares sold</a>, <a href=""https://80000hours.org/2015/07/new-definition-of-a-significant-plan-change/"">impact-adjusted plan changes</a>, and LessWrong t-shirts worn. Maybe we'll do one of those next time)</p><p>Ultimately, the team decided to target a metric derived from the amount of karma awarded via votes on posts and comments. Karma is a very broad metric and the amount given out can be increased via multiple methods, all of which we naively approve of increasing, e.g. increasing the number of posts, number of comments, and number of people reading posts and voting. This means that by targeting the amount of karma given out, we’re incentivizing ourselves to increase multiple valuable other “sub-metrics”.</p><h2>Design of the metric&nbsp;</h2><p>We did not target the raw amount of karma given out but instead a slightly modified metric:</p><ol><li>Remove all votes made by LessWrong team members</li><li>Multiply the value of all downvotes by 4x</li><li>Aggregate karma to individual posts/comments and raise the magnitude to the power of 1.2</li></ol><p>Clause #2 was chosen to disincentivize the creation of demon threads which otherwise might produce a lot of karma in their protracted, heated exchanges.&nbsp;</p><p>Clause #3 was chosen to heighten to reward/punishment for especially good or especially bad content. We’re inclined to think that single 100-karma post is worth more than four 25-karma posts and the exponentiation reflects this. (For comparison: 25^1.2 is 47.6, 100^1.2 is 251.2. So in our metric, one 100-karma post was worth about 30% more than four 25-karma posts).&nbsp;</p><p>In developing the metric, we experimented with a few different parameters and and checked them against our gut sense of how valuable different posts were.</p><p>[There’s some additional complexity in the computation in that the effect of each vote is calculated as the difference in the karma metric of a post/comment before and after the vote. This is necessary to compute changes in the metric nicely over time but makes no difference if you compute the metric for all time all at once.]</p><p>Following <a href=""http://www.paulgraham.com/growth.html"">Paul Graham’s advice</a>, we targeted 7% growth in this metric per week throughout Q3. This is equivalent to increasing the metric by 2.4x. Since PG’s advice was a major influence on us here, I’ll include a few excerpts [emphasis added]:</p><blockquote><p>A good growth rate during YC is 5-7% a week. If you can hit 10% a week you're doing exceptionally well. If you can only manage 1%, it's a sign you haven't yet figured out what you're doing.</p><p>...</p></blockquote><blockquote><p>In theory this sort of hill-climbing could get a startup into trouble. They could end up on a local maximum. But in practice that never happens. <strong>Having to hit a growth number every week forces founders to act, and acting versus not acting is the high bit of succeeding.</strong> Nine times out of ten, sitting around strategizing is just a form of procrastination. Whereas founders' intuitions about which hill to climb are usually better than they realize. Plus the maxima in the space of startup ideas are not spiky and isolated. Most fairly good ideas are adjacent to even better ones.</p><p>...</p></blockquote><blockquote><p>The fascinating thing about optimizing for growth is that it can actually discover startup ideas. <strong>You can use the need for growth as a form of evolutionary pressure.</strong> If you start out with some initial plan and modify it as necessary to keep hitting, say, 10% weekly growth, you may end up with a quite different company than you meant to start. But anything that grows consistently at 10% a week is almost certainly a better idea than you started with.</p></blockquote><h2>What we did to raise the metric</h2><p>At the highest level, we wanted to increase the number of posts, increase the number of comments, and increase the number of people viewing and voting. Major projects we worked on towards this included:</p><ul><li>The launch of Shortform<ul><li>We’d been experiencing demand for Shortform and metric quarter seemed like a good time to introduce a new section of the site with lower cost to entry.</li></ul></li><li>Subscriptions<ul><li>We failed to launch this during metric quarter, but we envisioned that subscriptions would increase the content people read and vote on.</li></ul></li><li>Reaching out to authors<ul><li>We reached out to a number of people who currently or previously have written top content for LessWrong to find out how we could help them write more.</li></ul></li><li>Setting up automatic cross-posting for top authors<ul><li>For authors whose material is a good fit for LessWrong, we reached out to them and asked about having their posts automatically cross-posted to LessWrong.</li></ul></li><li>Removing login 90-day log-in expiry so that people stay signed in and able to vote/comment/post.</li><li>Making it easier to create an account or sign-in.</li><li>The LessLong Launch party.<ul><li>We hosted a large party in Berkeley both to push the launch of Shortform but also generally to signal LessWrong’s activity and happeningness.</li></ul></li></ul><p>Other activities in this period which contributed were:</p><ul><li>Petrov Day</li><li>MIRI Summer Fellows Program</li></ul><p>These projects contributed significantly to the metric, but we would have probably done counterfactually even if we weren’t targeting the metric. (in truth the same can be said for everything else we did).</p><p>Targeting the metric did cause us to delay some other projects. For instance, we deprioritized reducing technical debt and new analytics infrastructure this quarter.</p><h1>How did we do?</h1><p><strong>Summary</strong></p><p>While our target was 7%/week growth, we achieved growth equivalent to 2%/week. As far as hitting the stated target went, we unambiguously failed.&nbsp;</p><p>In retrospect, 7% was probably a mistaken target. We perhaps should have been comparing ourselves to LessWrong's historical growth rates, which we in fact we did exceed. Our actual growth in this period of 2%/week over 3-4 months is higher than LessWrong's typical rate of growth throughout most of its history which was at best equivalent 0.5%-1%. Compounded over three months, that's the difference between 15% and 29% growth.</p><p>(LessWrong grew between 2009 and 2012 &nbsp;at around 0.5-1.0%/week and then began declining until 2017 when the LW2.0 project was started.)</p><p>However, the 7% target was probably still a good choice when we began. It was conceivably achievable and worth testing. For one thing, historically LessWrong didn't have a full-time team in the past who were deliberately working full-time to drive growth. Given the resources we were bringing to bear, it was worth testing if we could dramatically outperform the more ""natural"" historical growth rates. We have learnt that the answer, unfortunately, is ""not obviously or easily.""</p><p>Also, notwithstanding the failure to hit the target, the exercise still helped with our goals of becoming more empirical, using a stronger feedback loop, being more creative, feeling more urgency, testing hypotheses about growth, and generally applying and testing more of our models against reality. I think the experience has nudged our decision-making and processes in a positive direction even as we return to pursuing long-term, slow-feedback, difficult-to-measure objectives.</p><p><strong>Detailed Analysis</strong></p><figure class=""image""><img src=""https://lh3.googleusercontent.com/o1v3pFyyXrZ_17Kyo7N3j-sg5KBld5khUwmxHyambvYPPaWFlxOi1DSvhSfSzNPk_MbocC7MCvc89Hr97ilY1Fz6ag6XrgbVXbOXHE4HxP7QYoz5frGR1RhPQiogsCbwUJKg6W0V""><figcaption>Weekly Karma Metric Values + Target Growth Lines</figcaption></figure><p>The first graph (above) here shows the karma metric each week and displays clearly that the value does not go up monotonically, but rather fluctuates a fair bit, usually related to the occurrence of events like Petrov Day, Alignment Writing Day, or the publication of controversial posts. This is normal for all the metrics, yet makes it difficult to discern overall trends.</p><p>We can apply a 4-week moving average filter in order to smooth the graph and see the trend a little better.</p><figure class=""image""><img src=""https://i.imgur.com/PPtZiM9.png""><figcaption>Weekly Karma Metric Values with 4-week Moving Average smoothing</figcaption></figure><p>The latter graph shows the overall increase since July, i.e., the beginning of our ""metric quarter."" However, smaller differences at the weekly level become larger differences at the monthly and quarterly level.</p><figure class=""image""><img src=""https://i.imgur.com/lfyHLfU.png""><figcaption>Karma Metric Aggregated Quarterly</figcaption></figure><figure class=""image""><img src=""https://i.imgur.com/y8tz1Iy.png""><figcaption>Karma Metric Aggregated Monthly</figcaption></figure><p>The value of the karma metric in Q3 was 39% higher than than in Q2, 71k vs 51k. This is the largest growth since when the LW2 project began in late 2017 and when it first launched in 2018.</p><p>In the summary, I stated that this growth compares favorable to LessWrong's historical growth rates. Due to changes in how karma is computed introduced with LW2, we can't compare our karma metric backwards in time. Fortunately, the number of votes is a good proxy.</p><figure class=""image""><img src=""https://lh5.googleusercontent.com/qMlB4cdp-5QpgGNnTvAAbzD0EEw90unijFQTylaRLKSYbvQRY1tN3UG7Imlg64T7_Y3aoKHz5Ezdp_JOTHnGj_JHQVreV-KwgFCLMiSn5ZAcp6Ij7qJ3hIa9iSRJGtGHEd4VK5FF""><figcaption>Number of Votes (Weekly)&nbsp;</figcaption></figure><p>In absolute terms, LW2.0 has some catching up to do; growth-wise we compare nicely. The number of votes on LessWrong grew dramatically between 2009 and 2012 as can be seen in the graph. Growth in votes was 87% in 2009, 41% in 2011, 24% in 2012 and 92% in 2018 [3] . Those are the growth numbers for the entire years and correspond to average weekly growth rates of 1.2%, 0.7%, 0.4%, and 1.3%.</p><p>In comparison to that, growing votes by 40% in just one quarter (= 2.5%/week) is pretty good. The real question is whether this growth will be sustained. Yet so far so good. October saw the highest level of the karma metric so far in 2019.</p><p>We didn't hit 7%, but it's heartening that seemingly we managed to do something.</p><p>[3] Other years saw negative growth ranging between -20% and -65%.</p><h2>What contributed to our performance?</h2><p>As above, Q3 was 39% higher on the target metric relative to Q2, going from 51k to 71k. We can examine the contribution of our different activities to this. Where did the extra 20k come from?</p><p><strong>Shortform</strong></p><p>Karma granted to shortform posts and comments amounted to 5.5k KM or 7.7% of the total score for Q3 and 25% of the difference between Q2 and Q3. This is not fully counterfactual since we can assume Shortform cannibalized some activity from elsewhere on the site, however there has definitely been net growth.</p><figure class=""image""><img src=""https://lh6.googleusercontent.com/HeMxXtscg8TbdC3_MdV-JZS2eSzZntAq2vkl-_YvSy0LUiNPNnN32WgZR9FQtk7kspcyWD9VU65sfDa0rWAeMu0c4L49n13tyTDqwJqYBwcyincJr3RmPOfXzKwU8v5JE25avJw3""></figure><p>We see that the total number of comments (including all Shortform activity and all responses to questions) grew since July due to the introduction of Shortform while the number of regular comments did not shrink.</p><p><strong>Petrov Day</strong></p><p>Our Petrov Day commemoration had an outsized impact with the two posts plus their comments (<a href=""http://www.lesswrong.com/posts/vvzfFcbmKgEsDBRHh"">1</a>, <a href=""http://www.lesswrong.com/posts/krgNxiooRfnP9L4ZD"">2</a>) together generating 2.4k KM, or 3.3% of total karma for Q3 and 12% of the difference from Q2 to Q3.&nbsp;</p><p>It was a very good return on time spent by the team.</p><p><strong>Author Outreach</strong></p><p>In the hope of causing there to be more great content, we reached out to a number of authors to see what we could do get them posting. A lower bound on the KM we achieved this way is 2.7k, or 3.5% of total / 13.5% of difference.</p><p><strong>AI Alignment Writing Day</strong></p><p>The <a href=""https://www.lesswrong.com/s/YuTinYEzsyHmPoocw"">posts from MSFP writing day</a> generated 3.0k KM, or 4.2% of total / 15% of the difference. However this is definitely something we would have done anyway and is not obviously something we should count as a special intentional activity to drive karma.</p><p><strong>Novum Organum</strong></p><p>The posting of the <a href=""https://www.lesswrong.com/s/GTEay24Lxm3xoE4hy"">Novum Organum sequence</a> was motivated by having more content to get more karma. The fives posts posted in Q3 netted 0.3k KM, or 0.4% of total / 1.5% of difference. Not that impactful on the metric.</p><p><strong>Removing Login Expiry</strong></p><p>Vulcan, the framework upon which LW2.0 was built, automatically signed people out after 90 days. This would require them log-in again before voting, commenting, or posting. We removed this and the number of logged-in users rose for several months going from 600 logged-in users/week to over 800 logged-in users/week. This seems to have flowed onto the number of unique people voting each week.</p><p><strong>Making Login Easier</strong></p><p>The more people logged-in, the more people who can vote, comment, and post. We improved the login popup and added more prompts for login to the site. There was no large or definite change in the rate of logins after this.</p><p><strong>LessLong (Shortform) Launch Party</strong></p><p>It’s unclear whether this party drove much immediate activity on LessWrong in Q3. We hosted this primarily off the model that it would be good to do something that made LessWrong seem really alive.</p><p><strong>Subscriptions &amp; LessWrong Docs (our new editor)</strong></p><p>Though we worked on subscriptions and the new editor throughout Q3, our failure to release these means that they naturally didn’t generate any karma in Q3. Planning fallacy? (<a href=""https://www.lesswrong.com/posts/FvTc37vCGZQZdMWoz/site-update-subscriptions-bookmarks-and-pingbacks"">Subscriptions overhaul is now out</a>, new editor is nearing beta release.)</p><h2>Overall, how well did we accomplish our goals for this exercise?</h2><p>Above I listed multiple reasons it would be a good idea to target a metric for a quarter, and regardless of well we maximized the metric, we can still ask if we achieved the goals one-level up.</p><blockquote><p>It would test our ability to get concrete, visible results on purpose.</p><p>It would teach us to operate with a stronger empirical feedback loop.</p></blockquote><p>I think the exercise helped along this dimension.&nbsp;</p><ul><li>The metric target had the team [4] everyday looking at our dashboard and regularly asking questions about the impact of different posts.</li><li>We were forced to make plans based on the short-term predictions of our models. This enabled us to learn where we learnt where we wrong.<ul><li>For example, I overestimate the amount of KM generated by Novum Organum and underestimated that from Petrov Day.</li></ul></li><li>Even after the end of Metric Quarter, team members want to continue to monitor the numbers and include these as an input to our decision-making.</li></ul><p>[4] With the exception of Ben Pace who was in the Europe for most of the period.</p><blockquote><p>It would test how easily we can drive raw growth [1], i.e. see what rate of growth we get for our effort.</p></blockquote><p>By putting almost all of our effort into growth for three months, we were definitely able to make the metric jump up some. This was most salient with time-bound events like specific high-engagement posts or events like Petrov Day, yet seems to be true of long-term features like Shortform too (however Shortform is gotten a little bit quiet lately - I'll be looking into that).</p><p>At the same time, getting growth was not super easy. We're unlikely to 10x the site unless we try quite hard for some time. Which causes me to conclude that it's unlikely that we ought to fear growth: things probably won't happen so quickly that we'll be unable to react. My personal leaning is that should always be trying to grow at least a little bit, if only to keep from shrinking.&nbsp;</p><blockquote><p>The need to hit a clear target would introduce a degree or urgency and pressure we are typically lacking.</p></blockquote><p>This effect was real. We definitely experienced sitting around, looking at the metric, and thinking how are we going to make it up go up <i>this week</i>? Unfortunately, this effect flagged<i> </i>a little after the first month when some of us became pessimistic about maintaining the 7% target. I think if the target was one where it continued to seem like had a shot, we'd have continued to feel more pressure to not fall below it. Overall though, we did keep trying to hit it then there.</p><p>I found myself working harder and longer of projects I enjoy less but thought would be more impactful for the metric. This makes me wonder about how much my usual slow-feedback, less-constrained activities is decided by pleasantness of the activities. It feels like a wake-up call to really be asking myself about what actually matters all the time.</p><h2>Finale Take-aways</h2><p>We're back to our more usual planning style where we're optimizing for long-term improvement of difficult-to-measure quantities, but I think we're retaining something of the empirical spirit of trying to make predictions about the results of our actions and comparing this to what actually happens.</p>",Ruby,ruby,Ruby,
XyNv4KDCgadpuCEps,SSC Hangout - New Delhi,ssc-hangout-new-delhi,https://www.lesswrong.com/events/XyNv4KDCgadpuCEps/ssc-hangout-new-delhi,2019-11-07T23:36:27.496Z,1,1,0,False,False,,,Volor,volor,Volor,
rDd27wvEJWXinX52L,Social Meetup TLV,social-meetup-tlv,https://www.lesswrong.com/events/rDd27wvEJWXinX52L/social-meetup-tlv,2019-11-07T23:36:15.533Z,1,1,0,False,False,,"<p>A meetup for rationalish people &amp; people who like talking to rationalish people to casually chat, have beers and snacks together.</p>",daniel-davis,daniel-davis,Daniel Davis,
jsooAMxvcW9F52sJM,"New evidence on popular perception of ""AI"" risk",new-evidence-on-popular-perception-of-ai-risk,https://www.lesswrong.com/posts/jsooAMxvcW9F52sJM/new-evidence-on-popular-perception-of-ai-risk,2019-11-07T23:36:08.183Z,12,9,0,False,False,,"<p>The Mozilla Foundation recently conducted a survey about AI perception.  I participated after receiving an email invitation; I don't know if they recruited elsewhere.  They just released a writeup of the results today, which can be found <a href=""https://foundation.mozilla.org/en/blog/we-asked-people-around-the-world-how-they-feel-about-artificial-intelligence-heres-what-we-learned/?utm_source=email&amp;utm_medium=email&amp;utm_campaign=2019engagement-en&amp;utm_content=aisurveyreport&amp;utm_term=5174656"">here</a>.</p><p>Mozilla seems to take a broad view of ""AI"", with a lot of weight given to current and near-term issues and less to potential fate-of-humanity issues.  This is, of course, a different perspective from many in the LW crowd.</p><p>The popular perception is nonetheless potentially relevant to AI safety because it may represent the perception of some AI capabilities researchers.  It may also be relevant to predicting political intervention in AI research.</p><p>Highlights:</p><ul><li>51k sample size, 67k including partial submissions (see pdf linked from writeup)</li><li>overall, respondents were optimistic (i.e. not especially worried about risks)</li><li>most optimistic demographics were 19-24 years old, male, South Americans</li><li>only 10% self-reported being ""well-educated"" about AI, only 4% unfamiliar with term ""AI""</li><li>respondents generally interested in learning more about AI</li></ul><p>From link:  </p><p>""24% of respondents said AI will make our lives better. 41% of  respondents think AI will make our lives both better and worse. Only 10%  of respondents think AI will only make our lives worse""</p><p>"" Men (27%) are almost twice as optimistic as women (14%) that AI will  make our lives better. Nearly half of South Americans (46%) are  optimistic that AI is going to make their world better, making them the  most positive region in the world. And young people 19 - 24 years old  (35%) were the most likely age group to say AI will make the world  better. Only 5% of this age group said they thought AI would make the  world worse. ""</p><ul><li>""Respondents aged 19 - 44 were most likely to be “very interested” in learning more about AI (52%).</li><li>Respondents 65 and over were most likely to say they are somewhat interested in learning more about AI (64%)</li><li>South Americans (61%) and Africans (63%) said they were most interested in learning more about AI.""</li></ul>",eg,eg,eg,
ozLbqKAWBwY4Ebk7K,Self policing for self doubt,self-policing-for-self-doubt,https://www.lesswrong.com/posts/ozLbqKAWBwY4Ebk7K/self-policing-for-self-doubt,2019-11-07T23:10:01.683Z,36,11,3,False,False,,"<p>Sometimes it seems consequentially correct to do things that would also be good for you, if you were selfish. For instance, to save your money instead of giving it away this year, or to get yourself a really nice house that you expect will pay off pragmatically while also being delightful to live in. </p>
<p>Some people are hesitant to do such things, and prefer for instance to keep a habit of donating every year, or err toward sparse accommodation more than seems optimal on the object level.  I think because if their behavior is indistinguishable from selfishness, it is hard for them to be sure themselves that they aren’t drifting into selfishness. Not that selfishness would be bad if the optimal behavior was in fact the selfish one, but the worry is that if a selfishness-identical conclusion will bring them great personal gains, then they will tend toward concluding it even if they should not have.</p>
<p>This all makes sense, but there is something about it that I don’t like. It seems good to be able be coherent and curious and strategic and to believe in yourself and what you are doing in ways that I think this is at odds with. For instance, under this kind of arrangement you don’t get to have a solid position on ‘is this house worth having?’. You have your object level reasoning, and then not even a meta-level reason to adjust it, but a meta-level reason to distrust your whole thinking process, which leaves you in the vague epistemic state of not allowed to have certain conclusions on the house at all, or allowed to have them but not act on them. And having views but not acting on them is a weird state, because you are knowingly doing what is worse for the broader world, out of misalignment with yourself. And all this is to fend off the possibility that your motives are actually bad, or will become bad. I kind of want to say, ‘if your motives are bad, maybe you should just go and do something bad instead of rigging up some complicated process to thwart yourself’, but presumably there is some complicated relationship between bad and good parts of you that are trying to negotiate some kind of arrangement here. And maybe that is the way it must be, for you to do good. But it sounds suffocating and enfeebling. </p>
<p>On my preferred way of living, you do notice if you seem too excited about living in a nice house. But if you think you might have ‘the wrong values’ you address that problem head on, by object level inquiry into what your values are and what you think they ‘should be’. If you think you might be engaging in self-deception, you try to work out if that is true, and why, and stop it, rather than building a system that lets you move money through under the assumption that you are self-deceiving. </p>
<p>Relatedly, I think people sometimes donate to causes they don’t work on, though their position is that the one they work on is better, or hesitate to spend the amounts of money implied by their usual evaluations on improving something in their usual line of work, out of a modest sense that they might be biased about their choice of work, and that money could really save lives for instance. On my preferred way of living, if you suspect that you are biased about your choice of cause to work in such that money is better spent on a different one, you sit down and figure that out and don’t waste your career, not just send your Christmas donation somewhere else and then get back to work. </p>
<p>This all takes effort though, and won’t be perfect, and mileages vary, and everyone must do their best with whatever state of psychological mess they find themselves in. So quite possibly the ‘avoid non-sacrifice’ methods are better for some people.</p>
<p>But having to be this kind of creature, that can’t treat itself as an agent, that isn’t allowed certain beliefs, that second guesses itself and fears parts of itself and ties itself up to thwart them, seems like quite a cost, so I don’t think such strategies should be taken up by default or casually. </p>
<p>This is all my sense, but I haven’t spent huge amounts of time thinking about it (e.g. note my own position is pretty vague), and may come around pretty easily.</p>",KatjaGrace,katjagrace,KatjaGrace,
ivQCeNjAD352p9jkd,Kansas City Dojo Meetup: 11-5-19,kansas-city-dojo-meetup-11-5-19,https://www.lesswrong.com/posts/ivQCeNjAD352p9jkd/kansas-city-dojo-meetup-11-5-19,2019-11-07T21:32:06.985Z,4,2,0,False,False,,"<html><head></head><body><p>Kansas City Dojo Meetup 11-5-19
(names besides my own have been changed for privacy)</p>
<h2>PART I: 6pm-6:30</h2>
<p>There are three attendees total, including myself, and one is a newcomer and a stranger
to the Rationalist community. He found us on <a href=""http://Meetup.com"">Meetup.com</a>. I begin by explaining the Dojo proceedings to him: we each bring a problem/project we are working on, and the others at the table proceed to ask questions and then provide advice on that problem/project, with the backdrop of Rationality (logic, science, a Bayesian framework, etc).
I begin with myself as an example. I pull out my “Character Sheet” (commonly known in  the Rationalist Community as a “Bug List”; a list of problems in our lives. I have reframed it in a more positive light; a list of features that the Best Version of Alex has). I pick on feature off this list: my desire to be good at synthesizing information. The regular attendee, one of our founding members (hereafter known as ‘Life Engineer’), begins by asking me to be more specific.
“What do you mean by synthesis?” he asks. I say “the ability to take multiple pieces of  information, and use them to make deductions about reality.”</p>
<p>He asks a few more probing questions to help me better articulate what I’m talking
about. He mentions <a href=""https://www.mindtools.com/pages/article/smart-goals.htm"">“SMART Goals”</a> (Specific, Measurable, Attainable, Relevant, Time-bound”) as a good template to follow as inspiration. In an attempt to be more specific, I use two examples of different problems at my job:  one problem involves social tension between myself and a coworker. Another problem involves repairing a corrupt operating system. Two drastically different situations, but they share a few things in common:</p>
<ul>
<li>You need to examine the problem.</li>
<li>You need to be able to generate a hypothesis about a possible solution.</li>
<li>You need to be able to test your hypothesis.</li>
</ul>
<p>We taboo “synthesis” and use “problem solving” instead, to see if it serves to articulate what I’m trying to accomplish. Life Engineer did a year of professional problem solving for his job. His advice is to learn how to take better measurements. Of course, knowing what to measure requires some domain-specific knowledge, supporting my prior belief that Rationalists need to read books from many domains in order to know what to measure in any given situation. The most actionable thing I get from this is that I need to renew my efforts into tackling my reading list.</p>
<p>This reminds me of a larger, more meta problem I have with my list: I’m pretty sure some of them are not irreducible; some of them are multiple problems rolled into one. I use the example of my observational skills; I’m fairly certain that “observational skills” is a bunch of smaller, constituent skills, or the problems I’m seeing are a result of many smaller problems. My question, on the topic of measurement: how do we dig deeper to get specifics about a problem, in order to figure out what to measure? How do we perform introspection on our “bugs” to find the constituent problems?</p>
<p>We thought about this for five solid minutes, and couldn’t think of any good ideas
besides our usual “Talk about it with the group, to get more heads on the matter.”
During this particular conversation, I used another example from my personal life: I attempted recently to return an Amazon package. I printed out the label, and went to the Post Office, only to realize in line that this package was for UPS, not the Post Office. Not only did this result in embarrassment, it wasted some time as well. I had failed to make this observation entirely.</p>
<p>Life Engineer stressed, paraphrased “Notice, but don’t judge! Judging yourself will make the problem stay. Practicing noticing without judging will get you better at paying attention. It will also allow us to determine whether there is a pattern or not.”</p>
<p>We discuss mindfulness at this point, and how my mistake was not being in the present moment; being more concerned about what I was going to do next, instead of what I was doing in the present moment.</p>
<p>I take this opportunity to explain my Character Sheet to the newcomer; what it is, and why I use it; it brings our problems to conscious attention, and allows us to track our progress.</p>
<h2>PART II: 6:30-7:15</h2>
<p>We move on to Life Engineer’s concerns, which have to do with the loneliness crisis. We talk about the concept of “disease burden”, which is a metric for measuring the effects of a disease on society, usually measured in things like “missed work days”. Newcomer expresses skepticism about the accuracy of those metrics. Life Engineer asks whether Newcomer thinks the numbers need to be smaller or larger, and what his justification would be. Newcomer says he doesn’t know, he’s just skeptical because it is a complex problem, and would probably ignore the numbers entirely. Life Engineer says that despite it being a hard problem, ignoring what metrics we have is to prevent us from moving forward.
Newcomer then says “I don’t need to move everyone else forward, just move myself  forward. Someone else will take care of that. Part of the problem is that we help too many people, like vaccinating [people in other countries] and contributing to overpopulation, etc.”</p>
<p>It’s at this point discourse begins to break down. Life Engineer says that the particular  things Newcomer is talking about are a lot more complicated than that, and that we do have responsibility for resolving problems we helped create. They both began to debate whether we have a responsibility as a country to the rest of the world, and things got heated, some snide remarks thrown back and forth.</p>
<p>Not being prepared for this, I stumbled through attempts to mediate, and get us back on  more constructive topics. I moved on to Newcomer, who mentioned his goals were to lose weight and get into a relationship. I brought up SMART Goals again, and Life Engineer began asking probing questions, as per our norm. However, Newcomer was visibly uncomfortable with the questions, probably for a variety of reasons (not being used to such vulnerability, and also still on-edge with Life Engineer). I managed to catch on to this and stressed that he doesn’t have to partake in things right  now. He asked whether this process has been constructive thus far, and I shared my personal improvements with him.</p>
<p><em>Moving forward, I think I will establish a norm of being explicit to newcomers that we  ask psychologically intimate questions, and advise them to simply observe for their first meeting.</em></p>
<h2>PART III: 7:15-8:00</h2>
<p>We begin our usual meta discussion about the Dojo; what it is, what we want it to be,  how to improve it, etc. We mostly discuss the origins of the Rationality community as a whole, for the benefit of Newcomer. Our closing discussion is interspersed with misc. chatter about evo psych theories, different therapy techniques (specifically Carl Roger’s person-centered approach), and depression.</p>
</body></html>",Senarin,senarin,Bae's Theorem,
pEz9hbusMRP4gpAow,Literature on memetics?,literature-on-memetics,https://www.lesswrong.com/posts/pEz9hbusMRP4gpAow/literature-on-memetics,2019-11-07T19:18:05.748Z,17,8,2,False,True,,"<p>In certain circles, it&apos;s common to talk about memes as entities, in a metaphorical and handwaving way. But it seems to me that thinking rigorously and precisely about memes in the framework of &quot;memes::genes, memeplexes::infectious agents, minds::hosts&quot; actually has a lot of explanatory and predictive power. This kind of thing ought to be a tool in the rationalist toolkit. In the space of politics, for example, it can be very illuminating to strip away the content of an idea and analyze it purely as a replicator, or as a component of a larger replicator conferring a specific fitness advantage.</p><p>A cursory online search for existing literature on memetics reveals that the field is about as confused as you would expect. But perhaps I am going about my search in the wrong way. Is there another field that encompasses the kind of thing I am gesturing at here?</p>",moridinamael,moridinamael,moridinamael,
e5iwognG3Bi3TE7Dj,Randomness vs. Ignorance,randomness-vs-ignorance,https://www.lesswrong.com/posts/e5iwognG3Bi3TE7Dj/randomness-vs-ignorance,2019-11-07T18:51:55.706Z,5,4,5,False,False,,"<p>A distinction I don't see made often enough is between what I call <strong>randomness</strong> and <strong>ignorance</strong>. Roughly, every expression of uncertainty is either about ""where in the universe am I?"" or ""what is the universe like?"" (or both). The former is the domain of <strong>randomness</strong>, the latter of <strong>ignorance</strong>.</p><p>Suppose you roll a die. You know that you're in a situation where you've just rolled a die, and that, in roughly 1/6th of the situations where one has just rolled a die, the die will come up a three. Thus, your uncertainty about the die roll is <strong>random</strong>.</p><p>Suppose you're wondering whether or not an omnipotent and immortal being exists. Whatever the answer is, it is the same every time someone is asking this question. Thus there is no <strong>randomness </strong>involved, but you are <strong>ignorant</strong> of what the answer is (though you might have a hunch).</p><p>Often, your uncertainty will have components of both. Suppose someone hands you a die, you roll it five times, and every time you roll a three. You can probably guess that the die is biased. But why? One way to answer this question is that, in most of the situations where one is handed a die <em>and</em> rolls it five times <em>and</em> gets the same number five times, the die is biased. You are <strong>ignorant </strong>of exactly how often this is the case, though. It could be the case every 9 out of 10 times this happens, or perhaps every 8 out of 10 times. Now suppose you knew that it was 9 out of 10 times. Then it would still be <strong>random </strong>whether you are in one of the 9 cases, or in the tenth.</p><p>Next up: <a href=""https://www.lesswrong.com/posts/v64sK88iY4kpHCwr9/reference-classes-for-randomness#daKev7Z52HKgx7osz"">Reference Classes for Randomness</a></p>",sil-ver,sil-ver,Rafael Harth,
hEzR9SYCK8PZq8CKo,LessWrong Darmstadt Meetup,lesswrong-darmstadt-meetup,https://www.lesswrong.com/events/hEzR9SYCK8PZq8CKo/lesswrong-darmstadt-meetup,2019-11-07T17:55:52.355Z,1,1,0,False,False,,,MaxRa,maxra,MaxRa,
H7cJSWC6SM4t4EaBP,Units of Action,units-of-action,https://www.lesswrong.com/posts/H7cJSWC6SM4t4EaBP/units-of-action,2019-11-07T17:47:13.141Z,6,1,6,False,False,,"<p><em>Unit of action</em> is a term I have been using internally to be more specific when thinking about groups of people. This post is for fleshing out and clarifying my thinking for myself, and seeing if it would be useful to anyone else. Also it feels like there really ought to be a term for this already, and I might be able to find more information if someone knows it.</p><p><strong>Definition</strong></p><p>A unit of action is a group that takes actions, as a group.</p><p>I take the word <em>unit</em> from the military, and also from <em>unit of analysis</em>, reflecting my belief that this is the correct level of analysis for big-picture problems. <em>Action</em> is in the colloquial sense of ""did something on purpose.""</p><p>To be more concrete, the kinds of things I am pointing at are like families, corporations, and government agencies. The kinds of things I am pointing away from are like race, class, gender, and religion.</p><p><strong>Causal vs correlational</strong></p><p>One way to see the dividing line is between groups that <em>cause</em> things to happen, and groups <em>to whom</em> things happen. Families take vacations; corporations launch products; government agencies sue people for breaking regulations. The examples I pointed away from are demographic - they don't do anything as a group, but races may be segregated, genders have different bathrooms, and classes get tax breaks.</p><p><strong>Agent heuristic</strong></p><p>Another heuristic is whether the group can plausibly be modeled as a single agent. Following game-theoretic intuition further, the unit of action can be broken down into other units of action the same way agents can be broken apart into multiple agents. We might model one firm as one agent when looking at the behavior of firms in competition, but when looking at the behavior of one firm model the different departments within the firm as different agents. Sometimes, as in the case of the military, these components are very explicit.</p><p><strong>Perpetual Coordination</strong></p><p>Units of action are stable, successful-at-some-rate coordinators. I have a vague intuition that we can think of them as coordination strategies which propagate in the same way organisms have reproduction strategies, but the analogy is hardly precise; reproduction propagates genetic information, and units of action mostly propagate <em>relationships.</em></p><p><strong>Miscellaneous thoughts</strong></p><ul><li>Hierarchy is usually sufficient, but not necessary, to indicate a unit of action.</li><li>There is no taxonomy; it is defined by actions, not org type.</li><li>If a given group stops being a unit of action, I expect it to fall apart soon (split up, go bankrupt, etc).</li></ul>",ryan_b,ryan_b,ryan_b,
tTg4bn5rxHYqQJXhD,Uber Self-Driving Crash,uber-self-driving-crash,https://www.lesswrong.com/posts/tTg4bn5rxHYqQJXhD/uber-self-driving-crash,2019-11-07T15:00:01.625Z,109,51,1,False,False,,"<p>



<i>Content warning: discussion of death</i>



</p><p>

A year and a half ago an Uber self-driving car hit and killed Elaine
Herzberg.  I <a href=""https://www.facebook.com/jefftk/posts/933323644812"">wrote</a> at
the time:

</p>

<p>

</p>

<blockquote>
The dashcam video from the Uber crash has been released. It's really
bad. The pedestrian is slowly walking their bike left to right across
a two lane street with streetlights, and manages to get to the right
side of the right lane before being hit. The car doesn't slow down at
all. A human driver would have vision with more dynamic range than
this camera, and it looks to me like they would have seen the
pedestrian about 2s out, time to slow down dramatically even if not
stop entirely. But that doesn't matter here, because this car has
LIDAR, which generates its own light. I'm expecting that when the full
sensor data is released it will be very clear that the system had all
the information it needed to stop in time.

<p>

This is the sort of situation where LIDAR should shine, equivalent to
a driver on an open road in broad daylight. That the car took no
action here means things are very wrong with their system. If it were
a company I trusted more than Uber I would say ""at least two things
going wrong, like not being able to identify a person pushing a bike
and then not being cautious enough about unknown input"" but with Uber
I think they may be just aggressively pushing out immature tech.
</p>
</blockquote>



<p>

On <a href=""https://dms.ntsb.gov/pubdms/search/document.cfm?docID=477717&amp;docketID=62978&amp;mkey=96894"">Tuesday</a>
the NTSB released their report (<a href=""https://dms.ntsb.gov/public/62500-62999/62978/629713.pdf"">pdf</a>)
and it's clear that the system could easily have avoided this accident
if it had been better designed.  Major issues include:

</p>

<p>

</p>

<ul>

<li><p>""If we see a problem, wait and hope it goes away"". The car was
programmed to, when it determined things were very wrong,
wait one second.  Literally.  Not even gently apply the brakes.  This
is absolutely nuts.  If your system has so many false alarms that you
need to include this kind of hack to keep it from acting erratically,
you are not ready to test on public roads.</p></li>

<li><p>""If I can't stop in time, why bother?""  When the car concluded
emergency braking was needed, and after waiting one second to make
sure it was still needed, it decided not to engage emergency braking
because that wouldn't be sufficient to prevent impact.  Since
lower-speed crashes are far more survivable, you definitely still want
to brake hard even if it won't be enough.</p></li>

<li><p>""If I'm not sure what it is, how can I remember what it was
doing?"" The car wasn't sure whether Herzberg and her bike were a
""Vehicle"", ""Bicycle"", ""Unknown"", or ""Other"", and kept switching
between classifications.  This shouldn't have been a major issue,
except that with each switch it discarded past observations.  Had the
car maintained this history it would have seen that some sort of large
object was progressing across the street on a collision course, and
had plenty of time to stop.</p></li>

<li><p>""Only people in crosswalks cross the street."" If the car had
correctly classified her as a pedestrian in the middle of the road you
might think it would have expected her to be in the process of
crossing.  Except it only thought that for pedestrians in crosswalks;
outside of a crosswalk the car's prior was that any direction was
equally likely.</p></li>

<li><p>""The world is black and white.""  I'm less sure here, but it
sounds like the car computed ""most likely"" categories for objects, and
then ""most likely"" paths given their categories and histories, instead
of maintaining some sort of distribution of potential outcomes.  If it
had concluded that a pedestrian would <i>probably</i> be out of the
way it would act as if the pedestrian would <i>definitely</i> be out
of the way, even if there was still a 49% chance they wouldn't be.</p></li>

</ul>



<p>

This is incredibly bad, applying ""quick, get it working even if it's
kind of a hack"" programming in a field where failure has real
consequences.  Self-driving cars have the potential to prevent
hundreds of thousands of deaths a year, but this sort of reckless
approach does not help.

</p>

<p>

(Disclosure: I work at Google, which is owned by Alphabet, which owns
Waymo, which also operates driverless cars.  I'm speaking only for
myself, and don't know anything more than the general public does
about Waymo.)

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100120291885932"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
tSemJckYr29Gnxod2,Building Intuitions On Non-Empirical Arguments In Science,building-intuitions-on-non-empirical-arguments-in-science,https://www.lesswrong.com/posts/tSemJckYr29Gnxod2/building-intuitions-on-non-empirical-arguments-in-science,2019-11-07T06:50:02.354Z,56,25,27,False,False,,"<p><b>I.</b></p>
<p>Aeon: <a href=""https://aeon.co/essays/post-empirical-science-is-an-oxymoron-and-it-is-dangerous"">Post-Empirical Science Is An Oxymoron And It is Dangerous</a>:</p>
<blockquote><p>There is no agreed criterion to distinguish science from pseudoscience, or just plain ordinary bullshit, opening the door to all manner of metaphysics masquerading as science. This is ‘post-empirical’ science, where truth no longer matters, and it is potentially very dangerous.</p>
<p>It’s not difficult to find recent examples. On 8 June 2019, the front cover of New Scientist magazine boldly declared that we’re ‘Inside the Mirrorverse’. Its editors bid us ‘Welcome to the parallel reality that’s hiding in plain sight’. […]</p>
<p>[Some physicists] claim that neutrons [are] flitting between parallel universes. They admit that the chances of proving this are ‘low’, or even ‘zero’, but it doesn’t really matter. When it comes to grabbing attention, inviting that all-important click, or purchase, speculative metaphysics wins hands down.</p>
<p>These theories are based on the notion that our Universe is not unique, that there exists a large number of other universes that somehow sit alongside or parallel to our own. For example, in the so-called Many-Worlds interpretation of quantum mechanics, there are universes containing our parallel selves, identical to us but for their different experiences of quantum physics. These theories are attractive to some few theoretical physicists and philosophers, but there is absolutely no empirical evidence for them. And, as it seems we can’t ever experience these other universes, there will never be any evidence for them. As Broussard explained, these theories are sufficiently slippery to duck any kind of challenge that experimentalists might try to throw at them, and there’s always someone happy to keep the idea alive.</p>
<p>Is this really science? The answer depends on what you think society needs from science. In our post-truth age of casual lies, fake news and alternative facts, society is under extraordinary pressure from those pushing potentially dangerous antiscientific propaganda – ranging from climate-change denial to the anti-vaxxer movement to homeopathic medicines. I, for one, prefer a science that is rational and based on evidence, a science that is concerned with theories and empirical facts, a science that promotes the search for truth, no matter how transient or contingent. I prefer a science that does not readily admit theories so vague and slippery that empirical tests are either impossible or they mean absolutely nothing at all.</p></blockquote>
<p>As always, a single quote doesn’t do the argument justice, so go read the article. But I think this captures the basic argument: multiverse theories are bad, because they’re untestable, and untestable science is pseudoscience.</p>
<p>Many great people, both philosophers of science and practicing scientists, have already discussed the problems with this point of view. But none of them lay out their argument in quite the way that makes the most sense to me. I want to do that here, without claiming any originality or special expertise in the subject, to see if it helps convince anyone else.</p>
<p><b>II.</b></p>
<p>Consider a classic example: modern paleontology does a good job at predicting dinosaur fossils. But the creationist explanation – Satan buried fake dinosaur fossils to mislead us – also predicts the same fossils (we assume Satan is good at disguising his existence, so that the lack of other strong evidence for Satan doesn’t contradict the theory).  What principles help us realize that the Satan hypothesis is obviously stupid and the usual paleontological one more plausible?</p>
<p>One bad response: paleontology can better predict characteristics of dinosaur fossils, using arguments like “since plesiosaurs are aquatic, they will be found in areas that were underwater during the Mesozoic, but since tyrannosaurs are terrestrial, they will be found in areas that were on land”, and this makes it better than the Satan hypothesis, which can only retrodict these characteristics. But this isn’t quite true: since Satan is trying to fool us into believing the modern paleontology paradigm, he’ll hide the fossils in ways that conform to its predictions, so we will predict plesiosaur fossils will only be found at sea – otherwise the gig would be up!</p>
<p>A second bad response: “The hypothesis that all our findings were planted to deceive us bleeds into conspiracy theories and touches on the problem of skepticism. These things are inherently outside the realm of science.” But archaeological findings are <a href=""https://en.wikipedia.org/wiki/Archaeological_forgery#Known_archaeological_forgeries_and_hoaxes"">very often deliberate hoaxes</a> planted to deceive archaeologists, and in practice archaeologists consider and test that hypothesis the same way they consider and test every other hypothesis. Rule this out by fiat and we have to accept Piltdown Man, or at least claim that the people arguing against the veracity of Piltdown Man were doing something other than Science.</p>
<p>A third bad response: “Satan is supernatural and science is not allowed to consider supernatural explanations.” Fine then, replace Satan with an alien. I think this is a stupid distinction – if demons really did interfere in earthly affairs, then we could investigate their actions using the same methods we use to investigate every other process. But this would take a long time to argue well, so for now let’s just stick with the alien.</p>
<p>A fourth bad response: “There is no empirical test that distinguishes the Satan hypothesis from the paleontology hypothesis, therefore the Satan hypothesis is inherently unfalsifiable and therefore pseudoscientific.” But this can’t be right. After all, there’s no empirical test that distinguishes the paleontology hypothesis from the Satan hypothesis! If we call one of them pseudoscience based on their inseparability, we have to call the other one pseudoscience too!</p>
<p>A naive Popperian (which maybe nobody really is) would have to stop here, and say that we predict dinosaur fossils will have such-and-such characteristics, but that questions like that process that drives this pattern – a long-dead ecosystem of actual dinosaurs, or the Devil planting dinosaur bones to deceive us – is a mystical question beyond the ability of Science to even conceivably solve.</p>
<p>I think the correct response is to say that both theories explain the data, and one cannot <i>empirically</i> test which theory is true, but the paleontology theory <i>is more elegant</i> (I am tempted to say “simpler”, but that might imply I have a rigorous mathematical definition of the form of simplicity involved, which I don’t). It requires fewer other weird things to be true. It involves fewer other hidden variables. It transforms our worldview less. It gets a cleaner shave with Occam’s Razor. This elegance is so important to us that it explains our vast preference for the first theory over the second.</p>
<p>A long tradition of philosophers of science have already written eloquently about this, summed up by Sean Carroll <a href=""https://arxiv.org/pdf/1801.05016.pdf"">here</a>:</p>
<blockquote><p>What makes an explanation “the best.” Thomas Kuhn ,after his influential book The Structure of Scientific Revolutions led many people to think of him as a relativist when it came to scientific claims, attempted to correct this misimpression by offering a list of criteria that scientists use in practice to judge one theory better than another one: accuracy, consistency, broad scope, simplicity, and fruitfulness. “Accuracy” (fitting the data) is one of these criteria, but by no means the sole one. Any working scientist can think of cases where each of these concepts has been invoked in favor of one theory or another. But there is no unambiguous algorithm according to which we can feed in these criteria, a list of theories, and a set of data, and expect the best theory to pop out. The way in which we judge scientific theories is inescapably reflective, messy, and human. That’s the reality of how science is actually done; it’s a matter of judgment, not of drawing bright lines between truth and falsity or science and non-science.  Fortunately, in typical cases the accumulation of evidence eventually leaves only one viable theory in the eyes of most reasonable observers.</p></blockquote>
<p>The dinosaur hypothesis and the Satan hypothesis both fit the data, but the dinosaur hypothesis wins hands-down on simplicity. As Carroll predicts, most reasonable observers are able to converge on the same solution here, despite the philosophical complexity.</p>
<p><b>III.</b></p>
<p>I’m starting with this extreme case because its very extremity makes it easier to see the mechanism in action. But I think the same process applies to other cases that people really worry about.</p>
<p>Consider the riddle of the Sphinx. There’s pretty good archaeological evidence supporting the consensus position that it was built by Pharaoh Khafre. But there are a few holes in that story, and a few scattered artifacts suggest it was actually built by Pharaoh Khufu; a respectable minority of archaeologists believe this. And there are a few anomalies which, if taken wildly out of context, you can use to tell a story that it was built long before Egypt existed at all, maybe by Atlantis or aliens.</p>
<p>So there are three competing hypotheses. All of them are consistent with current evidence (even the Atlantis one, which was written after the current evidence was found and carefully adds enough epicycles not to blatantly contradict it). Perhaps one day evidence will come to light that supports one above the others; maybe in some unexcavated tomb, a hieroglyphic tablet says “I created the Sphinx, sincerely yours, Pharaoh Khufu”. But maybe this won’t happen. Maybe we already have all the Sphinx-related evidence we’re going to get. Maybe the information necessary to distinguish among these hypotheses has been utterly lost beyond any conceivable ability to reconstruct.</p>
<p>I don’t want to say “No hypothesis can be tested any further, so Science is useless to us here”, because then we’re forced to conclude stupid things like “Science has no opinion on whether the Sphinx was built by Khafre or Atlanteans,” whereas I think most scientists would actually have very strong opinions on that.</p>
<p>But what about the question of whether the Sphinx was built by Khafre or Khufu? This is a real open question with respectable archaeologists on both sides; what can we do about it?</p>
<p>I think the answer would have to be: the same thing we did with the Satan vs. paleontology question, only now it’s a lot harder. We try to figure out which theory requires fewer other weird things to be true, fewer hidden variables, less transformation of our worldview – which theory works better with Occam’s Razor. This is relatively easy in the Atlantis case, and hard but <i>potentially possible</i> in the Khafre vs. Khufu case.</p>
<p>(Bayesians can rephrase this to: given that we have a certain amount of evidence for each, can we quantify exactly how much evidence, and what our priors for each should be. It would end not with a decisive victory of one or the other, but with a probability distribution, maybe 80% chance it was Khafre, 20% chance it was Khufu)</p>
<p>I think this is a totally legitimate thing for Egyptologists to do, even if it never results in a particular testable claim that gets tested. If you don’t think it’s a legitimate thing for Egyptologists to do, I have trouble figuring out how you can justify Egyptologists rejecting the Atlantis theory.</p>
<p>(Again, Bayesians would start with a very low prior for Atlantis, and assess the evidence as very low, and end up with a probability distribution something like Khafre 80%, Khufu 19.999999%, Atlantis 0.000001%)</p>
<p><b>IV.</b></p>
<p>How does this relate to things like multiverse theory? Before we get there, one more hokey example:</p>
<p>Suppose scientists measure the mass of one particle at 32.604 units, the mass of another related particle at 204.897 units, and the mass of a third related particle at 4452.767 units. For a while, this is just how things are – it seems to be an irreducible brute fact about the universe. Then some theorist notices that if you set the mass of the first particle as x, then the second is 2πx and the third is 4/3 πx^2. They theorize that perhaps the quantum field forms some sort of extradimensional sphere, the first particle represents a diameter of a great circle of the sphere, the second the circumference of the great circle, and the third the volume of the sphere.</p>
<p>(please excuse the stupidity of my example, I don’t know enough about physics to come up with something that isn’t stupid, but I hope it will illustrate my point)</p>
<p>In fact, imagine that there are a hundred different particles, all with different masses, and all one hundred have masses that perfectly correspond to various mathematical properties of spheres.</p>
<p>Is the person who made this discovery doing Science? And should we consider their theory a useful contribution to physics?</p>
<p>I think the answer is clearly yes. But consider what this commits us to. Suppose the scientist came up with their Extradimensional Sphere hypothesis <i>after</i> learning the masses of the relevant particles, and so it has not predicted anything. Suppose the extradimensional sphere is outside normal space, curled up into some dimension we can’t possibly access or test without a particle accelerator the size of the moon. Suppose there are no undiscovered particles in this set that can be tested to see if they also reflect sphere-related parameters. This theory is exactly the kind of postempirical, metaphysical construct that the Aeon article savages.</p>
<p>But it’s really compelling. We have a hundred different particles, and this theory retrodicts the properties of each of them perfectly. And it’s so simple – just say the word “sphere” and the rest falls out naturally! You would have to be crazy not to think it was at least pretty plausible, or that the scientist who developed it had done some good work. </p>
<p>Nor do I think it seems right to say “The discovery that all of our unexplained variables perfectly match the parameters of a sphere is good, but the hypothesis that there <i>really is</i> a sphere is outside the bounds of Science.” That sounds too much like saying “It’s fine to say dinosaur bones have such-and-such characteristics, but we must never speculate about what kind of process produced them, or whether it involved actual dinosaurs”.</p>
<p><b>V.</b></p>
<p>My understanding of the multiverse debate is that it works the same way. Scientists observe the behavior of particles, and find that a multiverse explains that behavior more simply and elegantly than not-a-multiverse.</p>
<p>One (doubtless exaggerated) way I’ve heard multiverse proponents <a href=""https://aeon.co/essays/how-the-many-worlds-theory-of-hugh-everett-split-the-universe"">explain their position</a> is like this: in certain situations the math declares two contradictory answers – in the classic example, Schrodinger’s cat will be both alive and dead. But when we open the box, we see only a dead cat or an alive cat, not both. Multiverse opponents say “Some unknown force steps in at the last second and destroys one of the possibility branches”. Multiverse proponents say “No it doesn’t, both possibility branches happen exactly the way the math says, and we end up in one of them.”</p>
<p>Taking this exaggerated dumbed-down account as exactly right, this sounds about as hard as the dinosaurs-vs-Satan example, in terms of figuring out which is more Occam’s Razor compliant. I’m sure the reality is more nuanced, but I think it can be judged by the same process. Perhaps this is the kind of reasoning that only gets us to a 90% probability there is a multiverse, rather than a 99.999999% one. But I think determining that theories have 90% probability is a reasonable scientific thing to do.</p>
<p><b>VI.</b></p>
<p>At times, the Aeon article seems to flirt with admitting that something like this is necessary:</p>
<blockquote><p>Such problems were judged by philosophers of science to be insurmountable, and Popper’s falsifiability criterion was abandoned (though, curiously, it still lives on in the minds of many practising scientists). But rather than seek an alternative, in 1983 the philosopher Larry Laudan declared that the demarcation problem is actually intractable, and must therefore be a pseudo-problem. He argued that the real distinction is between knowledge that is reliable or unreliable, irrespective of its provenance, and claimed that terms such as ‘pseudoscience’ and ‘unscientific’ have no real meaning.</p></blockquote>
<p>But it always jumps back from the precipice:</p>
<blockquote><p>So, if we can’t make use of falsifiability, what do we use instead? I don’t think we have any real alternative but to adopt what I might call the empirical criterion. Demarcation is not some kind of binary yes-or-no, right-or-wrong, black-or-white judgment. We have to admit shades of grey. Popper himself was ready to accept this, [saying]:</p>
<p><i>“The criterion of demarcation cannot be an absolutely sharp one but will itself have degrees. There will be well-testable theories, hardly testable theories, and non-testable theories. Those which are non-testable are of no interest to empirical scientists. They may be described as metaphysical.”</i></p>
<p>Here, ‘testability’ implies only that a theory either makes contact, or holds some promise of making contact, with empirical evidence. It makes no presumptions about what we might do in light of the evidence. If the evidence verifies the theory, that’s great – we celebrate and start looking for another test. If the evidence fails to support the theory, then we might ponder for a while or tinker with the auxiliary assumptions. Either way, there’s a tension between the metaphysical content of the theory and the empirical data – a tension between the ideas and the facts – which prevents the metaphysics from getting completely out of hand. In this way, the metaphysics is tamed or ‘naturalised’, and we have something to work with. This is science.</p></blockquote>
<p>But as we’ve seen, many things we really want to include as science are not testable: our credence for real dinosaurs over Satan planting fossils, our credence for Khafre building the Sphinx over Khufu or Atlanteans, or elegant patterns that explain the features of the universe like the Extradimensional-Sphere Theory. </p>
<p>The Aeon article is aware of Carroll’s work – which, along with the paragraph quoted in Section II above, includes a lot of detailed Bayesian reasoning encompassing everything I’ve discussed. But the article dismisses it in a few sentences:</p>
<blockquote><p>Sean Carroll, a vocal advocate for the Many-Worlds interpretation, prefers abduction, or what he calls ‘inference to the best explanation’, which leaves us with theories that are merely ‘parsimonious’, a matter of judgment, and ‘still might reasonably be true’. But whose judgment? In the absence of facts, what constitutes ‘the best explanation’?</p>
<p>Carroll seeks to dress his notion of inference in the cloth of respectability provided by something called Bayesian probability theory, happily overlooking its entirely subjective nature. It’s a short step from here to the theorist-turned-philosopher Richard Dawid’s efforts to justify the string theory programme in terms of ‘theoretically confirmed theory’ and ‘non-empirical theory assessment’. The ‘best explanation’ is then based on a choice between purely metaphysical constructs, without reference to empirical evidence, based on the application of a probability theory that can be readily engineered to suit personal prejudices.</p></blockquote>
<p>“A choice between purely metaphysical constructs, without reference to empirical evidence” sounds pretty bad, until you realize he’s talking about the same reasoning we use to determine that real dinosaurs are more likely than Satan planting fossils.</p>
<p>I don’t want to go over the exact ways in which Bayesian methods are subjective (which I think are overestimated) vs. objective. I think it’s more fruitful to point out that your brain <a href=""https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/"">is already using Bayesian methods</a> to interpret the photons striking your eyes into this sentence, to make snap decisions about what sense the words are used in, and to integrate them into your model of the world. If Bayesian methods are good enough to give you every single piece of evidence about the nature of the external world that you have ever encountered in your entire life, I say they’re good enough for science.</p>
<p>Or if you don’t like that, you can use the explanation above, which barely uses the word “Bayes” at all and just describes everything in terms like “Occam’s Razor” and “you wouldn’t want to conclude something like that, would you?”</p>
<p>I know there are separate debates about whether this kind of reasoning-from-simplicity is actually good enough, when used by ordinary people, to consistently arrive at truth. Or whether it’s a productive way to conduct science that will give us good new theories, or <a href=""http://nautil.us/issue/71/flow/why-beauty-is-fatal-to-physics"">a waste of everybody’s time</a>. I sympathize with some these concerns, though I am nowhere near scientifically educated enough to have an actual opinion on the questions at play.</p>
<p>But I think it’s important to argue that even before you describe the advantages and disadvantages of the complicated Bayesian math that lets you do this, <i>something like this has to be done</i>. The untestable is a fundamental part of science, impossible to remove. We can debate how to explain it. But denying it isn’t an option.</p>",Yvain,scottalexander,Scott Alexander,
94YMDgQ5n5b4LdSLB,Personal quality experimentation,personal-quality-experimentation,https://www.lesswrong.com/posts/94YMDgQ5n5b4LdSLB/personal-quality-experimentation,2019-11-06T21:50:01.565Z,21,10,1,False,False,,"<p>Different people seem to have different strategies, which they use systematically across different parts of their lives, and that we recognize and talk about. For instance people vary on:</p>
<ul>
<li>Spontaneity</li>
<li>Inclination toward explicit calculations</li>
<li>Tendency to go meta</li>
<li>Skepticism</li>
<li>Optimism</li>
<li>Tendency to look at the big picture vs. the details</li>
<li>Expressed confidence</li>
<li>Enacted patience</li>
</ul>
<p>I don’t know of almost anyone experimenting with varying these axes, to see which setting is best for them, or even what different settings are like. Which seems like a natural thing to do in some sense, given the variation in starting positions and lack of consensus on which positions are best.</p>
<p>Possibly it is just very hard to change them, but my impression is that for at least some of them it is not hard to try, or to change them a bit for a short period, with some effort. (I have briefly tried making decisions faster and expressing more confidence.) And my guess is that that is enough to often be interesting. Also that if you effortfully force yourself to be more skeptical and it seems to go really well, you will find that it becomes appealing and thus easier to keep up and then get used to. </p>
<p>I also haven’t done this much, and it isn’t very clear to me why. Maybe it just doesn’t occur to people that much for some reason. (It also doesn’t occur to people to choose their value of time via experimentation I think, a related suggestion I like, I think from Tyler Cowen a long time ago.) So here, I suggest it. Fun date activity, maybe: randomly reselect one personality trait each, and both try to guess which one the other person is putting on.</p>",KatjaGrace,katjagrace,KatjaGrace,
WYmmC3W6ZNhEgAmWG,A mechanistic model of meditation,a-mechanistic-model-of-meditation,https://www.lesswrong.com/posts/WYmmC3W6ZNhEgAmWG/a-mechanistic-model-of-meditation,2019-11-06T21:37:03.819Z,137,67,12,False,False,,"<p>Meditation has been claimed to have all kinds of transformative effects on the psyche, such as improving concentration ability, healing trauma, <a href=""https://www.lesswrong.com/posts/QqSNFcGSZdnARx56E/meditation-insight-and-rationality-part-1-of-3"">cleaning up delusions</a>, allowing one to <u><a href=""https://www.lesswrong.com/posts/tMhEv28KJYWsu6Wdo/kensh?commentId=wgb3wu6kQYdCpoehL"">track their subconscious strategies</a></u>, and <u><a href=""https://www.lesswrong.com/posts/ZawRiFR8ytvpqfBPX/the-hard-work-of-translation-buddhism"">making one&#x2019;s nervous system more efficient</a></u>. However, an explanation for why and how exactly this would happen has typically been lacking. This makes people reasonably skeptical of such claims.</p><p>In this post, I want to offer an explanation for one kind of a mechanism: meditation increasing the degree of a person&#x2019;s introspective awareness, and thus leading to increasing psychological unity as internal conflicts are detected and resolved. </p><p>Note that this post does <em>not</em> discuss &#x201C;enlightenment&#x201D;. That is a related but separate topic. It is possible to pursue meditation mainly for its ordinary psychological benefits while being uninterested in enlightenment, and vice versa. </p><h1>What is introspective awareness?</h1><p>In an earlier <u><a href=""https://www.lesswrong.com/posts/AhcEaqWYpa2NieNsK/subagents-introspective-awareness-and-blending"">post on introspective awareness</a></u>, I distinguished between being <em>aware of something</em>, and <em>being aware of having been aware of something</em>. My example involved that of a robot whose consciousness contains one mental object at a time, and which is aware of different things at different times:</p><blockquote>Robot&#x2019;s thought at time 1: It&#x2019;s raining outside</blockquote><blockquote>Robot&#x2019;s thought at time 2: Battery low</blockquote><blockquote>Robot&#x2019;s thought at time 3: Technological unemployment protestors are outside</blockquote><blockquote>Robot&#x2019;s thought at time 4: Battery low</blockquote><blockquote>Robot&#x2019;s thought at time 5: I&#x2019;m now recharging my battery</blockquote><p>At times 2-5, the robot has no awareness of the fact that it was thinking about rain at time 1. As soon as something else captures its attention, it has no idea of this earlier conscious content - <em>unless</em> a particular subsystem happens to record the fact, and can later re-present the content in an appropriately tagged form:</p><blockquote>Time 6: At time 1, there was the thought that [It&#x2019;s raining outside]</blockquote><p>I said that at time 6, the robot had a <em>moment of introspective awareness</em>: a mental object containing a summary of its previous thoughts, which can then be separately examined and acted upon.</p><p>Humans are not robots. But I previously summarized the neuroscience book <em><u><a href=""https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain"">Consciousness and the Brain</a></u></em>, and its global neuronal workspace (GNW) model of consciousness. According to this model, the contents of consciousness correspond to what is being represented in a particular network of neurons - the global workspace - that connects different parts of the brain. Different systems are constantly competing to get their contents into the global workspace, which can only hold one piece of content at a time. Thus, like robots, we too are only aware of one thing at a time, and tend to lose awareness of our earlier thoughts - unless something reminds us of them.</p><p>In what follows, I will suggest that like robots, humans also have a type of conscious content that we might call <em>introspective awareness</em>, which allows us to be more aware of our previous mental activity. (I am borrowing the term from the meditation book <em>The Mind Illuminated, </em>which distinguishes between <em>introspective attention</em>, <em>introspective awareness</em>, and <em>metacognitive introspective awareness</em>. I am eliding these differences for the sake of simplicity.)</p><p>I will also explore the idea that introspective awareness is a sensory channel in a similar sense as vision and sound are. The experience of sight or sound is produced by subsystems which send information to consciousness; likewise, introspective awareness is produced by a subsystem which captures information in the brain and then sends it (back) to consciousness.</p><p>We can train our other senses to become more accurate and detailed. <u><a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.147.7825&amp;rep=rep1&amp;type=pdf"">Gilbert, Sigman &amp; Crist (2001)</a></u>, reviewing the neuroscience on sensory training, list a number of ways in which discrimination can be increased in a variety of sensory modalities: among other things, &quot;visual acuity, somatosensory spatial resolution, discrimination of hue, estimation of weight, and discrimination of acoustical pitch all show improvement with practice&quot;; even the spatial resolution of the visual system can be deliberately increased by training.</p><p>If introspective awareness is a sensory channel, can it also be practiced to improve the number of details it will pick up on? One may feel that I am stretching the metaphor here. But in fact, <em>Consciousness and the Brain </em>suggests that <em>all</em> sensory training is in a sense training in introspection. The additional information that we get by training our senses has always been collected by our brain, but that information has remained isolated at lower levels of processing. To make it conscious, one needs to grow new neural circuits which extract the lower-level information and re-encode it in a format which can be sent to consciousness.</p><p>Thus, the brain <em>already</em> has the ability to take normally unavailable subconscious information and make it consciously available by practice. What is needed is a way to point that learning process at the kind of information that we would normally consider &quot;introspective&quot;, rather than on an external information source.</p><p>From <em>Consciousness and the Brain:</em></p><blockquote>... a fourth way in which neural information can remain unconscious, according to workspace theory, is to be diluted into a complex pattern of firing. To take a concrete example, consider a visual grating that is so finely spaced, or that flickers so fast (50 hertz and above), that you cannot see it. Although you perceive only a uniform gray, experiments show that the grating is actually encoded inside your brain: distinct groups of visual neurons fire for different orientations of the grating. Why can&#x2019;t this pattern of neuronal activity be brought to consciousness? Probably because it makes use of an extremely tangled spatiotemporal pattern of firing in the primary visual area, a neural cipher too complex to be explicitly recognized by global workspace neurons higher up in the cortex. Although we do not yet fully understand the neural code, we believe that, in order to become conscious, a piece of information first has to be re-encoded in an explicit form by a compact assembly of neurons. The anterior regions of the visual cortex must dedicate specific neurons to meaningful visual inputs, before their own activity can be amplified and cause a global workspace ignition that brings the information into awareness. If the information remains diluted in the firing of myriad unrelated neurons, then it cannot be made conscious.</blockquote><blockquote>Any face that we see, any word that we hear, begins in this unconscious manner, as an absurdly contorted spatiotemporal train of spikes in millions of neurons, each sensing only a minuscule part of the overall scene. Each of these input patterns contains virtually infinite amounts of information about the speaker, message, emotion, room size . . . if only we could decode it&#x2014;but we can&#x2019;t. We become aware of this latent information only once our higher-level brain areas categorize it into meaningful bins. Making the message explicit is an essential role of the hierarchical pyramid of sensory neurons that successively extract increasingly abstract features of our sensations. Sensory training makes us aware of faint sights or sounds because, at all levels, neurons reorient their properties to amplify these sensory messages. Prior to learning, a neuronal message was already present in our sensory areas, but only implicitly, in the form of a diluted firing pattern inaccessible to our awareness.</blockquote><h2>Richard&#x2019;s therapy session</h2><p>We saw an example of introspective awareness in my <u><a href=""https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain"">post on the book <em>Unlocking the Emotional Brain</em></a></u>. In the transcript, a man named Richard has been suffering from severe self-doubt, and is asked to imagine how it would feel like if he made confident comments in a work meeting. The following conversation follows:</p><blockquote>Richard: Now I&#x2019;m feeling really uncomfortable, but-it&#x2019;s in a different way.</blockquote><blockquote>Therapist: OK, let yourself feel it - this different discomfort. [Pause.] See if any words come along with this uncomfortable feeling.</blockquote><blockquote>Richard: [Pause.] Now they hate me.</blockquote><p>The therapist is asking Richard to focus his attention on the feeling of discomfort, generating moments of introspective awareness <em>about</em> the discomfort. Notice that Richard becomes more thoughtful and less reactive to the anxiety as he does so. My guess of what is happening is something like this:</p><p>When Richard is feeling anxious, this means that a mental object encoding something like &#x201C;the feeling of anxiety&#x201D; is being represented in the workspace. This <u><a href=""https://www.lesswrong.com/posts/7zQPYQB5EeaqLrhBh/subagents-neural-turing-machines-thought-selection-and"">activates neural rules</a></u> which trigger the kinds of responses that anxiety <u><a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.109&amp;rep=rep1&amp;type=pdf"">has evolved to produce</a></u>. For example, a system may be triggered which attempts to plan how to escape the situation causing the anxiety. This system&#x2019;s intentions are then injected into the workspace, producing a state of mind where the feeling of anxiety alternates with thoughts of how to get away.</p><p>Introspective awareness is its own type of mental object, produced by a different subsystem which takes inputs from the global workspace, re-encodes them in a format which highlights particular aspects of that data, and outputs that back into the workspace. When a representation of an anxious state of mind is created, that representation does not by itself trigger the same rules as the original anxiety did. </p><p>As a result, as representations of the anxiety begin to alternate <em>together with</em> the anxiety, there are proportionately less moments of anxiety. This in turn triggers fewer of the subsystems attempting to escape the situation, making it easier to reflect on the anxiety without being bothered by it.</p><p>When Richard&#x2019;s therapist asks him to feel the anxiety and to see if any words come along with it, the subsystem for introspective awareness was primed to look for any content that could be re-presented in verbal form. As Richard&#x2019;s anxiety had been produced by an emotional schema including a prediction that being confident makes you hated, some of that information had passed through the workspace and been available for the awareness subsystem to capture. This brought up the verbalization of what the schema predicted would happen if Richard was confident - &#x201C;now they hate me&#x201D;.</p><blockquote>Therapist: &#x201C;Now they hate me.&#x201D; Good. Keep going: See if this really uncomfortable feeling can also tell you why they hate you now.</blockquote><p>According to the GNW model, when a particular piece of content is maintained as the center of attention, it strengthens the activation of any structures associated with it. As Richard&#x2019;s therapist guides him to focus on the verbal content, more information related to it is broadcast into the workspace. The further prompt guides the awareness subsystem to look for patterns that feel like the <em>reason</em> for the hate.</p><blockquote>Richard: [Pause.] Hnh. Wow. It&#x2019;s because&#x2026; now I&#x2019;m&#x2026; an arrogant asshole&#x2026; like my father&#x2026; a totally self-centered, totally insensitive know-it-all.</blockquote><p>The therapist then takes a pattern which Richard has brought up and helps crystallize it further, and throws it back to Richard for verification.</p><blockquote>Therapist: Do you mean that having a feeling of confidence as you speak turns you into an arrogant asshole, like Dad?</blockquote><blockquote>Richard: Yeah, exactly. Wow.</blockquote><p>In this example, we saw that having more moments of introspective awareness was beneficial for Richard. As aspects of his moment-to-moment consciousness were made available for other subsystems to examine, the emotional schema causing the anxiety was identified and its contents extracted into a format which could be fed into other subsystems. Later on, when Richard&#x2019;s co-worker displayed confidence which others approved of, a contradiction-detection mechanism noticed a discrepancy between reality and the prediction that confidence makes you hated, allowing the prediction to be revised.</p><p>Under this model, the system which produces moments of introspective awareness is a subsystem like any other in the brain. This means that it will be activated when the right cues trigger it, and its outputs compete with the outputs of other systems submitting content to consciousness. The circumstances under which the system triggers, and its probability of successfully making its contents conscious, are modified by reinforcement learning. Just as practicing a skill such as arithmetic eventually causes various subsystems to <u><a href=""https://www.lesswrong.com/posts/HbXXd2givHBBLxr3d/against-system-1-and-system-2-subagent-sequence"">manipulate the content of consciousness</a></u> in the right order, practicing a skill which benefits from introspective awareness will cause the subsystem generating introspective awareness to activate more often.</p><h1>Meditation as a technique for generating moments of introspective awareness</h1><p>Just as there are different forms and styles of therapy, there are also different forms and styles of meditation. All of them involve introspective awareness to at least some degree, but they differ in what that awareness is then used for. </p><p>In the example with Richard, his therapist asked him to imagine being confident and to then bring his awareness to <em>why</em> that felt uncomfortable. In contrast, a more behaviorally oriented therapist might not have examined the reason behind the discomfort. Rather, they might have taught Richard to notice his reaction to the discomfort, and then use that as a cue for implementing an opposite reaction. Both kinds of therapists would ask their clients to generate <em>some</em> introspective awareness, but aiming that awareness at different kinds of features, and using the awareness to trigger different kinds of strategies. The results would correspondingly be very different.</p><p>Likewise, systems of meditation differ in how much introspective awareness they produce, what kinds of features the awareness-producing subsystem is trained to extract, and what that awareness is then used for. For this article, I have chosen to use the example of the system in <em>The Mind Illuminated </em>(TMI), as it is clearly explained and explicitly phrased in these terms. (Again, TMI has a more precise distinction between introspective attention and introspective awareness, which I am eliding for the sake of simplicity.)</p><p>In TMI&#x2019;s system, as in many others, you start with trying to keep your attention on your breath. In terms of our model, this means that you want to keep sensory outputs corresponding to your breath as the main thing in your consciousness. </p><p>The problem with this goal is that there is no subsystem which can just unilaterally decide what to maintain as the center of attention. At any given moment, many different subsystems are competing to make their content conscious. So one system might have the intention to follow the breath, and you do it for a while, but then a planning system kicks in with its intention to think about dinner. Such planning has tended to feel rewarding, so it wins out and the intent to meditate is forgotten until five minutes later, when you decide what you want for dinner and then suddenly remember the thing about following your breath.</p><p>TMI calls this <em>mind-wandering from forgetting</em>, and the first step of practice is just to notice it whenever it happens, congratulate yourself for having noticed it, and then return to the breath. Being able to notice forgetting requires having a moment of introspective awareness which points out the fact that you had not been following your breath. When you take satisfaction in having noticed this, your awareness-producing subsystem gets assigned a reward and becomes slightly more likely to activate in the future. &#x201C;Have I remembered to follow my breath or not?&#x201D; acts a feedback mechanism that you can explicitly train on.</p><p>As the awareness-producing system starts to activate more often and ping you if you have forgotten to meditate, periods of mind-wandering grow shorter. </p><p>Now, even if you stop getting entirely lost in thought, you still have <em>distraction: </em>content from other subsystems that is in consciousness together with the sensations of the breath and the intention to focus on the breath. For example, you might be having stray thoughts, hearing sounds from your environment, and experiencing sensations from your body.</p><p>To more exclusively focus on the breath, you are instructed to maintain the intent to both attend to it and also to be aware of any distractions. The subsystems which output mental content can, and normally do, operate independently of each other. This means that the following may happen:</p><blockquote><em>Subsystem 1: </em>I&#x2019;m meditating well!</blockquote><blockquote><em>Subsystem 2:</em> Hmm, what&#x2019;s that smell.</blockquote><blockquote><em>Subsystem 1:</em> I&#x2019;m meditating well! No distractions.</blockquote><blockquote><em>Subsystem 2: </em>Smells kinda like cookies.</blockquote><blockquote><em>Subsystem 2: </em>Mmm, cookies.</blockquote><blockquote><em>Subsystem 1: </em>Continuing to meditate well!</blockquote><blockquote><em>Subsystem 2: </em>Say, what&#x2019;s for dinner?</blockquote><p>That is, a system which tracks the breath can continue to repeatedly find the breath, and report that your meditation is proceeding well and with no distractions&#x2026; all the while the content of your consciousness continues to alternate with distracted thoughts, which the breath-tracking subsystem is failing to notice (because it is tracking the breath, not the presence of other thoughts). Worse, since you may find it rewarding to just <em>think that you are meditating well</em>, that <em>thought</em> may start to become rewarded, and you may find yourself just <em>thinking</em> that you are meditating well&#x2026; even as that thought has become self-sustaining and no longer connected to whether you are following the breath or not!</p><p>There are all kinds of subtle traps like this, and reducing the amount of distraction requires you to first have better awareness <em>of</em> the distraction. This means more moments of introspective awareness which are tracking what&#x2019;s <em>actually</em> happening in your mind:</p><blockquote><em>Subsystem 1: </em>I&#x2019;m meditating well!</blockquote><blockquote><em>Subsystem 2:</em> Hmm, what&#x2019;s that smell.</blockquote><blockquote><em>Subsystem 1:</em> I&#x2019;m meditating well! No distractions.</blockquote><blockquote><em>Subsystem 2: </em>Smells kinda like cookies.</blockquote><blockquote><em>Subsystem 2: </em>Mmm, cookies.</blockquote><blockquote>A<em>wareness subsystem: </em>Wait, one train of thought keeps saying that it&#x2019;s meditating well, but another is totally getting into the thought of food.</blockquote><blockquote><em>Subsystem 1: </em>Oh. Better refocus that attention on the breath, and spend less time thinking about the <em>concept</em> of following the breath.</blockquote><p>This kind of a process also teaches you to pay attention to patterns of cause and effect in your mind. In this example, the smell of cookies caused you to think of cookies, which in turn made you think of dinner, which could have ultimately led to forgetting and mind-wandering. </p><p>Catching the train of thought after &#x201C;mmm, cookies&#x201D; meant that three &#x201C;processing steps&#x201D; had passed before you noticed it. If you <u><a href=""https://www.lesswrong.com/posts/riyvpus8x9sXa3W57/track-back-meditation"">practice tracing back trains of thought</a></u> in your mind, you seem to teach your awareness-system to collect and store data from a longer period, even when it is not actively outputting it. This means that at the &#x201C;mmm, cookies&#x201D; stage, you can query your awareness to get a trace of the immediately preceding thought chain. </p><p>You notice that you started to get distracted starting from the smell of the cookie and can then use this as further input to your awareness system. You are essentially taking the re-presented smell of the cookie which the system output, and feeding it back in, asking it to pay more attention to detecting &#x201C;things like this&#x201D;. The next time that you notice a smell, your introspective awareness may flag it right away, letting you catch the distraction at the very first stage and before it turns into an extended train of thought.</p><p>Note that there is nothing particularly mysterious or unusual about any of this. You are employing essentially the same process used in learning <em>any</em> skill. In learning to ride a bike, for example, attempting to keep the bike balanced involves adjusting your movements in response to feedback. When you do so, your brain becomes better at detecting things like &#x201C;tilting towards the right&#x201D; in the sense data, increasing your ability to apply the right correction. After you have learned to identify tilting-a-lot-but-not-quite-falling, your brain learns to backtrace to the preceding state of tilting-a-little-less, and apply the right correction there. Once its precision has been honed to identify that state, you can further detect an even subtler tilt, until you automatically apply the right corrections to keep you balanced. </p><p>Essentially the kind of a learning algorithm is being applied here. Increased sensory precision leads to improvements in skill which allow for increased sensory precision. (See also <u><a href=""https://rationaldharma.com/blog/the-sort-of-complete-guide-to-actually-getting-better-at-meditation/"">this article</a></u>, which goes into more detail about TMI as a form of deliberate practice.)</p><h1>Uses for moments of introspective awareness </h1><p>I should again emphasize that the preceding explanation is only looking at one particular meditation system. There are other systems which work very differently, but they all use or develop introspective awareness to some extent. For example:</p><ul><li><strong>In <u><a href=""https://www.youtube.com/watch?v=cZ6cdIaUZCA"">Shinzen Young&apos;s formulation of &#x201C;do nothing&#x201D; practice</a></u>, </strong>you have just two basic instructions: <em>let whatever happens, happen</em> and <em>when you notice an intention to control your attention, drop that intention. </em>This trains introspective awareness to notice when one is trying to control their attention&#x2026; but it is also a very different system, since maintaining an intention to notice when that happens would also be an attempt to control attention! Thus, one is instructed to drop intentions if one spontaneously notices them, but not to actively look for them.</li><li><strong>In <a href=""https://www.mctb.org/mctb2/table-of-contents/part-i-the-fundamentals/7-the-seven-factors-of-awakening/"">noting practice</a>, </strong>you are trying to consciously name or notice everything that happens in your consciousness. Introspective awareness is trained to very rapidly distinguish between everything that happens, but is not trained to maintain attention on any particular thing.</li><li><strong>In visualization practice, </strong>you might create a visual image in your mind, then use introspective awareness to examine the mental object that you&#x2019;ve created and compare it to what a real image would look like. This gives the subsystem creating the visualization feedback, and helps slowly develop a more realistic image.</li></ul><p>Going back to TMI-style introspective awareness, once you get it trained up, you can use it for various purposes. In particular, once you learn to maintain it during your daily life - and not just on the meditation couch - it will bring up more assumptions in your various schemas and mental models. Think of Richard paying attention to the assumptions behind his unwanted reactions and making them explicit, but as something that happens on a regular basis as the reactions come up. </p><p>Romeo Stevens <u><a href=""https://www.lesswrong.com/posts/ZawRiFR8ytvpqfBPX/the-hard-work-of-translation-buddhism"">described</a></u> what he called &#x201C;the core loop of Buddhism&#x201D;:</p><blockquote>So, what is the core loop?</blockquote><blockquote>It&apos;s basically cognitive behavioral therapy, supercharged with a mental state more intense than most pharmaceuticals.</blockquote><blockquote>There are two categories of practice, one for cultivating the useful mental state, the other uses that mental state to investigate the causal linkages between various parts of your perception (physical sensations, emotional tones, and mental reactions) which leads to clearing out of old linkages that weren&apos;t constructed well.</blockquote><blockquote>You have physical sensations in the course of life. Your nervous system reacts to these sensations with high or low valence (positive, negative, neutral) and arousal (sympathetic and parasympathetic nervous system activation), your mind reacts to these now-emotion-laden sensations with activity (mental image, mental talk) out of which you then build stories to make sense of your situation.</blockquote><blockquote>The key insight that drives everything is the knowledge (and later, direct experience) that this system isn&apos;t wired up efficiently. Importantly: I don&apos;t mean this in a normative way. Like you should wire it the way I say just because, but in the &apos;this type of circuit only needs 20 nand gates, why are there 60 and why is it shunting excess voltage into the anger circuits over there that have nothing to do with this computation?&apos; way. Regardless of possible arguments over an ultimately &apos;correct&apos; way to wire everything, there are very low hanging fruit in terms of improvements that will help you effectively pursue *any* other goal you set your mind to.</blockquote><p>Again, we saw an example of this with Richard. He had experienced his father as acting confident and as causing suffering to Richard and others; sensations which his mind has classified as negative. In order to avoid them, a model (story) was constructed saying that confidence is horrible, and behaviors (e.g. negative self-talk) were created to avoid appearing horrible. </p><p>Now, this caused problems down the line, making him motivated to try to appear more confident&#x2026; meaning that there was now a mechanism in his brain trying to prevent him from appearing confident, and another which considered this a problem and tried to make him more confident, in opposition to the first system. See what Romeo means when talking about circuits that only need 20 gates but are implemented using 60?</p><p>The article &#x201C;<u><a href=""http://bewelltuned.com/tune_your_motor_cortex"">tune your motor cortex</a></u>&#x201D; makes the following claims about muscle movement:</p><blockquote>Your motor cortex automatically learns to execute complex movements by putting together simpler ones, all the way down to control of individual muscles.</blockquote><blockquote>Because the process of learning happens organically, the resulting architecture of neural connections (you can think of them as &quot;hidden layers&quot; in machine learning terms) is not always perfectly suited to the task.</blockquote><blockquote>Some local optima of those neural configurations are hard to get out of, and constantly reinforced by using them.</blockquote><blockquote>There is some pressure for muscle control to be efficient, and the motor cortex is doing a &quot;good enough&quot; job at it, but tends to stop a fair bit from perfection.</blockquote><blockquote>By repeating certain movements and positions over and over again (e.g. during sitting work), we involuntarily strengthen connections between movements and muscles that don&apos;t make much sense lumped together.</blockquote><blockquote>E.g. control of shoulders might become spuriously wired together with control of thighs (both are often tense during sitting).</blockquote><p>There are various mental motions which are learned in basically the same way as physical motions are:</p><ul><li>You learn to <u><a href=""https://www.lesswrong.com/posts/7zQPYQB5EeaqLrhBh/subagents-neural-turing-machines-thought-selection-and"">calculate 12*13</a></u> by a technique such as first multiplying 10*13, keeping the result in your memory, calculating 2*13, and then adding the intermediate results together.</li><li>You learn that a particular memory makes you feel slightly unpleasant, and that <u><a href=""https://www.lesswrong.com/posts/u5RLu5F3zKTB3Qjnu/subagents-trauma-and-rationality"">flinching away from anything that would remind you of it</a></u> takes the pain away.</li><li>You learn that this also works on uncomfortable chores, <u><a href=""https://www.lesswrong.com/posts/EFQ3F6kmt4WHXRqik/ugh-fields"">teaching you to keep pushing the thought of them away</a></u>.</li><li>You learn that your father&#x2019;s behavior is painful to you, and that any confidence reminds you of that, so you <u><a href=""https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain"">learn negative self-talk</a></u> which blocks you from acting confident.</li><li>You learn that saying &#x201C;no&#x201D; to people reminds you of being punished for saying &#x201C;no&#x201D; to your parents, but that saying &#x201C;yes&#x201D; too often means that you are constantly fulfilling promises to other people - so you learn to <u><a href=""https://www.lesswrong.com/posts/oJwJzeZ6ar2Hr7KAX/subagents-akrasia-and-coherence-in-humans#Towers_of_protectors_as_a_method_for_coherence"">avoid situations where you would be asked anything</a></u>.</li><li>You learn that there&#x2019;s something you can do in your mind to stop feeling upset, so you start <u><a href=""https://www.lesswrong.com/posts/qmXqHKpgRfg83Nif9/how-to-ignore-your-emotions-while-also-thinking-you-re"">ignoring your emotions</a></u> and any information they might have.</li><li>You learn that if you feel bad about not getting the respect you want, thinking &#x201C;if only I was good enough at persuasion, I would get what I want&#x201D; <u><a href=""https://www.lesswrong.com/posts/E4zGWYzh6ZiG85b2z/the-curse-of-the-counterfactual#The__Nice_Guy__Paradigm"">gives you a sense of control</a></u> - even though this pattern also makes you feel personally at fault when you <em>don&#x2019;t</em> get what you want.</li><li>You learn that it&#x2019;s rewarding to punish people who have wronged, so you <em>always</em> want to punish someone when something goes wrong - even if there is <u><a href=""https://www.lesswrong.com/posts/E4zGWYzh6ZiG85b2z/the-curse-of-the-counterfactual#The_Bias"">nobody but reality</a></u> to punish.</li><li>You learn that it feels good to mentally punish someone who is munching too loud, but actually complaining about it would feel petty, and you&#x2019;ve learned that pettiness is frowned upon. So you also learn to block the impulse to say anything out loud, but continue to get increasingly angry about the sound, <u><a href=""https://www.lesswrong.com/posts/eRohP4gbxuBuhqTbe/attempted-telekinesis#The_case_of_the_munching_noises"">causing an escalating circle</a></u> of both the annoyance and the blocking ramping up in intensity.</li></ul><p>As with physical movements, these can form local optima that are hard to get out of. Many of them are learned in childhood, when your understanding of the world is limited. But new behaviors continue to <u><a href=""https://www.lesswrong.com/posts/NQgWL7tvAPgN2LTLn/spaghetti-towers"">build on top of them</a></u>, so you will eventually end up with a system which could use a lot of optimization.</p><p>If you have more introspective awareness of the exact processes that are happening in your mind, you can make more implicit assumptions conscious, causing your brain&#x2019;s built-in contradiction detector to notice when they contradict your later learning. Also, getting more feedback about what exactly is happening in your mind allows you to notice more <u><a href=""https://www.facebook.com/yudkowsky/posts/10151706498254228"">wasted motion</a></u> in general.</p><p>One particular effect is that, as <em><u><a href=""https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain"">Unlocking the Emotional Brain</a></u></em> notes, the mind often makes trade-offs where it causes itself some minor suffering in order to avoid a perceived greater suffering. For example, someone may feel guilt in order to motivate themselves, or experience self-doubt to avoid appearing too confident. By employing greater introspective awareness, one may find ways to achieve their goals <em>without</em> needing to experience any suffering in order to do so.</p><p>Of course, Buddhist meditation is not the only way to achieve this. Various therapies and techniques such as Focusing, <a href=""https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model"">Internal Family Systems</a>, <a href=""https://www.lesswrong.com/posts/mQmx4kQQtHeBip9ZC/internal-double-crux"">Internal Double Crux</a>, and so on, are also methods which use introspective awareness to reveal and refactor various assumptions. Increased introspective awareness from meditation tends to also boost the effectiveness of related techniques, as well as reveal more situations where they can be employed.</p><h1>If introspective awareness is so great, why don&#x2019;t we have it naturally?</h1><p>As with anything, there are tradeoffs involved. Having more introspective awareness can help fix a lot of issues&#x2026; but it also comes with risks, which I assume is the reason why we have <em>not</em> evolved to have a lot of it all the time.</p><p>First, it&#x2019;s worth noting that even for experienced meditators, intense emotional reactions tend to shut down introspective awareness. If one of the functions of e.g. fear and anxiety is to cause a rapid response, then excessive amounts of introspective awareness would slow down that response by reducing <u><a href=""https://www.lesswrong.com/posts/mELQFMi9egPn5EAjK/my-attempt-to-explain-looking-insight-meditation-and"">cognitive fusion</a></u>. Many emotions seem to inhibit many competing processes from accessing consciousness, so that you can deal with the situation at hand. </p><p>Another consideration involves traumatic memories. In the beginning of the article, I suggested that anxiety is a special kind of mental object which activates particular behaviors. In general, different emotional states have specific kinds of behaviors and activities associated with them - meaning that if you have some memories which are <em>really</em> painful, they can become overwhelming, <u><a href=""https://www.lesswrong.com/posts/7zQPYQB5EeaqLrhBh/subagents-neural-turing-machines-thought-selection-and"">making it necessary to block them</a></u> in order to carry on with your normal life. Meditation can be helpful for working through your trauma, but it can also <u><a href=""https://www.facebook.com/Xuenay/posts/10158478256833662"">bring it up before you are ready for it</a></u>, to the point of <u><a href=""https://www.dharmaoverground.org/discussion/-/message_boards/view_message/10415270#_19_message_10490025"">requiring professional psychotherapy</a></u> to get through. If you are better at noticing all kinds of subtle details in your mind, it also becomes easier to notice anything that would remind you of things you don&#x2019;t want to remember. A <em>decrease</em> in introspective awareness seems to be a common trauma symptom, as this helps block the unpleasant memories from being too easily triggered.</p><p>I have also heard advanced meditators mention that increased introspective awareness makes it difficult to push away pangs of conscience that they would otherwise have ignored, causing practical problems. For example, people have said that they are no longer able to eat animal products or tell white lies.</p><p>On the other hand, extended concentration practice can also make it easier to <em>block</em> things which you would be better off not blocking. </p><p>So far, this article has mostly focused on using introspective awareness to notice the <em>content</em> of your thoughts. But you can also use it to notice the <em>structure</em> of the higher-level processes generating your thoughts. Part of how you develop concentration ability is by maintaining introspective awareness of the fact that being able to concentrate on just one thing feels more pleasant than having your attention jump between many different things. This can give you an improved ability to choose what you are concentrating on&#x2026; but also to selectively exclude anything unpleasant from your mind.</p><p>For example, there was an occasion when I needed to do some work, but also had intense anxiety about not wanting to; intense enough that it would normally have made it impossible for me to focus on it. So then I <em>tried</em> to work, and let my introspective awareness observe the feeling of head-splitting agony from my attention alternating between the work and the desire not to&#x2026; and to also notice that whenever my attention was on the work, I felt temporarily better.</p><p>After a while of this, the anxiety started to get excluded from my consciousness, until it suddenly dropped away completely - as if some deeper process had judged it useless and revoked its access to consciousness. And while this allowed me to do the work that I needed to, it also felt internally violent, and like it would be too easy to repress any unpleasant thoughts using it. I still use this kind of technique on occasion when I need to concentrate on something, but I try to be cautious about it.</p><p>The negative side of being able to get better feedback about your mental processes, is that you can also get better feedback on exactly how pleasant wireheading feels. If you like to imagine pleasant things, you can get better and better at imagining pleasant things, and excluding any worries about it from your consciousness. Meditation teacher <u><a href=""https://www.mctb.org/mctb2/table-of-contents/part-vi-my-spiritual-quest/61-crazy/"">Daniel Ingram warns</a></u>:</p><blockquote>Strong insight and concentration practice, even when that practice wasn&#x2019;t dedicated to the powers, can make people go temporarily or permanently (or for the rest of that lifetime) psychotic. The more the practice involves creating experiences that diverge significantly from what I will crudely term &#x201C;consensus reality&#x201D;, and the longer one engages in these practices, the more likely prolonged difficulties are. It is of note that a significant number of the primary propagators of the Western magickal traditions became moderately nuts towards the ends of their lives.</blockquote><blockquote>As one Burmese man said to Kenneth, &#x201C;My brother does concentration practice. You know, sometimes they go a little mad!&#x201D; He was talking about what can sometimes happen when people get into the powers. [...] </blockquote><blockquote>I remember a letter from a friend who was on a long retreat in Burma and was supposed to be doing insight practices but had slipped into playing with these sorts of experiences. He was now fascinated by his ability to see spirit animals and other supernormal beings and was having regular conversations with some sort of low-level god that kept telling him that he was making excellent progress in his insight practice&#x2014;that is, exactly what he wanted to hear. However, the fact that he was having stable visionary experiences and was buying into their content made it abundantly clear that he wasn&#x2019;t doing insight practices at all, but was lost in and being fooled by these.</blockquote><p>Now, it should be pointed out that &#x201C;being able to exclude anything unpleasant from your consciousness&#x201D; is only going to be a worry for advanced practitioners who spend a lot of time on the kind of practice that inclines you towards these kinds of risks. Before you get to the point of something like this being a risk, you will get to resolve a lot of internal conflicts and old issues first.</p><p>Here is Culadasa, the author of <em>The Mind Illuminated,</em> <u><a href=""https://deconstructingyourself.com/transcript-culadasa-on-meditation-and-therapy.html"">being interviewed</a></u> about this kind of a &#x201C;first you resolve a lot of issues, but then you can get the ability to push down the rest&#x201D; dynamic:</p><blockquote>Michael Taft: &#x2026; and you&#x2019;re using the meditation practice to help work with your stuff. But what about the other case that we both know of where people have reached very high levels of meditative capacity, they&#x2019;ve got a lot of insight, maybe they&#x2019;re at some level of awakening, and they seem to have, in a way, missed a whole pocket of material, or several pockets of material. It&#x2019;s like they think they&#x2019;re doing fine, but maybe everyone around them is aware that they&#x2019;ve got these behavior patterns that do not seem awake at all. And yet the meditation has somehow missed that.</blockquote><blockquote>Culadasa: Yes, yes. [...] ... there seems to be a certain level of the stuff that we&#x2019;re talking about that it&#x2019;s necessary to deal with to achieve awakening, but it&#x2019;s sort of a minimal level. [...] What I think that is indicative of is that if that hasn&#x2019;t been sufficiently dealt with earlier, it has to get dealt with in one way or another at that point. That doesn&#x2019;t necessarily mean that it&#x2019;s going to get resolved; it may just get reburied a little more deeply.</blockquote><blockquote>Michael Taft: Pushed out of the way.</blockquote><blockquote>Culadasa: Yeah, pushed out of the way, or bypassed in some way. That allows a person to go ahead and [progress] and it&#x2019;s unrealistic to think that everything has been resolved. [...] a lot of the things that change [...] actually help to push these things aside, to bypass them in one way or another, whereas before somebody has [made as much progress] these would have been sufficiently problematic in their life that, in one way or another, they would be aware of them, whether or not they did anything about them or were at a place of just taking for granted that I have these, quote, &#x201C;personality characteristics&#x201D; that are a bit difficult.</blockquote><p>I used to be very enthusiastic about TMI&#x2019;s meditation system. I still consider it important and useful to make progress on, but am slightly more guarded after some of my own experiences, hearing about the experience of a friend who reached a high level in it, reading some critiques of its tendency to emphasize awareness of positive experiences [<u><a href=""https://vajrayananow.com/2019/07/05/the-mind-illuminated-a-journal-purity-and-impurity/"">1</a></u> <u><a href=""https://parletre.wordpress.com/2019/08/24/reflections-on-the-mind-illuminated/"">2</a></u>], and considering both the interview quoted above and <u><a href=""https://www.reddit.com/r/TheMindIlluminated/comments/csow9f/important_message_from_the_dharma_treasure_board/"">Culadasa&#x2019;s subsequent actions</a></u>. (That said, the focus on positive experiences can be a useful counterbalance for people who start off with an overall negative stance towards life.)</p><p>I continue to practice it, and would generally find it safe until you get to around the sixth or so of <u><a href=""https://www.consciouslifestylemag.com/ten-stages-of-meditation-complete-guide/"">its ten stages</a></u>, at which point I would suggest starting to exercise some caution. Off the couch, I mostly don&#x2019;t do much concentration practice (except in a context where I would need to concentrate anyway). Rather I try to focus my introspective awareness towards just observing my mind without actively interfering with it, <u><a href=""https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model"">Internal Family Systems</a></u> -style practice, and other activities that do not seem to risk excluding too much unpleasant material.</p><p>Finally, developing too much awareness into your mind may cause you to start noticing contradictions between how you thought it worked, and how it actually works. I suspect that a part of how our brains have evolved to operate, <em>relies on</em> those differences going unnoticed. This gets us to the topic of enlightenment, which I have not yet discussed, but will do in my next post.</p><p><em>Thanks to Maija Haavisto, Lumi Pakkanen and Romeo Stevens for comments on an earlier draft. </em></p>",Kaj_Sotala,kaj_sotala,Kaj_Sotala,
7GEviErBXcjJsbSeD,AI Alignment Research Overview (by Jacob Steinhardt),ai-alignment-research-overview-by-jacob-steinhardt,https://www.lesswrong.com/posts/7GEviErBXcjJsbSeD/ai-alignment-research-overview-by-jacob-steinhardt,2019-11-06T19:24:50.240Z,44,11,0,False,False,https://docs.google.com/document/d/1FbTuRvC4TFWzGYerTKpBU7FJlyvjeOvVYF2uYNFSlOc/edit,"<p><em>I'm really excited to see someone outline all the work they think needs solving in AI alignment - to describe what the problem looks like, what a solution looks like, and what work has been done so far. Especially from Jacob, who is a coauthor of the Concrete Problems in AI Safety paper.</em></p><p><em>Below, I've included some excerpts from doc. I've included the introduction, the following section describing the categories of technical work, and some high-level information from the long sections on 'technical alignment problem' and the 'detecting failures in advance'.</em></p><hr class=""dividerBlock""><h2>Introduction</h2><p>This document gives an overview of different areas of technical work that seem necessary, or at least desirable, for creating safe and aligned AI systems. The focus is on safety and alignment of powerful AI systems, i.e. systems that may exceed human capabilities in a broad variety of domains, and which likely act on a large scale. Correspondingly, there is an emphasis on approaches that seem scalable to such systems.</p><p>By “aligned”, I mean that the actions it pursues move the world towards states that humans want, and away from states that humans don’t want. Some issues with this definition are that different humans might have different preferences (I will mostly ignore this issue), and that there are differences between stated preferences, “revealed” preferences as implied by actions, and preferences that one endorses upon reflection (I won’t ignore this issue).</p><p>I think it is quite plausible that some topics are missing, and I welcome comments to that regard. My goal is to outline a critical mass of topics in enough detail that someone with knowledge of ML and some limited familiarity with AI alignment as an area would have a collection of promising research directions, a mechanistic understanding of why they are promising, and some pointers for what work on them might look like.</p><p>To that end, below I outline four broad categories of technical work: <strong>technical alignment</strong> (the overcoming of conceptual or engineering issues needed to create aligned AI), <strong>detecting failures </strong>(the development of tools for proactively assessing the safety/alignment of a system or approach), <strong>methodological understanding</strong> (best practices backed up by experience), and <strong>system-building</strong> (how to tie together the three preceding categories in the context of many engineers working on a large system). These are described in more detail in the next section.</p><p>In each section I give examples of problems we might want to solve. I imagine these in the context of future powerful AI systems, which means that most of the concrete scenarios are speculative, vague, and likely incorrect if interpreted as a prediction about the future. If I were to give the strongest justification for the research topics below, I would instead focus on near-future and existing systems, which already exhibit many of the issues I discuss. Nevertheless, I think this imaginative exercise can be helpful both for stimulating research and for keeping the focus on scalable solutions.</p><p><strong>Caveats.</strong> I found it difficult to write a research overview of a field as nascent as AI alignment, as anything I could write sounded either too authoritative relative to my confidence, or so full of caveats and qualifications as to be unreadable. I settled for eliding many of the qualifications and providing this single caveat up front: that this document reflects an imperfect snapshot of my current thinking, that it expresses many ideas more sloppily than I would usually feel comfortable putting into writing, and that I hope readers will forgive this sloppiness in the service of saying <em>something</em> about a topic that I feel is important.</p><p>This document is not meant to be a description of <em>my personal interests</em>, but rather of potentially promising topics within a field I care about. My own interests are neither a subset nor superset of the topics in this document, although there is high overlap. Even confined to AI alignment, this document is out-of-date and omits some of my recent thinking on economic aspects of ML.</p><p>Finally, I make a number of claims below about what research directions I think are promising or un-promising. Some of these claims are likely wrong, and I could even imagine changing my mind after 1 hour of conversation with the right person. I decided that this document would be more informative and readable if I gave my unfiltered take (rather than only opinions I thought I would likely defend upon consideration), but the flip side is that if you think I’m wrong about something, you should let me know!</p><h2>Categories of technical work</h2><p>In this document, I will discuss four broad categories of technical work:</p><p><strong><u>Technical alignment problem.</u></strong> Research on the “technical alignment problem” either addresses conceptual obstacles to making AI aligned with humans (e.g. robustness, reward mis-specification), or creates tools and frameworks that aid in making AI aligned (e.g. scalable reward generation).</p><p><strong><u>Detecting failures in advance.</u></strong> Independently of having solved various alignment problems, we would like to have ways of probing systems / blueprints of systems to know whether they are likely to be safe. Example topics include interpretability, red-teaming, or accumulating checklists of failure modes to watch out for.</p><p><strong><u>Methodological understanding.</u></strong>  There is relatively little agreement or first-hand knowledge of how to make systems aligned or safe, and even less about which methods for doing so will scale to very powerful AI systems. I am personally skeptical of our ability to get alignment right based on purely abstract arguments without also having a lot of methodological experience, which is why I think work in this category is important. An example of a methodology-focused document is Martin Zinkevich’s <u><a href=""http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf"">Rules of Reliable ML</a></u>, which addresses reliability of existing large systems.</p><p><strong><u>System-building.</u></strong> It is possible that building powerful AI will involve a large engineering effort (say, 100+ engineers, 300k+ lines of code). In this case we need a framework for putting many components together in a safe way.</p><h2>Technical alignment problem</h2><p>We would ideally like to build AI that acts according to some specification of human values, and that is robust both to errors in the specification and to events in the world. To achieve this robustness, the system likely needs to represent uncertainty about both its understanding of human values and its beliefs about the world, and to act appropriately in the face of this uncertainty to avoid any catastrophic events.</p><p>I split the technical alignment problem correspondingly into four sub-categories:</p><p><strong><u>Scalable reward generation.</u></strong> Powerful AI systems will potentially have to make decisions in situations that are foreign to humans or otherwise difficult to evaluate---for instance, on scales far outside human experience, or involving subtle but important downstream consequences. Since modern ML systems are primarily trained through human-labeled training data (or more generally, human-generated reward functions), this presents an obstacle to specifying which decisions are good in these situations. Scalable reward generation seeks to build processes for generating a good reward function.</p><p><strong><u>Reward learning.</u></strong> Many autonomous agents seek to maximize the expected value of some reward function (or more broadly, to move towards some specified goal state / set of states). Optimizing against the reward function in this way can cause even slight errors in the reward to lead to large errors in behavior--typically, increased reward will be well-correlated with human-desirability for a while, but will become anti-correlated after a point. Reward learning seeks to reason about differences between the observed (proxy) reward and the true reward, and to converge to the true reward over time.</p><p><strong><u>Out-of-distribution robustness</u></strong> is the problem of getting systems to behave well on inputs that are very different from their training data. This might be done by a combination of transfer learning (so the system works well in a broader variety of situations) and having more uncertainty in the face of unfamiliar/atypical inputs (so the system can at least notice where it is likely to not do well).</p><p><strong><u>Acting conservatively.</u></strong> Safe outcomes are more likely if systems can notice situations where it is unclear how to act, and either avoid encountering them, take actions that reduce the uncertainty, or take actions that are robustly good. This would, for instance, allow us to specify an ambiguous reward function that the system could clarify as needed, rather than having to think about every possible case up-front. </p><p>Acting conservatively interfaces with reward learning and out-of-distribution robustness, as the latter two focus on noticing uncertainty while the former focuses on what to do <em>given</em> the uncertainty. Unfortunately, current methods for constructing uncertainty estimates seem inadequate to drive such decisions, and even given a good uncertainty estimate little work has been done on how the system should use it to shape its actions.</p><p><strong>A toy framework. </strong>Conceptually, it may be useful to think in terms of the standard rational agent model, where an agent has a value function or utility function <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span>, and beliefs <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span>, and then takes actions <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> that maximize the expected value of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> under <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span> (conditioned on the action <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span>). Failures of alignment could come from incorrect beliefs <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span>, or a value function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> that does not lead to what humans want. Out-of-distribution robustness seeks to avoid or notice problems with <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span>, while scalable reward generation seeks to produce accurate information about some value function <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""V""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;"">V</span></span></span></span></span></span> that is aligned with humans. Reward learning seeks to correct for inaccuracies in the reward generation process, as well as the likely limited amount of total data about rewards. Finally, acting conservatively takes into account the additional uncertainty due to acting out-of-distribution and having a learned reward function, and seeks to choose actions in a correspondingly conservative manner.</p><p></p><figure><img src=""https://lh5.googleusercontent.com/5-T3fsAs2p1oTn0PcqR35cvyKV7dQdMBfyMh58A4JXBymijy_yyAVV3L8Wun6bK9NDmBot_pwOFH-JokJJNglfs-ERnKAFXmeNHcZijMl7kln2HgQdbXBfDRGR6HYnvTnJzi_jD1"" class=""draft-image "" style=""width:624%""></figure><p></p><p>In an RL setting where we take actions via a learned policy, we can tell the same story but with a slightly modified diagram. Instead of an action <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""A""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">A</span></span></span></span></span></span> we have a learned policy <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""θ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">θ</span></span></span></span></span></span></span></span>, and instead of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P*""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span></span></span></span></span> and <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label="" \tilde{P}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.153em; padding-bottom: 0.06em; padding-left: 0.305em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">~</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span></span></span></span></span></span> denoting beliefs, they denote distributions over environments (<span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""P*""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span></span></span></span></span> is the true on-policy environment at deployment time, while <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\tilde{P}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-texatom""><span class=""mjx-mrow""><span class=""mjx-munderover""><span class=""mjx-stack""><span class=""mjx-over"" style=""height: 0.153em; padding-bottom: 0.06em; padding-left: 0.305em;""><span class=""mjx-mo"" style=""vertical-align: top;""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.004em; padding-bottom: 0.298em;"">~</span></span></span><span class=""mjx-op""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;"">P</span></span></span></span></span></span></span></span></span></span></span> is the distribution of training environments).</p><p><strong>Other topics. </strong>Beyond the topics above, the problem of <strong><u>counterfactual reasoning</u></strong> cuts across multiple categories and seems worth studying on its own. There may be other important categories of technical work as well.</p><hr class=""dividerBlock""><h2>Detecting failures in advance</h2><p>The previous section lays out a list of obstacles to AI alignment and technical directions for working on them. This list may not be exhaustive, so we should also develop tools for discovering new potential alignment issues. Even for the existing issues, we would like ways of being more confident that we have solved them and what sub-problems remain.</p><p>While machine learning often prefers to hew close to empirical data, much of the roadmap for AI alignment has instead followed from more abstract considerations and thought experiments, such as asking “What would happen if this reward function were optimized as far as possible? Would the outcome be good?” I actually think that ML undervalues this abstract approach and expect it to continue to be fruitful, both for pointing to useful high-level research questions and for analyzing concrete systems and approaches.</p><p>At the same time, I am uncomfortable relying solely on abstract arguments for detecting potential failures. Rigorous empirical testing can make us more confident that a problem is actually solved and expose issues we might have missed. Finding concrete instantiations of a problem can both more fruitfully direct work and convince a larger set of people to care about it (as in the case of adversarial examples for images). More broadly, empirical investigations have the potential to reveal new issues that were missed under purely abstract considerations.</p><p>Two more empirically-focused ways of detecting failures are <strong><u>model probing/visualization</u></strong> and <strong><u>red-teaming</u>, </strong>discussed below. Also valuable is <strong>examining trends</strong> in ML. For instance, it looks to me like reward hacking in real deployed systems is becoming a bigger issue over time; this provides concrete instances of the problem to examine for insight, gives us a way to measure how well we’re doing at the problem, and helps rally a community around the problem. Examining trends is also a good way to take an abstract consideration and make it more concrete.</p>",Benito,benito,Ben Pace,
hPJMum5CNH5MKe27C,"[AN #72]: Alignment, robustness, methodology, and system building as research priorities for AI safety",an-72-alignment-robustness-methodology-and-system-building,https://www.lesswrong.com/posts/hPJMum5CNH5MKe27C/an-72-alignment-robustness-methodology-and-system-building,2019-11-06T18:10:01.604Z,26,7,4,False,False,,"<p>Find all Alignment Newsletter resources <u><a href=""http://rohinshah.com/alignment-newsletter/"">here</a></u>. In particular, you can <u><a href=""http://eepurl.com/dqMSZj"">sign up</a></u>, or look through this <u><a href=""https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing"">spreadsheet</a></u> of all summaries that have ever been in the newsletter. I&apos;m always happy to hear feedback; you can send it to me by replying to this email.</p><p>Audio version <u><a href=""http://alignment-newsletter.libsyn.com/alignment-newsletter-72"">here</a></u> (may not be up yet).</p><h2><strong>Highlights</strong></h2><p><u><a href=""https://docs.google.com/document/d/1FbTuRvC4TFWzGYerTKpBU7FJlyvjeOvVYF2uYNFSlOc/edit"">AI Alignment Research Overview</a></u> <em>(Jacob Steinhardt)</em> (summarized by Dan H): It has been over three years since <u><em><a href=""https://arxiv.org/abs/1606.06565"">Concrete Problems in AI Safety</a></em></u>. Since that time we have learned more about the structure of the safety problem. This document represents an updated taxonomy of problems relevant for AI alignment. Jacob Steinhardt decomposes the remaining technical work into &#x201C;technical alignment (the overcoming of conceptual or engineering issues needed to create aligned AI), detecting failures (the development of tools for proactively assessing the safety/alignment of a system or approach), methodological understanding (best practices backed up by experience), and system-building (how to tie together the three preceding categories in the context of many engineers working on a large system).&#x201D;</p><p>The first topic under &#x201C;technical alignment&#x201D; is &#x201C;Out-of-Distribution Robustness,&#x201D; which receives more emphasis than it did in Concrete Problems. Out-of-Distribution Robustness is in part motivated by the fact that transformative AI will lead to substantial changes to the real world, and we should like our systems to perform well even under these large and possibly rapid data shifts. Specific subproblems include <em>some</em> work on adversarial examples and out-of-distribution detection. Next, the problem of Reward Learning is described. For this, there are challenges including learning human values and ensuring those lossily represented human values can remain aligned under extreme optimization. While we have attained more conceptual clarity about reward learning since <em>Concrete Problems</em>, reward learning still remains largely &#x201C;uncharted,&#x201D; and it is still not clear &#x201C;how approach the problem.&#x201D; The next section on Scalable Reward Generation points out that, in the future, labeling meaning or providing human oversight will prove increasingly difficult. Next, he proposes that we ought to study how to make systems &#x201C;act conservatively,&#x201D; such as endowing systems with the ability to activate a conservative fallback routine when they are uncertain. The final topic under technical alignment is Counterfactual Reasoning. Here one possible direction is generating a family of simulated environments to generate counterfactuals.</p><p>The &#x201C;technical alignment&#x201D; section is the majority of this document. Later sections such as &#x201C;Detecting Failures in Advance&#x201D; highlight the importance of deep neural network visualization and recent model stress-test datasets. &#x201C;Methodological Understanding&#x201D; suggests that we are more likely to build aligned AI systems if we improve our best practices for building and evaluating models, and &#x201C;System Building&#x201D; speculates about how to do this for future multi-faceted ML systems.</p><p><strong>Dan H&apos;s opinion:</strong> This is a welcome update to <em>Concrete Problems</em> since it is slightly more concrete, current, and discusses improving safety in both deep learning and RL rather than mostly RL. While the document mentions many problems, the set of problems retains precision and fortunately does not include every capabilities concern that may possibly one day impact safety. A takeaway is that value learning and model transparency still need groundwork, but fortunately other problems including out-of-distribution robustness are more concretized and mostly need time and continued effort.</p><p><strong>Rohin&apos;s opinion:</strong> One thing I particularly like about this agenda is that the connection to AI <em>alignment</em> is significantly clearer than in <em>Concrete Problems</em>.</p><h1><strong>Technical AI alignment</strong></h1><h3><strong>Iterated amplification</strong></h3><p><u><a href=""https://ought.org/updates/2019-10-28-progress-update"">Ought Progress Update October 2019</a></u> <em>(Jungwon Byun and Andreas Stuhlm&#xFC;ller)</em> (summarized by Rohin): While this update provides details about Ought as a whole, I will focus only on the research they&apos;ve done. As a reminder, Ought&apos;s goal is to understand how we can delegate hard questions to machine and human experts. They initially focused on <u><a href=""https://www.alignmentforum.org/posts/DFkGStzvj3jgXibFG/factored-cognition"">Factored Cognition</a></u> (<u><a href=""https://mailchi.mp/6751e45fbb48/alignment-newsletter-36"">AN #36</a></u>), where each question was recursively decomposed into subquestions that would help <em>find</em> the answer. They now call this &quot;Factored Generation&quot;, and use &quot;Factored Cognition&quot; as the umbrella term for any approach that helps answer hard questions using some kind of decomposition.</p><p>While Ought has run some ML experiments aimed at automating decompositions, they have primarily worked on human experiments for <u><a href=""https://ought.org/presentations/delegating-cognitive-work-2019-06"">Factored Evaluation</a></u> (<u><a href=""https://mailchi.mp/4a1b3c4249ae/an-62are-adversarial-examples-caused-by-real-but-imperceptible-features"">AN #62</a></u>), where the decompositions are used to help <em>evaluate</em> answers. They are focusing on evaluating answers instead of finding answers for a few reasons. First, there may already exist experts whose answers we can use: this can be directly plugged into Factored Evaluation, but not Factored Generation. Second, evaluation is often easier than generation. Third, factored evaluation is more amenable to time-saving tricks like only focusing on a single branch of the tree (as in <u><a href=""https://blog.openai.com/debate/"">AI safety via debate</a></u> (<u><a href=""https://mailchi.mp/0ae5d69de63b/alignment-newsletter-5"">AN #5</a></u>)). Finally, when training ML systems, if a model is unable to exactly imitate the experts, we need something that can distinguish between better and worse behavior, which is possible with Factored Evaluation but not Factored Generation. (See also <u><a href=""https://ai-alignment.com/against-mimicry-6002a472fc42"">Against Mimicry</a></u>.)</p><p>The experiments involve a judge trying to decide which of two answers to a question is best, where one answer is provided by an honest expert and one by a malicious expert. (Subquestions may also get different answers from the two experts.) The goal is to find a setup where the judge reliably picks the honest answer, regardless of how powerful the malicious expert is: if this could be established, it would be strong evidence that the setup incentivizes honest answers. Of course, this requires us to quantify over all malicious strategies, but humans may not find the best malicious strategies. To mitigate this, the experiments provide the malicious expert with lots of advantages that the honest one doesn&apos;t have, to simulate very powerful malicious experts.</p><p>They have already learned from their experiments. Initially, they hoped participants would develop good meta-level strategies for determining the truth. (Meta-level here means that the strategies would generalize to other domains, e.g. a heuristic of always splitting an answer into separate claims and asking for the evidence for each claim separately.) They found that these strategies <em>don&apos;t</em> emerge organically, and so are planning to spend concentrated staff time on finding good strategies. They also found that malicious experts sometimes won due to avoidable mistakes, and are hoping to eliminate this by ensembling work from multiple people for increased robustness.</p><p><strong>Rohin&apos;s opinion:</strong> This is distinct progress since the last update, though I think the experiments are still exploratory enough that it&apos;s hard to have any big takeaways. The difficulty of generating good strategies suggests that it&apos;s particularly important that we train our human overseers (as suggested in <u><a href=""https://blog.openai.com/ai-safety-needs-social-scientists/"">AI Safety Needs Social Scientists</a></u> (<u><a href=""https://mailchi.mp/260cd31d5f03/alignment-newsletter-47"">AN #47</a></u>)) to provide the right kind of feedback, for example if we would like them to reward only <u><a href=""https://www.alignmentforum.org/posts/fkLYhTQteAu5SinAc/corrigibility"">corrigible reasoning</a></u> (<u><a href=""https://mailchi.mp/bbd47ba94e84/alignment-newsletter-35"">AN #35</a></u>). I&apos;m particularly excited for the next update, where we could see experiments powerful enough to come to more solid conclusions.</p><h3><strong>Learning human intent</strong></h3><p><u><a href=""https://hrilab.tufts.edu/publications/kasenbergetal18aies.pdf"">Norms, Rewards, and the Intentional Stance: Comparing Machine Learning Approaches to Ethical Training</a></u> <em>(Daniel Kasenberg et al)</em> (summarized by Asya) (H/T Xuan Tan): This paper argues that <em>norm inference</em> is a plausible alternative to inverse reinforcement learning (IRL) for teaching a system what people want. Existing IRL algorithms rely on the <em>Markov assumption</em>: that the next state of the world depends only on the previous state of the world and the action that the agent takes from that state, rather than on the agent&#x2019;s entire history. In cases where information about the past matters, IRL will either fail to infer the right reward function, or will be forced to make challenging guesses about what past information to encode in each state. By contrast, <em>norm inference</em> tries to infer what (potentially temporal) propositions encode the reward of the system, keeping around only past information that is relevant to evaluating potential propositions. The paper argues that norm inference results in more interpretable systems that generalize better than IRL -- systems that use norm inference can successfully model reward-driven agents, but systems that use IRL do poorly at learning temporal norms.</p><p><strong>Asya&apos;s opinion:</strong> This paper presents an interesting novel alternative to inverse reinforcement learning and does a good job of acknowledging potential objections. Deciding whether and how to store information about the past seems like an important problem that inverse reinforcement learning has to reckon with. My main concern with norm inference, which the paper mentions, is that optimizing over all possible propositions is in practice extremely slow. I don&apos;t anticipate that norm inference will be a performance-tractable strategy unless a lot of computation power is available.</p><p><strong>Rohin&apos;s opinion:</strong> The idea of &quot;norms&quot; used here is very different from what I usually imagine, as in e.g. <a href=""https://www.alignmentforum.org/posts/eBd6WvzhuqduCkYv3/following-human-norms"">Following human norms</a> (<a href=""https://mailchi.mp/f6488137d76c/alignment-newsletter-42"">AN #42</a>). Usually, I think of norms as imposing a constraint upon policies rather than defining an optimal policy, (often) specifying what not to do rather than what to do, and being a property of groups of agents, rather than of a single agent. (See also <a href=""https://www.alignmentforum.org/posts/eBd6WvzhuqduCkYv3/following-human-norms#ujma2pWoH7ibhdog2"">this comment</a>.) The &quot;norms&quot; in this paper don&apos;t satisfy any of these properties: I would describe their norm inference as performing IRL with history-dependent reward functions, with a strong inductive bias towards &quot;logical&quot; reward functions (which comes from their use of Linear Temporal Logic). Note that some inductive bias is necessary, as without inductive bias history-dependent reward functions are far too expressive, and nothing could be reasonably learned. I think despite how it&apos;s written, the paper should be taken not as a denouncement of IRL-the-paradigm, but a proposal for better IRL algorithms that are quite different from the ones we currently have.</p><p><u><a href=""https://arxiv.org/abs/1908.01007"">Improving Deep Reinforcement Learning in Minecraft with Action Advice</a></u> <em>(Spencer Frazier et al)</em> (summarized by Asya): This paper uses maze-traversal in Minecraft to look at the extent to which human advice can help with <em>aliasing</em> in 3D environments, the problem where many states share nearly identical visual features. The paper compares two advice-giving algorithms that rely on neural nets which are trained to explore and predict the utilities of possible actions they can take, sometimes accepting human advice. The two algorithms differ primarily in whether they provide advice for the current action, or provide advice that persists for several actions.</p><p>Experimental results suggest that both algorithms, but especially the one that applies to multiple actions, help with the problem of 3D aliasing, potentially because the system can rely on the movement advice it got in previous timesteps rather than having to discern tricky visual features in the moment. The paper also varies the frequency and accuracy of the advice given, and finds that receiving more advice significantly improves performance, even if that advice is only 50% accurate.</p><p><strong>Asya&apos;s opinion:</strong> I like this paper, largely because learning from advice hasn&apos;t been applied much to 3D worlds, and this is a compelling proof of concept. I think it&apos;s also a noteworthy though expected result that advice that sticks temporally helps a lot when the ground truth visual evidence is difficult to interpret.</p><h3><strong>Forecasting</strong></h3><p><u><a href=""https://www.lesswrong.com/posts/ZwSrTsP3YkgnmHWnJ/two-explanations-for-variability-in-human-abilities"">Two explanations for variation in human abilities</a></u> <em>(Matthew Barnett)</em> (summarized by Flo): How quickly might AI exceed human capabilities? One piece of evidence is the variation of intelligence within humans: if there isn&#x2019;t much variation, we might expect AI not to stay at human level intelligence for long. It has been argued that variation in human cognitive abilities is small compared to such variation for arbitrary agents. However, the variation of human ability in games like chess seems to be quite pronounced, and it took chess computers more than forty years to transition from beginner level to beating the best humans. The blog post presents two arguments to reconcile these perspectives:</p><p>First, <strong>similar minds could have large variation in learning ability</strong>: If we break a random part of a complex machine, it might perform worse or stop working altogether, even if the broken machine is very similar to the unbroken one. Variation in human learning ability might be mostly explainable by lots of small &quot;broken parts&quot; like harmful mutations.</p><p>Second, <strong>small variation in learning ability</strong> can be consistent with <strong>large variation in competence</strong>, if the latter is explained by variation in another factor like practice time. For example, a chess match is not very useful to determine who&apos;s smarter, if one of the players has played a lot more games than the other. This perspective also reframes AlphaGo&apos;s superhumanity: the version that beat Lee Sedol had played around 2000 times as many games as him.</p><p><strong>Flo&apos;s opinion:</strong> I liked this post and am glad it highlighted the distinction between learning ability and competence that seems to often be ignored in debates about AI progress. I would be excited to see some further exploration of the &quot;broken parts&quot; model and its implication about differing variances in cognitive abilities between humans and arbitrary intelligences.</p><h3><strong>Miscellaneous (Alignment)</strong></h3><p><u><a href=""https://www.alignmentforum.org/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety"">Chris Olah&#x2019;s views on AGI safety</a></u> <em>(Evan Hubinger)</em> (summarized by Matthew): This post is Evan&apos;s best attempt to summarize <u><a href=""https://colah.github.io/about.html"">Chris Olah</a></u>&apos;s views on how transparency is a vital component for building safe artificial intelligence, which he distinguishes into four separate approaches:</p><p>First, we can apply interpretability to audit our neural networks, or in other words, catch problematic reasoning in our models. Second, transparency can help safety by allowing researchers to deliberately structure their models in ways that systematically work, rather than using machine learning as a black box. Third, understanding transparency allows us to directly incentivize for transparency in model design and decisions -- similar to how we grade humans on their reasoning (not just the correct answer) by having them show their work. Fourth, transparency might allow us to reorient the field of AI towards microscope AI: AI that gives us new ways of understanding the world, enabling us to be more capable, without itself taking autonomous actions.</p><p>Chris expects that his main disagreement with others is whether good transparency is possible as models become more complex. He hypothesizes that as models become more advanced, they will counterintuitively become more interpretable, as they will begin using more crisp human-relatable abstractions. Finally, Chris recognizes that his view implies that we might have to re-align the ML community, but he remains optimistic because he believes there&apos;s a lot of low-hanging fruit, research into interpretability allows low-budget labs to remain competitive, and interpretability is aligned with the scientific virtue to understand our tools.</p><p><strong>Matthew&apos;s opinion:</strong> Developing transparency tools is currently my best guess for how we can avoid deception and catastrophic planning in our AI systems. I&apos;m most excited about applying transparency techniques via the first and third routes, which primarily help us audit our models. I&apos;m more pessimistic about the fourth approach because it predictably involves restructuring the incentives for machine learning as a field, which is quite difficult. My opinion might be different if we could somehow coordinate the development of these technologies.</p><p><u><a href=""https://www.alignmentforum.org/posts/CjW4axQDqLd2oDCGG/misconceptions-about-continuous-takeoff"">Misconceptions about continuous takeoff</a></u> <em>(Matthew Barnett)</em> (summarized by Flo): This post attempts to clarify the author&apos;s notion of continuous AI takeoff, defined as the growth of future AI capabilities being in line with extrapolation from current trends. In particular, that means that no AI project is going to bring sudden large gains in capabilities compared to its predecessors.</p><p>Such a continuous takeoff does not necessarily have to be slow. For example, generative adversarial networks have become better quite rapidly during the last five years, but progress has still been piecemeal. Furthermore, exponential gains, for example due to recursive self-improvement, can be consistent with a continuous takeoff, as long as the gains from one iteration of the improvement process are modest. However, this means that a continuous takeoff does not preclude large power differentials from arising: slight advantages can compound over time and actors might use their lead in AI development to their strategic advantage even absent discontinuous progress, much like western Europe used its technological advantage to conquer most of the world.</p><p>Knowing whether or not AI takeoff happens continuously is important for alignment research: A continuous takeoff would allow for more of an attitude of &quot;dealing with things as they come up&quot; and we should shift our focus on specific aspects that are hard to deal with as they come up. If the takeoff is not continuous, an agent might rapidly gain capabilities relative to the rest of civilization and it becomes important to rule out problems, long before they come up.</p><p><strong>Flo&apos;s opinion:</strong> I believe that it is quite important to be aware of the implications that different forms of takeoff should have on our prioritization and am glad that the article highlights this. However, I am a bit worried that this very broad definition of continuous progress limits the usefulness of the concept. For example, it seems plausible that a recursively self-improving agent which is very hard to deal with once deployed still improves its capabilities slow enough to fit the definition, especially if its developer has a significant lead over others.</p><h1><strong>AI strategy and policy</strong></h1><p><u><a href=""https://www.newamerica.org/cybersecurity-initiative/digichina/blog/special-report-ai-policy-and-china-realities-of-state-led-development/"">Special Report: AI Policy and China &#x2013; Realities of State-Led Development</a></u></p><h1><strong>Other progress in AI</strong></h1><h3><strong>Reinforcement learning</strong></h3><p><u><a href=""https://www.alexirpan.com/2019/10/29/openai-rubiks.html"">Let&apos;s Discuss OpenAI&apos;s Rubik&apos;s Cube Result</a></u> <em>(Alex Irpan)</em> (summarized by Rohin): This post makes many points about <u><a href=""https://openai.com/blog/solving-rubiks-cube/"">OpenAI&apos;s Rubik&apos;s cube result</a></u> (<u><a href=""https://mailchi.mp/732eaa192df0/an-70-agents-that-help-humans-who-are-still-learning-about-their-own-preferences"">AN #70</a></u>), but I&apos;m only going to focus on two. First, the result is a major success for OpenAI&apos;s focus on design decisions that encourage long-term research success. In particular, it relied heavily on the engineering-heavy model surgery and policy distillation capabilities that allow them to modify e.g. the architecture in the middle of a training run (which we&apos;ve seen with <u><a href=""https://blog.openai.com/openai-five-benchmark-results/"">OpenAI Five</a></u> (<u><a href=""https://mailchi.mp/4b19d2caa5a9/alignment-newsletter-19"">AN #19</a></u>)). Second, the domain randomization doesn&apos;t help as much as you might think: OpenAI needed to put a significant amount of effort into improving the simulation to get these results, tripling the number of successes on a face rotation task. Intuitively, we still need to put in a lot of effort to getting the simulation to be &quot;near&quot; reality, and then domain randomization can take care of the last little bit needed to robustly transfer to reality. Given that domain randomization isn&apos;t doing that much, it&apos;s not clear if the paradigm of zero-shot sim-to-real transfer is the right one to pursue. To quote the post&apos;s conclusion: <em>I see two endgames here. In one, robot learning reduces to building rich simulators that are well-instrumented for randomization, then using ludicrous amounts of compute across those simulators. In the other, randomization is never good enough to be more than a bootstrapping step before real robot data, no matter what the compute situation looks like. Both seem plausible to me, and we&#x2019;ll see how things shake out.</em></p><p><strong>Rohin&apos;s opinion:</strong> As usual, Alex&apos;s analysis is spot on, and I have nothing to add beyond strong agreement.</p>",rohinmshah,rohinmshah,Rohin Shah,
LfPYqcECjz9hJmdNE,"Judgment, Punishment, and the Information-Suppression Field",judgment-punishment-and-the-information-suppression-field,https://www.lesswrong.com/posts/LfPYqcECjz9hJmdNE/judgment-punishment-and-the-information-suppression-field,2019-11-06T17:44:38.908Z,19,14,12,False,False,http://benjaminrosshoffman.com/judgment-punishment-and-the-information-suppression-field/,"<html><head></head><body><p>There are a lot of senses in which I or the people around me can be considered unsafe. Many-tonned hunks of metal whiz by us on the same streets we have to navigate on foot to buy our groceries. The social infrastructure by which we have access to clean drinking water is gradually being adulterated. Our country is run by occasionally genocidal white nationalists. And, of course, The Bomb. But when I hear people talk about feeling unsafe, they are almost never describing a concrete threat to their physical well-being. (As usual, life may be different for the less privileged classes, who have reason to fear the authorities, and behave accordingly.) ""Safety"" does not come up as a motive for actions taken or avoided in order to mitigate such threats. Instead, it seems that ""safety"" nearly always means a nonjudgmental context (the exact opposite of <a href=""http://benjaminrosshoffman.com/safety-in-numbers/"">what I would naively expect</a> to be able to ensure clean drinking water or keep the cars from colliding with us), and ""feeling unsafe"" is generally used to explain only why they're trying to <a href=""http://benjaminrosshoffman.com/engineer-diplomat/"">withhold information</a> (mainly ""vulnerable,"" i.e. relevant-to-their-interests, information) in a way that seems out of proportion to actually existing risks and opportunities.</p>
<h1>Judgment and Punishment</h1>
<p>Consider a simple model: information about social censure consists of two parts. Each socially legible action is assigned a <em>vulnerability</em> score based on how often, empirically, someone responds by revealing the intent to punish the actor. Actions are sometimes defined contextually, so that talking loudly in a crowded bar or on the street is different than talking loudly in a library or theater, but it's not a different action depending on who is present - only impersonal context cues and stereotyped identities (e.g. some things are inappropriate ""in mixed company""). Vulnerability is a global variable with respect to persons.</p>
<p>If Cato is observed to punish singing but not dancing, and Flaccus is observed to punish dancing but not singing, this is treated as unpredictable random variation - possibly just measurement error. Cato and Flaccus both acquire a reputation for judginess, and both singing and dancing start to feel like vulnerable activities, so people will feel inhibited about doing either activity in the presence of either censor.</p>
<p>At the same time, each known person is evaluated for their generic propensity to punish, or judginess. Some people will physically attack you for violating norms (they often wear dark blue or gray-green), others will just yell at you, still others will politely hint that others might disapprove, and a few are universal receivers, totally nonjudgmental. Revealing <em>others'</em> intent to punish is considered a veiled threat, and is therefore itself a mild form of intent-to-punish. To be nonjudgmental, one must deny others information about what is likely to be punished elsewhere.</p>
<p>We recognize judgmental people not merely by their actual punishment behavior (in the ancestral environment, where ostracism could easily be permanent and deadly, this might have been playing things quite a bit too close), but by their posture, the patterns of tension in their voice, and so on.</p>
<p>I think that this model fits how people in our society experience a sense of social safety or unsafety surprisingly well for something so simple. One virtue of this model is that it correctly predicts that ""code-switching,"" i.e. adjusting to variations in standards <em>between different cultures</em> for the same activity in the same context, is more difficult than learning different behaviors for different contexts within a single culture. Code-switching imposes a greater cognitive load due to its strong dependence on theory of mind.</p>
<h1>The Information-Suppression Field</h1>
<p>One important characteristic of this setup is that it structurally advantages information-suppression tactics over clarity-creation tactics.</p>
<p>If I try to judge people adversely for giving me misleading information, I end up complaining a <em>lot</em>, and quickly acquire a reputation for being judgmental and therefore unsafe. Ironically, I get more of the behavior I punish, since being categorized as judgy leads to people avoiding <em>all</em> vulnerable behaviors around me, not just the ones I specifically punished. I cut myself off from a lot of very important information, and in exchange, <em>maybe</em> slightly improve the average punishment function - but this would provide an information subsidy to <em>all</em> other judgy agents, even ones whose interests conflict with mine and are trying to prevent me from learning some things. And most likely I just add to the morass of learned inhibitions.</p>
<p>On the other hand, if I wish to suppress some information - say, that some enterprise I'm profiting from is fraudulent - and I don't otherwise read as unsafe, then I can very slightly punish it - say, by gently discouraging people from talking about it because it seems likely to be harmful, because it hurts some people's feelings, etc, If I only need to suppress a few pieces of information, and there are other REALLY judgy people out there, then I can externalize most of the enforcement costs onto either the actual judgy people or the imaginations of the people I am manipulating.</p>
<p>A simple example:</p>
<p>Alice has a pervasive sense that she is being cheated in life somehow, and lashes out from time to time at people who seem like they're piling on. Carol has a consistently gentle, positive vibe, and owns a drugstore from which Alice regularly purchases expensive homeopathic medicines. Bob, who knows both of them, starts to tell Carol about how he's done some thinking about it, and homeopathy seems to him like it couldn't possibly work. Carol hints to Bob that this is a sensitive subject. Bob reasons, implicitly, that if even Carol doesn't like him talking about his idea, he had darn well better make sure not to talk about it around Alice.</p>
<p>This is an adversarial game that different secretive coalitions can play against each other, at the expense of other people trying to use censure for other reasons. All such moves, however, also benefit nonjudgmental people, who can collect a surplus from living in a society that relies on standards, while collecting a disproportionate amount of information and social capital by never contributing to attempts to track and censure misbehavior.</p>
</body></html>",Benquo,benquo,Benquo,
dsfmdur2XqHGe6Kkc,Lisbon SSC Meetup #3,lisbon-ssc-meetup-3,https://www.lesswrong.com/events/dsfmdur2XqHGe6Kkc/lisbon-ssc-meetup-3,2019-11-06T10:07:26.237Z,1,1,0,False,False,,"<p>Hello, everyone!<br>The topic of discussion for this meetup is Journalism and its Future. It will be assumed that everyone attending has read the New Yorker article &quot;Does Journalism Have a Future?&quot; by Jill Lepore (https://www.newyorker.com/magazine/2019/01/28/does-journalism-have-a-future) for historical context and challenges for the future. From there we will debate incentive structures, consumer habits and viable business models for mainstream media.</p><p>Meetup page:  <a href=""https://www.meetup.com/Lisbon-SSC-Meetup/events/266255022/"">https://www.meetup.com/Lisbon-SSC-Meetup/events/266255022/</a> </p>",tamkin&popkin,tamkin-and-popkin,tamkin&popkin,
q7d3L7hhibcLdLWTD,Is my perception of reality bounded by my intelligence?,is-my-perception-of-reality-bounded-by-my-intelligence,https://www.lesswrong.com/posts/q7d3L7hhibcLdLWTD/is-my-perception-of-reality-bounded-by-my-intelligence,2019-11-05T20:40:50.246Z,1,1,1,False,True,,"<p>Hello all, </p><p>Here I am living in the Netherlands, 2019 AD. In my perception there is no two-way explicit communication with non-human intelligence, no space travel. Artifical intelligence is in it&apos;s infancy (at least, as seen by the general public). All my evidence to today tells me I this current objective reality is certain. </p><p>But now I am asking myself from a rationality perspective: How is this perception of reality is bounded by my intelligence (in whatever way my biological system has implemented this intelligence) and (unaware) filtering of evidence? </p><p>If I were able to enhance my intelligence by just 1 bit, changing some personal absolute certainty into something probabilistic, what would be the effect on my objective reality? What would be the effect on our shared objective reality? What experiment could be designed to find out?</p>",,,,
MoD5a5qr6rhD4R24J,Normative reductionism,normative-reductionism,https://www.lesswrong.com/posts/MoD5a5qr6rhD4R24J/normative-reductionism,2019-11-05T20:20:02.083Z,13,5,19,False,False,,"<p>Here’s a concept that seems useful, but that I don’t remember ever hearing explicitly referred to (with my own tentative name for it—if it turns out to not already have one in some extensive philosophical literature, I might think more about whether it is a good name):</p>
<blockquote><p><i>Normative reductionism</i>: The value of a world history is equal to the value of its parts (for some definition of relevant parts).</p></blockquote>
<p>For instance, if two world histories only differ between time t and time t’, according to NR you do not need to know what happened at other times to evaluate them in full. Similarly, the value of Alice’s life, or the value of Alice enjoying a nap, depend on the nature of her life or the nap, and not for instance on other people’s lives or events that took place before she was born with no effect on her (unless perhaps she has preferences about those events or they involve people having preferences about her, but still the total value can be decomposed into the value of different preferences being fulfilled or not). Straightforward hedonistic utilitarianism probably implies normative reductionism.</p>
<p>My impression is that people have different intuitions about this and vary in how much they assume it, and that it mostly isn’t entirely aligned with other axes of ethical view, either logically or sociologically, though is related to them. So it seems maybe worth noting explicitly.</p>",KatjaGrace,katjagrace,KatjaGrace,
ZwW66G7GkJC5FfHBt,Lite Blocking,lite-blocking,https://www.lesswrong.com/posts/ZwW66G7GkJC5FfHBt/lite-blocking,2019-11-05T13:50:02.402Z,21,6,4,False,False,,"<p>

There are people I would like to interact less with online: perhaps
they post inane things, perhaps they pull comment threads off in bad
directions, perhaps they make terrible arguments for things I agree
with.  The standard tools social networks offer for this sort of
situation are:



<ul>
<li><p>Blocking: you can't see their stuff, they can't see your stuff,
you can't interact.</p></li>
<li><p>Hiding: you don't see their stuff, or you see less of it.  You
can still interact.</p></li>
</ul>

I'd like another tool:



<ul>
<li><p>Lite blocking: as if they'd hidden you.</p></li>
</ul>



</p><p>

Social networks generally have far more things they could show you
than you'll be able to look at.  To prioritize they use inscrutable
algorithms that boil down to ""we show you the things we predict you're
going to like"". You can think of hiding as ""dramatically lower the
prediction that I would like seeing their stuff"", and lite blocking as
""dramatically lower the prediction that they would like seeing my
stuff"".

</p>

<p>

Lite blocking could be symmetrical or not, but the important thing to
me is that the network would stop encouraging people to interact with
me if I don't want those interactions.

</p>

<p>

Perhaps I should just block people?  I'm glad blocking exists, and
there are times when it's the right tool.  But other times it's much
too powerful:

</p>

<p>

</p>

<ul>
<li><p>Blocking is obvious, but with the level of ""who knows
why the things decided to show me what it did"" lite blocking maintains
plausible deniability.  This is important for people you want to avoid
interacting with but need to stay on good terms with for other
reasons.</p></li>

<li><p>Blocking is too thorough.  Maybe I don't like the way you tend
to come into threads I host and derail them, but I'd still like you to
be able to find our past discussions and reference them if
intentionally seek them out.</p></li>

<li><p>Groups often have high thresholds for kicking people out, but
an in-between level where someone would just see fewer group posts in
their feed would be helpful in cases where the moderators think
someone's posts are generally making the group worse.</p></li>

</ul>



<p>

Since lite blocking explicitly overrides the network's prediction
about how much someone will like things, you could imagine a change to
add it being difficult to get past launch review.  It would probably
look bad on the core metrics, with a decrease in estimated user
satisfaction and engagement.  But the metrics don't capture the ways
""so and so isn't showing up in my discussions any more"" would make
others happier and improve their experience using the network.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100119961967092"">facebook</a></i></p>",jkaufman,jkaufman,jefftk,
bNXdnRTpSXk9p4zmi,Book Review: Design Principles of Biological Circuits,book-review-design-principles-of-biological-circuits,https://www.lesswrong.com/posts/bNXdnRTpSXk9p4zmi/book-review-design-principles-of-biological-circuits,2019-11-05T06:49:58.329Z,234,112,24,False,False,,"<p>I remember seeing a talk by a synthetic biologist, almost a decade ago. The biologist used a genetic algorithm to evolve an electronic circuit, something like this:</p><p><img style=""width:520%"" src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/xsz6ysbsvsaq1bomyb3j""></p><p>(<a href=""http://www.genetic-programming.com/hc/cubic.html""><u>source</u></a>)</p><p>He then printed out the evolved circuit, brought it to his colleague in the electrical engineering department, and asked the engineer to analyze the circuit and figure out what it did.</p><p>“I refuse to analyze this circuit,” the colleague replied, “because it was not designed to be understandable by humans.” He has a point - that circuit is a big, opaque mess.</p><p>This, the biologist argued, is the root problem of biology: evolution builds things from random mutation, connecting things up without rhyme or reason, into one giant <a href=""https://www.lesswrong.com/posts/NQgWL7tvAPgN2LTLn/spaghetti-towers""><u>spaghetti tower</u></a>. We can take it apart and look at all the pieces, we can simulate the whole thing and see what happens, but there’s no reason to expect any deeper understanding. Organisms did not evolve to be understandable by humans.</p><p>I used to agree with this position. I used to argue that there was no reason to expect human-intelligible structure inside biological organisms, or deep neural networks, or other systems not designed to be understandable. But over the next few years after that biologist’s talk, I changed my mind, and one major reason for the change is Uri Alon’s book <a href=""https://www.amazon.com/gp/product/1439837171/""><u>An Introduction to Systems Biology: Design Principles of Biological Circuits</u></a>.</p><p>Alon’s book is the ideal counterargument to the idea that organisms are inherently human-opaque: it directly demonstrates the human-understandable structures which comprise real biological systems. Right from the first page of the introduction:</p><blockquote><p>… one can, in fact, formulate general laws that apply to biological networks. Because it has evolved to perform functions, biological circuitry is far from random or haphazard. ... Although evolution works by random tinkering, it converges again and again onto a defined set of circuit elements that obey general design principles.</p></blockquote><blockquote><p>The goal of this book is to highlight some of the design principles of biological systems... The main message is that biological systems contain an inherent simplicity. Although cells evolved to function and did not evolve to be comprehensible, simplifying principles make biological design understandable to us.</p></blockquote><p>It’s hard to update one’s gut-level instinct that biology is a giant mess of spaghetti without seeing the structure first hand, so the goal of this post is to present just enough of the book to provide some intuition that, just maybe, biology really is human-understandable.</p><p>This review is prompted by the release of the book’s second edition, just this past August, and that’s the edition I’ll follow through. I will focus specifically on the parts I find most relevant to the central message: biological systems are not opaque. I will omit the last three chapters entirely, since they have less of a <a href=""https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding""><u>gears-level</u></a> focus and more of an evolutionary focus, although I will likely make an entire separate post on the last chapter (evolution of modularity).</p><h2>Chapters 1-4: Bacterial Transcription Networks and Motifs</h2><p>E-coli has about 4500 proteins, but most of those are chunked together into chemical pathways which work together to perform specific functions. Different pathways need to be expressed depending on the environment - for instance, e-coli won’t express their lactose-metabolizing machinery unless the environment contains lots of lactose and not much glucose (which they like better).</p><p>In order to activate/deactivate certain genes depending on environmental conditions, bacteria use transcription factors: proteins sensitive to specific conditions, which activate or repress transcription of genes. We can think of the transcription factor activity as the cell’s internal model of its environment. For example, from Alon:</p><blockquote><p>Many different situations are summarized by a particular transcription factor activity that signifies “I am starving”. Many other situations are summarized by a different transcription factor activity that signifies “My DNA is damaged”. These transcription factors regulate their target genes to mobilize the appropriate protein responses in each case.</p></blockquote><p>The entire state of the transcription factors - the e-coli’s whole model of its environment - has about 300 degrees of freedom. That’s 300 transcription factors, each capturing different information, and regulating about 4500 protein genes.</p><p>Transcription factors often regulate the transcription of other transcription factors. This allows information processing in the transcription factor network. For instance, if either of two different factors (X, Y) can block transcription of a third (Z), then that’s effectively a logical NOR gate: Z levels will be high when neither X nor Y is high. In general, transcription factors can either repress or promote (though rarely both), and arbitrarily complicated logic is possible in principle - including feedback loops.</p><p>Now we arrive at our first major piece of evidence that organisms aren’t opaque spaghetti piles: bacterial transcription network motifs.</p><p>Random mutations form random connections between transcription factors - mutations can make any given transcription factor regulate any other very easily. But actual transcription networks do not look like random graphs. Here’s a visualization from the book:</p><p><img style=""width:287%"" src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/zrxdgppfklf27epm3ysi""></p><p>A few differences are immediately visible:</p><ul><li>Real networks have much more autoregulation (transcription factors activating/repressing their own transcription) than random networks</li><li>Other than self-loops (aka autoregulation), real networks contain almost no feedback loops (at least in bacteria), though such loops are quite common in random networks</li><li>Real networks are mostly tree-shaped; most nodes have at most a single parent.</li></ul><p>These patterns can be quantified and verified statistically via “motifs” (or “antimotifs”): connection patterns which occur much more frequently (or less frequently) in real transcription factor networks than in random networks.</p><p>Alon uses an e-coli transcription network with 424 nodes and 519 connections to quantify motifs. Chapters 2-4 each look at a particular class of motifs in detail:</p><ul><li>Chapter 2 looks at autoregulation. If the network were random, we’d expect about 1.2 ± 1.1 autoregulatory loops. The actual network has 40.</li><li>Chapter 3 looks at three-node motifs. There is one massively overrepresented motif: the feed-forward loop (see diagram below), with 42 instances in the real network and only 1.7 ± 1.3 in a random network. Distinguishing activation from repression, there are eight possible feed-forward loop types, and two of the eight account for 80% of the feed-forward loops in the real network.</li><li>Chapter 4 looks at larger motifs, though it omits the statistics. Fan-in and fan-out patterns, as well as fanned-out feed-forward loops, are analyzed.</li></ul><p>Alon analyzes the chemical dynamics of each pattern, and discusses what each is useful for in a cell - for instance, autoregulatory loops can fine-tune response time, and feed-forward loops can act as filters or pulse generators.</p><figure class=""image""><img src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/d8h9kf6wysychusry8es"" srcset=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/vziqcznqhvjb3kipbbab 144w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/anbl8rbbfxwab1yqfxc3 224w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/v0mtgjo9jbdsc9cwybz6 304w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/q5ua4c3o0siwvvtx6x0m 384w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/cdxecftfrq5wuspgxy02 464w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/sf1b8sfulvn9oliko1tq 544w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/fuicjeibqeoihb0ae8io 624w""></figure><h2>Chapters 5-6: Feedback and Motifs in Other Biological Networks</h2><p>Chapter 5 opens with developmental transcription networks, the transcription networks which lay out the body plan and differentiate between cell types in multicellular organisms. These are somewhat different from the bacterial transcription networks discussed in the earlier chapters. Most of the overrepresented motifs in bacteria are also overrepresented in developmental networks, but there are also new overrepresented motifs - in particular, positive autoregulation and two-node positive feedback.</p><p>Both of these positive feedback patterns are useful mainly for inducing bistability - i.e. multiple stable steady states. A bistable system with steady states A and B will stay in A if it starts in A, or stay in B if it starts in B, meaning that it can be used as a stable memory element. This is especially important to developmental systems, where cells need to decide what type of cell they will become (in coordination with other cells) and then stick to it - we wouldn’t want a proto-liver cell changing its mind and becoming a proto-kidney cell instead.</p><p>After discussing positive feedback, Alon includes a brief discussion of motifs in other biological networks, including protein-protein interactions and neuronal networks. Perhaps surprisingly (especially for neuronal networks), these include many of the same overrepresented motifs as transcription factor networks - suggesting universal principles at work.</p><p>Finally, chapter 6 is devoted entirely to biological oscillators, e.g. circadian rhythms or cell-cycle regulation or heart beats. The relevant motifs involve negative feedback loops. The main surprise is that oscillations can sometimes be sustained even when it seems like they should die out over time - thermodynamic noise in chemical concentrations can “kick” the system so that the oscillations continue indefinitely.</p><p>At this point, the discussion of motifs in biological networks wraps up. Needless to say, plenty of references are given which quantify motifs in various biological organisms and network types.</p><h2>Chapters 7-8: Robust Recognition and Signal-Passing</h2><p>There’s quite a bit of hidden purpose in biological systems - seemingly wasteful side-reactions or seemingly arbitrary reaction systems turn out to be functionally critical. Chapters 7-8 show that robustness is one such “hidden” purpose: biological systems are buffeted by thermodynamic noise, and their functions need to be robust to that noise. Once we know to look for it, robustness shows up all over, and many seemingly-arbitrary designs don’t look so random anymore.</p><p>Chapter 7 mainly discusses kinetic proofreading, a system used by both ribosomes (RNA-reading machinery) and the immune system to reduce error rates. At first glance, kinetic proofreading just looks like a wasteful side-reaction: the ribosome/immune cell binds its target molecule, then performs an energy-consuming side reaction and just waits around a while before it can move on to the next step. And if the target unbinds at any time, then it has to start all over again!</p><p>Yet this is exactly what’s needed to reduce error rates.</p><p>The key is that the <i>correct</i> target is always most energetically stable to bind, so it stays bound longer (on average) than <i>incorrect</i> targets. At equilibrium, maybe 1% of the bound targets are incorrect. The irreversible side-reaction acts as a timer: it marks that some target is bound, and starts time. If the target falls off, then the side-reaction is undone and the whole process starts over… but the incorrect targets fall off much more quickly that the correct targets. So, we end up with correct targets “enriched”: the fraction of incorrect targets drops well below its original level of 1%. Both the delay and the energy consumption are necessary in order for this to work: the delay to give the incorrect targets time to fall off, and the energy consumption to make the timer irreversible (otherwise everything just equilibrates back to 1% error).</p><p>Alon offers an analogy, in which a museum curator wants to separate the true Picasso lovers from the non-lovers. The Picasso room usually has about 10x more lovers than non-lovers (since the lovers spend much more time in the room), but the curator wants to do better. So, with a normal mix of people in there, he locks the incoming door and opens a one-way door out. Over the next few minutes, only a few of the picasso lovers leave, but practically all the non-lovers leave - Picasso lovers end up with much more than the original 10x enrichment in the room. Again, we see both key pieces: irreversibility and a delay.</p><p>It’s also possible to stack such systems, performing multiple irreversible side-reactions in sequence, in order to further lower the error rate. Alon goes into much more depth, and explains the actual reactions involved in more detail.</p><p>Chapter 8 then dives into a different kind of robustness: robust signal-passing. The goal here is to pass some signal from outside the cell to inside. The problem is, there’s a lot of thermodynamic noise in the number of receptors - if there happen to be 20% more receptors than average, then a simple detection circuit would measure 20% stronger signal. This problem can be avoided, but it requires a specific - and nontrivial - system structure.</p><p>In this case, the main trick is to have the receptor both activate and deactivate (i.e. <a href=""https://en.wikipedia.org/wiki/Phosphorylation""><u>phosphorylate</u></a> and dephosphorylate) the internal signal molecule, with rates depending on whether the receptor is bound. At first glance, this might seem wasteful: what’s the point of a receptor which undoes its own effort? But for robustness, it’s critical - because the receptor both activates and deactivates the internal signal, its concentration cancels out in the equilibrium expression. That means that the number of receptors won’t impact the equilibrium activity level of the signal molecule, only how fast it reaches equilibrium.</p><p>The trick can also be extended to provide robustness to the background level of the signal molecule itself - Alon provides more detail. As you might expect, this type of structure is a common pattern in biological signal-receptor circuits.</p><p>For our purposes, the main takeaway from these two chapters is that, just because the system <i>looks</i> wasteful/arbitrary, does not mean it <i>is</i>. Once we know what to look for, it becomes clear that the structure of biological systems is not nearly so arbitrary as it looks.</p><h2>Chapters 9-11: Exact Adaptation, Fold Change and Related Topics</h2><p>When we move from an indoor room into full sunlight, our eyes quickly adjust to the brightness. A bacteria swimming around in search of food can detect chemical gradients among background concentrations varying by three orders of magnitude. Beta cells in the pancreas regulate glucose usage, bringing the long-term blood glucose concentration back to 5 mM, even when we shift to eating or exercising more. In general, a wide variety of biological sensing systems need to be able to detect changes and then return to a stable baseline, across a wide range of background intensity levels.</p><p>Alon discusses three problems in this vein, each with its own chapter:</p><ul><li>Exact adaptation: the “output signal” of a system always returns to the same baseline when the input stops changing, even if the input settles at a new level.</li><li>Fold change: the system responds to percentage changes, across several decibels of background intensity.</li><li>Extracellular versions of the above problems, in which control is decentralized.</li></ul><p>Main takeaway: fairly specific designs are needed to achieve robust behavior.</p><h3><u>Exact Adaptation</u></h3><p>The main tool used for exact adaptation will be immediately familiar to engineers who’ve seen some linear control theory: integral feedback control. There are three key pieces:</p><ul><li>Some internal state variable&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></span></span></span>&nbsp;- e.g. concentration/activation of some molecule type or count of some cell type - used to track “error” over time</li><li>An “internal” signal&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span></li><li>An “external” signal and a receptor, which increases production/activation of the internal signal whenever it senses the external signal</li></ul><p>The “error” tracked by the internal state&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>&nbsp;is the difference between the internal signal’s concentration&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>&nbsp;and its long-term steady-state concentration&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X^*""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.024em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.115em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span></span></span></span></span></span></span></span>. The internal state increases/decreases in direct proportion to that difference, so that over time, the&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>&nbsp;is proportional to the integral&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""\int_t (X^* - X) dt""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.138em;""><span class=""mjx-mo"" style=""padding-right: 0.138em;""><span class=""mjx-char MJXc-TeX-size1-R"" style=""padding-top: 0.593em; padding-bottom: 0.593em;"">∫</span></span></span><span class=""mjx-sub"" style=""font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;""><span class=""mjx-mi"" style=""""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">(</span></span><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.024em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.115em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span></span></span><span class=""mjx-mo MJXc-space2""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.298em; padding-bottom: 0.446em;"">−</span></span><span class=""mjx-mi MJXc-space2""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">)</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;"">d</span></span><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.372em; padding-bottom: 0.298em;"">t</span></span></span></span></span></span></span>. Then,&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>&nbsp;itself represses production/activation of the internal signal&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>.</p><p>The upshot: if the external signal increases, then at first the internal signal&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>&nbsp;also increases, as the external receptor increases production/activation of&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>. But this pushes&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>&nbsp;above its long-term steady-state&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X^*""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-msubsup""><span class=""mjx-base"" style=""margin-right: -0.024em;""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span><span class=""mjx-sup"" style=""font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.115em; padding-right: 0.071em;""><span class=""mjx-mo"" style=""""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.298em;"">∗</span></span></span></span></span></span></span></span></span>, so&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>&nbsp;gradually increases, repressing&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>. The longer and further&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>&nbsp;is above its steady-state, the more&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>&nbsp;increases, and the more&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>&nbsp;is repressed. Eventually,&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>&nbsp;reaches a level which balances the new average level of the external signal, and&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>&nbsp;returns to the baseline.</p><p>Alon then discusses robustness of this mechanism compared to other possible mechanisms. Turns out, this kind of feedback mechanism is robust to changes in the background level of&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span></span>,&nbsp;<span><span class=""mjpage""><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""X""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;"">X</span></span></span></span></span></span></span>, etc - steady-state levels shift, but the qualitative behavior of exact adaptation remains. Other, “simpler” mechanisms do not exhibit such robustness.</p><h3><u>Fold-Change Detection</u></h3><p>Fold-change detection is a pretty common theme in biological sensory systems, from eyes to bacterial chemical receptors. <a href=""https://en.wikipedia.org/wiki/Weber%E2%80%93Fechner_law""><u>Weber’s Law</u></a> is the general statement: sensory systems usually respond to changes on a log scale.</p><p>There’s two important pieces here:</p><ul><li>“Respond to changes” means exact adaption - the system returns to a neutral steady-state value in the long run when nothing is changing.</li><li>“Log scale” means it’s percent changes which matter, and the system can work across several orders of magnitude of external signal</li></ul><p>Alon gives an interesting example: apparently if you use a screen and an eye-tracker to cancel out a person’s rapid eye movements, their whole field of vision turns to grey and they can’t see anything. That’s responding to changes. On the other hand, if we step into bright light, background intensity can easily jump by an order of magnitude - yet a 10% contrast looks the same in low light or bright light. That’s operating on a log-scale.</p><p>Again, there’s some pretty specific criteria for systems to exhibit fold-change detection - few systems have consistent, useful behavior over multiple orders of magnitude of input values. Alon gives two particular circuits, as well as a general criterion.</p><h3><u>Extracellular/Decentralized Adaptation</u></h3><p>Alon moves on to the example of blood glucose regulation. Blood glucose needs to be kept at a pretty steady 5 mM level long-term; too low will starve the brain, and too high will poison the brain. The body uses an integral feedback mechanism to achieve robust exact adaptation of glucose levels, with the count of pancreatic beta cells serving as the state variable: when glucose is too low, the cells (slowly) die off, and when glucose is too high, the cells (slowly) proliferate.</p><p>The main new player is insulin. Beta cells do not themselves produce or consume much glucose; rather, they produce insulin, which we can think of as an inverse-price signal for glucose. When insulin levels are low (so the “price” of glucose is high), many cells throughout the body cut back on their glucose consumption. The beta cells serve as market-makers: they adjust the insulin/price level until the glucose market clears - meaning that there is no long-term increase or decrease in blood glucose.</p><p>A very similar system exists for many other metabolite/hormone pairs. For instance, calcium and parathyroid uses a nearly-identical system: integral feedback mechanism using cell count as a state variable with a hormone serving as price-signal to provide decentralized feedback control throughout the body.</p><p>Alon also spends a fair bit of time on one particular issue with this set-up: mutant cells which mismeasure the glucose concentration could proliferate and take over the tissue. One defense against this problem is for the beta cells to die when they measure very high glucose levels (instead of proliferating very quickly). This handles must mutations, but it also means that sufficiently high glucose levels can trigger an unstable feedback loop: beta cells die, which reduces insulin, which means higher glucose “price” and less glucose usage throughout the body, which pushes glucose levels even higher. That’s type-2 diabetes.</p><h2>Chapter 12: Morphological Patterning</h2><p>The last chapter we’ll cover here is on morphological patterning: the use of chemical reactions and diffusion to lay out the body plans of multicellular organisms.</p><p>The basic scenario involves one group of cells (A) producing some signal molecule, which diffuses into a neighboring group of cells (B). The neighbors then differentiate themselves based on how strong the signal is: those nearby A will see high signal, so they adopt one fate, while those farther away see lower signal, so they adopt another fate, with some cutoff in between.</p><p>This immediately runs into a problem: if A produces too much or too little of the signal molecule, then the cutoff will be too far to one side or the other - e.g. the organism could end up with a tiny rib and big space between ribs, or a big rib and a tiny space between. It’s not robust.</p><p>Once again, the right design can mitigate the problem.</p><p>Apparently one group ran a brute-force search over parameter space, looking for biologically-plausible systems which produced robust patterning. Only a few tiny corners of the parameter space worked, and those tiny corners all used a qualitatively similar mechanism. Alon explains the mechanism in some depth, but I’m gonna punt on it - much as I enjoy nonlinear PDEs (and this one is even analytically tractable), I’m not going to inflict them on readers here.</p><p>Once again, though it may seem that evolution can solve problems a million different ways and it’s hopeless to look for structure, it actually turns out that only a few specific designs work - and those are understandable by humans.</p><h2>Takeaway</h2><p>Let’s return to the Alon quote from the introduction:</p><blockquote><p>Because it has evolved to perform functions, biological circuitry is far from random or haphazard. ... Although evolution works by random tinkering, it converges again and again onto a defined set of circuit elements that obey general design principles.</p></blockquote><blockquote><p>The goal of this book is to highlight some of the design principles of biological systems... The main message is that biological systems contain an inherent simplicity. Although cells evolved to function and did not evolve to be comprehensible, simplifying principles make biological design understandable to us.</p></blockquote><p>We’ve now seen both general evidence and specific examples of this.</p><p>In terms of general evidence, we’ve seen that biological regulatory networks do not look statistically random. Rather, a handful of patterns - “motifs” - repeat often, lending the system a lot of consistent structure. Even though the system was not designed to be understandable, there’s still a lot of recognizable internal structure.</p><p>In terms of specific examples, we’ve seen that only a small subset of possible designs can achieve certain biological goals:</p><ul><li>Robust recognition of molecules</li><li>Robust signal-passing</li><li>Robust exact adaptation and distributed exact adaptation</li><li>Fold-change detection</li><li>Robust morphological patterning</li></ul><p>The designs which achieve robustness are exactly the designs used by real biological systems. Even though the system was not designed to be understandable, the simple fact that it works <i>robustly</i> forces the use of a handful of understandable structures.</p><p>A final word: when we do not understand something, it does not <i>look</i> like there is anything to be understood at all - it just looks like random noise. Just because it looks like noise does not mean there is no hidden structure.</p><p><img style=""width:340%"" src=""https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/bNXdnRTpSXk9p4zmi/j1sfzvwnu7evj2uvdykf""></p>",johnswentworth,johnswentworth,johnswentworth,
7oemSwabXXpMcvCsg,What would happen if all the water on Earth were accumulated into spheres & drop on the surface?,what-would-happen-if-all-the-water-on-earth-were-accumulated,https://www.lesswrong.com/posts/7oemSwabXXpMcvCsg/what-would-happen-if-all-the-water-on-earth-were-accumulated,2019-11-05T04:55:38.035Z,2,8,4,False,True,,"<p>I was inspired by the APOD pictures and discussion <u><a href=""http://asterisk.apod.com/viewtopic.php?f=10&amp;t=28555"">here</a></u> and <u><a href=""https://apod.nasa.gov/apod/ap120515.html"">here</a></u>. The conditions for the &apos;experiment&apos; are:</p><ul><li>For some mysterious reason, all the water on Earth (minus that in living things - the biosphere) suddenly &amp; immediately converges into 17 identical sphere and let to drop down to the land below right away. </li><li>The places of those water balls are the centers of 17 biggest tectonic plates as listed <a href=""https://www.worldatlas.com/articles/major-tectonic-plates-on-earth.html"">here</a>.</li><li>The bottoms of the huge balls just touch the highest points on the ground there. Also from my calculation, which may be wrong, their radius is 258 km.</li><li>The ISS is currently at its highest altitude of 460 km with ship(s) in dock.</li></ul><p><em>So, what will happen to <strong>us</strong>, the <strong>Earth </strong>and <strong>things </strong>on it? </em></p><p>My prediction is very grim for humanity, thus I turn to the ISS as our last hope. Supposed that at t=0, the astronauts can choose the station&apos;s direction of flying. Can they avoid all the 17 falling balls? Is there any chance they can land back on Earth without any help from Houston when things settle down, in case the water <em>does </em>settle down and not all turn into vapor? (That&apos;s a possibility I can&apos;t calculate and will need your help).</p><p>I&apos;m looking for answers in <a href=""https://what-if.xkcd.com/archive/"">xkcd </a>style, which IMO is a textbook way to respond to absurd &quot;What if?&quot; questions. It&apos;s detailed, with nice pictures to help our imagination, displaying formulas when necessary but also very rookie-friendly, tackle the problem from many different angles &amp; POVs, and takes into account some easy-to-overlook stuffs. Too bad he doesn&apos;t answer anymore.</p><p>Anyway, thank you just for reading! :)</p>",Long try,long-try,Long try,
oDyCKT2admtoQeiTk,What AI safety problems need solving for safe AI research assistants?,what-ai-safety-problems-need-solving-for-safe-ai-research,https://www.lesswrong.com/posts/oDyCKT2admtoQeiTk/what-ai-safety-problems-need-solving-for-safe-ai-research,2019-11-05T02:09:17.686Z,14,4,13,False,True,,"<html><head></head><body><p>In his <a href=""https://www.alignmentforum.org/posts/bnY3L48TtDrKTzGRb/ai-safety-success-stories"">AI Safety “Success Stories”</a> post, Wei Dai writes:</p>
<blockquote>
<p>[This] comparison table makes Research Assistant seem a particularly attractive scenario to aim for, as a stepping stone to a more definitive success story. Is this conclusion actually justified?</p>
</blockquote>
<p>I share Wei Dai's intuition that the Research Assistant path is neglected, and I want to better understand the safety problems involved in this path.</p>
<p>Specifically, I'm envisioning AI research assistants, built without any kind of reinforcement learning, that help AI alignment researchers identify, understand, and solve AI alignment problems.  Some concrete examples:</p>
<p><strong>Possible with yesterday's technology</strong>: Document clustering that automatically organizes every blog post about AI alignment.  Recommendation systems that find AI alignment posts similar to the one you're reading &amp; identify connections between the thinking of various authors.</p>
<p><strong>May be possible with current or near future technology</strong>: An AI chatbot, trained on every blog post about AI alignment, which makes the case for AI alignment to skeptics or attempts to shoot down FAI proposals.  Text summarization software that compresses a long discussion between two forum users in a way that both feel is accurate and fair.  A NLP system that automatically organizes AI safety writings into a problem/solution table as I described in <a href=""https://www.lesswrong.com/posts/znt3p9AGQDbYGf9Sy/the-problem-solution-matrix-calculating-the-probability-of"">this post</a>.</p>
<p><strong>May be possible with future breakthroughs in unsupervised learning, generative modeling, natural language understanding, etc.</strong>: An AI system that generates novel FAI proposals, or writes code for an FAI directly, and tries to break its own designs.  An AI system that augments the problem/solution table from <a href=""https://www.lesswrong.com/posts/znt3p9AGQDbYGf9Sy/the-problem-solution-matrix-calculating-the-probability-of"">this post</a> with new rows and columns generated based on original reasoning.</p>
<p>What safety problems are involved in creating research assistants of this sort?  I'm especially interested in safety problems which haven't yet received much attention, and safety problems with advanced assistants based on future breakthroughs.</p>
</body></html>",John_Maxwell_IV,john_maxwell,John_Maxwell,
Wa2hASzbxyvutHJff,Total horse takeover,total-horse-takeover,https://www.lesswrong.com/posts/Wa2hASzbxyvutHJff/total-horse-takeover,2019-11-05T00:10:01.319Z,103,36,14,False,False,,"<p>I hear a lot of talk of ‘taking over the world’. What is it to take over the world? Have I done it if I am king of the world? Have I done it if I burn the world? Have humans or the printing press or Google or the idea of ‘currency’ done it? </p>
<p>Let’s start with something more tractable, and be clear on what it is to take over a horse. </p>
<p>A natural theory is that to take over a horse is to be the arbiter of everything about the horse —to be the one deciding the horse’s every motion.</p>
<p>But you probably don’t actually want to control the horse’s every motion, because the horse’s own ability to move itself is a large part of its value-add. Flaccid horse mass isn’t that helpful, not even if we throw in the horse’s physical strength to move itself according to your commands, and some sort of magical ability for you to communicate muscle-level commands to it. If you were in command of the horse’s every muscle, it would fall over. (If you directed its cellular processes too, it would die; if you controlled its atoms, you wouldn’t even have a dead horse.) </p>
<p><strong>Information and computing capacity</strong></p>
<p>The reason this isn’t so good is that balancing and maneuvering a thousand pounds of fast-moving horse flesh balanced on flexible supports is probably hard for you, at least via an interface of individual muscles, at least without more practice being a horse. I think for two reasons:</p>
<ul>
<li><b>Lack of information</b> e.g. about exactly where every part of the horse’s body is and where its hoofs are touching the ground how hard</li>
<li><b>Lack of computing power</b> to dedicate to calculating desired horse muscle motions from the above information and your desired high level horse behavior</li>
</ul>
<p>(Even if you have these things, you don’t obviously know how to use them to direct the horse well, but you can probably figure this out in finite time, so it doesn’t seem like a really fundamental problem.)</p>
<p>Tentative claim: holding more levers is good for you only insofar as you have the information and computing capacity to calculate which directions you should want those levers pushed. </p>
<p>So, you seem to be getting a lot out of the horse and various horse subcomponents making their own decisions about steering and balance and breathing and snorting and mitosis and where electrons should go. That is, you seem to be getting a lot out of not being in control of the horse. In fact so far it seems like the more you are in control of the horse in this sense, the worse things go for you. </p>
<p>Is there a better concept of ‘taking over’—a horse, or the world—such that someone relatively non-omniscient might actually benefit from it? (Maybe not—maybe extreme control is just bad if you aren’t near-omniscient, which would be good to know.) </p>
<p><strong>What riding a horse is like</strong></p>
<p>Perhaps a good first question: is there any sort of power that won’t make things worse for you? Surely yes: training a horse to be ridden in the usual sense seems like ‘having control over’ the horse more than you would otherwise, and seems good for you. So what is this kind of control like? </p>
<p>Well, maybe you want the horse to go to London with you on it, so you get on it and pull the reins to direct it to London. You don’t run into the problems above, because aside from directing its walking toward London, it sticks to its normal patterns of activity pretty closely (for instance, it continues breathing and keeping its body in an upright position and doing walking motions in roughly the direction its head is pointed).</p>
<p>So maybe in general: you want to command the horse by giving it a high level goal (‘take me to London’) then you want it to do the backchaining and fill in all the details (move right leg forward, hop over this log, breathe..). That’s not quite right though, because the horse has no ability to chart a path from here to London, due to its ignorance of maps and maybe London as a concept. So you are hoping to do the first step of the backchaining—figure out the route—and then to give the horse slightly lower level goals such as, ‘turn left here’, ‘go straight’, and for it to do the rest. Which still sounds like giving it a high level goal, then having it fill in the instrumental subgoals and do them.</p>
<p>But that isn’t quite right. You probably also want to steer the details there somewhat. You are moment-to-moment adjusting the horse’s motion to keep you on it, for instance. Or to avoid scaring some chickens. Or to keep to the side as another horse goes by. While not steering it entirely, at that level. You are relying on its own ability to avoid rocks and holes and to dodge if something flies toward it, and to put some effort into keeping you on it. How does this fit into our simple model? </p>
<p>Perhaps you want the horse to behave as it would—rather than suddenly leaving every decision to you—but for you to be able to adjust any aspect of it, and have it again work out how to support that change with lower level choices. You push it to the left and it finds new places to put its feet to make that work, and adjusts its breathing and heart rate to make the foot motions work. You pull it to a halt, and it changes its leg muscle tautnesses and heart rate and breathing to make that work. </p>
<p><b>Levers</b></p>
<p>On this model, in practice your power is limited by what kinds of changes the horse can and will fill in new details for. If you point its head in a new direction, or ask it to sit down, it can probably recalculate its finer motions and support that. Whereas if you decide that it should have have holes in its legs, it just doesn’t have an affordance for doing that. And if you do it, it will bleed a lot and run into trouble rather than changing its own bloodflow. If you decide it should move via a giant horse-sized bicycle, it probably can’t support that, even if in principle its physiology might allow it. If you hold up one of its legs so its foot is high in the air, it will ‘support’ that change by moving its leg back down again, which is perhaps not what you were going for.</p>
<p>This suggests that taking over a thing is not zero sum. There is not a fixed amount of control to be had by intentional agents. Because perhaps you have all the control that anyone has over a horse, in the sense that if the horse ever has a choice, it will try to support your commands to it. But still it just doesn’t know how to control its own heart rate consciously or ride a giant horse-sized bicycle. Then one day it learns these skills, and can let you adjust more of its actions. You had all the control the whole time, but all became more.</p>
<p><b>Consequences</b></p>
<p>One issue with this concept of taking over is that it isn’t clear what it means to ‘support’ a change. Each change has a number of consequences, and some of them are the point while others are undesirable side effects, such that averting them is an integral part of supporting the change. For instance, moving legs faster means using up blood oxygen and also traveling faster. If you gee up the horse, you want it to support this by replacing the missing blood oxygen, but not to jump on a treadmill to offset the faster travel. </p>
<p>For the horse to get this right in general, it seems that it needs to know about your higher level goals. In practice with horses, they are just built so that if they decide to run faster their respiratory system supplies more oxygen and they aren’t struck by a compulsion to get on a treadmill, and if that weren’t true we would look for a different animal to ride. The fact that they always assume one kind of thing is the goal of our intervention is fine, because in practice we do basically always want legs for motion and never for using up oxygen.</p>
<p>Maybe there is a systematic difference between desirable consequences and ones that should be offset—in the examples that I briefly think of, the desirable consequences seem more often to do with relationships with larger scale things, and the ones that need offsetting are to do with internal things, but that isn’t always true (I might travel because I want to be healthier, but I want to be in the same relationship with those who send me mail). If the situation seems to turn inputs into outputs, then the outputs are often the point, though that is also not always true (e.g. a garbage burner seeks to get rid of garbage, not create smoke). Both of these also seem maybe contingent on our world, whereas I’m interested in a general concept. </p>
<p><strong>Total takeover</strong></p>
<p>I’ll set that aside, and for now define a desirable model of controlling a system as something like: the system behaves as it would, but you can adjust aspects of the system and have it support your adjustment, such that the adjustment forwards your goals. </p>
<p>There isn’t a clear notion of ‘all the control’, since at any point there will be things that you can’t adjust (e.g. currently the shape of the horse’s mitochondria, for a long time the relationship between space and time in the horse system), either because you or the system don’t have a means of making the adjustment intentionally, or the system can’t support the adjustment usefully. However ‘all of the control that anyone has’ seems more straightforward, at least if we define who is counted in ‘anyone’. (If you can’t control the viral spread, is the virus a someone who has some of the universe’s control?)</p>
<p>I think whether having all of the control at a particular time gets at what I usually mean by having ‘taken over’ depends on what we expect to happen with new avenues of control that appear. If they automatically go to whoever had control, then having all of the control at one time seems like having taken over. If they get distributed more randomly (e.g. the horse learns to ride a bicycle, but keeps that power for itself, or a new agent is created with a power), so that your fraction of control deteriorates over time, that seems less like having taken over. If that is how our world is, I think I want to say that one cannot take it over.</p>
<p>***</p>
<p>This was a lot of abstract reasoning. I especially welcome correction from someone who feels they have successfully controlled a horse to a non-negligible degree.</p>",KatjaGrace,katjagrace,KatjaGrace,
iydwbZhATANhjoGP7,More variations on pseudo-alignment,more-variations-on-pseudo-alignment,https://www.lesswrong.com/posts/iydwbZhATANhjoGP7/more-variations-on-pseudo-alignment,2019-11-04T23:24:20.335Z,27,8,8,False,False,,"<p>In ""<a href=""https://arxiv.org/abs/1906.01820"">Risks from Learned Optimization</a>,"" we talked about a variety of different forms of pseudo-alignment—that is, ways in which a trained model's objective (its <em>mesa-objective</em>) can be misaligned off-distribution with the loss function it was trained under (the <em>base objective</em>). In particular, we distinguished between <a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/pL56xPoniLvtMDQ4J"">proxy alignment, suboptimality alignment, approximate alignment,</a> and <a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks"">deceptive alignment</a>. I still make heavy use of this classification, though I now believe that there are some additional types of pseudo-alignment which I think are fairly important but which I don't feel like this classification fully addresses. In particular, there are two variations on pseudo-alignment not discussed in the paper which I want to talk about here: <em>corrigible pseudo-alignment</em> and <em>suboptimality deceptive alignment</em>.</p>
<p><strong>Corrigible pseudo-alignment.</strong> In the paper, we defined <em>corrigible alignment</em> as the situation in which ""the base objective is incorporated into the mesa-optimizer's epistemic model and [the mesa-optimizer's] objective is modified to 'point to' that information."" We mostly just talked about this as a form of robust alignment—however, as I note in ""<a href=""https://www.alignmentforum.org/posts/BKM8uQS6QdJPZLqCr/towards-a-mechanistic-understanding-of-corrigibility"">Towards a mechanistic understanding of corrigibility</a>,"" this is a very unstable operation, requiring you to get your pointer just right. Thus, I think it's better to talk about corrigible alignment as the class of possible relationships between the base and mesa-objectives defined by the model having some sort of pointer to the base objective, including both <em>corrigible robust alignment</em> (if the pointer is robust) and <em>corrigible pseudo-alignment</em> (if the pointer is to some sort of non-robust proxy). In particular, I think this distinction is fairly important to why deceptive alignment might be more likely than robust alignment, as it points at why robust alignment via corrigibility might be quite difficult (which is a point we made in the paper, but one which I think is made much clearer with this distinction).</p>
<p><strong>Suboptimality deceptive alignment.</strong> In the paper, we defined <em>suboptimality alignment</em> as follows:</p>
<blockquote>
<p>A mesa-optimizer is <em>suboptimality aligned</em> if some deficiency, error, or limitation in its optimization process causes it to exhibit aligned behavior on the training distribution. This could be due to computational constraints, unsound reasoning, a lack of information, irrational decision procedures, or any other defect in the mesa-optimizer's reasoning process. Importantly, we are not referring to a situation where the mesa-optimizer is robustly aligned but nonetheless makes mistakes leading to bad outcomes on the base objective. Rather, suboptimality alignment refers to the situation where the mesa-optimizer is misaligned but nevertheless performs <em>well</em> on the base objective, precisely because it has been selected to make mistakes that lead to good outcomes on the base objective.</p>
</blockquote>
<p>I now think we may have seriously understated the importance of this case (especially the ""lack of information"" part). In particular, I think suboptimality alignment may be one of the most difficult to root out ways in which you get deceptive alignment.<sup class=""footnote-ref""><a href=""#fn-c83LAGH9YrND5SyJD-1"" id=""fnref-c83LAGH9YrND5SyJD-1"">[1]</a></sup></p>
<p>Specifically, suppose you train a model and end up with a proxy pseudo-aligned mesa-optimizer. Furthermore, suppose that the reason that it isn't deceptive is that it hasn't yet figured out that deception is a good strategy.<sup class=""footnote-ref""><a href=""#fn-c83LAGH9YrND5SyJD-2"" id=""fnref-c83LAGH9YrND5SyJD-2"">[2]</a></sup> If you then go to deploy such a model, doing so could be almost as (if not more) dangerous than deploying an already deceptive model, as it could turn deceptive on you at any point if it encounters the right information during deployment. Since this is a situation in which the only reason the model isn't deceptive is due to a lack of information, I've taken to calling this situation <em>suboptimality deceptive alignment</em> (though I'm open to suggestions for less clunky names).</p>
<p>As I mentioned recently in <a href=""https://www.lesswrong.com/posts/xzFQp7bmkoKfnae9R/but-exactly-how-complex-and-fragile#E37QgDmrP3tFy9DMb"">this comment</a>, I think that suboptimality deceptive alignment complicates a lot of stories for how we can correct issues in our AIs as they appear. First, even if you have the ability to detect and train away any deceptive cognition that appears during training, that's still insufficient to rule out suboptimality deceptive alignment, as your model could still end up becoming deceptive later during deployment.<sup class=""footnote-ref""><a href=""#fn-c83LAGH9YrND5SyJD-3"" id=""fnref-c83LAGH9YrND5SyJD-3"">[3]</a></sup> Second, it may be that the input which causes the model to become deceptive isn't generated naturally, but rather adversarially (by some competitor AI, for example). If natural inputs are unlikely to produce deception but adversarial ones are, then this could create a situation in which the deception comes too late to properly deal with (namely, only after you've already filled the world with competing AIs).<sup class=""footnote-ref""><a href=""#fn-c83LAGH9YrND5SyJD-4"" id=""fnref-c83LAGH9YrND5SyJD-4"">[4]</a></sup></p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-c83LAGH9YrND5SyJD-1"" class=""footnote-item""><p>I discussed this possibility previously in the section on suboptimality alignment in ""<a href=""https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"">Relaxed adversarial training for inner alignment</a>,"" though I think it also deserves additional attention here. <a href=""#fnref-c83LAGH9YrND5SyJD-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-c83LAGH9YrND5SyJD-2"" class=""footnote-item""><p>As opposed to because it's <a href=""https://www.alignmentforum.org/posts/BKM8uQS6QdJPZLqCr/towards-a-mechanistic-understanding-of-corrigibility"">myopic</a> (which solves this problem since a myopic model should never want to become deceptive) or some other reason that isn't due to a lack of information. <a href=""#fnref-c83LAGH9YrND5SyJD-2"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-c83LAGH9YrND5SyJD-3"" class=""footnote-item""><p>Online learning complicates this story somewhat, though even in that case it seems likely that there will still be some point at which you're relying on your model to generalize correctly in a situation where deception would be catastrophic (helping you build another AI, for example). <a href=""#fnref-c83LAGH9YrND5SyJD-3"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-c83LAGH9YrND5SyJD-4"" class=""footnote-item""><p>Unless you're doing some sort of <a href=""https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"">relaxed adversarial training</a> to train away such adversarial inputs. <a href=""#fnref-c83LAGH9YrND5SyJD-4"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
",evhub,evhub,evhub,
bfB879qQiPjwK9P7Y,Drug Policy,drug-policy,https://www.lesswrong.com/posts/bfB879qQiPjwK9P7Y/drug-policy,2019-11-04T21:30:02.058Z,7,1,1,False,False,,"<p>

I've been thinking some about what drug policy should look like, from
a few angles:



</p><p>

</p>

<ul>

<li><p>Drug prohibition hasn't gone very well.  It's very expensive,
leads to a lot of crime and jail time, and dangerous drugs are still
widely available.  Plus a lot of the ways that we think ""drugs are
dangerous"" are actually ""getting addicted to something illegal and
inconsistent is dangerous.</p></li>

<li><p>Which drugs we prohibit is a historical accident.  Alcohol is
substantially worse (<a href=""https://www.jefftk.com/nutt2007.pdf"">Nutt 2007</a>) than many
illegal options.</p></li>

<li>
<p>I <a href=""https://www.jefftk.com/p/mind-altering-substances"">don't like</a>
recreational drugs.  For a social lubricant I strongly prefer food,
music, dancing, singing, or gaming.

</p>
<p>

<a href=""https://www.jefftk.com/temperance-songs-big.jpg""><img src=""https://www.jefftk.com/temperance-songs.jpg"" /></a></p>
</li>

<li><p>Lots of people disagree with me on this.</p></li>

</ul>



<p>

I'd like to see a policy that approaches drugs from the perspective
that our society is going to have some, and pushes people in the
direction of drugs and approaches that are least harmful.  Something
like high taxes on alcohol and cigarettes, while removing restrictions
on vaping, cannabis, LSD, MDMA, and psilocybin.

</p>

<p>

For extremely addictive drugs such as heroin and other opioids, there
are probably social environments where they could be consumed safely.
Unlike alcohol, they don't lead people to hurt those around them, and
mostly cause harm through the efforts people will take to obtain more.
You could imagine some sort of ""heroin retirement"" that mitigates
these issues by having you put up funds to pay for heroin and
nursing-home style care for the rest of your life.

</p>

<p>

When considering the effects of various drugs there's also the way
they tend to make people change.  Stimulants typically increase
productivity, cannabis often reduces ambition, LSD can give people a
sense of oneness that can make them more altruistic, etc.  I'm not
sure if policy should consider things like this.

</p>

<p>

Overall our current policy is so far from reasonable that there are a
lot of potential ways to make it better, and I think the recent
efforts around marijuana legalization are a step forward.

  </p>",jkaufman,jkaufman,jefftk,
J9D6Bi3eFDDhCaovi,Will transparency help catch deception? Perhaps not,will-transparency-help-catch-deception-perhaps-not,https://www.lesswrong.com/posts/J9D6Bi3eFDDhCaovi/will-transparency-help-catch-deception-perhaps-not,2019-11-04T20:52:52.681Z,43,13,5,False,False,,"<p>In the last few months, some AI safety researchers have signaled what Wei Dai <a href=""https://www.alignmentforum.org/posts/pFAavCTW56iTsYkvR/ai-alignment-open-thread-october-2019#9sy6DdZx7tSSFYXcg"">called</a> a ""wave of optimism"" for using transparency tools to catch deceptive behavior in our machine learning models. By a transparency tool, I mean any technique that allows us to peek inside a model to get a better idea of what goes on inside of it. This post outlines one reason to be pessimistic about the usefulness of using transparency tools to catch advanced deception.</p><p>First, I construct a model for why we need transparency tools in the first place. I imagine the training process as a game played by two adversaries: a deceptive model, and an overseer trying to catch any deceptive reasoning. The issue for the overseer is that the deceptive model is opaque, which means that the overseer must use some tools to interpret its thoughts and behavior.</p><p>While by design, the deceptive model and overseer are comparably intelligent, the nature of using transparency tools enables a ""weakest link"" dynamic, implying that the deceptive model can exploit weaknesses in the transparency procedure to fool the overseer. In particular, deception can be hidden if the deceptive model has a good understanding of the deployment environment that isn't revealed while using transparency tools<em>.</em></p><p>In the end, I consider whether this weakness implies that transparency tools act as unnecessary middlemen for catching deception, and use an analogy to GANs to argue that training an overseer to detect deception end-to-end might work better.</p><h1>The model</h1><p>Our goal is to take a neural network and detect whether there are any inputs to the network that will cause it to act unacceptably. By assumption, we are concerned about <a href=""https://www.lesswrong.com/posts/zthDPAjh9w6Ytbeks/deceptive-alignment"">deceptive alignment</a>, a scenario where a misaligned model understands its training process, and will therefore act aligned during training while plotting something else for later.</p><p>Since we want to detect deceptive thoughts, we are interested in opening up the model and seeing what goes on inside. We have access to an overseer that interprets the model and spends time thinking whether the model has inputs which cause it to act catastrophically, which will allow us to penalize the model accordingly. Crucially, this overseer is not able to understand the model weights by themselves: instead it relies on a transparency procedure that converts the model into a relatable abstraction, which it then uses to determine whether the model is deceptive.</p><p>Formally, we can imagine the dynamic as the following. We are training a model, <span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-surd + .mjx-box {display: inline-flex}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span> which comes from a class of models <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span>. A transparency function maps models in <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""M""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span></span></span></span></span> to an abstract description of what the model does, <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""T:M\rightarrow D ""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;"">T</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;"">M</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span></span></span></span></span> . Descriptions can be construed very broadly, and they can include natural language descriptions of the model's decision process, charts and graphs, or even pseudocode. This description is fed to an overseer <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""O:D \rightarrow \{\text{True}, \text{False}\}""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.519em; padding-bottom: 0.298em;"">O</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.151em; padding-bottom: 0.372em;"">:</span></span><span class=""mjx-mi MJXc-space3""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.446em; padding-bottom: 0.298em;"">D</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.225em; padding-bottom: 0.372em;"">→</span></span><span class=""mjx-mo MJXc-space3""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">{</span></span><span class=""mjx-mtext""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">True</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""margin-top: -0.144em; padding-bottom: 0.519em;"">,</span></span><span class=""mjx-mtext MJXc-space1""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.372em; padding-bottom: 0.372em;"">False</span></span><span class=""mjx-mo""><span class=""mjx-char MJXc-TeX-main-R"" style=""padding-top: 0.446em; padding-bottom: 0.593em;"">}</span></span></span></span></span></span>, which detects whether the description implies that the model will act deceptively in the deployment environment.</p><p>We can think of the transparency function as making a tradeoff between two variables: brevity of the description, and faithfulness of the description to the model <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span>. If the description is too long, or complex, then there is no point of using a transparency function in the first place, since it doesn't actually make the model any more transparent. On the other hand, if the transparency function produces descriptions that are too short, then another problem occurs: the overseer will miss information that allows it to deduce the deceptive capabilities of <span><span class=""mjx-chtml""><span class=""mjx-math"" aria-label=""m""><span class=""mjx-mrow"" aria-hidden=""true""><span class=""mjx-mi""><span class=""mjx-char MJXc-TeX-math-I"" style=""padding-top: 0.225em; padding-bottom: 0.298em;"">m</span></span></span></span></span></span>.</p><p>Achieving a good balance of these variables will determine whether we should use transparency tools in the first place. A good transparency scheme will ideally provide a concise description of how the model makes decisions, while ensuring that nothing important is left out. We will now explore an example of this dynamic in an image classifier, and I will suggest that striking a perfect balance could be difficult.</p><h1>A deceptive image classifier</h1><p>Suppose we are training a neural network to recognize cars using some advanced neural network design. This neural network is smarter than your average convolutional neural network. In particular, rather than imagining it only as a set of neural layers with edge detectors, we also imagine that it has adaptive computational layers that can change depending on the gradient updates. At the extreme end, the training process could even nudge the neural network into arbitrary computational graphs, which allows for if-statements, explicit memory, and loops.</p><p>Allowing the model to adapt its structure during the gradient updates is very important, as it enables the model to be more robust to different domain distributions. For illustration of this effect, consider if the gradient updates produce the following schematic for the model.</p><span><figure><img src=""https://i.imgur.com/S0pWUux.png"" class=""draft-image center"" style=""width:81%""></figure></span><br><p>This design allows the model to be robust to different type of lighting, which demonstrates the utility of the adaptive approach. However, there's also a dark side to this adaptivity. While normally we think of models having only a choice over their input/output behavior, a sufficiently competent model could also understand the whole training procedure, which means that it could use <a href=""https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking"">gradient hacking</a> to route a path through the space of computational graphs.</p><p>Since the deceptive model can ask questions about what setting they are in, they can exploit this functionality by inserting an if-statement that checks whether they are currently inside the training environment. During training, we can expect that the model will act safely. During deployment, however, the switch will be activated and the model will pursue its own devious plans.</p><p>That's where the transparency tools and overseer come in.</p><p>The transparency function has the job of creating a relatable description of the model that would allow the overseer to catch any attempted deception. Of course, the transparency function can't just rely on using the input/output behavior of the model during training to produce a faithful description. Doing this would create a misleading impression, as it wouldn't allow the overseer to detect the dangers involved in a distribution shift.</p><p>Instead, the transparency function must convert the pile of matrices, and thus the internal structure of the model, into a relatable abstraction. But now this allows for the following troubling dynamic.</p><p>If the deceptive model understands how the transparency tools work, then it can modify its own architecture so that the transparency function leaves out important information. In the above example, the deceptive model might realize that the deployment environment will occur at night, and therefore use this if-statement as its signal to perform a treacherous turn. Further, since the deceptive model understands the transparency tool, it knows how to place if-statements that will be glossed over.</p><p>The transparency tools are intended to highlight decisions like this, but by assumption, the transparency tools are less 'intelligent' than the deceptive model. Therefore, it may choose to omit this if-statement in its description of the model, and focus on information it believes is more critical.</p><p>In other words, not realizing that the nighttime-check was the signal for a treacherous turn, the transparency tool glosses over this if-statement, and doesn't provide it to the overseer.</p><p>This ends in catastrophe once the deception is successful. The overseer <em>is</em> comparably intelligent to the deceptive model, but since the if-statement above was omitted in the transparency description, the overseer was not able to deduce the dangerous off-distribution behavior. </p><p>Therefore, the deceptive model successfully fooled the overseer, even though both players in the game were comparably intelligent.</p><h2>Why are we assuming that the transparency tools are less intelligent than the deceptive model?</h2><p>An immediate objection is simply, ""Yes but a good transparency tool would not have omitted the if-statement."" Ultimately, I think this is a weak objection.</p><p>The first thing to note is that is that the transparency function wasn't totally dumb. Understanding the nature of the deployment environment is hard. The transparency function was just doing its job by trading off brevity and faithfulness. To make this point more compelling, we can consider that the true computational graph was really a large decision tree, with a huge branching factor for the various types of situations the model could be in. </p><span><figure><img src=""https://i.imgur.com/cbhPoDp.png"" class=""draft-image center"" style=""width:40%""></figure></span><p>In my example, the transparency tool is really just doing its best job of pruning the irrelevant parts of the tree. If you didn't know the important detail that the deployment environment was at night, then checking whether there is dark or dim lighting could simply be seen as a side feature that allowed the model to be more robust, and something like that can be omitted.</p><p>More importantly, if we allow the transparency tools to be more intelligent than the deceptive model, we must question the role that the overseer is playing in this dynamic. For instance, if the transparency model was exceptionally competent, then all it needs to do in its description is either say, ""This model is deceptive"" or say, ""This model is not deceptive."" Then, the overseer's job is trivial.</p><p>This suggests that decomposing safety-checking into two components: a transparency tool, and an overseer that interprets the results of the tool, is a <em>bad</em> <em>model</em>. If the transparency tools are too weak, then the deceptive model will exploit this weakness to fool the overseer, even if the overseer is very intelligent. On the other hand, if the tools are very strong, then the overseer plays no role at all -- suggesting that there was never any need to create interpretability tools, since a deception-checker trained end-to-end would have worked fine.</p><p>To better highlight why I think this casts doubt on transparency tools, I offer an analogy with GANs.</p><h1>A fictional suggestion for training GANs</h1><p>GANs are trained via an adversarial game between two neural networks. One neural network -- the generator -- is trained to produce a counterfeit sample when it is given some latent noise, and the other -- the discriminator -- is trained to detect whether a sample is counterfeit or from the real distribution.</p><p>Suppose someone were to propose the following way to help the discriminator: rather than training it end-to-end to help detect counterfeit samples, we instead make its input equal to the output of a transparency tool that gives it insight into how the current sample looks. The transparency tool could, for instance, highlight if it detects any weird shadows or bad lighting, and then feed this information to the discriminator to produce a final determination.</p><p>""Since the transparency tool focuses on the weaknesses of the generator, this will allow the discriminator to more easily detect counterfeit samples,"" the person argues.</p><p>But what the person failed to consider was that all this tool did was <em>relax</em> the job of the generator, since now all it needs to do is get past the weird-shadow and bad-lighting detector stage. It doesn't even matter how competent the discriminator is, since it's only given information from the transparency tool.</p><p>The person replies, ""OK fine, we can give the discriminator the output from the tool, <em>and</em> the original sample. That way it can use the tool as a bonus to help it make the determination."" </p><p>But now, the discriminator is operating over a larger dimension input-space than it would have otherwise, which makes its job harder. If it was simply trained end-to-end, then it could have developed a weird-shadow detector and bad-lighting detector <em>on its own, </em>if that were appropriate. But now it has extraneous information, which may or may not be useful for actually detecting counterfeit samples.</p><h1>Conclusion</h1><p>Contra <a href=""https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines"">Betteridge's law of headlines</a>, I still think that transparency tools can be useful for catching deception. Also, this argument does not imply that transparency tools are useless for tasks other than catching deception. The biggest weakness with my argument is that the alternative I offered was training an overseer end-to-end, which is not possible if we are assuming a human is the overseer. </p><p>However, I don't think that this weakness is fatal to my argument: in order for transparency tools to work well, they must be strong enough that their weaknesses can't be exploited by a deceptive model. But we just argued above that if the tools were that strong, they would already be indistinguishable from a deception checker trained end-to-end.</p><p>Finally, I suspect people will object to my argument by saying that I am taking a very narrow approach to transparency tools, and that a model trained end-to-end to detect deception <em>still counts</em> as a transparency tool. I have little to say about this objection other than, I'm not arguing against <em>that</em> <em>type</em> of tool.</p>",matthew-barnett,matthew-barnett,Matthew Barnett,
BsHsHuKouQYRx2CJB,Politics is work and work needs breaks,politics-is-work-and-work-needs-breaks,https://www.lesswrong.com/posts/BsHsHuKouQYRx2CJB/politics-is-work-and-work-needs-breaks,2019-11-04T17:10:01.120Z,19,9,0,False,False,,"<p><em>A post written a few years ago, posting now during a time of irrelevance (as far as I know with my limited attention on politics or social media) so as not to be accidentally taking a side in any specific political debates.</em></p>
<p>***</p>
<blockquote>
<p><strong>Alexandra </strong>What has happened is shocking and everyone should oppose it.</p>
<p><strong>Beatrice </strong>I’m eating a sandwich. It is better than I expected.</p>
<p><strong>Alexandra</strong> I can’t believe you would write about a sandwich at a time like this. Don’t you oppose what happened?</p>
<p><em>(<strong>Claire</strong> is excited by the breakfast bread discussion but guesses that contributing a picture of her bagel is pretty inappropriate and looks at SMBC instead.)</em></p>
</blockquote>
<p>People break up their time into work and leisure. You might think of work vs. leisure as roughly ‘doing stuff because other people pay for it’ vs. ‘doing stuff because you want to’. You can also think of it as roughly ‘effortful’ vs. ‘relaxing’. Often these categories align—other people pay you to do effortful things, and the things you want to do are more relaxing. They don’t always align. Helping your aged relative go to the doctor might be effortful but a thing you do because you want to, or your job might be so easy that you come home with a bunch of energy for challenging tasks.</p>
<p>I’m going to call these ‘resting-‘ vs. ‘challenged-‘ and ‘-boss’ vs. ‘-employee’. So entirely free time is mostly resting-boss and paid work is usually challenged-employee. But you can also get resting-employee and challenged-boss activities. This all maybe relies on some models of rest and attention and effort and such that don’t work out, but they seem at least close the models that most people practically rely on. For whatever reason, most people prefer to spend a decent fraction of their time doing non-effortful things, unless something terrible will happen soon if they don’t.</p>
<p>People mostly use social media as leisure, both in the sense that nobody would intentionally pay them for it, and in the sense that it is not effortful. When important political things are happening, social media naturally turns to discussion of them. Which, if you are lucky, might be thoughtful analysis of world affairs, with a bunch of statistics and rethinking your assumptions and learning new facts about the world. Which is all great, but it is not leisure in the ‘not effort’ sense. When I need a break from researching the likely social consequences of artificial intelligence, moving to researching the likely social consequences of changing identity politics in America does not hit the spot as well as you might hope. I assume something similar is true of many people.</p>
<p>When there are opportunities to move a lot of leisure time from resting-boss idle chat to challenged-boss political discussions, people can be appalled when others do not redirect their use of social media to talking about the problem. They are thinking, ‘when you are doing what you want, you should be wanting this! If you would really spend your limited time on pictures of animals that look like pastry when you can help to stop this travesty, you are terrible!’</p>
<p>However this means moving time that was in ‘relaxing’ to ‘effortful’, which as far as I can tell is not super sustainable. In the sense that people usually need to spend some amount of time relaxing to be happy and able to do effortful things at other times. Redistributing all of the relaxing time to effortful time makes sense when there is a very immediate threat—for instance, your house is on fire, or you have a deadline this week that will cause you to lose your job if you don’t dedicate all of your time to it. However if you have a problem on the scale of months’ or years’ worth of effort, I think most people would favor making that effort as a sustainable trek, with breaks and lunch and jokes. For instance, if you are trying to get tenure in a few years, many would predict that you are less likely to succeed if you now attempt to ban all leisure from your life and work all of the time.</p>
<p>When there are political events that seem to some people to warrant talking about all of the time, and some people who really don’t want to, I think this less implies a difference in concern about the problem than you might think. The disagreeing parties could also be framing work and leisure differently, or disagreeing over how short-lived the important problem is, or when the high leverage times for responding to it are.</p>",KatjaGrace,katjagrace,KatjaGrace,
RegdNi2yMHjcywAAx,Elon Musk is wrong: Robotaxis are stupid. We need standardized rented autonomous tugs to move customized owned unpowered wagons.,elon-musk-is-wrong-robotaxis-are-stupid-we-need-standardized,https://www.lesswrong.com/posts/RegdNi2yMHjcywAAx/elon-musk-is-wrong-robotaxis-are-stupid-we-need-standardized,2019-11-04T14:04:10.851Z,36,36,35,False,False,,"<p>Sorry for the flashy headline, but I genuinely feel this might be the best idea I ever had.</p><p>After the invention of the horseless carriage, it supposedly took people years to realize that without reins to hold, the driver could now sit inside the cabin. Change of the core technology allowed a rethink of the entire product (the vehicle) but that rethink was hard.</p><p>With autonomous cars, we already have a rethink. Autonomous vehicles can be called to a person who needs it, so they should not be owned (and sit idle while the owner doesn&apos;t need to move) but should be taxis. Lots of people, including Elon Musk, agree that&apos;s the way to go. And it is indeed an improvement over the current car ownership model. But it doesn&apos;t go far enough.</p><p>The robotaxi concept retains an outdated assumption: that a single product, a single vehicle needs to do both the moving and the accommodation of the user.</p><p>Get rid of that assumption and imagine instead a system made from two very different parts that can (automatically) couple and uncouple:</p><ul><li>A driving unit (tug) with the motor, driving and communication systems. This is usually rented not owned.</li><li>An accommodation unit (wagon) for the human(s) and their stuff. This is usually owned not rented.</li></ul><p>How is this better than robotaxis? Lots of reasons!</p><ul><li>Your personal wagon can have a bed in it, or your valuables, or spare underwear. You can use it as a movable locker, as you do every time you use a personal car to get groceries from multiple shops. You can sleep in it.</li><li>Your personal wagon gives you full control over the space you occupy while traveling. A robotaxi requires you to take out your stuff every time you leave and check whether the previous user did every time you enter. And what if the previous occupant used a perfume you&apos;re allergic to?</li><li>The tug doesn&apos;t need seats, windows or air conditioning. It doesn&apos;t need to haul all that mass every time it is called to a new user. A lot of complexity is removed from production, so these are much cheaper to build than robotaxis.</li><li>Renting out these tugs is much less hassle than renting out robotaxis because they need much less maintenance. They can be pretty thoroughly protected from interference by users. Charging infrastructure for tugs needs much less space than charging infrastructure for robotaxis.</li><li>Your personal wagon can be in a huge variety of designs and sizes! Human-piloted cars, and robotaxis, are very hard to build and only make economic sense in huge numbers, forcing standard designs that are suboptimal at specialized tasks. Unpowered wagons are much easier to build, so small production runs make sense. A small-ish company could build specialized wagon types like the self-driving office, the mobile hairdresser&apos;s salon or the Sparkly Unicorn Car that takes your kid to school.</li></ul><p>Now that I thought of it, I can&apos;t unsee it. It seems blindingly obvious this kind of system is much better than robotaxis.</p><p>And the technical side wouldn&apos;t be that hard to do. You need a standard interface between the two, the wagon needs to give the tug reliable info about its physical properties and maybe it&apos;s worth thinking about whether one of the two can make do without a battery. No doubt I&apos;m missing some details, but trains have separated locomotives from wagons for a long time, it can&apos;t be that hard.</p><p>There&apos;s a bit of a chicken and egg problem where you need to be sure the other part of the system will exist before you start producing your own side. But that seems solvable with sufficient clout. If Tesla can indeed demonstrate functioning robotaxis, then Elon Musk saying they&apos;re going to build tugs (with an open source coupling interface) should be enough for lots of players to start designing wagons.</p><p>So I think it&apos;s very doable. And the aforementioned advantages over robotaxis would help get rid of gasoline cars even faster than robotaxis would. And that would help with global warming. So we should all want this.</p><p>Am I wrong?</p>",chaosmage,chaosmage,chaosmage,
xh3z6St5dCt5frRAF,Book Review: Man's Search for Meaning by Victor Frankel,book-review-man-s-search-for-meaning-by-victor-frankel,https://www.lesswrong.com/posts/xh3z6St5dCt5frRAF/book-review-man-s-search-for-meaning-by-victor-frankel,2019-11-04T11:21:05.791Z,17,9,0,False,False,,"<p>(Oops, I meant this to be a shortform)</p><p>&quot;Everything can be taken from a man but one thing: the last of the human freedoms&#x2014;to choose one&#x2019;s attitude in any given set of circumstances, to choose one&#x2019;s own way&quot;</p><p>&#x201C;He who has a why to live for can bear almost any how.&#x201D; &#x2014;Friedrich Nietzsche</p><p>The core premise of this book is well-known: that in order to survive the harshest and most terrible of circumstances one must have some kind of purpose to keep them going. This book describes the kind of mindset that one would have to adopt to survive in such circumstances, but the question that kept arising in my mind was, &quot;Would it actually be worth it?&quot;. Would it actually be worth it to endure the degrading and inhumane conditions of a concentration camp given that it would almost certainly come to nothing? Perhaps if I knew that I was going to survive then I could find some meaning and growth in the suffering, but to go through all that suffering and for it all to be a waste... Or perhaps one could endure for love, but what would this amount to if you were likely to never be reunited, if they could already be dead? Or if one thought they could achieve the kind of good Victor Frankel did, but that lot falls to very few.</p><p>Victor Frankel is religious so he can find purpose in this. If there is a God and he he has a purpose, then one has played a role in this divine plan by bearing their suffering with dignity and could further hope to be rewarded in the afterlife. So he would view his life as having been meaningful even if he had perished, but what about the rest of us? Ultimately, I suspect that I may be asking too much out of him. These techniques could still provide a large amount of value, even if we reject his premise that any life is still worth leading, for a life can still be worth leading even if it involves a great deal of suffering.</p><p>His view that life is always worth living is expressed in the following quote: &quot;Life asks you the meaning of life; you don&apos;t ask life. You are questioned by life. It&apos;s not what you expect from life, but what life expects from you.&quot; As noted, I disagree with this in extreme circumstances, but nonetheless, once it has been established that life is worthwhile or at least that you don&apos;t want to die, this attitude is on the whole healthy.</p><p>Camp life:</p><p>I found these descriptions very insightful. Very quickly: The despair when a prisoner wasn&apos;t allowed to keep anything, not even a wedding ring or a manuscript containing their lives work. A guard pointing left or right determining whether you live or die. The importance of regularly shaving so that they would appear fit for work. That the prisoner&apos;s were allowed some amusement in camp; they often self-organised a cabaret. That smoking a cigarette indicated giving up on life; it could have been traded for a soup. How a prisoner felt lucky when they received a scoop of soup from the bottom as it would contain peas.</p><p>Dr Frankel believes that we are often far more capable of adapting than we believe. He found that most prisoners quickly became inured to the crowded conditions and the beatings of the guards. Even the horror of the gas chambers disappear for many as it at least spared them committing suicide. Surprisingly, all of the suffering didn&apos;t dull their feeling of indignation when they felt they&apos;d been treated unfairly. For example, Dr Frankel had been working really hard and only paused for a moment, but it happened to be just when a guard turned around. The guard threw a rock at him which missed, but this still triggered a strong emotional reaction in him.</p><p>After release:</p><p>Dr Frankel noted that release came with some hazards too. He relates an example of a fellow prisoner treading through young crops despite his protests. The prisoner angrily exclaimed, &quot;My wife and child have been gassed, not to mention everything else, you would forbid me the right to tread on a few oats&quot;. Dr Frankel was not so worried about a few crops as the long term effects that might result from such an attitude.&apos;</p><p>He talks about the bitterness that could often result. That someone could survive all of that and only be met with a shrug of the shoulders or hackneyed phrases like &quot;we have suffered too&quot; as though their suffering had been unimportant. Others suffered horrible disillusionment. During the camps people had held onto the hope of being reunited with their loved ones in order to make it through, but often found that no-one was waiting for them.</p><p>Meaning:</p><p>Victor Frankel takes an existential view of life. He believes that finding a purpose is overwhelmingly important as, &quot;to live is to suffer, to survive is to find meaning in the suffering&quot;. He doesn&apos;t believe that this meaning is fixed, but that it, &quot;differs from man to man, day to day and hour to hour&quot;. He is determined not to allow the patient to make him the judge, but rather to force them to decide for themselves, &quot;whether they are responsible to society or merely their own conscious&quot;.</p><p>He argues that one can gain meaning from the contemplation of the loved, even if they are no longer present or even alive. The later claim here really struck me. On one level it seems almost absurd to gain meaning from the contemplation of one who no longer exists, as though one is denying reality. However, on another level, what was achieved was achieved and what does being meaningful mean apart from the fact that it is meaningful for you?</p><p>He writes that that &quot;someone who is passive will regret the passage of time, but someone who is active can reflect on all the life that they&apos;ve lived to the fullest&quot;. He argues that they wouldn&apos;t envy a young person as instead of possibilities they would have concrete realities and achievements in the past. This seems like a really healthy attitude to life.</p><p>Societal expectations:</p><p>Dr Frankel is critical of the mental hygiene movement that considers unhappiness a defect as he argues that this only makes people more unhappy. He writes: &quot;To the European, it is a characteristic of the American culture that again and again one is ordered to be happy. But happiness cannot be pursued, one must have a reason to be happy. But once the reason is found, one becomes happy automatically&quot;.</p><p>He encountered young patients who were neurotic as a result of unemployment. He writes that, &quot;joblessness was equated with being useless and being uselessness with having a meaningless life&quot;. Their depression abated when he succeeded in convincing them to fill their time with some kind of volunteering.</p><p>Therapy:</p><p>One technique he often used was what he called paradoxical intention. The idea was that we are often stuck in a cycle where we fail because we are nervous and we are nervous because we fail. His solution is to intentional fail; sometimes we will find that we cannot any we actually succeed, other times we will, but we&apos;ll lose our fear of failure.</p><p>Another technique he uses is to ask people to imagine looking back from their death bed. A mother was in great despair because one of her sons had died and the other was disabled. When imagining looking back from her deathbed, she realised that if she had lived an easy life, but had no children she wouldn&apos;t have considered it a meaningful life, but that she found that she would consider it to have been meaningful to have made her son&apos;s life better. Sometimes intentionally adopting this perspective can make us aware that our life is meaningful in a way that we missed.</p>",Chris_Leong,chris_leong,Chris_Leong,
JMoASne9ccMBxntaX,Ways that China is surpassing the US,ways-that-china-is-surpassing-the-us,https://www.lesswrong.com/posts/JMoASne9ccMBxntaX/ways-that-china-is-surpassing-the-us,2019-11-04T09:45:53.881Z,59,28,19,False,False,https://palladiummag.com/2019/10/11/the-american-dream-is-alive-in-china/,"<html><head></head><body><p>[Edit: Changed the post title from the original article title to something more meaningful.]</p>
<p>I came across this article today, and I have to agree with it strongly based on my own recent trip to China. The update it triggered for me is the realization that China is genuinely doing better than the US on many fronts, most importantly on <em>governance</em>. How/why did that happen? Did anyone or any political theory predict this ahead of time? (In case it's not clear, this is not meant to be a rhetorical question. I'm surprised and confused and am wondering if someone or some theory can offer an explanation.) What does it imply for things like AI governance and global coordination on x-risks?</p>
<p>Below I'll quote two sections that summarize most of the article. Click the link above for the full text.</p>
<hr>
<p>China is changing in a deep and visceral way, and it is changing fast , in a way that is almost incomprehensible without seeing it in person. In contrast to America’s stagnation, China’s culture, self-concept, and morale are being transformed at a rapid pace—mostly for the better.</p>
<p>For Americans, this transformation towards competence and prosperity should be the more worrying thing about China. We aren’t well-coordinated with China, and it is starting to surpass the U.S. in important ways. If we ignore this point by focusing only on the moral negatives, of which there are many, we risk underrating the competition until it’s too late, or failing to reflect on the importance of solving our own mounting problems of governance.</p>
<p>More optimistically, we should study Chinese development as a positive example of how to do better on the things that America has been fumbling recently: infrastructure, growth, industrial policy, and positive transformation of everyday life. America has been a shining beacon of this kind of development in the past, and can be again, if we’re willing to look closer at what China does right.</p>
<p>[...]</p>
<p>If I’m being honest, China’s success scares me. There is something deeply disconcerting about watching China surpass America in the ways it is. China is transforming fishing villages into major industrial cities, while we fail to build high-speed rail or new housing. How are we going to catch up?</p>
<p>Is it really as bad as it seems? I understand the instinct to avoid the topic, disbelieve it, and play it down. I’ve even had the instinct to stay quiet about China’s progress myself: I worry that no one will appreciate the reminder. Perhaps this is why we’ve heard so little about this aspect of things.</p>
<p>But if we’re going to build a good society in America, we have to face these things head-on.</p>
<p>In the U.S., we face an ongoing crisis of governance. We need to understand our own failures, and we need to grapple with unexpected demonstrations of success—even if they come from non-liberal societies.</p>
<p>China’s success challenges our implicit ideology and deep-seated assumptions about governance. It needs to be studied—not just to bring about better coordination, but because in its accomplishments, we may find important truths needed to bring about American revitalization.</p>
</body></html>",Wei_Dai,wei-dai,Wei Dai,
gptXmhJxFiEwuPN98,Meetup Notes: Ole Peters on ergodicity,meetup-notes-ole-peters-on-ergodicity,https://www.lesswrong.com/posts/gptXmhJxFiEwuPN98/meetup-notes-ole-peters-on-ergodicity,2019-11-03T23:31:01.889Z,32,15,13,False,False,,"<p><u><a href=""https://ergodicityeconomics.com/"">Ole Peters</a></u> claims that the standard expected utility toolbox for evaluating wagers is a flawed basis for rational decisionmaking. In particular, it commonly fails to take into account that an investor/bettor taking a series of repeated bets is not an <u><a href=""https://en.wikipedia.org/wiki/Ergodicity"">ergodic</a></u> process.</p><p><a href=""https://www.lesswrong.com/users/optimization-process"">Optimization Process</a>, <a href=""https://www.lesswrong.com/users/internety"">internety</a>, myself, and a couple others spent about 5 hours across a couple of Seattle meetups investigating what Peters was saying.</p><h1>Background</h1><h2>Why do we care?</h2><p>Proximally, because <u><a href=""https://medium.com/incerto/the-logic-of-risk-taking-107bf41029d3"">Nassim Taleb is bananas about ergodicity</a></u>.</p><p>More interestingly, expected utility maximization is widely accepted as the basis for rational decisionmaking. Finding flaws (or at least pathologies) in this foundation is therefore quite high leverage.</p><p>A specific example: many people&apos;s retirement investment strategies might be said to be taking the &quot;ensemble average&quot; as their optimization target - i.e. their portfolios are built on the assumption that, every year, an individual investor should make the choice that, when averaged across (e.g.) 100,000 investors making that choice for that year, will maximize the mean wealth (or mean utility) of investors in the group at the end of that year. It&apos;s <u><a href=""https://medium.com/fresheconomicthinking/revisiting-the-mathematics-of-economic-expectations-66bc9ad8f605"">claimed</a></u> that this means that individual retirement plans can&apos;t work because many individuals will, in actuality, eventually be impoverished by market swings, and that social insurance schemes (e.g. Social Security) where the current rich are transferring wealth to the current poor avoid this pitfall.</p><p>Claims about shortcomings in expected utility maximization are also interesting because I&apos;ve felt vaguely confused for a long time about why expected value/utility is the right way to evaluate decisions; it seems like I might be more strongly interested in something like &quot;the 99th percentile outcome for the overall utility generated over my lifetime&quot;. Any work that promises to pick at the corners of EU maximization is worth looking at.</p><h2>What does existing non-Peters theory say?</h2><p>The <u><a href=""https://en.wikipedia.org/w/index.php?title=Von_Neumann%E2%80%93Morgenstern_utility_theorem&amp;oldid=911857950"">Von Neumann-Morgenstern theorem</a></u> says, loosely, that all rational actors are maximizing <em>some</em> utility function in expectation. It&apos;s almost certainly not the case that Ole Peters has produced a counterexample, but (again) identifying apparently pathological behavior implied by the VNM math would be quite useful.</p><p>Economics research as a whole tends to take it as given that individual actors are trying to maximize, in expectation, the logarithm of their wealth (or some similar risk-averse function mapping wealth to utility).</p><h1>Specific claims made by Peters et al.</h1><p>We were pretty confused about this and spent a bunch of investigation time simply nailing down what was being claimed!</p><ul><li><u><a href=""https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2011.0065"">Log-wealth-maximization straightforwardly falls out of doing some &quot;more appropriate&quot; time-average (instead of ensemble-average) analysis of the St. Petersburg lottery.</a></u></li><li><u><a href=""https://arxiv.org/pdf/1405.0585.pdf"">You can make rational choices about wealth without needing to pick a &quot;utility function&quot; at all.</a></u></li><li><u><a href=""https://arxiv.org/pdf/1405.0585.pdf"">Expected utility maximization has some major pathologies.</a></u> (didn&apos;t have time to dig through this paper enough to identify the specific pathologies claimed)</li><li><u><a href=""https://medium.com/fresheconomicthinking/revisiting-the-mathematics-of-economic-expectations-66bc9ad8f605"">There&apos;s a major difference between the conclusions you&apos;ll come to when reasoning using &quot;ensemble average&quot; instead of &quot;time average&quot;.</a></u></li></ul><h1>What we learned</h1><h2><u><a href=""https://medium.com/fresheconomicthinking/revisiting-the-mathematics-of-economic-expectations-66bc9ad8f605"">1.5x/0.6x coin flip bet</a></u></h2><p>This is a specific example from <u><a href=""https://medium.com/fresheconomicthinking/revisiting-the-mathematics-of-economic-expectations-66bc9ad8f605"">https://medium.com/fresheconomicthinking/revisiting-the-mathematics-of-economic-expectations-66bc9ad8f605</a></u></p><p>Here&apos;s what we concluded. [These tags explain the level of proof we used.]</p><ul><li>It is indeed the case that playing many, many rounds of this bet compresses almost all the winnings into a tiny corner of probability space, with &quot;lost a bunch of money&quot; being the overwhelming majority of outcomes. [math proof]</li><li><u><a href=""https://drive.google.com/file/d/1CradEIbYGJHtXAF3Do7OnKvKCmbSsVvk/view?usp=sharing"">However, no log-wealth-maximizer would accept the bet, ever (at least, not at the stated &quot;bet entire bankroll every time&quot; stakes). [math proof]</a></u></li><li>Betting only a tiny, constant chunk of your bankroll every time instead of all your money at once does, as expected, make you richer most of the time. [Monte Carlo simulation, intuition]</li><li>Reasoning about what happens over a gazillion rounds of the game is a little bunk because you don&apos;t have to commit to play a zillion rounds up front. [hand-waving math intuition]</li><ul><li>i.e. if someone is choosing, every round, whether or not to keep playing the game, pointing out that (their decision in round N to keep playing is dumb because it would be a terrible idea to commit to play a gazillion ( &gt;&gt; N ) rounds up front) is a red herring.</li></ul></ul><h2>&quot;Rich house, poor player&quot; theorems</h2><p>The &quot;coin flip&quot; example of the previous section is claimed to be interesting because most players go bankrupt, despite every wager offered being positive expected value to the player.</p><p>So then an interesting question arises: can some rich &quot;house&quot; exploit some less-rich &quot;player&quot; player by offering a positive-expected-value wager that the player will always choose to accept, but that leads with near certainty to the player&apos;s bankruptcy when played indefinitely?</p><p>(As noted in the last section, no log-wealth-utility player would take even the first bet, so we chose to steelman/simplify by assuming that wealth == utility (either adjusting the gamble so that it <em>is</em> positive expected utility, or adjusting the player to have utility linear in wealth))</p><p>We think it&apos;s pretty obvious that, if the house can fund wagers whose player-utility is unbounded (either the house has infinity money, or the player has some convenient utility function), then, yes, the house can <u><a href=""https://en.wikipedia.org/wiki/Almost_surely"">almost surely</a></u> bankrupt the player.</p><p>So, instead, consider a house that has some finite amount of money. We have a half-baked math proof (<u><a href=""https://drive.google.com/file/d/1DpaupTMRQJVfOzlYkqAKNv2eoSSCne6T/view?usp=sharing"">[1]</a></u> <u><a href=""https://drive.google.com/file/d/1Du-y1MiTk_GTpvDDMccze_RBZZUYK2A1/view?usp=sharing"">[2]</a></u>) that there can&apos;t exist a way for the house to almost-surely (defined as &quot;drive the probability of bankruptcy to above (1 - epsilon) for any given epsilon&quot;) bankrupt the player.</p><p>Tangentially: there&apos;s a symmetry issue here: you can just as well say &quot;the house will eventually go bankrupt&quot; if the house will be repeatedly playing some game with unbounded max payoff with many players. However, note that zero-sum games that neither party deems wise to play are not unheard of; risk-averse agents don&apos;t want to play <em>any</em> zero-sum games at fair odds!</p><h2><u><a href=""https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2011.0065"">Paper: The time resolution of the St Petersburg Paradox</a></u></h2><p>This paper claims to apply Peters&apos;s time-average (instead of ensemble-average) methods to resolve the <u><a href=""https://en.wikipedia.org/wiki/St._Petersburg_paradox"">St. Petersburg Paradox</a></u>, and to derive &quot;utility logarithmic in wealth&quot; as a straightforward implication of the time-average reasoning he uses.</p><p>We spent about an hour trying to digest this. Unfortunately, academic math papers are often impenetrable even when they&apos;re making correct statements using mathematical tools the reader is familiar with, so we&apos;re not sure of our conclusions.</p><p>That said <u><a href=""https://docs.google.com/document/d/1nH2u24d9SmRosLtJKqgT80RlQ41Sxbd9n2jpafgEFtk/edit?usp=sharing"">here are some loose notes pointing to particular steps we either  couldn&apos;t verify the validity of or think are invalid</a></u>.</p><p><a href=""https://www.lesswrong.com/users/optimization-process"">Optimization Process</a> also pointed out that equation (6.6) doesn&apos;t really make sense for a lottery where the payout is always zero.</p><p>This paper works from the assumption that the player is trying to maximize (in expectation) the exponential growth rate of their wealth. <u><a href=""https://drive.google.com/file/d/11lxWpJhFkV-oWquPtOx0Md_5Z-6U3Gmm/view?usp=sharing"">We noticed that this <em>is</em> the log-wealth-maximizer</a></u> - i.e. in order to to get from &quot;maximizes growth&quot; to &quot;maximizes the logarithm of wealth&quot;, you don&apos;t seem to actually need whatever derivation Peters&apos;s paper is making.</p><h1>Conclusions</h1><p>We still don&apos;t understand what &quot;the problem with expected utility&quot; is that Peters is pointing at. It seems like expected utility with a risk-averse utility function is sufficient to make appropriate choices in the 1.5x/0.6x flip and St. Petersburg gambles.</p><p>Peters&apos;s time-average vs. ensemble-average St. Petersburg paper either has broken math, or we don&apos;t understand it. Either way, we&apos;re still confused about the time- vs. ensemble-average distinction&apos;s application to gambles.</p><p>Peters&apos;s St. Petersburg Paradox paper does derive something equivalent to log-wealth-utility from maximizing expected growth rate, but maybe this is an elaborate exercise in begging the question by assuming &quot;maximize expected growth rate&quot; as the goal.</p><p>I, personally, am unimpressed by Peters&apos;s claims, and I don&apos;t intend to spend more brainpower investigating them.</p>",Orborde,orborde,Orborde,
bhSjufKtnPRWqW52h,"Picture Frames, Window Frames and Frameworks",picture-frames-window-frames-and-frameworks-1,https://www.lesswrong.com/posts/bhSjufKtnPRWqW52h/picture-frames-window-frames-and-frameworks-1,2019-11-03T22:09:58.181Z,35,12,7,False,False,,"<p>Some commenters on <a href=""http://localhost:3000/posts/f886riNJcArmpFahm/noticing-frame-differences"">Noticing Frames</a> were confused about<i> </i>what I actually meant by ""frame."" I defined it briefly as ""different ways of seeing, thinking and communicating"", but this was a bit vague.</p><p>I'm definitely using the word ""frame"" as a broad metaphor, rather than a concrete specific phenomenon. I'm not at a point where <i>I'm</i> sure I have a more concrete phenemonon to explicitly describe. I recognize this as an important red flag –&nbsp;<a href=""http://localhost:3000/posts/XosKB3mkvmXMZ3fBQ/specificity-your-brain-s-superpower"">specificity is good</a>, and I'll try to get more concrete in future posts. For now, though, I think the broad metaphor is useful, and want to explain it slightly better.</p><p>After reflecting on the feedback, I realized it was actually three different metaphors:</p><ul><li><strong>Picture Frames</strong> (ways of communicating)</li><li><strong>Window Frames</strong> (ways of seeing)</li><li><strong>Frameworks</strong> (ways of thinking)</li></ul><p>Upon reflection, I endorse using all three metaphors fuzzily rolled into one.</p><p>The past few years, I kept thinking I had figured out why resolving disagreements was hard, and kept being surprised by <i>new</i> ways to subtly miss each other. At first I thought the main reasons to disagree were <i>""different beliefs""</i>, <i>""different values""</i>, and <i>""confusion over beliefs/values.""</i> This isn't wrong, but it wasn't nuanced enough for me to notice all the disconnects.</p><p>I've come to believe there's an important general skill, which goes something like:</p><blockquote><p><strong>Trigger: </strong>Notice when a conversation is going nowhere, especially over the timescale of months/years.</p></blockquote><blockquote><p><strong>Action: </strong>Look for frame differences <i>outside of the ones you know to make sense of, </i>and figure out how to make sense of them.</p></blockquote><p>That's a hell of a vague action, I admit. It's composed of smaller, more specific actions (which are probably easier to learn). I was worried that if I named the most specific actions I could point at, people would focus on that and <a href=""http://localhost:3000/posts/sP2Hg6uPwpfp3jZJN/lost-purposes"">lose sight of the more general problem.</a> I'm not even certain that the ""different ways of seeing, thinking, and communicating"" schema is complete –&nbsp;it's meant to be illustrative rather than comprehensive.</p><p>Someday, ideally, there'll be a ""how to"" doublecrux sequence that teaches concrete skills and exercises that are each immediately useful. (I think Eli might be <a href=""http://localhost:3000/posts/faaoyve5ryY8E5M4r/eli-s-shortform-feed#HpFfoqZXAbBZcsPKF"">working on something like this</a>). But this sequence is <a href=""http://localhost:3000/posts/oPEWyxJjRo4oKHzMu/the-3-books-technique-for-learning-a-new-skilll"">more about ""Why"" than ""How</a>"", much of what I want to talk about is the overall mindset, and how various skills fit together.</p><p>I'm using ""frame"" to mean ""the broadest possible way for two people can miss each other."" I deliberately didn't use words like ""ontology"" or ""outlook"", that misleadingly sound like they mean something specific.</p><p><i>Attention conservation notice: if this all makes intuitive sense and you're pretty sure you understand what I mean by 'frame' you can probably skip the rest of this article.</i></p><h1>Holistic Frame Evaluation</h1><p>Why focus on all three ways-of-<i>seeing</i>/<i>thinking</i>/<i>communicating</i> at once? My experience is that they often come all muddled together. It's useful to be able to separate them, but their default state is often intertwined.</p><p>In the previous essay, I listed some possible frames, including:</p><ul><li><i>Gears-Oriented-Frames, </i>focused on physical processes in the world and how they interact</li><li><i>Feelings-Oriented-Frames, </i>focused on what emotions and inner experiences the conversation participants are having</li><li><i>Power-Oriented-Frames</i>, focused on the relative status and power of the participants and how that fits into the broader world</li></ul><p>(Again, these are not at all meant to be comprehensive. These are just a few examples, like pointing at a rabbit, a bumblebee and a human and saying ""Hey, I'm talking about animals. Here's a few examples of animals to get the idea across of what an animal is."")</p><p>This time I'll try to cross-reference those frames with the Seeing / Thinking / Communicating schema.</p><h1>Ways of Communicating</h1><p>Taymon on Facebook remarked, regarding my previous post:</p><blockquote><p>The conflicts you describe are when each participant has a false belief about the other participants' objectives, and so the things they say, that they expect to help accomplish those objectives, don't.</p></blockquote><blockquote><p>The whole thing doesn't seem that conceptually difficult.</p></blockquote><blockquote><p>You seems to have had something bigger and harder to grasp in mind, but I still don't feel like I have much of a clue as to what it is.</p></blockquote><p>I have at least a bit more in mind here. But, ""people have different conversational goals"" is at least one major source of frame conflict, and is perhaps the most obvious one. So let's start there.</p><h2>Picture Frames, and Context</h2><p>These pictures are identical, but have different frames.</p><figure class=""image""><img src=""https://i.imgur.com/IORLFcY.jpg""></figure><p><i>(Image by </i><a href=""https://www.flickr.com/photos/134699689@N08/37882585736""><i>Ken Rementer</i></a><i>)</i></p><p>The frame conveys information about the intent of the photo. The first is a polaroid that was probably taken off-the-cuff. The second and third look more like deliberate family portraits. But the third's elaborate frame conveys some additional ""specialness"" and pride.</p><p>Similarly, the same conversation might have very different contexts depending on who's participating, how they relate to each other, and what they think they're talking about.</p><p><strong>Picture Frame Examples</strong></p><p><i>[note: </i><a href=""https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer""><i>political examples can be unnecessarily mindkilling</i></a><i>, but it seemed useful to have a concrete example that readers would likely be familiar with. Most of the examples here aren't too dependent on which position is right or wrong]</i></p><p>Alice and Bob are in a newly formed relationship, arguing about the politics of minimum wage.&nbsp;</p><p>There are some ""obvious"" frame disconnects that can happen here, if, say, Alice, thinks that the primary focus of the conversation is to figure out optimal policy, and Bob thinks it's to avoid relationship conflict.</p><p>(Or: if one of them thinks the goal is to figure out who is smarter and more socially dominant in their relationship)</p><p>There could be subtler mismatches:&nbsp;</p><p>Maybe they both think the conversation is more about their relationship than their preferred policies. (Apart from voting once a year, neither are major political activists).&nbsp;</p><p>But Alice enjoys barbed wit and thinks of the argument as a playful banter, which is a sign of comfort-with-each-other. (She thinks they are both comfortable enough with each others positions that the relationship is not at risk if they disagree too hard). She thinks it's fine to make straw-man-ish-jokes about Bob's position.</p><p>Bob thinks that political disagreement is evidence of longterm incompatibility, and thinks that Alice's banter is signaling disrespect, and strawmanny jokes make him feel particularly ""not seen.""</p><h1>Ways of Seeing</h1><h2>Windows, Lenses, and ""Tuning In""</h2><p>Take a look at this street:</p><figure class=""image""><img src=""https://i.imgur.com/fZyc150.jpg""></figure><p>There's a lot going on here. But, imagine that you live in a house with only one window facing this landscape. Your impression of the landscape might depend a lot on where that window is placed.</p><figure class=""image""><img src=""https://i.imgur.com/8cDJXGW.jpg""></figure><p>One window showcases a city skyline. Another primarily focuses on trees and sunset. The third reveals a pile of construction rubble.</p><p>Sometimes people have the exact same goals for a conversation, and yet nonetheless face weird disconnects because they <i>aren't looking at the same parts of reality.</i></p><p>It's compounded if they have different goals for the conversation <i>and also</i> aren't looking at the same parts of reality. Even if they say ""oh, I just realized we were coming at this conversation with two different goals"", they'll keep talking past each other.</p><p>Another metaphor here is the <i>lens, </i>where two people are looking at the exact same scene, but they perceive it differently.</p><figure class=""image""><img src=""https://i.imgur.com/JqozteA.jpg""></figure><p><strong>Window Frame / Lens Example</strong></p><p>Alice and Bob are still arguing about minimum wage. Here are few different sets of ""windows"" they could be looking through.</p><p><i>Different priors and past experience</i></p><p>Alice has read some econblogs and the first question she's asking is ""what do the laws of supply and demand say about this? Is it marginally profitable to hire an additional person?"". Bob has read some socialist blogs and his first questions have more to do with ""what is fair, what do people deserve, who has power and how much surplus do they have?""</p><p>Bob has a bunch of friends struggling to get by on minimum wage who can't pay their bills.&nbsp;</p><p>Alice has friends trying to run small businesses, constantly frustrated by the difficulty of navigating regulations.&nbsp;</p><p>They might believe each other's points are real and relevant, but feel frustrated by each other's <a href=""https://www.econlib.org/archives/2016/01/the_invisible_t.html"">missing moods</a>, which leads them to be suspicious of each other.</p><p><i>Different needs in the moment</i></p><p>What if Alice and Bob are having <i>both</i> a ""Picture Frame"" and ""Window Frame"" mismatch?</p><p>Maybe it's a situation where Alice thinks the point is figuring out optimal policy, and Bob thinks the point is to figure out longterm relationship compatibility, ideally demonstrating that they care about each other. So at the beginning of the conversation, Alice is casually dismissing arguments she thinks are bad as ""stupid"".</p><p>In this scenario, both Alice and Bob have enough relationship/conversational intelligence to notice that that's happening. They have a meta conversation about their respective needs, and then continue in the conversation to <i>both </i>figure out optimal policy while attending to Bob's feelings and their overall relationship.</p><p>But...</p><p>...it's still the case that Alice is <i>very practiced </i>at noticing how policy positions fit together, and <i>not</i> practiced at tracking Bob's facial expressions, emotional state, or how her comments might be coming across. If part of what Bob wants is to <i>feel seen</i>, then Alice might still not do a good job of doing that because Alice is still used to looking through the ""policy cause-and-effect"" window than the ""feelings and relationships"" window — <i>even when that's explicitly her goal.</i></p><p>Part of navigating frame differences is learning to tune into different aspects of a conversation.</p><h1>Ways of Thinking</h1><h2>Frameworks, and how ideas fit together</h2><p>Then, there's how ideas fit together. The framework of a car can fit different sorts of pieces into it than the framework of a bridge. There are different ways of conceptually connecting things.&nbsp;</p><figure class=""image""><img src=""https://i.imgur.com/ryfoZKv.jpg""></figure><p>Different ways of thinking afford different ways of combining evidence, and permit different sorts of answers.</p><p>In many social environments, ""authority"" is treated as a legitimate source of truth, and ""the boss/priest/god says so"" is a legitimate argument to bring to the table.&nbsp;</p><p>In an empirical/rationalist framework, authority often still matters, but ideally <a href=""https://www.lesswrong.com/posts/5yFRd3cjLpm3Nd6Di/argument-screens-off-authority-1"">argument screens off authority</a>.</p><p>Even among people trying to reason carefully, there's a lot of disagreement about how to think. Frequentist vs Bayesian? Probabilistic vs Proof Based? How do you evaluate a study? In what circumstances (if ever) are personal experiences better evidence than a study?&nbsp;</p><p>Do certain types of evidence have a track record of being biased or harmful to you? (Or: do they have a track record of... making you uncomfortable and annoyed and you don't like to think about it?)</p><p>All of this can interface with Picture Frames or Window Frames. You might have different ways of thinking you employ in different domains. Your way of thinking may bias which sort of evidence you look for and how seriously you take it.</p><p><strong>Framework Example</strong></p><p>Alice and Bob are both arguing about minimum wage policy through a materialist cause-and-effect lens. But Alice's opinion is shaped by econ 101 models (i.e. raising prices on a thing should decrease the amount of it), and Bob's opinion is shaped by having read some studies saying that raising minimum wage hasn't caused more unemployment.</p><p>Bob thinks empiricism is the ultimate judge, more important than theory. Alice thinks the theory is robust enough that she <a href=""https://www.lesswrong.com/posts/vrHRcEDMjZcx5Yfru/i-defy-the-data"">defies the data</a>, and argues Bob's studies are either cherry-picked or the result of a messy, <a href=""https://forum.effectivealtruism.org/posts/jSPGFxLmzJTYSZTK3/reality-is-often-underpowered"">underpowered world</a>.</p><p>At least part of their discussion is going to need to address the question ""what counts as good evidence."" (Exactly how to go about that is, in this post, left as an exercise to the reader)</p><h1>Composite and Unconscious Frames</h1><p>What makes this all quite hard, in my experience, is the way this is all intertwined. Often there's multiple layers of Window-Frame/Picture-Frame/Framework at play, and it's not obvious how important each of them respectively are.</p><p>There also can be multiple ""contents of frame"", involved in each layer. A person's window-frame might be focused on <i>both</i> economic theory and also power dynamics (or subtle subsets of each other those).&nbsp;</p><p>And some of this may be totally unconscious: sometimes Alice is quite confident that her goal is simply to point out good policy, but she's unconsciously employing a strategy optimized to make her feel smart and in control, and Bob may be more tuned into the later than the former.&nbsp;</p><p>(Or, Bob may think he's noticing important social moves that Alice is pulling, but Bob has become hypersensitized to social nuances and is noticing things that honestly aren't there, or aren't nearly as causally relevant as he thinks)</p><p>What exactly to do with all this is tricky, and context dependent, and requires building up a few different skills (many of which are hard to convey via blogpost). But it seems useful to at least have a rough sense of the landscape.</p>",Raemon,raemon,Raemon,
pmifMjht6Y4dBPhqF,Skill and leverage,skill-and-leverage,https://www.lesswrong.com/posts/pmifMjht6Y4dBPhqF/skill-and-leverage,2019-11-03T21:10:02.416Z,49,22,8,False,False,,"<p>Sometimes I hear people say ‘how can make a big difference to the world, when I can’t make a big difference to that pile of dishes in my sock drawer?’ How can I improve the sustainability of world energy usage when I can’t improve the sustainability of my own Minecraft usage? The basic thought is that if you can’t do ‘easy’ things that humans are meant to be able to do, on the scale of your own life, you probably lack general stuff-doing ability, and are not at the level where you can do something a million times more important. </p>
<p>I think this is a generally wrong model, for two reasons. One is that the difficulty of actions is not that clearly well ordered—if you have a hard time keeping your room tidy, this just doesn’t say that much about whether you can write well or design rockets or play the piano.</p>
<p>The second reason is that the difficulty of actions doesn’t generally scale with their consequences. I think this is more unintuitive.</p>
<p>Some examples:</p>
<ol>
<li>Applying for funding for a promising new anti-cancer drug is probably about as hard as applying for funding for an investigation into medieval references to toilet paper (and success is probably easier), but the former is much more valuable.  </li>
<li>Having a good relationship with your ex Bob might be about as hard and take about the same skills as having a good relationship with your more recent ex Trevor, but if you have children with Trevor, the upside of that effort may be a lot higher.</li>
<li>If you have a hard time making a speech at your brother’s birthday, you will probably also have a hard time making a speech to the UN. But, supposing it is fifty thousand times more important, it isn’t going to be fifty thousand times harder. It’s not even clear that it is going to be harder at all—it probably depends on the topic and your relationship with your family and the UN.</li>
<li>Writing a good book about x-risk is not obviously much harder than writing a good book about the role of leprechauns through the ages, but is vastly more consequential in expectation.</li>
</ol>
<p>My basic model is that you can have skills that let you do particular physical transformations (an empty file into a book, some ingredients into a cake), and there are different places you can do those tricks, and some of the places are just much higher leveraged than others. Yet the difficulty is mostly related to the skill or trick. If you are trying to start a fire, holding the burning match against the newspapers under the logs is so much better than holding it in the air nearby or on the ground or at the top of the logs, and this doesn’t involve the match being better or worse in any way.</p>
<p>In sum, there isn’t a clear ladder of actions a person can progress through, with easy unimportant ones at the bottom, and hard important ones at the top. There will be hard-for-you unimportant actions, and easy-for-you important actions. The last thing you should do if you come across a hard-for-you unimportant action is stop looking for other things to do. If you are bad at keeping your room clean and room cleanliness isn’t crucial to your wellbeing, then maybe look for the minimum version of cleanliness that that lets you live happily, and as quickly as possible get to finding things that are easier for you, and places to deploy them that are worthwhile.</p>",KatjaGrace,katjagrace,KatjaGrace,
xzFQp7bmkoKfnae9R,But exactly how complex and fragile?,but-exactly-how-complex-and-fragile,https://www.lesswrong.com/posts/xzFQp7bmkoKfnae9R/but-exactly-how-complex-and-fragile,2019-11-03T18:20:01.268Z,87,26,32,False,False,,"<p><i>This is a post about my own confusions. It seems likely that other people have discussed these issues at length somewhere, and that I am not up with current thoughts on them, because I don’t keep good track of even everything great that everyone writes. I welcome anyone kindly directing me to the most relevant things, or if such things are sufficiently well thought through that people can at this point just </i><a href=""https://worldlypositions.tumblr.com/post/171950502129/rude-awakening""><i>correct me in a small number</i></a><i> of sentences, I’d appreciate that even more.</i></p>
<p>~</p>
<p>The traditional argument for AI alignment being hard is that human value is <a href=""https://intelligenceexplosion.com/2012/value-is-complex-and-fragile/"">‘complex’ and</a> <a href=""https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile"">‘fragile’</a>. That is, it is hard to write down what kind of future we want, and if we get it even a little bit wrong, most futures that fit our description will be worthless. </p>
<p>The <a href=""https://www.lesswrong.com/posts/GNnHHmm8EzePmKzPk/value-is-fragile"">illustrations</a> <a href=""https://intelligenceexplosion.com/2012/value-is-complex-and-fragile/"">I have seen</a> of this involve a person trying to write a description of value conceptual analysis style, and failing to put in things like ‘boredom’ or ‘consciousness’, and so getting a universe that is highly repetitive, or unconscious. </p>
<p>I’m not yet convinced that this is world-destroyingly hard. </p>
<p>Firstly, it seems like you could do better than imagined in these hypotheticals:</p>
<ol>
<li>These thoughts are from a while ago. If instead you used ML to learn what ‘human flourishing’ looked like in a bunch of scenarios, I expect you would get something much closer than if you try to specify it manually. Compare manually specifying what a face looks like, then generating examples from your description to using modern ML to learn it and generate them.</li>
<li>Even in the manually describing it case, if you had like a hundred people spend a hundred years writing a very detailed description of what went wrong, instead of a writer spending an hour imagining ways that a more ignorant person may mess up if they spent no time on it, I could imagine it actually being pretty close. I don’t have a good sense of how far away it is.</li>
</ol>
<p>I agree that neither of these would likely get you to exactly human values.</p>
<p>But secondly, I’m not sure about the fragility argument: that if there is basically any distance between your description and what is truly good, you will lose everything. </p>
<p>This seems to be a) based on a few examples of discrepancies between written-down values and real values where the written down values entirely exclude something, and b) assuming that there is a fast takeoff so that the relevant AI has its values forever, and takes over the world.</p>
<p>My guess is that values that are got using ML but still somewhat off from human values are much closer in terms of not destroying all value of the universe, than ones that a person tries to write down. Like, the kinds of errors people have used to illustrate this problem (forget to put in, ‘consciousness is good’) are like forgetting to say faces have nostrils in trying to specify what a face is like, whereas a modern ML system’s imperfect impression of a face seems more likely to meet my standards for ‘very facelike’ (most of the time).</p>
<p>Perhaps a bigger thing for me though is the issue of whether an AI takes over the world suddenly. I agree that if that happens, lack of perfect alignment is a big problem, though not obviously an all value nullifying one (see above). But if it doesn’t abruptly take over the world, and merely becomes a large part of the world’s systems, with ongoing ability for us to modify it and modify its roles in things and make new AI systems, then the question seems to be how forcefully the non-alignment is pushing us away from good futures relative to how forcefully we can correct this. And in the longer run, how well we can correct it in a deep way before AI does come to be in control of most decisions. So something like the speed of correction vs. the speed of AI influence growing. </p>
<p>These are empirical questions about the scales of different effects, rather than questions about whether a thing is analytically perfect. And I haven’t seen much analysis of them. To my own quick judgment, it’s not obvious to me that they look bad.</p>
<p>For one thing, these dynamics are already in place: the world is full of agents and more basic optimizing processes that are not aligned with broad human values—most individuals to a small degree, some strange individuals to a large degree, corporations, competitions, the dynamics of political processes. It is also full of forces for aligning them individually and stopping the whole show from running off the rails: law, social pressures, adjustment processes for the implicit rules of both of these, individual crusades. The adjustment processes themselves are not necessarily perfectly aligned, they are just overall forces for redirecting toward alignment. And in fairness, this is already pretty alarming. It’s not obvious to me that imperfectly aligned AI is likely to be worse than the currently misaligned processes, and even that it won’t be a net boon for the side of alignment. </p>
<p>So then the largest remaining worry is that it will still gain power fast and correction processes will be slow enough that its somewhat misaligned values will be set in forever. But it isn’t obvious to me that by that point it isn’t sufficiently well aligned that we would recognize its future as a wondrous utopia, just not the very best wondrous utopia that we would have imagined if we had really carefully sat down and imagined utopias for thousands of years. This again seems like an empirical question of the scale of different effects, unless there is a an argument that some effect will be totally overwhelming. </p>",KatjaGrace,katjagrace,KatjaGrace,
HZ567R3e96ZK5DCCf,"[Math] Proofs vs. documentation vs. ""it's trivial""",math-proofs-vs-documentation-vs-it-s-trivial,https://www.lesswrong.com/posts/HZ567R3e96ZK5DCCf/math-proofs-vs-documentation-vs-it-s-trivial,2019-11-03T16:50:17.428Z,13,7,0,False,False,,"<p>In my abstract algebra and real analysis classes, my TAs say that I frequently come up with &quot;technically right&quot; solutions. They don&apos;t mean in the Futurama sense; &quot;technically right&quot; here is a little looser - I did some trick that wasn&apos;t really expected, or a bit outside of the nature of the class, in order to arrive at my proof.</p><p>This is really cool! I readily admit my ego is a bit boosted by contrasting my less obvious approach to the more studied approach of my classmates. It&apos;s good to embrace what&apos;s unique about yourself.</p><p>The problem is that the solutions I generate on a homework problem, where I have all the time in the world to putt about and generate little sub-proofs and lemmas, don&apos;t work in an exam situation. I don&apos;t write that fast. Even if I did write that fast, I don&apos;t think that fast. The things I claim aren&apos;t quite so trivial that I feel comfortable using them without proof - I&apos;d lose points if I did.</p><br><p>Calling something &quot;trivial&quot; in math is more of a judgment call than I think people realize. The universal-accessibility option for triviality might be to hyperlink to someone else&apos;s proof of a claim, that is in roughly the same flavor as your own; that way, a reader who feels confident they could reconstruct the proof can just read over it, without hurting the flow of the text, and someone who feels less confident could slow down. Since a lot of good mathematics texts are designed to be reread to jog one&apos;s own memory from time to time, this seems like an especially good balance - after reading the proof through the first or second time for the nontrivial triviality, it probably genuinely does start to look trivial to you. You&apos;ve absorbed whatever was missing that made it look nontrivial.</p><p>And that&apos;s interesting. I think that &quot;trivial&quot; statements are more like <em>heuristic-checks</em> than nontrivial ones. Do you have the requisite background knowledge to grind this proof out without breaking a sweat? Do you realize you have that knowledge - is it a &quot;known known&quot; for you? Maybe it&apos;s an unknown known, that happens often. But it also happens often that you genuinely have mismatched heuristics for the problems in question. They probably aren&apos;t wrong -- they&apos;re just not a good fit for right now.</p><p>Mismatched heuristic-checks are the same phenomena, I think, that causes my first-pass proofs to be called &quot;technically correct&quot; by my professors. These problems were probably specifically chosen to be challenging to an undergraduate, but not so challenging that they appear <em>nontrivial to the grader</em>, who themselves have much more experience with the field. When a proof is trivial to the grader, they can devote more mental energy to the rote work of making sure the proof-writer crossed their Ts and dotted their Is. So when you do something surprising, there really is a sense in which it&apos;s the &apos;wrong&apos; approach to the situation, even if it gets the right answer.</p><br><p>For now, my solution is to apply some of the principles of good <strong>code documentation</strong> to my proofs. Good code documentation usually provides whatever is being documented at various levels of complexity:</p><ul><li>There&apos;s usually a few concrete examples of the code in use, for the programmer who&apos;s in a hurry and just needs to know what to do. (Honestly, if we&apos;re talking raw number of function lookups, this one is the one I get the most value out of.)</li><li>There&apos;s usually a link or an embedded snippet of what the code actually <em>is</em>. For a function, this is a link to the definition in the database itself, preferably automatically updating with new builds. This is so that someone who wants to look into the <em>explicit construction</em> of the abstract thing we&apos;re talking about can do so, and is tremendously helpful in spotting bugs. This is the closest thing to what we usually think of as the &quot;proof&quot; part of a math proof, and it is indeed the most critical part of both, in different senses. But it&apos;s not always good for <em>explaining </em>what&apos;s going on.</li><li>Finally, there&apos;s usually a short bit about what&apos;s going on in plain English, maybe some informal explanation of how to use this bit of code or what its various arguments do.</li></ul><p>I don&apos;t mind spilling some extra ink to explain what I&apos;m doing clearly to the reader -- if I lose points, I at least want it to be exceedingly clear what mistake I made that caused me to lose them. I still have to go back and learn the &quot;proper&quot; way to do things for exams, but this is a happy medium for me when it comes to my homework.</p>",aaq,aaq,aaq,
qmZoa7uTjQ9R6nTCN,[Question] When Do Unlikely Events Should Be Questioned?,question-when-do-unlikely-events-should-be-questioned,https://www.lesswrong.com/posts/qmZoa7uTjQ9R6nTCN/question-when-do-unlikely-events-should-be-questioned,2019-11-03T15:21:25.930Z,6,4,8,False,False,,"<p>Today someone shared a picture on Facebook showing four d20 dies (d20 is a 20-sided die), supposedly all landed on 20. He was saying how cool it was that he and his friends were playing a tabletop role-playing game and they all got a 20 on their spot check at the same time.</p><p>My first reaction was &quot;Huh, neat!&quot;</p><p>My second reaction was &quot;p = (1/20)^4 = 160,000. In Israel&apos;s small role-playing community this seems just very unlikely. This picture is probably a fake.&quot;</p><p>1st me: &quot;Well, this just happened to be exactly 4 dies. If that happened to be 5 dies, 6 dies, etc ... we would still consider this as an exceptional event with low probability. We have to sum over all the probabilities for all plausible die numbers&quot;</p><p>2nd me: &quot;Sure, but every extra die reduces the probability by a factor of 1/20, so it seems likely that we can save ourselves the trouble of summing and just assume that 1/160,000 gives us a fair estimate.&quot;</p><p>1st me: &quot;But what about if there were only 3 dies? 2 dies? What if they had all shown 1&apos;s instead of 20? What if they had shown 17, 18, 19, 20? What if we had encountered that picture on an international role-playing group, much larger than the Israeli one? Where do we draw the line? We need to find a way to estimate the probability of observing a picture on social media of something unlikely that is drawn from a huge set of unlikely possibilities&quot;</p><p>At that point me no. 2 usually frowns and forgets about the matter until it emerges again, leaving it unresolved.</p><br><p>So I am now seeking the community&apos;s wisdom; let the elders speak. How do you estimate the likelihood of occurrences such as this? Can this problem be easily resolved somehow?</p><br>",NSegall,nsegall,NSegall,
WmAyKHor6vwqJRNdm,Where should I ask this particular kind of question?,where-should-i-ask-this-particular-kind-of-question,https://www.lesswrong.com/posts/WmAyKHor6vwqJRNdm/where-should-i-ask-this-particular-kind-of-question,2019-11-03T11:27:24.478Z,3,2,11,False,True,,"<p>I am pondering a hypothetical scenario that I think is fascinating but quite unrealistic and involves knowledge across a wide variety of fields, of which IMO physics gets the better part.</p><p>I&apos;m considering some sites that I know. Reddit has a sub called r/AskScienceDiscussion but this sub is not very warm to this type of query. Quora has degraded so much and doesn&apos;t even have the option to expand the subject over a length of mere 150 chars or so, which is utterly ridiculous. I&apos;m not sure about Stackexchange - should I post in their physics site? LessWrong boasts that people can ask anything and it aims to be better than the former 2, but judging from what I read, questions almost exclusively focus on rationality, and the reach (the amount of folks who can read it, or how popular the platform is within a population) is small. There&apos;s another option of posting in fora such as physicsforum, but I don&apos;t have an account there so my knowledge is limited about how people will respond.</p><p>Thus, my question is a bit meta: what do you think is the best place to post the question? If there&apos;s something better than what I listed, then please kindly enlighten me. Also, I&apos;d like to ask you guys to not be biased toward our own platform we&apos;re standing on. Thanks!</p>",Long try,long-try,Long try,
kczouh3rvEoxJWFh5,"“embedded self-justification,” or something like that",embedded-self-justification-or-something-like-that,https://www.lesswrong.com/posts/kczouh3rvEoxJWFh5/embedded-self-justification-or-something-like-that,2019-11-03T03:20:01.848Z,40,16,14,False,False,,"<p><b>preamble</b></p><p>Sometimes I wonder what the MIRI-type crowd thinks about some issue related to their interests.  So I go to alignmentforum.org, and quickly get in over my head, lost in a labyrinth of issues I only half understand.</p><p>I can never tell whether they’ve never thought about the things I’m thinking about, or whether they sped past them years ago.  They do seem very smart, that’s for sure.</p><p>But if they have terms for what I’m thinking of, I lack the ability to find those terms among the twists of their mirrored hallways.  So I go to tumblr.com, and just start typing.</p><p><b>parable (1/3)</b></p><p>You’re an “agent” trying to take good actions over time in a physical environment under resource constraints.  You know, the usual.</p><p>You currently spend a lot of resources doing a particular computation involved in your decision procedure.  Your best known algorithm for it is O(N^n) for some n.</p><p>You’ve worked on the design of decision algorithms before, and you think this could perhaps be improved.  But to find it, you’d have to shift resources some away from running the algorithm for a time, putting them into decision algorithm design instead.</p><p>You do this.  Almost immediately, you discover an O(N^(n-1)) algorithm.  Given the large N you face, this will dramatically improve all your future decisions.</p><p>Clearly (…“<i>clearly</i>”?), the choice to invest more in algorithm design was a good one.</p><p>Could you have anticipated this beforehand?  Could you have acted on that knowledge?</p><p><b>parable (2/3)</b><br /></p><p>Oh, you’re so very clever!  By now you’ve realized you need, above and beyond your regular decision procedure to guide your actions in the outside world, a “meta-decision-procedure” to guide your own decision-procedure-improvement efforts.</p><p>Your meta-decision-procedure does require its own resource overhead, but in exchange it tells you when and where to spend resources on R&amp;D.  All your algorithms are faster now.  Your decisions are better, their guiding approximations less lossy.</p><p>All this, from a meta-decision-procedure that’s only a first draft.  You frown over the resource overhead it charges, and wonder whether it could be improved.</p><p>You try shifting some resources away from “regular decision procedure design” into “meta-decision-procedure-design.”  Almost immediately, you come up with a faster and better procedure.</p><p>Could you have anticipated this beforehand?  Could you have acted on that knowledge?</p><p><b>parable (3/3)</b><br /></p><p>Oh, you’re so very clever!  By now you’ve realized you need, above and beyond your meta-meta-meta-decision-procedure, a “meta-meta-meta-meta-decision-procedure” to guide your meta-meta-meta-decision-procedure-improvement efforts.<br /></p><p>Way down on the object level, you have not moved for a very long time, except to occasionally update your meta-meta-meta-meta-rationality blog.</p><p>Way down on the object level, a dumb and fast predator eats you.</p><p>Could you have anticipated this beforehand?  Could you have acted on that knowledge?</p><p><b>the boundary</b></p><p>You’re an “agent” trying to take good actions, et cetera.  Your actions are guided by some sort of overall “model” of how things are.</p><p>There are, inevitably, two parts to your model: the interior and the boundary.</p><p>The interior is everything you treat as fair game for iterative and reflective improvement.  For “optimization,” if you want to put it that way.  Facts in the interior are subject to rational scrutiny; procedures in the interior have been judged and selected for their quality, using some further procedure.</p><p>The boundary is the outmost shell, where resource constraints force the regress to stop.  Perhaps you have a target and an optimization procedure.  If you haven’t tested the optimization procedure against alternatives, it’s in your boundary.  If you <i>have</i>, but you haven’t tested your optimization-procedure-testing-procedure against alternatives, then <i>it’s</i> in your boundary.  Et cetera.</p><p>You are a business.  You do retrospectives on your projects.  You’re so very clever, in fact, that you do retrospectives on your retrospective process, to improve it over time.  But how do you improve these retro-retros?  You don’t.  They’re in your boundary.</p><p>Of everything you know and do, you trust the boundary the least.  You have applied less scrutiny to it than anything else.  You suspect it may be shamefully suboptimal, just like the previous boundary, before you pushed <i>it</i> into the interior.</p><p><b>embedded self-justification</b></p><p>You would like to look back on the resources you spend – each second, each joule – and say, “I spent it the right way.”  You would like to say, “I have a theory of what it means to decide well, and I applied it, and so I decided well.”</p><p>Why did you spend it as you did, then?  You cannot answer, ever, without your answer invoking something on the boundary.</p><p>How did you spent that second?  On looking for a faster algorithm.  Why?  Because your R&amp;D allocation procedure told you to.  Why follow that procedure?  Because it’s done better than others in the past.  How do you know?  Because you’ve compared it to others.  Which others?  Under what assumptions?  Oh, your procedure-experimentation procedure told you.  And how do you know <i>it</i> works?  Eventually you come to the boundary, and throw up your hands: “I’m doing the best I can, okay!”</p><p>If you lived in a simple and transparent world, maybe you could just find the optimal policy once and for all.  If you really were <i>literally</i> the bandit among the slot machines – and you knew this, perfectly, with credence 1 – maybe you could solve for the optimal explore/exploit behavior and then do it.</p><p>But your world isn’t like that.  You know this, and know that you know it.  Even if you could obtain a perfect model of your world and beings like you, you wouldn’t be able to fit it inside your own head, much less run it fast enough to be useful.  (If you had a <a href=""https://intelligence.org/files/ReflectiveOraclesAI.pdf"">magic amulet</a>, you might be able to fit yourself inside your own head, but you live in reality.)</p><p>Instead, you have detailed pictures of specific fragments of the world, in the interior and subject to continuous refinement.  And then you have pictures of the picture-making process, and so on.  As you go further out, the pictures get coarser and simpler, because their domain of description becomes ever vaster, while your resources remain finite, and you must nourish each level with a portion of those resources before the level above it even becomes thinkable.</p><p>At the end, at the boundary, you have the coarsest picture, a sort of cartoon.  There is a smiling stick figure, perhaps wearing a lab coat to indicate scientific-rational values.  It reaches for the lever of a slot machine, labeled “action,” while peering into a sketch of an oscilloscope, labeled “observations.”  A single arrow curls around, pointing from the diagram back into the diagram.  It is labeled “optimization,” and decorated with cute little sparkles and hearts, to convey its wonderfulness.  The margins of the page are littered with equations, describing the littlest of toy models: bandit problems, Dutch book scenarios, Nash equilibria under perfect information.</p><p>In the interior, there are much richer, more beautiful pictures that are otherwise a lot like this one.  In the interior, meta-learning algorithms buzz away on a GPU, using the latest and greatest procedures for finding procedures, justified in precise terms in your latest paper.  You gesture at a whiteboard as you prioritize options for improving the algorithms.  Your prioritization framework has gone through rigorous testing.</p><p>Why, in the end, do you do all of it?  Because you are the little stick figure in the lab coat.</p><p><b>coda</b></p><p>What am I trying to get at, here?</p><p>Occasionally people talk about the relevance of computational complexity issues to AI and its limits.  Gwern has a good <a href=""https://www.gwern.net/Complexity-vs-AI"">page</a> on why these concerns can’t place useful bounds on the potential of machine intelligence in the way people sometimes argue they do.</p><p>Yet, somehow I feel an unscratched itch when I read arguments like Gwern’s there.  They answer the question I think I’m asking when I seek them out, but at the end I feel like I really meant to ask some other question instead.</p><p>Given computational constraints, how “superhuman” could an AI be?  Well, it could just do what we do, but sped up – that is, it could have the same resource efficiency but more resources per unit time.  That’s enough to be scary.  It could also <i>find</i> more efficient algorithms and procedures, just as we do in our own research – but it would find them ever faster, more efficiently.</p><p>What remains unanswered, though, is whether there is any useful way of talking about doing this (the whole thing, including the self-improvement R&amp;D) <i>well</i>, doing it <i>rationally</i>, as opposed to doing it in a way that simply “seems to work” after the fact.</p><p>How would an AI’s own policy for investment in self-improvement compare to our own (to yours, to your society’s)?  Could we look at it and say, “this is better”?  Could the AI do so?  Is there anything better than simply bumbling around in concept-space, in a manner that perhaps has many <i>internal</i> structures of self-justification but is not <i>known to work as a whole?</i>  Is there such a thing as (approximate) knowledge about the right way to do <i>all of it</i> that is still small enough to fit inside the agent on which it passes judgment?</p><p>Can you represent your <i>overall</i> policy, your outermost strategy-over-strategies considered a response to your <i>entire</i> situation, in a way that is not a cartoon, a way real enough to defend itself?</p><p>What is really known about the best way to spend the next unit of resources?  I mean, known at the level of the resource-spenders, not as a matter of external judgment?  Can <i>anything </i>definite be said about the topic in general except “it is possible to do better or worse, and it is probably possible to do better than <i>we</i> do now?”  If not, what standard of rationality do we have left to apply beyond toy models, to ourselves or our successors?</p>",nostalgebraist,nostalgebraist,nostalgebraist,
RasFpce3fNZ8xp2T4,Open & Welcome Thread - November 2019,open-and-welcome-thread-november-2019,https://www.lesswrong.com/posts/RasFpce3fNZ8xp2T4/open-and-welcome-thread-november-2019,2019-11-02T20:06:54.030Z,12,4,76,False,False,,"<ul><li>If it&#x2019;s worth saying, but not worth its own post, here&apos;s a place to put it.</li><ul><li>You can also make a <a href=""http://www.lesslong.com/"">shortform post</a>.</li></ul><li>And, if you are new to LessWrong, here&apos;s the place to introduce yourself.</li><ul><li>Personal stories, anecdotes, or just general comments on how you found us and what you hope to get from the site and community are welcome.</li></ul></ul><p>If you want to explore the community more, I recommend <a href=""https://www.lesswrong.com/library"">reading the Library,</a> <a href=""https://www.lesswrong.com/?view=curated"">checking recent Curated posts</a>, <a href=""https://www.lesswrong.com/community"">seeing if there are any meetups in your area</a>, and checking out the <a href=""https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq-1#Getting_Started"">Getting Started</a> section of the <a href=""https://www.lesswrong.com/posts/2rWKkWuPrgTMpLRbp/lesswrong-faq-1"">LessWrong FAQ</a>.</p><p>The Open Thread sequence is <a href=""https://www.lesswrong.com/s/yai5mppkuCHPQmzpN"">here</a>.</p>",habryka4,habryka4,habryka,
d8vdrvZDYLDiRYfjE,Economics and Evolutionary Psychology,economics-and-evolutionary-psychology,https://www.lesswrong.com/posts/d8vdrvZDYLDiRYfjE/economics-and-evolutionary-psychology,2019-11-02T16:36:34.026Z,12,4,0,False,False,http://www.daviddfriedman.com/Academic/econ_and_evol_psych/economics_and_evol_psych.html?fbclid=IwAR2EokR7Z1lUPCDKTrJOFCAlZ-M-vPqbjhau1fxdaMYptrcgsPS-ZXaJTDo,"<p>This article provides game theoretic reasons for acting in ways that may seem naive from the standard economic point of view.</p><p>Key quotes from the article:</p><p>&quot;As a member of a hunter-gatherer band, you engage in a variety of transactions with your fellows, trading goods and services&#x2014;food, sex, support in intra-group conflict, and the like... In this world all markets are thin&#x2014;it is, after all, a small band&#x2014;so the typical transaction is a bilaterial monopoly bargain.</p><p>Assume an environment sufficiently stable so that, for some transactions, there are &#x201C;usual prices.&#x201D; Those prices must be within the bargaining ranges of both buyer and seller, since otherwise the transactions would not occur. The environment is not, however, perfectly stable. Sometimes the circumstances of one party or another shift his bargaining range&#x2014;the range of terms for which the transaction is in his interest.</p><p>You are a buyer whose current circumstances make the good much more valuable to you than usual, widening the bargaining range. If you could somehow commit yourself not to pay more than the usual price, you, rather than the seller, would get the increased benefit from this transaction. One way to do so is to be emotionally programmed to resent any increase above the usual price&#x2014;resent it enough so that the humiliation of being &#x201C;cheated&#x201D; will outweigh the gain from the transaction.</p><p>As in any bilateral monopoly game, the argument works both ways. If the seller could somehow commit himself not to accept less than your reservation price, he would be the one to pocket the gains from the trade. There is, however, an important difference between your situations. You know the usual price and, assuming the special circumstances affect only you, know that it is probably within the seller&#x2019;s bargaining range. So your commitment strategy is unlikely to commit you to a price outside the bargaining range&#x2014;which would make the transaction impossible. The seller does not know your reservation price, so if he commits himself to his guess at what you are willing to pay he may choose a price at which the transaction can not occur.</p><p>... What about the situation where the seller&#x2019;s costs are unusually high, making him unwilling to sell at the usual price? If the result is to eliminate the bargaining range, no transaction will or should take place. But if the seller&#x2019;s cost is lower than the value to the buyer, either because the special circumstances affect both in similar ways or because the increased cost is still within the usual bargaining range, a buyer&#x2019;s commitment not to pay more than the usual price results in an inefficient bargaining breakdown.</p><p>There is a solution to this problem. A seller charging an unusually high price can defend himself against the buyer&#x2019;s commitment strategy by offering to show the buyer that his costs really are unusually high, that he is really, and not only strategically, unwilling to sell at the usual price. From that we get the conventional view of pricing that economists find so frustrating and wrongheaded&#x2014;as the outcome of bargaining between buyer and seller, with each required to justify any deviation from past prices.&quot;</p>",Chris_Leong,chris_leong,Chris_Leong,
ZHsFC8kjGvbYKaJiD,Speaking up publicly is heroic,speaking-up-publicly-is-heroic,https://www.lesswrong.com/posts/ZHsFC8kjGvbYKaJiD/speaking-up-publicly-is-heroic,2019-11-02T12:00:01.882Z,44,16,2,False,False,,"<p>



<i>Content warning: discussion of abuse.</i>



</p><p>

I was recently in a discussion of safety, ""me too"", and responding to
harmful behavior where someone wrote, paraphrased:

</p>

<p>

</p>

<blockquote>
Discussing things like this, publicly and in writing, is dangerous.
Posting negative things about people could get you sued for libel, or
even physically assaulted if the person takes it poorly enough.  Why
would you put yourself at risk, just to get something off your chest?
</blockquote>



<p>

While they're right that speaking up is risky, the idea that people
who make public posts are doing it lightly doesn't match what I've
seen.  Most people who post know the risk, but decide to go ahead for
important reasons including ""no one else should have to go through
this"" and ""if people know bad behavior will come back to bite them
they'll behave better.""

</p>

<p>

In November 2017 someone in one of my communities posted publicly
about someone who had abused them, and then in September 2018 two
people in another of my communities posted about a different
person. [1] While these two abusers were different in a series of
ways, they had a lot in common: they were relatively popular, they
used age, inexperience, and intoxicants to take advantage of people,
they had abused a series of people, and there were <a href=""https://en.wikipedia.org/wiki/Missing_stair"">whispered warnings</a>
but not everyone heard or believed them.

</p>

<p>

In both cases, the public posts completely changed the situation by
pulling all of this into common knowledge.  The abusers were rightly
ejected and communities started working on figuring out how they had
let things get to this point.

</p>

<p>

We need to build a world where this is not needed, and where we have
good social systems for handling harmful behavior.  I don't know what
this should look like yet, however, and all the proposals I've seen
have good and bad parts.  In my corner of the world I've been working
on this with <a href=""https://www.bidadance.org/safety/"">BIDA's safety
committee</a>, and I'm glad that communities are generally taking this
more seriously.  We also need to handle this on a personal level,
supporting friends who've been hurt and holding others accountable
when they hurt people.  But while stopping abusers should not require
this level of personal risk, as long as it does I have enormous
respect for people who decide to take that risk and speak up.

</p>

<p>
<br />

[1] I'm not linking the two here, even though both are world-readable,
because they've served their purposes and I'm not trying to put more
attention on those two cases in particular.

  </p>",jkaufman,jkaufman,jefftk,
ZNQ7cu5MpBrh8Y2Qp,What are human values? - Thoughts and challenges,what-are-human-values-thoughts-and-challenges,https://www.lesswrong.com/posts/ZNQ7cu5MpBrh8Y2Qp/what-are-human-values-thoughts-and-challenges,2019-11-02T10:52:51.585Z,11,4,6,False,False,,"<p>Epistemic Status: Rough outline of ideas</p><p>The first step in achieving a goal is knowing what you want. But in order to answer this question, we first need to know what it means to want. Do we care more about your desires at the point of the decision or at the point of the experience? Do we care more about what you want emotionally or what you want cognitively? Ultimately, there's no real meaning to the word ""want"" inscribed in the universe, there's just a whole bunch of related meanings clustered under the same term. I'll try to break this down, but unfortunately I can only sketch a rough non-empirically based model as this post really just needs to be written by a neuroscientist or psychologist.</p><p>Our brain seems to consist of three main subsystems. Firstly, we have emotional systems like pleasure, pain, desire, disinterest, rightness and wrongness. These trigger at various times: contemplation of a possible choice or outcome, after locking in a decision, after learning about the outcome, whilst experiencing the outcome and in self-reflection afterwards. We may switch from positive to negative and back again at different stages and this may be because our preferences have changed or it may just be a consistent conflict between our preferences. For example, we may feel inspired when considering a physical challenge, hate every moment of the experience and then feel a real sense of achievement when we are done. </p><p>Secondly, we have the cognitive components. These can be explicit goals (""I must achieve X""), things to be avoided (""I must not fail""), moral imperatives (""I have an obligation to protect X"") and decisions (""I will prioritise my long term happiness over temporary pleasures""). Again, these evaluations may change during an experience or afterwards and it's not always clear whether this is us updating our preferences, keeping our preference and learning more information or some of our preferences being fake and merely for social signalling.</p><p>Thirdly, we have intuition or a sense that certain actions will be good or bad. This may oppose our explicit cognitive components, for example, a man who is consciously trying to become a lawyer, but subconsciously sabotaging themselves because they think they'd hate it. This is separate from the emotional system as we can have an intuition that we'll hate something without feeling dread about the possibility of it occurring.</p><p>Further complications arise. Firstly, it isn't clear how separate the cognitive, intuitive and emotional components really are. Perhaps some cognitions or intuitions intrinsically have certain emotions attached to them Secondly, those who believe in qualia will want the actual qualia to be treated as a seperate component from the information processing components of emotions. Thirdly, our emotional subsystems can respond differently to the same idea framed in a different way and who can say which framing is neutral.</p><p>Lastly, we can use these systems to evaluate each other and they may come to different conclusions. For example, our cognitive system might think it is logical to accept one hour of pain for two of equivalent pleasure, but our emotional system may strongly reject such a proposition due to some kind of loss aversion. So then we end up trying to adjudicate meta-level issues such as whether we care more about what our cognitive system thinks or our emotional system, but we can't decide this without choosing a system to decide. And if, for example, we choose our cognitive system as meta-level decider and tells us that we should prefer it on the object level too, then that hardly seems like a fair way of resolving this internal disagreement.</p><p>So there's a sense in which these question are meaningless, but I expect that most people also feel very strongly that we <em>should</em> resolve it a particular way and that seems somewhat confusing. I'll finish by acknowledge that I haven't quite reached the point where I've completely dissolved the issue to my own satisfaction, but at the same time, being aware of all these different subsystems seems like significant progress towards the answer.</p>",Chris_Leong,chris_leong,Chris_Leong,
SvhzEQkwFGNTy6CsN,"AlphaStar: Impressive for RL progress, not for AGI progress",alphastar-impressive-for-rl-progress-not-for-agi-progress,https://www.lesswrong.com/posts/SvhzEQkwFGNTy6CsN/alphastar-impressive-for-rl-progress-not-for-agi-progress,2019-11-02T01:50:27.208Z,113,62,58,False,False,,"<p>DeepMind <a href=""https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning"">released their AlphaStar paper a few days ago</a>, having reached Grandmaster level at the partial-information real-time strategy game StarCraft II over the summer.</p><p>This is very impressive, and yet less impressive than it sounds. I used to watch a lot of StarCraft II (I stopped interacting with Blizzard recently because of how they rolled over for China), and over the summer there were many breakdowns of AlphaStar games once players figured out how to identify the accounts.</p><p>The impressive part is getting reinforcement learning to work at all in such a vast state space- that took breakthroughs beyond what was necessary to solve Go and beat Atari games. AlphaStar had to have a rich enough set of potential concepts (in the sense that e.g. a convolutional net ends up having concepts of different textures) that it could learn a concept like &quot;construct building P&quot; or &quot;attack unit Q&quot; or &quot;stay out of the range of unit R&quot; rather than just &quot;select spot S and enter key T&quot;. This is new and worth celebrating.</p><p>The overhyped part is that AlphaStar doesn&apos;t really do the &quot;strategy&quot; part of real-time strategy. Each race has a few solid builds that it executes at GM level, and the unit control is fantastic, but the replays don&apos;t look creative or even especially reactive to opponent strategies.</p><p>That&apos;s because there&apos;s no representation of causal thinking - &quot;if I did X then they could do Y, so I&apos;d better do X&apos; instead&quot;. Instead there are many agents evolving together, and if there&apos;s an agent evolving to try Y then the agents doing X will be replaced with agents that do X&apos;. But to explore as much as humans do of the game tree of viable strategies, this approach could take an amount of computing resources that not even today&apos;s DeepMind could afford.</p><p>(This lack of causal reasoning especially shows up in building placement, where the consequences of locating any one building here or there are minor, but the consequences of your overall SimCity are major for how your units and your opponents&apos; units would fare if they attacked you. In one comical case, AlphaStar had surrounded the units it was building with its own factories so that they couldn&apos;t get out to reach the rest of the map. Rather than lifting the buildings to let the units out, which is possible for Terran, it destroyed one building and then immediately began rebuilding it before it could move the units out!)</p><p>This means that, first, AlphaStar just doesn&apos;t have a decent response to strategies that it didn&apos;t evolve, and secondly, it doesn&apos;t do very well at building up a reactive decision tree of strategies (if I scout this, I do that). The latter kind of play is unfortunately very necessary for playing Zerg at a high level, so the internal meta has just collapsed into one where its Zerg agents predictably rush out early attacks that are easy to defend if expected. This has the flow-through effect that its Terran and Protoss are weaker against human Zerg than against other races, because they&apos;ve never practiced against a solid Zerg that plays for the late game.</p><p>The end result cleaned up against weak players, performed well against good players, but practically never took a game against the top few players. I think that DeepMind realized they&apos;d need another breakthrough to do what they did to Go, and decided to <a href=""https://www.bbc.com/news/technology-50212841"">throw in the towel</a> while making it look like they were claiming victory. (Key quote: &quot;Prof Silver said the lab &apos;may rest at this point&apos;, rather than try to get AlphaStar to the level of the very elite players.&quot;)</p><p>Finally, RL practitioners have known that genuine causal reasoning could never be achieved via known RL architectures- you&apos;d only ever get something that could execute the same policy as an agent that had reasoned that way, via a very expensive process of evolving away from dominated strategies at each step down the tree of move and countermove. It&apos;s the biggest known unknown on the way to AGI.</p>",orthonormal,orthonormal,orthonormal,
X2i9dQQK3gETCyqh2,Chris Olah’s views on AGI safety,chris-olah-s-views-on-agi-safety,https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety,2019-11-01T20:13:35.210Z,208,90,40,False,False,,"<p><em>Note: I am not Chris Olah. This post was the result of lots of back-and-forth with Chris, but everything here is my interpretation of what Chris believes, not necessarily what he actually believes. Chris also wanted me to emphasize that his thinking is informed by all of his colleagues on the OpenAI Clarity team and at other organizations.</em></p>
<p>In thinking about AGI safety—and really any complex topic on which many smart people disagree—I’ve often found it very useful to build a collection of different viewpoints from people that I respect that I feel like I understand well enough to be able to think from their perspective. For example, I will often try to compare what an idea feels like when I put on my Paul Christiano hat to what it feels like when I put on my Scott Garrabrant hat. Recently, I feel like I’ve gained a new hat that I’ve found extremely valuable that I also don’t think many other people in this community have, which is my Chris Olah hat. The goal of this post is to try to give that hat to more people.</p>
<p>If you’re not familiar with him, Chris Olah leads the Clarity team at OpenAI and formerly used to work at Google Brain. Chris has been a part of many of the most exciting ML interpretability results in the last five years, including <a href=""https://distill.pub/2019/activation-atlas/"">Activation Atlases</a>, <a href=""https://distill.pub/2018/building-blocks/"">Building Blocks of Interpretability</a>, <a href=""https://distill.pub/2017/feature-visualization/"">Feature Visualization</a>, and <a href=""https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html"">DeepDream</a>. Chris was also a coauthor of “<a href=""https://arxiv.org/abs/1606.06565"">Concrete Problems in AI Safety</a>.”</p>
<p>He also thinks a lot about technical AGI safety and has a lot of thoughts on how ML interpretability work can play into that—thoughts which, unfortunately, haven’t really been recorded previously. So: here’s my take on Chris’s AGI safety worldview.</p>
<h1>The benefits of transparency and interpretability</h1>
<p>Since Chris primarily works on ML transparency and interpretability, the obvious first question to ask is how he imagines that sort of research aiding with AGI safety. When I was talking with him, Chris listed four distinct ways in which he thought transparency and interpretability could help, which I’ll go over in his order of importance.</p>
<h2>Catching problems with auditing</h2>
<p>First, Chris says, interpretability gives you a mulligan. Before you deploy your AI, you can throw all of your interpretability tools at it to check and see what it actually learned and make sure it learned the right thing. If it didn’t—if you find that it’s learned some sort of potentially dangerous proxy, for example—then you can throw your AI out and try again. As long as you’re in a domain where your AI isn’t actively trying to deceive your interpretability tools (via <a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks"">deceptive alignment</a>, perhaps), this sort of a mulligan could help quite a lot in resolving more standard robustness problems (<a href=""https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/pL56xPoniLvtMDQ4J"">proxy alignment</a>, for example). That being said, that doesn’t necessarily mean waiting until you’re on the verge of deployment to look for flaws. Ideally you’d be able to discover problems early on via an ongoing auditing process as you build more and more capable systems.</p>
<p>One of the OpenAI Clarity team’s major research thrusts right now is developing the ability to more rigorously and systematically audit neural networks. The idea is that interpretability techniques shouldn’t have to “get lucky” to stumble across a problem, but should instead reliably catch any problematic behavior. In particular, one way in which they’ve been evaluating progress on this is the “auditing game.” In the auditing game, one researcher takes a neural network and makes some modification to it—maybe images containing both dogs and cats are now classified as rifles, for example—and another researcher, given only the modified network, has to diagnose the problem and figure out exactly what modification was made to the network using only interpretability tools without looking at error cases. Chris’s hope is that if we can reliably catch problems in an adversarial context like the auditing game, it’ll translate into more reliably being able to catch alignment issues in the future.</p>
<h2>Deliberate design</h2>
<p>Second, Chris argues, advances in transparency and interpretability could allow us to significantly change the way we design ML systems. Instead of a sort of trial-and-error process where we just throw lots of different techniques at the various benchmarks and see what sticks, if we had significantly better transparency tools we might be able to design our systems deliberately by understanding why our models work and how to improve them. In this world, because we would be building systems with an understanding of why they work, we might be able to get a much better understanding of their failure cases as well and how to avoid them.</p>
<p>In addition to these direct benefits, Chris expects some large but harder-to-see benefits from such a shift as well. Right now, not knowing anything about how your model works internally is completely normal. If even partly understanding one’s model became normal, however, then the amount we don’t know might become glaring and concerning. Chris provides the following analogy to illustrate this: if the only way you’ve seen a bridge be built before is through unprincipled piling of wood, you might not realize what there is to worry about in building bigger bridges. On the other hand, once you’ve seen an example of carefully analyzing the structural properties of bridges, the absence of such an analysis would stand out.</p>
<h2>Giving feedback on process</h2>
<p>Third, access to good transparency and interpretability tools lets you give feedback to a model—in the form of a loss penalty, reward function, etc.—not just on its output, but also on the process it used to get to that output. Chris and his coauthors lay this argument out in “<a href=""https://distill.pub/2018/building-blocks/"">Building Blocks of Interpretability</a>:”</p>
<blockquote>
<p>One very promising approach to training models for these subtle objectives is learning from human feedback. However, even with human feedback, it may still be hard to train models to behave the way we want if the problematic aspect of the model doesn’t surface strongly in the training regime where humans are giving feedback. Human feedback on the model’s decision-making process, facilitated by interpretability interfaces, could be a powerful solution to these problems. It might allow us to train models not just to make the right decisions, but to make them for the right reasons. (There is however a danger here: we are optimizing our model to look the way we want in our interface — if we aren’t careful, this may lead to the model fooling us!)</p>
</blockquote>
<p>The basic idea here is that rather than just using interpretability as a mulligan at the end, you could also use it as part of your objective during training, incentivizing the model to be as transparent as possible. Chris notes that this sort of thing is quite similar to the way in which we actually judge human students by asking them to show their work. Of course, this has risks—it could increase the probability that your model only looks transparent but isn’t actually—but it also has the huge benefit of helping your training process steer clear of bad uninterpretable models. In particular, I see this as potentially being a big boon for <a href=""https://ai-alignment.com/informed-oversight-18fcb5d3d1e1"">informed oversight</a>, as it allows you to incorporate into your objective an incentive to be more transparent to an amplified overseer.</p>
<p>One way in particular that the Clarity team’s work could be relevant here is a research direction they’re working on called model diffing. The idea of model diffing is to have a way of systematically comparing different models and determining what’s different from the point of view of high-level concepts and abstractions. In the context of informed oversight—or specifically <a href=""https://www.alignmentforum.org/posts/9Dy5YRaoCxH9zuJqa/relaxed-adversarial-training-for-inner-alignment"">relaxed adversarial training</a>—you could use model diffing to track exactly how your model is evolving over the course of training in a way which is inspectable to the overseer.<sup class=""footnote-ref""><a href=""#fn-ZFdWxFnGBAHnXoxpN-1"" id=""fnref-ZFdWxFnGBAHnXoxpN-1"">[1]</a></sup></p>
<h2>Building microscopes not agents</h2>
<p>One point that Chris likes to talk about is that—despite talking a lot about how we want to avoid race-to-the-bottom dynamics—the AI safety community seems to have just accepted that we have to build agents, despite the dangers of agentic AIs.<sup class=""footnote-ref""><a href=""#fn-ZFdWxFnGBAHnXoxpN-2"" id=""fnref-ZFdWxFnGBAHnXoxpN-2"">[2]</a></sup> Of course, there’s a reason for this: agents seem to be more competitive. Chris cites Gwern’s “<a href=""https://www.gwern.net/Tool-AI"">Why Tool AIs Want to Be Agent AIs</a>” here, and notes that he mostly agrees with it—it does seem like agents will be more competitive, at least by default.</p>
<p>But that still doesn’t mean we have to build agents—there’s no universal law compelling us to do so. Rather, agents only seem to be on the default path because a lot of the people who currently think about AGI see them as the shortest path.<sup class=""footnote-ref""><a href=""#fn-ZFdWxFnGBAHnXoxpN-3"" id=""fnref-ZFdWxFnGBAHnXoxpN-3"">[3]</a></sup> But potentially, if transparency tools could be made significantly better, or if a major realignment of the ML community could be achieved—which Chris thinks might be possible, as I’ll talk about later—then there might be another path.</p>
<p>Specifically, rather than using machine learning to build agents which directly take actions in the world, we could use ML as a <em>microscope</em>—a way of learning about the world without directly taking actions in it. That is, rather than training an RL agent, you could train a predictive model on a bunch of data and use interpretability tools to inspect it and figure out what it learned, then use those insights to inform—either with a human in the loop or in some automated way—whatever actions you actually want to take in the world.</p>
<p>Chris calls this alternative vision of what an advanced AI system might look like a microscope AI since the AI is being used sort of like a microscope to learn about and build models of the world. In contrast with something like a tool or oracle AI that is designed to output useful information, the utility of a microscope AI wouldn’t come from its output but rather our ability to look inside of it and access all of the implicit knowledge it learned. Chris likes to explain this distinction by contrasting Google Translate—the oracle/tool AI in this analogy—to an interface that could give you access to all the linguistic knowledge implicitly present in Google Translate—the microscope AI.</p>
<p>Chris talks about this vision in his post “<a href=""https://colah.github.io/posts/2015-01-Visualizing-Representations/"">Visualizing Representations: Deep Learning and Human Beings</a>:”</p>
<blockquote>
<p>The visualizations are a bit like looking through a telescope. Just like a telescope transforms the sky into something we can see, the neural network transforms the data into a more accessible form. One learns about the telescope by observing how it magnifies the night sky, but the really remarkable thing is what one learns about the stars. Similarly, visualizing representations teaches us about neural networks, but it teaches us just as much, perhaps more, about the data itself.</p>
<p>(If the telescope is doing a good job, it fades from the consciousness of the person looking through it. But if there’s a scratch on one of the telescope’s lenses, the scratch is highly visible. If one has an example of a better telescope, the flaws in the worse one will suddenly stand out. Similarly, most of what we learn about neural networks from representations is in unexpected behavior, or by comparing representations.)</p>
<p>Understanding data and understanding models that work on that data are intimately linked. In fact, I think that understanding your model has to imply understanding the data it works on.</p>
<p>While the idea that we should try to visualize neural networks has existed in our community for a while, this converse idea—that we can use neural networks for visualization—seems equally important [and] is almost entirely unexplored.</p>
</blockquote>
<p>Shan Carter and Michael Nielsen have also discussed similar ideas in their <a href=""https://distill.pub/2017/aia/"">Artificial Intelligence Augmentation</a> article in Distill.</p>
<p>Of course, the obvious question with all of this is whether it could ever be anything but hopelessly uncompetitive. It is important to note that Chris generally agrees that microscopes are unlikely to be competitive—which is why he’s mostly betting on the other routes to impact above. He just hasn’t entirely given up hope that a realignment of the ML community away from agents towards things like deliberate design and microscopes might still be possible.</p>
<p>Furthermore, even in a world where the ML community still looks very similar to how it does today, if we have really good interpretability tools and the largest AI coalition has a strong lead over the next largest, then it might be possible to stick with microscopes for quite some time. Perhaps enough to either figure out how to align agents or otherwise get some sort of decisive strategic advantage.</p>
<h1>What if interpretability breaks down as AI gets more powerful?</h1>
<p>Chris notes that one of the biggest differences between him and many of the other people in the AI safety community is his belief that very strong interpretability is at all possible. The model that Chris has here is something like a reverse compilation process that turns a neural network into human-understable code. Chris notes that the resulting code might be truly gigantic—e.g. the entire Linux kernel—but that it would be faithful to the model and understandable by humans. Chris’s basic intuition here is that neural networks really do seem to learn meaningful features and that if you’re willing to put a lot of energy in to understand them all—e.g. just actually inspect every single neuron—then you can make it happen. Chris notes that this is in contrast to a lot of other neural network interpretability work which is more aimed at approximating what neural networks do in particular cases.</p>
<p>Of course, this is still heavily dependent on exactly what the scaling laws are like for how hard interpretability will be as our models get stronger and more sophisticated. Chris likes to use the following graph to describe how he sees transparency and interpretability tools scaling up:</p>
<p><img src=""https://i.imgur.com/DQPWNC5.png"" alt=""""></p>
<p>This graph has a couple of different components to it. First, simple models tend to be pretty interpretable—think for example linear regression, which gives you super easy-to-understand coefficients. Second, as you scale up past simple stuff like linear regression, things get a lot messier. But Chris has a theory here: the reason these models aren’t very interpretable is because they don’t have the capacity to express the full concepts that they need, so they rely on confused concepts that don’t quite track the real thing. In particular, Chris notes that he has found that better, more advanced, more powerful models tend to have crisper, clearer, more interpretable concepts—e.g. InceptionV1 is more interpretable than AlexNet. Chris believes that this sort of scaling up of interpretability will continue for a while until you get to around human-level performance, at which point Chris hypothesizes that the trend will stop as models start moving away from crisp human-level concepts to still crisp but now quite alien concepts.</p>
<p>If you buy this graph—or something like it—then interpretability should be pretty useful all the way up to and including AGI—though perhaps not for very far past AGI. But if you buy a continuous-takeoff worldview, then that’s still pretty useful. Furthermore, in my opinion, I think that the dropping off of interpretability at the end of this graph is just an artifact of using a human overseer. If you instead substituted in an amplified overseer, then I think it’s plausible that interpretability could just keep going up, or at least level off at some high level.</p>
<h1>Improving the field of machine learning</h1>
<p>One thing that Chris thinks could really make a big difference in achieving a lot of the above goals would be some sort of realignment of the machine learning community. Currently, the thing that the ML community primarily cares about is chasing state-of-the-art results on its various benchmarks without regard for understanding what the ML tools they’re using are actually doing. But that’s not what the machine learning discipline has to look like, and in fact, it’s not what most scientific disciplines do look like.</p>
<p>Here’s Chris’s vision for what an alternative field of machine learning might look like. Currently, machine learning researchers primarily make progress on benchmarks via trial and error. Instead, Chris wants to see a field which focuses on deliberate design where understanding models is prioritized and the way that people make progress is through deeply understanding their systems. In this world, ML researchers primarily make better models by using interpretability tools to understand why their models are doing what they’re doing instead of just throwing lots of things at the wall and seeing what sticks. Furthermore, a large portion of the field in this world is just devoted to gathering information on what models do—cataloging all the different types of circuits that appear across different neural networks, for example<sup class=""footnote-ref""><a href=""#fn-ZFdWxFnGBAHnXoxpN-4"" id=""fnref-ZFdWxFnGBAHnXoxpN-4"">[4]</a></sup>—rather than on trying to build new models.<sup class=""footnote-ref""><a href=""#fn-ZFdWxFnGBAHnXoxpN-5"" id=""fnref-ZFdWxFnGBAHnXoxpN-5"">[5]</a></sup></p>
<p>If you want to change the field in this way, there are essentially two basic paths to making something like that happen—you can either:</p>
<ol>
<li>get current ML researchers to switch over to interpretability/deliberate design/microscope use or</li>
<li>produce new ML researchers working on those things.</li>
</ol>
<p>Chris has thoughts on how to do both of these, but I’ll start with the first one. Chris thinks that several factors could make a high-quality interpretability field appealing for researchers. First, interpretability could be a way for researchers without access to large amounts of compute to stay relevant in a world where relatively few labs can train the largest machine learning models. Second, Chris thinks there’s lots of low hanging fruit in interpretability such that it should be fairly easy to have impressive research results in the space over the next few years. Third, Chris’s vision of interpretability is very aligned with traditional scientific virtues—which can be quite motivating for many people—even if it isn’t very aligned with the present paradigm of machine learning.</p>
<p>However, If you want researchers to switch to a new research agenda and/or style of research, it needs to be possible for them to support careers based on it. Unfortunately, the unit of academic credit in machine learning tends to be traditional papers, published in conferences, evaluated on whether they set a new state-of-the-art on a benchmark (or more rarely by proving theoretical results). This is what decides who gets hired, promoted, and tenured in machine learning.</p>
<p>To address this, Chris founded <a href=""https://distill.pub/about/"">Distill</a>, an academic machine learning journal that aims to promote a different style of machine learning research. Distill aims to be a sort of “adapter” between the traditional method of evaluating research and the new style of research—based around things like deliberate design and microscope use—that Chris wants to see the field move to. Specifically, Distill does this by being different in a few key ways:</p>
<ol>
<li>Distill explicitly publishes papers visualizing machine learning systems, or even just explanations improving Clarity of thought in machine learning (Distill’s expository articles have become widely used references).</li>
<li>Distill has all of the necessary trappings to make it recognized as a legitimate academic journal such that Distill publications will be taken seriously and <a href=""https://scholar.google.com/scholar?q=site%3Adistill.pub"">cited</a>.</li>
<li>Distill has support for all the sorts of nice interactive diagrams that are often necessary for presenting interpretability research.</li>
</ol>
<p>The second option is to produce new ML researchers pursuing deliberate design rather than converting old ones. Here, Chris has a pretty interesting take on how this can be done: convert neuroscientists and systems biologists.</p>
<p>Here’s Chris’s pitch. There are whole fields of neuroscience dedicated to understanding all the different connections, circuits, pathways, etc. in all different manner of animal brains. Similarly, for the systems biologists, there are significant communities of researchers studying individual proteins, their interactions and pathways, etc. While neural networks are different from these lines of research at a detailed level, a lot of high level research expertise—e.g. epistemic standards for studying circuits, recurring motifs, research intuition—may be just as helpful for this type of research as machine learning expertise. Chris thinks neuroscientists or systems biologists willing to make this transition would be able to get funding to do their research, a much easier time running experiments, and lots of low-hanging fruit in terms of new publishable results that nobody has found yet.</p>
<h2>Doesn’t this speed up capabilities?</h2>
<p>Yes, it probably does—and Chris agrees that there’s a negative component to that—but he’s willing to bet that the positives outweigh the negatives.</p>
<p>Specifically, Chris thinks the main question is whether principled and deliberate model design based on interpretability can beat automated model design approaches like neural architecture search. If it can, we get capabilities acceleration, but also a paradigm shift towards deliberate model design, which Chris expects to significantly aid alignment. If we don’t, interpretability loses one of its upsides (other advantages like auditing still exist in this world) but also doesn’t have the downside of acceleration. Both the upside and downside go hand in hand, and Chris expects the upside to outweigh the downside.</p>
<hr>
<p><em>Update: If you're interested in understanding Chris's current transparency and interpretability work, a good starting point is the <a href=""https://distill.pub/2020/circuits/"">Circuits Thread</a> on Distill.</em></p>
<hr class=""footnotes-sep"">
<section class=""footnotes"">
<ol class=""footnotes-list"">
<li id=""fn-ZFdWxFnGBAHnXoxpN-1"" class=""footnote-item""><p>In particular, this could be a way of getting traction on addressing <a href=""https://www.alignmentforum.org/posts/uXH4r6MmKPedk8rMA/gradient-hacking"">gradient hacking</a>. <a href=""#fnref-ZFdWxFnGBAHnXoxpN-1"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-ZFdWxFnGBAHnXoxpN-2"" class=""footnote-item""><p>As an example of the potential dangers of agents, more agentic AI setups seem much more prone to <a href=""https://arxiv.org/abs/1906.01820"">mesa-optimization</a>. <a href=""#fnref-ZFdWxFnGBAHnXoxpN-2"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-ZFdWxFnGBAHnXoxpN-3"" class=""footnote-item""><p>A notable exception to this, however, is Eric Drexler’s “<a href=""https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf"">Reframing Superintelligence: Comprehensive AI Services as General Intelligence</a>.” <a href=""#fnref-ZFdWxFnGBAHnXoxpN-3"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-ZFdWxFnGBAHnXoxpN-4"" class=""footnote-item""><p>An example of the sort of common circuit that appears in lots of different models that the Clarity team has found is the way in which convolutional neural networks stay reflection-invariant: to detect a dog, they separately detect leftwards-facing and rightwards-facing dogs and then union them together. <a href=""#fnref-ZFdWxFnGBAHnXoxpN-4"" class=""footnote-backref"">↩︎</a></p>
</li>
<li id=""fn-ZFdWxFnGBAHnXoxpN-5"" class=""footnote-item""><p>This results in a large portion of the field being focused on what is effectively microscope use, which could also be quite relevant for making microscope AIs more tenable. <a href=""#fnref-ZFdWxFnGBAHnXoxpN-5"" class=""footnote-backref"">↩︎</a></p>
</li>
</ol>
</section>
",evhub,evhub,evhub,
ozr49Wro6BxaCMmJ7,Explaining Visual Thinking,explaining-visual-thinking,https://www.lesswrong.com/posts/ozr49Wro6BxaCMmJ7/explaining-visual-thinking,2019-11-01T20:00:54.037Z,7,6,14,False,True,,"<p>One of my students asked me how visual thinking works. As someone who does not think in pictures, I was a bit stumped on how to explain it because I can&apos;t simulate visual thinking in my mind (I usually try to conceptualise and simulate things I haven&apos;t experienced in order to understand them better). I&apos;m actually really interested now, myself, in understanding the mechanisms of visual thinking, and how it all works.</p><p>Are any of you here visual thinkers? How would you explain the way your visual thinking occurs in your mind to someone so they could conceptualise it in terms of both the processes and the sensations?</p>",Teach,teach,Teach,
E4zGWYzh6ZiG85b2z,The Curse Of The Counterfactual,the-curse-of-the-counterfactual,https://www.lesswrong.com/posts/E4zGWYzh6ZiG85b2z/the-curse-of-the-counterfactual,2019-11-01T18:34:41.186Z,140,75,35,False,False,,"<h3>The Introduction</h3>
<p>The Curse of the Counterfactual is a side-effect of the way our brains process <a href=""https://www.lesswrong.com/posts/SCEi8uxS25bCDzHRj/mental-representation-and-the-is-ought-distinction"">is-ought distinctions</a>.  It causes our brains to compare our past, present, and future to various counterfactual imaginings, and then blame and punish ourselves for the difference between reality, and whatever we just made up to replace it.</p>
<p>Seen from the outside, this process manifests itself as stress, anxiety, procrastination, perfectionism, creative blocks, loss of motivation, inability to let go of the past, constant starting and stopping on one goal or frequent switching between goals, low self-esteem and many other things.  From the <em>inside</em>, however, these counterfactuals can feel more real to us than <em>reality itself</em>, which can make it difficult to even notice it's happening, let alone being able to stop it.</p>
<p>Unfortunately, even though each specific <em>instance</em> of the curse can be defused using relatively simple techniques, we can’t just remove the parts of our brain that generate new instances of the problem.  Which means that you can’t sidestep the Curse by imagining yet another counterfactual world: one in which you believe you <em>ought</em> to be able to avoid falling into its trap, just by being smarter or more virtuous!</p>
<p>Using examples derived from my client work, this article will show how the Curse operates, and the bare bones of some approaches to rectifying it, with links to further learning materials.  (Case descriptions are anonymized and/or composites; i.e., the names are not real, and identifying details have been changed.)</p>
<h4>The Disclaimer</h4>
<p>To avoid confusion between object-level advice, and the meta-level issue of “how our moral judgment frames interfere with rational thinking”, I have intentionally <strong>omitted</strong> any description of how the fictionalized or composite clients <em>actually</em> solved the real-life problems implied by their stories.  The examples in this article do not promote or recommend any specific <em>object-level</em> solutions for even those clients’ actual specific problems, let alone universal advice for people in similar situations.</p>
<p>So, if you have the impression that I am recommending, for example, specific ways to deal with career or relationship issues, you are extrapolating something that is <em>not actually here</em>: this article is strictly about how the interaction between counterfactuals and moral judgment interferes with our practical thinking processes, not about what <em>conclusions</em> people draw once their ability to think practically has been restored.</p>
<h3>The Stories</h3>
<h4>The Wish</h4>
<p>Carlos is telling me about his childhood.  His father was very strict, imposing cruel and sadistic punishments for the most minor offences.  Years ago, the punishments stopped, but Carlos is still upset.  His father should not have done those things, he says.  “He should have loved me more.”</p>
<p>“Is that true?” I ask.  “If you compare the statement ‘He should have loved me more’, to what <em>actually happened</em>, what do you feel?”</p>
<p>Carlos is hesitant, confused.</p>
<p>I explain further.  “Is the truth that he <em>should</em> have loved you more?  Or is it only true that you <em>wish</em> he loved you more?”</p>
<p>Try these two statements on for size, I tell him.  How do they feel?  Which one is better?  Which one is <em>true</em>?</p>
<ul>
<li>My father <em>should</em> have loved me more</li>
<li>I <em>wish</em> my father had loved me more</li>
</ul>
<p>The first feels angry.  Resentful.  He feels like a victim, helpless.  There is nothing he can do.</p>
<p>The second one, when he tries it, feels different.  It is sad, because what he wishes did not come to pass.  At the same time, it is wistful, because he is experiencing a glimpse of what it would be like, if his father <em>had</em> loved him more.  And then the feeling of sadness passes.  There is grief, but then it’s <em>over</em>.</p>
<p>When he looks back on the past, it’s now just a memory.  He still <em>wishes</em> that things were different, still feels wistful...  but he’s no longer a victim, at least in that particular way.</p>
<h4>The Principle</h4>
<p>Sara is telling me about a professional conference she recently attended.  As part of a group exercise, she tried hard to persuade her group to adopt her plan for their presentation, and was met with dismissal and obstruction.</p>
<p>She is angry at herself for not being better at persuading them.  She should’ve been less stubborn, she says.  Should have listened more, tried to understand their points of view beforehand, so she could be more persuasive later.  If they understood what she had to offer, she thinks, they would have used her ideas.</p>
<p>I explain to Sara that she is suffering from the Curse of the Counterfactual: the brain’s tendency to attach <strong>moral weight</strong> to the things that we imagine <em>could</em> have gone differently, or how we believe things <em>ought</em> to be.</p>
<p>She is suffering from a more complex version of the Curse than Carlos, but the result is similar.  She feels angry at herself, not her father.  And she feels at fault for her perceived failings, because her brain is <em>literally</em> punishing her for what she failed to do, with guilt and self-directed anger.</p>
<p>“Compare your experience of the event with what you think <em>should</em> have happened.  Is it true that you <em>should</em> have been less stubborn?  Or do you only <em>wish</em> you had been less stubborn?”</p>
<p>Sara fights the question more than Carlos.  Less experienced in emotional reflection, she retreats to a logical argument, saying that it’s <em>definitely</em> true she should have been less stubborn, because that would have produced better results.</p>
<p>Her brain, I explain, is in a loop.  On the one hand, she knows the facts of what <em>actually</em> happened.  She admits that she did not <em>actually</em> do any of the things she thinks she should have.  But her brain persists in arguing that <strong>reality is wrong</strong>.  Her brain is telling her it should not have happened the way it did, and that (in effect), the fact that it <em>did</em> happen that way must be <strong>punished</strong>.</p>
<p>I explain to Sara that our brain has special machinery devoted to punishing.  It makes us feel anger or disgust when we perceive our standards – or our tribe’s standards – being violated.  And it generally doesn’t stop, until or unless the violator is sufficiently punished, or repents.</p>
<p>But <em>reality</em> cannot be punished.  And it certainly can’t ever repent!  So every time she thinks of what <em>did</em> happen, her brain keeps on punishing her, telling her that it should <em>not</em> have happened the way that it did.</p>
<p>“Have you ever heard the phrase, ‘it’s the principle of the thing’?” I ask.  “People go to ridiculous lengths when a principle is at stake, because our brains want to make it costly for others to cross us.  The problem is, when we apply ‘principles’ to reality, the only person who gets punished is <em>us</em>.”</p>
<h4>The Punishment Myth</h4>
<p>Ingvar is having trouble getting his work done.  He believes he <em>should</em> be able to knock it out in an afternoon, but he doesn’t.  He surfs the internet, feeling guilty the entire time, because he <em>should</em> be working.</p>
<p>Ingvar is experienced at Focusing and IFS, so he has better access to his felt sense than Sara or Carlos, and we rapidly dismantle the moral belief that he is a bad person whenever he is not working.  Afterwards, we test his prior thought that he should be able to get his work done in a certain amount of time, and he spontaneously begins talking about strategies for getting it done more easily and quickly.  He no longer feels stuck about doing the work, the way he did before.</p>
<p>I explain to him that this is because the brain has different machinery for different types of motivation.  Our moral judgment system does not motivate us to actually <em>accomplish</em> anything.  All it can do is motivate us to punish or protest, to rage and repent.  “After all,” I say.  “Punishment doesn’t actually change your behavior in any meaningful way.  When you weren’t doing your work, you punished yourself constantly while surfing the internet.  But you never actually <em>stopped</em>.”</p>
<p>“In fact, while you were punishing yourself, you got to feel <em>good</em> about yourself, because punishing meant you <em>cared</em>.  You weren’t some bad person who wouldn’t even feel <em>guilty</em> about not working.  So your self-punishment actually gave you a <a href=""https://en.wikipedia.org/wiki/Self-licensing"">moral license</a> to continue as you were.”</p>
<p>“Yeah,” Ingvar says.  “You’re right.  I felt guilty, but also, <em>better</em>.  If I hadn’t been punishing myself it would have been worse, because I would’ve felt like a <em>bad person</em>.”</p>
<p>“Exactly.  Exercising moral judgment makes us feel good and righteous, because our brain wants to reward us for punishing violators.  But because it works this way, it hijacks our actual motivation to <em>accomplish</em> anything.  The act of punishing <em>feels</em> like we’re accomplishing something, so we don’t feel like doing anything else.</p>
<p>“In addition, while all that is going on, our brain’s creative, problem-solving modules are idle.  That’s why you were stuck before.  The ideas you’re coming up with now, for <em>how</em> to do the work, are not things you thought of before.  Some of them, I thought of when you first told me about your problem.  But I didn’t <em>mention</em> any of them, because from where you were before, you would have said, “yeah, but...” to them.  Am I right?”</p>
<p>Ingvar admits that this, too, is true.  The very same ideas he is coming up with now to get his work done, would have felt irrelevant, useless, or even insulting had someone suggested them to him thirty minutes ago...  because they wouldn’t have helped him <em>punish</em> anybody!</p>
<h4>The “Nice Guy” Paradigm</h4>
<p>I’m explaining the same thing to Sara.  She’s protesting that if she <em>doesn’t</em> think she should be less stubborn, then how will she ever change it?</p>
<p>“What we <em>want</em> and what we think we <em>should</em> are two different things.  If it truly would be better to be less stubborn, if that’s something you <em>want</em>, then not having the ‘should’ actually makes it <em>easier</em>.</p>
<p>“But what your brain is doing right now is not <em>wanting</em> to be better.  Rather, your brain is trying to cancel out a <strong>loss</strong>.</p>
<p>“Right now, you are imagining a way that you would prefer things to have happened at the conference.  But the fact that it didn’t happen that way is painful, because the way things actually went is not as good as what you imagined or hoped for.  But if you say to yourself that you <em>should</em> have acted differently, then it allows your brain to preserve <em>hope</em>.</p>
<p>“If you believe you <em>should</em> have acted differently, then you can continue to believe that they <em>would</em> have accepted your ideas, if only you had been better at convincing them.  It’s like holding on to a bad investment and not selling it, so you don’t have to acknowledge the loss in your mental bookkeeping.”</p>
<p>The specific variant of the Counterfactual Curse that Sara is experiencing is the “Nice Guy Paradigm”.  (Which, despite the name, is not actually gender-specific; it’s actually from a book called “No More Mr. Nice Guy”, about becoming assertive instead of people-pleasing.)</p>
<p>The Nice Guy Paradigm is any belief of the form, “If I were X enough, then [other people / reality / I] would [do / be / have] Y.”  (In the book’s original formulation, this was expressed more concretely as, “IF I can hide my flaws and become what I think others want me to be, THEN I will be loved, get my needs met, and have a problem-free life.”)</p>
<p>In Sara’s case, she believes that <em>if only</em> she were good enough at persuasion, not being stubborn, etc. then people would understand and accept her ideas (and respect and appreciate her).</p>
<p>The upside of this belief is that it allows her to continue hoping that <em>someday</em>, maybe she will be good enough at these things, so <em>eventually</em> she will get the respect and acknowledgment she deserves and desires.  (Which helps her feel less bad about the fact that <em>today</em>, she is not getting those things.)</p>
<p>The downside of this belief, though, is that since what other people do is not 100% within her control, she could be the world’s best persuader and <em>still</em> get let down sometimes.  And because this belief runs backwards as well as forwards, then when other people <em>don’t</em> acknowledge or respect her, she will still feel that it is <em>all her fault</em>.  (And it will never cross her mind that some people might just be dicks or just plain <em>unwilling</em> to understand or accept her or her ideas, <em>no matter how good</em> she or those ideas may be.)</p>
<h4>The Bad News</h4>
<p>Another client, Victor, is excited.  I’ve just explained the curse of the counterfactual as it relates to his problem.  “So I should just stop using ‘should’ and everything will be better?”</p>
<p>“No, sorry.  It doesn’t work that way.  The part of your brain that ties counterfactual imaginings to moral judgment isn’t going to go away by us wishing it would.  We can remove the <em>links</em> from the activities and situations that <em>trigger</em> the “shoulds”, and we can <em>specifically</em> question the truth of individual “shoulds” to get free of them.  But it is not an intellectual exercise.  It’s an <strong>experiential</strong> one.</p>
<p>“To put it another way, your moral judgment system can be persuaded that it made a mistake about whether to punish <em>this one thing in particular</em>, but it cannot be persuaded that <em>it’s a mistake to punish things in general</em>.  (Motivating you to punish things is what that part of your brain <em>does</em>, after all; it’s not like it can go get another job!)”</p>
<p>I tell him about the time I first found out about the Curse and how to fix individual instances of it, and how I, too, thought that <em>I</em> “should” be able to “just stop using shoulds”.  (And I’m not proud to say it took me <em>years</em> to fully realize the inherent meta-contradiction taking place there!)</p>
<p>I tell Victor about a book on the process we’ve just used to tackle one of his problems, and mention that there’s a chapter in it devoted to a session where the issue somebody wants to work on is <em>this very one</em>: the fact that they think they <em>should</em> be able to fix all their problems without having to individually address each and every “should” they have.</p>
<p>Victor laughs once he sees the “meta” of it, the inherent contradiction that nonetheless took me years to beat into my own skull.  “So I should probably work on that first, yeah?”</p>
<p>Probably so, Victor.  Probably so.</p>
<h3>The Theory</h3>
<h4>The Bias</h4>
<p>Byron Katie has a wonderful term we can use to name an instance of the Curse.  She calls it “an argument with reality”.  Because our brain is arguing that, because it can imagine something <em>better</em> than whatever actually happened, then, in some vaguely “moral” sense, that better thing <em>ought</em> to have happened instead.</p>
<p>But, since that better thing <em>didn’t</em> happen, that clearly means reality is <strong>wrong</strong>, and <em>someone</em> must therefore be punished.</p>
<p>(Maybe you!)</p>
<p>But reality, no matter how repugnant it may be (morally or otherwise), and no matter how much we want to punish it, is still <em>reality</em>.</p>
<p>And as Byron Katie puts it, “When I argue with reality, I <em>lose</em>...  but only 100% of the time!”</p>
<p>Now, to our moral brains, this statement may <em>itself</em> seem morally wrong.  “How dare you!” our brains may say.  “How dare you imply that we should forgive/accept/approve historical atrocity X!”</p>
<p>How <em>dare</em> you tell us to accept the existence of suffering, death, imperfection?</p>
<p>It is important to understand that this is an illusion, a <em>bias</em>.  When activated, the moral brain acts as though the <strong>only</strong> thing motivating <em>anyone</em> is proper punishment and disapproval.  It makes us feel that, if we fail to be sufficiently outraged, then <em>nothing</em> will ever happen.  Justice will <em>never</em> be done.</p>
<p>And it does this to us, because, for the good of the tribe – that is to say, the good of our genes! – we must be motivated to not only punish the wrongdoers, we must <em>also</em> be motivated to <a href=""https://www.lesswrong.com/posts/GAgdHvzRDanQ5R7Qg/is-there-a-definitive-intro-to-punishing-non-punishers"">punish the non-punishers</a>.</p>
<p>So when you first consider the possibility of accepting reality, over your moral brain’s objections, it will feel like you are arguing for the collapse of civilization, and the abandonment of everything you hold dear.</p>
<p>Do not believe this.</p>
<h4>The Difference</h4>
<p>You can <em>want</em> to end death, disease, and suffering, without rejecting the <em>reality</em> of death, disease and suffering.</p>
<p>Moral judgment and preferences are two entirely different and separate things.  And when moral judgment is involved, <a href=""https://www.scientificamerican.com/article/psychology-of-taboo-tradeoff/"">trade-offs become taboo</a>.</p>
<p>When Ingvar was procrastinating, and felt he <em>should</em> do his work faster, his brain spent absolutely <strong>zero</strong> time considering <em>how</em> he might get it done at all, let alone how he might do it faster.</p>
<p>Why?  Because to the moral mind, the <em>reasons</em> he is not getting it done <em>do not matter</em>.  Only punishing the evildoer matters, so even if someone suggested ways he could make things easier, his moral brain rejects them as irrelevant to the <em>real</em> problem, which is <em>clearly</em> his moral failing.  Talking or thinking about problems or solutions isn’t really “working”, therefore it’s further evidence of his failing.  And making the work <em>easier</em> would be lessening his rightful punishment!</p>
<p>So when moral judgment is involved, actually <em>reasoning</em> about things feels <strong>wrong</strong>.  Because reasoning might lead to a compromise with the Great Evil: a lessening of punishment or a toleration of non-punishers.</p>
<p>This is only an illusion, albeit a <em>very persistent one</em>.</p>
<p>The truth is that, when you switch off moral judgment, <em>preference</em> remains.  Most of us, given a choice, actually <em>prefer</em> that good things happen, that we actually act in ways that are good and kind and righteous, that are not about fighting Evil, but simply making <em>more</em> of whatever we actually want to see in the world.</p>
<p>And ironically, we are <em>more</em> motivated to actually <em>produce</em> these results, when we do so from preference than from outrage.  We can be creative, we can plan, or we can even compromise and <em>adjust</em> our plans to work with reality as it <em>is</em>, rather than as we would prefer it to be.</p>
<p>After all, when we think that something is how the world <em>should</em> be, it gives us no real motivation to <em>change</em> it.  We are motivated instead to <em>protest</em> and <em>punish</em> the state of the world, or to “speak out” against those we believe responsible...  and then <em>feel</em> like we just accomplished something by doing so!</p>
<p>And so we end up just like Ingvar, surfing the net and punishing himself, but never <em>actually</em> working...  nor even choosing <em>not</em> to work and to do something more rewarding instead.</p>
<h3>The Way Out</h3>
<h4>The Methods</h4>
<p>There are many methods we can use to combat the curse of the counterfactual.</p>
<p>For example, the <a href=""https://www.lesswrong.com/posts/HYWhKXRsMAyvRKRYz/you-can-face-reality"">Litany of Gendlin</a> tells us that admitting to reality <em>cannot</em> make it worse, because whatever is happening, we are already enduring it.  (It just doesn’t <em>feel</em> that way, while the mind is still clinging to its counterfactuals, as if it were a corporate executive putting off writing down a bad investment, so as not to affect the shareholders’ annual report!)</p>
<p>We can also use the <a href=""https://wiki.lesswrong.com/wiki/Litany_of_Tarski"">Litany of Tarski</a>, and tell ourselves that if we live in a world where the counterfactual is true, then we need to know that, but conversely, if we live in a world where it is <em>not</em> true, then we need just as much to know that, too.</p>
<p>These litanies, however, are more of a reminder that points to a thing, than the actual thing itself.  They remind us and prompt us to <a href=""https://www.lesswrong.com/posts/3nZMgRTfFEfHp34Gb/the-meditation-on-curiosity"">wrestle with the truth</a> (or our idea of it), but they aren’t a substitute for <em>actually doing so</em>.</p>
<p>So the primary technique I use and teach for actually engaging with the brain’s moral judgment system (and then switching it off), is a variation on <a href=""https://en.wikipedia.org/wiki/Byron_Katie#Teachings"">The Work of Byron Katie</a>.</p>
<p>The Work is a process that in its simplest form consists of a few questions that, when asked in the right way, can gently lead our brain to notice that 1) our counterfactuals are not reality, 2) thinking they <em>are</em> reality is <em>painful</em>, and 3) maybe it would feel better if we <em>didn’t</em> think that way any more.  A little ditty describing the process goes, “Judge your neighbor, write it down; ask four questions, turn it around.”</p>
<p>The reason it begins with “judge your neighbor” is that the technique was originally created to deal with external moral judgments about what other people should or shouldn’t do.  (Like, “my father should have loved me more”.)  The technique is a little easier to use on such judgments, presumably because our moral system is more oriented towards judging other people than abstract concepts.  (So using it on judgments of yourself can be a good bit more challenging if you haven’t <em>first</em> practiced it in the way it was intended to be used.)</p>
<p>In this article, I am not going to get into much detail on the process, as there are <a href=""https://thework.com/instruction-the-work-byron-katie/#work-step-three"">free downloads at Byron Katie’s website</a>, and she has two excellent books (<em>Loving What Is</em>, and <em>I Need Your Love: Is That True?</em>) containing transcript after transcript of people doing the process on a wide variety of beliefs, as well as additional exercises for discovering one’s judgments in the first place.  Instead, I want to share the unique variations and caveats that I have learned and refined to both make the process itself clearer, and to make it easier to teach to others, especially people who are more systematically-minded and less “woo” than average.</p>
<p>(Note: some of Byron Katie’s books discuss sensitive topics including rape, child abuse, war atrocities, and more.  In addition, some of this discussion includes having victims question their belief that such things “should not” have happened or the belief it was not their fault.  And based on some reviews I’ve seen online, this is apparently even <em>more</em> triggering for some people than hearing about the actual events, once their <a href=""#The_Bias"">moral outrage kicks in</a>.)</p>
<h4>The Tests</h4>
<p>One of the biggest challenges in learning self-help techniques (or rationality techniques, for that matter), is not knowing how something is supposed to <em>feel from the inside</em>.  We can hear people telling us to believe in ourselves, to let go and accept things, or whatever, but unless we have a way to know what these things are <em>like</em>, we cannot know if we’re making progress at actually doing them.</p>
<p>For this reason, one of the most important things I do as a mindhacking instructor is to develop <em>tests</em> that one can apply to one’s experience, to know if a technique is being correctly applied.</p>
<p>For the Work of Byron Katie, there are two primary tests that I use and teach, for the first and fourth questions, to know if you are asking the questions correctly, or actually paying attention to your answers.</p>
<p>The first question of the Work is simply, “Is that true?”  But it’s not looking for what your <em>reasoning</em> says, because in the presence of moral judgment, <em>all</em> reasoning is motivated reasoning.  (Like Sara arguing that it’s true she should’ve been a certain way, because it would have made things better...  because things would have been better if she’d done things a certain way.)</p>
<p>Instead, the <em>real</em> question we are asking is something more like, “if you reflect on your experience of what has happened/been happening in <em>reality</em>, is it actually consistent with the way you're insisting it’s supposed to be?”</p>
<p>And the most important part of that question is not “is it consistent?” but “<strong>if you reflect on your experience</strong>.”  The thing that actually produces a loosening of your moral judgment is not your reasoning about the facts, but the <em>process</em> of inquiring into your <em>experience</em> of them, and your inward <em>reflection</em> on what that means.</p>
<p>This distinction is why the Work is easier for those who have easy access to their inner experience, a skill honed by Focusing, IFS, and various other therapeutic or self-help modalities.  But even though those people have the <em>ability</em> to access their inner experience, that doesn’t necessarily mean they will actually do so.  When contemplating this question, we are <strong>all</strong> tempted sometimes to deflect, to distract, to deny the very possibility of, rather than actually <em>investigating</em>.</p>
<p>Because of this, Work facilitators are trained to reject answers to this question other than “yes”, or “no”, because from the outside, this is the primary “tell” that lets them know whether you’re doing this process correctly.  If you are answering with something other than “yes” or “no” – for example, if you begin some kind of explanation or story or justification – they immediately know you aren’t reflecting on your experience, but providing reasons <em>not to</em>, or creating distractions so you won’t <em>have to</em>.</p>
<p>Unfortunately, while requiring an answer of “yes or no” keeps a facilitator from being sidetracked by your reasoning and distractions, it doesn’t actually fix the problem of “not reflecting on your experience”, or help with even knowing whether you’re reflecting on your experience to begin with.</p>
<h4>The First Test</h4>
<p>But after many years of doing and teaching this process, I have noticed that there are certain patterns in the <em>results</em> of reflecting on one’s inner experience in response to the question “is that true?”  Whenever I or my clients do the process correctly, there are actually <em>three</em> possible answers, not just two, when you take into account how you <em>feel</em>.</p>
<p>If you are correctly reflecting on “is that true?”, the <em>experience</em> of your answer will be similar to one of these three descriptions:</p>
<ul>
<li>[feeling of lightness, release, relief] “Huh...  I guess that’s <em>not</em> true.”  (e.g. “most people should like me...  huh, yeah, no, I guess there’s not any reason for that to be true”)</li>
<li>[feeling of heaviness, oppression] “I know it doesn’t make any sense, but it still <em>feels</em> true” (e.g. “I’m bad for not doing my work...  I don’t want to be, but it feels like <em>that’s just how it is</em>.”)</li>
<li>[feeling of longing or regret] “I <em>wish</em> it were” (e.g. “I <em>wish</em> my father loved me more, but I guess it didn’t actually happen”)</li>
</ul>
<p>Without understanding this sorting, people often confuse the experience of <em>wishing</em> it were true and it actually <em>being</em> true.  So they answer “yes, it’s true” to the question, because the feeling of wishing it true, is rather similar to the feeling that something <em>is</em> true.</p>
<p>However, when compared to the heavy feeling of “I hate that it’s true”,  the sad feeling of “I wish it were true” is a bit different, and once identified, can be handled much more easily.  (It’s fairly simple, after all, to take the admission that you <em>wish</em> something were true, and from there, further admit that this means it’s actually <em>not</em>.)</p>
<p>Or, if you are feeling like it’s a bad-but-true thing <em>oppressing</em> you, then you are at least making progress of a different kind.  You now know that you have an implicit belief or emotional schema <em>you don’t endorse</em>; that you simply learned at some point that this thing was a moral standard of your tribe.  (And knowing this, you can shift to a process more suited for eliciting and correcting such beliefs.)</p>
<p>Or, you can also use The Work’s question 2: “Can I absolutely <em>know</em> that it’s true?”  This question can help to loosen the sense of “rightness”, inviting you to consider how you could <em>possibly</em> know with 100% certainty the <em>actual</em> truth of an “ought”, rather than an “is”, and whether you could make that distinction in practice.  (To use a legal analogy, it’s a bit like asking if there’s any conceivable <em>doubt</em>.)</p>
<h4>The Second Test</h4>
<p>For brevity’s sake, we’ll skip a detailed treatment of the Work’s other questions, jumping straight to the outcome of question 4: “Who would you be without that thought?”  That is, what is your inwardly-reflected, <em>simulated experience</em> of how you would behave, if you weren’t thinking your “should”?</p>
<p>In my experience, the most common failure mode people have for this question is what I call “happy-ever-aftering”.  Instead of allowing their mind to automatically generate a simulation based on the what-if, they try to specifically and <em>deliberately</em> envision themselves being a better person...</p>
<p>And then fail to notice their feeling that something is <em>wrong!</em></p>
<p>Because about as often as not, the real, <em>experiential</em> answer to “Who would you be if you weren’t thinking X?”, is actually an <strong>objection</strong>, <strong>reservation</strong>, or other form of <strong>argument</strong> from your brain.</p>
<p>The thing you imagine doesn’t feel <em>real</em> or realistic.  Or worse, you feel like you would be a <em>bad person</em> in some way, if you stopped thinking or believing the moral judgment.  Or perhaps some <em>bad consequence</em> would happen, like maybe everybody would stop caring about their work and then nobody would have any coffee and civilization would fall apart.</p>
<p>These reservations can be subtle, but <em>ignoring</em> them will make the process fail.  You may briefly feel better, having imagined a different “better world” than before, but will soon be disappointed because the oppressive “should” will return, as strong as ever.  (Or perhaps be replaced by the idea that you “should” be the better person you imagined at this step!)</p>
<p>But what a reservation or objection simply means, is that your brain has <em>another</em> “should” in effect.</p>
<p>For example, at one point when I began this process, I felt that “I should be doing something” when I was trying to go to sleep.  When I got to the part about “who I would be without that thought”, I realized that I would feel <em>worse</em>, like a “bad person”.  Further inquiry showed that this was because I believed that <em>not</em> worrying about doing things meant I “wasn’t taking things seriously enough” – a new level of moral judgment to question the truth of.</p>
<p>If we think of our moral judgments as a belief network, where some beliefs are central (“you should take things seriously – i.e., worry about them”) and others less so (“you should be doing something right now”), then most of the time, we are only <em>aware</em> of the non-central ones.  In our day to day lives, for example, we may often think things like, “I should have done this by now”, but only rarely do we <em>explicitly</em> think things like, “I’m a bad person if I’m not working.”</p>
<p>So when we begin the Work of eliminating these harmful judgments, we will nearly always be starting somewhere <em>shallow</em>.  Thus, the real value of doing the process isn’t that it will fix the first thought we work on (e.g. “I should be doing something”), but that it will <em>lead us</em> to the deeper thoughts (e.g. “I’m a bad person”), through the <em>objections</em> or <em>reservations</em> we have about changing the first, shallower thoughts.</p>
<p>Then, once we are aware of those deeper beliefs, we can take steps in turn to change <em>those</em>.  And finally, once they’re no longer supported by these central “strategic” beliefs (I’m bad/not serious/etc.), the everyday, “tactical” beliefs (I should be doing something) tend to fall away on their own.</p>
<p>And then we can actually <em>think</em> about solving our real problems, instead of merely punishing ourselves for not having succeeded yet.</p>
<h3>The Conclusion</h3>
<p>The Curse of the Counterfactual is a side-effect of the way our brains process is-ought distinctions.  It causes our brains to compare our past, present, and future to various counterfactual imaginings, and then blame and punish ourselves for the difference between reality, and whatever we just made up to replace it.</p>
<p>Seen from the outside, this process manifests itself as stress, anxiety, procrastination, perfectionism, creative blocks, loss of motivation, inability to let go of the past, constant starting and stopping on one goal or frequent switching between goals, low self-esteem and many other things.  From the <em>inside</em>, however, these counterfactuals can feel more real to us than <em>reality itself</em>, which can make it difficult to even notice it's happening, let alone being able to stop it.</p>
<p>To counteract and fix this tendency, we can use various techniques (such as the litanies of Gendlin and Tarski, and the Work of Byron Katie).  But doing so is inherently effortful, in a way that <em>cannot</em> be bypassed by mere understanding.  There are, however, skills we can learn that make it easier, and tests we can apply to our inner experience that can help us know if we’re making progress or not.</p>
<p>There is no permanent or universal cure for the Curse, but reflecting on our experience in the right ways can release us from individual, <em>specific</em> cases of it.  And applied closer to the root or center of our belief networks, it can even produce broader, more dramatic shifts in our behavior and what we think of ourselves.</p>
<p>But that’s a topic for another article, as this post is now almost as long as a short ebook!</p>
<h3>The Addendum</h3>
<p>Speaking of short ebooks, if you’re interested in <em>other</em> bugs in the brain that switch off our problem-solving and creativity subsystems, you may want to grab a free copy of <a href=""https://theeffortlessway.com/#free-ebook"">A Minute To Unlimit You</a>, as I am currently soliciting feedback on it.</p>
<p>The specific kind of “stuck” it deals with is the kind where you are under pressure to do something, but all you can think about is why you <em>can’t</em> do it, what’s stopping you, how you don’t know what to do or can’t decide, etc., instead of anything actually <em>helpful</em>.</p>
<p>So if you have a problem like that, I'd appreciate your (emailed) feedback on the content.  (Are the instructions clear?  Were you able to apply the technique?  What happened afterwards?  Just hit ""reply"" on the receipt email after your download to answer.)  Thanks!</p>
",pjeby,pjeby,pjeby,
HALR7bAiNf7bgNetE,Shared Cache is Going Away,shared-cache-is-going-away,https://www.lesswrong.com/posts/HALR7bAiNf7bgNetE/shared-cache-is-going-away,2019-11-01T15:10:02.635Z,17,7,6,False,False,,"<p>

Browsers historically have had a single HTTP Cache.  This meant that
if 

www.a.example and 

www.b.example both used


cdn.example/jquery-1.2.1.js then JQuery would only be
downloaded once.  Since it's the same resource regardless of which
site initiates the download, a single shared cache is more
efficient. [1]



</p><p>

Unfortunately, a shared cache enables a privacy leak.  Summary of the
simplest version:

</p>

<ul>
<li>I want to know if you're a moderator on www.forum.example.</li>
<li>I know that only pages under
www.forum.example/moderators/private/ load
www.forum.example/moderators/header.css.</li>
<li>When you visit my page I load
www.forum.example/moderators/header.css and see if it came
from cache.</li>
</ul>

Versions of this have been around for a while, but in March 2019
Eduardo Vela disclosed a 

<a href=""https://sirdarckcat.blogspot.com/2019/03/http-cache-cross-site-leaks.html"">way
to make it much more powerful and reliable</a>.  Browsers are
responding by partitioning the cache (

<a href=""https://www.chromestatus.com/feature/5730772021411840"">Chrome</a>,


<a href=""https://bugzilla.mozilla.org/show_bug.cgi?id=1536058"">Firefox</a>;
Safari 

<a href=""https://bugs.webkit.org/show_bug.cgi?id=110269"">already
had</a>). [2] It's not clear from me reading the bugs when it will
launch, but it does sound soon. [3]



<p>

What does this mean for developers?  The main thing is that there's no
longer any advantage to trying to use the same URLs as other sites.
You won't get performance benefits from using a canonical URL over
hosting on your own site (unless they're on a CDN and you're not) and
you have no reason to use the same version as everyone else (but
staying current is still a good idea).

</p>

<p>

I'm sad about this change from a general web performance perspective
and from the perspective of someone who really likes small independent
sites, but I don't see a way to get the performance benefits without
the leaks.

</p>

<p>
<br />

[1] When I worked on <a href=""https://www.modpagespeed.com/"">mod_pagespeed</a>, rewriting web
pages so they would load faster, we had an opt-in feature to <a href=""https://www.modpagespeed.com/doc/filter-canonicalize-js"">Canonicalize
JavaScript Libraries</a>.

</p>

<p>

[2] I was curious if this had launched yet so I made a pair of test pages
and tried it out in WebPageTest for <a href=""https://webpagetest.org/result/191101_KK_ca05481e79950902c9491ac7e7ff9a6c/"">Chrome
Canary</a> and <a href=""https://webpagetest.org/result/191101_VD_b829e9699c17349bce52b663474bfce1/"">Firefox
Nightly</a> but it's not out yet.  I used a WPT script consisting of:

</p>

<pre>
navigate https://www.trycontra.com/test/cache-partition
navigate https://www.bidadance.org/test/cache-partition
</pre>



<p>

[3] Firefox's <a href=""https://bugzilla.mozilla.org/show_bug.cgi?id=1536058"">bug</a> is
marked ""fixed"" and ""Milestone: mozilla70"", but I have Firefox 70.0.1
and it doesn't seem to be enabled:

</p>

<p>

<a href=""https://www.jefftk.com/firefox-not-cache-partitioning-big.png""><img src=""https://www.jefftk.com/firefox-not-cache-partitioning.png"" /></a>

</p>

<p>

Perhaps this is just the code change and they still need a flag flip?
I don't know how Firefox does this.

  </p>

<p><i>Comment via: <a href=""https://www.facebook.com/jefftk/posts/10100119293431842"">facebook</a>, <a href=""https://lesswrong.com/posts/La4v9GBcqx6tij2FX"">lesswrong</a></i></p>",jkaufman,jkaufman,jefftk,
