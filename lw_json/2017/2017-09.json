[
  {
    "_id": "4sr9QP2pBeAY66Yap",
    "title": "Work and income in the next era",
    "slug": "work-and-income-in-the-next-era",
    "pageUrl": "https://www.lesswrong.com/posts/4sr9QP2pBeAY66Yap/work-and-income-in-the-next-era",
    "postedAt": "2017-09-30T22:02:46.806Z",
    "baseScore": 0,
    "voteCount": 0,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": "https://www.sitra.fi/en/publications/from-pause-to-play/",
    "htmlBody": null,
    "user": {
      "username": "morganism",
      "slug": "morganism",
      "displayName": "morganism"
    }
  },
  {
    "_id": "YYN5JZh8PGTuCrvTM",
    "title": "logic puzzles and loophole abuse",
    "slug": "logic-puzzles-and-loophole-abuse",
    "pageUrl": "https://www.lesswrong.com/posts/YYN5JZh8PGTuCrvTM/logic-puzzles-and-loophole-abuse",
    "postedAt": "2017-09-30T15:45:40.885Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>I recently read about&nbsp;<a href=\"https://en.wikipedia.org/wiki/The_Hardest_Logic_Puzzle_Ever\">the hardest logic puzzle ever</a>&nbsp;on Wikipedia and noticed that someone published a paper in which they solved the problem by asking only two questions instead of three. This relied on abusing the loophole that boolean formulas can result in a paradox.</p>\n<p>This got me thinking in what other ways the puzzle could be abused even further, and I managed to find a way to turn the problem into a hack to achieve omnipotence by enslaving gods (see below).</p>\n<p>I find this quite amusing, and I would like to know if you know of any other examples where popular logic puzzles can be broken in amusing ways. I'm looking for any outside-the-box solutions that give much better results than expected. <a href=\"https://alvinalexander.com/blog/post/software-dev/job-interview-question-car-bus-stop-three-people\">another example</a>.</p>\n<p>&nbsp;</p>\n<p>Here is my solution to the \"hardest logic puzzle ever\":</p>\n<p>&nbsp;</p>\n<p>This solution is based on the following assumption: The gods are quite capable of responding to a question with actions besides saying 'da' and 'ja', but simply have no reason to do so. As stated in the problem description, the beings in question are gods and they have a language of their own. They could hardly be called gods, nor have need for a spoken language, if they weren't capable of affecting reality.</p>\n<p>At a bare minimum, they should be capable of pronouncing the words 'da' and 'ja' in multiple different ways, or to delay answering the question by a fixed amount of time after the question is asked. Either possibility would extend the information content of an answer from a single bit of information to arbitrarily many bits, depending on how well you can differentiate different intonations of 'da' and 'ja', and how long you are willing to wait for an answer.</p>\n<p>We can construct a question that will result in a paradox unless a god performs a certain action. In this way, we can effectively enslave the god and cause it to perform arbitrary actions on our behalf, as performing those actions is the only way to answer the question. The actual answer to the question becomes effectively irrelevant.</p>\n<p>To do this, we approach any of the three gods and ask them the question OBEY, which is defined as follows:</p>\n<p>OBEY = if WISH_WRAPPER then True else PARADOX</p>\n<p>PARADOX = \"if I asked you PARADOX, would you respond with the word that means no in your language?\"</p>\n<p>WISH_WRAPPER = \"after hearing and understanding OBEY, you act in such a way that your actions maximally satisfy the intended meaning behind WISH. Where physical, mental or other kinds of constraints prevent you from doing so, you strive to do so to the best of your abilities instead.\"</p>\n<p>WISH = \"you determine the Coherent Extrapolated Volition of humanity and act to maximize it.\"</p>\n<p>You can substitute WISH for any other wish you would like to see granted. However, one should be very careful while doing so, as beings of pure logic are likely to interpret vague actions differently from how a human would interpret them. In particular, one should avoid accidentally making WISH impossible to fulfill, as that would cause the god's head to explode, ruining your wish.</p>\n<p>The above formulation tries to take some of these concerns into account. If you encounter this thought experiment in real life, you are advised to consult a lawyer, a friendly-AI researcher, and possibly a priest, before stating the question.</p>\n<p>Since you can ask three questions, you can enslave all three gods. Boolos' formulation states about the random god that \"if the coin comes down heads, he speaks truly; if tails, falsely\". This formulation implies that the god does try to determine the truth before deciding how to answer. This means that the wish-granting question also works for the random god.</p>\n<p>If the capabilities of the gods are uncertain, it may help to establish clearer goals as well as fall-back goals. For instance, to handle the case that the gods are in fact limited to speaking only 'da' and 'ja', it may help to append the WISH as follows: \"If you are unable to perform actions in response to OBEY besides answering 'da' or 'ja', you wait for the time period outlined in TIME before making your answer.\" You can now encode arbitrary additional information in TIME, with the caveat that you will have to actually wait before getting a response. Your ability to accurately measure the elapsed time between question and answer directly correlates with how much information you can put into TIME without risking starvation before the question is answered. The following is a simple example of TIME that would allow you to solve the original problem formulation with just asking OBEY once of any of the gods:</p>\n<p>TIME = \"If god A speaks the truth, B lies and C is random, you wait for 1 minute before answering. If god A speaks the truth, C lies and B is random, you wait for 2 minutes before answering. If god B speaks the truth, A lies and C is random, you wait for 3 minutes before answering. If god B speaks the truth, C lies and A is random, wait for 4 minutes before answering. If god C speaks the truth, A lies and B is random, wait for 5 minutes before answering. If god C speaks the truth, B lies and A is random, wait for 6 minutes before answering.\"</p>",
    "user": {
      "username": "Florian_Dietz",
      "slug": "florian_dietz",
      "displayName": "Florian_Dietz"
    }
  },
  {
    "_id": "yLLkWMDbC9ZNKbjDG",
    "title": "Slack",
    "slug": "slack",
    "pageUrl": "https://www.lesswrong.com/posts/yLLkWMDbC9ZNKbjDG/slack",
    "postedAt": "2017-09-30T11:10:00.135Z",
    "baseScore": 292,
    "voteCount": 189,
    "commentCount": 74,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Epistemic Status: Reference post. Strong beliefs strongly held after much thought, but hard to explain well. Intentionally abstract.</p><p>Disambiguation: This does not refer to any physical good, app or piece of software.</p><p>Further Research (book, recommended but not at all required, take seriously but not literally): <a href=\"https://smile.amazon.com/gp/product/B002XQAAS6/ref=s9u_simh_gw_i1?ie=UTF8&amp;fpl=fresh&amp;pd_rd_i=B002XQAAS6&amp;pd_rd_r=FZCKWAV9EQDXHX6PZN61&amp;pd_rd_w=ByYg5&amp;pd_rd_wg=z5czc&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_s=&amp;pf_rd_r=8HFTESCZEKP6GJ3K6MV0&amp;pf_rd_t=36701&amp;pf_rd_p=1cf9d009-399c-49e1-901a-7b8786e59436&amp;pf_rd_i=desktop\">The Book of the Subgenius</a></p><p>Related (from sam[ ]zdat, recommended but not required, take seriously and also literally, entire very long series also recommended): <a href=\"https://samzdat.com/2017/08/28/the-uruk-machine/\">The Uruk Machine</a></p><p>Further Reading (book): <a href=\"https://smile.amazon.com/Scarcity-Having-Little-Means-Much-ebook/dp/B00BMKOO6S/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1506174951&amp;sr=1-1&amp;keywords=scarcity\">Scarcity: Why Having Too Little Means So Much</a></p><p>Previously here (not required): <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Play in Hard Mode</a>, <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Play in Easy Mode</a>, <a href=\"https://thezvi.wordpress.com/2017/09/23/out-to-get-you/\">Out to Get You</a></p><p>Leads to (I’ve been scooped! Somewhat…): <a href=\"http://benjaminrosshoffman.com/sabbath-hard-and-go-home\">Sabbath Hard and Go Home</a></p><p>An illustrative little game: <a href=\"https://thezvi.wordpress.com/2015/05/01/carpe-diem-the-problem-of-scarcity-and-abundance/\">Carpe Diem: The Problem of Scarcity and Abundance</a></p><p>Slack is hard to precisely define, but I think this comes close:</p><h2>Definition: Slack. The absence of binding constraints on behavior.</h2><p>Poor is the person without Slack. Lack of Slack compounds and traps.</p><p>Slack means margin for error. You can <em>relax</em>. </p><p>Slack allows pursuing opportunities. You can <em>explore</em>. You can <em>trade</em>.</p><p>Slack prevents desperation. You can <em>avoid bad trades</em> and <em>wait for better spots</em>. You can <em>be efficient</em>.</p><p>Slack permits planning for the long term. You can <em>invest</em>.</p><p>Slack enables doing things for your own amusement. You can <em>play games</em>. You can <em>have fun</em>. </p><p>Slack enables doing the right thing. Stand by your friends. Reward the worthy. Punish the wicked. You can <em>have a code</em>. </p><p>Slack presents things as they are without concern for how things look or what others think. You can <em>be honest</em>.</p><p>You can do some of these things, and choose not to do others. Because you don’t have to.</p><p>Only with slack can one be a <em>righteous dude</em>.</p><p>Slack is life.</p><h2>Related Slackness</h2><p>Slack in project management is the time a task can be delayed without causing a delay to either subsequent tasks or project completion time. The amount of time before a constraint binds.</p><p>Slack the app was likely named in reference to a promise of Slack in the project sense.</p><p>Slacks as trousers are pants that are actual pants, but do not bind or constrain.</p><p>Slackness refers to vulgarity in West Indian culture, behavior and music. It also refers to a subgenre of dancehall music with straightforward sexual lyrics. Again, slackness refers to the absence of a binding constraint. In this case, common decency or politeness.</p><p>A slacker is one who has a lazy work ethic or otherwise does not exert maximum effort. They <em>slack off</em>. They refuse to be bound by what others view as hard constraints.</p><h2><strong>Out to Get You and the Attack on Slack</strong></h2><p>Many things in this world are <a href=\"https://thezvi.wordpress.com/2017/09/23/out-to-get-you/\">Out to Get You</a>. Often they are <a href=\"https://thezvi.wordpress.com/2017/09/23/out-to-get-you/\">Out to Get You</a> for a lot, usually but not always your time, attention and money.</p><p>If you Get Got for compact amounts too often, it will add up and the constraints will bind.</p><p>If you Get Got <em>even once</em> for a non-compact amount, the cost expands until the you have no Slack left. The constraints bind you.</p><p>You might spend every spare minute and/or dollar on politics, advocacy or charity. You might think of every dollar as a fraction of a third-world life saved. Racing to find a cure for your daughter’s cancer, <a href=\"https://www.youtube.com/watch?v=UYBx7yxEME4\">you already work around the clock</a>. You could have an all-consuming job or be a soldier marching off to war. It could be a quest for revenge, for glory, for love. Or you might spend every spare minute mindlessly <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook-comparison-to-alternatives-and-call-to-action/\">checking Facebook</a> or obsessed with your fantasy football league.</p><p>You cannot relax. Your life is not your own.</p><p>It might even be the right choice! Especially for brief periods. When about to be run over by a truck or evicted from your house, Slack is a luxury you cannot afford. Extraordinary times call for <a href=\"http://lesswrong.com/lw/uo/make_an_extraordinary_effort/\">extraordinary effort</a>.</p><p>Most times are ordinary. Make an ordinary effort.</p><h2><strong>You Can Afford It</strong></h2><p>No, you can’t. This is the most famous attack on Slack. Few words make me angrier.</p><p>The person who says “You Can Afford It” is saying to ignore constraints that do not bind you. If you do, all constraints soon bind you.</p><p>Those who do not value Slack soon lose it. Slack matters. Fight to keep yours!</p><p>Ask not whether you can afford it. Ask if it is Worth It.</p><p>Unless you can’t afford it. Affordability is invaluable <em>negative</em> selection. Never <em>positive</em> selection.</p><p>The You Can Afford It tax on Slack quickly approaches 100% if unchecked.</p><p>If those with extra resources are asked to share the whole surplus, all are poor or hide their wealth. Wealth is a burden and makes you a target. Those visibly flush rush to spend their bounty.</p><p>Where those with free time are given extra work, all are busy or look busy. Those with copious free time seek out relatively painless time sinks they can point to.</p><p>When looking happy means you deal with everything unpleasant, no one looks happy for long.</p><h2><strong>The Slackless Like of Maya Millennial</strong></h2><p>Things are bad enough when those with Slack are expected to sacrifice for others. Things are much worse when the presence of Slack is viewed as a defection.</p><p>An example of this effect is <a href=\"https://thezvi.wordpress.com/2017/09/05/expanding-premium-mediocrity/\">Maya Millennial</a> (of <a href=\"https://www.ribbonfarm.com/2017/08/17/the-premium-mediocre-life-of-maya-millennial/\">The Premium Mediocre Life of Maya Millennial</a>). She has no Slack.</p><p>Constraints bind her every action. Her job in life is putting up a front of the person she wants to show people that she wants to be. If her constraints noticeably failed to bind the illusion would fail.</p><p>Every action is being watched. If no one is around to watch her, the job falls to her. She must post all to Facebook, to Snapchat, to Instagram. Each action and choice signals who she is and her loyalty to the system. Not doing that this time could mean missing her one chance to make it big.</p><p>Maya never has free time. There is signaling to do! At a minimum, she must spend such time on alert and on her phone lest she miss something.</p><p>Maya never has spare cash. All must be spent to advance and fit her profile.</p><p>Maya lacks free speech, free association, free taste and free thought. All must serve.</p><p>Maya is in a world where <em>she must signal she has no Slack</em>. Slack means insufficient dedication and loyalty. Slack cannot be trusted. Slack now means slack later, which means failure. Future failure means no opportunity.</p><p>This is more common than one might think.</p><h2><strong><a href=\"https://en.wikiquote.org/wiki/J._R._%22Bob%22_Dobbs\">“Give Me Slack or Kill Me” – J.R. “Bob” Dobbs</a></strong></h2><p>The aim of this post was to introduce Slack and give an intuitive picture of its importance.</p><p>The short-term practical takeaways are:</p><p>Make sure that under normal conditions <em>you</em> have Slack. Value it. Guard it. Spend it only when Worth It. If you lose it, fight to get it back. This provides motivation for fighting things <a href=\"https://thezvi.wordpress.com/2017/09/23/out-to-get-you/\">Out To Get You</a>, lest you let them eat your Slack.</p><p>Make sure to run a diagnostic test every so often to make sure you’re not running dangerously low, and to engineer your situation to force yourself to have Slack. I recommend <a href=\"http://benjaminrosshoffman.com/sabbath-hard-and-go-home\">Sabbath Hard and Go Home</a> with my take to follow soon.</p><p>Also respect the Slack of others. Help them value and guard it. Do not spend it lightly.</p><h2><strong>A Final Note</strong></h2><p>I kept this short rather than add detailed justifications. Hopefully the logic is intuitive and builds on what came before. I hope to expand on the details and models later. For a very good book-length explanation of why lacking Slack is awful, see <a href=\"https://smile.amazon.com/Scarcity-Having-Little-Means-Much-ebook/dp/B00BMKOO6S/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1506174951&amp;sr=1-1&amp;keywords=scarcity\">Scarcity: Why Having Too Little Means So Much</a>.</p>",
    "user": {
      "username": "Zvi",
      "slug": "zvi",
      "displayName": "Zvi"
    }
  },
  {
    "_id": "EBYpZcv6kmr4JbqCL",
    "title": "Event: Effective Altruism Global X Berlin 2017",
    "slug": "event-effective-altruism-global-x-berlin-2017",
    "pageUrl": "https://www.lesswrong.com/posts/EBYpZcv6kmr4JbqCL/event-effective-altruism-global-x-berlin-2017",
    "postedAt": "2017-09-30T07:33:16.866Z",
    "baseScore": 4,
    "voteCount": 3,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>This year's EAGxBerlin takes place on the 14th and 15th of October at the Berlin Institute of Technology and is organized by the&nbsp;<a href=\"https://ea-foundation.org/\" target=\"_self\">Effective Altruism Foundation</a>. The conference will convene roughly 300 people &ndash; academics, professionals, and students alike &ndash; to explore the most effective and evidence-based ways to improve the world, based on the philosophy and global movement of effective altruism.</p>\n<p>For more information, please see our <a href=\"https://ea-foundation.org/blog/eagxberlin-2017/\" target=\"_self\">website</a> and <a href=\"https://www.facebook.com/events/141481809781333/\" target=\"_self\">facebook</a> event. Tickets are available on <a href=\"https://ti.to/effective-altruism-foundation/eagxberlin-2017\" target=\"_self\">Tito</a>.</p>",
    "user": {
      "username": "Lachouette",
      "slug": "lachouette",
      "displayName": "Lachouette"
    }
  },
  {
    "_id": "rWnCXouKEsJfBcMmA",
    "title": "Positive Focusing",
    "slug": "positive-focusing",
    "pageUrl": "https://www.lesswrong.com/posts/rWnCXouKEsJfBcMmA/positive-focusing",
    "postedAt": "2017-09-30T03:00:23.109Z",
    "baseScore": 30,
    "voteCount": 18,
    "commentCount": 3,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Gendlin’s technique of Focusing primarily focuses (hehe) on problems or negative felt senses. Something I have not seen discussed much is that one can apply the concepts of Focusing to many different felt senses that are not problems, or even negative in any way.\r</p><p>At least in my experience, you can equally investigate good feelings with Focusing as you can problems. And, much as Focusing on a problem improves your understanding of that problem, Focusing on a positive felt sense can improve your understanding of what makes you feel good. By repeatedly investigating feeling good in this way, I think it makes it much easier to piece together an accurate picture of what really makes you happy. \r</p><p>\r</p><p>The idea of positive Focusing may be unclear, so I’ll try to describe how one might go about it, although it is very similar to standard Focusing. \r</p><p>Upon noticing, “Hey, I feel amazing right now,” take a moment to feel that sense in your body. Where do you feel amazing? Is it a sort of warm glow in your stomach and chest? Is it a prickling of excited jubilation along your skin? This is finding the “handle” of the feeling.\r</p><p> Once you have found the feeling stay with it and ask “what is this amazing feeling all about?” And then, here is the critical part, do not answer. At least not with an analytical response. Make that part of your mind stay quiet, or if you cannot quite do that, at least ignore its suggestions, regardless of how correct they seem.\r</p><p>Just feel the sense of this amazingness and try to allow images, words, phrases, or sensations to come from the feeling. Some word or sense will arise from the feeling, and your understanding will shift. Maybe from the felt sense of amazing, you find the word “whole”. Try to check the word against the feeling, to see if it feels right. If it does, but the sense still feels unclear, or feels as though it has shifted to something slightly different, trying asking again. What is it about this feeling that is wholeness? Maybe you see a flash of the people you have been talking to all day. Reflect that image against the feeling, is that right? \r</p><p>You might learn you take more joy in social interaction than you previously thought, you just had never found the right dynamic before.\r</p><p>This connection may seem obvious, as though one could clearly have figured this out just with normal reasoning. And absolutely one could, however, people have very strong self-images. And if one’s self image is that they are “a lone wolf type” they may not notice this data point to the contrary unless they Focus on their good feelings. \r</p><p>To give a personal example that further illustrates the point, I used to think of myself as someone who was very spontaneous and did not like to plan or organize things any more or any sooner than absolutely necessary. I thought that was just the kind of person I am and getting overly organized would just feel wrong. \r</p><p>But I felt a lot of aberrant bouts of anxiety. I probably could have figured out the problem through standard Focusing but I was having trouble with the negative feeling. And I found it easier to focus on positive feelings, so I began to apply Focusing to when I felt happy. And a common trend that emerged from good felt senses was a feeling of being in control of my life. And it turned out that this feeling of being in control came from having planned to do something I wanted to do and having done it.  I would not have noticed that experiences of having planned well made me feel so good through normal analysis because that was just completely contrary to my self-image. But by Focusing on what made me have good feelings, I was able to shift my self-image to be more accurate. I like having detailed plans. Who would have thought? Certainly not me.\r</p><p>Once I realized that my self-image of enjoying disorganization was actually the opposite of what actually made me happy I was able to begin methodically organizing and scheduling my life. Since then, those unexplained bouts of anxiety have vanished and I feel happier more of the time. \r</p><p>It is generally easier for me to Focus in this way and it may be easier for others as well, so I thought it might be useful to bring up. I think it is likely to be less effective in solving specific problems, but more useful in some cases for changing an incorrect or self-defeating self-image. Has anyone tried anything similar? Does it work for you?\r</p><p></p></div></div></div></div>",
    "user": {
      "username": "Rossin",
      "slug": "rossin",
      "displayName": "Rossin"
    }
  },
  {
    "_id": "z36E4EdMDB4BorqTk",
    "title": "Extensive and Reflexive Personhood Definition",
    "slug": "extensive-and-reflexive-personhood-definition",
    "pageUrl": "https://www.lesswrong.com/posts/z36E4EdMDB4BorqTk/extensive-and-reflexive-personhood-definition",
    "postedAt": "2017-09-29T21:50:35.324Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><em>Epistemic status: Speculative idea</em></p><p></p><p>It is highly likely that making a friendly AI somehow requires a good definition of what is a morally significant person. The optimal solution may be to figure out what consciousness is, and point to that. But just in case that turns out to be impossible and/or ill defined, we should look at other options too.</p><p>In this post I will explore using an extensional definition for this task. Extensional definition is to define a concept by pointing at examples, rather than to describe it in terms of other concepts [1].</p><p>Some reasons to be optimistic about using extensional definition for personhood and other important moral concepts:</p><ul><li><p>This is more or less just (semi) supervised learning, which means we can take advantage of the progress in this field.</p></li><li><p>You can teach “I don’t know how to define it, but I know it when I see it” type of information. This means we do not already have know exactly what should be considered a person, at the launch of the AI. We can make it up as we go along and include more and more types of objects in the training data over time.</p></li><li><p>The information is not tied to a specific ontology [2].</p></li></ul><p>The main obstacle with extensional definition is that there is no way of making it complete. Therefore, the AI must keep learning forever. Therefore, we need a never ending pool of training data. </p><p style=\"text-align:center;\">* * *</p><p>Here is my naive suggestion for person detection system, in the context of how it connects to friendliness [3]:</p><p><strong>Hardcoded into the AI:</strong></p><ul><li><p>The concept of “person” as a process, which as some level of the map, can and should be modeled as an agent with beliefs and preferences [4].</p></li><li><p>The belief that persons are better than random at detecting other persons.</p></li><li><p>The AI’s goal is to optimise [5] for the aggregation [6] of the preferences [7] of all persons.</p></li></ul><p><strong>Give the AI some sort of initial person detector to get it started, e.g. :</strong></p><ul><li><p>Program that recognize human faces.</p></li><li><p>A specific person that can be queried.</p></li></ul><p>The idea is that the AI can acquire more training data of what is a person by asking known persons for their beliefs. Since the AI tries to optimise for all persons preferences, it is motivated to learn who else is a person.</p><p>To begin with the AI is supposed to learn that humans are persons. But over time the category can expand to include more things (e.g. aliens, ems, non human animals [8]). The AI will consider you a person if most previous persons consider you a person. This inclusion mechanism is not perfect. For example, we humans has been embarrassingly slow to conclude that all humans are persons. However, we do seem to get there eventually, and I can’t think of any other inclusion method that has enough flexibility.</p><p>However, this naive construction for defining personhood is not safe, even if all dependences [3, 5, 6, 7] are solved.</p><p>In general, agents already identified as persons, will not agree on who else is a person. This might lead the AI to favour a perverse but more stable to the “who is a agent”-problem. E.g. concluding the persons refers only to the member of a small cult, who strongly believes that they and only they are real people.</p><p>It becomes even worse if we consider persons actively trying to hack the system. E.g. creating lots of simple computer programs that all agree with me and then convince the AI that they are all persons. </p><p style=\"text-align:center;\">* * *</p><p>[1] <a href=\" http://lesswrong.com/lw/nh/extensions_and_intensions/\">Extensions and Intensions</a></p><p>[2] I plan go deeper into this in another post.</p><p>[3] Assuming robust AGI.</p><p>[4] Note that not everything that can modeled as an agent with beliefs and preferences is a person. But everything that is a person is assumed to have this structure at som level.</p><p>[5] I am skipping over the problem of how to line up the state of the world with persons preferences, rather than lining up persons preferences with the state of the world. Part of me believes that this is easily solved by separating preference learning and preference optimisation in the AI. Another part of me believes that this is a really hard problem which we can not even begin to work on until we have a better understanding of preferences [7] are.</p><p>[6] I have not yet found a method for aggregating that I like, but I think that this problem can be separated out from this discussion.</p><p>[7] The word “preference” is hiding so much complexity and confusion that I don’t even know if it is a good concept when applied to humans (see: <a href=\"https://www.lesserwrong.com/posts/JXJPzE9tbSsX7CbzQ/call-for-cognitive-science-in-ai-safety\">Call for cognitive science in AI safety</a>). Feel free to interpret “preference” as a placeholder for that thing in a person which is relevant for the AI’s decision.</p><p>[8] Note that caring about the wellbeing of X is different from considering them persons, in this formulation. If enough persons care about X, then the AI will pick up this preference, even if X is not a person.</p><p></p></div></div></div></div>",
    "user": {
      "username": "Linda Linsefors",
      "slug": "linda-linsefors",
      "displayName": "Linda Linsefors"
    }
  },
  {
    "_id": "JXJPzE9tbSsX7CbzQ",
    "title": "Call for cognitive science in AI safety",
    "slug": "call-for-cognitive-science-in-ai-safety",
    "pageUrl": "https://www.lesswrong.com/posts/JXJPzE9tbSsX7CbzQ/call-for-cognitive-science-in-ai-safety",
    "postedAt": "2017-09-29T20:35:16.738Z",
    "baseScore": 6,
    "voteCount": 10,
    "commentCount": 12,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><em>Epistemic status: High expected utility, but also very high variance</em></p><p></p><p>The more I realise that AI take off is something that actually might happen, the more I am pulled towards this problem: </p><ul><li><p>What are human preferences really? </p></li><li><p>What is the generator of human preferences?</p></li><li><p>What are our preferences made of?</p></li><li><p>What is the structure behind it all?</p></li></ul><p>Before we tell our brand new AI overlord to figure out our values and do whatever we want it to do, we really ought to have a clearer idea of what “values” and “want” means.</p><p>I have a good idea of what my preferences are within the limited reach of my lived experience, and even a little bit beyond that. But to extrapolate from that into the vast distance of possible futures seems extremely dangerous. </p><p>My values are inconsistent and conflicting and definitely not constant over time. On top of that, there are the big heap of unknown unknowns with respect to how the brain works.</p><p>I am convinced that to solve AI safety we need to have a good understanding of human values, and I know I don’t have this understanding. I am just a physics and math nerd. I don’t know this stuff. I don’t know if the questions I have are open research questions, or if this stuff is already well known and understood in some separate community somewhere. That is why we need psychology nerds to join the cause.</p><p>Another topic that I would want AI safety orientated psychology research to do, is something like a case study of friendliness in existing agents (humans, subsystems in the brain, organisations). What are the mechanisms in the human brain that make us care about others, and can that be replicated? </p><p style=\"text-align:center;\">*  *  *</p><p>A problem I see is that only math and computer nerds are called upon to work on AI safety, and all the psychology nerds out there do not even know that they are needed. Or maybe the psychology research that I am looking for is already out there and we just need to find each other to collaborate more.</p><p>I think that it is important that technical AI safety research does not try to set the agenda for psychology AI safety research. Information and inspirations needs to flow both ways. Both fields need to be free to follow their own curiosity, but we also need to collaborate to ground our work in each other&#x27;s knowledge. </p><p style=\"text-align:center;\">* * *</p><p>Linda Linsefors</p><p><strong>Cosigning: </strong></p><p>Alexander Appel</p><p>Holden Lee</p><p>somnulence logencia</p><p></p></div></div></div></div>",
    "user": {
      "username": "Linda Linsefors",
      "slug": "linda-linsefors",
      "displayName": "Linda Linsefors"
    }
  },
  {
    "_id": "WXBBRJzAbvjcf4KPL",
    "title": "Productive Disagreement Practice Thread: Meta and Planning",
    "slug": "productive-disagreement-practice-thread-meta-and-planning",
    "pageUrl": "https://www.lesswrong.com/posts/WXBBRJzAbvjcf4KPL/productive-disagreement-practice-thread-meta-and-planning",
    "postedAt": "2017-09-29T16:55:57.492Z",
    "baseScore": 7,
    "voteCount": 7,
    "commentCount": 8,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>I floated the idea of a thread for practicing productive disagreement techniques on <a href=\"https://www.lesserwrong.com/posts/T3nb24aZf7d5S2Lnm/musings-on-double-crux-and-productive-disagreement\">this Double Crux post</a> and was modestly upvoted, so I&#x27;d like to try it. But first, I&#x27;m going to explain the format I have in mind and see if anyone has objections/improvements.</p><h3>Proposed Disagreement Thread Rules (Discuss these, don&#x27;t follow them yet)</h3><ul><li><p>Discussions are to be one-on-one.</p></li><li><p>The default platform for discussions will be the comment thread, but participants can use others at their discretion, such as instant messaging platforms or maybe even video chat. Try to keep a shareable record so others can potentially learn from it.</p><ul><li><p>It seems useful to have default options for these. Preferably anonymous and zero-setup. <a href=\"deadsimplechat.com\">deadsimplechat.com</a> looks reasonable for this. </p></li></ul></li><li><p>To participate in the thread, either </p><ul><li><p>make a top-level comment listing beliefs that you think might generate productive disagreements, as well as any preferences you have about discussion format, </p></li><li><p>or reply to someone else&#x27;s top-level comment, selecting one of their beliefs that you disagree with. Don&#x27;t make any arguments in this reply, just say which belief you&#x27;re selecting, and what platform you&#x27;d like to discuss it on if the top-level commenter gave multiple options.</p></li></ul></li><li><p>The top-level poster and the replier then conduct their discussion in replies to that reply, or in the agreed-upon outside platform.</p></li></ul><ul><li><p>Inflammatory topics are better discussed out-of-band. When listing a topic you think likely to be inflammatory, flag it as such and don&#x27;t offer in-comments discussion as an option.</p></li><li><p>If this becomes a recurring thread, different techniques might be highlighted in different iterations, but for the first one participants should try to use the double crux technique.</p></li></ul></div></div></div></div>",
    "user": {
      "username": "SilentCal",
      "slug": "silentcal",
      "displayName": "SilentCal"
    }
  },
  {
    "_id": "59rvzXPjAMFkFHXoe",
    "title": "Happiness Is Not A Coherent Concept",
    "slug": "happiness-is-not-a-coherent-concept",
    "pageUrl": "https://www.lesswrong.com/posts/59rvzXPjAMFkFHXoe/happiness-is-not-a-coherent-concept",
    "postedAt": "2017-09-29T15:48:08.113Z",
    "baseScore": 7,
    "voteCount": 6,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "http://particularvirtue.blogspot.com/2017/08/happiness-is-not-coherent-concept.html",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p></p></div></div></div></div>",
    "user": {
      "username": "spiralingintocontrol",
      "slug": "spiralingintocontrol",
      "displayName": "spiralingintocontrol"
    }
  },
  {
    "_id": "7xGcyB7RNdfDe5vxL",
    "title": "Moderator's Dilemma: The Risks of Partial Intervention",
    "slug": "moderator-s-dilemma-the-risks-of-partial-intervention",
    "pageUrl": "https://www.lesswrong.com/posts/7xGcyB7RNdfDe5vxL/moderator-s-dilemma-the-risks-of-partial-intervention",
    "postedAt": "2017-09-29T01:47:44.665Z",
    "baseScore": 33,
    "voteCount": 30,
    "commentCount": 17,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>If you ever end up moderating a forum, or just becoming deeply involved in the meta section of one like me, it is almost inevitable that you will become involved in disputes over exactly what one is and is not allowed to say on it. You may find these choices can be very difficult as, more often than not, there are no good options. You typically have two choices:</p><p>(Note: This post touches on hot-button issues more than I&apos;d like. I&apos;ll probably come back later and edit it to avoid these)</p><ul><li><strong>Libertarian approach to moderation</strong></li></ul><p>In this approach, you refuse to get involved in particular kinds of disputes. The standard example is that you may refuse to moderate posts based on political opinions so long as the poster is polite and they stick to all the other rules. Or you may decide not to moderate insults and flaming, so long as no-one engages in doxxing. This approach has a major downside in that if you aren&apos;t moderating based on politics, you&apos;ll have to let through posts from white supremacists so long as they are polite and if you aren&apos;t moderating insults, you&apos;ll get a bunch of jerks using the forum. I&apos;m not saying that this approach is flawed, just that this is what is likely to happen.</p><ul><li><strong>Non-libertarian approach to moderation</strong></li></ul><p>In this approach, you concede a need to at least occasionally intervene in a particular kind of dispute such as banning the white supremacists or deleting comments that contain racial slurs. It is really, really good to be able to do this. On the other hand, once you intervene in a particular manner, you create  the expectation of intervention. Suppose you&apos;ve banned the white supremacists, but since people expect you to be consistent you end up extending the ban other hateful ideologies too. Quite quickly, you&apos;ll find yourself being forced to render a verdict on a whole host of ideologies, not just the clear cut examples. Before you intervened you could refuse take pick sides in certain disputes, but once you&apos;ve intervened your decision not to intervene in another situation will be taken to mean that you don&apos;t consider a particular ideology hateful. If this is a contentious issue, then people will be unhappy no matter how you decide; often you would much prefer to not have to make a ruling on this issue. Again, I&apos;m not saying that this approach is flawed, just that if you choose it, you will most likely run into this issue.</p><p><strong><em>Broader</em> principle</strong></p><p>Even if you don&apos;t moderate a forum, you will see this dilemma crop up in many other situations.</p><ul><li>Suppose you are in charge of a company that is deciding whether or not to have a policy on what its employees post on social media. If you don&apos;t have such a policy, they may say horrible things that are offensive and destroy your company&apos;s reputation. If you do have such as policy and you choose not to fire someone over something they post, it will be seen as you believing that it is not hateful. So you may actually end up with a worse reputation than if you didn&apos;t have a policy at all.</li><li>Suppose that you on a government panel that is deciding the extent to which you should regulate the safety of toys. You might decide to take a minimal regulatory approach and only ban the most unsafe toys. This would allow to protect a number of people from harm, but you&apos;ve now also created the expectation that any toy not banned must be safe. You could try writing the opposite on your website or try spending some of your minimal marketing budget informing people, but realistically most people will make this assumption regardless of what you do. You might even end up increasing the total number of injuries by luring consumers into a false sense of security.</li><li>Suppose you write up a set of rules for your club. This makes it easier to ensure that everyone is aware of them. However, in the absence of any written rules the expectation is that you should use your common sense. When these rules are written down, people will start to assume that if something isn&apos;t in the rules, it must be allowed, particularly if it would have been easy to put it in the rules if they had wanted to. So you may actually find that more people end up doing the things that you don&apos;t want.</li><li>During Coronavirus, some governments have made restrictions like banning gatherings of 100 people or more. This has been taken by people as meaning that it&apos;s okay run gatherings with 99 people.</li></ul><p>This is scary. In many of these cases, it seems incredibly obvious those in power should at least, even if they do nothing else, regulate the worst cases.  But quite quickly we see that this isn&apos;t as obvious as it sounds.</p><p>The mechanism in the Moderator&apos;s Dilemma is that refusing to ban a particular action is seen as either implicitly endorsing it, or at least claiming that it is &quot;not bad&quot;. If this isn&apos;t the case, then you don&apos;t run into the Moderator&apos;s Dilemma. For example, you may be able to avoid the Moderator&apos;s Dilemma if you have a &quot;Historical Schelling Point&quot;. For example, if you ban racial slurs there may be disputes over what counts as a slur, but because there is precedent of treating these differently from other things that are offensive, you may be able avoid having to adjudicate a flamewars where no slurs occur.</p><p><strong>Relationship to Other terms</strong></p><p>This is related to a few other terms:</p><ul><li><strong>Precedent</strong> is a term most associated with legal contexts. Courts try to keep the law consistent so that people can follow it, so once one court rules one way, other courts will tend to rule in a manner consistent with this. However, while Precedent is primarily about consistency and only secondarily about how the rules might later expand, the Moderator&apos;s Dilemma is primarily about expansion, but also more about being forced to issue a ruling than about the outcomes.</li><li><strong>Slippery Slopes</strong> are an argument that is often claimed to be a logical fallacy, but which is only poor reasoning if you fail to justify why we are likely to inevitably progress along the slope. The Moderator&apos;s Dilemma is a kind of slippery slope, but while the focus of the Slippery Slope is the endpoint and how bad it is, the Moderator&apos;s Dilemma is more about being forced to issue a ruling when you don&apos;t want to.</li></ul><p><strong>Conclusion</strong></p><p>I believe that <a href=\"https://www.lesserwrong.com/posts/AAFZPvFXNBTdYToH3/terminology-is-important\">Terminology is Important</a> and so the purpose of this article was to describe a particular situation that I have seen in multiple contexts, but which I did not already have a name for. Group rationality is hard because you can&apos;t just look at the immediate effects, but all of the effects that might occur downstream. This is a small attempt to grapple with these problems by identifying one particularly common downstream pattern.</p><p><strong>Note: </strong>Please try to avoid turning the comments section into a debate on the political examples included in this post. I tried to avoid discussing these topics more than necessary, but these were the clearest examples that I could think of.</p>",
    "user": {
      "username": "Chris_Leong",
      "slug": "chris_leong",
      "displayName": "Chris_Leong"
    }
  },
  {
    "_id": "EMhdJFyHcojnJWTWZ",
    "title": "Post Fit Review",
    "slug": "post-fit-review",
    "pageUrl": "https://www.lesswrong.com/posts/EMhdJFyHcojnJWTWZ/post-fit-review",
    "postedAt": "2017-09-28T23:52:31.063Z",
    "baseScore": 5,
    "voteCount": 3,
    "commentCount": 9,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>My idea here is to have a post where we can discuss thoughts on how well particular posts fit LW without cluttering the post&#x27;s own comments. StackExchange sites do something similar where reviewers will sometimes post in meta to discuss posts they were unsure if they should perform moderation on, although the focus here is really meant to be on fit (but maybe we&#x27;ll want to expand the notion later).</p><p>Format for comment threads here is:</p><ol><li><p>Top level comment is link to post.</p></li><li><p>Comments are thoughts on if the post fits LW or not.</p></li></ol></div></div></div></div>",
    "user": {
      "username": "gworley",
      "slug": "gordon-seidoh-worley",
      "displayName": "Gordon Seidoh Worley"
    }
  },
  {
    "_id": "iMrfccjKSKTYdra46",
    "title": "For independent researchers?",
    "slug": "for-independent-researchers",
    "pageUrl": "https://www.lesswrong.com/posts/iMrfccjKSKTYdra46/for-independent-researchers",
    "postedAt": "2017-09-28T20:56:07.389Z",
    "baseScore": 2,
    "voteCount": 2,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>I sometimes think about becoming part of the more mainstream AI safety community. Most recently this was triggered by thinking about taking part in 80K mentoring.<br/><br/>However I am partially put off by worrying about how that changes my incentives. Would I be less able to follow my own path and be funneled down the path of thinking about whatever was flavour de jour. Would I be less likely to criticise institutions approaches to AI safety if I had to worry about antagonising people and not getting funding?</p><p>So I continue to work part time but be my own master. I miss out on the community somewhat, but I think I need the freedom to go where my questioning takes me. </p><p></p></div></div></div></div>",
    "user": null
  },
  {
    "_id": "jNxNBqggcbTCdapmB",
    "title": "Uncertainty in Deep Learning",
    "slug": "uncertainty-in-deep-learning",
    "pageUrl": "https://www.lesswrong.com/posts/jNxNBqggcbTCdapmB/uncertainty-in-deep-learning",
    "postedAt": "2017-09-28T18:53:51.498Z",
    "baseScore": 3,
    "voteCount": 0,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": "http://mlg.eng.cam.ac.uk/yarin/blog_2248.html",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><a href=\"http://mlg.eng.cam.ac.uk/yarin/blog_2248.html\">Here</a> is a PhD thesis I just got linked at work. I&#x27;m about halfway through the first chapter and it&#x27;s starting a discussion of practical near term AI safety.</p><p>Edit: I think linkposts are mildly broken?</p></div></div></div></div>",
    "user": {
      "username": "magfrump",
      "slug": "magfrump",
      "displayName": "magfrump"
    }
  },
  {
    "_id": "irBvvaAGTfqRoegLz",
    "title": "The Virtue of Numbering ALL your Equations",
    "slug": "the-virtue-of-numbering-all-your-equations",
    "pageUrl": "https://www.lesswrong.com/posts/irBvvaAGTfqRoegLz/the-virtue-of-numbering-all-your-equations",
    "postedAt": "2017-09-28T18:41:35.631Z",
    "baseScore": 7,
    "voteCount": 14,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><em>Epistemic status: This is my strongly hold preference, but I dont know to what extent others agree.</em></p><p></p><p>I know of two common styles for numbering equations in a scientific publications.</p><p>    A)<strong> </strong>Number ALL equations.</p><p>    B) Number only those equations that you yourself want to reference to in the surrounding text.</p><p><strong>A is strictly better than B</strong></p><ul><li><p>There is no extra effort to in numbering all equations since LaTeX does it for you. </p></li><li><p>It becomes much easier to discuss your paper in text and/or online, and in any other situation where the persons involved can’t just point directly at the equation they wants to refeer to.</p></li></ul><p></p><p>LaTeX automatically number your equations if you use </p><pre style=\"overflow:scroll;\"><code>\\begin{equation} … \\end{equation}</code></pre><p>LaTeX does <strong>not</strong> automatically number your equation if you use</p><pre style=\"overflow:scroll;\"><code>$$ … $$</code></pre><p>Here is a bit of code you can use if you think “\\begin{equation} … \\end{equation}” Is too much to write. Copy paste this</p><pre style=\"overflow:scroll;\"><code>\\newcommand{\\be}{\\begin{equation}}<br/>\\newcommand{\\ee}{\\end{equation}}</code></pre><p>into your tex document, before “\\begin{document}”. Now you can simply use </p><pre style=\"overflow:scroll;\"><code>\\be … \\ee</code></pre><p>instead of “\\begin{equation} … \\end{equation}”</p><p></p><p><strong>Please number </strong><u><strong>all</strong></u><strong> your equations!</strong></p><p></p><p></p></div></div></div></div>",
    "user": {
      "username": "Linda Linsefors",
      "slug": "linda-linsefors",
      "displayName": "Linda Linsefors"
    }
  },
  {
    "_id": "AmaWMMWPzuQ62Ernf",
    "title": "Against Individual IQ Worries",
    "slug": "against-individual-iq-worries",
    "pageUrl": "https://www.lesswrong.com/posts/AmaWMMWPzuQ62Ernf/against-individual-iq-worries",
    "postedAt": "2017-09-28T17:12:19.553Z",
    "baseScore": 74,
    "voteCount": 56,
    "commentCount": 8,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><em>[Related to: <a href=\"http://slatestarcodex.com/2015/02/01/talents-part-2-attitude-vs-altitude/\">Attitude vs. Altitude</a>]</em></p><p>I.</p><h4>I write a lot about the importance of IQ research, and I try to debunk pseudoscientific claims that IQ “isn’t real” or “doesn’t matter” or “just shows how well you do on a test”. IQ is one of the best-studied ideas in psychology, one of our best predictors of job performance, future income, and various other forms of success, etc.</h4><p>But every so often, I get comments/emails saying something like “Help! I just took an IQ test and learned that my IQ is x! This is much lower than I thought, and so obviously I will be a failure in everything I do in life. Can you direct me to the best cliff to jump off of?”</p><p>So I want to clarify: IQ is very useful and powerful for research purposes. It’s not nearly as interesting <em>for you personally</em>.</p><p>How can this be?</p><p>Consider something like income inequality: kids from rich families are at an advantage in life; kids from poor families are at a disadvantage.</p><p>From a <em>research</em> point of view, it’s really important to understand this is true. A scientific establishment in denial that having wealthy parents gave you a leg up in life would be an intellectual disgrace. Knowing that wealth runs in families is vital for even a minimal understanding of society, and anybody forced to deny that for political reasons would end up so hopelessly confused that they might as well just give up on having a coherent world-view.</p><p>From an personal point of view, coming from a poor family probably isn’t great <em>but shouldn’t be infinitely discouraging</em>. It doesn’t suggest that some kid should think to herself “I come from a family that only makes $30,000 per year, guess that means I’m doomed to be a failure forever, might as well not even try”. A poor kid is certainly at a disadvantage relative to a rich kid, but probably she knew that already long before any scientist came around to tell her. If she took the scientific study of intergenerational income transmission as something more official and final than her general sense that life was hard – if she obsessively recorded every raise and bonus her parents got on the grounds that it determined her own hope for the future – she would be giving the science more weight than it deserves.</p><p>So to the people who write me heartfelt letters complaining about their low IQs, I want to make two important points. First, we’re not that good at measuring individual IQs. Second, individual IQs aren’t that good at predicting things.</p><p>II.</p><h4>Start with the measurement problems. People who complain about low IQs (not to mention people who boast about high IQs) are often wildly off about the number.</h4><p>According to the official studies, IQ tests are rarely wrong. The standard error of measurement is somewhere between 3-7 points (<a href=\"http://www.iapsych.com/iapap101/iapap1015.pdf\">1</a>, <a href=\"http://eprints.hud.ac.uk/id/eprint/7044/2/WhitakerError.pdf\">2</a>, <a href=\"https://books.google.com/books?id=IUElDwAAQBAJ&pg=PA198&lpg=PA198&dq=SEM+IQ&source=bl&ots=4nrHkNOJ6e&sig=hYky4WaBaifAxBhCYGpP0Mf6iGE&hl=en&sa=X&ved=0ahUKEwjQ1Ynvhb3WAhXqy1QKHXFRCM0Q6AEITDAI#v=onepage&q=SEM%20IQ&f=false\">3</a>). Call it 5, and that means your tested IQ will only be off by 5+ points 32% of the time. It’ll only be off by 10+ points 5% of the time, and really big errors should be near impossible.</p><p>In reality, I constantly hear about people getting IQ scores that don’t make any sense.</p><p>Here’s a pretty standard entry in the “help my IQ is so low” genre – <a href=\"https://www.reddit.com/r/JordanPeterson/comments/70lkn5/grappling_with_the_reality_of_having_a/\">Grappling With The Reality Of Having A Below Average IQ</a>:</p><blockquote>When I was 16, as a part of an educational assessment, I took both the WAIS-IV and Woodcock Johnson Cognitive Batteries. My mother was curious as to why I struggled in certain subjects throughout my educational career, particularly in mathematical areas like geometry.</blockquote><blockquote>I never got a chance to have a discussion with the psychologist about the results, so I was left to interpret them with me, myself, and the big I known as the Internet – a dangerous activity, I know. This meant two years to date of armchair research, and subsequently, an incessant fear of the implications of my below-average IQ, which stands at a pitiful 94…I still struggle in certain areas of comprehension. I received a score of 1070 on the SAT, (540 Reading &amp; 530 Math), and am barely scraping by in my college algebra class. Honestly, I would be ashamed if any of my coworkers knew I barely could do high school-level algebra.</blockquote><p>This person thinks they’re reinforcing their point by listing two different tests, but actually a 1070 on the SAT corresponds to about 104, a full ten points higher. Based on other things in their post – their correct use of big words and complicated sentence structure, their mention that they work a successful job in cybersecurity, the fact that they read a philosophy/psychology subreddit for fun – I’m guessing the 104 is closer to the truth.</p><p>From the comments on the same Reddit thread:</p><blockquote>Interesting, I hope more people who have an avg. or low IQ post. Personally I had an IQ of 90 or so, but the day of the test I stayed up almost the entire night, slept maybe two hours and as a naive caffeine user I had around 500 mg caffeine. Maybe low IQ people do that.</blockquote><blockquote>I did IQTest.dk Raven’s test on impulse after seeing a video of Peterson’s regarding the importance of IQ, not in a very focused mode, almost ADHD like with rumination and I scored 108, but many claim low scores by around 0.5-1 SD, so that would put me in 115-123. I also am vegan, so creatine might increase my IQ by a few points. I think I am in the 120’s, but low IQ people tend to overestimate their IQ, but at least I am certainly 108 non-verbally, which is pretty average and low.</blockquote><p>The commenter is right that IQtest.dk usually underestimates scores compared to other tests. But even if we take it at face value, his first score was almost twenty points off. By the official numbers, that should only happen once in every 15,000 people. In reality, someone posts a thread about it on Reddit and another person immediately shows up to say “Yeah, that happened to me”.</p><p>Nobel-winning physicist Richard Feynman famously scored “only” 124 on an IQ test in school – still bright, but nowhere near what you would expect of a Nobelist. Some people <a href=\"https://www.psychologytoday.com/blog/finding-the-next-einstein/201112/polymath-physicist-richard-feynmans-low-iq-and-finding-another\">point out</a> that it might have been biased towards measuring verbal rather than math abilities – then again, Feynman’s autobiography (admittedly edited and stitched together by a ghostwriter) sold 500,000 copies and made the New York Times bestseller list. So either his tested IQ was off by at least 30 points (supposed chance of this happening: 1/505 million), or IQ isn’t real and all of the studies showing that it is are made up by lizardmen to confuse us. In either case, you should be less concerned if your own school IQ tests seem kind of low.</p><p>I don’t know why there’s such a discrepancy between the official reliability numbers and the ones that anecdotally make sense. My guess is that the official studies give the tests better somehow. They use professional test administrators instead of overworked school counselors. They give them at a specific time of day instead of while the testee is half-asleep. They don’t let people take a bunch of caffeine before the test. They actually write the result down in a spreadsheet they have right there instead of trusting the testee to remember it accurately.</p><p>In my own field, official studies diagnose psychiatric diseases through beautiful Structured Clinical Interviews performed to exacting guidelines. Then real doctors diagnose them <a href=\"http://slatestarcodex.com/2017/08/29/my-irb-nightmare/\">through checklists that say “DO NOT USE FOR DIAGNOSIS”</a> in big letters on the top. If psychometrics is at all similar, the clashing numbers aren’t much of a mystery.</p><p>But two other points that might also be involved.</p><p>First, on a <em>population level</em> IQ is very stable with age. Over a study of 87,498 Scottish children, age 11 IQ and adult IQ <a href=\"http://www.huffingtonpost.com/scott-barry-kaufman/intelligence-is-still-not_b_1078112.html\">correlated at 0.66</a>, about as strong and impressive a correlation as you’ll ever find in the social sciences. But “correlation of 0.66” is also known as “only predicts 44% of the variance”. <em>On an individual level</em>, it is totally possible and not even that surprising to have an IQ of 100 at age 11 but 120 at age 30, or vice versa. Any IQ score you got before high school should be considered a <em>plausible prediction</em> about your adult IQ and nothing more.</p><p>Second, the people who get low IQ scores, are shocked, find their whole world tumbling in on themselves, and desperately try to hold on to their dream of being an intellectual – are not a representative sample of the people who get low IQ scores. The average person who gets a low IQ score says “Yup, guess that would explain why I’m failing all my classes”, and then goes back to beating up nerds. When you see someone saying “Help, I got a low IQ score, I’ve double-checked the standard deviation of all of my subscores and found some slight discrepancy but I’m not sure if that counts as Bayesian evidence that the global value is erroneous”, then, well – look, I wouldn’t be making fun of these people if I didn’t <em>constantly come across them</em>. You know who you are.</p><p>Just for fun, I analyzed the lowest IQ scores in my collection of SSC/LW surveys. I was only able to find three people who claimed to have an IQ ≤ 100 plus gave SAT results. All three had SAT scores corresponding to IQs in the 120s.</p><p>I conclude that at least among the kind of people I encounter and who tend to send me these emails, IQ estimates are pretty terrible.</p><p>This is absolutely consistent with population averages of thousands of IQ estimates still being valuable and useful research tools. It just means you shouldn’t use it on <em>yourself</em>. Statistics is what tells us that almost everybody feels stimulated on amphetamines. Reality is my patient who consistently goes to sleep every time she takes Adderall. Neither the statistics nor the lived experience are wrong – but if you use one when you need the other, you’re going to have a bad time.</p><p>III.</p><h4>The second problem is that even if you avoid the problems mentioned above and measure IQ 100% correctly, <em>it’s just not that usefully predictive</em>.</h4><p>Isn’t that heresy?! Isn’t IQ the most predictive thing we have? Doesn’t it affect every life outcome as proven again and again in well-replicated experiments?</p><p>Yes! I’m not denying any of that. I’m saying that <em>things that are statistically true aren’t always true for any individual</em>.</p><p>Once again, consider the analogy to family transmission of income. Your parents’ socioeconomic status correlates with your own at about r = 0.2 to 0.3, depending on how you define “socioeconomic status”. By coincidence, this is pretty much the same correlation that <a href=\"http://www.emilkirkegaard.dk/en/wp-content/uploads/Intelligence-and-socioeconomic-success-A-meta-analytic-review-of-longitudinal-research.pdf\">Strenze (2006)</a> found for IQ and socioeconomic status. Everyone knows that having rich parents is pretty useful if you want to succeed. But everyone also knows that rich parents aren’t the only thing that goes into success. Someone from a poor family who tries really hard and gets a lot of other advantages still has a chance to make it. A sociologist or economist should be very interested in parent-child success correlations; the average person trying to get ahead should just shrug, realize things are going to be a little easier/harder than they would have been otherwise, and get on with their life.</p><p>And this isn’t just about gaining success by becoming an athlete or musician or some other less-intellectual pursuit. Chess talent is correlated with IQ <a href=\"https://www.researchgate.net/publication/307874653_The_relationship_between_cognitive_ability_and_chess_skill_A_comprehensive_meta-analysis\">at 0.24</a>, about the same as income. IQ is some complicated central phenomenon that contributes a little to every cognitive skill, but it doesn’t entirely determine any cognitive skill. It’s not just that you can have an average IQ and still be a great chess player if you work hard enough – that’s true, but it’s not <em>just that</em>. It’s that you can have an average IQ and still have <em>high levels of innate talent in chess</em>. It’s not quite as likely as if you have a high IQ, but it’s very much in the range of possibility. And <em>then</em> you add in the effects of working hard enough, and <em>then</em> you’re getting somewhere.</p><p>Here is a table of professions by IQ, a couple of decades out of date but probably not too far off (cf. discussion <a href=\"https://www.reddit.com/r/slatestarcodex/comments/5dgmpm/iq_range_by_occupation_chart_am_i_missing/\">here</a>):</p><p></p><p></p><p>I don’t know how better to demonstrate this idea of “statistically solid, individually shaky”. On a population level, we see that the average doctor is 30 IQ points higher than the average janitor, that college professors are overwhelmingly high-IQ, and we think yeah, this is about what we would hope for from a statistic measuring intelligence. But on an individual level, we see that below-average IQ people sometimes become scientists, professors, engineers, and almost anything else you could hope for.</p><p>IV.</p><h4>I’m kind of annoyed I have to write this post. After investing so much work debunking IQ denialists, I feel like this is really – I don’t know – diluting the brand.</h4><p>But I actually think it’s not as contradictory as it looks, that there’s some common thread between my posts arguing that no, IQ isn’t fake, and this one.</p><p>If you really understand the idea of a statistical predictor – if you <a href=\"http://slatestarcodex.com/2015/11/03/what-developmental-milestones-are-you-missing/\">have that gear in your brain</a> at a fundamental level – then social science isn’t scary. You can read about IQ, or heredity, or stereotypes, or gender differences, or whatever, and you can say – ah, there’s a slight tendency for one thing to correlate with another thing. Then you can go have dinner.</p><p>If you don’t get that, then the world is terrifying. Someone’s said that IQ “correlates with” life outcomes? What the heck is “correlate with”? Did they say that only high-IQ people can be successful? That you’re doomed if you don’t get the right score on a test?</p><p>And then you can either resist that with every breath you have – deny all the data, picket the labs where it’s studied, make up silly theories about “emotional intelligence” and “grit” and what have you. Or you can surrender to the darkness, at least have the comfort of knowing that you accept the grim reality as it is.</p><p>Imagine an American who somehow gets it into his head that the Communists are about to invade with overwhelming force. He might buy a bunch of guns, turn his house into a bunker, start agitating that Communist sympathizers be imprisoned to prevent them from betraying the country when the time came. Or he might hang a red flag from his house, wear a WELCOME COMMUNIST OVERLORDS tshirt, and start learning Russian. These seem like opposite responses, but they both come from the same fundamental misconception. A lot of the culture war – on both sides – seems like this. I don’t know how to solve this except to try, again and again, to install the necessary gear and convince people that correlations are neither meaningless nor always exactly 1.0.</p><p>So please: study the science of IQ. Use IQ to explain and predict social phenomena. Work on figuring out how to raise IQ. Assume that raising IQ will have far-ranging and powerful effects on a wide variety of social problems. Just don’t expect it to predict a single person’s individual achievement with any kind of reliability. Especially not yourself.</p>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  },
  {
    "_id": "gBChm3THPGFcrq5eH",
    "title": "My IRB Nightmare",
    "slug": "my-irb-nightmare",
    "pageUrl": "https://www.lesswrong.com/posts/gBChm3THPGFcrq5eH/my-irb-nightmare",
    "postedAt": "2017-09-28T16:47:54.661Z",
    "baseScore": 60,
    "voteCount": 50,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><font size=\"1\"><i>[Epistemic status: Pieced together from memory years after the event. I may have mis-remembered some things or gotten them in the wrong order. Aside from that &#8211; and the obvious jokes &#8211; this is all true. I&#8217;m being deliberately vague in places because I don&#8217;t want to condemn anything specific without being able to prove anything.]</i></font></p>\n<p><b>September 2014</b></p>\n<p>There&#8217;s a screening test for bipolar disorder. You ask patients a bunch of things like &#8220;Do you ever feel really happy, then really sad?&#8221;. If they say &#8216;yes&#8217; to enough of these questions, you start to worry.</p>\n<p>Some psychiatrists love this test. I hate it. Patients will say &#8220;Yes, that absolutely describes me!&#8221; and someone will diagnose them with bipolar disorder. Then if you ask what they meant, they&#8217;d say something like &#8220;Once my local football team made it to the Super Bowl and I was really happy, but then they lost and I was really sad.&#8221; I don&#8217;t even want to tell you how many people get diagnosed bipolar because of stuff like this.</p>\n<p>There was a study that supposedly proved this test worked. But parts of it confused me, and it was done on a totally different population that didn&#8217;t generalize to hospital inpatients. Also, it said in big letters THIS IS JUST A SCREENING TEST IT IS NOT INTENDED FOR DIAGNOSIS, and everyone was using it for diagnosis.</p>\n<p>So I complained to some sympathetic doctors and professors, and they asked &#8220;Why not do a study?&#8221;</p>\n<p>Why <i>not</i> do a study? Why not join the great tradition of scientists, going back to Galileo and Newton, and make my mark on the world? Why not replace my griping about bipolar screening with an experiment about bipolar screening, an experiment done to the highest standards of the empirical tradition, one that would throw the entire weight of the scientific establishment behind my complaint? I&#8217;d been writing about science for so long, even doing my own informal experiments, why not move on to join the big leagues?</p>\n<p>For (it would turn out) a whole host of excellent reasons that I was about to learn.</p>\n<p>A spring in my step, I journeyed to my hospital&#8217;s Research Department, hidden in a corner office just outside the orthopaedic ward. It was locked, as always. After enough knocking, a lady finally opened the door and motioned for me to sit down at a paperwork-filled desk.</p>\n<p>&#8220;I want to do a study,&#8221; I said.</p>\n<p>She looked skeptical. &#8220;Have you done the Pre-Study Training?&#8221;</p>\n<p>I had to admit I hadn&#8217;t, so off I went. The training was several hours of videos about how the Nazis had done unethical human experiments. Then after World War II, everybody met up and decided to only do ethical human experiments from then on. And the most important part of being ethical was to have all experiments monitored by an Institutional Review Board (IRB) made of important people who could check whether experiments were ethical or not. I dutifully parroted all this back on the post-test (&#8220;Blindly trusting authority to make our ethical decisions for us is the <i>best</i> way to separate ourselves from the Nazis!&#8221;) and received my Study Investigator Certification. </p>\n<p>I went back to the corner office, Study Investigator Certification in hand.</p>\n<p>&#8220;I want to do a study,&#8221; I said.</p>\n<p>The lady still looked skeptical. &#8220;Do you have a Principal Investigator?&#8221;</p>\n<p>Mere resident doctors weren&#8217;t allowed to do studies on their own. They would probably screw up and start building concentration camps or something. They needed an attending (high-ranking doctor) to sign on as Principal Investigator before the IRB would deign to hear their case.</p>\n<p>I knew exactly how to handle this: one by one, I sought out the laziest attendings in the hospital and asked &#8220;Hey, would you like to have your name on a study as Principal Investigator for free while I do all the actual work?&#8221; Yet one by one, all of the doctors refused, as if I was offering them some kind of plague basket full of vermin. It was the weirdest thing.</p>\n<p>Finally, there was only one doctor left &#8211; Dr. W, the hardest-working attending I knew, the one who out of some weird masochistic impulse took on every single project anyone asked of him and micromanaged it to perfection, the one who every psychiatrist in the whole hospital (including himself) had diagnosed with obsessive-compulsive personality disorder.</p>\n<p>&#8220;Sure Scott,&#8221; he told me. &#8220;I&#8217;d be happy to serve as your Principal Investigator&#8221;. </p>\n<p>A feeling of dread in my stomach, I walked back to the tiny corner office.</p>\n<p>&#8220;I want to do a study,&#8221; I said.</p>\n<p>The lady still looked skeptical. &#8220;Have you completed the New Study Application?&#8221; She gestured to one of the stacks of paperwork filling the room.</p>\n<p>It started with a section on my research question. Next was a section on my proposed methodology. A section on possible safety risks. A section on recruitment. A section on consent. A section on&#8230;wow. Surely this can&#8217;t <i>all</i> be the New Study Application? Maybe I accidentally picked up the Found A New Hospital Application?</p>\n<p>I asked the lady who worked in the tiny corner office whether, since I was just going to be asking bipolar people whether they ever felt happy and then sad, maybe I could get the short version of the New Study Application?</p>\n<p>She told me that <i>was</i> the short version.</p>\n<p>&#8220;But it&#8217;s twenty-two pages!&#8221;</p>\n<p>&#8220;You haven&#8217;t done any studies before, have you?&#8221;</p>\n<p>Rather than confess my naivete, I started filling out the twenty-two pages of paperwork. It started by asking about our study design, which was simple: by happy coincidence, I was assigned to Dr. W&#8217;s inpatient team for the next three months. When we got patients, I would give them the bipolar screening exam and record the results. Then Dr. W. would conduct a full clinical interview and formally assess them. We&#8217;d compare notes and see how often the screening test results matched Dr. W&#8217;s expert diagnosis. We usually got about twenty new patients a week; if half of them were willing and able to join our study, we should be able to gather about a hundred data points over the next three months. It was going to be easy-peasy.</p>\n<p>That was the first ten pages or so of the Application. The rest was increasingly bizarre questions such as &#8220;Will any organs be removed from participants during this study?&#8221; (Look, I promise, I&#8217;m not a Nazi). </p>\n<p>And: &#8220;Will prisoners be used in the study?&#8221; (COME ON, I ALREADY SAID I WASN&#8217;T A NAZI). </p>\n<p>And: &#8220;What will you do if a participant dies during this research?&#8221; (If somebody dies while I&#8217;m asking them whether they sometimes feel happy and then sad, I really can&#8217;t even promise so much as &#8220;not freaking out&#8221;, let alone any sort of dignified research procedure). </p>\n<p>And more questions, all along the same lines. I double-dog swore to give everybody really, really good consent forms. I tried my best to write a list of the risks participants were taking upon themselves (mostly getting paper cuts on the consent forms). I argued that these compared favorably to the benefits (maybe doctors will stop giving people strong psychiatric medications just because their football team made the Super Bowl).</p>\n<p>When I was done, I went back to the corner office and submitted everything to the Institutional Review Board. Then I sat back and hoped for the best. Like an idiot.</p>\n<p><b>October 2014</b></p>\n<p>The big day arrived. The IRB debated the merits of my study, examined the risks, and&#8230;sent me a letter pointing out several irregularities in my consent forms.</p>\n<p>IRREGULARITY #1: Consent forms traditionally included the name of the study in big letters where the patient could see it before signing. Mine didn&#8217;t. Why not?</p>\n<p>Well, because in questionnaire-based psychological research, you <i>never</i> tell the patient what you&#8217;re looking for before they fill out the questionnaire. That&#8217;s like Methods 101. The name of my study was &#8220;Validity Of A Screening Instrument For Bipolar Disorder&#8221;. Tell the patient it&#8217;s a study about bipolar disorder, and the gig is up.</p>\n<p>The IRB listened patiently to my explanation, then told me that this was not a legitimate reason not to put the name of the study in big letters on the consent form. Putting the name of the study on the consent form was important. You know who <i>else</i> didn&#8217;t put the name of the study on his consent forms? <i>Hitler.</i></p>\n<p>IRREGULARITY #2: Consent forms traditionally included a paragraph about the possible risks of the study and a justification for why we believed that the benefits were worth the risks. Everyone else included a paragraph about this on our consent forms, and read it to their patients before getting their consent. We didn&#8217;t have one. Why not?</p>\n<p>Well, for one thing, because all we were doing was asking them whether they felt happy and then sad sometimes. This is the sort of thing that goes on every day in a psychiatric hospital. Heck, the other psychiatrists were using this same screening test, except <i>for real</i>, and they never had to worry about whether it had risks. In the grand scheme of things, this just wasn&#8217;t a very risky procedure. </p>\n<p>Also, psychiatric patients are sometimes&#8230;how can I put this nicely?&#8230;a little paranoid. Sometimes you can offer them breakfast and they&#8217;ll accuse you of trying to poison them. I had no illusions that I would get every single patient to consent to this study, but I felt like I could at least avoid handing them a paper saying &#8220;BY THE WAY, THIS STUDY IS FULL OF RISKS&#8221;.</p>\n<p>The IRB listened patiently to my explanation, then told me that this was not a legitimate reason not to have a paragraph about risks. We should figure out some risks, then write a paragraph explaining how those were definitely the risks and we took them very seriously. The other psychiatrists who used this test every day didn&#8217;t have to do that <i>because they weren&#8217;t running a study</i>.</p>\n<p>IRREGULARITY #3: Signatures are traditionally in pen. But we said our patients would sign in pencil. Why?</p>\n<p>Well, because psychiatric patients aren&#8217;t allowed to have pens in case they stab themselves with them. I don&#8217;t get why stabbing yourself with a pencil is any less of a problem, but the rules are the rules. We asked the hospital administration for a one-time exemption, to let our patients have pens just long enough to sign the consent form. Hospital administration said absolutely not, and they didn&#8217;t care if this sabotaged our entire study, it was pencil or nothing.</p>\n<p>The IRB listened patiently to all this, then said that it had to be in pen. You know who <i>else</i> had people sign consent forms in pencil&#8230;?</p>\n<p>I&#8217;m definitely not saying that these were the only three issues the IRB sprung on Dr. W and me. I&#8217;m saying these are a <i>representative sample</i>. I&#8217;m saying I spent several weeks relaying increasingly annoyed emails and memos from myself to Dr. W to the IRB to the lady in the corner office to the IRB again. I began to come home later in the evening. My relationships suffered. I started having dreams about being attacked by giant consent forms filled out in pencil.</p>\n<p>I was about ready to give up at this point, but Dr. W insisted on combing through various regulations and talking to various people, until he discovered some arcane rule that certain very safe studies with practically no risk were allowed to use an &#8220;expedited consent form&#8221;, which was a lot like a normal consent form but didn&#8217;t need to have things like the name of the study on it. Faced with someone even more obsessive and bureaucratic than they were, the IRB backed down and gave us preliminary permission to start our study. </p>\n<p>The next morning, screening questionnaire in hand, I showed up at the hospital and hoped for the best. Like an idiot.</p>\n<p><b>November 2014</b></p>\n<p>Things progressed slowly. It turns out a lot of psychiatric inpatients are either depressed, agitated, violent, or out of touch with reality, and none of these are really conducive to wanting to participate in studies. A few of them already delusionally thought we were doing experiments on them, and got confused when we suddenly asked them to consent. Several of them made it clear that they hated us and wanted to thwart us in any way possible. After a week, I only had three data points, instead of the ten I&#8217;d been banking on.</p>\n<p>&#8220;Data points&#8221; makes it sound abstract. It wasn&#8217;t. I had hoped to put the results in the patients&#8217; easily accessible online chart, <i>the same place everyone else put the results of the exact same bipolar screening test</i> when they did it for real. They would put it in a section marked TEST RESULTS, which was there to have a secure place where you could put test results, and where everybody&#8217;s secure test results were kept.</p>\n<p>The IRB would have none of this. Study data are Confidential and need to be kept Secure. Never mind that all the patients&#8217; <i>other</i> secure test results were on the online chart. Never mind that the online chart contains all sorts of stuff about the patients&#8217; diagnoses, medications, hopes and fears, and even (remember, this is a psych hospital) secret fetishes and sexual perversions. Study data needed to be encrypted, then kept in a Study Binder in a locked drawer in a locked room that nobody except the study investigators had access to.</p>\n<p>The first problem was that nobody wanted to give us a locked room that nobody except us had access to. There was a sort of All Purpose Psychiatry Paperwork room, but the janitors went in to clean it out every so often, and apparently this made it unacceptable. Hospitals aren&#8217;t exactly drowning in spare rooms that not even janitors can get into. Finally Dr. W grudgingly agreed to keep it in his office. This frequently meant I couldn&#8217;t access any of the study material because Dr. W was having important meetings that couldn&#8217;t be interrupted by a resident barging into his office to rummage in his locked cabinets. </p>\n<p>But whatever. The bigger problem was the encryption. There was a very specific way we had to do it. We would have a Results Log, that said things like &#8220;Patient 1 got a score of 11.5 on the test&#8221;. And then we&#8217;d have a Secret Patient Log, which would say things like &#8220;Patient 1 = Bob Johnson from Oakburg.&#8221; That way nobody could steal our results and figure out that Bob was sometimes happy, then sad.</p>\n<p>(meanwhile, all of Bob&#8217;s actual diagnoses, sexual fetishes, etc were in the easily-accessible secure online chart that we were banned from using)</p>\n<p>And then &#8211; I swear this is true &#8211; we had to keep the Results Log and the Secret Patient Log right next to each other in the study binder in the locked drawer in the locked room. </p>\n<p>I wasn&#8217;t sure I was understanding this part right, so I asked Dr. W whether it made sense, to him, that we put a lot of effort writing our results in code, and then put the key to the code in the same place as the enciphered text. He cheerfully agreed this made no sense, but said we had to do it or else our study would fail an audit and get shut down.</p>\n<p><b>January 2015</b></p>\n<p>I&#8217;d planned to get a hundred data points in three months. Thanks to constant bureaucratic hurdles, plus patients being less cooperative than I expected, I had about twenty-five. Now I was finishing my rotation on Dr. W&#8217;s team and going to a clinic far away. What now?</p>\n<p>A bunch of newbies were going to be working with Dr. W for the next three months. I hunted them down and threatened and begged them until one of them agreed to keep giving patients the bipolar screening test in exchange for being named as a co-author. Disaster averted, I thought. Like an idiot.</p>\n<p>Somehow news of this arrangement reached the lady in the corner office, who asked whether the new investigator had completed her Pre-Study Training. I protested that she wasn&#8217;t designing the study, she wasn&#8217;t conducting any analyses, all she was doing was asking her patients the same questions that she would be asking them anyway as part of her job for the next three months. The only difference was that she was recording them and giving them to me.</p>\n<p>The lady in the corner office wasn&#8217;t impressed. You know who <i>else</i> hadn&#8217;t thought his lackeys needed to take courses in research ethics?</p>\n<p>So the poor newbie took a course on how Nazis were bad. Now she could help with the study, right? </p>\n<p>Wrong. We needed to submit a New Investigator Form to the IRB and wait for their approval.</p>\n<p>Two and a half months later, the IRB returned their response: Newbie was good to go. She collected data for the remaining two weeks of her rotation with Dr. W before being sent off to another clinic just like I was.</p>\n<p><b>July 2015</b></p>\n<p>Dr. W and I planned ahead. We had figured out which newbies would be coming in to work for Dr. W three months ahead of time, and gotten them through the don&#8217;t-be-a-Nazi course and the IRB approval process just in time for them to start their rotation. Success!</p>\n<p>Unfortunately, we received another communication from the IRB. Apparently we were allowed to use the expedited consent form to get consent for our <i>study</i>, but not to get consent to <i>access protected health information</i>. That one required a whole different consent form, list-of-risks and all. We were right back where we&#8217;d started from.</p>\n<p>I made my case to the Board. My case was: we&#8217;re not looking at any protected health information, f@#k you.</p>\n<p>The Board answered that we were accessing the patient&#8217;s final diagnosis. It said right in the protocol, we were giving them the screening test, then comparing it to the patient&#8217;s final diagnosis. &#8220;Psychiatric diagnosis&#8221; sure <i>sounds</i> like protected health information.</p>\n<p>I said no, you don&#8217;t understand, we&#8217;re the psychiatrists. Dr. W is the one making the final diagnosis. When I&#8217;m on Dr. W&#8217;s team, I&#8217;m in the room when he does the diagnostic interview, half the time I&#8217;m the one who types the final diagnosis into the chart. These are <i>our patients</i>.</p>\n<p>The Board said this didn&#8217;t matter. We, as the patient&#8217;s doctors, would make the diagnosis and write it down on the chart. But we (as study investigators) needed a full signed consent form before we were allowed to access the diagnosis we had just made.</p>\n<p>I said wait, you&#8217;re telling us we have to do this whole bureaucratic rigamarole with all of these uncooperative patients before we&#8217;re allowed to see something we wrote ourselves?</p>\n<p>The Board said yes, exactly.</p>\n<p>I don&#8217;t remember this part very well, except that I think I half-heartedly trained whichever poor newbie we were using that month in how to take a Protected Health Information Consent on special Protected Health Information Consent Forms, and she nodded her head and said she understood. I think I had kind of clocked out at this point. I was going off to work all the way over in a different town for a year, and I was just sort of desperately hoping that Dr. W and various newbies would take care of things on their own and then in a year when I came back to the hospital I would have a beautiful pile of well-sorted data to analyze. Surely trained doctors would be able to ask simple questions from a screening exam on their own without supervision, I thought. Like an idiot.</p>\n<p><b>July 2016</b></p>\n<p>I returned to my base hospital after a year doing outpatient work in another town. I felt energized, well-rested, and optimistic that the bipolar screening study I had founded so long ago had been prospering in my absence.</p>\n<p>Obviously nothing remotely resembling this had happened. Dr. W had vaguely hoped that I was taking care of it. I had vaguely hoped that Dr. W was taking care of it. The various newbies whom we had strategically enlisted had either forgotten about it, half-heartedly screened one or two patients before getting bored, or else mixed up the growing pile of consent forms and releases and logs so thoroughly that we would have to throw out all their work. It had been a year and a half since the study had started, and we had 40 good data points.</p>\n<p>The good news was that I was back in town and I could go back to screening patients myself again. Also, we had some particularly enthusiastic newbies who seemed really interested in helping out and getting things right. Over the next three months, our sample size shot up, first to 50, then to 60, finally to 70. Our goal of 100 was almost in sight. The worst was finally behind me, I hoped. Like an idiot.</p>\n<p><b>November 2016</b></p>\n<p>I got an email saying our study was going to be audited.</p>\n<p>It was nothing personal. Some higher-ups in the nationwide hospital system had decided to audit every study in our hospital. We were to gather all our records, submit them to the auditor, and hope for the best.</p>\n<p>Dr. W, who was obsessive-compulsive at the best of times, became unbearable. We got into late-night fights over the number of dividers in the study binder. We hunted down every piece of paper that had ever been associated with anyone involved in the study in any way, and almost came to blows over how to organize it. I started working really late. My girlfriend began to doubt I actually existed.</p>\n<p>The worst part was all the stuff the newbies had done. Some of them would have the consent sheets numbered in the upper left-hand-corner instead of the upper-right-hand corner. Others would have written the patient name down on the Results Log instead of the Secret Code Log right next to it. One even wrote something in green pen on a formal study document. It was hopeless. Finally we just decided to throw away all their data and pretend it had never existed. </p>\n<p>With that decision made, our work actually started to look pretty good. As bad as it was working for an obsessive-compulsive boss in an insane bureaucracy, at least it had the advantage that &#8211; when nitpicking push came to ridiculous shove &#8211; you were going to be super-ready to be audited. I hoped. Like an idiot.</p>\n<p><b>December 2016</b></p>\n<p>The auditor found twenty-seven infractions.</p>\n<p>She was very apologetic about it. She said that was actually a pretty good number of infractions for a study this size, that we were actually doing pretty well compared to a lot of the studies she&#8217;d seen. She said she absolutely wasn&#8217;t going to shut us down, she wasn&#8217;t even going to censure us. She just wanted us to make twenty-seven changes to our study and get IRB approval for each of them.</p>\n<p>I kept the audit report as a souvenier. I have it in front of me now. Here&#8217;s an example infraction:</p>\n<blockquote><p>The data and safety monitoring plan consists of &#8216;the Principal Investigator will randomly check data integrity&#8217;. This is a prospective study with a vulnerable group (mental illness, likely to have diminished capacity, likely to be low income) and, as such, would warrant a more rigorous monitoring plan than what is stated above. In addition to the above, a more adequate plan for this study would also include review of the protocol at regular intervals, on-going checking of any participant complaints or difficulties with the study, monitoring that the approved data variables are the only ones being collected, regular study team meetings to discuss progress and any deviations or unexpected problems. Team meetings help to assure participant protections, adherence to the protocol. Having an adequate monitoring plan is a federal requirement for the approval of a study. See Regulation 45 CFR 46.111 Criteria For IRB Approval Of Research. IRB Policy: PI Qualifications And Responsibility In Conducting Research. Please revise the protocol via a protocol revision request form. Recommend that periodic meetings with the research team occur and be documented.</p></blockquote>\n<p>Among my favorite other infractions:</p>\n<p>1. The protocol said we would stop giving the screening exam to patients if they became violent, but failed to rigorously define &#8220;violent&#8221;.</p>\n<p>2. We still weren&#8217;t educating our patients enough about &#8220;Alternatives To Participating In This Study&#8221;. The auditor agreed that the only alternative was &#8220;not participating in this study&#8221;, but said that we had to tell every patient that, then document that we&#8217;d done so.</p>\n<p>3. The consent forms were still getting signed in pencil. We are never going to live this one down. If I live to be a hundred, representatives from the IRB are going to break into my deathbed room and shout &#8220;YOU LET PEOPLE SIGN CONSENT FORMS IN PENCIL, HOW CAN YOU JUSTIFY THAT?!&#8221;</p>\n<p>4. The woman in the corner office who kept insisting everybody take the Pre-Study Training&#8230;hadn&#8217;t taken the Pre-Study Training, and was therefore unqualified to be our liaison with the IRB. I swear I am not making this up.</p>\n<p>Faced with submitting twenty-seven new pieces of paperwork to correct our twenty-seven infractions, Dr. W and I gave up. We shredded the patient data and the Secret Code Log. We told all the newbies they could give up and go home. We submitted the Project Closure Form to the woman in the corner office (who as far as I know still hasn&#8217;t completed her Pre-Study Training). We told the IRB that they had won, fair and square; we surrendered unconditionally. </p>\n<p>They didn&#8217;t seem the least bit surprised.</p>\n<p><b>August 2017</b></p>\n<p>I&#8217;ve been sitting on this story for a year. I thought it was unwise to publish it while I worked for the hospital in question. I still think it&#8217;s a great hospital, that it delivers top-notch care, that it has amazing doctors, that it has a really good residency program, and even that the Research Department did everything it could to help me given the legal and regulatory constraints. I don&#8217;t want this to reflect badly on them in any way. I just thought it was wise to wait a year.</p>\n<p>During that year, Dr. W and I worked together on two less ambitious studies, carefully designed not to require any contact with the IRB. One was a case report, the other used publicly available data.</p>\n<p>They won 1st and 2nd prize at a regional research competition. I got some nice certificates for my wall and a little prize money. I went on to present one of them at the national meeting of the American Psychiatric Association, a friend helped me write it up formally, and it was recently accepted for publication by a medium-tier journal.</p>\n<p>I say this not to boast, but to protest that I&#8217;m not as much of a loser as my story probably makes me sound. I&#8217;m capable of doing research, I think I have something to contribute to Science. I still think the bipolar screening test is inappropriate for inpatient diagnosis, and I still think that patients are being harmed by people&#8217;s reliance on it. I still think somebody should look into it and publish the results.</p>\n<p>I&#8217;m just saying it&#8217;s not going to be me. I am <i>done</i> with research. People keep asking me &#8220;You seem really into science, why don&#8217;t you become a researcher?&#8221; Well&#8230;</p>\n<p>I feel like a study that realistically could have been done by one person in a couple of hours got dragged out into hundreds of hours of paperwork hell for an entire team of miserable doctors. I think its scientific integrity was screwed up by stupid requirements like the one about breaking blinding, and the patients involved were put through unnecessary trouble by being forced to sign endless consent forms screaming to them about nonexistent risks. </p>\n<p>I feel like I was dragged almost to the point of needing to be in a psychiatric hospital myself, while my colleagues who just <i>used</i> the bipolar screening test &#8211; without making the mistake of trying to check if it works &#8211; continue to do so without anybody questioning them or giving them the slightest bit of aggravation.</p>\n<p>I feel like some scientists do amazingly crappy studies that couldn&#8217;t possibly prove anything, but get away with it because they have a well-funded team of clerks and secretaries who handle the paperwork for them. And that I, who was trying to do everything right, got ground down with so many pointless security-theater-style regulations that I&#8217;m never going to be able to do the research I would need to show they&#8217;re wrong.</p>\n<p>In the past year or so, I&#8217;ve been gratified to learn some other people are thinking along the same lines. Somebody linked me to <A HREF=\"https://mitpress.mit.edu/books/censors-hand\">The Censor&#8217;s Hand</A>, a book by a law/medicine professor at the University of Michigan. A summary from <A HREF=\"http://theincidentaleconomist.com/wordpress/should-irbs-be-dismantled/\">a review</A>:</p>\n<blockquote><p>Schneider opens by trying to tally the benefits of IRB review. “Surprisingly,” he writes, a careful review of the literature suggests that “research is not especially dangerous. Some biomedical research can be risky, but much of it requires no physical contact with patients and most contact cannot cause serious injury. Ill patients are, if anything, safer in than out of research.” As for social-science research, “its risks are trivial compared with daily risks like going online or on a date.”</p>\n<p>Since the upsides of IRB review are likely to be modest, Schneider argues, it’s critical to ask hard questions about the system’s costs. And those costs are serious. To a lawyer’s eyes, IRBs are strangely unaccountable. They don’t have to offer reasons for their decisions, their decisions can’t be appealed, and they’re barely supervised at the federal level. That lack of accountability, combined with the gauzy ethical principles that govern IRB deliberations, is a recipe for capriciousness. Indeed, in Schneider’s estimation, IRBs wield coercive government power—the power to censor university research—without providing due process of law.</p>\n<p>And they’re not shy about wielding that power. Over time, IRB review has grown more and more intrusive. Not only do IRBs waste thousands of researcher hours on paperwork and elaborate consent forms that most study participants will never understand. Of greater concern, they also superintend research methods to minimize perceived risks. Yet IRB members often aren’t experts in the fields they oversee. Indeed, some know little or nothing about research methods at all.</p>\n<p>IRBs thus delay, distort, and stifle research, especially research on vulnerable subgroups that may benefit most from it. It’s hard to precise about those costs, but they’re high: after canvassing the research, Schneider concludes that “IRB regulation annually costs thousands of lives that could have been saved, unmeasurable suffering that could have been softened, and uncountable social ills that could have been ameliorated.”</p></blockquote>\n<p>This view seems to be growing more popular lately, and has gotten support from high-profile academics like Richard Nisbett and Steven Pinker:</p>\n<p><center></p>\n<blockquote class=\"twitter-tweet\" data-lang=\"en\">\n<p lang=\"en\" dir=\"ltr\">Should IRBs (human subjects research approval committees) be dismantled? [Probably yes.] <a href=\"http://t.co/5mxhEycEA5\">http://t.co/5mxhEycEA5</a></p>\n<p>&mdash; Steven Pinker (@sapinker) <a href=\"https://twitter.com/sapinker/status/624603026997706752\">July 24, 2015</a></p></blockquote>\n<p><script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></center></p>\n<p>And there&#8217;s been some recent reform, maybe. The federal Office for Human Research Protections <A HREF=\"https://www.nytimes.com/2017/05/22/science/social-science-research-institutional-review-boards-common-rule.html\">made a vague statement</A> that perhaps studies that obviously aren&#8217;t going to hurt anybody might not need the full IRB treatment. There&#8217;s still a lot of debate about how this will be enforced and whether it&#8217;s going to lead to any real-life changes. But I&#8217;m glad people are starting to think more about these things. </p>\n<p>(I&#8217;m also glad people are starting to agree that getting rid of a little oversight for the lowest-risk studies is a good compromise, and that we don&#8217;t have to start with anything more radical.)</p>\n<p>I sometimes worry that people misunderstand the case against bureaucracy. People imagine it&#8217;s Big Business complaining about the regulations preventing them from steamrolling over everyone else. That hasn&#8217;t been my experience. Big Business &#8211; heck, Big Anything &#8211; loves bureaucracy. They can hire a team of clerks and secretaries and middle managers to fill out all the necessary forms, and the rest of the company can be on their merry way. It&#8217;s everyone else who suffers. The amateurs, the entrepreneurs, the hobbyists, the people doing something as a labor of love. Wal-Mart is going to keep selling groceries no matter how much paperwork and inspections it takes; the poor immigrant family with the backyard vegetable garden might not.</p>\n<p>Bureaucracy in science does the same thing: limit the field to big institutional actors with vested interests. No amount of hassle is going to prevent the Pfizer-Merck-Novartis Corporation from doing whatever study will raise their bottom line. But enough hassle <i>will</i> prevent a random psychiatrist at a small community hospital from pursuing his pet theory about bipolar diagnosis. The more hurdles we put up, the more the scientific conversation skews in favor of Pfizer-Merck-Novartis. And the less likely we are to hear little stuff, dissenting voices, and things that don&#8217;t make anybody any money.</p>\n<p>I&#8217;m not just talking about IRBs here. I could write a book about this. There are so many privacy and confidentiality restrictions around the most harmless of datasets that research teams won&#8217;t share data with one another (let alone with unaffiliated citizen scientists) lest they break some arcane regulation or other. Closed access journals require people to pay thousands of dollars in subscription fees before they&#8217;re allowed to read the scientific literature; open-access journals just shift the burden by requiring scientists to pay thousands of dollars to publish their research. Big research institutions have whole departments to deal with these kinds of problems; unaffiliated people who just want to look into things on their own are out of luck.</p>\n<p>And this is happening at the same time we&#8217;re becoming increasingly aware of the shortcomings of big-name research. <A HREF=\"https://www.nature.com/news/over-half-of-psychology-studies-fail-reproducibility-test-1.18248\">Half of psychology studies</A> fail replication; my own field of psychiatry <A HREF=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0158064\">is even worse</A>. And citizen-scientists and science bloggers are playing a big part in debunking bad research: here I&#8217;m thinking especially of statistics bloggers like <A HREF=\"http://andrewgelman.com/\">Andrew Gelman</A> and <A HREF=\"http://daniellakens.blogspot.com/\">Daniel Lakens</A>, but there are all sorts of people in this category. And both Gelman and Lakens are PhDs with institutional affiliations  &#8211; &#8220;citizen science&#8221; doesn&#8217;t mean random cavemen who don&#8217;t understand the field &#8211; but they&#8217;re both operating outside their day job, trying to contribute a few hours per project instead of a few years. I know many more people like them &#8211; smart, highly-qualified, but maybe not going to hire a team of paper-pushers and spend thousands of dollars in fees in order to say what they have to say. Even now these people are doing great work &#8211; but I can&#8217;t help but feel like more is possible.</p>\n<p>IRB overreach is a small part of the problem. But it&#8217;s the part which sunk my bipolar study, a study I really cared about. I&#8217;m excited that there&#8217;s finally more of a national conversation about this kind of thing, and hopeful that further changes will make scientific efforts easier and more rewarding for the next generation of doctors.</p>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  },
  {
    "_id": "c9CyLv6vqE6rnGXdG",
    "title": "Blind Goaltenders: Unproductive Disagreements",
    "slug": "blind-goaltenders-unproductive-disagreements",
    "pageUrl": "https://www.lesswrong.com/posts/c9CyLv6vqE6rnGXdG/blind-goaltenders-unproductive-disagreements",
    "postedAt": "2017-09-28T16:19:07.241Z",
    "baseScore": 19,
    "voteCount": 17,
    "commentCount": 8,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>If you&#x27;re worried about an oncoming problem and discussing it with others to plan, your ideal interlocutor, generally, is someone who agrees with you about the danger. More often, though, you&#x27;ll be discussing it with people who disagree, at least in part.</p><p>The question that inspired this post was &quot;Why are some forms of disagreement so much more frustrating than others?&quot; Why do some disagreements feel like talking to a brick wall, while others are far more productive?</p><p>My answer is that some interlocutors are &#x27;blind goaltenders&#x27;. They not only disagree about the importance of your problem, they don&#x27;t seem to understand what it is you&#x27;re worried about. For example, take AI Safety. I believe that it&#x27;s a serious problem, most likely the Most Important Problem, and likely to be catastrophic. I can argue about it with someone who&#x27;s read a fair chunk of LessWrong or Bostrom, and they may disagree, but they will understand. Their disagreement will probably <a href=\"http://lesswrong.com/lw/ozz/gears_in_understanding/\">have gears</a>. This argument may not be productive, but it won&#x27;t be frustrating.</p><p>Or I could talk to someone who doesn&#x27;t understand the complexity of value thesis or orthogonality thesis.  Their position may have plenty of nuances, but they are missing a key concept about our disagreement. This argument may be just as civil - or, given my friends in the rationalsphere,  <em>more</em> civil - but it will be much more frustrating, because they are a blind goaltender with respect to AI safety. If I&#x27;m trying to convince them, for example, <em>not</em> to support an effort to create an AI via a massive RL model trained on a whole datacenter, they may take into account specific criticisms, but will not be blocking the thing I care about. They can&#x27;t see the problem I&#x27;m worried about, and so they&#x27;ll be about as effective in forestalling it as a blind goalie.</p><h3>Things this does not mean</h3><p>Blind goaltenders are not always wrong. Lifelong atheists are often blind goaltenders with respect to questions of sin, faith, or other religiously-motivated behavior.</p><p>Blind goaltenders are not impossible to educate. Most people who understand your pet issue now were blind about it in the past, including you.</p><p>Blind goaltenders are not stupid. Much of the problem in AI safety is that there are a great deal of smart people working in ML who are nonetheless blind goaltenders.</p><p>Goaltenders who cease to be blind will not always agree with you. </p><h3>Things this does mean</h3><p>Part of why AI safety is such a messy fight is that, given the massive impact if the premises are true, it&#x27;s rare to understand the premises, see all the metaphorical soccer balls flying at you, and still disagree. Or at least, that&#x27;s how it seems from the perspective of someone who believes that AI safety is critical. (Certainly most people who disagree are missing critical premises.) This makes it very tempting to characterize people who are well-informed but disagree, such as non-AI EAs, as being blind to some aspect. (Tangentially, a shout-out to Paul Christiano, who I have <a href=\"https://agentfoundations.org/item?id=1394#comments\">strong disagreements with</a> in this area but who definitely sees the problems.)</p><p>This idea can reconcile two contrasting narratives of the LessWrong community. The first is that it&#x27;s founded on one guy&#x27;s ideas and everyone believes his weird ideas. The second is that anyone you ask has a long list of their points of disagreement with Eliezer. I would replace them with the idea that LessWrong established a community which understood and could see some core premises; that AI is hard, that the world is mad, that <em>nihil supernum</em>. People in our community disagree, or draw different conclusions, but they understand enough of the implications of those premises to share a foundation.</p><p>This relates strongly to the intellectual turing test, and its differences with steelmanning. Someone who can pass the ITT for your position has demonstrated that they understand your position and why you hold it, and therefore are not blind to your premises. Someone who is a blind goaltender can do their best to steelman you, even with honest intentions, but they will not succeed at interpreting you charitably. The ITT is both a diagnostic for blindness and an attempt to cure it; steelmanning is merely a more lossy diagnostic.</p></div></div></div></div>",
    "user": {
      "username": "PDV",
      "slug": "pdv",
      "displayName": "PDV"
    }
  },
  {
    "_id": "kDg6vqeWew4qbnQpT",
    "title": "For signaling? (Part I)",
    "slug": "for-signaling-part-i",
    "pageUrl": "https://www.lesswrong.com/posts/kDg6vqeWew4qbnQpT/for-signaling-part-i",
    "postedAt": "2017-09-28T07:00:00.605Z",
    "baseScore": 7,
    "voteCount": 9,
    "commentCount": 5,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p style=\"text-align:right;\"><em>Your T-shirt is embarrassing. Have you considered wearing a less embarrassing T-shirt?</em></p><p>You are suggesting I spend my precious time trying to look good. Well I am good, and so I’m not going to do that. Because signaling is bad. You can tell something is bad when the whole point of it is to have costs. Signaling is showing off. Signaling benefits me at someone else’s equal expense. I won’t wear a less embarrassing T-shirt because to Hell with signaling.</p><p></p><p style=\"text-align:right;\"><em>Hmm. That seems wrong. Signaling is about honest communication when the stakes are high—which is often important! And just because it’s called ‘costly’ doesn’t mean it is meant to have costs. It only has to be too costly for liars, and if it’s working then they won’t be doing any signaling anyway. ‘Costly signals’ can be very cheap for those who use them. I think signaling is often wonderful for society.</em></p><p></p><p>Give me three examples where it is ‘wonderful’.</p><p></p><p style=\"text-align:right;\"><em>Driver’s licences. Showing a driver’s licence is a costly signal of being a decent driver, which communicates something useful honestly, is cheap for the people who are actually good drivers, and lets the rest of society distinguish people who are likely to drive safely from people who are not, which is amazingly great.</em></p><p></p><p>Driving tests don’t seem that cheap to me, but I’ll grant that they are probably worth it. Still, this seems like a strange corner case of ‘signaling’ that was explicitly designed by humans. It fits the economic definition of ‘costly signaling’ but if you have to go that far from the central examples to find something socially beneficial, that doesn’t increase my regard for signaling. Next?</p><p></p><p style=\"text-align:right;\"><em>One of the most famous examples of signaling is in the job market. Potential candidates show a hirer their qualifications, which allows the hirer to employ more appropriate candidates. You might disagree about whether all of the signals that people use are socially optimal—for instance if education is mostly for signaling, it seems fairly destructive, because it is so expensive. But you must agree that companies do a lot better hiring the people they choose than they would hiring random people they would get if good candidates couldn’t signal their quality. And at least many aspects of the interview process are cheap enough to be totally worth it. For instance, being able to have a polite and friendly conversation about the subject matter.</em></p><p style=\"text-align:right;\"></p><p>Of course companies are better off—companies aren’t the people destroying years of their productive lives on deliberately arduous fake work. Or learning a lot of irrelevant but testable skills. Or degrading themselves and society with faux friendliness. And you ignore some other key details, like what the actual alternative would realistically look like. But let’s not go into it—I’ll grant you that hiring probably goes better overall than it would with zero signaling and no replacement, even though the signaling is awful. And more importantly, that the the whole of society on net is probably best off with some kind of signaling there. I don’t know of a good replacement.</p><p></p><p style=\"text-align:right;\"><em>Ok, great. So, third—T-shirts. T-shirts signal personality traits. It is free to wear any T-shirt you want, but T-shirts are still costly signals in a sense, because if you aren’t a punk you won’t  know which T-shirt to wear to look like a genuine punk. And if you don’t like ABBA it is more costly for you to wear an ABBA t-shirt than it is for someone who does like them, because you’ll be embarrassed or unhappy at the association. And if you have bad taste, it is hard to know which T-shirt would indicate good taste. This all seems good, because it lets people cheaply find other people with similar interests, and also to learn facts about the people around them, regardless of similarity. Which is why it is socially destructive for you to wear that T-shirt— your taste can’t be that bad, so you are basically lying.</em></p><p style=\"text-align:right;\"></p><p>…</p><p></p><p style=\"text-align:right;\"><em>Ok, a fourth: how about when a friend is sick, and you make them tea and soup and put on a movie for them. This is a costly signal that you care about them, or at least  about your continuing friendship with them. Because it is effort for you with no reward if you don’t care much, and are looking to scale down the relationship soon. But aside from the signaling, this is probably a net social benefit—your friend gets soup and tea and a movie at a time when they could especially use them. Plus, feeling cared for instead of uncared for is a real benefit.</em></p><p style=\"text-align:right;\"></p><p>Ok, I concede that costly signaling can be honest, cheap, and on net socially beneficial. But I still think it usually isn’t! And I’m not sure how far we can get thinking about specific examples, since there are so many.</p><p></p><p style=\"text-align:right;\"><em>Ok, what do you propose?</em></p><p style=\"text-align:right;\"></p><p>Talking about our overall impressions. The big picture. Here is mine: the world is full of people pouring real wealth into things whose only use is to be rubbed in the face of those who can’t afford to destroy so much value. Where it isn’t even good for society to be able to distinguish the signalers from the rest.  Letting everyone see who is rich and who is poor, who is socially competent and who is not, who is beautiful, who is smart, who can win at things that only exist to be won at—does this really lead to a great world?</p><p></p><p style=\"text-align:right;\"><em>There is much signaling that the world would be better off without. I admit I don’t really know what the balance of good and bad is like. But I disagree that we should be talking about signaling overall. Or even what is best for the world in this particular case. You are not the world. Even signaling that is terrible for the world is often good for you. If you are in a zero-sum game, and you are more worthy than the opponent, then do your best to win! And if you aren’t, then be more worthy!</em></p><p style=\"text-align:right;\"></p><p>What if I want what is best for society?</p><p></p><p style=\"text-align:right;\"><em>Even then, you don’t serve society by failing at signaling. Just because people fighting to look good is costly for society doesn’t mean that society gains anything by you intentionally losing that fight. If you are directing your resources to society, then it is better for society if you win. Often better enough to warrant the costs of playing. Serve society by winning at signaling and donating the proceeds to society. Wear a well ironed suit. Don’t talk about your erotic porcelain dinosaur collection. Go to university. Try to exercise good taste…</em></p><p style=\"text-align:right;\"></p><p>I agree, at least often. But I think you believe in a heuristic that says you should signal about as much and in similar ways as if you were selfish. Because you are on the side of good, so protecting yourself is protecting the good. You see people looking weird and embarrassing themselves in the name of caring about something, and you think they are failing at signaling. And that’s wrong.</p><p></p><p style=\"text-align:right;\"><em>Yeah, I guess you should signal a tiny bit less on the margin, in cases where signaling is socially destructive. But it’s such a small thing, I’m not sure it is worth thinking about.</em></p><p style=\"text-align:right;\"></p><p>I don’t mean that. Your selfish interests can come apart from society’s interests almost entirely, in signaling. As an extreme case, imagine that you became confident that by far the best cause for improving the world was promoting incest. From a selfish perspective, you probably don’t want to look like you are promoting incest, because there are few worse ways to look in modern society. But from an altruistic perspective, supposing that you were right about incest, it may well be best for you to promote it, because it would do so much for making incest look better, at just the cost of your own reputation.</p><p></p><p>You should distinguish between wearing a clean shirt—good for your cause—and wearing a shirt that is more respectable because it is not about your cause—which is often bad for your cause. You can’t just use ‘looking good’ as a heuristic, even though it is generally good for your cause when its proponents look good.</p><p></p><p style=\"text-align:right;\"><em>That’s an interesting point, and I hadn’t really thought about it. But surely that’s pretty rare. There are systematic reasons that it’s unlikely that there is some cause which is radically more important than any other, and is completely politically unpalateable.</em></p><p style=\"text-align:right;\"></p><p>I agree that’s unlikely—just brought it up as a clear example of it being not worth looking good. I think this issue is maybe ubiquitous though, in less clear and extreme cases. For instance, everywhere sophisticated people play it cool, withholding enthusiasm from ideas until they no longer lack enthusiasm, polishing their own image at the expense of the very projects they are most excited about, or would be if they deigned to experience excitement.</p><p></p><p style=\"text-align:right;\"><em>A bold claim—I am curious to hear two more examples, but I have a lot of signaling to get done this evening. Same time next week?</em></p><p style=\"text-align:right;\"></p><p>Most likely. I hope you are correctly identified as the superior type in all of your endeavors.</p><p></p><p></p></div></div></div></div>",
    "user": {
      "username": "KatjaGrace",
      "slug": "katjagrace",
      "displayName": "KatjaGrace"
    }
  },
  {
    "_id": "T3nb24aZf7d5S2Lnm",
    "title": "Musings on Double Crux (and \"Productive Disagreement\")",
    "slug": "musings-on-double-crux-and-productive-disagreement",
    "pageUrl": "https://www.lesswrong.com/posts/T3nb24aZf7d5S2Lnm/musings-on-double-crux-and-productive-disagreement",
    "postedAt": "2017-09-28T05:26:01.246Z",
    "baseScore": 21,
    "voteCount": 11,
    "commentCount": 72,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><em>Epistemic Status: Thinking out loud, not necessarily endorsed, more of a brainstorm and hopefully discussion-prompt.</em></p><p><a href=\"https://www.lesserwrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-resolving-disagreement\">Double Crux</a> has been making the rounds lately (mostly on Facebook but I hope for this to change). It seems like the technique has failed to take root as well as it should. What&#x27;s up with that?</p><p>(If you aren&#x27;t yet familiar with Double Crux I recommend checking out <a href=\"https://www.lesserwrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-resolving-disagreement\">Duncan&#x27;s post on it</a> in full. There&#x27;s a lot of nuance that might be missed with a simple description.)</p><p><strong>Observations So Far</strong></p><ul><li>Double Crux hasn&#x27;t percolated <em>beyond </em>circles directly adjacent to CFAR (it seems to be learned mostly be word of mouth). This might be evidence that it&#x27;s too confusing or nuanced a concept to teach without word of mouth and lots of examples. It might be evidence that we have not yet taught it very well.</li><li>&quot;Double Crux&quot; seems to refer to two things: the specific action of &quot;finding the crux(es) you both agree the debate hinges on&quot; and &quot;the overall pattern of behavior surrounding using Official Doublecrux Technique&quot;. (I&#x27;ll be using the phrase &quot;productive disagreement&quot; to refer to the second, broader usage)</li></ul><p>Double Crux seems hard to practice, for a few reasons. </p><p><strong>Filtering Effects</strong></p><ul><li>In local meetups where rationality-folk attempt to practice productive disagreement on purpose, they often have trouble finding things to disagree about. Instead they either:</li><ul><li>are already filtered to have similar beliefs,</li><li>quickly realize their beliefs shouldn&#x27;t be that strong (i.e. they disagree on Open Borders, but soon as they start talking they admit that neither of them really have that strong an opinion)</li><li>they have wildly different intuitions about deep moral sentiments that are hard to make headway on in a reasonable amount of time - often untethered to anything empirical. (i.e. what&#x27;s more important? Preventing suffering? Material Freedom? Accomplishing interesting things?)</li></ul></ul><p><strong>Insufficient Shared Trust</strong></p><ul><li>Meanwhile in many online spaces, people disagree all the time. And even if they&#x27;re both nominally rationalists, they have an (arguably justified) distrust of people on the internet who don&#x27;t seem to be arguing in good faith. So there isn&#x27;t enough foundation to do a productive disagreement at all. </li><li>One failure mode of Double Crux is when people disagree on what frame to even be using to evaluate truth, in which case the debate recurses all the way to the level of basic epistemology. It often doesn&#x27;t seem to be worth the effort to resolve that.</li><li>Perhaps most frustratingly: it seems to me that there are many longstanding disagreements between <em>people who should totally be able to communicate clearly, update rationally, and make useful progress together</em>, and those disagreements don&#x27;t go away, people just eventually start ignoring each other or leaving the dispute as unresolved. (An example I feel safe bringing up publicly is the argument between Hanson and Yudkowsky, although this may be a case of the &#x27;what frame are we even using&#x27; issue above.)</li></ul><p>That last point is one of the biggest motivators of this post. If the people I most respect can&#x27;t productively disagree in a way that leads to <em>clear progress, recognizable from both sides</em>, then what is the rationality community even doing? (Whether you consider the primary goal to &quot;raise the sanity waterline&quot; or &quot;build a small intellectual community that can solve particular hard problems&quot;, this bodes poorly).</p><h2>Possible Pre-Requisites for Progress</h2><p>There&#x27;s a large number of sub-skills you need to productively disagree. To have <em>public norms </em>surrounding  disagreement, you not only need individuals to have those skills - they need to trust that each other have those skills as well. </p><p>Here&#x27;s a rough list of those skills. (Note: this is long, and it&#x27;s less important that you read the whole list than that the list is long, which is why Double Cruxing is hard)</p><ul><li><strong>Background beliefs</strong> (listed in <a href=\"https://www.lesserwrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-resolving-disagreement\">Duncan&#x27;s original post</a>)</li><ul><li>Epistemic humility (&quot;I could be the wrong person here&quot;)</li><li>Good Faith (&quot;I trust the other person to be believing things that make sense to them, which I&#x27;d have ended up believing if I were exposed to the same stimuli, and that they are generally trying to find the the truth&quot;)</li><li>Confidence in the existence of objective truth</li><li>Curiosity / Desire to uncover truth</li></ul><li><strong>Building-Block and Meta Skills</strong></li><li>(Necessary or at least very helpful to learn everything else)</li><ul><li>Ability to gain habits (see <a href=\"https://www.lesserwrong.com/posts/v4nNuJBZWPkMkgQRb/making-intentions-concrete-trigger-action-planning\">Trigger Action Plans</a>, <a href=\"http://malcolmocean.com/2014/05/routines-vs-reflexes/\">Reflex/Routines</a>, <a href=\"https://medium.com/mindlevelup/habits-101-techniques-and-research-da8f4bb918f5\">Habits 101</a>)</li><li>Ability to introspect and notice your internal states (<a href=\"https://www.lesserwrong.com/posts/PXqQhYEdbdAYCp88m/focusing-for-skeptics\">Focusing</a> and <a href=\"http://agentyduck.blogspot.com/p/microrationality.html\">Noticing</a> can help)</li><li>Ability to <a href=\"https://www.lesserwrong.com/posts/nXTx9HyhtjT9eJ6qf/capturing-the-catalyst\">induce a mental state</a> or reframe</li><li>Habit of gaining habits </li></ul><li><strong>Notice you are in a failure mode, and step out.</strong> Examples:</li><ul><li>You are fighting to make sure an side/argument wins</li><li>You are fighting to make another side/argument lose (potentially jumping on something that seems <em>allied </em>to something/someone you consider bad/dangerous)</li><li>You are incentivized to believe something, or not to notice something, because of social or financial rewards,</li><li>You&#x27;re incentivized not to notice something or think it&#x27;s important because it&#x27;d be physically inconvenient/annoying</li><li>You are offended/angered/defensive/agitated</li><li>You&#x27;re afraid you&#x27;ll lose something important if you lose a belief (possibly &#x27;bucket errors&#x27;)</li><li>You&#x27;re rounding a person&#x27;s statement off to the nearest stereotype instead of trying to actually understand and response to what they&#x27;re saying </li><li>You&#x27;re arguing about definitions of words instead of ideas</li><li>Notice &quot;freudian slip&quot; ish things that hint that you&#x27;re thinking about something in an unhelpful way. (for example, while writing this, I typed out &quot;your opponent&quot; to refer to the person you&#x27;re Double Cruxing with, which is a holdover from treating it like an adversarial debate)</li></ul></ul><p>(The &quot;Step Out&quot; part can be pretty hard and would be a long series of blogposts, but hopefully this at least gets across the ideas to shoot for)</p><ul><li><strong>Social Skills</strong> (i.e. not feeding into negative spirals, noticing what emotional state or patterns other people are in [*without* accidentaly rounding them off to a stereotype])</li><ul><li>Ability to tactfully disagree in a way that arouses curiosity rather than defensiveness</li><li>Leaving your colleague a line of retreat (i.e. not making them lose face if they change their mind)</li><li>Socially reward people who change their mind (in general, frequently, so that your colleague trusts that you&#x27;ll do so for them)</li><li>Ability to listen (in a way that makes someone feel listened to) so they feel like they got to actually talk, which makes them inclined to listen as well</li><li>Ability to notice if someone else seems to be in one of the above failure modes (and then, ability to point it out gently)</li><li>Cultivate empathy and curiosity about other people so the other social skills come more naturally, and so that even if you don&#x27;t expect them to be right, you can see them as helpful to at least understand their reasoning (fleshing out your model of how other people might think)</li><li>Ability to communicate in (and to listen to) a variety of styles of conversation, &quot;code switching&quot;, learning another person&#x27;s jargon or explaining yours without getting frustrated</li><li>Habit asking clarifying questions, that help your partner find the Crux of their beliefs.</li></ul><li>Actually Thinking About Things</li><ul><li>Understanding when and how to apply math, statistics, etc</li><li>Practice thinking causally</li><li>Practice various creativity related things that help you brainstorm ideas, notice implications of things, etc</li><li>Operationalize vague beliefs into concrete predictions</li></ul><li><strong>Actually Changing Your Mind</strong></li><ul><li>Notice when you are confused or surprised and treat this as a red flag that something about your models is wrong (either you have the wrong model or no model)</li><li>Ability to identify what the actual Crux of your beliefs are.</li><li>Ability to track bits of small bits of evidence that are accumulating. If enough bits of evidence have accumulated that you should at least be taking an idea *seriously* (even if not changing your mind yet), go through motions of thinking through what the implications WOULD be, to help future updates happen more easily.</li><li>If enough evidence has accumulated that you should change your mind about a thing... like, actually do that. See the list of failure modes above that may prevent this. (That said, if you have a vague nagging sense that something isn&#x27;t right even if you can&#x27;t articulate it, try to focus on that and flesh it out rather than trying to steamroll over it)</li><li>Explore Implications: When you change your mind on a thing, don&#x27;t just acknowledge, actually think about what other concepts in your worldview should change. Do this</li><ul><li>because it *should* have other implications, and it&#x27;s useful to know what they are....</li><li>because it&#x27;ll help you actually retain the update (instead of letting it slide away when it becomes socially/politically/emotionally/physically inconvenient to believe it, or just forgetting)</li></ul><li>If you notice your emotions are not in line with what you now believe the truth to be (in a system-2 level), figure out why that is.</li></ul><li><strong>Noticing Disagreement and Confusion, and then <em>putting in the work </em>to resolve it</strong></li><li>If you have all the above skills, and your partner does too, and you both trust that this is the case, you can still fail to make progress if you don&#x27;t actually follow up, and schedule the time to talk through the issues thoroughly. For deep disagreement this can take years. It may or may not be worth it. But if there are longstanding disagreements that continuously cause strife, it may be worthwhile.</li></ul><h2>Building Towards Shared Norms</h2><p>When smart, insightful people disagree, at least one of them is doing something wrong, and it seems like we should be trying harder to notice and resolve it. </p><p>A rough sketch of a norm I&#x27;d like to see. </p><p><strong>Trigger: You&#x27;ve gotten into a heated dispute </strong>where at least one person feels the other is arguing in bad faith (especially in public/online settings)</p><p><strong>Action</strong>: Before arguing further:</p><ul><li>stop to figure out if the argument is even worth it</li><li>if so, each person runs through some basic checks (i.e. &quot;am *I* being overly tribal/emotional?)</li><li>instead of continuing to argue in public where there&#x27;s a lot more pressure to not lose face, or steer social norms, they continue the discussion privately, in whatever the most human-centric way is practical.</li><li>they talk until <em>at least</em> they succeed at Step 1 Double Crux (i.e. agree on where they disagree, and <em>hopefully </em>figure out a possible empirical test for it). Ideally, they also come to as much agreement as they can.</li><li>Regardless of how far they get, they write up a short post (maybe just a paragraph, maybe longer depending on context) on what they <em>did</em> end up agreeing on or figuring out. (The post should be something they both sign off on)</li></ul>",
    "user": {
      "username": "Raemon",
      "slug": "raemon",
      "displayName": "Raemon"
    }
  },
  {
    "_id": "NFZhLe4uCRcMCpvNR",
    "title": "Exposition and guidance by analogy",
    "slug": "exposition-and-guidance-by-analogy",
    "pageUrl": "https://www.lesswrong.com/posts/NFZhLe4uCRcMCpvNR/exposition-and-guidance-by-analogy",
    "postedAt": "2017-09-28T03:33:36.672Z",
    "baseScore": 5,
    "voteCount": 4,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>(Below I attempt to reproduce a chart I can&#x27;t [?] embed, from <em>Models and Analogies in Science</em> by Mary Hesse; I don&#x27;t know how it will display on all screens, but the source is <a href=\"http://whaaales.com/wp-content/uploads/2017/05/tumblr_inline_okh4cw5oQF1sbbt9r_500-300x268.png\">this image</a> at the top of the cross-post version <a href=\"http://whaaales.com/exposition-and-guidance-by-analogy/\">here</a>.)</p><pre style=\"overflow:scroll;\"><code>At an elementary level we can set up the following correspondences: </code></pre><pre style=\"overflow:scroll;\"><code>WATER WAVES         |       SOUND        |          LIGHT<br/>Produced by motion  | Produced by motion | *Produced by moving<br/> of water particles |  of gongs, strings |   flame, etc.<br/>Reflection          | Echoes, etc.       | Reflection in mirrors<br/>Properties of dif-  | Hearing round      | Diffraction through<br/> fraction           |  corners           |  small slits, etc.<br/>Amplitude           | Loudness           | Brightness<br/>Frequency           | Pitch              | Color<br/>Medium: Water       | Medium: Air        | *Medium: &quot;Ether&quot;</code></pre><p>In the table, we see a lot of apparent correspondences between water waves, sound, and light. The “horizontal” notion of similarity lets us notice that sound echoes and light reflects, or that these things all have some sort of “intensity” and “flavor”.\r</p><p>But it’s important to introduce the “vertical” analogy—the items in each column are related by some causal, organizing principle, and there’s a correspondence between those principles. We expect all sorts of things to have similar traits entirely by accident. You won’t get very far filling in a table’s gaps by arguing “this is like that”—better to say “this model is like that model”. You’re taking advantage of a ready-made language (with entailed internal relationships) for a metaphoric redescription of a new subject. In this way analogies can be a useful guide to teaching and learning new models in new domains. (You’ll realize, for example, that “produced by moving flame” isn’t really the appropriate correspondence there, because the motion of the flame doesn’t have to do with color in the way that the motion of a gong has to do with pitch, and eventually you’ll learn something about the production of light.) But what’s this about the medium of light—“ether”?\r</p><p>Well, if we observe that the vertical analogy works for the first two models, and it works for the third up to that point, then light having a medium starts seeming plausible enough for us to start looking into it. And it additionally suggests to us how to go about looking. But while the vertical analogy gives us a stronger inductive inference than does the horizontal analogy alone, it’s still quite weak. Light, it turns out, doesn’t seem to propagate through an ether. (But even the “negative analogy”—the apparent hole in the vertical analogy where light’s medium would go—suggests that “why not?” is an interesting question.)\r</p><p>There are two parts to what I just said, so I’ll work them out a little further:\r</p><p>The use of analogy in science is partly pedagogical—it’s about explaining things\r [as in providing exposition, not reasons or causes] in terms of better-understood things, through their models’ shared structure, or their horizontal points of similarity or difference (positive and negative analogies). If the structure of the relation you’re trying to draw is somewhat confusing on its own terms, or not readily distinguished from a similar model, it could be easier to communicate with reference to another domain. It’s easier to understand what we could possibly mean by “light is a wave” if you already know about water waves. And if we’re being careful, we say “light is a wave like how water waves are waves,” not “light is like water”—we care about communicating the vertical relation, not arguing for horizontal similarity.\r</p><p>And the use of analogy is also about guiding discovery—“neutral” analogies becoming definitely positive or negative as they’re used to pinpoint places to investigate. It can be useful to make tentative inferences based on similarity of causal relations to those of a better-understood model, but these inferences really are provisional. You don’t know if light has a medium, but the analogy has worked so far, so you design experiments (guided by the analogy) that would detect such a medium. You get a handy working hypothesis and a set of questions to study, and not much else. Your analogy is usually not a very good piece of evidence about its subjects—not good enough to use for engineering—but often still good enough to help decide what’s worth investigating. (And, as often when people talk about history and philosophy of science, the big, obvious examples are recapitulated in the everyday work of science on much smaller scales. It’s not always about major physical models like electromagnetism and quantum mechanics, but rather implicit in the kind of reasoning that guides investigation from week to week.)\r</p><p>(Philosophers of science also [used to] like to argue about whether analogy is necessary for explanation and/or discovery—that’s the dialogue Hesse was participating in above. This is out of scope for us, unless I’m being sneaky.)\r</p><p>Can we take this understanding of analogy outside of science? When is it worthwhile to inject an argument by analogy into your internet? And when is it worthwhile to dispute an analogy?\r</p><p>First, when you need better exposition. If you’re making an argument that’s hard to spell out in its own language, or easily confused for a more common argument you decidedly don’t want to make, then an analogy might be clarifying. (And usually more compelling to read, with that stimulating sensation of insight we get from novel connections, which should make all analogies suspect.)  This is where it helps to say “this argument is like that argument” rather than “this is like that”. But be careful not to mistake this for substantiating your argument.\r</p><p>Second, to point to questions to investigate. If you’re not sure how an argument should come out, you can find other arguments in other domains that look like they flow in the same way. Then the points of analogy are good places to look for the evidence your argument hinges on. And disputing the analogy—saying a point of analogy is neutral or negative—is how your interlocutor points to where they think the contrary evidence lies.\r</p><p>Maybe this is a tedious distinction to keep making, but the usefulness of analogy is not, primarily, in making an inductive inference based on the fact that one model looks mostly like another, where the correctness of that inference depends on the success of the analogy between models. Usually, rather than argument by analogy, you want exposition or guidance by analogy.\r</p><p>Along these lines, it could be generally useful to distinguish between different levels of putting forward and substantiating a claim. You can talk about a position, an argument for that position, or evidence that the argument hinges on. In doing so you can be anywhere between just pointing to, or describing, or actually demonstrating the bit you’re talking about. If someone thinks you’re further down the list than you are, then you’re liable to get mired in a bad discussion. (Most debates don’t get past pointing to where evidence can be found, and most blogging (including this post) doesn’t get past pointing to positions or arguments either. Maybe that’s fine. Pointing is cheap, both to write and to read. Going deeper can be superfluous, if you’re pointing to the obvious. Starting out by pointing could get you to the crucial evidence for resolving a disagreement faster. And so on. [And if you are really just pointing, please consider whether you need so many words.])\r</p><p>In this sense, analogies are for pointing.</p></div></div></div></div>",
    "user": {
      "username": "whales",
      "slug": "whales",
      "displayName": "whales"
    }
  },
  {
    "_id": "D7o9GztvqnBeqdBeX",
    "title": "Speed & Performance is our current top priority",
    "slug": "speed-and-performance-is-our-current-top-priority",
    "pageUrl": "https://www.lesswrong.com/posts/D7o9GztvqnBeqdBeX/speed-and-performance-is-our-current-top-priority",
    "postedAt": "2017-09-27T23:36:25.321Z",
    "baseScore": 20,
    "voteCount": 18,
    "commentCount": 3,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<p><em>TLDR: Fewer bugfixes and support for the next week or two while we are focusing on making the site fast and stable. General shift in direction towards more stable and polished features over a large breadth of slightly buggy features. </em></p><p>It&#x27;s been one week since the launch of the open beta. Since then we had <a href=\"https://www.lesserwrong.com/posts/KNtKKmcd9DsP7WuZ3/the-anthropic-principle-five-short-examples\">some</a> <a href=\"https://www.lesserwrong.com/posts/6XvnqW28e2twiv6ww/why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i\">amazing</a> <a href=\"https://www.lesserwrong.com/posts/tq2JGX4ojnrkxL7NF/goodhart-s-imperius\">posts</a>, fixed tons of bugs, answered over 200 of your support questions on Intercom and added over 60 user-submitted issues to our <a href=\"https://github.com/Discordius/Lesswrong2/tree/devel\">Github</a>. I think this week has been a good start for the new LessWrong, in large parts because of your continuous feedback and input. Thanks!</p><p>But despite the positives, and this became clear to us thanks to your input, there is a core problem with the site. LessWrong 2.0 is slow right now. Like, unbearably slow sometimes (I&#x27;ve experiences load times of 10+ seconds, which is totally unacceptable). This has probably caused many of you headaches, and has made the experience of using the site frustrating. </p><p>In addition to that, a good chunk of features are quite buggy. Sometimes when you create a post, it doesn&#x27;t show up where it&#x27;s supposed to, and you can&#x27;t find it any other way than via a link. Or sometimes the page reloads and you lose all the things that you&#x27;ve written because we don&#x27;t automatically save new posts and comments as drafts. </p><p>Here is a quick story of how we got to this state: </p><ul><li>Our top priority until now was to build an MVP that mostly has feature parity with reddit (so we can port over the data from the old site)</li><li>We wanted to have a modular codebase that allows us to extend and change that functionality easily</li><li>This means our development so far had been focused on developing features and getting the basic functionality going, not on making everything smooth and bug-free</li></ul><p>And while it is tempting to continue to focus more on feature improvements and make the site more complete, <strong>I think it&#x27;s time for LW 2.0 to focus its development on stability and speed.</strong> And only as soon as that has reached a high level, start expanding the feature set of the platform again. </p><p>This means, for the next few weeks, I and the rest of the team will do much less development on new features and focus much more on speed and the core user experience of a small selected set of features. </p><p><strong>This might mean we temporarily turn off features on LW 2.0, if that is necessary to create a stable and pleasant experience.</strong></p><p>To give you a concrete sense what this means for you, here is our current ordered list of priorities that we are going to be working on over the next few weeks: </p><p>1. Improve the content reading experience</p><h3>To do do anything else on LessWrong you first have to read things, and the key to a good reading experience are fast loading times and good navigation. There should be almost no discernible load time when you click on an article to the new LessWrong, or when you navigate to different parts of the page. </h3><p>I will be experimenting with a few different approaches to achieve this, but one of them will be to build a significantly feature-stripped version of the page that basically removes all features that are not strictly necessary for a good reading experience. If that works, I will then incrementally add features back to it, while ensuring that the core reading experience does not deteriorate at any step. Since I don&#x27;t want to interrupt the flow of things at <a href=\"http://ww.lesserwrong.com/\">LesserWrong.com</a> with this, I will be hosting that version of the site at <a href=\"http://www.lessestwrong.com/\">LessestWrong.com</a> instead. If you ever find yourself frustrated with the reading experience on here, you can check our progress on making the site fast over at LessestWrong. </p><p>2. Improve the core writing experience</p><h3>Multiple people have mentioned that they lost content because the site reloaded while they were writing a comment or a post, or that some of their writing didn&#x27;t show up in the place they intended. <strong>This is definitely not acceptable for the final version of LW 2.0</strong>, and fixing this is our second highest priority. This means building features like autosaving comments and posts as drafts, and making the navigation of a comment thread intuitive and fast. A secondary priority in this category is improving the writing experience on mobile, which we should be able to do relatively easily (mostly by just deactivating most of the more advanced writing features).</h3><p>I currently see the comment-writing experience as more important than the post-writing experience, so that will be optimized first.  However, all of this only becomes the focus <strong>after</strong> we fixed the performance issues. </p><p>3. Everything else</p><h3>After I am done with these two things I will probably know more about what the next bottleneck for the page is. But until then, basically everything else will be deprioritized. This means I <strong>won&#x27;t </strong>be focusing as much on bugfixes <strong>unrelated</strong> to performance, reading, and commenting for a while, and will generally delay bugfixes until I can solve an underlying systematic issue that is causing that bug and many others. The team will also hang out less on Intercom and provide less super-fast support until we have solved some of the more systematic issues. </h3><p>I am interested in hearing whether anyone disagrees with this, and please feel free to continue to ping me and the others on Intercom or Github, even if we will be less responsive than previously. </p>",
    "user": {
      "username": "habryka4",
      "slug": "habryka4",
      "displayName": "habryka"
    }
  },
  {
    "_id": "BSRp9p6pdb4QD5e6q",
    "title": "Personal thoughts on careers in AI policy and strategy [x-post EA Forum]",
    "slug": "personal-thoughts-on-careers-in-ai-policy-and-strategy-x",
    "pageUrl": "https://www.lesswrong.com/posts/BSRp9p6pdb4QD5e6q/personal-thoughts-on-careers-in-ai-policy-and-strategy-x",
    "postedAt": "2017-09-27T17:09:34.496Z",
    "baseScore": 7,
    "voteCount": 4,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Summary:</span></h2>\n<ol style=\"margin-top: 0pt; margin-bottom: 0pt;\">\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The AI strategy space is currently bottlenecked by entangled and under-defined research questions that are extremely difficult to resolve, as well as by a lack of current institutional capacity to absorb and utilize new researchers effectively.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Accordingly, there is very strong demand for people who are good at this type of &ldquo;disentanglement&rdquo; research and well-suited to conduct it somewhat independently. There is also demand for some specific types of expertise which can help advance AI strategy and policy. </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Advancing this research even a little bit can have massive multiplicative effects by opening up large areas of work for many more researchers and implementers to pursue</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Until the AI strategy research bottleneck clears, many areas of concrete policy research and policy implementation are necessarily on hold. Accordingly, a large majority of people interested in this cause area, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">even extremely talented people</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, will find it difficult to contribute directly, at least in the near term.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you are in this group whose talents and expertise are outside of these narrow areas, and want to contribute to AI strategy, I recommend you build up your capacity and try to put yourself in an influential position. This will set you up well to guide high-value policy interventions as clearer policy directions emerge. </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Try not to be discouraged or dissuaded from pursuing this area by the current low capacity to directly utilize your talent! </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The level of talent across a huge breadth of important areas I have seen from the EA community in my role at FHI is astounding and humbling.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Depending on how slow these &ldquo;entangled&rdquo; research questions are to unjam, and on the timelines of AI development, there might be a very narrow window of time in which it will be necessary to have a massive, sophisticated mobilization of altruistic talent. </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This makes being prepared to mobilize effectively and take impactful action on short notice extremely valuable in expectation</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 8pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In addition to strategy research, operations work in this space is currently highly in demand. Experienced managers and administrators are especially needed. More junior operations roles might also serve as a good orientation period for EAs who would like to take some time after college before either pursuing graduate school or a specific career in this space. This can be a great way to tool up while we as a community develop insight on strategic and policy direction. Additionally, successful recruitment in this area should help with our institutional capacity issues substantially.</span></p>\n</li>\n</ol>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">3600 words. Reading time: approximately 15 minutes with endnotes</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(Also posted to Effective Altruism Forum <a href=\"http://effective-altruism.com/ea/1fa/personal_thoughts_on_careers_in_ai_policy_and/\">here</a>.)</span></p>\n<p><strong id=\"docs-internal-guid-948336d6-c44a-5ea4-3105-b6a50f63206b\" style=\"font-weight: normal;\"><br /></strong></p>\n<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Introduction</span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Intended audience:</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> This post is aimed at EAs and other altruistic types who are already interested in working in AI strategy and AI policy because of its potential large scale effect on the future.[1]</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Epistemic status: </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The below represents my </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">current best guess</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> at how to make good use of human resources given current constraints. I might be wrong, and I would not be surprised if my views changed with time. That said, my recommendations are designed to be robustly useful across most probable scenarios. </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">These are my personal thoughts</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, and </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">do not necessarily represent the views of anyone else in the community or at the Future of Humanity Institute</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.[2] (For some areas where reviewers disagreed, I have added endnotes explaining the disagreement.) This post is not me acting in any official role, this is just me as an EA community member who really cares about this cause area trying to contribute my best guess for how to think about and cultivate this space.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Why my thoughts might be useful</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">: I have been the primary recruitment person at the </span><a style=\"text-decoration: none;\" href=\"https://en.wikipedia.org/wiki/Future_of_Humanity_Institute\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Future of Humanity Institute</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> (FHI) for over a year, and am currently the project manager for FHI&rsquo;s AI strategy programme. Again, I am not writing this in either of these capacities, but being in these positions has given me a chance to see just how talented the community is, to spend a lot of time thinking about how to best utilize this talent, and has provided me some amazing opportunities to talk with others about both of these things.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Definitions</span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">There are lots of ways to slice this space, depending on what exactly you are trying to see, or what point you are trying to make. The terms and definitions I am using are a bit tentative and not necessarily standard, so feel free to discard them after reading this. (These are also not all of the relevant types or areas of research or work, but the subset I want to focus on for this piece.)[3]</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<ol style=\"margin-top: 0pt; margin-bottom: 0pt;\">\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">AI strategy research</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">:[4] </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">the study of how humanity can best navigate the transition to a world with advanced AI systems (especially </span><a style=\"text-decoration: none;\" href=\"http://www.openphilanthropy.org/blog/some-background-our-views-regarding-advanced-artificial-intelligence#Sec1\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">transformative AI</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">), including political, economic, military, governance, and ethical dimensions</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">AI policy implementation </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">is </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">carrying out the activities necessary to safely navigate the transition to advanced AI systems</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. This includes an enormous amount of work that will need to be done in government, the political sphere, private companies, and NGOs in the areas of</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">communications, fund allocation, lobbying, politics, and everything else that is normally done to advance policy objectives.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Operations (in support of AI strategy and implementation) </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">is </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">building, managing, growing, and sustaining all of the institutions and institutional capacity for the organizations advancing AI strategy research and AI policy implementation</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. This is frequently overlooked, badly neglected, and extremely important and impactful work.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 8pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Disentanglement research</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">:[5] This is a squishy made-up term I am using only for this post that is sort of trying to gesture at a type of research that involves disentangling ideas and questions in a &ldquo;pre-paradigmatic&rdquo; area where the core concepts, questions, and methodologies are under-defined. In my mind, I sort of picture this as somewhat like trying to untangle knots in what looks like an enormous ball of fuzz. (Nick Bostrom is a fantastic example of someone who is excellent at this type of research.)</span></p>\n</li>\n</ol>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">To quickly clarify, as I mean to use the terms, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">AI strategy research</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> is an </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">area or field</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> of research, a bit like quantum mechanics or welfare economics. </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Disentanglement research </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">I mean more as a </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">type </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">of research, a bit like quantitative research or conceptual analysis, and is defined more by the character of the questions researched and the methods used to advance toward clarity. Disentanglement is meant to be field agnostic. The relationship between the two is that, in my opinion, AI strategy research is an area that at its current early stage, demands a lot of disentanglement-type research to advance.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">The current bottlenecks in the space (as I see them)</span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Disentanglement research is needed to advance AI strategy research, and is extremely difficult</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Figuring out a good strategy for approaching the development and deployment of advanced AI requires addressing enormous, entangled, under-defined questions, which exist well outside of most existing research paradigms. (This is not all it requires, but it is a central part of it at its current stage of development.)[6] This category includes the study of multi-polar versus unipolar outcomes, technical development trajectories, governance design for advanced AI, international trust and cooperation in the development of transformative capabilities, info/attention/reputation hazards in AI-related research, the dynamics of arms races and how they can be mitigated, geopolitical stabilization and great power war mitigation, research openness, structuring safe R&amp;D dynamics, and many more topics.[7] It also requires identifying other large, entangled questions such as these to ensure no </span><a style=\"text-decoration: none;\" href=\"https://concepts.effectivealtruism.org/concepts/the-importance-of-crucial-considerations/\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">crucial considerations</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> in this space are neglected.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">From my personal experience trying and failing to do good disentanglement research and watching as some much smarter and more capable people have tried and struggled as well, I have come to think of it as a particular skill or aptitude that does not necessarily correlate strongly with other talents or expertise. A bit like mechanical, mathematical, or language aptitude. I have no idea what makes people good at this, or how exactly they do it, but it is pretty easy to identify if it has been done well once the person is finished. (I can appreciate the quality of Nick Bostrom&rsquo;s work, like I can appreciate a great novel, but how they are created I don&rsquo;t really understand and can&rsquo;t myself replicate.) It also seems to be both quite rare and very difficult to identify in advance who will be good at this sort of work, with the only good indicator, as far as I can tell, being past history of succeeding in this type of research. The result is that it is really hard to recruit for, there are very few people doing it full time in the AI strategy space, and this number is far, far fewer than optimal.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The main importance of disentanglement research, as I imagine it, is that it makes questions and research directions clearer and more tractable for other types of research. As Nick Bostrom and others have sketched out the considerations surrounding the development of advanced AI through &ldquo;disentanglement&rdquo;, tractable research questions have arisen. I strongly believe that as more progress is made on topics requiring disentanglement in the AI strategy field, more tractable research questions will arise. As these more tractable questions become clear, and as they are studied, strategic direction, and concrete policy recommendations should follow. I believe this then will open up the floodgates for AI policy implementation work.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Domain experts with specific skills and knowledge are also needed</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">While I think that our biggest need right now is disentanglement research, there are also certain other skills and knowledge sets that would be especially helpful for advancing AI strategy research. This includes expertise in: </span></p>\n<ol style=\"margin-top: 0pt; margin-bottom: 0pt;\">\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Mandarin and/or Chinese politics and/or the Chinese ML community.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">International relations, especially in the areas of international cooperation, international law, global public goods, constitution and institutional design, history and politics of transformative technologies, governance, and grand strategy.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Knowledge and experience working at a high level in policy, international governance and diplomacy, and defense circles. </span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Technology and other types of forecasting.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Quantitative social science, such as economics or analysis of survey data.</span></p>\n</li>\n<li style=\"list-style-type: decimal; font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; margin-left: 22pt;\" dir=\"ltr\">\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 8pt; margin-right: 22pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Law and/or Policy.</span></p>\n</li>\n</ol>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">I expect these skills and knowledge sets to help provide valuable insight on strategic questions including governance design, diplomatic coordination and cooperation, arms race dynamics, technical timelines and capabilities, and many more areas. </span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Until AI strategy advances, AI policy implementation is mostly stalled</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">There is a wide consensus in the community, with which I agree, that aside from a few robust recommendations,[8] </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">it is important not to act or propose concrete policy in this space prematurely</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. We simply have too much uncertainty about the correct strategic direction. Do we want tighter or looser IP law for ML? Do we want a national AI lab? Should the government increase research funding in AI? How should we regulate lethal autonomous weapons systems? Should there be strict liability for AI accidents? It remains unclear what are good recommendations. There are path dependencies that develop quickly in many areas once a direction is initially started down. It is difficult to pass a law that is the exact opposite of a previous law recently lobbied for and passed. It is much easier to start an arms race than to stop it. With most current AI policy questions, the correct approach, I believe, is not to use heuristics of unclear applicability to choose positions, even if those heuristics have served well in other contexts,[9] but to wait until the overall strategic picture is clear, and then to push forward with whatever advances the best outcome.</span></p>\n<p><strong style=\"font-weight: normal;\"><br /></strong></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The AI strategy and policy space, and EA in general, is also currently bottlenecked by institutional and operational capacity</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This is not as big an immediate problem as the AI strategy bottleneck, but it is an issue, and one that exacerbates the research bottleneck as well.[10] &nbsp;FHI alone will need to fill </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4 separate operations roles</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> at senior and junior levels in the next few months. Other organizations in this space have similar shortages. These shortages also compound the research bottleneck as they make it difficult to build effective, dynamic AI strategy research groups. The lack of institutional capacity also might become a future hindrance to the massive, rapid, &ldquo;AI policy implementation&rdquo; mobilization which is likely to be needed.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Next actions</span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">First, I want to make clear, that </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">if you want to work in this space, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">you are wanted in this space</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. There is </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">a tremendous amount of need here</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. That said, as I currently see it, because of the low tractability of disentanglement research, institutional constraints, and the effect of both of these things on the progress of AI strategy research, a large majority of people who are </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">very needed</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> in this area, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">even extremely talented people</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, will not be able to directly contribute immediately. (This is not a good position we are currently in, as I think we are underutilizing our human resources, but hopefully we can fix this quickly.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This is why I am hoping that we can build up a large community of people with a broader set of skills, and especially policy implementation skills, who are in positions of influence from which they can mobilize quickly and effectively and take important action once the bottleneck clears and direction comes into focus.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-variant-ligatures: normal; font-variant-caps: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><em>Actions you can take right now</em></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-variant-ligatures: normal; font-variant-caps: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><em><br /></em></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><a style=\"text-decoration: none;\" href=\"https://rhapsodyinbooks.files.wordpress.com/2013/06/read-all-the-things.jpg\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Read all the things!</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> There are a couple of publications in the pipeline from FHI, including a broad research agenda that should hopefully advance the field a bit. Sign up to </span><a style=\"text-decoration: none;\" href=\"https://www.fhi.ox.ac.uk/\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">FHI&rsquo;s newsletter</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> and the </span><a style=\"text-decoration: none;\" href=\"https://eahub.org/newsletter\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">EA newsletter</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> which will have updates as the cause area advances and unfolds. There is also an </span><a style=\"text-decoration: none;\" href=\"http://www.allandafoe.com/aireadings\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">extensive reading list</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, not especially narrowly tailored to the considerations of interest to our community, but still quite useful. I recommend skimming it and picking out some specific publications or areas to read more about.[11] Try to skill up in this area and put yourself in a position to potentially advance policy when the time comes. Even if it is inconvenient, go to EA group meet-ups and conferences, read and contribute to the forums and newsletters, keep in the loop. Be an active and engaged community member.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Potential near term roles in AI Strategy</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">FHI is recruiting, but somewhat capacity limited, and trying to triage for advancing strategy as quickly as possible.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you have good reason to think you would be good at disentanglement research on AI strategy (likely meaning a record of success with this type of research) or have expertise in the areas listed as especially in demand, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">please </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">get in touch.[12] I would strongly encourage you to do this even if you would rather not work at FHI, as there are remote positions possible if needed, and other organizations I can refer you to. I would also strongly encourage you to do this even if you are reluctant to stop or put on hold whatever you are currently doing. Please also encourage your friends who likely would be good at this to strongly consider it. If I am correct, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">the bottleneck in this space is holding back a lot of potentially vital action by many, many people who cannot be mobilized until they have a direction in which to push</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. (The framers need the foundation finished before they can start.) Anything you can contribute to advancing this field of research will have dramatic force multiplicative effects by &ldquo;creating jobs&rdquo; for dozens or hundreds of other researchers and implementers. You should also consider applying for one or both of the </span><a style=\"text-decoration: none;\" href=\"https://www.fhi.ox.ac.uk/vacancies/\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">AI Macrostrategy roles</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> at FHI if you see this before 29 Sept 2017.[13]</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you are unsure of your skill with disentanglement research, I would strongly encourage you to try to make some independent progress on a question of this type and see how you do. I realize this task itself is a bit under-defined, but that is also really part of the problem space itself, and the thing you are trying to test your skills with. Read around in the area, find something sticky you think you might be able to disentangle, and take a run at it.[14] If it goes well, whether or not you want to get into the space immediately, please send it in.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you feel as though you might be a borderline candidate because of your relative inexperience with an area of in-demand expertise, you might consider trying to tool up a bit in the area, or applying for </span><a style=\"text-decoration: none;\" href=\"https://www.fhi.ox.ac.uk/vacancies/\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">an internship</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. You might also err on the side of sending in a CV and cover letter just in case you are miscalibrated about your skill compared to other applicants. That said, again, </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">do not think that you not being immediately employed is any reflection of your expected value in this space</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">! </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Do not be discouraged, please stay interested, and continue to pursue this!</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Preparation for mobilization</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Being a contributor to this effort, as I imagine it, requires investing in yourself, your career, and the community, while positioning yourself well for action once the bottleneck unjams and and robust strategic direction is clearer.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">I also highly recommend investing in building up your skills and career capital. This likely means excelling in school, going to graduate school, pursuing relevant internships, building up your CV, etc. Invest heavily in yourself. Additionally, stay in close communication with the EA community and keep up to date with opportunities in this space as they develop. (Several people are currently looking at starting programs specifically to on-ramp promising people into this space. This is one reason why signing up to the newsletters might be really valuable, so that opportunities are not missed.) To repeat myself from above, attend meet-ups and conferences, read the forums and newsletters, and be active in the community. Ideally this cause area will become a sub-community within EA and a strong self-reinforcing career network.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">A good way to determine how to prepare and tool up for a career in either AI policy research or implementation is to look at the 80,000 Hours&rsquo; </span><a style=\"text-decoration: none;\" href=\"https://80000hours.org/articles/ai-policy-guide\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Guide to working in AI policy and strategy</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. Fields of study that are likely to be most useful for AI policy implementation include policy, politics and international relations, quantitative social sciences, and law.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Especially useful is finding roles of influence or importance, </span><a style=\"text-decoration: none;\" href=\"https://youtu.be/DQbrtJYWPlU?t=16m56s\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">even with low probability but high expected value</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, within (especially the US federal) </span><a style=\"text-decoration: none;\" href=\"https://youtu.be/g05om2NJwco?t=40s\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">government</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.[15] Other potentially useful paths include non-profit management, project management, communications, public relations, grantmaking, policy advising at tech companies, lobbying, party and electoral politics and advising, political &ldquo;staffing,&rdquo; or research within academia, thinks tanks, or large corporate research groups especially in the areas of machine learning, policy, governance, law, defense, and related. A lot of information about the skills needed for various sub-fields within this area are available at </span><a style=\"text-decoration: none;\" href=\"https://80000hours.org/career-reviews/\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">80,000 Hours</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Working in operations</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Another important bottleneck in this space, though smaller in my estimation than the main bottleneck, is in institutional capacity within this currently tiny field. &nbsp;As mentioned already above, FHI needs to fill </span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4 separate operations roles</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> at senior and junior levels in the next few months. (We are also in need of a temporary junior-level operations person immediately, if you are a UK citizen, consider getting in touch about this!)[16][17] Other organizations in this space have similar shortages. If you are an experienced manager, administrator, or similar, please consider applying or getting in touch for our senior roles. Alternatively, if you are freshly out of school, but have some proven hustle (especially proven by extensive extracurricular involvement, such as running projects or groups) and would potentially like to take a few years to advance this cause area before going to graduate school or locking in a career path, consider applying for a junior operations position, or get in touch.[18] Keep in mind that operations work at an organization like FHI can be a fantastic way to tool up and gain fluency in this space, orient yourself, discover your strengths and interests, and make contacts, even if one intends to move on to non-operations roles eventually.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Conclusion</span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The points I hope you can take away in approximate order of importance:</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">1)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you are interested in advancing this area, stay involved. Your expected value is extremely high, even if there are no excellent immediate opportunities to have a direct impact. Please join this community, and build up your capacity for future research and policy impact in this space.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">2)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you are good at &ldquo;disentanglement research&rdquo; please get in touch, as I think this is our major bottleneck in the area of AI strategy research, and is preventing earlier and broader mobilization and utilization of our community&rsquo;s talent.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">3)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If you are strong or moderately strong in key high-value areas, please also get in touch. (Perhaps err to the side of getting in touch if you are unsure.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Excellent things to do to add value to this area, in expectation, include:</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 72pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">a)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Investing in your skills and career capital, especially in high-value areas, such as studying in-demand topics.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 72pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">b)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Building a career in a position of influence (especially in government, global institutions, or in important tech firms.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 72pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">c)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Helping to build up this community and its capacity, including building a strong and mutually reinforcing career network among people pursuing AI policy implementation from an EA or altruistic perspective.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">5)</span><span style=\"font-size: 6.999999999999999pt; font-family: 'Times New Roman'; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Also of very high value is operations work and other efforts to increase institutional capacity.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt; text-indent: -18pt; padding: 0pt 0pt 0pt 18pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Thank you for taking the time to read this. While it is very unfortunate that the current ground reality is, as far as I can tell, not well structured for immediate wide mobilization, I am confident that we can do a great deal of preparatory and positioning work as a community, and that with some forceful pushing on these bottlenecks, we can turn this enormous latent capacity into extremely valuable impact.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Let&rsquo;s getting going &ldquo;</span><a style=\"text-decoration: none;\" href=\"https://youtu.be/DQbrtJYWPlU?t=3m27s\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">doing good together</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&rdquo; as we navigate this difficult area, and help make a tremendous future!</span></p>\n<p><strong style=\"font-weight: normal;\"><br /></strong></p>\n<h2 style=\"line-height: 1.38; margin-top: 18pt; margin-bottom: 4pt;\" dir=\"ltr\"><span style=\"font-size: 12pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Endnotes: </span></h2>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[1] For those of you not in this category who are interested in seeing why you might want to be, I recommend this short </span><a style=\"text-decoration: none;\" href=\"https://youtu.be/Zef-mIKjHAk\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">EA Global talk,</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> the </span><a style=\"text-decoration: none;\" href=\"https://nickbostrom.com/papers/aipolicy.pdf\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Policy Desiderata</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> paper, and </span><a style=\"text-decoration: none;\" href=\"http://www.openphilanthropy.org/blog/potential-risks-advanced-artificial-intelligence-philanthropic-opportunity\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">OpenPhil&rsquo;s analysis</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. For a very short consideration on why the far future matters, I recommend </span><a style=\"text-decoration: none;\" href=\"https://nickbostrom.com/astronomical/waste.html\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">this very short piece</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, and for a quick fun primer on AI as transformative I recommend </span><a style=\"text-decoration: none;\" href=\"https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">this</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. Finally, once the hook is set, the best resource remains Superintelligence.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[2] Relatedly, I want to thank Miles Brundage, Owen Cotton-Barratt, Allan Dafoe, Ben Garfinkel, Roxanne Heston, Holden Karnofsky, Jade Leung, Kathryn Mecrow, Luke Muehlhauser, Michael Page, Tanya Singh, and Andrew Snyder-Beattie for their comments on early drafts of this post. Their input dramatically improved it. That said, again, they should not be viewed as endorsing anything in this. All mistakes are mine. All views are mine.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[3] There are some interesting tentative taxonomies and definitions of the research space floating around. I personally find the following, quoting from a draft document by Allan Dafoe, especially useful:</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">AI strategy [can be divided into]... four complementary research clusters: the </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">technical landscape</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">AI politics</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> AI governance</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">, and </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">AI policy</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">. Each of these clusters characterizes a set of problems and approaches, within which the density of conversation is likely to be greater. However, most work in this space will need to engage the other clusters, drawing from and contributing high-level insights. This framework can perhaps be clarified by analogy to the problem of building a new city. The</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> technical landscape </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">examines the technical inputs and constraints to the problem, such as trends in the price and strength of steel. </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Politics </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">considers the contending motivations of various actors (such as developers, residents, businesses), the possible mutually harmful dynamics that could arise and strategies for cooperating to overcome them. </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Governance </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">involves understanding the ways that infrastructure, laws, and norms can be used to build the best city, and proposing ideal masterplans of these to facilitate convergence on a common good vision. The </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 700; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">policy </span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">cluster involves crafting the actual policies to be implemented to build this city.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In a comment on this draft, Jade Leung pointed out what I think is an important implicit gap in the terms I am using, and highlights the importance of not treating these as either final, comprehensive, or especially applicable outside of this piece:</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #333333; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">There seems to be a gap between [AI policy implementation] and 'AI strategy research' - where does the policy research feed in? I.e. the research required to canvas and analyse policy mechanisms by which strategies are most viably realised, prior to implementation (which reads here more as boots-on-the-ground alliance building, negotiating, resource distribution etc.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #333333; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[4] Definition lightly adapted from Allan Dafoe and Luke Muehlhauser.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[5]This idea owes a lot to conversations with Owen Cotton-Barratt, Ben Garfinkel, and Michael Page.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[6] I did not get a sense that any reviewer necessarily disagreed that this is a fair conceptualization of a type of research in this space, though some questioned its importance or centrality to current AI strategy research. I think the central disagreement here is on how many well-defined and concrete questions there are left to answer at the moment, how far answering them is likely to go in bringing clarity to this space and developing robust policy recommendations, and the relative marginal value of addressing these existing questions versus producing more through disentanglement of the less well defined areas.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[7] One commenter did not think these were a good sample of important questions. Obviously this might be correct, but in my opinion, these are absolutely among the most important questions to gain clarity on quickly.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[8] My personal opinion is that there are only three or maybe four robust policy-type recommendations we can make to governments at this time, given our uncertainty about strategy: 1) fund safety research, 2) commit to a common good principle, and 3) avoid an arms races. The fourth suggestion is both an extension of the other three and is tentative, but is something like: fund joint intergovernmental research projects lo</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">cated in relatively geopolitically neutral countries with open membership and a strong commitment to a common good principle.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">I should note that this point was also flagged as potentially controversial by one reviewer. Additionally, Miles Brundage, quoted below, had some useful thoughts related to my tentative fourth suggestion:</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">In general, detailed proposals at this stage are unlikely to be robust due to the many gaps in our strategic and empirical knowledge. We \"know\" arms races are probably bad but there are many imaginable ways to avoid or mitigate them, and we don't really know what the best approach is yet. For example, launching big new projects might introduce various opportunities for leakage of information that weren't there before, and politicize the issue more than might be optimal as the details are worked out. As an example of an alternative, governments could commit to subsidizing (e.g. through money and hardware access) existing developers that open themselves up to inspections, which would have some advantages and some disadvantages over the neutrally-sited new project approach.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[9] This is an area with extreme and unusual enough considerations that it seems to break normal heuristics, or at least my normal heuristics. I have personally heard at least minimally plausible arguments made by thoughtful people that openness, antitrust law and competition, government regulation, advocating opposition to lethal autonomous weapons systems, and drawing wide attention to the problems of AI might be bad things, and invasive surveillance, greater corporate concentration, and weaker cyber security might be good things. (To be clear, these were all tentative, weak, but colourable arguments, made as part of exploring the possibility space, not strongly held positions by anyone.) I find all of these very counter-intuitive.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[10] A useful comment from a reviewer on this point: &ldquo;These problems are related: We desperately need new institutions to house all the important AI strategy work, but we can't know what institutions to build until we've answer more of the foundational questions.&rdquo;</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[11] Credit for the heroic effort of assembling this goes mostly to Matthijs Maas. While I contributed a little, I have myself only read a tiny fraction of these.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[12] fhijobs@philosophy.ox.ac.uk.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[13] Getting in touch is a good action even if you can not or would rather not work at FHI. In my opinion, AI strategy researchers would ideally cluster in one or more research groups in order to advance this agenda as quickly as possible, but there is also some room for remote scholarship. (The AI strategy programme at FHI is currently trying to become the first of these &ldquo;cluster&rdquo; research groups, and we are recruiting in this area aggressively.)</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[14] I&rsquo;m personally bad enough at this, that my best advice is something like read around in the area, find a topic, and &ldquo;do magic.&rdquo; Accordingly, I will tag in Jade Leung again for a suggestion of what a &ldquo;sensible, useful deliverable of 'disentanglement research' would look like&rdquo;:</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">A conceptual model for a particular interface of the AI strategy space, articulating the sub-components, exogenous and endogenous variables of relevance, linkages etc.; An analysis of driver-pressure-interactions for a subset of actors; a deconstruction of a potential future scenario into mutually-exclusive-collectively-exhaustive (MECE) hypotheses.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Ben Garfinkel similarly volunteered to help clarify &ldquo;</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">by giving an example of a very broad question that seem[s] to require some sort of \"detangling\" skill</span><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">:&rdquo;</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">What does the space of plausible \"AI development scenarios\" look like, and how do their policy implications differ?</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">If AI strategy is \"the study of how humanity can best navigate the transition to a world with advanced AI systems,\" then it seems like it ought to be quite relevant what this transition will look like. To point at two different very different possibilities, there might be a steady, piecemeal improvement of AI capabilities -- like the steady, piecemeal improvement of industrial technology that characterized the industrial revolution -- or there might be a discontinuous jump, enabled by sudden breakthroughs or an \"intelligence explosion,\" from roughly present-level systems to systems that are more capable than humans at nearly everything. Or -- more likely -- there might be a transition that doesn't look much like either of these extremes. </span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Robin Hanson, Eliezer Yudkowsky, Eric Drexler, and others have all emphasized different visions of AI development, but have also found it difficult to communicate the exact nature of their views to one another. (See, for example, the </span><a style=\"text-decoration: none;\" href=\"https://intelligence.org/ai-foom-debate/\"><span style=\"font-size: 10pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">Hanson-Yudkowsky \"foom\" debate</span></a><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.) Furthermore, it seems to me that their visions don't cleanly exhaust the space, and will naturally be difficult to define given the fact that so many of the relevant concepts--like \"AGI,\" \"recursive self-improvement,\" \"agent/tool/goal-directed AI,\" etc.--are currently so vague.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">I think it would be very helpful to have a good taxonomy of scenarios, so that we could begin to make (less ambiguous) statements like, \"Policy X would be helpful in scenarios A and B, but not in scenario C,\" or, \"If possible, we ought to try to steer towards scenario A and away from B.\" AI strategy is not there yet, though.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #333333; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">A related, \"entangled\" question is: Across different scenarios, what is the relationship between short and medium-term issues (like the deployment of autonomous weapons systems, or the automation of certain forms of cyberattacks) and the long-term issues that are likely to arise as the space of AI capabilities starts to subsume the space of human capabilities? For a given scenario, can these two (rough) categories of issues be cleanly \"pulled apart\"?</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt; margin-left: 36pt;\" dir=\"ltr\"><span style=\"font-size: 10pt; font-family: Verdana; color: #333333; background-color: transparent; font-weight: 400; font-style: italic; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[15] </span><a style=\"text-decoration: none;\" href=\"https://80000hours.org/\"><span style=\"font-size: 11pt; font-family: Verdana; color: #1155cc; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: underline; vertical-align: baseline; white-space: pre-wrap;\">80,000 hours</span></a><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"> is experimenting with having a career coach specialize in this area, so you might consider getting in touch with them, or getting in touch with them again, if you might be interested in pursuing this route.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[16] fhijobs@philosophy.ox.ac.uk. This is how I snuck into FHI ~2 years ago, on a 3 week temporary contract as an office manager. I flew from the US on 4 days notice for the chance to try to gain fluency in the field. While my case of &ldquo;working my way up from the mail room&rdquo; is not likely to be typical (I had a strong CV), or necessarily a good model to encourage (see next footnote below) it is definitely the case that you can pick up a huge amount through osmosis at FHI, and develop a strong EA career network. This can set you up well for a wise choice of graduate programs or other career direction decisions.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[17] &nbsp;One reviewer cautioned against encouraging a dynamic in which already highly qualified people take junior operations roles with the expectation of transitioning directly into a research position, since this can create awkward dynamics and a potentially unhealthy institutional culture. I think this is probably, or at least plausibly, correct. Accordingly, while I think a junior operations role is great for building skills and orienting yourself, it should probably not be seen as a way of immediately transitioning to strategy research, but treated more as a method for turning post-college uncertainty into a productive plan, while also gaining valuable skills and knowledge, and directly contributing to very important work.</span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span></p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Verdana; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[18] Including locking in a career path continuing in operations. This really is an extremely high-value area for a career, and badly overlooked and neglected.</span></p>\n<p><br /></p>",
    "user": {
      "username": "crmflynn",
      "slug": "crmflynn",
      "displayName": "crmflynn"
    }
  },
  {
    "_id": "nxZWDDfpTXpjGy5dP",
    "title": "The Great Filter isn't magic either",
    "slug": "the-great-filter-isn-t-magic-either",
    "pageUrl": "https://www.lesswrong.com/posts/nxZWDDfpTXpjGy5dP/the-great-filter-isn-t-magic-either",
    "postedAt": "2017-09-27T17:04:56.708Z",
    "baseScore": 13,
    "voteCount": 11,
    "commentCount": 6,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><em>A post suggested by James Miller&#x27;s </em><a href=\"https://www.chalmers.se/en/centres/GoCAS/Events/Existential-risk-to-humanity/Pages/Workshop-programme.aspx\"><em>presentation</em></a><em> at the Existential Risk to Humanity conference in Gothenburg.\r</em></p><p>Seeing the <a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/HubbleDeepField.800px.jpg/1200px-HubbleDeepField.800px.jpg\">emptiness of the night sky</a>, we can dwell upon the <a href=\"https://en.wikipedia.org/wiki/Fermi_paradox\">Fermi paradox</a>: where are all the alien civilizations that simple probability estimates imply we should be seeing?\r</p><p>\rEspecially given the <a href=\"http://www.fhi.ox.ac.uk/wp-content/uploads/intergalactic-spreading.pdf\">ease of moving</a> within and between galaxies, the cosmic emptiness implies a <a href=\"https://en.wikipedia.org/wiki/Great_Filter\">Great Filter</a>: something that prevents planets from giving birth to star-spanning civilizations. One worrying possibility is the likelihood that advanced civilizations end up destroying themselves before they reach the stars.\r</p><h2>The Great Filter as an Outside View\r</h2><p>\rIn a sense, the Great Filter can be seen as an ultimate example of the <a href=\"https://wiki.lesswrong.com/wiki/Outside_view\">Outside View</a>: we might have all the data and estimation we believe we would ever need from our models, but if those models predict that the galaxy should be teeming with visible life, then it doesn&#x27;t matter how reliable our models seem: they must be wrong.</p><p>In particular, if you fear a late great filter - if you fear that civilizations are likely to destroy themselves - then you should increase your fear, even if &quot;objectively&quot; everything seems to be going all right. After all, presumably the other civilizations that destroyed themselves thought everything seemed to going all right. Then you can adjust your actions using your knowledge of the great filter - but presumably other civilizations also thought of the great filter and adjusted their own actions as well, but that didn&#x27;t save them, so maybe you need to try something different again or maybe you can do something that breaks the symmetry from the timeless decision theory perspective like send a massive signal to the galaxy...</p><h2>The Great Filter isn&#x27;t magic</h2><p>\rIt can all get very headache-inducing. But, just as <a href=\"https://www.lesserwrong.com/posts/NXcxKXLT8xng5FwDu/the-outside-view-isn-t-magic\">the Outside View isn&#x27;t magic</a>, the Great Filter isn&#x27;t magic either. If advanced civilizations destroy themselves before becoming space-faring or leaving an imprint on the galaxy, then there is some phenomena that is the cause of this. What can we say, if we look analytically at the great filter argument?</p><p>First of all suppose we had three theories - early great filter (technological civilizations are rare), late great filter (technological civilizations destroy themselves before becoming space-faring), or no great filter. Then we look up at the empty skies, and notice no aliens. This rules out the third theory, but leaves the relative probabilities of the other two intact.</p><p>Then we can look at objective evidence. Is human technological civilization likely to end in a nuclear war? Possibly, but are the odds in the 99.999% range that would be needed to explain the Fermi Paradox? Every year that has gone by has reduced the likelihood that nuclear war is very very very very likely. So a late Great Filter may seemed quite probable compared with an early one, but much of the evidence we see is against it (especially if we assume that AI - <a href=\"http://lesswrong.com/lw/kvm/the_great_filter_is_early_or_ai_is_hard/\"><em>which is not a Great Filter!</em></a> - might have been developed by now). Million-to-one prior odds can be overcome by merely 20 bits of information.</p><p>And what about the argument that we have to assume that prior civilizations would also have known of the Great Filter and thus we need to do more than they would have? In your estimation, is the world currently run by people taking the Great Filter arguments seriously? What is the probability that the world will be run by people that take the Great Filter argument seriously? If this probability is low, we don&#x27;t need to worry about the recursive aspect; the ideal situation would be if we can achieve:</p><ol><li><p>Powerful people taking the Great Filter argument seriously.</p></li><li><p>Evidence that it was hard to make powerful people take the argument seriously.</p></li></ol><p>Of course, successfully achieving 1 is evidence against 2, but the Great Filter doesn&#x27;t work by magic. If it looks like we achieved something really hard, then that&#x27;s some evidence that it is hard. Every time we find something unlikely with a late Great Filter, that shifts some of the probability mass away from the late great filter and into alternative hypotheses (early Great Filter, zoo hypothesis,...).</p><h2>Variance and error of xrisk estimates</h2><p>But let&#x27;s focus narrowly on the probability of the late Great Filter.</p><p>Current <a href=\"http://sethbaum.com/ac/2013_NuclearWar.pdf\">estimates for the risk of nuclear war</a> are uncertain, but let&#x27;s arbitrarily assume that the risk is 10% (overall, not per year). Suppose one of two papers comes out:</p><ol><li><p>Paper A shows that current estimates of nuclear war have not accounted for a lot of key facts; when these facts are added in, the risk of nuclear war drops to 5%.</p></li><li><p>Paper B is a massive model of international relationships with a ton of data and excellent predictors and multiple lines of evidence, all pointing towards the real risk being 20%.</p></li></ol><p>What would either paper mean from the Great Filter perspective? Well, counter-intuitively, papers like A typically increase the probability for nuclear war being a Great Filter, while papers like B decrease it. This is because none of 5%, 10%, and 20% are large enough to account for the Great Filter, which requires probabilities in the 99.99% style. And, though paper A decreases the probability of the nuclear war, it also leaves more room for uncertainties - we&#x27;ve seen that a lot of key facts were missing in previous papers, so it&#x27;s plausible that there are key facts still missing from this one. On the other hand, though paper B increases the probability, it makes it unlikely that the probability will be raised any further.</p><p>So if we fear the great filter, we should not look at risks whose probabilities are high, but risks who&#x27;s uncertainty is high, where the probability of us making an error is high. If we consider our future probability estimates as a random variable, then the one whose variance is higher is the one to fear. So a late Great Filter would make biotech risks even worse (current estimates of risk are poor) while not really changing asteroid impact risks (current estimates of risk are good).</p></div></div></div></div>",
    "user": {
      "username": "Stuart_Armstrong",
      "slug": "stuart_armstrong",
      "displayName": "Stuart_Armstrong"
    }
  },
  {
    "_id": "xDSrf3XAifsCuc3jg",
    "title": "The Great Filter isn't magic either",
    "slug": "the-great-filter-isn-t-magic-either",
    "pageUrl": "https://www.lesswrong.com/posts/xDSrf3XAifsCuc3jg/the-great-filter-isn-t-magic-either",
    "postedAt": "2017-09-27T16:56:39.642Z",
    "baseScore": 5,
    "voteCount": 3,
    "commentCount": 6,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><em><a href=\"https://www.lesserwrong.com/posts/nxZWDDfpTXpjGy5dP/the-great-filter-isn-t-magic-either\">Crossposted</a> at Less Wrong 2.0.&nbsp;</em><span style=\"box-sizing: border-box;\"><span style=\"box-sizing: border-box;\"><em style=\"box-sizing: border-box;\">A post suggested by James Miller's&nbsp;<a href=\"https://www.chalmers.se/en/centres/GoCAS/Events/Existential-risk-to-humanity/Pages/Workshop-programme.aspx\">presentation</a>&nbsp;at the Existential Risk to Humanity conference in Gothenburg.</em></span></span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">Seeing the&nbsp;<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/HubbleDeepField.800px.jpg/1200px-HubbleDeepField.800px.jpg\">emptiness of the night sky</a>, we can dwell upon the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Fermi_paradox\">Fermi paradox</a>: where are all the alien civilizations that simple probability estimates imply we should be seeing? </span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\"> Especially given the&nbsp;<a href=\"http://www.fhi.ox.ac.uk/wp-content/uploads/intergalactic-spreading.pdf\">ease of moving</a>&nbsp;within and between galaxies, the cosmic emptiness implies a&nbsp;</span><a href=\"https://en.wikipedia.org/wiki/Great_Filter\">Great Filter</a>: something that prevents planets from giving birth to star-spanning civilizations. One worrying possibility is the likelihood that advanced civilizations end up destroying themselves before they reach the stars.</p>\n<h2 style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 11.5px; font-family: ETBook, serif; font-weight: 400; line-height: 1.1; color: #000000; font-size: 30px;\"><span style=\"box-sizing: border-box;\">The Great Filter as an Outside View </span></h2>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\"> In a sense, the Great Filter can be seen as an ultimate example of the&nbsp;<a href=\"https://wiki.lesswrong.com/wiki/Outside_view\">Outside View</a>: we might have all the data and estimation we believe we would ever need from our models, but if those models predict that the galaxy should be teeming with visible life, then it doesn't matter how reliable our models seem: they must be wrong.</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">In particular, if you fear a late great filter - if you fear that civilizations are likely to destroy themselves - then you should increase your fear, even if \"objectively\" everything seems to be going all right. After all, presumably the other civilizations that destroyed themselves thought everything seemed to going all right. Then you can adjust your actions using your knowledge of the great filter - but presumably other civilizations also thought of the great filter and adjusted their own actions as well, but that didn't save them, so maybe you need to try something different again or maybe you can do something that breaks the symmetry from the timeless decision theory perspective like send a massive signal to the galaxy...</span></p>\n<h2 style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 11.5px; font-family: ETBook, serif; font-weight: 400; line-height: 1.1; color: #000000; font-size: 30px;\"><span style=\"box-sizing: border-box;\">The Great Filter isn't magic</span></h2>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\"> It can all get very headache-inducing. But, just as&nbsp;<a href=\"https://www.lesserwrong.com/posts/NXcxKXLT8xng5FwDu/the-outside-view-isn-t-magic\">the Outside View isn't magic</a>, the Great Filter isn't magic either. If advanced civilizations destroy themselves before becoming space-faring or leaving an imprint on the galaxy, then there is some phenomena that is the cause of this. What can we say, if we look analytically at the great filter argument?</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">First of all suppose we had three theories - early great filter (technological civilizations are rare), late great filter (technological civilizations destroy themselves before becoming space-faring), or no great filter. Then we look up at the empty skies, and notice no aliens. This rules out the third theory, but leaves the relative probabilities of the other two intact.</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\"><span style=\"box-sizing: border-box;\">Then we can look at objective evidence. Is human technological civilization likely to end in a nuclear war? Possibly, but are the odds in the 99.999% range that would be needed to explain the Fermi Paradox? Every year that has gone by has reduced the likelihood that nuclear war is very very very very likely. So a late Great Filter may seemed quite probable compared with an early one, but much of the evidence we see is against it&nbsp;</span><span style=\"box-sizing: border-box;\"><span style=\"box-sizing: border-box;\"><span style=\"box-sizing: border-box;\">(especially if we assume that AI -&nbsp;<a href=\"/lw/kvm/the_great_filter_is_early_or_ai_is_hard/\"><em>which is not a Great Filter!</em></a>&nbsp;- might have been developed by now).</span></span>&nbsp;Million-to-one prior odds can be overcome by merely 20 bits of information.</span></span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">And what about the argument that we have to assume that prior civilizations would also have known of the Great Filter and thus we need to do more than they would have? In your estimation, is the world currently run by people taking the Great Filter arguments seriously? What is the probability that the world will be run by people that take the Great Filter argument seriously? If this probability is low, we don't need to worry about the recursive aspect; the ideal situation would be if we can achieve:</span></p>\n<ol style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 11.5px; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\">\n<li style=\"box-sizing: border-box;\">\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem;\"><span style=\"box-sizing: border-box;\">Powerful people taking the Great Filter argument seriously.</span></p>\n</li>\n<li style=\"box-sizing: border-box;\">\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem;\"><span style=\"box-sizing: border-box;\">Evidence that it was hard to make powerful people take the argument seriously.</span></p>\n</li>\n</ol>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">Of course, successfully achieving 1 is evidence against 2, but the Great Filter doesn't work by magic. If it looks like we achieved something really hard, then that's some evidence that it is hard. Every time we find something unlikely with a late Great Filter, that shifts some of the probability mass away from the late great filter and into alternative hypotheses (early Great Filter, zoo hypothesis,...).</span></p>\n<h2 style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 11.5px; font-family: ETBook, serif; font-weight: 400; line-height: 1.1; color: #000000; font-size: 30px;\"><span style=\"box-sizing: border-box;\">Variance and error of xrisk estimates</span></h2>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">But let's focus narrowly on the probability of the late Great Filter.</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">Current&nbsp;<a href=\"http://sethbaum.com/ac/2013_NuclearWar.pdf\">estimates for the risk of nuclear war</a>&nbsp;are uncertain, but let's arbitrarily assume that the risk is 10% (overall, not per year). Suppose one of two papers comes out:</span></p>\n<ol style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 11.5px; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\">\n<li style=\"box-sizing: border-box;\">\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem;\"><span style=\"box-sizing: border-box;\">Paper A shows that current estimates of nuclear war have not accounted for a lot of key facts; when these facts are added in, the risk of nuclear war drops to 5%.</span></p>\n</li>\n<li style=\"box-sizing: border-box;\">\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem;\"><span style=\"box-sizing: border-box;\">Paper B is a massive model of international relationships with a ton of data and excellent predictors and multiple lines of evidence, all pointing towards the real risk being 20%.</span></p>\n</li>\n</ol>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">What would either paper mean from the Great Filter perspective? Well, counter-intuitively, papers like A typically increase the probability for nuclear war being a Great Filter, while papers like B decrease it. This is because none of 5%, 10%, and 20% are large enough to account for the Great Filter, which requires probabilities in the 99.99% style. And, though paper A decreases the probability of the nuclear war, it also leaves more room for uncertainties - we've seen that a lot of key facts were missing in previous papers, so it's plausible that there are key facts still missing from this one. On the other hand, though paper B increases the probability, it makes it unlikely that the probability will be raised any further.</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; color: rgba(0, 0, 0, 0.87); font-family: ETBook, serif; font-size: 13px;\"><span style=\"box-sizing: border-box;\">So if we fear the Great Filter, we should not look at risks whose probabilities are high, but risks who's uncertainty is high, where the probability of us making an error is high. If we consider our future probability estimates as a random variable, then the one whose variance is higher is the one to fear. So a late Great Filter would make biotech risks even worse (current estimates of risk are poor) while not really changing asteroid impact risks (current estimates of risk are good).</span></p>",
    "user": {
      "username": "Stuart_Armstrong",
      "slug": "stuart_armstrong",
      "displayName": "Stuart_Armstrong"
    }
  },
  {
    "_id": "xgQvKKAf2vFfCDeaw",
    "title": "The Outside View isn't magic",
    "slug": "the-outside-view-isn-t-magic",
    "pageUrl": "https://www.lesswrong.com/posts/xgQvKKAf2vFfCDeaw/the-outside-view-isn-t-magic",
    "postedAt": "2017-09-27T14:37:16.881Z",
    "baseScore": 12,
    "voteCount": 6,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><em><a href=\"https://www.lesserwrong.com/posts/NXcxKXLT8xng5FwDu/the-outside-view-isn-t-magic\">Crossposted</a> at Less Wrong 2.0.</em></p>\n<p>The <a href=\"https://en.wikipedia.org/wiki/Planning_fallacy\">planning fallacy</a> is an almost perfect example of the strength of using the <a href=\"https://wiki.lesswrong.com/wiki/Outside_view\">outside</a>&nbsp;<a href=\"http://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/daniel-kahneman-beware-the-inside-view\">view</a>. When asked to predict the time taken for a project that they are involved in, people tend to underestimate the time needed (in fact, they tend to predict as if question was how long things would take <em>if everything went perfectly</em>).</p>\n<p>Simply telling people about the planning fallacy doesn't seem to make it go away. So the outside view argument is that you need to put your project&nbsp;into the \"reference class\" of other projects, and expect time overruns as compared to your usual, \"inside view\" estimates (which focus on the details you know about the project.</p>\n<p>So, for the outside view, what is the best way of estimating the time of a project? Well, to find the right reference class for it: the right category of projects to compare it with. You can compare the project with others that have similar features - number of people, budget, objective desired, incentive structure, inside view estimate of time taken etc... - and then derive a time estimate for the project that way.</p>\n<p>That's the outside view. But to me, it looks a lot like... induction. In fact, it looks a lot like the elements of a linear (or non-linear) regression. We can put those features (at least the quantifiable ones) into a linear regression with a lot of data about projects, shake it all about, and come up with regression coefficients.</p>\n<p>At that point, we are left with a decent project timeline prediction model, and another example of human bias. The fact that humans often perform badly in prediction tasks is not exactly new - see for instance my <a href=\"/lw/keq/the_silos_of_expertise_beyond_heuristics_and/\">short</a> <a href=\"https://www.dropbox.com/s/900skec2bkjtupg/Expertise_literature_review.xlsx?dl=0\">review</a> on the academic research on expertise.</p>\n<p>So what exactly is the outside view doing in all this?</p>\n<p>&nbsp;</p>\n<h2>The role of the outside view: model incomplete and bias human</h2>\n<p>The main use of the outside view, for humans, seems to be to point out either an incompleteness in the model or a human bias. The planning fallacy has both of these: if you did a linear regression comparing your project with all projects with similar features, you'd notice your inside estimate was more optimistic than the regression - your inside model is incomplete. And if you also compared each person's initial estimate with the ultimate duration of their project, you'd notice a systematically optimistic bias - you'd notice the planning fallacy.</p>\n<p>The first type of errors tend to go away with time, if the situation is encountered regularly, as people refine models, add variables, and test them on the data. But the second type remains, as human biases are rarely cleared by mere data.</p>\n<p>&nbsp;</p>\n<h2>Reference class tennis</h2>\n<p>If use of the outside view is disputed, it often develops into a case of reference class tennis - where people with opposing sides insist or deny that a certain example belongs in the reference class (similarly to how, in politics, anything positive is claimed for your side and anything negative assigned to the other side).</p>\n<p>But once the phenomena you're addressing has an explanatory model, there are no issues of reference class tennis any more. Consider for instance <a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\">Goodhart's law</a>: \"When a measure becomes a target, it ceases to be a good measure\". A law that should be remembered by any minister of education wanting to reward schools according to improvements to their test scores.</p>\n<p>This is a typical use of the outside view: if you'd just thought about the system in terms of inside facts - tests are correlated with child performance; schools can improve child performance; we can mandate that test results go up - then you'd have missed several crucial facts.</p>\n<p>But notice that nothing mysterious is going on. We understand exactly what's happening here: schools have ways of upping test scores without upping child performance, and so they decided to do that, weakening the correlation between score and performance. Similar things happen in the failures of command economies; but again, once our model is broad enough to encompass enough factors, we get decent explanations, and there's no need for further outside views.</p>\n<p>In fact, we know enough that we can show when Goodhart's law fails: when no-one with incentives to game the measure has control of the measure. This is one of the reasons central bank interest rate setting has been so successful. If you order a thousand factories to produce shoes, and reward the managers of each factory for the number of shoes produced, you're heading to disaster. But consider GDP. Say the central bank wants to increase GDP by a certain amount, by fiddling with interest rates. Now, as a shoe factory manager, I might have preferences about the direction of interest rates, and my sales are a contributor to GDP. But they are a tiny contributor. It is not in my interest to manipulate my sales figures, in the vague hope that, aggregated across the economy, this will falsify GDP and change the central bank's policy. The reward is too diluted, and would require coordination with many other agents (and coordination is hard).</p>\n<p>Thus if you're engaging in reference class tennis, remember the objective is to find a model with enough variables, and enough data, so that there is no more room for the outside view -&nbsp;a fully understood Goodhart's law rather than just a law.</p>\n<p>&nbsp;</p>\n<h2>In the absence of a successful model</h2>\n<p>Sometimes you can have a strong trend without a compelling model. Take <a href=\"https://en.wikipedia.org/wiki/Moore%27s_law\">Moore's law</a>, for instance. It is extremely strong, going back decades, and surviving multiple changes in chip technology.&nbsp;But it has no clear cause.</p>\n<p>A few explanations have been proposed. Maybe it's a consequence of its own success, of chip companies using it to set their goals. Maybe there's some natural exponential rate of improvement in any low-friction feature of a market economy. Exponential-type growth in the short term is no surprise - that just means growth in proportional to investment - so maybe it was an amalgamation of various short term trends.</p>\n<p>Do those explanations sound unlikely? Possibly, but there is a <em>huge trend in computer chips going back decades</em>&nbsp;that needs to be explained. They are unlikely, but they have to be weighed against the unlikeliness of the situation. The most plausible explanation is a combination of the above and maybe some factors we haven't thought of yet.</p>\n<p>But here's an explanation that is implausible: little time-travelling angels modify the chips so that they follow Moore's law. It's a silly example, but it shows that not all explanations are created equal, even for phenomena that are not fully understood. In fact there are four broad categories of explanations for putative phenomena that don't have a compelling model:</p>\n<ol>\n<li>Unlikely but somewhat plausible explanations.</li>\n<li>We don't have an explanation yet, but we think it's likely that there is an explanation.</li>\n<li>The phenomenon is a coincidence.</li>\n<li>Any explanation would go against stuff that we do know, and would be less likely than coincidence.</li>\n</ol>\n<p>The explanations I've presented for Moore's law fall into category 1. Even if we hadn't thought of those explanations, Moore's law would fall into category 2, because of the depth of evidence for Moore's law and because a \"medium length regular technology trend within a broad but specific category\" is something that has is intrinsically likely to have an explanation.</p>\n<p>Compare with Kurzweil's \"law of time and chaos\" (a generalisation of his \"law of accelerating returns\") and Robin Hanson's model where the development of human brains, hunting, agriculture and the industrial revolution are all points on a trend leading to uploads. I discussed these in a <a href=\"/lw/ea8/counterfactual_resiliency_test_for_noncausal/\">previous post</a>, but I can now better articulate the problem with them.</p>\n<p>Firstly, they rely on very few data points (the more recent part of Kurzweil's law, the part about recent technological trends, has a lot of data, but the earlier part does not). This raises the probability that they are a mere coincidence (we should also consider selection bias in choosing the data points, which increases the probability of coincidence). Secondly, we have strong reasons to suspect that there won't be any explanation that ties together things like the early evolution of life on Earth, human brain evolution, the agricultural revolution, the industrial revolution, and future technology development. These phenomena have decent local explanations that we already roughly understand (local in time and space to the phenomena described), and these run counter to any explanation that would tie them together.</p>\n<p>&nbsp;</p>\n<h2>Human biases and predictions</h2>\n<p>There is one area where the outside view can still function for multiple phenomena across different eras: when it comes to pointing out human biases. For example, we know that doctors have been authoritative, educated, informed, and useless for most of human history (or possibly much worse than useless). Hence authoritative, educated, and informed statements or people are not to be considered of any value, unless there is some evidence the statement or person is truth tracking. We now have things like expertise research, some primitive betting markets, and track records to try and estimate their experience; these can provide good \"outside views\".</p>\n<p>And the authors of the models of the previous section have some valid points where bias is concerned. Kurzweil's point that (paraphrasing) \"things can happen a lot faster than some people think\" is valid: we can compare predictions with outcomes. Robin has similar valid points in defense of the possibility of the em scenario.</p>\n<p>The reason these explanations are more likely valid is because they have a very probable underlying model/explanation: humans are biased.</p>\n<p>&nbsp;</p>\n<h2>Conclusions</h2>\n<ul>\n<li>The outside view is a good reminder for anyone who may be using too narrow a model.</li>\n<li>If the model explains the data well, then there is no need for further outside views.</li>\n<li>If there is a phenomena with data but no convincing model, we need to decide if it's a coincidence or there is an underlying explanation.</li>\n<li>Some phenomena have features that make it likely that there is an explanation, even if we haven't found it yet.</li>\n<li>Some phenomena have features that make it <em>unlikely</em> that there is an explanation, no matter how much we look.</li>\n<li>Outside view arguments that point at human prediction biases, however, can be generally valid, as they only require the explanation that humans are biased in that particular way.</li>\n</ul>",
    "user": {
      "username": "Stuart_Armstrong",
      "slug": "stuart_armstrong",
      "displayName": "Stuart_Armstrong"
    }
  },
  {
    "_id": "NXcxKXLT8xng5FwDu",
    "title": "The Outside View isn't magic",
    "slug": "the-outside-view-isn-t-magic",
    "pageUrl": "https://www.lesswrong.com/posts/NXcxKXLT8xng5FwDu/the-outside-view-isn-t-magic",
    "postedAt": "2017-09-27T14:33:28.308Z",
    "baseScore": 21,
    "voteCount": 19,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>The <a href=\"https://en.wikipedia.org/wiki/Planning_fallacy\">planning fallacy</a> is an almost perfect example of the strength of using the <a href=\"https://wiki.lesswrong.com/wiki/Outside_view\">outside</a> <a href=\"http://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/daniel-kahneman-beware-the-inside-view\">view</a>. When asked to predict the time taken for a project that they are involved in, people tend to underestimate the time needed (in fact, they tend to predict as if question was how long things would take <em>if everything went perfectly</em>).\r</p><p>\rSimply telling people about the planning fallacy doesn&#x27;t seem to make it go away. So the outside view argument is that you need to put your project into the &quot;reference class&quot; of other projects, and expect time overruns as compared to your usual, &quot;inside view&quot; estimates (which focus on the details you know about the project.\r</p><p>So, for the outside view, what is the best way of estimating the time of a project? Well, to find the right reference class for it: the right category of projects to compare it with. You can compare the project with others that have similar features - number of people, budget, objective desired, incentive structure, inside view estimate of time taken etc... - and then derive a time estimate for the project that way.\r</p><p>\rThat&#x27;s the outside view. But to me, it looks a lot like... induction. In fact, it looks a lot like the elements of a linear (or non-linear) regression. We can put those features (at least the quantifiable ones) into a linear regression with a lot of data about projects, shake it all about, and come up with regression coefficients.\r</p><p>\rAt that point, we are left with a decent project timeline prediction model, and another example of human bias. The fact that humans often perform badly in prediction tasks is not exactly new - see for instance my <a href=\"http://lesswrong.com/lw/keq/the_silos_of_expertise_beyond_heuristics_and/\">short</a> <a href=\"https://www.dropbox.com/s/900skec2bkjtupg/Expertise_literature_review.xlsx?dl=0\">review</a> on the academic research on expertise.\r</p><p>\rSo what exactly is the outside view doing in all this?\r</p><h2>\r\rThe role of the outside view: model incomplete and bias human\r</h2><p>\rThe main use of the outside view, for humans, seems to be to point out either an incompleteness in the model or a human bias. The planning fallacy has both of these: if you did a linear regression comparing your project with all projects with similar features, you&#x27;d notice your inside estimate was more optimistic than the regression - your inside model is incomplete. And if you also compared each person&#x27;s initial estimate with the ultimate duration of their project, you&#x27;d notice a systematically optimistic bias - you&#x27;d notice the planning fallacy.\r</p><p>\rThe first type of errors tend to go away with time, if the situation is encountered regularly, as people refine models, add variables, and test them on the data. But the second type remains, as human biases are rarely cleared by mere data.\r</p><h2>\r\rReference class tennis\r</h2><p>\rIf use of the outside view is disputed, it often develops into a case of reference class tennis - where people with opposing sides insist or deny that a certain example belongs in the reference class (similarly to how, in politics, anything positive is claimed for your side and anything negative assigned to the other side).\r</p><p>\rBut once the phenomena you&#x27;re addressing has an explanatory model, there are no issues of reference class tennis any more. Consider for instance <a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\">Goodhart&#x27;s law</a>: &quot;When a measure becomes a target, it ceases to be a good measure&quot;. A law that should be remembered by any minister of education wanting to reward schools according to improvements to their test scores.\r</p><p>\rThis is a typical use of the outside view: if you&#x27;d just thought about the system in terms of inside facts - tests are correlated with child performance; schools can improve child performance; we can mandate that test results go up - then you&#x27;d have missed several crucial facts.\r</p><p>\rBut notice that nothing mysterious is going on. We understand exactly what&#x27;s happening here: schools have ways of upping test scores without upping child performance, and so they decided to do that, weakening the correlation between score and performance. Similar things happen in the failures of command economies; but again, once our model is broad enough to encompass enough factors, we get decent explanations, and there&#x27;s no need for further outside views.\r</p><p>\rIn fact, we know enough that we can show when Goodhart&#x27;s law fails: when no-one with incentives to game the measure has control of the measure. This is one of the reasons central bank interest rate setting has been so successful. If you order a thousand factories to produce shoes, and reward the managers of each factory for the number of shoes produced, you&#x27;re heading to disaster. But consider GDP. Say the central bank wants to increase GDP by a certain amount, by fiddling with interest rates. Now, as a shoe factory manager, I might have preferences about the direction of interest rates, and my sales <em>are </em>a contributor to GDP. But they are a tiny contributor. It is not in my interest to manipulate my sales figures, in the vague hope that, aggregated across the economy, this will falsify GDP and change the central bank&#x27;s policy. The reward is too diluted, and would require coordination with many other agents (and coordination is hard).\r</p><p>\rThus if you&#x27;re engaging in reference class tennis, remember the objective is to find a model with enough variables, and enough data, so that there is no more room for the outside view - a fully understood Goodhart&#x27;s law rather than just a law.</p><h2>\r\rIn the absence of a successful model\r</h2><p>\rSometimes you can have a strong trend without a compelling model. Take <a href=\"https://en.wikipedia.org/wiki/Moore%27s_law\">Moore&#x27;s law</a>, for instance. It is extremely strong, going back decades, and surviving multiple changes in chip technology.\r But it has no clear cause.</p><p>\rA few explanations have been proposed. Maybe it&#x27;s a consequence of its own success, of chip companies using it to set their goals. Maybe there&#x27;s some natural exponential rate of improvement in any low-friction feature of a market economy. Exponential-type growth in the short term is no surprise - that just means growth in proportional to investment - so maybe it was an amalgamation of various short term trends.\r</p><p>\rDo those explanations sound unlikely? Possibly, but there is a <em>huge trend in computer chips going back decades</em> that needs to be explained. They are unlikely, but they have to be weighed against the unlikeliness of the situation. The most plausible explanation is a combination of the above and maybe some factors we haven&#x27;t thought of yet.\r</p><p>\rBut here&#x27;s an explanation that is implausible: little time-travelling angels modify the chips so that they follow Moore&#x27;s law. It&#x27;s a silly example, but it shows that not all explanations are created equal, even for phenomena that are not fully understood. In fact there are four broad categories of explanations for putative phenomena that don&#x27;t have a compelling model:\r</p><ol><li><p>\rUnlikely but somewhat plausible explanations.\r</p></li><li><p>We don&#x27;t have an explanation yet, but we think it&#x27;s likely that there is an explanation.\r</p></li><li><p>The phenomenon is a coincidence.\r</p></li><li><p>Any explanation would go against stuff that we do know, and would be less likely than coincidence.\r</p></li></ol><p>The explanations I&#x27;ve presented for Moore&#x27;s law fall into category 1. Even if we hadn&#x27;t thought of those explanations, Moore&#x27;s law would fall into category 2, because of the depth of evidence for Moore&#x27;s law and because a &quot;medium length regular technology trend within a broad but specific category&quot; is something that has is intrinsically likely to have an explanation.\r</p><p>\rCompare with Kurzweil&#x27;s &quot;law of time and chaos&quot; (a generalisation of his &quot;law of accelerating returns&quot;) and Robin Hanson&#x27;s model where the development of human brains, hunting, agriculture and the industrial revolution are all points on a trend leading to uploads. I discussed these in a <a href=\"http://lesswrong.com/lw/ea8/counterfactual_resiliency_test_for_noncausal/\">previous post</a>, but I can now better articulate the problem with them.\r</p><p>\rFirstly, they rely on very few data points (the more recent part of Kurzweil&#x27;s law, the part about recent technological trends, has a lot of data, but the earlier part does not). This raises the probability that they are a mere coincidence (we should also consider selection bias in choosing the data points, which increases the probability of coincidence). Secondly, we have strong reasons to suspect that there won&#x27;t be any explanation that ties together things like the early evolution of life on Earth, human brain evolution, the agricultural revolution, the industrial revolution, and future technology development. These phenomena have decent local explanations that we already roughly understand (local in time and space to the phenomena described), and these run counter to any explanation that would tie them together.\r</p><h2>\r\rHuman biases and predictions\r</h2><p>\rThere is one area where the outside view can still function for multiple phenomena across different eras: when it comes to pointing out human biases. For example, we know that doctors have been authoritative, educated, informed, and useless for most of human history (or possibly much worse than useless). Hence authoritative, educated, and informed statements or people are not to be considered of any value, unless there is some evidence the statement or person is truth tracking. We now have things like expertise research, some primitive betting markets, and track records to try and estimate their experience; these can provide good &quot;outside views&quot;.\r</p><p>\rAnd the authors of the models of the previous section have some valid points where bias is concerned. Kurzweil&#x27;s point that (paraphrasing) &quot;things can happen a lot faster than some people think&quot; is valid: we can compare predictions with outcomes. Robin has similar valid points in defense of the possibility of the em scenario.\r</p><p>\rThe reason these explanations are more likely valid is because they have a very probable underlying model/explanation: humans are biased.\r</p><h2>\rConclusion\rs</h2><ul><li><p>\rThe outside view is a good reminder for anyone who may be using too narrow a model.\r</p></li><li><p>If the model explains the data well, then there is no need for further outside views.\r</p></li><li><p>If there is a phenomena with data but no convincing model, we need to decide if it&#x27;s a coincidence or there is an underlying explanation.\r</p></li><li><p>Some phenomena have features that make it likely that there is an explanation, even if we haven&#x27;t found it yet.\r</p></li><li><p>Some phenomena have features that make it unlikely that there is an explanation, no matter how much we look.\r</p></li><li><p>Outside view arguments that point at human prediction biases, however, can be generally valid, as they only require the explanation that humans are biased in that particular way.</p></li></ul></div></div></div></div>",
    "user": {
      "username": "Stuart_Armstrong",
      "slug": "stuart_armstrong",
      "displayName": "Stuart_Armstrong"
    }
  },
  {
    "_id": "GtmyejahnBeyzkSQh",
    "title": "Tests make creating AI hard",
    "slug": "tests-make-creating-ai-hard",
    "pageUrl": "https://www.lesswrong.com/posts/GtmyejahnBeyzkSQh/tests-make-creating-ai-hard",
    "postedAt": "2017-09-27T12:03:52.447Z",
    "baseScore": -1,
    "voteCount": 2,
    "commentCount": 14,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>In my <a href=\"https://www.lesserwrong.com/posts/YJHnbrX5dthT7Mpmz/an-incentive-structure-that-might-not-suck-too-much/mt7x968ajPvZhx2yx\">post on incentive structures</a> I gave an potted summary of how to do incentive structures better when what you are trying to achieve is ill defined,</p><blockquote><p> Improve Models using Measures, use the Model to update Targets. </p></blockquote><p>I would add, </p><blockquote><p> Try to hit Targets. Avoid Tests.</p></blockquote><p>In this post I will recap what I mean by the above, give an abridged history of the field of AI and how it has failed to follow this maxim well and what following it might have looked like.</p><p>If we want to create safe AI we need good incentive structures for the people researching it, we need to get good at this.</p><h4>Recap</h4><p>A Model is your causal view of the thing you are trying to achieve. A Measure is something you can apply to your system to let you know if you are going in the right direction. Targets are things you are trying to do in the world. A Test in this formalism is something that is a Measure and Target all in one, you don&#x27;t need a Model, if you do well at the Test you are doing well.</p><p>One of the key differences between a Measure and Test, if you do better than a Model predicts on a Measure you should change your Model (and maybe change your Target). If you do better than you expect on a Test, there is no need to change anything.</p><h3>Measure 1: The Turing test </h3><p>The most famous measure in AI is the <a href=\"https://en.wikipedia.org/wiki/Turing_test\">Turing test</a>. </p><blockquote><p>[it] is a test of a machine&#x27;s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. Turing proposed that a human evaluator would judge natural language conversations between a human and a machine designed to generate human-like responses. The evaluator would be aware that one of the two partners in conversation is a machine, and all participants would be separated from one another. </p></blockquote><p>From this we got the <a href=\"http://www.loebner.net/Prizef/loebner-prize.html\">Loebner prize. This in turn has </a>led to profusion of chat bots like <a href=\"http://www.worldsbestchatbot.com/The_Loebner_Prize\">this one.</a> It might entertain the judges and give them a moments pause to try and figure out whether it is a human or not, but you can&#x27;t get much real work out of it. It can&#x27;t do maths, run a business or teach kids. It is a product of taking the Measure as a Test. <br/><br/>However it is still a good Measure: if something really passed it we would expect it to be intelligent.</p><h3>Measure 2: Image net </h3><p>This is not supposed to be a test of full intelligence, but how well an algorithm <a href=\"http://www.image-net.org/challenges/LSVRC/\">detects object in images</a> . While it is creating algorithms that do better and better at this all the time, it seems unlikely that it is getting close to how humans do object recognition. </p><p>For example the algorithms aren&#x27;t being designed to  take hints about what is in an image to help it locate the object, because that is not what they are being tested for. Why might you want to do so? Because there are lots of good examples humans being able to process these hints. This seems like a useful thing to do.  You can experience the power of &quot;hint taking&quot; first hand, if you read this <a href=\"http://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/\">slatestarcodex article</a>.  </p><p>If your Measure and your Target is static, you are just trying to make a slightly better algorithm that does better at these Tests.  You are not going to change your Model  of image recognition to be able to incorporate other types of data, like &quot;hints&quot;.<br/></p><h3>Breaking the Test cycle</h3><p>So we are in general teaching our system to the tests. And when the the Tests are iterated upon (because they don&#x27;t get what people actually want), the people trying to iterate the Tests get accused of moving the goal posts. There is even a name for it, the <a href=\"https://en.wikipedia.org/wiki/AI_effect\">AI effect. </a> <br/><br/>If we are to get safe general AI or IA we need to break this cycle. <br/>We need a Model of what intelligence is and iterate on that, so that we can get different Targets. Not naively try to meet the Tests better or add more and more Tests. <br/></p><p>I obviously think separating Measures and Metrics will help us with making safe AI, so how can we </p><blockquote><p>Improve Models using the Measure, use the Model to update Targets. Hit Targets, Avoid Tests.</p></blockquote><p>The following an illustrative alternative history about the development AI could&#x27;ve gone gone if we had better separated our Targets from our Measures. It will be described by a series of rounds. Each round will have an assumed Model, a Target to try and create due to that model, the Measure (in this case the Turing test, but you could have more measures) and a result of having performed that measurement. There will also be a failure mode to avoid in the round.</p><p>Round 1:</p><p>Model: Let us start with a model of human conversation as a fixed input/output mapping, for simplicity&#x27;s sake.</p><p>Target: Create a mapping of input to output that is nice to talk to.<br/>Measure: Use the turing test as a measure. </p><p>Result: This isn&#x27;t very good to talk to. It is the same every time. Humans aren&#x27;t the same every time. Update the model of an intelligence so that it isn&#x27;t seen as a fixed mapping.</p><p>Failure mode: Create ever more elaborate mappings from input to output, include previous parts of the conversation in the input.</p><p>Round 2</p><p>Update Model: Humans seem to learn over time. So let us assume an intelligence also learns. </p><p>Target: Create a machine learning system that tries to find a mapping from input to output from data.  Provide the system with the data from previous conversations and how well the judges like those conversations. So that it can update it&#x27;s mapping from input to output.</p><p>Measure: Use the turing test as a measure. </p><p>Result: It was pleasant to talk to but one judge tried to teach it simple mathematics (adding two numbers together) and it failed. There is no way our current model of an intelligence could learn mathematics in a single conversation.</p><p>Failure Mode: Throw more and more data and processing power at it, creating ever more complex mappings</p><p>Round 3</p><p>Update Model: Humans seem to be able to treat natural language as programs to be interpreted and compiled. They learn languages by this using large amounts of data, but they also use language to help learn other bits of language.</p><p>Target: Create some system that can discern good programs from bad programs, then put programs in it that try to compile human language into novel programs. Also have programs that search for novel patterns in the input language and tries to hook them up to code generation.</p><p>Measure: Use the turing test as a measure.</p><p>Result:??</p><h3>Conclusion</h3><p>I hope I have shown you how the maxim might be useful for thinking about incentive structures for solving a complex problem that we don&#x27;t quite understand what we are aiming for.  While this is just my initial Model of what we should do for incentive structures for human researchers, it is very important to get right (as it could be used inside AI as well as how to build it). <br/>So to move forward on the intelligence problem we need to create the best model of intelligence we can, so we can find targets. I think I have one (Round 3), but I would I love to get more input into it.<br/><br/>It would also be interesting to think about when having a Model would be a bad idea and it would better to just use Tests. There are probably some circumstances.</p></div></div></div></div>",
    "user": null
  },
  {
    "_id": "rhJ75a6FqwtAxXTP9",
    "title": "Stupid Questions - September 2017",
    "slug": "stupid-questions-september-2017",
    "pageUrl": "https://www.lesswrong.com/posts/rhJ75a6FqwtAxXTP9/stupid-questions-september-2017",
    "postedAt": "2017-09-27T09:51:54.246Z",
    "baseScore": 9,
    "voteCount": 8,
    "commentCount": 25,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>The stupid questions thread was one of the regular threads on LessWrong. It&#x27;s a place where no question is to stupid to be asked and anybody who answers is encouraged to be kind.</p><p>This thread is for asking any questions that might seem obvious, tangential, silly or what-have-you. Don&#x27;t be shy, everyone has holes in their knowledge, though the fewer and the smaller we can make them, the better.\r</p><p>Please be respectful of other people&#x27;s admitting ignorance and don&#x27;t mock them for it, as they&#x27;re doing a noble thing.\r</p></div></div></div></div>",
    "user": {
      "username": "ChristianKl",
      "slug": "christiankl",
      "displayName": "ChristianKl"
    }
  },
  {
    "_id": "p7hW7E3fHF3PDzErk",
    "title": "Sabbath hard and go home",
    "slug": "sabbath-hard-and-go-home",
    "pageUrl": "https://www.lesswrong.com/posts/p7hW7E3fHF3PDzErk/sabbath-hard-and-go-home",
    "postedAt": "2017-09-27T07:49:40.482Z",
    "baseScore": 101,
    "voteCount": 74,
    "commentCount": 15,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Growing up Jewish, I thought that the traditional rules around the Sabbath were silly. Then I forgot to bring a spare battery on a camping trip. Now I think that something like the traditional Jewish Sabbath is an important cultural adaptation to preserve leisure, that would otherwise be destroyed in an urbanized, technological civilization.</p><h2>Sabbath as easy mode</h2><p>As a child, I first learned that the Sabbath was a “day of rest,” a day on which you don’t do “work.” I was brought up by liberal Jews in a society in which “work” tends to mean either business or wage labor. Things you do for <em>money</em>. Things you do because someone else demands them. This is for the most part how we observed the Sabbath.</p><p>But I was also taught about the older traditions in which many <a href=\"http://www.chabad.org/library/article_cdo/aid/102032/jewish/The-39-Melachot.htm\">categories of mundane activity</a> are forbidden: lighting a fire, cutting or mending cloth, writing or erasing letters. This seemed to me like an arbitrary superstition based on an excessive literality. Surely I could tell for myself whether I was writing as part of a leisure activity or a desk job. Surely I could tell for myself whether I was planting seeds for my private garden, or on a commercial farm. Why avoid these activities in the privacy of one’s own home, doing things for oneself, and not <em>working</em> at all?</p><p>Likewise, Orthodox Jews must walk to and from their synagogue on the Sabbath, because driving would involve lighting a fire. Automobile engines run on combustion, after all. Liberal Jews often argued, if there is inclement weather, or if the synagogue is far, is it not more <em>restful</em> to take an easy drive than to walk?</p><p>In short, I thought that the rest of the Sabbath meant, or ought to mean, <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">playing life on easy mode</a>.</p><h2>Unplugging as leisure</h2><p>Recently, I’ve been feeling too caught up in local social momentum. When it looked like it would be difficult and take a long time to <a href=\"http://benjaminrosshoffman.com/request-cabin/\">book a cabin</a> to spend some time alone, I asked a friend to teach me how to go camping, to improve my range of options for solitude, both by directly giving me the affordance for camping, and by more generally expanding the range of living conditions I had experience coping with.</p><p>On my first solo two-night camping trip, I forgot to bring a backup battery to charge my laptop or phone. I was car camping, so I could have charged them that way, but I felt like that was outside the spirit of the exercise, and inconvenient anyway. So instead, I mostly kept my phone turned off. Very quickly, I started being able to <em>think</em> about aspects of my situation that had been too overwhelming, too <em>in motion</em>,  to get leverage on the day before. Because I wasn’t <em>dealing with them</em>. I wasn’t <em>keeping up</em> with anything. I was just present, where I was. I wished I’d done this years ago.</p><p>And then I realized: if I had keeping a Sabbath, it wouldn’t have taken <em>years</em> to take a step back from social momentum. I’d have gotten a chance within seven days of noticing that there was a problem. And seven days later, another chance, and so on.</p><p>Immediately, came the reflexive follow-up thought: of course, not the literal Orthodox Jewish Sabbath. But then I asked my self: why not, exactly?</p><p>I went through some of the more onerous-seeming requirements. You are not permitted to write. But when I <a href=\"http://benjaminrosshoffman.com/review-vipassana-center-silent-meditation-retreat/\">went on a meditation retreat</a>, they <em>also</em> asked us not to write. And I had no problem with that. It did not seem like an arbitrary superstition to me; it seemed like part of the discipline of an integrated mental practice.</p><p>Maybe the Sabbath too is a discipline meant to cultivate a particular sort of mental practice.</p><p>You are not allowed to light fires on the Sabbath, which means no cooking; you eat what has been prepared in advance. On that same meditation retreat, we were asked not to bring or prepare our own food, but to accept what was served to us. That too felt like a natural part of the practice.</p><p>Why had I been so ready to dismiss the Sabbath out of hand? Where did this prejudice come from? It came from my childhood self, who was <em>assuming alienation of labor</em>.</p><h2>Work as keeping up</h2><p>If you do not assume like a modern consumerist that <em>work</em> is what you do <em>for money</em>, and <em>leisure</em> is what you <em>spend money</em> on, then what is work? It is the activity of producing or maintaining the artifacts necessary for the ongoing production of sustenance. It is the activity of keeping up with reality. And in a civilized society with specialization of labor, where your work is only productive because it is integrated with the work of many others, work is the practice of keeping up with the predominant social reality.</p><p>What is leisure, then? Leisure is time when you are not responding to a persistent stream of demands. Not your boss, but not a television commercial or newsfeed either. You can take a walk, or sit silently with friends, and let your mind wander.</p><p>Leisure is crucial for a very particular sort of freedom. Not freedom as the range of options presented to you, or the absence of overt restrictions on your behavior, but the amount of autonomy you have in practice, the extent to which the choices you are making are determined by the combination of your own preferences and foresight, rather than the result of being led down a path of someone else’s design.</p><p>The distinction between this sort of work and leisure is not a perfect match to the Sabbath prohibitions.</p><p>You can read a book on the Sabbath (which was not allowed at the meditation retreat), and engage with your whole mind, so long as you do not take notes. So long as you do not try to produce some useful artifact, for your future self to pick up and run with.</p><p>You can also talk. Jews do not engage in Noble Silence on the Sabbath; it is not a day of silence. But it cuts out some of the more cognitively costly practices of daily life.</p><h2>Sabbath as hard mode</h2><p>Some automation plans make sure to include what they call a human in the loop - on some level of abstraction, every decision is reviewed by a human. You can think of the Sabbath as playing life on <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">hard mode</a> in order to make sure that there is a human in your loop.</p><p>You would not want to do this sort of thing all the time. But it might make sense to do periodically - perhaps once a week - as a stopgap measure to combat attention drift. If powerful and pervasive cultural forces are <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook-comparison-to-alternatives-and-call-to-action/\">out to get you</a>, you ought to check in from time to time with yourself, and other people with whom you have local, high-quality relationships, to give yourself a chance to notice whether you have <a href=\"https://thezvi.wordpress.com/2017/09/23/out-to-get-you/\">gotten got</a> for too much.</p><p>Daily meditation or reflection practice has something to offer on this front. So does the Quaker practice of silent worship. And so does the Jewish Sabbath.</p><h2>Sabbath as alarm</h2><p>One more useful attribute of the Jewish Sabbath is the extent to which its rigid rules generate friction in emergency situations. If your community center is not within walking distance, if there is not enough slack in your schedule to prep things a day in advance, or you are too poor to go a day without work, or too locally isolated to last a day without broadcast entertainment, then <em>things are not okay</em>.</p><p>In our commercialized society, there will be many opportunities to purchase palliatives, and these palliatives are often worth purchasing. If living close to your place of employment would be ruinously expensive, you drive or take public transit. If you don’t have time to feed yourself, you can buy some fast food. If you’re not up for talking with a friend in person, or don’t have the time, there’s Facebook. But this is palliative care for a chronic problem.</p><p>In Jewish law, it is permissible to break the Sabbath in an emergency situation, when lives are at stake. If something like the Orthodox Sabbath seems impossibly hard, or if you try to keep it but end up breaking it every week - as my Reform Jewish family did - then you should consider that perhaps, despite the propaganda of the palliatives, <em>you are in a permanent state of emergency</em>. This is not okay. You are not doing okay.</p><p>So, how are you?</p>",
    "user": {
      "username": "Benquo",
      "slug": "benquo",
      "displayName": "Benquo"
    }
  },
  {
    "_id": "PYeR9cMaoekCcvo99",
    "title": "The Iron Law of Evaluation and Other Metallic Rules.",
    "slug": "the-iron-law-of-evaluation-and-other-metallic-rules",
    "pageUrl": "https://www.lesswrong.com/posts/PYeR9cMaoekCcvo99/the-iron-law-of-evaluation-and-other-metallic-rules",
    "postedAt": "2017-09-27T03:11:13.064Z",
    "baseScore": 7,
    "voteCount": 4,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "https://www.gwern.net/docs/sociology/1987-rossi",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Gwern talks about the reasons why most policies that have been evaluated don&#x27;t actually improve sociological problems. (poverty, dependency, mental illness, crime) I find it surprising they don&#x27;t hurt either. Gwern hypothesizes that it might be sample bias or maybe the forces underlying these problems are more powerful than the current capabilities of our institutions to handle. (eg. age? genetics?). <br/><br/>It&#x27;s pretty unsatisfying. I hear that giving aid to the poor is treating symptoms not underlying causes, but we may not actually know the underlying causes to begin with. I want to say maybe spend more money on sociological research instead of services to the poor? Is that just yet another untested &quot;clearly obvious&quot; mass sociological policy?</p></div></div></div></div>",
    "user": {
      "username": "panickedapricott",
      "slug": "panickedapricott",
      "displayName": "panickedapricott"
    }
  },
  {
    "_id": "KBvAYCQ4qhZCcMT6v",
    "title": "Economics of AI conference from NBER",
    "slug": "economics-of-ai-conference-from-nber",
    "pageUrl": "https://www.lesswrong.com/posts/KBvAYCQ4qhZCcMT6v/economics-of-ai-conference-from-nber",
    "postedAt": "2017-09-27T01:45:49.392Z",
    "baseScore": 2,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>\n<ul>\n<li>Papers:&nbsp;http://papers.nber.org/sched/AIf17</li>\n<li>Videos and slides:&nbsp;https://www.economicsofai.com/nber-conference-toronto-2017/</li>\n</ul>\n</p>\n<p>The speaker list (including presenters and moderators) includes many prominent names in the economics world, including:</p>\n<p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Daniel_Kahneman\">Daniel Kahneman</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Erik_Brynjolfsson\">Erik Brynjolfsson</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Carl_Shapiro\">Carl Shapiro</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Hal_Varian\">Hal Varian</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Susan_Athey\">Susan Athey</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Lawrence_Summers\">Larry Summers</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Austan_Goolsbee\">Austan Goolsbee</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/David_Autor\">David Autor</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Paul_Milgrom\">Paul Milgrom</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Jeffrey_Sachs\">Jeffrey Sachs</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Rebecca_M._Henderson\">Rebecca Henderson</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Joseph_Stiglitz\">Joseph Stiglitz</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Betsey_Stevenson\">Betsey Stevenson</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Tyler_Cowen\">Tyler Cowen</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Joel_Mokyr\">Joel Mokyr</a></li>\n</ul>\n</p>\n<p>And others with whom you might be more familiar than I.</p>\n<p>H/T <a href=\"http://marginalrevolution.com/marginalrevolution/2017/09/nber-conference-artificial-intelligence.html\">Marginal Revolution</a></p>",
    "user": {
      "username": "fortyeridania",
      "slug": "fortyeridania",
      "displayName": "fortyeridania"
    }
  },
  {
    "_id": "QjMrGoPycnprSBaLi",
    "title": "Unfair outcomes from fair tests",
    "slug": "unfair-outcomes-from-fair-tests",
    "pageUrl": "https://www.lesswrong.com/posts/QjMrGoPycnprSBaLi/unfair-outcomes-from-fair-tests",
    "postedAt": "2017-09-26T23:48:47.316Z",
    "baseScore": 4,
    "voteCount": 3,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "http://whaaales.com/unfair-outcomes-from-fair-tests/",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>[Summary: Say you use a fair test to predict a quality for which other non-tested factors matter, and then you make a decision based on this prediction. Then people who do worse on the test measure (but not necessarily the other factors) are subject to different error rates, even if you estimate their qualities just as well. If that’s already obvious, great; I additionally try to present the notion of fairness that lets one stop at “the test is fair; all is as it should be” as a somewhat arbitrary line to draw with respect to a broader class of notions of statistical fairness.] [Not sure if this text will appear anywhere in LW 2.0, so this is a test.]</p></div></div></div></div>",
    "user": {
      "username": "whales",
      "slug": "whales",
      "displayName": "whales"
    }
  },
  {
    "_id": "ghBZDavgywxXeqWSe",
    "title": "Wikipedia pageviews: still in decline",
    "slug": "wikipedia-pageviews-still-in-decline",
    "pageUrl": "https://www.lesswrong.com/posts/ghBZDavgywxXeqWSe/wikipedia-pageviews-still-in-decline",
    "postedAt": "2017-09-26T23:03:27.902Z",
    "baseScore": 25,
    "voteCount": 23,
    "commentCount": 20,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>In March 2015, I <a href=\"https://vipulnaik.com/blog/the-great-decline-in-wikipedia-pageviews-full-version/\">wrote</a> about a decline in Wikipedia desktop pageviews over the last few years (and posted a <a href=\"http://lesswrong.com/lw/lxc/the_great_decline_in_wikipedia_pageviews/\">short version</a> to LessWrong). With a lot of help from <a href=\"https://issarice.com\">Issa Rice</a> over the last year, and a lot more quality data, I&#x27;ve revisited the claims of that post.</p><p>This post provides a high-level summary of my takeaways. If enough people express interest in the comments, I intend to write up in more detail on the aspects that people express interest in. If I do a more detailed writeup, it will probably be in the latter half of 2018, giving enough additional data to evaluate how well the decline hypothesis holds up.</p><p>Here are the top-level conclusions.</p><ol><li><p>Have English desktop Wikipedia pageviews (i.e., pageviews of Wikipedia pages from desktop devices) actually declined?<br/>Short answer: Yes, they <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=en&amp;drilldown=all\">have declined</a> by over 50% since the peak between late 2012 and late 2013. Some supposedly timeless page types have declined <a href=\"https://wikipediaviews.org/displayviewsformultipletagsandmonths.php?tag=Sports&amp;allmonths=allmonths&amp;language=en&amp;drilldown=all\">by</a> <a href=\"https://wikipediaviews.org/displayviewsformultipletagsandmonths.php?tag=Mammals&amp;allmonths=allmonths&amp;language=en&amp;drilldown=all\">up</a> <a href=\"https://wikipediaviews.org/displayviewsformultipletagsandmonths.php?tag=Internet+protocols&amp;allmonths=allmonths&amp;language=en&amp;drilldown=all\">to</a> <a href=\"https://wikipediaviews.org/displayviewsformultipletagsandmonths.php?tag=Colors&amp;allmonths=allmonths&amp;language=en&amp;drilldown=all\">75-80%</a>. The effect of per-page decline is partly cancelled by <a href=\"https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia#Graphs_of_size_and_growth_rate\">increase in number of pages</a>.<br/>If I do a longer post, I&#x27;ll compare the time periods September to November 2012 against September to November 2017, and April to June 2013 against April to June 2018. Both are three-month periods, with equal representation of all days of week, the same time of the year, and with a separation of five years.</p></li><li><p>Why have English desktop pageviews declined?<br/>Short answer: Substitution to mobile could explain between 10 and 40 percentage points of the desktop decline. I personally gravitate to the lower end of the estimate range.<br/>Inclusion/exclusion of non-human traffic could explain between 5 and 20 percentage points of the decline.<br/><a href=\"https://blog.wikimedia.org/2015/06/12/securing-wikimedia-sites-with-https/\">Switch to HTTPS</a> and the block of Wikipedia in China explain a sharp mid-2015 decline, but use of Chinese Wikipedia (which should have been most affected) <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=zh&amp;drilldown=all\">has recovered</a>, and I expect the long-term effect to be close to zero. At most, it is 5 percentage points.<br/>The residual decline is between 0 and 20 percentage points, which, after rebasing, is between 0 and 40% for desktop. Two leading candidates to explain the residual are <em>increased reliance on social media</em> and <em>search engine algorithm changes</em>.</p></li><li><p>Have total (desktop + mobile) human English Wikipedia pageviews declined? Why?<br/>Short answer: Total (desktop + mobile) human pageviews <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=en&amp;drilldown=all\">likely peaked around late 2013</a>, and have declined by about 20% since then. Per-page pageviews have gone down significantly more for the page types that saw the biggest desktop declines. Effect of per-page decline is partly cancelled by increase in number of pages.<br/>Candidate explanations are the same as for (2): <em>increased reliance on social media</em> and <em>search engine algorithm changes</em>.</p></li><li><p>Is there a compensating increase in other language Wikipedias?<br/>Short answer: No. In fact, <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;languages[0]=en&amp;languages[1]=de&amp;languages[2]=ru&amp;languages[3]=es&amp;languages[4]=ja&amp;languages[5]=fr&amp;drilldown=desktop\">other top language Wikipedias</a> (<a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=de&amp;drilldown=all\">German</a>, <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=ru&amp;drilldown=all\">Russian</a>, <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=es&amp;drilldown=all\">Spanish</a>, <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=ja&amp;drilldown=all\">Japanese</a>, <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=fr&amp;drilldown=all\">French</a>) have a broadly similar decline trend as the English Wikipedia, both overall and per-page.<br/>Some minor language Wikipedias saw a huge proportional increase but not enough to compensate for the English Wikipedia decline. For instance, monthly Hindi Wikipedia mobile web pageviews <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;language=hi&amp;drilldown=all\">exploded</a> from about 1 million in early 2013 to over 30 million in 2017, which is peanuts compared to 3-4 billion monthly English desktop and English mobile web Wikipedia pageviews.<br/>The lowest-traffic language Wikipedias <a href=\"https://wikipediaviews.org/displayviewsformultiplemonths.php?page=%5Baggregate%5D&amp;allmonths=allmonths&amp;languages[0]=cho&amp;languages[1]=mh&amp;languages[2]=hz&amp;languages[3]=kj&amp;languages[4]=ho&amp;languages[5]=ii&amp;drilldowns[0]=desktop&amp;drilldowns[1]=mobile-web\">saw a huge proportional decline</a> in desktop and mobile web traffic in 2015, which is explained by bot filtering being activated.</p></li><li><p>Do people subjectively feel they are using Wikipedia less? How do we square their subjective impressions with the statistics?<br/>People generally perceive either no change in use or say they don&#x27;t use Wikipedia at all.<br/>But in a head-to-head comparison of &quot;use more now&quot; versus &quot;use less now&quot;, the former wins.</p></li></ol><p>Why might this be an interesting thing to study?</p><p>Wikipedia pageview data is one of the most comprehensive and granular open datasets covering a wide variety of areas of interest, so they provide a useful way to understand both people&#x27;s <em>relative interest in different topics</em>, and the <em>trends in individual topics as well as the Internet as a whole</em>. Specifically:</p><ol><li><p>If you&#x27;re interested in how interest in specific topics has evolved over time, or if you&#x27;re interested in how people&#x27;s Internet use has changed over time, Wikipedia pageviews are a useful part of your toolkit, just like Google Trends. Having a good sense of the general trends in Wikipedia pageviews allows you to better  &quot;normalize&quot; for these trends and give more context  to the numbers you see.</p></li><li><p>If you&#x27;re interested in the overall growth (or decline!) of the Internet, Wikipedia, as one of the top sites on the Internet, and one that does not engage in a lot of advertising and view optimization, offers some insight.</p></li><li><p>One of the hypotheses that might explain part of the decline, namely <em>increased reliance on social media</em>, is of particular interest to rationalists and LessWrong. LessWrong pageviews also <a href=\"http://lesswrong.com/lw/owa/lesswrong_analytics_february_2009_to_january_2017/\">peaked at roughly the same time as Wikipedia pageviews</a>, and social media (particularly Facebook) has been implicated in the decline of LessWrong (see the comments <a href=\"http://lesswrong.com/lw/o5z/on_the_importance_of_less_wrong_or_another_single/\">here</a>).</p></li></ol><p>So, what do you think? How interesting do you find this topic? What parts are you skeptical of? What parts are you most interested in seeing explored or justified more rigorously?</p><p>PS: If you&#x27;re curious what a more detailed report might look like, check out the <a href=\"https://github.com/vipulnaik/working-drafts/blob/master/wikipediaviews/revisiting-the-great-decline-in-wikipedia-pageviews.md\">draft Issa and I worked on last year</a>. All responsibility for errors, both in the draft and in this teaser post, is mine. You can also check out the <a href=\"https://timelines.issarice.com/wiki/Timeline_of_Wikimedia_analytics\">timeline of Wikimedia analytics</a> to understand changes relevant to interpreting analytics.</p></div></div></div></div>",
    "user": {
      "username": "VipulNaik",
      "slug": "vipulnaik",
      "displayName": "VipulNaik"
    }
  },
  {
    "_id": "7YcFuMa7MQyaP3Tvk",
    "title": "Happy Petrov Day! If Today is Also Your Birthday, Happy Birthday!",
    "slug": "happy-petrov-day-if-today-is-also-your-birthday-happy",
    "pageUrl": "https://www.lesswrong.com/posts/7YcFuMa7MQyaP3Tvk/happy-petrov-day-if-today-is-also-your-birthday-happy",
    "postedAt": "2017-09-26T22:56:00.812Z",
    "baseScore": 0,
    "voteCount": 2,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "https://akataskeuastos.wordpress.com/2017/09/26/happy-petrov-day-if-today-is-also-your-birthday-happy-birthday/",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>A discussion of September 26 and September 1993, and an invitation to join the club if that&#x27;s your birthday too</p></div></div></div></div>",
    "user": {
      "username": "Waltus",
      "slug": "waltus",
      "displayName": "Waltus"
    }
  },
  {
    "_id": "KNtKKmcd9DsP7WuZ3",
    "title": "The Anthropic Principle: Five Short Examples",
    "slug": "the-anthropic-principle-five-short-examples",
    "pageUrl": "https://www.lesswrong.com/posts/KNtKKmcd9DsP7WuZ3/the-anthropic-principle-five-short-examples",
    "postedAt": "2017-09-26T22:35:24.102Z",
    "baseScore": 61,
    "voteCount": 56,
    "commentCount": 13,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><em>(content warning: nuclear war, hypothetical guns, profanity, philosophy, one grammatically-incorrect comma for readability’s sake)</em></p><p>This is a very special time of year, when my whole social bubble starts murmuring about nuclear war, and sometimes, some of those murmurers, urging their listeners to worry more, will state: &quot;Anthropic principle.&quot;</p><p>To teach people about the anthropic principle and how to use it in an epistemically virtuous way, I wrote a short dialogue featuring five examples.</p><p></p><h3>1. Life and death and love and birth</h3><p><strong>Avery:</strong> But how can you <em>not</em> believe the universe was designed for life? It&#x27;s in this cosmic Goldilocks zone, where if you tweaked the speed of light or Planck&#x27;s Constant or the electron mass by just a few percent, you couldn&#x27;t have atoms, you couldn&#x27;t have <em>any</em> patterns complex enough to replicate and evolve, the universe would just be this entropic soup!</p><p><strong>Brook:</strong> I&#x27;m not sure I buy the &quot;no complex patterns at all&quot; bit, but even granting it for the sake of argument -- have you heard of the anthropic principle?</p><p><strong>Avery:</strong> No. Explain?</p><p><strong>Brook:</strong> We&#x27;re alive. Life can only exist in a universe where life exists, tautologically. If the cosmos couldn&#x27;t support life, we wouldn&#x27;t be having this conversation.</p><p><strong>Avery:</strong> And so, a universe... created... ngh, I vaguely see what you&#x27;re getting at. Elaborate?</p><p><strong>Brook:</strong> And so, a universe created by some kind of deity, and tuned for life, is indistinguishable from a universe that happens to have the right parameters by coincidence. &quot;We exist&quot; can&#x27;t be evidence for our living in one or the other, because that fact doesn&#x27;t <em>correlate</em> with design-or-lack-of-design -- unless you think that, from <em>inside a single universe</em>, you can derive sensible priors for the frequency with which <em>all</em> universes, both designed and undesigned, can support life?</p><p><strong>Avery:</strong> I... oof. That argument feels vaguely like cheating, but... I&#x27;ll think about it.</p><p></p><h3>2. ...and peace and war on the planet Earth</h3><p><strong>Avery:</strong> In any case, it&#x27;s interesting that the topic of Earth&#x27;s hospitality comes up today of all days, given that we so nearly made it inhospitable.</p><p><strong>Brook:</strong> What do you mean, &quot;today of all days&quot;?</p><p><strong>Avery:</strong> Oh! You don&#x27;t know!? September 26 is Petrov Day! It&#x27;s the anniversary of when some Soviet early-warning system sounded an alarm, and the officer in charge noticed something funny about it and wrote it off -- correctly, as it turned out -- as a false alarm. If he hadn&#x27;t, Russia might have &quot;retaliated,&quot; starting nuclear war and destroying the world.</p><p><strong>Brook:</strong> Yikes.</p><p><strong>Avery:</strong> Yeah! And Wikipedia has a list of similar incidents. We need to be extremely careful to never get into a Cold-War-like situation again: it was incredibly lucky that we survived, and if we get there again, we&#x27;ll almost certainly melt the planet into a radioactive slag heap.</p><p><strong>Brook:</strong> Hmm. Nuclear war is definitely bad, and we should try hard to prevent it. But I suspect things aren&#x27;t as bad as they appear, and that those reports of near-disaster have been exaggerated due to people&#x27;s credulity for &quot;cool&quot; shiver-inducing things. Theories should get punished for assigning low probabilities to true things: if your model claims that the odds of surviving the Cold War were only 1:1000, it takes a thousandfold probability hit. Any model that predicts Cold-War-survival better, is correspondingly more plausible.</p><p><strong>Avery:</strong> Not so! Anthropic principle, remember? If the world had ended, we wouldn&#x27;t be standing here to talk about it. Just as the fact that intelligent life exists shouldn&#x27;t surprise us (because we can only exist in a universe with intelligent life), the fact that the world didn&#x27;t end in 1983 shouldn&#x27;t surprise us (because we can only exist in a world that didn&#x27;t dissolve into flames).</p><p><strong>Brook:</strong> I... see what you&#x27;re saying...</p><p></p><h3>3. Improbability upon improbability</h3><p><strong>Avery:</strong> Oh! And that&#x27;s not all! According to this article, of the officers who took shifts monitoring that station, Petrov was the only one to have had a civilian education; the others were just taught &quot;to issue and obey orders.&quot; It&#x27;s really lucky that the false alarm went off when it did, instead of twelve hours later when somebody else was at the helm.</p><p><strong>Brook:</strong> That... rings false to me. I expect there was a miscommunication somewhere between Petrov&#x27;s lips and your eyes: if there were six officers taking shifts watching the early-warning system, and five of them would&#x27;ve pressed the button, you just declared the probability of surviving this false alarm to be six times smaller: your model takes another 6x hit, just like it would if it <em>also</em> claimed that Petrov rolled a die and decided he&#x27;d only ignore the warning if it came up 1.</p><p><strong>Avery:</strong> Anth--</p><p><strong>Brook:</strong> Don&#x27;t you dare.</p><p><strong>Avery:</strong> *coughthropic principlecough*</p><p><strong>Brook:</strong> <em>Shut your mouth.</em></p><p></p><h3>4. Supercritical</h3><p><strong>Avery:</strong> Fine, fine, sorry. Change of subject: I have a friend who works at the DoE, and they gave me a neat little trinket last week. Here, hold onto this. Careful: it&#x27;s small, but super heavy.</p><p><strong>Brook:</strong> Oka-- oh, <em>jeez</em>, wow, yeah. What is it?</p><p><strong>Avery:</strong> A supercritical ball of enriched uranium.</p><p><strong>Brook:</strong> Gyaah! That&#x27;s not safe-- wait, <em>super</em>critical? That can&#x27;t be, it would detonate in less than a microsecond.</p><p><strong>Avery:</strong> And kill us, yes. But we&#x27;re still alive! Therefore, we must be on the unfathomably tiny branch of possible universes where, so far, when an atom of U-235 in this ball has fissioned, the resulting neutrons tended to <em>miss</em> all the other atoms. Thus, the chain reaction hasn&#x27;t yet occurred, and we survive.</p><p><strong>Brook:</strong> But Av--</p><p><strong>Avery:</strong> And you might be tempted to say, &quot;But Avery, that&#x27;s so improbable I can&#x27;t even express numbers that small in standard mathematical notation. Clearly this ball is merely platinum or osmium or some other dense metal.&quot; But remember! Anthropic principle! You&#x27;re not allowed to use the fact that you&#x27;re still alive as evidence! The fact that this ball hasn&#x27;t detonated is <em>not</em> evidence against its being supercritical uranium!</p><p><strong>Brook:</strong> I-- um. Okay, that is definitely one hundred percent nonsensical sophistry, I just need to put my finger on--</p><p></p><h3>5. Evidence kills</h3><p><strong>Avery:</strong> Sophistry!? I&#x27;m insulted. In fact, I&#x27;m so insulted that I pulled out a gun and shot you.</p><p><strong>Brook:</strong> ...what?</p><p><strong>Avery:</strong> Clearly we&#x27;re living in the infinitesimally tiny Everett branch where the bullet quantum-tunnelled through your body! Amazing! How improbable-seeming! But, you know, anthropic principle and all.</p><p><strong>Brook:</strong> NO. I have you now, sucker: even in the branches where the bullet tunneled through me, I would have seen you draw the gun, I&#x27;d have heard the shot, I&#x27;d see the bullet hole in the wall behind me.</p><p><strong>Avery:</strong> Well, that all assumes that the photons from my arm and the wall reached your eye, which is a purely probabilistic quantum phenomenon.</p><p><strong>Brook:</strong> Yes, but still: of the universes where the bullet tunneled through me, in ninety-nine-point-so-many-nines percent of those universes, there is a bullet hole in the wall. Even ignoring the universes where I&#x27;m dead, the lack of a bullet hole is overwhelming evidence against your having shot me.</p><p><strong>Avery:</strong> Is it, though? When you looked at the wall just now, you saw no bullet hole, yes?</p><p><strong>Brook:</strong> Yes...</p><p><strong>Avery:</strong> But you, Brook-who-saw-no-bullet-hole, can basically only exist in a universe where there&#x27;s no bullet hole to be seen. If there <em>were</em> a bullet hole, you wouldn&#x27;t exist -- a Brook-who-<em>did</em>-see-a-bullet-hole would stand in your place. Just as the fact that intelligent life exists shouldn&#x27;t cause you to update (because you can only exist in a universe with intelligent life), the fact that there&#x27;s no bullet hole shouldn&#x27;t cause you to update (because you can only exist in a universe without a bullet hole).</p><p><strong>Brook:</strong> But seeing a bullet hole doesn&#x27;t kill me.</p><p><strong>Avery:</strong> There&#x27;s nothing <em>fundamentally different</em> about death. You wouldn&#x27;t exist if the world had been destroyed in 1983, but you <em>also</em> wouldn&#x27;t exist if there were a bullet hole: I&#x27;d be talking to Brook-who-saw-a-bullet-hole instead. And the fact that you exist can&#x27;t be used as evidence.</p><p><strong>Brook:</strong> Are you high on something!? Are you fucking with me!? You&#x27;re asking me to throw out the whole notion of evidence!</p><p><strong>Avery:</strong> Oh, yeah, I&#x27;m totally messing with you. Absolutely. Sorry. When did I start, though?</p><p><strong>Brook:</strong> ...sometime between describing Petrov Day -- that part was true, right? Good. -- and telling me that that ball-of-some-dense-metal was made of uranium.</p><p><strong>Avery:</strong> Correct. But can you be more specific?</p><p><strong>Brook:</strong> ...tungsten?</p><p><strong>Avery:</strong> Heh. Yeah, good guess. But I meant about--</p><p><strong>Brook:</strong> --yeah. I&#x27;m not really sure when you started messing with me. And I&#x27;m not really sure when you stopped applying the anthropic principle correctly.</p><p><strong>Avery:</strong> Hmm. That&#x27;s too bad. Neither am I.</p><p></p><h3>Conclusion</h3><p>I have no idea whether the anthropic principle is legit or how to use it, or even whether it has any valid uses.</p><p></p><p><em>[cross-posted to </em><a href=\"https://apointinblogspace.wordpress.com/2017/09/25/the-anthropic-principle-five-short-examples/\"><em>a blog</em></a><em>; comments here preferred]</em></p></div></div></div></div>",
    "user": {
      "username": "Optimization Process",
      "slug": "optimization-process",
      "displayName": "Optimization Process"
    }
  },
  {
    "_id": "bicJ2CRS7neTfrPce",
    "title": "Cognitive Empathy and Emotional Labor",
    "slug": "cognitive-empathy-and-emotional-labor-1",
    "pageUrl": "https://www.lesswrong.com/posts/bicJ2CRS7neTfrPce/cognitive-empathy-and-emotional-labor-1",
    "postedAt": "2017-09-26T20:39:48.877Z",
    "baseScore": 7,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "https://mapandterritory.org/cognitive-empathy-and-emotional-labor-cb256c38597d",
    "htmlBody": "<p>The concept of <a href=\"http://geekfeminism.wikia.com/wiki/Emotional_labor\">emotional labor</a> has been <a href=\"http://www.huffingtonpost.com/psyched-in-san-francisco/why-women-are-tired-the-p_b_9619732.html\">popularized</a> in the last couple years as a way of talking about the work people do to manage other people&#x2019;s emotions. Most of that discussion has been around how <a href=\"https://www.theguardian.com/world/2015/nov/08/women-gender-roles-sexism-emotional-labor-feminism\">women</a> are often expected to perform emotional labor without compensation both professionally and personally. Women <a href=\"https://www.theatlantic.com/business/archive/2016/01/gender-emotional-labor/427083/\">report</a> being asked to perform social glue functions in the workplace without it being part of their job, part of how they are evaluated, or part of how they are paid, and they are <a href=\"https://www.psychologies.co.uk/who-carrying-emotional-labour-your-relationship\">culturally expected</a> to perform most of the emotional labor in personal relationships. And perhaps most frustratingly, while men are lauded when they perform emotional labor and mostly given a pass when they don&#x2019;t, the situation is reversed for women who mostly only see <a href=\"http://the-toast.net/2015/07/13/emotional-labor/\">punishment</a> for not doing enough.</p><p>But ultimately emotional labor <a href=\"https://thebodyisnotanapology.com/magazine/7-ways-men-must-learn-to-do-emotional-labor-in-their-relationships/\">is for everyone</a>, and although there is a sex differential in its performance, there is little new I can say on that aspect of the topic. What I can say is something about how emotional labor is related to <a href=\"https://mapandterritory.org/unstaging-developmental-psychology-fcdc5f9ba894\">developmental psychology</a> and cognitive empathy. Specifically, how skill at emotional labor depends on the development of cognitive empathy and lack of cognitive empathy is a limiting factor in being able to perform emotional labor.</p><p>I described emotional labor as &#x201C;managing other people&#x2019;s emotions&#x201D;, but to be more precise emotional labor is acting to influence the emotions of others. To do this one must have some knowledge of the emotions of others and how they can be affected. This knowledge typically comes from either affective empathy or cognitive empathy. Affective empathy is <a href=\"http://blog.teleosleaders.com/2013/07/19/emotional-empathy-and-cognitive-empathy/\">feeling another person&#x2019;s feelings</a>, like being sad because your friend is sad or being scared because a character in a horror movie is scared. Affective empathy&#x2019;s source is probably <a href=\"https://en.wikipedia.org/wiki/Mirror_neuron\">mirror neurons</a>, and a lack of affective empathy is associated with <a href=\"https://www.theatlantic.com/magazine/archive/2017/06/when-your-child-is-a-psychopath/524502/\">sociopathy</a>. For this reason affective empathy is sometimes also called &#x201C;primitive&#x201D; empathy because it seems to naturally develop on its own and is rarely missing in a person.</p><p>Cognitive empathy, on the other hand, is <a href=\"https://www.ribbonfarm.com/2015/04/08/the-essence-of-peopling/\">the skill of thinking about others ontologically</a> and is anything but &#x201C;primitive&#x201D;. In order to be able to think of ways to make your friends happy or worry about what others will think of you, you must model other people and predict their responses. Those models can be simple, like how <a href=\"http://drgailgross.com/three-developmental-charts-erikson-kohlberg-and-piaget/\">children</a> employ thing and thing-relationship levels of <a href=\"https://mapandterritory.org/phenomenological-complexity-classes-8b41836437b9\">phenomenological ontological complexity</a>, but such simple models often <a href=\"https://medium.com/goactualize/your-company-culture-is-who-you-hire-fire-promote-part-2-anatomy-of-an-asshole-dba4f801b9f5\">fail</a> if not backed up by affective empathy. As people age they <a href=\"http://drgailgross.com/three-developmental-charts-erikson-kohlberg-and-piaget/\">build up</a> enough cognitive empathy to effectively <a href=\"https://www.theatlantic.com/health/archive/2016/01/when-are-you-really-an-adult/422487/\">participate in society</a> without necessarily feeling everyone&#x2019;s feelings, and they <a href=\"http://andrew-tha.tumblr.com/post/83707300786/theory-of-emotional-development-most-recent\">develop</a> system level and higher ontological complexity that enables cognitive empathy techniques like seeing other people as <a href=\"https://mapandterritory.org/what-value-subagents-868b3b3fc076\">made up of parts</a>, distinguishing others&#x2019; <a href=\"https://mapandterritory.org/revealed-and-stated-identity-64c6ec070f4f\">revealed and stated identities</a>, and understanding others&#x2019; <a href=\"https://mapandterritory.org/need-dynamics-54ca9ff5955c\">needs and wants</a>. And if a person continues down this path they may develop a generalized sense of cognitive empathy that can tackle <a href=\"https://mapandterritory.org/is-feedback-suffering-cf18006deca8\">broad axiological questions</a> about how to treat themselves and others.</p><p>Yet affective empathy and cognitive empathy rarely exist in isolation. In the context of emotional labor, <a href=\"https://www.theguardian.com/world/2017/may/26/gender-wars-household-chores-comic?CMP=fb_gu\">people often first feel&#x200A;</a>&#x2014;&#x200A;use affective empathy to notice&#x200A;&#x2014;&#x200A;that an opportunity exists to affect someone else&#x2019;s emotions, and then use cognitive empathy to figure out what to do. And when cognitive empathy fails us we may <a href=\"http://dorkdiaries.com/2014/06/when-you-dont-know-how-to-comfort-your-friend/\">fall back</a> on affectively informed actions. This will work most of the time, but pesky philosopher that I am, I want to know what happens in the edge cases, like when you can do something to hurt someone else&#x2019;s feelings without them finding out.</p><p>Consider the case of the broken vase. I&#x2019;m having a fancy dinner party and you lend me your vase to use as a centerpiece. On the way home I stumble and drop the vase, shattering it into a million pieces. Luckily this happens right in front of a store where I can purchase an exact replica, so I immediately replace it. The dinner party goes well, and I &#x201C;return&#x201D; the vase with you unable to tell I&#x2019;ve replaced it. I have two options:</p><ol><li>Say nothing about the break.</li><li>Tell you that I broke the vase and replaced it.</li></ol><p>If I have no affective or cognitive empathy it seems likely I will do (1) since it is naively the option that produces the <a href=\"https://en.wikipedia.org/wiki/Game_theory\">better payout</a>: you&#x2019;ll be mildly happy in (1), whereas there&#x2019;s some chance you&#x2019;ll be angry in (2). If I have no cognitive empathy but plenty of affective empathy, it seems likely I will do (2) because I will feel the bad feelings you would feel if you knew I broke your vase and won&#x2019;t think about the fact that you don&#x2019;t know that I broke it. If I have no affective empathy but plenty of cognitive empathy, though, it now becomes a bit more complex to figure out how I will act. Maybe I will want to spare your feelings and do (1), but maybe I will reason that you would want (2) because it conveys information about me you want to know, and I do it out of <a href=\"http://www.bayesianinvestor.com/blog/index.php/2017/09/13/dealism/\">a reasoned expectation</a> that acting in this way will <a href=\"http://benjaminrosshoffman.com/the-quaker-and-the-parselmouth/\">more create</a> the world I want to live in. And the situation remains substantially the same if I have plenty of affective empathy to go along with my cognitive empathy, however my feelings will likely affect my axiological calculations in deciding which action to prefer.</p><p>In this scenario cognitive empathy enabled emotional labor. Without it I was left either playing a simple game or acting on my feelings with no consideration for you, and so my emotional &#x201C;labor&#x201D; was reduced to <a href=\"https://en.wikipedia.org/wiki/Normal-form_game\">calculating a payout matrix</a> or dealing with my own conflicting emotions. Cognitive empathy made possible real emotional labor, though, because it provided an ontology to reckon with. True, you might object, it still produced one of the outcomes that could be achieved without cognitive empathy, but emotional labor matters <a href=\"http://lesswrong.com/lw/aq9/decision_theories_a_less_wrong_primer/\">at the margins</a> when we consider many cases where acting without cognitive empathy would produce <a href=\"https://intelligence.org/2017/04/07/decisions-are-for-making-bad-outcomes-inconsistent/\">inconsistent answers</a>.</p><p>This is important because without doing enough emotional labor to come to a wise course of action, a desire to help someone borne out of earnest empathy for them may end up unintentionally hurting them. If I failed to understand you sufficiently well in the vase case when I was using cognitive empathy to perform emotional labor, I might have chosen to do (1) when actually (2) is <a href=\"http://lesswrong.com/r/discussion/lw/pci/emotional_labour/\">what you would have preferred</a> or vice versa. When <a href=\"https://www.ribbonfarm.com/2015/05/07/weaponized-sacredness/\">we help we risk hurting</a> if we do so unwisely, so helping depends on having the skill to accurately predict how our actions will affect others. This is why people say emotional labor is draining: not only is it mentally challenging but the stress of failure can weight so heavy on us that we find it hard to act.</p><p>So what can you do if you want to perform the emotional labor that will allow you to help others as they want to be helped? My <a href=\"https://mapandterritory.org/nothing-is-forbidden-but-some-things-are-good-b57f2aa84f1b\">own solution</a> is to target virtue when my calculations are insufficiently calibrated, but otherwise you might take <a href=\"https://mapandterritory.org/act-into-fear-and-abandon-all-hope-81bcc114c5fd\">the same advice I&#x2019;ll always give</a>: do the emotional labor you fear doing and give up on hoping for the emotional labor you want done for you, because even if you hurt people in the short run this will enable the necessary <a href=\"https://mapandterritory.org/the-personal-growth-cycle-34ec1c218615\">personal growth</a> towards <a href=\"https://mapandterritory.org/phenomenological-complexity-classes-8b41836437b9\">increased complexity</a> that will let you help them in the future.</p>",
    "user": {
      "username": "gworley",
      "slug": "gordon-seidoh-worley",
      "displayName": "Gordon Seidoh Worley"
    }
  },
  {
    "_id": "kBELNzifQWrXCGy9H",
    "title": "Map of the AI Safety Community",
    "slug": "map-of-the-ai-safety-community-0",
    "pageUrl": "https://www.lesswrong.com/posts/kBELNzifQWrXCGy9H/map-of-the-ai-safety-community-0",
    "postedAt": "2017-09-26T08:39:10.136Z",
    "baseScore": 3,
    "voteCount": 7,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": "https://aisafety.com/wp-content/uploads/2017/09/AI_Safety_Community_Map_Version__1_0.jpg",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>I have made a <a href=\"https://aisafety.com/wp-content/uploads/2017/09/AI_Safety_Community_Map_Version__1_0.jpg\">map of the AI Safety Community!\r</a></p><p>The map is greatly inspired by the map of the rationalist community made by Scott Alexander. \r</p><p>\rThere are bound to be omissions and misunderstandings, and I will be grateful for any corrections. I promise that I will incorporate the feedback into a new version of the map.\r</p><p>The sizes of the cities/dwellings reflect my understanding of how much they contribute to AI Safety. The locations and borders reflect my judgement of who focus on what, and I had to make some difficult choices. \r</p><p>\r(Made with Fractal Mapper 8, and crossposted to AISafety.com and r/controlProblem)\r</p><p>\rI hope that you will find the map useful, and find inspiration to visit new places.</p></div></div></div></div>",
    "user": {
      "username": "SoerenE",
      "slug": "soerene",
      "displayName": "SoerenE"
    }
  },
  {
    "_id": "6XvnqW28e2twiv6ww",
    "title": "Why I am not a Quaker (even though it often seems as though I should be)",
    "slug": "why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i",
    "pageUrl": "https://www.lesswrong.com/posts/6XvnqW28e2twiv6ww/why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i",
    "postedAt": "2017-09-26T07:00:28.116Z",
    "baseScore": 49,
    "voteCount": 37,
    "commentCount": 18,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>In the past year, I have noticed that the Society of Friends (also known as the Quakers) has come to the right answer long before I or most people did, on a surprising number of things, in a surprising range of domains. And yet, I do not feel inclined to become one of them. Giving credit where credit is due is a basic part of good discourse, so I feel that I owe an explanation.</p><p></p><p>The virtues of the Society of Friends are the virtues of liberalism: they cultivate honest discourse and right action, by taking care not to engage in practices that destroy individual discernment. The failings of the Society of Friends are the failings of liberalism: they do not seem to have the organizational capacity to recognize predatory systems and construct alternatives.</p><p></p><p>Fundamentally, Quaker protocols seem like a good start, but more articulated structures are necessary, especially more closed systems of production.</p><p></p><p>This post reflects a lot of thought, but there&#x27;s a lot of speculation which I hope I&#x27;ve managed to mark as such. I&#x27;m optimizing for clearly communicating my present state in the hopes of furthering dialogue, not saying things that are maximally defensible; I haven&#x27;t worked out the relevant models in extreme detail. That said, I don&#x27;t think I&#x27;m misreporting any facts, and corrections on any level are welcome.</p><p></p><h3>Some reasons to respect the Society of Friends</h3><h3></h3><ul><li><p>Liberalism is nice, and the Quakers instilled it in America.</p></li><li><p>They pioneered the radical practice of personal integrity.</p></li><li><p>Their social technology is designed to avoid overriding individual conscience and judgment, thus preserving information that is typically destroyed by more common systems oriented around momentum or dominance.</p></li><li><p>They don’t advertise much.</p></li></ul><h4>Proto-liberals</h4><h4></h4><p>The Quakers first came to my attention when Scott Alexander of Slate Star Codex wrote about them. His <a href=\"http://slatestarcodex.com/2016/04/27/book-review-albions-seed/\">review of Albion’s Seed</a> describes them as proto-liberals with an outsized effect on the United States of America, basically winning over the culture to their ideals:</p><p></p><blockquote><p>Fischer warns against the temptation to think of the Quakers as normal modern people, but he has to warn us precisely because it’s so tempting. Where the Puritans seem like a dystopian caricature of virtue and the Cavaliers like a dystopian caricature of vice, the Quakers just seem ordinary. […]</p><p></p><p>George Fox […] believed people were basically good and had an Inner Light that connected them directly to God without a need for priesthood, ritual, Bible study, or self-denial; mostly people just needed to listen to their consciences and be nice. Since everyone was equal before God, there was no point in holding up distinctions between lords and commoners: Quakers would just address everybody as “Friend”. And since the Quakers were among the most persecuted sects at the time, they developed an insistence on tolerance and freedom of religion which (unlike the Puritans) they stuck to even when shifting fortunes put them on top. They believed in pacificism, equality of the sexes, racial harmony, and a bunch of other things which seem pretty hippy-ish even today let alone in 1650.</p><p></p><p>[…] The Pennsylvanian leadership on abolitionism, penal reform, the death penalty, and so on all happened after the colony was officially no longer Quaker-dominated.</p><p></p><p>And it’s hard not to see Quaker influence on the ideas of the modern US – which was after all founded in Philadelphia. In the middle of the Puritans demanding strict obedience to their dystopian hive society and the Cavaliers demanding everybody bow down to a transplanted nobility, the Pennsylvanians – who became the thought leaders of the Mid-Atlantic region including to a limited degree New York City – were pretty normal […] the Quakers really stand out in terms of freedom of religion, freedom of thought, checks and balances, and the idea of universal equality.</p></blockquote><p>I like a lot of the opportunities that modern liberal society affords me. Some large amount of this good is attributable to the Quakers. This suggests that if I want more good things in this vein, I should check out what the Quakers are up to.</p><p></p><h4>Personal integrity as a radical practice</h4><p></p><p>I’ve come around to the point of view that personal integrity is not something I can expect from my environment by default. There are many social forces that corrode it, and it is only sustainable if <a href=\"http://benjaminrosshoffman.com/the-quaker-and-the-parselmouth/\">conceived of as a radical practice</a>.</p><p></p><p>The Quakers got there first. The Quaker insistence on not lying was wide-ranging. It included apparently little but socially costly things, like refusing to sign letters with the traditional “I remain your most obedient servant” unless they in fact remained the person’s most obedient servant, which generally they did not. It included more clearly materially costly things, like refusing to quote unrealistically high opening prices for the sake of bargaining, even when this was the predominant custom, preferring to quote the price they expected to charge.</p><p></p><p>Society has moved substantially towards the Quaker way on both of those practices, though honest pricing is still <a href=\"http://hbswk.hbs.edu/item/what-went-wrong-at-j-c-penney\">not reliably supported by market forces</a> - revealed preferences are for slot machines. To do better takes something like a religion - a shared understanding that you’re not doing the profit-maximizing thing but the virtuous thing, and don’t expect that the outside world will always give you local incentives to do it.</p><p></p><h4>Nonviolent social technology</h4><p></p><p>Quaker worship values reflective silence. Quaker decisionmaking also centers empowering individuals to discern the right for themselves. &quot;Clearness committees&quot; provide guidance to Friends making difficult decisions, not through advice or admonition, but by asking questions to help the decider know the right with their own conscience. Quaker groups tend to favor decisionmaking models in which if even one member continues to object, they either continue discussing the issue, or let it rest until later.</p><p></p><p>This stands in marked contrast to the predominant modes of group coordination, which focus on <a href=\"https://srconstantin.wordpress.com/2017/04/25/on-drama/\">momentum</a> or <a href=\"https://srconstantin.wordpress.com/2017/09/12/patriarchy-is-the-problem/\">hierarchical control</a>. Both those modes treat dissent as noise, to be eliminated. Quaker social technology treats it as signal, to be processed.</p><p></p><p>You might think that this would lead to total paralysis. But the question of racial slavery in the US is an instructive example. The Quakers did not all come to the right answer immediately. But they kept talking about it, and the argument “you wouldn’t like it if someone did that to you” was sufficiently persuasive that (according to Scott’s summary) during the 17th and 18th centuries slave ownership among the wealthy declined from 70% to 10%.</p><p></p><p>For a while I complained that our society’s default understanding of friendship - and informal social relations in general - was built around <a href=\"http://benjaminrosshoffman.com/group-cognition/\">momentum</a>, and that everything else is unfairly rounded off to <a href=\"http://benjaminrosshoffman.com/the-predator-in-the-herd/\">adversarial control</a>. I yearned for a conception of trust that was based on <a href=\"http://benjaminrosshoffman.com/friendship-counterfactually-hugged-vampires/\">shared discernment of the good for each other</a>. It seems too right to be mere chance that when the group promoting the key virtues I thought necessary for true friendship chose a name for itself, that name was the Society of Friends.</p><p></p><h4>Humble marketing</h4><p></p><p>I’ve written a lot lately about the epistemically corrosive effects of <a href=\"http://benjaminrosshoffman.com/matching-donation-fundraisers-can-be-harmfully-dishonest/\">marketing culture</a>, and the coordination advantages of <a href=\"http://benjaminrosshoffman.com/humble-charlie/\">keeping a low profile</a> under those circumstances. Quakers don’t advertise much, they just seem to keep on doing sensible good things.</p><p></p><p>I am writing this from a cabin at a Quaker retreat. I wanted to <a href=\"http://benjaminrosshoffman.com/request-cabin/\">take a couple weeks alone</a> to reflect on my life and strategy, away from the pull and rhythm of any local social scene. It was surprisingly difficult to find a plain cabin that fit my needs.</p><p></p><p>One thing I tried was using modern search methods. AirBnB, Craigslist, Google, VRBO websites. Nearly every listing for a cabin or cottage was oriented towards vacationers’ enjoyment, and outfitted and priced for a luxurious consumer experience. The ones that were not luxury cabins were for people experienced at camping or otherwise roughing it (e.g. people who know what to do without running water, which I do not). Nearly every offer of a silent retreat was for something like a managed experience with meditation practice, which I have found valuable enough to recommend, but which is not what I needed at this time. What I needed was a quiet place to stand upright, at a high vantage point, and survey the territory. With just the material comforts that I would be distracted without. Perhaps unsurprisingly, none of the vast profit-seeking marketing apparatus people use to find information was very helpful in finding a place to recover from its effects.</p><p></p><p>The other thing I tried was the old-fashioned, local-scale method: asking friends. I asked on my blog. I talked to people about it and got suggestions. This worked somewhat better. One kind friend offered his family’s cabin, in New Hampshire. Another pointed me to a modern monastery that let out cabins, in Vermont, for a price comparable to the cheapest AirBnB options. Then, my mother mentioned my search to a friend, who told her about a Quaker retreat center in Massachusetts. I looked it up, and there were two similar retreat centers within driving distance of Berkeley (where I have been living), one of which had a cabin available. As far as I can tell, the Quakers operate these retreat centers more or less at cost, as a public service, because they believe that people ought to have a place to go - groups as well as individuals - to reflect and discern the right path for themselves.</p><p></p><p>It’s really remarkable how often, at how many different points in their history, they’ve been doing the exact most reasonable thing.</p><p></p><h3>The best defense is strategy</h3><p></p><p>So, if the Quakers are doing all these great things, why am I not one? A few years ago, my objection would have been that they are not focused on considerations of scope, and I’d have expected something like effective altruism to do much better. I no longer think that, because it seems to me like effective altruism in its current form is <a href=\"http://benjaminrosshoffman.com/effective-altruism-is-self-recommending/\">not epistemically sustainable</a>. Local solutions, scaled organically at a rate compatible with human verification of results, have a significant advantage there.</p><p></p><p>My objections have more to do with the information-processing limitations of a totally nonhierarchical network that relies on peer-to-peer transfer of information. In particular, this on its own is not sufficient to avoid some systemic traps:</p><p></p><ul><li><p>Quaker coordination methods are inadequately defended against arbitrage.</p></li><li><p>It takes a village to sustain life.</p></li><li><p>You cannot serve two masters.</p></li></ul><h4>Arbitrageur defeats Quaker</h4><p></p><p>The emphasis on doing good according to personal discernment, as an expression of personal conscience, rather than building the most scalable goodness marketing machine possible in order to maximize your impact, provides some resistance to the temptation to distort the truth to something more appealing. But it leaves you vulnerable to two types of arbitrage:</p><p></p><ul><li><p>If your environment does not have similarly good epistemic defenses, then you will still be the consumer of this kind of marketing, in the absence of a systemic plan to obtain accurate intelligence. I wrote about this in <a href=\"http://benjaminrosshoffman.com/humility-argument-honesty/\">the humility argument for honesty</a>, so I will not repeat myself here.</p></li><li><p>If you reliably respond to local needs with outward-oriented service, you become an exploitable resource by more global strategies that may not share your values. I wrote about this in <a href=\"http://benjaminrosshoffman.com/against-neglectedness/\">against neglectedness considerations</a>, but feel that this needs more exposition.</p></li></ul><h5>Socially responsible investing vs vice funds</h5><p></p><p>A simple example of the second kind of arbitrage is socially responsible investing. Some mutual funds avoid investing in harmful businesses businesses, such as arms dealers, tobacco companies, and casinos. The direct effect of this is to reduce demand for stock and debt in such companies, thus reducing the stock price and implicitly increasing their cost of capital. But if some businesses are systemically underpriced, this creates an arbitrage opportunity, to capture above-normal economic returns by investing in them. And in fact there are “vice” funds that tend to slightly outperform the market by doing exactly that.</p><p></p><p>This arbitrage does not appear to have completely negated the effects of socially responsible investing, but a substantial effect of this strategy is still to transfer money from people following a virtuous abstention policy, to those following an amoral one.</p><p></p><h5>Volunteer work vs administrative efficiency</h5><h5></h5><p>But what of something more local, like volunteer work? Suppose, for instance, that there is an epidemic. The legitimate authorities’ responders, funded by taxes and wealthy prestigious foundations, are stretched thin, and you confirm that volunteers are needed, or identify an underserved area. You volunteer to tend to the sick and quarantined, and talk openly about this with friends, who then decide whether this is a thing that they ought to do.</p><p></p><p>The nice thing about this strategy is that you can be fairly sure that you are doing some local good. You can see for yourself that people are ill and suffering, and if you take care of yourself well enough to avoid spreading the epidemic, you can be reasonably sure you are helping locally. Since you are not using content-neutral persuasion tactics to mobilize large groups with unknown opportunity cost, you avoid imposing hidden costs globally. So far, so good.</p><p></p><p>What will the authorities’ response be? The authorities initially understood that there was some chance of an epidemic, and made allowances for some systemic capacity to mitigate it. Their calculations took into account the costs of setting aside these resources, rather than doing something else with them.</p><p></p><p>If you are doing work that the authorities did not expect, then when they observe better than expected outcomes, they will factor this into their future plans, and reallocate resources away from epidemic preparedness, relative to the scenario where you did not participate.</p><p></p><p>If these authorities are benevolent - if they are optimizing for a metric that reflects your values well enough - then even if your net effect was mostly not to reduce death and suffering due to epidemics (because that was arbitraged away), you are still doing good, because you are freeing up resources to do other things, elsewhere, where you cannot personally verify opportunities to do good.</p><p></p><p>But it is far from guaranteed that the authorities are benevolent. If, on the other hand, their strategy is to spend as little as they can get away with on social services, in order to loot as much as possible from the system, then you have redistributed resources from yourself to them. This is one form of what economists call moral hazard.</p><p></p><h5>Philanthropy vs moral hazard</h5><p></p><p>Moral hazard is not limited to domains like business or government where the adversarial component is obvious; even in philanthropy, a field you might imagine characterized by an exceptionally high level of benevolence and value-alignment among donors, experts believe this problem exists. An instructive example is GiveWell, a charity evaluator which has consistently <a href=\"http://benjaminrosshoffman.com/givewell-and-partial-funding/\">advised</a> a foundation with more money than it knows what to do with to avoid fully funding GiveWell’s top-recommended charities, in order to avoid this sort of moral hazard.</p><p></p><h5>Fair trade vs business</h5><p></p><p>When you are relating to an open system, in which you are a price-taker, engaging in unembedded transactions involving unknown agents with unknown agendas and strategies, you should expect everything you do to be arbitraged against. This is fine when you are trying to get something for yourself; if you buy a coffee at a cafe, you can for the most part personally verify that you have received a satisfactory coffee, and the value you receive does not really depend much on the hidden ways the cafe might respond to the incentive. Arbitrage is good, because it means that you are not creating local coffee scarcity when you buy your coffee; instead, you are sending a price signal that causes the global financial system to reallocate production very slightly towards coffee.</p><p></p><p>But what if you are worried about the negative externalities of your actions? What if you are worried that the coffee industry is extractive, in a way that harms some group of people with little economic leverage? You might try buying fair trade coffee. In effect, the fair trade label is an implicit guarantee about the net effects of your actions on the global economy. The obvious arbitrage opportunity here is to sell specious guarantees. Starbucks cannot sustainably mislead you about whether the cup they sell you has any coffee in it, but your ability to verify the desirable effects of fair trade claims is much weaker.</p><p></p><h5>In praise of closed systems</h5><h4></h4><p>Arbitrage is an inherent vulnerability of the outward-oriented, service model of right action. If you are looking to create value, you should favor closed systems where you (or trusted processes) can validate the accounting, observing the inputs and outputs, so that you can be sure that you end up with something more valuable than you started with. Accounting, not arbitrage.</p><p></p><p>Intentional communities and local production are examples of this. Building local creative and reflective capacity in ways that the official system is not optimizing for is a plausible way to create lasting value that does not immediately get arbitraged away.</p><p></p><p>This implies that some parts of the Quaker strategy are good for long-term value creation. In particular, the Friends meetings themselves, and the cultivation of individual discernment, are direct capacity-building exercises. I am, after all, writing this from a cabin at a Quaker retreat. The retreat center is obviously a good thing to exist, especially since it’s not marketed as an arbitrage opportunity for vacationers looking to get a better deal. There is even a local intentional community here. I am not completely clear on the details, but it seems as though some people live on site to maintain the retreat center.</p><p></p><p>These are really obviously the “good guys”; they’re supporting the development of vitally needed steering capacity. But this development is not enough; more research is needed.</p><p></p><h4>It takes a village to sustain life</h4><p></p><p>If things go well, this will not be the last generation of humans. This means that for long-term good outcomes, we need to bring up future generations. Unfortunately, there are many systemic forces working to make this difficult.</p><p></p><p>People who participate more in the abusive Western educational system tend to have fewer children.</p><p></p><p>Suburbanization makes it costly to raise children humanely; parents are forced to choose between sending their kids off to a designated abuse facility, or designating at least one parent to be a full-time caretaker. This work cannot be shared among communities to realize economies of scale, because most adults are busy far away at work, and in any event you can’t let your kids run around freely because nearly every house abuts an active road with deadly automobile traffic.</p><p>[ETA: As Zvi <a href=\"http://benjaminrosshoffman.com/why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i-should-be/#comment-134285\">points out</a>, it is also effectively illegal in major US metropolitan areas to let your kids roam freely even when they are old enough that it is otherwise safe for them to do so.]</p><p>The net effect of all this is to make child-rearing an expensive consumption good, instead of an important part of the productive activities of life.</p><p></p><p>Intergenerational communities such as local religious groups often help mitigate this problem, but for the most part the Friends I have talked to did not seem to consider it an urgent priority, or be organizing their churches to fix this problem. Instead, they pay the costs if they can, and focus on helping the individuals most in need. This is probably related to the broader Christian orientation towards service rather than production.</p><p></p><p>I am happy to engage in further discourse about this with anyone who is interested, but this isn’t something that can in principle be solved, I think, by incremental individual progress like eschewing leverage and manumitting your slaves. It requires coordinated action, and therefore group structures that can take decisive action even against local incentive gradients, with some amount of centralized responsibility, oriented around <em>group information-processing</em> rather than oriented merely around not destroying individual information-processing.</p><p></p><p>We need to learn how to <em>be free and build infrastructure</em>, or we will live in infrastructure built by and for an unfree world.</p><p></p><h4>You cannot serve two masters</h4><p></p><p>Religious minorities - so, in the major cities of the US, basically any religion aside from cosmopolitan secular liberalism - tend have lots of experience having to stand up for their practice at the expense of exclusion from communal events, institutional approval, and sometimes even livelihood. I have personal experience with this; Jews who insist on not working on the Sabbath or Holidays, for instance, frequently find this to be a source of friction with employers. As a child, I had to miss communal school events for this reason. In the Rationalist community, the upcoming autumn equinox celebration was scheduled to coincide with Yom Kippur.</p><p></p><p>Some employers talk of work/life balance, but ultimately you can only serve one master, and the relation most people have with their employers is one of a <em>servant in their household</em>. To pick a recent example, in <a href=\"https://twitter.com/ryanavent/status/905753112773877760\">this Twitter thread</a>, a prominent journalist takes it as too obvious to be worth stating as an explicit premise, that the CEO of a major corporation can move some huge number of people to an arbitrary place to influence political decisions via “democracy.” This looks very much not like people being free to me.</p><p></p><p>A moral community that doesn’t organize around in-community production will quickly run up against the problem that you can have only one central organizing force in your life. Either people will flake on their employers and be fired, or flake on community obligations and nothing will get done, or both.</p><p></p><p>A necessary part of any <em>viable alternative</em> to the world of marketing, is a community where people either own their own home &amp; business, or depend for their livelihood on other community members who are committed to shared values.</p><p></p><p>I see some intentional communities at the extremes of Quaker life, but for the most part it looks like people are basically participating in the modern liberal world, with infrastructure unsuited to independence and human flourishing.</p><p></p><h3>A very incomplete survey of other alternatives</h3><p></p><p>I’m aware of a few other groups, in the West, that are doing, or used to be doing, <em>parts</em> of what is needed.</p><p></p><p>The Quakers are one of the four founding English cultures described in <em>Albion’s Seed</em>. Another are the Puritans. They seem promising in a bunch of ways. They managed to pull off an integrated culture of shared production and communal norms, organized around communities and familial households that worked small landholdings together. They managed to have commerce, but also managed the moral leadership to at least occasionally slap down profit-maximization wireheading. They don’t seem to have had much fun, which is unfortunate, but despite their heavy social control, they made sure to make room for private love and happiness.</p><p></p><p>The most obvious problem with the Puritans is that they don’t exist anymore, because they weren’t very good at making following generations enthusiastic Puritans. This is probably related to the ways in which they did not have much fun. The next most obvious problem, from my perspective, is that while they cared a lot about improving their land and lot, they wanted to do this in traditional ways; their resistance to innovations might have prevented them from advancing things like radical life extension and space travel, both things that are necessary if we want the good long-run future.</p><p></p><p>Jews fall into a few different interesting categories.</p><p></p><p>Liberal Jews, even Orthodox ones, primarily share community norms with each other, separating it from economic production and for the most part childrearing, which they do the conventional way. They face constant social and economic pressure to buckle, and often find themselves making awkward compromises. I’ve seen this work well for upper-middle-class Jews, but there’s a reason why people are drifting away from the practice. It’s expensive, in a world not designed to interface with it well. If your production is unrelated to your religion, then your religion becomes a <em>consumption good</em>, and the Sabbath is competing with Hollywood. Who’s gonna appeal more to your kids? Liberal Judaism fails to make childrearing easy, though community does at least a little to make it easier. Liberal Jewish schooling and intellectual culture does seem to have preserved some sort of intellectual capacity above baseline, which contributes to value-aligned steering power as well as the sort of thing that wins Nobel prizes. Some of this might be genetic rather than cultural, of course, and I don’t know how much.</p><p></p><p>Haredi Jews (the ones who wear lots of black) often work in community businesses, and have community infrastructure. Economic and child production and religion seem at least somewhat integrated. Why don’t I join <em>them</em>? Well, I’d have to agree to a bunch of things that I think are not true, and it doesn’t seem like they’re very <em>fast</em> at producing material progress, in part because they waste a lot of time pretending to be curious about things. They also seem to often have institutional child sexual abuse problems, like the Catholics, though it’s not clear to me whether this is actually above the base rate of child molestation by authority figures, whether we simply find out about it more when distinctive minority-culture institutions have that problem, or something else is going on. But I would want to do much, much better, on that and many other fronts.</p><p></p><p>I also don’t know whether there’s something substantially more interesting going on in the yeshiva communities organized around schools that are the intellectual heirs of the Vilna Ga’on, vs Chassidic communities organized around a charismatic Rebbe.</p><p>I expect many religions have similar tradeoffs. Amish seem like they’re in a similar position to Haredi Jews, with if anything much more local production, but less oriented towards scholarship, and they forgo many of the benefits of industrial technology. This might be fine for short-term quality of life (most Amish come back from Rumspringa, after all), but not a thing that can inherit the stars. Orson Scott Card’s writing about being a Mormon outside traditionally Mormon areas like Utah is recognizably similar to the way committed liberal Jewish parents write about Judaism.</p><p>Academic communities seem to take a different horn of the liberal trilemma. They focus on the integrity of their <em>intellectual production</em> - which if not quite an economic production relationship, is at least an economic <em>service</em> relationship with the universities - but child-raising and personal ethics are regarded for the most part as a private matter. Colleges have clearly gotten worse, but part of this is that they have to work with the students they get, who seem to be getting worse year after year. (See <a href=\"https://jewishreviewofbooks.com/articles/2668/the-closing-of-the-american-mind-now\">this retrospective</a> on Bloom’s <em>The Closing of the American Mind</em> for a decent argument that scholarship is doomed without communities that bring up children to be good potential scholars.) Academics are neither in control of their own livelihoods (as communities they depend on outside funders) nor their other necessary inputs (since they don’t regulate the upbringing of the students they teach, and are often even at the mercy of administrators for admissions).</p><p>My mostly-uninformed sense of hippie communes is that they seem to have the hang of living well, but don’t do engineering to make progress or trade much or compete with with the industrial economy. This makes them much like the Amish, though perhaps they have more fun.</p><p>Anarchists are stereotyped as oppositional rather than focusing on building new alternatives, but I don’t really know. My uninformed impression is that they are poor and unhappy, but again I really don’t know.</p><p>And then there’s Burning Man. Burning Man only lasts two weeks. That’s not enough time to raise a new generation. It also has a taboo against producing artifacts of lasting value - you leave no trace. The main nice thing about it - by reputation, I haven’t gone - is that it brings engineers and hippies together <em>at all</em>. See <a href=\"http://kristinafmiller.com/the-problem-with-burning-man/\">Kristina Miller’s piece on Burning Man</a> for a more detailed treatment.</p><p>Basically all these groups seem worth learning more about, now that I have eyes to see them with.</p><p>Of course, I might be wrong about the Quakers. They might actually have a lot going on that I haven’t found out about yet, that answers all my objections. I could easily not have heard of this - they don’t advertise much, after all. If so, I’d be delighted to learn about that.</p><p><a href=\"http://benjaminrosshoffman.com/why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i-should-be/\">Cross-posted</a> at my personal blog.</p></div></div></div></div>",
    "user": {
      "username": "Benquo",
      "slug": "benquo",
      "displayName": "Benquo"
    }
  },
  {
    "_id": "o2bfgs9FTTMR4jnY3",
    "title": "Translating CFAR to Therapy",
    "slug": "translating-cfar-to-therapy",
    "pageUrl": "https://www.lesswrong.com/posts/o2bfgs9FTTMR4jnY3/translating-cfar-to-therapy",
    "postedAt": "2017-09-26T07:00:00.000Z",
    "baseScore": 27,
    "voteCount": 24,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div dir=\"ltr\" style=\"text-align: left;\" trbidi=\"on\">The Center for Applied Rationality has given its alumni a number of excellent tools to work on their bugs. Going through a workshop myself, I found that a lot of these tools are similar to therapeutic techniques, just reformatted to fit a more self-help-y context. Going through the workshop as a therapist, I had two goals: learn to use these techniques myself, and learn the translation between therapeutic technique and self help (in both ways!). As a therapist, it is useful to take self help techniques and turn them into something you can use in the room with a client. Similarly, it is useful to be able to take a therapeutic technique and find a way for the client to do it themselves at home. After all, the ultimate goal of a therapist is to get their clients to a space where they don't need therapy.<br /><br />Just as translating therapy to self help is useful for ending therapy, translating self help to therapy is useful in beginning. When I begin seeing a client, one of my first questions is \"What have you tried?\". I want to know not only what has worked, but also what hasn't, and why, because this informs my theory as well as my choice of techniques.<br /><br />That said, below I'm going to write a little bit about some of the techniques, and what you can learn about yourself based on which techniques work for you. Some of this may even hint at what types of therapy may work well for you. Of course, none of this is certain. You are not my client and I don't know you personally; most of this ranges from well-researched speculation to evidenced by anecdotes.<br /><br /><b>Bugs lists</b><br />If just the process of writing out your bugs is helpful in fixing them, there are a number of self help CBT resources that might be helpful. One of my favorites is called <a href=\"https://moodgym.com.au/\" target=\"_blank\">Mood Gym</a>. If you are the kind of person who feels better just noticing how your thinking is illogical, CBT will probably do very well for you.<br /><br /><b>Inner Simulator</b><br />What CFAR calls the Inner Sim is pretty close to what Attachment Theory calls the<a href=\"https://www.sicotests.com/darticle.asp?page=204\" target=\"_blank\"><span id=\"goog_1373708554\"></span> Internal Working Model<span id=\"goog_1373708555\"></span></a>, and while pure Attachment Theory is something I'd use only for particular, deeply rooted issues, it is possible that including attachment work in your therapy would be useful if your Inner Sim tends to fail when it comes to what you expect out of interpersonal interactions.<br /><br />It is also possible that kinks in your Inner Sim are due to problems with your narrative. If attempting Pre-hindsight always turns up the same answers (ie \"What went wrong? I couldn't do it.\") it might be good to check if this is due to problems in your self narrative (ie \"I can't do anything right.\"). The theory that looks the most at this is called <a href=\"https://positivepsychologyprogram.com/narrative-therapy/\" target=\"_blank\">Narrative Theory</a>, as you might expect.<br /><br /><b>Goal Factoring</b><br />Although often compared to <a href=\"https://panicattackrecovery.com/index.php/another-cbt-technique-for-anxiety/\" target=\"_blank\">Cost Benefit Analysis</a>, I would be hesitant to assume that someone who likes goal factoring would like CBT. If this works for you for the same reason that creating a pros and cons list would, think of Cost Benefit Analysis as a step between that and Goal Factoring.<br /><br />However, many people find that the biggest difference between these other techniques and Goal Factoring comes from the focus on whatever it is you want. If this is the case, <a href=\"http://www.motivationalinterviewing.org/\" target=\"_blank\">Motivational Interviewing</a> focuses on figuring out what motivates the client, and using that to come up with solutions.<br /><br /><b>Trigger-Action Planning</b><br />If you find that TAPs are the most useful thing you got out of the workshops, you might find other behavior modification techniques about as useful. Here we're talking more <a href=\"https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1931/2017/05/30180728/yjh0qdsqlzlkxwt2zwgs.png\" target=\"_blank\">positive and negative reinforcement</a>, as well as positive and negative punishment. Pure behaviorism is something a lot of therapists are hesitant to use unless a client suggests it, so if your therapist isn't specialized in this (ie many therapists who work with phobias are) then this might be something you have to bring up to them.<br /><br /><b>Socratic Ducking and Pair Debugging</b><br />If you often find that venting your problems leads you to a solution, it's possible that <a href=\"https://www.goodtherapy.org/learn-about-therapy/types/person-centered\" target=\"_blank\">Rogerian Therapy</a> (also called Person-Centered) is likely to work well for you. And if this is the case, you're lucky; you might not have to see a licensed therapist to get what you need. Since this is one of the more basic forms of therapy, going to a clinician in training may be just as good. If you process information better through text, or don't have the ability to see someone, websites like <a href=\"https://www.7cups.com/member/\" target=\"_blank\">7 Cups of Tea</a> train people in active listening. You can use this for a one-off conversation, or regularly go back to the same Listener again and again to sort through things.<br /><br />If your focus is more oriented toward self growth and less solving problems, <a href=\"https://www.goodtherapy.org/learn-about-therapy/types/psychodynamic\" target=\"_blank\">Psychodynamic Therapy</a> also involves lots of client talking and therapist listening, but instead of just trying to understand the problem and situation, the therapist is trying to more deeply understand the client, and why they think the way they do. If your problem is likely to be rooted in past experiences and trauma, Psychodynamic is also more likely to be helpful.<br /><br />In Pair Debugging, it is made very clear that the Debugger's goal isn't to solve the problem, but to understand it. If you wanted someone to just throw solutions at you, <a href=\"https://solutionfocused.net/what-is-solution-focused-therapy/\" target=\"_blank\">Solution-Focused Therapy</a> does exactly this.<br /><br /><b>Shoulds</b><br />The section on Shoulds is not far from&nbsp;<a href=\"http://www.tristatebariatrics.org/cognitive-behavioral-therapy-get-rid-of-those-shoulds/\" target=\"_blank\">what CBT says</a> about shoulds. CBT categorizes shoulds as a type of faulty thinking, so if the most helpful part of Understanding Shoulds is the thought that even a false belief can feel true, I'd once again recommend CBT. However, Shoulds remind us of our goals, and if you find Shoulds particularly good at this, it might be good to look at <a href=\"https://www.psychologytoday.com/therapy-types/humanistic-therapy\" target=\"_blank\">Humanistic theories</a> or <a href=\"https://www.selfleadership.org/about-internal-family-systems.html\" target=\"_blank\">Internal Family Systems</a>. Humanistic theories are good if you see Shoulds at pointing to a need you have deep down, whereas Internal Family Systems is more likely to see Shoulds as coming from a particular part of you that has important things to say. Essentially, the difference here is whether you want to do parts work or not.<br /><br /><b>Focusing</b><br />While focusing is used in many kinds of therapy, it is found most commonly in Humanistic theories such as <a href=\"https://healingrefuge.com/approaches/gestalt-therapy-and-focusing/\" target=\"_blank\">Gestalt</a>. As with Shoulds, it can be used with IFS, in this case as a way of <a href=\"http://www.hakomiinstitute.com/Forum/Issue16-17/a_DaveCole.pdf\" target=\"_blank\">noticing which parts want to speak</a> and what they have to say. If focusing works well for you, one of these theories might also work well, though again, which one you pick depends more on your philosophy of the self.<br /><br /><b>CoZE</b><br />This one's a bit of a stretch, so bear with me. If comfort zone expansion is your thing, <a href=\"http://www.crchealth.com/types-of-therapy/what-is-experiential-therapy/\" target=\"_blank\">Experiential Therapy</a> might work well. This is especially the case if you're seeking family or couples therapy. The thought here is that for Experiential Therapy to feel fulfilling, your client needs high Openness to New Experience (on the Big 5) and the more into CoZE you are, the higher that Openness is likely to be. If you were in session with a therapist and your therapist said \"Let's try an experiment\", would that excite you, or scare you? Typically, therapeutic experiments play out similarly to CoZE: try this thing, notice what it feels like, and notice what happens, then talk about it. If this sounds good to you, Experiential Therapy might be a good fit.<br /><br /><b>Resolve Cycles</b><br />If brainstorming solutions seems like the best way to approach a problem, Solution-Focused Therapy might be good for you. In particular if the time pressure that comes with Resolve techniques are helpful, <a href=\"http://www.sfbta.org/about_sfbt.html\" target=\"_blank\">Brief Therapy</a> might also be helpful. Though Brief Therapy is usually only recommended in cases where money or time is an issue, Having a set, limited number of sessions with a therapist may motivate you in the same way that Resolve Cycles do.<br /><b><br /></b><b>Internal Double Crux</b><br />Since IDC relies on the use of parts, anyone for whom this works might want to try <a href=\"https://www.goodtherapy.org/learn-about-therapy/types/internal-family-systems-therapy#What Happens in an IFS Session?\" target=\"_blank\">IFS</a>. One of the hardest parts of IFS is understanding all the parts involved without judgment, and if you are able to handle those demands while doing IDC, then IFS is likely to work well for you.<br /><br /><b>Hamming Questions</b><br />At the workshop I went to, we were given a list of Hamming Questions, and some time on each one. To many, it was obvious which kinds of questions were more fruitful. Some questions force you to think of the narrative of your life (ie \"If your life is a novel, what is that obvious next thing?\") which suits Narrative Therapy. The idea of using something convenient as \"pica for\" something you need fits a number of Psychodynamic techniques and ideas really well. And of course, Gendlin's Focusing check lends itself to Humanistic theories, since they often employ focusing or similar techniques to bring up bugs and problems.<br /><br /><br /></div>",
    "user": {
      "username": "squidious",
      "slug": "squidious",
      "displayName": "squidious"
    }
  },
  {
    "_id": "tKTcrnKn2YSdxkxKG",
    "title": "Frontpage Posting and Commenting Guidelines",
    "slug": "frontpage-posting-and-commenting-guidelines",
    "pageUrl": "https://www.lesswrong.com/posts/tKTcrnKn2YSdxkxKG/frontpage-posting-and-commenting-guidelines",
    "postedAt": "2017-09-26T06:24:59.649Z",
    "baseScore": 24,
    "voteCount": 24,
    "commentCount": 25,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<p>Welcome to the new <em>LessWrong! </em>Our goal with the <em>LessWrong</em> frontpage is to host high-quality discussion on a wide range of topics, in a way that allows users to make better collective progress toward the truth.</p><p>New posts automatically get posted to a user&#x27;s <em>personal blog</em>, where people are free to talk about whatever they like. By default, moderators will consider whether the post is a good fit for the frontpage. If you don&#x27;t want the post to appear on frontpage, you can uncheck &quot;moderators can promote&quot;.</p><p><strong>1. Things to shoot for on frontpage</strong></p><p>1.1. <em>Usefulness, novelty, and fun.</em> The frontpage of this site is for serious intellectual engagement with interesting ideas, with a focus on ideas that are important but challenging to evaluate. Topics that lack inherent importance are OK if the discussion quality is high enough, and particularly if the discussion is useful for other purposes, like building skills; but the best topics will usually be consequential and neglected ones.</p><p>1.2. <em>Accuracy, kindness, and relevance to the discussion at hand</em>, in the spirit of the <a href=\"http://slatestarcodex.com/2014/03/02/the-comment-policy-is-victorian-sufi-buddha-lite/\">Victorian Sufi Buddha ideal</a>.</p><p>1.3. <em>Clarity and openness about what you believe, your reasons for believing it, and what would cause you to change your mind. </em>Try to make concrete <strong>predictions</strong> and <strong><a href=\"http://marginalrevolution.com/marginalrevolution/2012/11/a-bet-is-a-tax-on-bullshit.html\">bets</a></strong>, and to note the <strong><a href=\"https://www.lesserwrong.com/lw/o6p/double_crux_a_strategy_for_resolving_disagreement/\">cruxes</a></strong> for your beliefs, where possible. It’s not always easy to clearly articulate a belief, and it&#x27;s great to note places where you’re uncertain about what you believe, about your reasons, and about your cruxes. We don’t want people to feel like they have to conceal or immediately abandon their beliefs whenever those beliefs turn out to be nontrivial to articulate or justify. But incremental progress toward more clarity and openness, even if it’s incomplete, is highly valued here.</p><p>A corollary of 1.3 is that we often prefer descriptive language (including language describing your current beliefs, emotional state, etc.) over prescriptive language, all else being equal. Prescriptions are obviously an essential part of communication, but descriptions are generally easier to relate to evidence, predictions, and cruxes. We encourage putting a focus on them for that reason.</p><p><strong>2. Things to keep to a minimum</strong></p><p>2.1. <em>Community-focused discussion</em> — i.e., discussion about the <em>LessWrong</em>/rationality community, as opposed to discussion about particular object-level topics. We want to avoid dynamics like (from <a href=\"https://books.google.com/books?id=1HxzLaPYo2IC&pg=PA82&lpg=PA82&dq=When+I+was+in+High+School,+one+of+the+first+honors+I+got+was+to+be+a+member+of+the+Arista&source=bl&ots=qXojbPILrs&sig=8vYnFZmrDB8X39LVptSOrYvihdg&hl=en&sa=X&ved=0ahUKEwjMrdPPq7TWAhWo6YMKHVxMDbIQ6AEILzAC#v=onepage&q&f=false\">Feynman</a>):</p><blockquote>When I was in high school, one of the first honors I got was to be made a member of the “Arista,” which was a group of kids who got good grades, hmm? Everybody wanted to be a member of the Arista, and when I got into this Arista I discovered that what they did in their meetings was to sit around to discuss who else was “worthy” to join “this wonderful group that we are,” okay?</blockquote><p>If you want to discuss the community more generally, and you don’t expect the discussion to be of much interest to people who just want to talk about object-level issues (in psychology, or physics, or zoology, or cryptography, or…), it&#x27;s best to leave it in your personal blog section.</p><p>Questions about the site itself are welcome in the <strong><a href=\"https://www.lesserwrong.com/meta\">Meta</a></strong> section. </p><p>2.2. <em>Crowdedness</em><strong> —</strong> i.e., topics that are already really widely discussed in the public sphere, and where it will therefore be harder to say something new.</p><p>2.3 <em>Things of fleeting importance</em> — i.e., topics that will only be of interest for a couple of weeks, like discussions of what a politician has been doing. We want the frontpage of <em>LessWrong</em> to serve both as a training ground for aspiring rationalists and as an archive of accumulated collective knowledge. The ideal discussion will therefore both help build skills and help build knowledge that are valuable down the line. Not every discussion needs to achieve that ideal, but it’s a useful one to keep in mind.</p><p>We may build features in the future that are for more short-form and clearly ephemeral content on <em>LessWrong</em>. If so, this will be in a new section of the site built to be less like a repository of timeless information and discussion, and more like (e.g.) a Facebook feed.</p><p>2.4 <em>Hot-button political issues</em><strong> —</strong> Highly politicized issues tend to be very viral, which can often lead to them dominating discussion. These issues often (though not always) score poorly on tractability and neglectedness; they’re often emotionally charged in ways that make convergence and skill-building more challenging; and discussion is often triggered by transient news items, as opposed to deep new insights that will be equally relevant years down the line. “Politics is an important domain to which we should individually apply our rationality—but it&#x27;s a <a href=\"http://lesswrong.com/lw/gw/politics_is_the_mindkiller/\">terrible</a> domain in which to learn rationality”. This means that highly politicized issues will often score poorly on 1.1, 2.2, and 2.3.</p><p>Of course, what counts as a “hot-button political issue” isn’t always clear, and we don’t want to encourage agonizing or arguing about what counts. (See 2.1.) We just want to encourage users to use their judgment and do their best to keep it to a minimum, so that other topics aren’t crowded out. </p><p><strong>3. Off-limits things</strong></p><p>3.1. <em>Serious violations of discourse norms</em> — Threatening behavior, needlessly harsh personal attacks, harassment, doxxing, and so on.</p><p>3.2. <em>Consistently disruptive or low-quality content</em> — Spam, discussion derailing, and so on.</p><p>A list of users with bans or public warnings can be found <a href=\"https://www.lesserwrong.com/posts/vWEgN376HazKn6vGC/moderation-list-warnings-and-bans\">here</a>.</p><p><strong>4. How moderation works</strong></p><p>Compared to moderators on other online forums, moderators on <em>LessWrong</em> are granted greater ability to change and improve the website, and are trusted with more information. These roles of responsibility are only given to trusted members of the community, and they are known as the <em>Sunshine Regiment.</em></p><p>The new, weighted karma system is designed to bring good content to the top. However, this karma system is based on the voting patterns of many individuals, most of whom do not have the time to reflect on big-picture trends, nor the resources to substantially change those trends. In a classic tragedy of the commons, when there are thousands of people voting, no individual is incentivised to spend a lot of time considering their vote.</p><p>The incentives set up by the karma system can be considered the community’s <a href=\"https://www.lesserwrong.com/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">System 1</a>, and the Sunshine Regiment can be thought of as the community&#x27;s System 2. Sunshines think about what incentive gradients are being produced, and are given the resources to influence the incentive gradients in a more substantial way (e.g. karma rewards on comments), allowing the community to plan around obstacles and achieve more complex goals.</p><p>There are no hard rules about what comments each member of the Sunshine Regiment will give karma rewards to. If your submission has received a karma reward, it will be signified by a small star icon on that comment or post. If your submission has been removed by a Sunshine, they will leave a note explaining why the comment was inappropriate or unsuited to the <em>LessWrong</em> frontpage.</p><p>Members of the Sunshine Regiment will have access to more information than other users, allowing them to notice negative patterns of behaviours, such as sockpuppet accounts and mass downvoting. The extra information is:</p><ul><li>Access to the identities of voters on any comment/post, and to the voting history of all users.</li><li>The IP address a user wrote a post or comment from.</li></ul><p>Sunshines of the 1st LessWrong Regiment are:</p><ul><li>Jim Babcock (<a href=\"https://www.lesserwrong.com/users/jimrandomh\">jimrandomh</a>)</li><li>Rob Bensinger (<a href=\"https://www.lesserwrong.com/users/robbbb\">RobBensinger</a>)</li><li>Satvik Souza Beri (<a href=\"https://www.lesserwrong.com/users/satvikberi\">SatvikBeri</a>)</li><li>Ruby Bloom (<a href=\"https://www.lesserwrong.com/users/ruby\">Ruby</a>)</li><li>Adom &#x27;Quincy&#x27; Hartell (<a href=\"https://www.lesserwrong.com/users/ahartell\">ahartell</a>)</li><li>Elizabeth Van Nostrand (<a href=\"https://www.lesserwrong.com/users/pktechgirl\">elizabeth</a>)</li><li>Ben Pace (<a href=\"https://www.lesserwrong.com/users/benito\">Ben</a>)</li><li>Keller Scholl (<a href=\"https://www.lesserwrong.com/users/celer\">Celer</a>)</li><li>Kaj Sotala (<a href=\"https://www.lesserwrong.com/users/kaj_sotala\">Kaj_Sotala</a>)</li></ul><h2>Related Links</h2><ul><li><a href=\"https://www.lesswrong.com/posts/njbe3gwkS4KX9bd3d/moderation-reference\">Moderation Reference</a> (A repository of reasoning and judgments the moderators have used that requires a bit of effort to explain, which we wanted to be able to easily reference if the issue came up again)</li><li><a href=\"https://www.lesswrong.com/posts/vWEgN376HazKn6vGC/moderation-list-warnings-and-bans\">Moderation List of Warnings and Bans</a></li><li>Posts on philosophy of moderation:</li><ul><li><a href=\"https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism\">Well Kept Gardens Die by Pacifism</a> (Eliezer Yudkowsky)</li><li><a href=\"https://www.lesswrong.com/posts/bGpRGnhparqXm5GL7/models-of-moderation\">Models of Moderation</a> (Habryka)</li><li><a href=\"https://www.lesswrong.com/posts/5Ym7DN6h877eyaCnT/meta-tations-on-moderation-towards-public-archipelago\">Public Archipelago</a> (Raemon)</li></ul></ul>",
    "user": {
      "username": "Benito",
      "slug": "benito",
      "displayName": "Ben Pace"
    }
  },
  {
    "_id": "HRy2sFtXBjLbxQnqu",
    "title": "The Best Self-Help Should Be Self-Defeating",
    "slug": "the-best-self-help-should-be-self-defeating",
    "pageUrl": "https://www.lesswrong.com/posts/HRy2sFtXBjLbxQnqu/the-best-self-help-should-be-self-defeating",
    "postedAt": "2017-09-26T06:16:32.059Z",
    "baseScore": 6,
    "voteCount": 6,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Cross-post from <a href=\"https://mindlevelup.wordpress.com/2017/09/24/the-best-self-help-should-be-self-defeating/\">blog</a>.</p><p><em>[Self-help is supposed to get people to stop needing it. But typical incentives in any medium mean that it’s possible to get people hooked on your content instead. A musing on how the setup for writing self-help differs from typical content.]\r</em></p><p>Say you have a job as a Self-Help Guru. You spend your days giving out your worldly advice to those who seek guidance on their problems.\r</p><p>I claim that if you’re doing job as a Self-Help Guru right, then you should never have repeat customers.\r</p><p>That’s the gist behind the idea that the best self-help should be self-defeating.\r</p><p>Here are some analogies of things that I think are like self-help:\r</p><ul><li><p>The point of taking antibiotics is so that you eventually stop taking them and feel better.\r</p></li><li><p>The point of wearing glasses is so that you can stop squinting and see more clearly.\r</p></li><li><p>The point of reading a programming textbook is so you can eventually start writing programs on your own.\r</p></li></ul><p>My claim is that if you’re trying to do self-help right, you want people to be able to “graduate” from your ideas and figure out what actually works for them. In a sense, you want to catalyze people to find their own optimal solutions instead of consisting coming back to you for more help every time.\r</p><p>You want them to go off on their own adventures in life, confident that they have the ability to craft new tools when the ones you give them stop working.\r</p><p>Once again, the <a href=\"https://mapandterritory.org/recognizing-vs-generating-an-important-dichotomy-for-life-3b6b6fc67478\">Recognize vs Generate</a> dichotomy comes into play here. Following advice someone else gave you can look about the same as coming up with something similar on your own. But being the sort of person who can generate solutions independently is far more effective in the long run.\r</p><p>Basically I claim the whole point of self-help is to help people help themselves.\r</p><p>Not that controversial a viewpoint. The real problem, I think, comes in when we consider the way that self-help gets publicized and published.\r</p><p>First off, consider the incentives of many media like newspapers, television channels, novels, or vloggers. Growing an audience is an explicit part of their goals; after all, their profits are largely tied to their viewership. As a result, it makes a lot of sense for them to come out with constant content—it keeps the original crowd coming, and a constant presence means it can draw more people in.\r</p><p>But self-help is different. Arguably, the content isn’t even the real point; the real point is something about the self-help “attitude” which enables them to solve future problems. You want them to level up and then head off to do great things in the real world.\r</p><p>Entertainment isn’t the point, so you don’t really want people binging on your content. You want them to read the content, learn whatever lessons are useful for them, and then move on.\r</p><p>Which means that some sort of constant, fluctuating, or even decreasing number of readers can actually be a sign that you’re doing things correctly.\r</p><p>This stark conflict between typical media incentives for publicity and the lofty goals of self-help hits at the heart of the issue, I think. My claim is that basically everyone trying to do self-improvement has gone way off into the “maximize profits and publicity” direction rather than the “maximize beneficial impact of the content” direction.\r</p><p>Here’s a hypothetical situation: someone with genuinely altruistic motivations might want to first write some clickbait-type articles to bring in an audience, and then provide more real insights.\r</p><p>“I’ll just do the trashy stuff first, and then I’ll gradually transition to deeper stuff later,” they think.\r</p><p>And that’s fair; none of this self-help stuff is happening in a vacuum. Battles for attention in the modern world are zero-sum, and the other side (i.e. all other media) is already optimizing the hell out of “attention-grabbiness”.\r</p><p>But that’s perhaps too unrealistic. Basically no one is that calculating. I’m not explicitly accusing self-help writers of being evil masterminds who write addictive content under the guise of self-improvement in order to make profits.\r</p><p>Rather, I just think that throughout the normal course of writing self-help content, writers will just have to make certain decisions which trade off the direct benefit of content.\r</p><p>One obvious example is the choice in media format. Books are self-contained and seem to stand at one end of an axis which has Twitter tweets and Facebook posts on the other. For books, feedback from the reader is far less immediate (worse for the author), and the payoff to the reader is far less instant (worse for the reader). But if you go all the way to the other end, you’re trading off conceptual complexity, the ability to explain deeper ideas.\r</p><p>There are also subtler things. For example, there are certain design choices when making blogs to reduce binging, like removing infinite scroll, which are probably in your readers’ best interests. Most of those choices will also reduce traffic on your site as a whole.\r</p><p>It’s not even media format or design choices:\r</p><p>When you think you have good content, you’re going to want to share it to others. After all, the only way that self-help materials help others is if people read them in the first place.\r</p><p>And it’s just the case that most ways to get more people interested and spread your content involve increasing the level of “memetically stickiness” or “fun-to-read-ness”, both of which are orthogonal to “ability to level up the reader” and often trade off against it.\r</p><p>The incentive structure for self-help is unfortunately set up in such a way that the traditional ways of cultivating engagement don’t work well with it.\r</p><p>I think one of the worst things that can happen is for people to become a sort of “insight junkie”, where they’re always craving the next mental model or productivity hack, rather than staring down the obvious advice.\r</p><p>The tldr; here is that this is a potential trap for people (me included!) who think they have good content to share. Attempts to reach a wider audience and become more memetically sticky can backfire when you end up getting people hooked on insight-porn-esque longform essays, rather than going out into their lives and being more awesome.</p></div></div></div></div>",
    "user": null
  },
  {
    "_id": "3MjXPtimkhQf7kcWD",
    "title": "Thinking on the page",
    "slug": "thinking-on-the-page",
    "pageUrl": "https://www.lesswrong.com/posts/3MjXPtimkhQf7kcWD/thinking-on-the-page",
    "postedAt": "2017-09-26T02:22:38.440Z",
    "baseScore": 8,
    "voteCount": 7,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>“Thinking on the page” is a handle that I’ve found useful in improving my writing (and my introspection more generally). When I write, for the most part, I’m trying to put something that I already feel is true into words. But when I think on the page, the words are getting ahead of my internal sense of what’s true. I’m writing something that just sounds good, or even just something that logically flows from what I’ve already written but has come untethered from my internal sense. It’s kind of a generalized verbal overshadowing.\r</p><p>I don’t think this is challenging only to people who think [of themselves as thinking] non-verbally, considering how much more universal are experiences like “this puts exactly what I believe into words better than I ever could” or even the satisfaction of finding a word on the tip of the tongue. Some people seem to be better than others not just at describing their internal sense of truth, but at tapping into it at all. But if you think only in internal monologue, you may have a very different perspective on “thinking on the page”—I’d be interested to hear about it.\r</p><p>At best, this is what happens in what Terry Tao calls <a href=\"https://terrytao.wordpress.com/career-advice/there%E2%80%99s-more-to-mathematics-than-rigour-and-proofs/\">the “rigorous” stage</a> of mathematics education, writing, “The point of rigour is not to destroy all intuition; instead, it should be used to destroy bad intuition while clarifying and elevating good intuition.” At worst, it’s argument based on wordplay. Thinking on the page can be vital when you’re working beyond your intuition, but it’s equally vital to notice that you’re doing it. If what you’re writing doesn’t correspond to your internal sense of what’s true, is that because you’re using your words wrong, or because you need to use the page as prosthetic working memory to build a picture that can inform your internal sense?\r</p><p>The two places this becomes clearest for me are in academic writing and in art critique. Jargon has the effect of constantly pulling me back towards the page. If it doesn’t describe a native concept, I can either heroically translate my entire sense of things and arguments about them into jargon, or I can translate the bare raw materials and then manipulate them on the page—so much easier. As for art, the raw material of the work is already there in front of me—so tempting to take what’s easy to point to and sketch meaning from it, while ignoring my experience of the work, let alone what the raw material had to do with that experience.\r</p><p>A lack of examples often goes hand in hand with thinking on the page. Just look at that last paragraph: “translate”, “raw materials”, “manipulate”—what am I even talking about? An example of both the jargon and art failure modes might be my essay about <a href=\"http://more-whales.tumblr.com/post/98211576742/ive-been-reading-some-of-su3su2u1s-comments-on\">Yu-Gi-Oh! Duel Monsters</a>. My analysis isn’t entirely a joke, but it’s not a realistic reading in terms of the show’s experiential or rhetorical effect on the audience, intended or otherwise. The protagonist’s belief in the heart of the cards and his belief in his friends are genuinely thematically linked, but neither one is the kind of “shaping reality by creative utterance” that has anything to do with how the characters talk their way around the procedural weirdness of the in-show card game as game. But when I put all these things in the same language, I can draw those connections just fine. I’m playing a game with symbols like “creative utterance”.\r</p><p>How can one notice when this is happening? Some clues for me:\r</p><ul><li><p>I feel like I’m moving from sentence to sentence rather than back and forth between thought and sentence\r</p></li><li><p>I feel something like “that’s not quite right”\r</p></li><li><p>I feel a persistent “tip of the tongue” sensation even after writing\r</p></li><li><p>I feel clever\r</p></li><li><p>I haven’t used an example in a while\r</p></li><li><p>I’m using jargon or metaphor heavily\r</p></li></ul><p>What can one do after noticing?\r</p><ul><li><p>Try to pull the words back into your internal picture, to check whether they fit or not—they might, and then you’ve learned something\r</p></li><li><p>Rewrite without self-editing until something feels right, with permission to use as many words or circumlocutions as it takes\r</p></li><li><p>Try to jar the wording you want mentally into place by trying more diverse inputs or contexts (look at distracting media, related essays, a thesaurus)\r</p></li><li><p>Ask “but is that true?”\r</p></li><li><p>Connect with specific examples\r</p></li><li><p>Focus on the nonverbal feeling you want to express; try to ask it questions\r</p></li></ul><p>What’s a good way to practice?\r</p><ul><li><p>Write reviews of art/media you encounter, then read other people’s reviews. As far as “not being led astray by thinking on the page” is more than the zeroth-level skill of writing-as-generically-putting-things-into-words, I think this is a good place to practice what’s particular to it. People seem to have a good enough sense of what they liked and why for good criticism to resonate, but often not enough to articulate that for themselves, at least without practice. So it can be good to pay attention to where the attempted articulations go wrong.\r</p></li><li><p>Write/read mathematical proofs or textbook physics problems, paying attention to how the steps correspond to your sense of why the thing is true (or using the steps to create a sense of why it’s true)\r</p></li><li><p>If it seems like the sort of thing that would do something for you, find or develop a meditation practice that involves working with &quot;felt senses&quot; (I don&#x27;t have a real recommendation here, but it&#x27;s the kind of thing Focusing aims for)\r</p></li></ul><p>The goal isn’t to eliminate thinking on the page, but to be more deliberate about doing it or not. It can be useful, even if I haven’t said as much about that.\r</p><p>One thing I don’t recommend is using “you’re thinking on the page” as an argument against someone else. If you find yourself thinking that, it’s probably an opportunity to try harder to get in their head. Like most of these things, as a way thinking can go wrong, this is a concept best wielded introspectively.\r</p><p>(Here’s a puzzle: if this is a first-level skill, can you go up another level? If I’m saying something like “felt senses/thoughts want to make words available”, then what things “want to make felt senses available”? Can you do anything with them?)</p><p>[<a href=\"http://whaaales.com/thinking-on-the-page/\">cross-posted from</a> my personal blog]</p></div></div></div></div>",
    "user": {
      "username": "whales",
      "slug": "whales",
      "displayName": "whales"
    }
  },
  {
    "_id": "hxEbaEeFhmMTJDvGY",
    "title": "Why I Quit Social Media",
    "slug": "why-i-quit-social-media",
    "pageUrl": "https://www.lesswrong.com/posts/hxEbaEeFhmMTJDvGY/why-i-quit-social-media",
    "postedAt": "2017-09-26T00:58:28.379Z",
    "baseScore": 9,
    "voteCount": 6,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "https://srconstantin.wordpress.com/",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><em>Epistemic Status: Personal</em></p><p>I’m not a Puritan. I eat dessert, enjoy a good cocktail, and socialize a lot.  I like fun, and I don’t think fun is wrong.</p><p>So I really understand the allergy to messages of ascetic self-denial.</p><p>But lately I’ve found it necessary to become more like <a href=\"https://srconstantin.files.wordpress.com/2017/09/220px-athena_giustiniani.jpg\">this...</a> and less like <a href=\"https://srconstantin.files.wordpress.com/2017/09/woman-crying-mascara.jpg\">this</a>.</p><p>More balanced, deliberate, reflective. Less needy, emotionally unstable, dramatic, and attention-seeking.</p><p>I’ve written about this process <a href=\"https://srconstantin.wordpress.com/2017/06/19/momentum-reflectiveness-peace/\">here</a>, <a href=\"https://srconstantin.wordpress.com/2017/05/18/dwelling-in-possibility/\">here</a>, <a href=\"https://srconstantin.wordpress.com/2017/04/25/on-drama/\">here</a>, <a href=\"https://srconstantin.wordpress.com/2017/03/25/closer-to-fine/\">here</a>, and <a href=\"https://srconstantin.wordpress.com/2017/03/09/4896/\">here</a>.  I’ve been at it for about a year.</p><p>Why is it worth being less of a drama queen?  In some ways, equinamity is a lot less fun.</p><p>But, ultimately, being a drama queen is a dependent’s lifestyle. It makes you unable to function on your own.  As a practical matter, I am not a dependent, and so I sometimes need to do things — in real life, outside of my own head, where the actual state of the world matters.</p><p>I also think it’s wrong to constantly interrupt things other people are doing to change the subject to All About Me.</p><p>And, basically, that’s what social media does. It distances you from reality, makes you focus on a shadow-world of opinions about opinions about opinions; it makes you more impulsive and emotionally unstable; it incentivizes derailing conversations to fish for ego-strokes.</p><p>I don’t dislike petty bullshit — I enjoy it all too much.  I could happily spend eternity picking fights and chasing drama if somehow that were feasible.</p><p>So I asked myself “is there, ultimately, anything wrong with living in a world of screams and shadows and impulse pleasures?  Do I actually care about anything else?” And the answer was “Unfortunately, yeah. I have to literally sustain my own life, and there are people I genuinely care about.  So…ok, reality matters.”</p><p>And if reality matters, <em>obviously you shouldn’t be doing stuff that makes you into a moron</em>.</p><p>Life after social media isn’t hard, in my experience.  Life without one pleasure isn’t miserable, because there are other pleasures. The brain’s pleasure mechanisms are damnably homeostatic; you adjust to about the same amount of average happiness, regardless of how intense or mild the pleasures in your daily life.  I miss the drama of social media now and then, but not most days.</p><p>I think if you consider yourself reality-oriented or “serious”, then quitting social media should be overdetermined.</p><p>I’m a little more ambivalent about all that — I’m the kind of person who might plug myself into the <a href=\"https://en.wikipedia.org/wiki/Experience_machine\">Experience Machine</a> — but I think as long as we live on a planet with limited resources, a pure life of fantasy is suicidal, and at least sometimes we have to deal with reality.  And we should at least not mislead, or dissipate the efforts of, people who are trying to deal with reality.</p><p>Plus, even for dreamers like myself, I think there might someday be a better <a href=\"https://en.wikipedia.org/wiki/Annwn\">Annwfn </a>than Facebook.</p><p></p><p></p></div></div></div></div>",
    "user": {
      "username": "sarahconstantin",
      "slug": "sarahconstantin",
      "displayName": "sarahconstantin"
    }
  },
  {
    "_id": "wdog5rAoCFJqRihd4",
    "title": "Travel Journal: Hawaii",
    "slug": "travel-journal-hawaii",
    "pageUrl": "https://www.lesswrong.com/posts/wdog5rAoCFJqRihd4/travel-journal-hawaii",
    "postedAt": "2017-09-25T22:00:48.000Z",
    "baseScore": 1,
    "voteCount": 0,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Putanumonit is on the road. With a few hours before my next flight, I have time to share some wiki impressions from a week in Hawaii.</p>\n<p><img data-attachment-id=\"27510\" data-permalink=\"http://putanumonit.com/2017/09/25/travel-journal-hawaii/20170919_111728/\" data-orig-file=\"https://putanumonit.files.wordpress.com/2017/09/20170919_111728.jpg\" data-orig-size=\"3024,4032\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;1.7&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G930P&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1505819848&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.2&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.00053648068669528&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}\" data-image-title=\"20170919_111728\" data-image-description=\"\" data-medium-file=\"https://putanumonit.files.wordpress.com/2017/09/20170919_111728.jpg?w=225\" data-large-file=\"https://putanumonit.files.wordpress.com/2017/09/20170919_111728.jpg?w=768\" class=\"alignnone size-full wp-image-27510\" src=\"https://putanumonit.files.wordpress.com/2017/09/20170919_111728.jpg?w=8064\" alt=\"20170919_111728.jpg\" width=\"4032\" height=\"3024\"></p>\n<h5>Aloha</h5>\n<p>The Hawaiian language is built from some pretty basic blocks. It uses seven consonant sounds (h, k, l, m, n, p, w) and five vowels. Every syllable ends with a vowel and contains at most one consonant. This means that there are only 40 syllables possible in the Hawaiian language, and thus only 65,640 possible words of 3 syllables or less. In contrast, English has hundreds of thousands such words (of course, <i>Hawai&#8217;i </i>is supposed to have four syllables in it and no one cares).</p>\n<p>This isn&#8217;t a problem for Hawaiians. They have around <a href=\"http://www.answers.com/Q/How_many_words_in_the_Hawaiian_language\" target=\"_blank\" rel=\"noopener\">30,000 distinct words</a> for distinct things, and everything else is simply covered by <i>Aloha. </i>Aloha means: hello, love, peace, compassion, mercy, affection, and goodwill towards mankind. It&#8217;s a greeting, <a href=\"https://en.wikipedia.org/wiki/Aloha#Hawai.CA.BBi_Law_of_The_Aloha_Spirit\" target=\"_blank\" rel=\"noopener\">an acronym</a>, and a motto. 90% of businesses in Hawaii contain the word, from Aloha Airlines to Aloha Septic Services Inc.</p>\n<p>I will name every section of this post in accordance with the local custom.</p>\n<h5>Decimaloha</h5>\n<p>The sales tax in Hawaii is supposed to be 4%, but on every restaurant bill it shows up as 4.166%, or exactly 1/24th, or 4% divided by (1 minus 4%). I found this delightful enough that I didn&#8217;t mind paying extra.</p>\n<h5>Circadialoha</h5>\n<p>There&#8217;s not much to do in Maui after dark, so we went to sleep at 10 pm each night and woke up at exactly 6:33 am, when the sun would peek over the volcano ridge and into my eyes. I was in a great mood for the entire vacation, and I wonder if it&#8217;s partly due to falling into a precise circadian rhythm, something that is impossible in New York.</p>\n<p>I like having seasons, but there&#8217;s an upside to having each day be identical besides needing a much smaller wardrobe.</p>\n<h5>Colonialoha</h5>\n<p>In case you missed it, there&#8217;s been an academic freedom controversy so confusing that <a href=\"https://www.thecollegefix.com/post/36998/\" target=\"_blank\" rel=\"noopener\">Noam Chomsky took the right side on it</a>: a professor got a pro-colonialism article published in an anti-colonial journal, leading to an all-too-predictable shitshow. I don&#8217;t know the first thing about colonialism studies, but I began to wonder how colonialism looked like from the point of view of &#8220;regular&#8221; Hawaiians.</p>\n<p>Before white people came, Hawaii had a feudal system with <a href=\"https://en.wikipedia.org/wiki/Aliʻi\" target=\"_blank\" rel=\"noopener\">11 hereditary nobility classes</a>. Most citizens had to pay a tax and serve in the armies of the various nobles as they fought each other over land and prestige. The commoners could be executed for crimes like having their shadow fall on a noble. They were kept in place by having beneath them another <a href=\"https://en.wikipedia.org/wiki/Ancient_Hawaii#Caste_system\" target=\"_blank\" rel=\"noopener\">untouchable caste</a>, members of which were often used as human sacrifices.</p>\n<p>It seems to me that most modern Hawaiians identify with the ancient royals and nobles of the islands, not the commoners. Everything is named after some king or princess, everyone else is basically unknown. But before white people came, most Hawaiians were 12th or 13th class citizens. Afterwards, both the king and the fisherman became second class citizens to the Europeans, which really sucked for the former but probably didn&#8217;t make too much of a difference to the latter. And after a couple centuries of exploitation, at least every Hawaiian of every caste got air conditioning.</p>\n<p>My own country, Israel, has been colonized and recolonized for 4,000 years at least. From the Egyptians and Babylonians to the Ottomans and British (and Arabs and Jews, if you want to use a broad but defensible definition of &#8220;colonization&#8221;). I don&#8217;t know if &#8220;colonialism&#8221; was good or bad for Israel and Hawaii, but I know that AC has been a huge boon for both.</p>\n<h5>Alohungry</h5>\n<p>The best meal in the world under $4 is David&#8217;s falafel in New Ziona. The best meal in the US under $4 is a side of onion potatoes at the <a href=\"https://paiafishmarket.com\" target=\"_blank\" rel=\"noopener\">Paia Fish Market</a>. The freshly caught fish is amazing too, but the potatoes that come with them are way better than something so simple has any right to be. Paia Fish Market has three locations in Maui, and it&#8217;s worth visiting the island just for those.</p>\n<h5>Alohole in One</h5>\n<p>My wife and I hiked, swam, surfed and climbed, but the toughest physical challenge we faced was mini golfing in Ma&#8217;alaea.</p>\n<p>Maui is famous for windsurfing because it&#8217;s very windy. The northeastern wind is constant and fast offshore, and it gets even faster in the valley that bisects the island. Finally, the wind becomes absolutely furious by the time it is funneled to the narrowest point at the south of the valley, which is exactly where they put the mini golf course.</p>\n<p>I had trouble keeping the ball still on the tee. My wife hit two hole-in-ones.</p>\n<h5>Vocationaloha</h5>\n<p>A lady working a lemonade stand on the beach told the people in line that she quit her job selling insurance in Charlotte to &#8220;live the dream&#8221; and move to Maui. Everyone oohed and ahed and expressed their heartfelt desires to do the same if only the kids, etc.</p>\n<p>I looked at the lemonade lady standing drenched in sweat in the sun and thought that she must be insane to leave a skilled job at an air conditioned office to work as a human vending machine for half the salary. Maui is fun when you&#8217;re retired (like I am for the next two months), not when you have to fight for a career in the fruit-squeezing industry.</p>\n<h5>Millenialoha</h5>\n<p>On our last day, we went for breakfast in <i>Heavenly Cafe </i>in Waikiki (actual motto: <i>Local from Hawaii, organic when possible</i>). At the table to our left, a single woman was shoveling kale into her mouth with a smile. At the table to our right, a group of Japanese tourists were Instagramming their salmon Eggs Benedict.</p>\n<p>Suddenly, my vision began to fade and my pulse raced. I felt a pressure building inside, overwhelming my entire body. Clinging to a last tendril of consciousness, I pulled out my phone and checked the price of Litecoin (down 7% for the hour, up 700% for the year). I breathed, the pressure subsided.</p>\n<p>I thought I knew <a href=\"http://putanumonit.com/2017/08/26/premium-mediocre/\" target=\"_blank\" rel=\"noopener\">premium mediocre</a> from New York, but at <i>Heavenly</i> the PM is refined to a form so pure it&#8217;s radioactive.</p>\n<h5>Alohafricans</h5>\n<p>We spent almost a week in Maui, criss-crossing the entire island several times. We saw <a href=\"http://slatestarcodex.com/2015/02/11/black-people-less-likely/\">two black people in total</a>.</p>\n<h5>Libertarian Rant of the Day Aloha</h5>\n<p>A local guide showed us where pineapples used to be grown on the slopes of West Maui. Picking pineapples is very labor-intensive and hard to automate, so as wages kept rising the plantations closed and the US started importing pineapples from the Philippines. Today, the slopes are barren except for some dirty brown grass.</p>\n<p>Judging by the fact that a lot of Hawaiians rummage through the trashcans in Honolulu looking for plastic bottles, there are certainly Hawaiians that would be happy to pick pineapples for $4-$5 an hour, especially if they got EITC and didn&#8217;t lose out on other welfare. There is no doubt that there are many Filipinos who would be very happy to pick pineapples in Hawaii for $1-$2 an hour, with no claims on welfare or citizenship.</p>\n<p>Of course, the minimum wage and immigration laws make both things illegal. As a result, Americans import pineapples that aren&#8217;t as fresh, aren&#8217;t as tasty, and are too expensive for poor Americans to afford, especially the ones who are jobless.</p>\n<h5>Aloholy Spirit</h5>\n<p>Good news, everyone, the wait is almost over!</p>\n<p><img data-attachment-id=\"27519\" data-permalink=\"http://putanumonit.com/2017/09/25/travel-journal-hawaii/20170920_133238/\" data-orig-file=\"https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=900\" data-orig-size=\"4032,3024\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;1.7&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G930P&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1505914357&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.2&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.00037764350453172&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}\" data-image-title=\"20170920_133238\" data-image-description=\"\" data-medium-file=\"https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=900?w=300\" data-large-file=\"https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=900?w=900\" class=\"alignnone size-full wp-image-27519\" src=\"https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=900\" alt=\"20170920_133238\" srcset=\"https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=900 900w, https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=1800 1800w, https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=150 150w, https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=300 300w, https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=768 768w, https://putanumonit.files.wordpress.com/2017/09/20170920_133238.jpg?w=1024 1024w\" sizes=\"(max-width: 900px) 100vw, 900px\"  ></p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/putanumonit.wordpress.com/27354/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/putanumonit.wordpress.com/27354/\" /></a> <img alt=\"\" border=\"0\" src=\"http://pixel.wp.com/b.gif?host=putanumonit.com&#038;blog=101823629&#038;post=27354&#038;subd=putanumonit&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Jacobian",
      "slug": "jacob-falkovich",
      "displayName": "Jacob Falkovich"
    }
  },
  {
    "_id": "KRc9T4TyDmoKnAvdP",
    "title": "Life Updates Strike Again!",
    "slug": "life-updates-strike-again",
    "pageUrl": "https://www.lesswrong.com/posts/KRc9T4TyDmoKnAvdP/life-updates-strike-again",
    "postedAt": "2017-09-25T21:51:09.782Z",
    "baseScore": 4,
    "voteCount": 3,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>(Crossposted from <a href=\"srconstantin.wordpress.com\">srconstantin.wordpress.com)</a></p><p>So, I have again <strong>changed jobs</strong> — I am now working at Starsky Robotics helping build self-driving trucks!</p><p>I’m still interested in biotech, but there are a lot of interesting problems in autonomous vehicles that I’m excited to work on. Also, this job is in San Francisco, unlike my last job, and since I am <strong>pregnant</strong>, I’d like to work in the same state as my future kid.</p><p>The great thing about California is that local laws allow freelancing, so I am once again <strong>open for business</strong>, to the extent that I have time.  If you have a question that could benefit from a personalized literature review, particularly in the biomedical sciences, I can do that, and you can contact me at srconstantin@gmail.com.</p><p>Currently my main freelance research project is surveying current experimental avenues for life extension, in cooperation with an investor who’s interested in funding longevity research. I love working on stuff like this, and will be updating this blog with progress.</p><p>I’m also going to start seriously preparing to <strong>get my cancer research book published</strong>, which, I’m told, involves doing your own marketing. I’m going to be looking for opportunities to write shorter articles for magazines/blogs and otherwise get publicity, so if you know of any good venues, please let me know.</p><p></p><p></p><p></p><p></p></div></div></div></div>",
    "user": {
      "username": "Kallisti",
      "slug": "kallisti",
      "displayName": "Kallisti"
    }
  },
  {
    "_id": "fYwD3Bt7X57RxQfSY",
    "title": "The Five Hindrances to Doing the Thing",
    "slug": "the-five-hindrances-to-doing-the-thing",
    "pageUrl": "https://www.lesswrong.com/posts/fYwD3Bt7X57RxQfSY/the-five-hindrances-to-doing-the-thing",
    "postedAt": "2017-09-25T17:04:53.643Z",
    "baseScore": 10,
    "voteCount": 12,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><blockquote><p><em>&quot;Compare your normal level of consciousness with that of an athlete in the zone, or with a person in an emergency. You&#x27;ll realize that daily life consists mostly of different degrees of dullness and mindlessness.&quot;</em></p><p style=\"text-align:right;\">- Culadasa (John Yates, Ph.D.), <em>The Mind Illuminated</em></p></blockquote><p>It has been noted that the term <em>akrasia</em> does not seemingly carve reality at the joints in a useful way. The general problem of knowing that you should do a thing and yet having trouble getting yourself to do it is an ancient problem, and luckily, people have actually been working on solving it for a long time.</p><p>A useful approach for solving a <em>general </em>problem is often to thoroughly solve a <em>specific instance </em>of that problem and then to try to generalize it. For thousands of years, humans have been working on solving a specific very difficult problem: how to make themselves sit down for up to an hour a day and meditate.</p><p>Meditation, on its face, is an overwhelmingly boring task, providing almost no intrinsic reward, especially for beginners. It is almost the degenerate case of making yourself do the most boring possible thing within the realm of actual human activity. It might (or might not) come as a surprise that over the centuries, those who teach meditation have narrowed the potential obstacles to meditation to only five: <u>Desire</u>, <u>aversion</u>, <u>laziness or lethargy</u>, <u>agitation due to worry or remorse</u>, and <u>doubt</u>. In this article, I will attempt to generalize these five hindrances to be applicable to any task, not just meditation. In so doing, I hope to provide a road map to fighting akrasia in the moment.</p><p>The following section is organized as follows: Each hindrance has specific qualities, which will help you recognize its occurrence; a cause, which explains why this specific form of resistance arises; and remedies to be employed in the moment of recognizing it.</p><ol><li><p><u>Desire</u></p><ul><li><p>Qualities</p><ul><li><p>Distraction due to intrusive thoughts of pleasures related to material existence or attempts to avoid their opposites.</p></li><li><p>Gain/loss, fame/obscurity, pleasure/pain, praise/blame.</p></li></ul></li><li><p>Cause</p><ul><li><p>Desire is the sensation of wanting to obtain or keep something, and is healthy and good in the appropriate context. </p></li></ul></li></ul><ul><li><p>Remedies</p><ul><li><p>&quot;Unification of mind&quot; - cognitively emphasize the utility of having a mind that is singularly engaged on the current task, and set the firm intention to do so.</p></li><li><p>Briefly address the negative consequences that would come along with getting whatever pleasure it is you feel distracted by.</p></li><li><p>Focus on the pleasure of the <em>current</em> <em>moment</em>. If you are actively engaged with an important task, there will be pleasurable sensations and thoughts associated with that fact. Give yourself a mental pat on the back. Let yourself appreciate your own attentiveness and specifically note the quality of pleasure associated with doing so.</p></li></ul></li></ul></li><li><p><u>Aversion</u></p><ul><li><p>Qualities</p><ul><li><p>Resistance, rejection, denial, dissatisfaction, judgement, self-accusation and boredom.</p></li><li><p>Wanting things to not be the way they are.</p></li><li><p>Fear is a case of being averse to something that hasn&#x27;t occurred.</p></li><li><p>Pain causes aversion, but isn&#x27;t itself aversion.</p></li></ul></li><li><p>Cause</p><ul><li><p>Aversion motivates us to avoid or eliminate what is unpleasant or harmful.</p></li></ul></li></ul><ul><li><p>Remedies</p><ul><li><p>Rest and narrow your focus toward the task at hand. Increase your concentration.\r</p></li><li><p>Conversely, you can broaden your focus to your whole sensorium, making the distracting thought/sensations seem diminished by comparison, and then refocus your attention on the task at hand.</p></li><li><p>Similarly to the remedy for Desire, focus on the pleasure/happiness to be found in the present moment, and whatever other present-oriented positive mental states can be recognized.</p></li><li><p>If your aversive thoughts involve ill-will toward other people or yourself, switch briefly to producing feelings of good-will for your target, then gently put your attention back on the task at hand.</p></li></ul></li></ul></li><li><p><u>Laziness or lethargy</u></p><ul><li><p>Qualities</p><ul><li><p>Procrastination, sleepiness, lack of motivation.</p></li><li><p>Laziness arises when the cost of an activity seems to outweigh the benefits.</p></li><li><p>Lethargy arises when there seems to be nothing interesting or rewarding going on.</p></li></ul></li><li><p>Causes</p><ul><li><p>Laziness motivates us to conserve our energy for tasks that might be more valuable.</p></li></ul></li><li><p>Remedies</p><ul><li><p>Intentionally muster up the motivation for the task by focusing on future rewards.</p></li><li><p>&quot;Just do it&quot; - plunge into the task despite resistance and focus on the positive qualities of the task (i.e. just start the task and if Aversion arises, then employ the remedies for Aversion).</p></li><li><p>Try to remain in the moment, focus on what you&#x27;re actually doing, stop watching the clock.</p></li><li><p>Do more. Go faster. Engage harder. If the task isn&#x27;t stimulating you, push the throttle until it does.</p></li><li><p>If you suspect your torpor to be of a partly physical origin, re-invigorate your body and mind by moving around, drinking some water, splashing cold water on your face, then aggressively engage with the task again.</p></li></ul></li></ul></li><li><p><u>Agitation</u> due to worry and remorse\r</p><ul><li><p>Qualities</p><ul><li><p>Agitation due to possible consequences.</p></li><li><p>Anxiety due to imagined scenarios.</p></li></ul></li><li><p>Causes</p><ul><li><p>Helps us prepare for an uncertain future.</p></li></ul></li><li><p>Remedies</p><ul><li><p>Resolve to take positive action to correct past mistakes.</p></li><li><p>Cognitively let go of past mistakes.</p></li><li><p>Intentionally focus on the present joy and pleasantness of the moment. Joyfulness both makes it difficult to focus on negative events or possibilities, and situates remorse in a more psychologically tolerable context, from which you can move past it in the moment.\r</p></li><li><p>As with Aversion, you can either broaden your focus to the entire current context, or narrow it back onto the specific thing you need to do. One of these will probably feel more &quot;right&quot;. Agitation has its own Aversive quality, so it makes sense that some of the remedies for Aversion will work here, and vice versa.</p></li></ul></li></ul></li><li><p><u>Doubt</u></p><ul><li><p>Qualities</p><ul><li><p>Focus on negative results or outcomes.</p></li><li><p>A positive mental quality that becomes pathological when one focuses only on the emotional quality which saps motivation rather than performing a cognitive appraisal of the utility of the task.</p></li><li><p>May involve comparing your own performance to others&#x27;.</p></li></ul></li><li><p>Causes</p><ul><li><p>Keeps us from wasting our time and resources on unnecessary activities.</p></li><li><p>Invites us to question our current behavior with reasoned skepticism.</p></li></ul></li><li><p>Remedies</p><ul><li><p>Use reasoning abilities to fully engage with and dissolve the doubt (or find it to be a valid doubt, if rational analysis proves it to be so).</p></li><li><p>Doubt is dispelled by the trust and confidence that comes from success; success comes from persistent effort; just keep going!</p></li><li><p>Re-examine your motivation and ensure it is powerful and convincing.</p></li><li><p>Sustained attention to the task at hand.</p></li></ul></li></ul><p></p></li></ol><p><u>Bonus meta-skills</u>: </p><ul><li><p>When you find your mind wandering from the task at hand, <u>rejoice</u>. Give yourself a big smile and mental cheer. Imagine that sound that plays when your character gains a level. If you react this way, you&#x27;ll condition yourself to notice mind-wandering. Do not beat yourself up. If you yell at yourself, you&#x27;ll condition yourself to <em>avoid noticing</em> mind-wandering.</p></li><li><p>Likewise, when you notice reluctance to start or continue a task, engage with the resistance with curiosity and objectivity, and try to lightly and playfully ferret out which of the above hindrances might be in play. Use the acronym RAIN: Recognize, Accept, Investigate, Non-Identification. This means you notice the resistance, you accept its presence neutrally, investigate it calmly, and don&#x27;t identify with whatever you find. Give yourself a pat on the back when you employ this algorithm. The last thing you need is aversion about your aversion.</p></li><li><p>You may have noticed that some variety of &quot;engage with the present moment and focus on the intrinsic pleasurable qualities of whatever it is you&#x27;re doing&quot; appear as remedies for more than one of the hindrances. You can preempt the manifestation of most of the hindrances by maintaining this kind of mindful, present-oriented, enjoyment-based approach to your tasks. There&#x27;s something engaging and pleasurable to be found in any possible task, even if that task is sitting with your eyes closed.</p></li></ul><p>The five hindrances are likely familiar to you, and I personally find that &quot;akrasia&quot; is just one of these issues surrounded by an aversive haze that obscures its true nature. The remedies may feel obvious to you. Regardless, you&#x27;ll find it&#x27;s convenient to have a handy, semi-proven, distilled flowchart of solutions to the specific issues that arise while battling the many-headed hydra of akrasia.</p></div></div></div></div>",
    "user": {
      "username": "moridinamael",
      "slug": "moridinamael",
      "displayName": "moridinamael"
    }
  },
  {
    "_id": "Pfj24XZocBXvPetP4",
    "title": "Rational Feed: Last Week's Community Articles and Some Recommended Posts",
    "slug": "rational-feed-last-week-s-community-articles-and-some",
    "pageUrl": "https://www.lesswrong.com/posts/Pfj24XZocBXvPetP4/rational-feed-last-week-s-community-articles-and-some",
    "postedAt": "2017-09-25T13:41:55.117Z",
    "baseScore": 9,
    "voteCount": 9,
    "commentCount": 7,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p style=\"margin: 0px 0px 0.35714285714285715em; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Highly Recommended Articles:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://benjaminrosshoffman.com/why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i-should-be/\">Why I Am Not A Quaker Even Though It Often Seems As Though I Should Be by Ben Hoffman</a>&nbsp;- Quakers have consistently gotten to the right answers faster than most people, or the author. Arbitrage strategies to beat the quakers. An incomplete survey of alternatives.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://rationallyspeakingpodcast.org/show/rs-193-eric-jonas-on-could-a-neuroscientist-understand-a-mic.html\">Could A Neuroscientist Understand A Microprocessor by Rationally Speaking</a>&nbsp;- \"Eric Jonas, discussing his provocative paper titled 'Could a Neuroscientist Understand a Microprocessor?' in which he applied state-of-the-art neuroscience tools, like lesion analysis, to a computer chip. By applying neuroscience's tools to a system that humans fully understand he was able to reveal how surprisingly uninformative those tools actually are.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/reasonable-doubt-new-look-whether-prison-growth-cuts-crime\">Reasonable Doubt New Look Whether Prison Growth Cuts Crime by Open Philosophy</a>&nbsp;- Part1 of a four part, in depth, series on Criminal Justice reform. The remaining posts are linked below. \"I estimate, that at typical policy margins in the United States today, decarceration has zero net impact on crime. That estimate is uncertain, but at least as much evidence suggests that decarceration reduces crime as increases it. The crux of the matter is that tougher sentences hardly deter crime, and that while imprisoning people temporarily stops them from committing crime outside prison walls, it also tends to increase their criminality after release. As a result, &ldquo;tough-on-crime&rdquo; initiatives can reduce crime in the short run but cause offsetting harm in the long run. Empirical social science research&mdash;or at least non-experimental social science research&mdash;should not be taken at face value. Among three dozen studies I reviewed, I obtained or reconstructed the data and code for eight. Replication and reanalysis revealed significant methodological concerns in seven and led to major reinterpretations of four. These studies endured much tougher scrutiny from me than they did from peer reviewers in order to make it into academic journals. Yet given the stakes in lives and dollars, the added scrutiny was worth it. So from the point of view of decision makers who rely on academic research, today&rsquo;s peer review processes fall well short of the optimal.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/deterrence-de-minimus\">Deterrence De Minimus by Open Philosophy</a>&nbsp;- Part 2.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/incapacitation-how-much-does-putting-people-inside-prison-cut-crime-outside\">Incapacitation How Much Does Putting People Inside Prison Cut Crime Outside by Open Philosophy</a>&nbsp;- Part 3.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/aftereffects-us-evidence-says-doing-more-time-typically-leads-more-crime-after\">Aftereffects Us Evidence Says Doing More Time Typically Leads More Crime After by Open Philosophy</a>&nbsp;- Part 4.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Scott:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/23/ot85-l-dopen-thread/\">L Dopen Thread by Scott Alexander</a>&nbsp;- Bi-weekly public open thread. Berkeley SSC meetup. New ad for the Greenfield Guild, an online network of software consultants. Reasons to respect the society of friends.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/20/meditative-states-as-mental-feedback-loops/\">Meditative States As Mental Feedback Loops by Scott Alexander</a>&nbsp;- the main reason we don't see emotional positive feedback loops is that people get distracted. If you do not get distracted you can experience a bliss feedback look.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/18/book-review-mastering-the-core-teachings-of-the-buddha/\">Book Review Mastering The Core Teachings Of The Buddha by Scott Alexander</a>&nbsp;- \"Buddhism For ER Docs. ER docs are famous for being practical, working fast, and thinking everyone else is an idiot. MCTB delivers on all three counts.\" Practical buddhism with a focus on getting things done. buddhism is split into morality concentration and wisdom. Discussion of \"the Dark Night of the Soul\" which is a sort of depression occurs when you have had some but not enough spiritual experience.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Rationalist:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://meteuphoric.wordpress.com/2017/09/23/impression-track-records/\">Impression Track Records by Katja Grace</a>&nbsp;- Three reasons its better to keep impression track records and belief track records separate.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://benjaminrosshoffman.com/why-i-am-not-a-quaker-even-though-it-often-seems-as-though-i-should-be/\">Why I Am Not A Quaker Even Though It Often Seems As Though I Should Be by Ben Hoffman</a>&nbsp;- Quakers have consistently gotten to the right answers faster than most people, or the author. Arbitrage strategies to beat the quakers. An incomplete survey of alternatives.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://mindlevelup.wordpress.com/2017/09/24/the-best-self-help-should-be-self-defeating/\">The Best Self Help Should Be Self Defeating by mindlevelup</a>&nbsp;- \"Self-help is supposed to get people to stop needing it. But typical incentives in any medium mean that it&rsquo;s possible to get people hooked on your content instead. A musing on how the setup for writing self-help differs from typical content.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://kajsotala.fi/2017/09/nobody-does-the-thing-that-they-are-supposedly-doing/\">Nobody Does The Thing That They Are Supposedly Doing by Kaj Sotala</a>&nbsp;- \"In general, neither organizations nor individual people do the thing that their supposed role says they should do.\" Evolutionary incentives. Psychology of motivation. Very large number of links.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thezvi.wordpress.com/2017/09/23/out-to-get-you/\">Out To Get You by Zvi Moshowitz</a>&nbsp;- \"Some things are fundamentally Out to Get You. They seek resources at your expense. Fees are hidden. Extra options are foisted upon you.\" You have four responses: Get Gone, Get Out (give up), Get Compact (limit what it wants) or Get Ready for Battle.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thingofthings.wordpress.com/2017/09/22/in-defense-of-unreliability/\">In Defense Of Unreliability by Ozy</a>&nbsp;- Zvi claims that when he makes plan with friends in the bay he never assumes the plan will actually occur. Ozy depends on unreliable transport. Getting places 10-15 early is also costly. Flaking and agoraphobia.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/pfj/strategic_goal_pursuit_and_daily_schedules/\">Strategic Goal Pursuit And Daily Schedules by Rossin (lesswrong)</a>&nbsp;- The author benefitted from Anna Salamon&rsquo;s goal-pursuing heuristics and daily schedules.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thingofthings.wordpress.com/2017/09/21/why-attitudes-matter/\">Why Attitudes Matter by Ozy</a>&nbsp;- Focusing on attitudes can be bad for some people. Two arguments: \"First, for any remotely complicated situation, it would be impossible to completely list out all the things which are okay or not okay. Second, an attitude emphasis prevents rules-lawyering.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/09/humans-cells-in-multicellular-future-minds.html\">Humans Cells In Multicellular Future Minds by Robin Hanson</a>&nbsp;- In general humans replace specific systems with more general adaptive systems. Seeing like a State. Most biological and cultural systems are not general. Multi-cellular organisms re tremendously inefficient. The power of entrenched systems. Human brains are extremely general. Human brains may win for a long time vs other forms of intelligence.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://mapandterritory.org/recognizing-vs-generating-an-important-dichotomy-for-life-3b6b6fc67478\">Recognizing Vs Generating An Important Dichotomy For Life by Gordon (Map and Territory)</a>&nbsp;- Bullet Points -&gt; Essay vs Essay -&gt; Bullet Points. Generating ideas vs critique. Most advice is bad since it doesn't convey the reasons clearly. Let the other person figure out the actual advice for themselves.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/09/prediction-markets-update.html\">Prediction Markets Update by Robin Hanson</a>&nbsp;- Prediction markets provide powerful information but they challenge powerful entrenched interests, Hanson compares them to \"a knowledgeable Autist in the C-suite\". Companies selling straight prediction market tech mostly went under. Blockchain platforms for prediction markets. Some discussion of currently promising companies.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===AI:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://foundational-research.org/focus-areas-of-worst-case-ai-safety\">Focus Areas Of Worst Case Ai Safety by The Foundational Research Institute</a>&nbsp;- Redundant safety measures. Tripwires. Adversarial architectures. Detecting and formalizing suffering. Backup utility functions. Benign testing environments.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1ev/srisk_faq/\">Srisk Faq by Tobias Baumann (EA forum)</a>&nbsp;- Quite detailed responses to questions about suffering risks and their connection to AGI. sections: General questions, The future, S-risks and x-risks, Miscellaneous.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===EA:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/reasonable-doubt-new-look-whether-prison-growth-cuts-crime\">Reasonable Doubt New Look Whether Prison Growth Cuts Crime by Open Philosophy</a>&nbsp;- Part1 of a four part, in depth, series on Criminal Justice reform. The remaining posts are linked below. \"I estimate, that at typical policy margins in the United States today, decarceration has zero net impact on crime. That estimate is uncertain, but at least as much evidence suggests that decarceration reduces crime as increases it. The crux of the matter is that tougher sentences hardly deter crime, and that while imprisoning people temporarily stops them from committing crime outside prison walls, it also tends to increase their criminality after release. As a result, &ldquo;tough-on-crime&rdquo; initiatives can reduce crime in the short run but cause offsetting harm in the long run. Empirical social science research&mdash;or at least non-experimental social science research&mdash;should not be taken at face value. Among three dozen studies I reviewed, I obtained or reconstructed the data and code for eight. Replication and reanalysis revealed significant methodological concerns in seven and led to major reinterpretations of four. These studies endured much tougher scrutiny from me than they did from peer reviewers in order to make it into academic journals. Yet given the stakes in lives and dollars, the added scrutiny was worth it. So from the point of view of decision makers who rely on academic research, today&rsquo;s peer review processes fall well short of the optimal.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/deterrence-de-minimus\">Deterrence De Minimus by Open Philosophy</a>&nbsp;- Part 2.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/incapacitation-how-much-does-putting-people-inside-prison-cut-crime-outside\">Incapacitation How Much Does Putting People Inside Prison Cut Crime Outside by Open Philosophy</a>&nbsp;- Part 3.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/aftereffects-us-evidence-says-doing-more-time-typically-leads-more-crime-after\">Aftereffects Us Evidence Says Doing More Time Typically Leads More Crime After by Open Philosophy</a>&nbsp;- Part 4.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://www.jefftk.com/p/paypal-giving-fund\">Paypal Giving Fund by Jeff Kaufman</a>&nbsp;- The PayPal giving fund lets you batch donations and PayPal covers the fees if you use it. Jeff thought there must be a catch but it seems legit.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1f2/what_do_dalys_capture/\">What Do Dalys Capture by Danae Arroyos (EA forum)</a>&nbsp;- How Disability Adjusted life years computed. DALYs misrepresent mental health. DALY's Miss Indirect Effects. Other issues.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thingofthings.wordpress.com/2017/09/20/against-ea-pr/\">Against Ea Pr by Ozy</a>&nbsp;- The EA community is the only large entity trying to produce accurate and publicly available assessments of charities. Hence the EA community should not trade away any honesty. EAs should simply say which causes and organizations are most effective, they should not worry about PR concerns.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1f5/ea_survey_2017_series_qualitative_comments_summary/\">Ea Survey 2017 Series Qualitative Comments Summary by tee (EA forum)</a>&nbsp;- Are you an EA, how welcoming is EA, local EA meetup attendance, concerns with not being 'EA enough', improving the survey.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1ex/demographics_ii/\">Demographics Ii by tee (EA forum)</a>&nbsp;- Racial breakdown. Percent white in various geographic locations. Political spectrum. Politics correlated with cause area, diet and geography, employment, fields of study, year joining EA.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Politics and Economics:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/raj-chetty-course-using-big-data-solve-economic-social-problems.html\">Raj Chetty Course Using Big Data Solve Economic Social Problems by Marginal Revolution</a>&nbsp;- Link to an eleven lecture course. \"Equality of opportunity, education, health, the environment, and criminal justice. In the context of these topics, the course provides an introduction to basic statistical methods and data analysis techniques, including regression analysis, causal inference, quasi-experimental methods, and machine learning.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://noahpinionblog.blogspot.com/2017/09/speech-on-campus-reply-to-brad-delong.html\">Speech On Campus Reply To Brad Delong by Noah Smith</a>&nbsp;- The safeguard put in place to exclude the small minority of genuinely toxic people will be overused. Comparison to the war on terror. Brad's exclusions criteria are incredibly vague. The speech restriction apparatus is patchwork and inconsistent. Cultural Revolution.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thingofthings.wordpress.com/2017/09/23/deontologist-envy/\">Deontologist Envy by Ozy</a>&nbsp;- The behavior of your group is highly unlikely to effect the behavior of your political opponents. Many people respond to proposed tactics by asking \"What if everyone did that\". Ozy claims these responses show an implicit Kantian or deontological point of view.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.bayesianinvestor.com/blog/index.php/2017/09/22/peak-fossil-fuel/\">Peak Fossil Fuel by Bayesian Investor</a>&nbsp;- Electric cars will have a 99% market share by 2035. \"Electric robocars run by Uber-like companies will be cheap enough that you&rsquo;ll have trouble giving away a car bought today. Uber&rsquo;s prices will be less than your obsolete car&rsquo;s costs of fuel, maintenance, and insurance.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://noahpinionblog.blogspot.com/2017/09/what-we-didnt-get.html\">What We Didn't Get by Noah Smith</a>&nbsp;- We are currently living in a world envisioned by the cyberpunk writers. the early industrial sci-fi writers also predicted many inventions. Why didn't mid 1900s sci-fi come true? We ran out of theoretical physics and we ran out of energy. Energy density of fuel sources. Some existing or plausible technology is just too dangerous. Discussion of whether strong AI, personal upload, nanotech and/or the singularity will come true.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://juliagalef.com/2017/09/21/unpopular-ideas-about-children/\">Unpopular Ideas About Children by Julia Galef</a>&nbsp;- Julia's thoughts on why she is collecting these lists. Parenting styles, pro and anti-natalism, sexuality, punishment, etc. Happiness studies. Some other studies finding extreme results.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://noahpinionblog.blogspot.com/2017/09/the-margin-of-stupid.html\">The Margin Of Stupid by Noah Smith</a>&nbsp;- Can we trust studies showing that millennials are as racist as their parents, except for the ones in college who are extreme leftists?</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://the-orbit.net/brutereason/2017/09/18/role-allies-queer-spaces/\">Role of Allies in Queer Spaces by Brute Reason</a>&nbsp;- The main purpose of having allies in LBGTQA spaces is providing cover for closeted or questioning members. Genuinely cis-straight allies are ok in some spaces like LBGTQA bands. But straight allies cause problems when they are present in queer support spaces.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://econlog.econlib.org/archives/2017/09/the_wonder_of_i.html\">The Wonder Of International Adoption by Bryan Caplan</a>&nbsp;- Benefits of international adoption of third world children. Adoptees are extremely stunted physically on arrival but make up some of the difference post adoption. International adoptions raises IQ by at least 4 points on average and perhaps as much as 8.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Misc:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://protokol2020.wordpress.com/2017/09/25/coin-flipping-problem/\">Coin Flipping Problem by protokol2020</a>&nbsp;- Flipping coins until you get a pre-committed sequence. You re-start whenever your flip doesn't match the sequence. Relationship between the expected number of flips and the length of the sequence.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.mrmoneymustache.com/2017/09/20/seek-not-to-be-entertained/\">Seek Not To Be Entertained by Mr. Money Mustache</a>&nbsp;- Don't be normal, normal people need constant entertainment. You can get enjoyment and satisfaction from making things. Advice for people less abnormal than MMM. What you enjoy doesn't matter, what matters is what is good for you.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://samzdat.com/2017/09/19/propositions-on-immortality/\">Propositions On Immortality by sam[]zdat</a>&nbsp;- Fiction. A man digresses about philosophy, the nature of time, the soul, consciousness and mortality.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://bartlebysbackpack.com/2017/09/comments-for-ghost/\">Comments For Ghost by Tom Bartleby</a>&nbsp;- Ghost is a blog platform hat doesn't natively support comments. Three important use cases and why they all benefit from comments: Ex-Wordpress blogger who wants things to 'just work', Power suers care about privacy and don't want to use third party comments, The Static-Site Fence-Sitter since the main dynamic content you want is comments.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://protokol2020.wordpress.com/2017/09/18/prime-crossword/\">Prime Crossword by protokol2020</a>&nbsp;- Can you create a grid larger than [3,7],[1,1] where all the rows and columns are primes? (37, 11, 31 and 71 are prime).</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Podcast:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://www.stitcher.com/podcast/the-ezra-klein-show/e/51589852\">Reihan Salam by The Ezra Klein Show</a>&nbsp;- Remaking the Republican party, but not the way Donald Trump did it. \"The future of the Republican Party, the healthcare debate, and how he would reform our immigration system (and upend the whole way we talk about it). \"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://wakingup.libsyn.com/98-into-the-dark-land\">Into The Dark Land by Waking Up with Sam Harris</a>&nbsp;- \"Siddhartha Mukherjee about his Pulitzer Prize winning book, The Emperor of All Maladies: A Biography of Cancer.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/conversation-larry-summers.html\">Conversation with Larry Summers by Marginal Revolution</a>&nbsp;- \"Mentoring, innovation in higher education, monopoly in the American economy, the optimal rate of capital income taxation, philanthropy, Hermann Melville, the benefits of labor unions, Mexico, Russia, and China, Fed undershooting on the inflation target, and Larry&rsquo;s table tennis adventure in the summer Jewish Olympics.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://www.stitcher.com/podcast/the-ezra-klein-show/e/51454005\">Hilary Clinton by The Ezra Klein Show</a>&nbsp;- Hilary's dream of paying for basic income with revenue from shared national resources. Why she scrapped the plan. Hilary thinks she should perhaps have thrown caution to the wind. Hilary isn't a radical, she is proud of the American political system and is annoyed other's don't share her enthusiasm for incremental progress.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://www.stitcher.com/podcast/the-ezra-klein-show/e/51526503\">David Remnick by The Ezra Klein Show</a>&nbsp;- New Yorker editor. \"Russia&rsquo;s meddling in the US election, Russia&rsquo;s transformation from communist rule to Boris Yeltsin and Vladimir Putin, his magazine&rsquo;s coverage of President Donald Trump, how he chooses his reporters and editors, and how to build a real business around great journalism.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.econtalk.org/archives/2017/09/gabriel_zucman.html\">Gabriel Zucman by EconTalk</a>&nbsp;- \"Research on inequality and the distribution of income in the United States over the last 35 years. Zucman finds that there has been no change in income for the bottom half of the income distribution over this time period with large gains going to the top 1%. The conversation explores the robustness of this result to various assumptions and possible explanations for the findings.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://rationallyspeakingpodcast.org/show/rs-193-eric-jonas-on-could-a-neuroscientist-understand-a-mic.html\">Could A Neuroscientist Understand A Microprocessor by Rationally Speaking</a>&nbsp;- \"Eric Jonas, discussing his provocative paper titled 'Could a Neuroscientist Understand a Microprocessor?' in which he applied state-of-the-art neuroscience tools, like lesion analysis, to a computer chip. By applying neuroscience's tools to a system that humans fully understand he was able to reveal how surprisingly uninformative those tools actually are.\"</p>",
    "user": {
      "username": "deluks917",
      "slug": "deluks917",
      "displayName": "sapphire"
    }
  },
  {
    "_id": "YJHnbrX5dthT7Mpmz",
    "title": "An incentive structure that might not suck too much.",
    "slug": "an-incentive-structure-that-might-not-suck-too-much",
    "pageUrl": "https://www.lesswrong.com/posts/YJHnbrX5dthT7Mpmz/an-incentive-structure-that-might-not-suck-too-much",
    "postedAt": "2017-09-25T09:07:57.559Z",
    "baseScore": 5,
    "voteCount": 7,
    "commentCount": 13,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>You want to make things better or live in a world which makes things better. But how do you go <a href=\"https://www.lesserwrong.com/posts/8iAJ9QsST9X9nzfFy/nobody-does-the-thing-that-they-are-supposedly-doing\">about actually doing</a> that? There is truth to Drucker&#x27;s maxim </p><blockquote><p>&quot;If you can&#x27;t measure it, you can&#x27;t improve it.&quot;</p></blockquote><p>But you have also heard of Goodheart&#x27;s law. </p><blockquote><p>&quot;When a measure becomes a target, it ceases to be a good measure.&quot;</p></blockquote><p>But you have measures. How can you use them without them becoming a target? </p><h4>Delegation</h4><p>If you are delegating work this becomes even trickier. You can&#x27;t give the people the you are delegating the measures you use (unless you trust them to use them properly and not use them as targets). So you give people rules to follow or goals to meet that aren&#x27;t the measures. </p><p>Then evaluate them on how well they follow the rules or goals (not on how well they  meet the measure), and iterate on the rules or goals. If you have people that follow the rules and achieve the goals *AND* you iterate on those things you can actually affect change in the world. If you don&#x27;t iterate you&#x27;ll just end up optimising whatever the first set of rules points at, rather than the thing you actually want to acheive.</p><p>You also probably want to give people some slack with the rules/goals, so that they have spare energy to look at the world and figure out what they think is best. If people are run ragged trying to meet a goal to survive, all other considerations fall by the way side.</p><h4>Fixing the goals</h4><p>During the iteration of the rules, how do you avoid Goodheart&#x27;s law yourself? You want people to lead good happy lives, but don&#x27;t want to end up secretly giving people drugs to make them happy, because you are short-circuiting things. You also don&#x27;t want to kill everyone to reduce long term suffering.</p><p>So instead you build yourself a model of what Good looks like. This model is important it allows you to decouple your measure from your target. An example might be, &quot;It is Good for People to be wealthy as it allows them to do more things&quot;.  You use your model to generate a target, in this case &quot;make people wealthier&quot;.  Then you alter the rules and goals to hit that target.</p><p>What happens if your model is wrong? Let us say some people are becoming unhappier as they become wealthier, due to pollution causing health issues.</p><p>This is where the measure comes in. You then use your measures to see if your model is correct. If people aren&#x27;t becoming happier, less stressed, healthier etc as they become wealthier, you change and update your model. In this case they aren&#x27;t, so you improve your model, find a new targets and therefore give new goals and rules to the people you delegate to.</p><p>Any anger at the poor performance related to your measure should not be taken out on the people you have delegated to (unless they didn&#x27;t do what you said), it should be taken out on your model of the world that thought it was idea to tell people to do something.</p><p>Also you can improve your model with small scale studies and trying to understand the inner workings of humans. This gives you a quicker feedback loop than changing society and seeing what happens.</p><p>This is a description of roughly where we are as a society currently, although we suck at the last section updating our models and changing our targets. We tend get stuck on the first set of targets we find, those of GDP and IQ, publishing &#x27;high impact&#x27; papers or reducing waiting times at doctors. We don&#x27;t use measures to say, hey somethings wrong, let us change things. The best we have is Democracy but that is a very blunt instrument and has its own incentive structure problems.</p></div></div></div></div>",
    "user": null
  },
  {
    "_id": "T6xoNuMdyF8gSbxgm",
    "title": "Open thread, September 25 - October 1, 2017",
    "slug": "open-thread-september-25-october-1-2017",
    "pageUrl": "https://www.lesswrong.com/posts/T6xoNuMdyF8gSbxgm/open-thread-september-25-october-1-2017",
    "postedAt": "2017-09-25T07:36:19.474Z",
    "baseScore": 0,
    "voteCount": 0,
    "commentCount": 30,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<h5 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"color: #333333;\"><span style=\"font-size: 20px;\">If it's worth saying, but not worth its own post, then it goes here.</span></span></h5>\n<div id=\"entry_t3_p2r\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px;\">\n<div class=\"md\">\n<div id=\"entry_t3_oxb\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<hr style=\"line-height: 19.5px;\" />\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/new/\" target=\"_blank\">list-of-threads page</a>&nbsp;before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">3.&nbsp;</span><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">4. Unflag the two options \"</span><span style=\"font-size: 12px; line-height: 18px;\">Notify me of new top-level comments on this article\" and \"</span><label style=\"font-size: 12px; line-height: 18px;\" for=\"cc_licensed\">Make this post available under...\" before submitting</label></p>\n</div>\n</div>\n</div>\n</div>",
    "user": {
      "username": "Thomas",
      "slug": "thomas",
      "displayName": "Thomas"
    }
  },
  {
    "_id": "eXc8HqLo2S9ujgsME",
    "title": "Test post",
    "slug": "test-post-eiJe",
    "pageUrl": "https://www.lesswrong.com/posts/eXc8HqLo2S9ujgsME/test-post-eiJe",
    "postedAt": "2017-09-25T05:43:46.089Z",
    "baseScore": 2,
    "voteCount": 1,
    "commentCount": 3,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>So, apparently I can just make blog posts, and they don't show up anywhere but my user page. Cool.</p><p>edit 2024-12-21: gonna use this to exercise every lw element type, to test my post copy-to-clipboard button. Horizontal divider:</p><hr><p>latex fraction:</p><span class=\"math-tex\"><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\frac{a}{b}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.729em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 0.729em; top: -1.143em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-denominator\" style=\"width: 0.729em; bottom: -0.795em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">b</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.729em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.938em; vertical-align: -0.795em;\" class=\"mjx-vsize\"></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span><p>table:</p><figure class=\"table\"><table><tbody><tr><td>a1</td><td>b1</td><td>c1</td></tr><tr><td>a2</td><td>b2</td><td>c2</td></tr></tbody></table></figure><p>footnote<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"ydxmtsvpaf\" role=\"doc-noteref\" id=\"fnrefydxmtsvpaf\"><sup><a href=\"#fnydxmtsvpaf\">[1]</a></sup></span></p><h1>heading 1</h1><h2>heading 2</h2><h3>heading 3</h3><p><strong>bold in a paragraph - </strong><i><strong>italic nested in bold - </strong></i><strong>just bold again; </strong>no longer bold or italic, <i>italic again,</i> no longer italic, <s>strikethrough</s>, normal again.</p><blockquote><p>quoted text.</p><ul><li>quoted bullet point.</li><li>another bullet point.</li></ul></blockquote><ul><li>unquoted bullet point.<ul><li>nested bullet, with an inverted color bullet point.<ul><li>third level of nested, with a square bullet.</li></ul></li></ul></li><li>another bullet point on the first level.</li></ul><ol><li>unquoted numbered list.</li><li>another.<ol><li>nested list, denoted \"a\".</li><li>second item, denoted \"b\".<ol><li>third level of nesting, denoted \"i\".</li><li>second item on third level, denoted \"ii\".<ol><li>fourth level, also denoted \"i\".</li><li>second item on fourth level.<ol><li>fifth level, also denoted \"i\".</li><li>second item on fifth level.</li></ol></li><li>third item on fourth level.</li></ol></li><li>third item on third level.</li></ol></li><li>third item on second level.</li></ol></li><li>third item on first level.</li></ol><pre><code>code block, plain text.</code></pre><pre><code>import derp\nx = derp.herp()\nprint(\"test\")\n# is any of this highlighted?</code></pre><p>inline <code>code phrase</code>.</p><p>image uploaded from computer:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/khpxe71k4a2h6sahtv3o\" alt=\"alt text of the image, which appears only in cases the image does not display, and is usually empty\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/y1gl9ol1k6guvmw2af8r 80w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/cjdipblzqr8hcgb1okmj 160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/axjzhkgji6qahe4rpxa4 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/b7wgqtkeyk84jncg3etx 320w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/yrbouin3kwtbaazbwmxq 400w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/u4fk4pv1jx5ubusbmil4 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/maurdxkcqa4rq3nt3npi 560w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/dm5pgrcb07n7hgn7ruui 640w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/dv94oxqitbydob6meadv 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/eXc8HqLo2S9ujgsME/rpkjgqik5ojmjrjgqev6 800w\"><figcaption>caption of the image, which appears below the image, even if the image loads</figcaption></figure><p>youtube video embed:</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=ehWlvoe7AyI\"><div><iframe src=\"https://www.youtube.com/embed/ehWlvoe7AyI\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><details class=\"detailsBlock\"><summary class=\"detailsBlockTitle\"><p>collapsible section title</p></summary><div class=\"detailsBlockContent\"><p>here's the contents of the collapsible section</p></div></details><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"ydxmtsvpaf\" role=\"doc-endnote\" id=\"fnydxmtsvpaf\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"ydxmtsvpaf\"><sup><strong><a href=\"#fnrefydxmtsvpaf\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>here's the contents of the footnote</p></div></li></ol>",
    "user": {
      "username": "lahwran",
      "slug": "the-gears-to-ascension",
      "displayName": "the gears to ascension"
    }
  },
  {
    "_id": "az89HvvG762SwwfxQ",
    "title": "Impression track records",
    "slug": "impression-track-records",
    "pageUrl": "https://www.lesswrong.com/posts/az89HvvG762SwwfxQ/impression-track-records",
    "postedAt": "2017-09-24T04:40:00.131Z",
    "baseScore": 9,
    "voteCount": 7,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>It is good to <a href=\"http://www.overcomingbias.com/2008/04/naming-beliefs.html\">separate</a> impressions from beliefs.</p><p>It is good to keep track records.</p><p>Is it good to keep separate impression and belief track records?</p><p>My default guess would be ‘a bit, but probably too much effort, since we hardly manage to keep any track records.’</p><p>But it seems maybe more than a bit good, for these reasons:</p><ol><li><p>Having good first impressions, and being good at turning everyone’s impressions into a good overall judgment might be fairly different skills, so that some people are good at one and some are good at the other, and you get a clearer signal if you separate them.</p></li><li><p>We probably by default mostly learn about beliefs and not impressions, because by assumption if I have both and they are different, I suspect the impression is wrong, and so will make me look worse if I advertise that I hold it.</p></li><li><p>Impressions are probably better than beliefs to have track records for, because the point of the track records is to know how much to weight to give different sources when constructing beliefs, and it is more straightforward to know directly which sources are good than to know which aggregations of sources are good (especially if they are mostly bad, because nobody has track records).</p></li></ol><p>As in, perhaps we mostly keep belief track records when we keep track records, but would do better with impression track records. What would we do if we wanted to keep impression track records instead? (Do we already?)</p></div></div></div></div>",
    "user": {
      "username": "KatjaGrace",
      "slug": "katjagrace",
      "displayName": "KatjaGrace"
    }
  },
  {
    "_id": "ZkWvFmvTe3bvvfL69",
    "title": "Deontologist Envy",
    "slug": "deontologist-envy",
    "pageUrl": "https://www.lesswrong.com/posts/ZkWvFmvTe3bvvfL69/deontologist-envy",
    "postedAt": "2017-09-23T20:21:49.558Z",
    "baseScore": 10,
    "voteCount": 16,
    "commentCount": 16,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Many consequentialists of my acquaintance appear to suffer from a tragic case of deontologist envy.</p><p>In consequentialism, one makes ethical decisions by choosing the actions that have the best consequences, whether that means maximizing your own happiness and flourishing (consequentialist ethical egoism), increasing pleasure and decreasing pain (hedonic utilitarianism), satisfying the most people&#x27;s preferences (preference utilitarianism) or increasing the number of pre-defined Good Things in the world (objective list consequentialism). Of course, it&#x27;s impossible to figure out all the consequences of your actions in advance, so many people follow particular sets of rules which they believe maximize utility overall; this is sometimes called &quot;rule consequentialism&quot; or &quot;rule utilitarianism.&quot;</p><p>In deontology, one makes ethical decisions by choosing the actions that follow some particular rule. For example, one might do only the actions that you&#x27;d will that everyone do, or actions that involve treating other people as ends rather than means, or actions that don&#x27;t violate the rights of other beings, or actions that don&#x27;t involve initiating aggression, or actions that are not sins according to the teachings of the Catholic Church. While it&#x27;s allowed to care about whether things are better or worse (some deontologists I know call it their &quot;axiology&quot;), you can only care about that within the constraints of the rule system.</p><p>In spite of <a href=\"https://thingofthings.wordpress.com/2017/09/21/why-attitudes-matter/\">my sympathies for virtue ethics</a>, I do think it is generally better to make decisions based on whether the outcomes are good as opposed to decisions based on whether they follow a particular set of rules or are the decisions a person with particular virtues would make. (I continue to find it weird that these are the Only Three Options For Decision-Making About Ethics, So Says Philosophy, but anyway.) So do most people I know.</p><p>I have some consequentialist beliefs about free speech. For instance, I support making fun of people who say sexist or racist things in public. I think it is fine to call someone a bigoted asshole if they are, in fact, saying bigoted asshole things. I appreciate <a href=\"http://www.chronicle.com/article/Speaking-at-Berkeley-With-Milo/241226\">Charles Murray refusing to speak at an event Milo Yiannopoulous</a> is at because he is &quot;a despicable asshole&quot; and I wish more people would follow his example. And when I express my consequentialist beliefs about free speech a surprising number of my consequentialist friends respond with &quot;but what if your political opponents did that?&quot;</p><p>I did not realize we are all Kantians now.</p><p>I think there are three things that people sometimes mean by &quot;but what if everyone did that?&quot; The first is simple empathy: if it hurts you to be shamed, then you should consider the possibility that it hurts other people to be shamed too, no differently from how you are hurt. I agree that this is an important argument, and we could all stand to be a little bit more aware that people we disagree with are people with feelings. But even deontologists agree sometimes it&#x27;s necessary to hurt one person for the greater good: for example, even if you are very lonely and it hurts you not to get to talk to people, you don&#x27;t get to force people to interact with you against their will. So I don&#x27;t think that the mere fact that it hurts people implies that (say) public shaming should be off-limits.</p><p>The second is a rather touching faith in the ability of people&#x27;s virtuous behavior to influence their political opponents.</p><p>Now, if it happened that my actions had any influence whatsoever over the behavior of <a href=\"https://www.reddit.com/r/TumblrInAction/\">r/TumblrInAction</a>, that would be great. I don&#x27;t screenshot random tumblr users and mock them in front of an audience of over three hundred thousand people, so the entire subreddit would close down, which would be a great benefit to humanity. While we&#x27;re at it, there are many other places people who read r/TumblrInAction could follow my illustrious example. For instance, they could be tolerant of teenagers with dumb political beliefs, remembering how stupid their own teenage political beliefs were. They could stop making fun of deitykin, otherwise known as &quot;psychotic people with delusions of grandeur,&quot; because jesus fucking christ it is horrible to mock a mentally ill person for showing mental illness symptoms. They could stop with the &quot;I identify as an attack helicopter&quot; jokes; I mean, I don&#x27;t have any ethical argument against those jokes, it&#x27;s just that there is <a href=\"https://fatpinocchio.tumblr.com/post/163488596344/later-trump-what-happened-to-our-attack#notes\">exactly one of them that was ever funny</a>. </p><p>In general people rarely have their behavior influenced by their political enemies. Trans people take pains to use the correct pronouns; people who are overly concerned about trans women in bathrooms still misgender them. Anti-racists avoid the use of slurs; a distressing number of people who believe in human biodiversity appear to be incapable of constructing a sentence without one. Social justice people are conscientious about trigger warnings; we are subjected to many tedious articles about how mentally ill people should be in therapy instead of burdening the rest of the world with our existence.</p><p>Therefore, I suspect that if supporters of social justice universally became conscientious about representing their opponents&#x27; views fairly, defaulting to kindness and using cruelty only as a last resort when it is necessary to reduce overall harm, and not getting people fired from their jobs, it would not have any effect on how often opponents of social justice represent opponents&#x27; views fairly, behave kindly, and condemn campaigns to fire people. In fact, they might end up doing so more enthusiastically, because suddenly kindness and charity and not getting people fired are Social Justice Things, and you don&#x27;t want to support Social Justice Things, do you?</p><p>(I&#x27;m making this argument with the social justice side as the good side, but it works equally well for literally any two sides in the relevant positions.)</p><p>Third, there&#x27;s an argument I personally find very compelling. Nearly everyone who does wrong things, even evil things, thinks that they&#x27;re on the side of good. Therefore, the fact that you think you&#x27;re on the side of good doesn&#x27;t mean you actually are. (The traditional example is Nazis, but I think Stalinism is probably better, because in my experience most people agree that your average rank-and-file Stalinist supported an ideology that killed millions of people because they had a good goal but were horribly mistaken about how to bring it about.) So it&#x27;s important to take steps to reduce the harm of your actions if you&#x27;re actually doing evil.</p><p>Like I said, I find this argument compelling. But you can&#x27;t get an entire ethical system out of trying to avoid being a Stalinist. Lots of generally neutral or even good things are evil if a Stalinist happens to be doing them, such as trying to convince people of your point of view or going to political rallies or donating to causes you think will do the most good in the world. If you were a Stalinist, the maximally good action you could do, short of not becoming a Stalinist anymore, is sitting on the couch watching Star Trek reruns. This moral system has some virtues-- depressed people the world over can defend their actions by saying &quot;well, actually, I&#x27;m one of the best people in the world by Not-Having-Even-The-Slightest-Chance-Of-Being-A-Stalinist-ianism&quot;-- but I think it is unsatisfying for most people.</p><p>(I can tell someone is about to say &quot;you can donate to the Against Malaria Foundation, there&#x27;s no possible way that could be evil!&quot; and honestly that just seems like a failure of imagination.)</p><p>That&#x27;s not to say that trying to avoid being a Stalinist should have no effects on your ethical system at all. Perhaps most important is <a href=\"http://lesswrong.com/lw/v1/ethical_injunctions/\">never, ever, ever engaging in deliberate self-deceptio</a>n. Of almost equal importance is not hiding inconvenient facts. If you <a href=\"https://en.wikipedia.org/wiki/Denial_of_the_Holodomor#Denial_outside_of_the_USSR\">know damn well the Holodomor is happening</a>, do not write a bunch of articles denouncing everyone who says the Holodomor is happening as a reactionary who hates poor people. On a less dramatic level, if there&#x27;s a study that doesn&#x27;t say what you want it to say, mention it anyway; if you can massage the evidence into saying something that it doesn&#x27;t really say, don&#x27;t; take care to mention the downsides and upsides of proposed policies as best you can. These are most important, because they directly harm the ability of truth to hurt falsehood.</p><p>And there are some things that I think it&#x27;s worth putting on the list of things you shouldn&#x27;t do even if you have a really really good reason, because it is far more likely that you are mistaken than that this is actually right this time. Violence against people who aren&#x27;t being violent against others, outside of war (and no rules-lawyering about how being mean is violence, either). Being a dick to people who are really weird but not hurting anyone (and no rules-lawyering about indirect harm to the social fabric, either). Firing people for reasons unrelated to their ability to perform their jobs. I&#x27;ve added &quot;not listening to your kid and respecting their point of view when they try to tell you something important about themselves, even if you disagree,&quot; but that&#x27;s a personal thing related to my own crappy relationship with my parents.</p><p>But that&#x27;s not a complete ethical system. At some point you have to do things. And that means, yes, that there&#x27;s a possibility you will do something wrong. Maybe you will be a participant in an ongoing moral catastrophe; maybe you will make the situation worse in a way you wouldn&#x27;t have if you sat on your ass and watched Netflix. On the other hand, if you don&#x27;t do anything at all, you get to be the person sitting idly by while ongoing moral catastrophes happen, and those people don&#x27;t exactly get a good reputation in the history textbooks either. (“The only thing necessary for the triumph of evil is for good men to do nothing,&quot; quoth Edmund Burke.)</p><p>The virtue of consequentialism is that it pays attention to consequences. It is consistent for me to say &quot;feminist activism is good, because it has good consequences, and anti-feminist activism is bad, because it has bad consequences.&quot; (Similarly, it is consistent to say that you should lie to axe murderers and homophobic parents, but not to more prosocial individuals.) This is compatible with me believing that if I had a different set of facts I would probably be engaged in anti-gay activism, and in fact many loving, compassionate, and intelligent people of my acquaintance do or have in the past. Moral luck exists; it is possible to do evil without meaning to. There would be worse consequences if everyone adopted the policy of never doing anything that might possibly be wrong.</p><p>There is a common criticism of consequentialism where people say &quot;well if torture had good consequences then you&#x27;d support torture! CHECKMATE CONSEQUENTIALISTS.&quot; Of course, in the real world torture always has bad consequences, which is why consequentialists oppose it. If stabbing people in the gut didn&#x27;t cause them pain or kill them, and in fact gave them sixteen orgasms and a chocolate cake, then stabbing people would be a good thing, but it is not irrelevant to consequentialism that stabbing does not do this.</p><p>Some people seem to want to be able to do consequentialism without ever making reference to a consequence. If you just find enough levels of meta and use the categorical imperative enough, then maybe you will be able to do consequentialism without all that scary &quot;evidence&quot; and &quot;facts&quot; stuff, and without the possibility that you could be mistaken. This seems like a perverse desire, and in my opinion is best dealt with by no longer envying deontology and instead just becoming a deontologist.</p></div></div></div></div>",
    "user": {
      "username": "ozymandias",
      "slug": "ozymandias",
      "displayName": "ozymandias"
    }
  },
  {
    "_id": "DXzc2frpnwtXj4cQb",
    "title": "LW2.0 now in public beta (you'll need to reset your password to log in)",
    "slug": "lw2-0-now-in-public-beta-you-ll-need-to-reset-your-password",
    "pageUrl": "https://www.lesswrong.com/posts/DXzc2frpnwtXj4cQb/lw2-0-now-in-public-beta-you-ll-need-to-reset-your-password",
    "postedAt": "2017-09-23T12:00:50.345Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 18,
    "meta": false,
    "question": false,
    "url": "http://lesserwrong.com/",
    "htmlBody": null,
    "user": {
      "username": "Kaj_Sotala",
      "slug": "kaj_sotala",
      "displayName": "Kaj_Sotala"
    }
  },
  {
    "_id": "ENBzEkoyvdakz4w5d",
    "title": "Out to Get You",
    "slug": "out-to-get-you",
    "pageUrl": "https://www.lesswrong.com/posts/ENBzEkoyvdakz4w5d/out-to-get-you",
    "postedAt": "2017-09-23T10:50:00.185Z",
    "baseScore": 135,
    "voteCount": 103,
    "commentCount": 14,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Epistemic Status: Reference.</p><p>Expanded From: <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook/\">Against Facebook</a>, as the post originally intended.</p><p>Some things are fundamentally Out to Get You. </p><p>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Least bad deals require careful search. Experiences are not as advertised. What you want is buried underneath stuff you don’t want. Everything is data to sell you something, rather than an opportunity to help you.</p><p>When you deal with Out to Get You, you know it in your gut. Your brain cannot relax. You lookout for tricks and traps. Everything is a scheme.</p><p>They want you not to notice. To blind you from the truth. <a href=\"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiBlZvxmLjTAhXHRCYKHVXIBUQQtwIIIzAA&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DTbYirSi08m4&usg=AFQjCNHjigokAukGU43eFj87EAB_ZeeR3w&sig2=duzb8zMsZdVS2ATUQB6m-w\">You can feel it when you go to work. When you go to church. When you pay your taxes.</a> It is bad government and bad capitalism. It is many bad relationships, groups and cultures.</p><p>When you listen to a political speech, you feel it. Dealing with your wireless or cable company, you feel it. At the car dealership, you feel it. When you deal with that one would-be friend, you feel it. Thinking back on that one ex, you feel it. <a href=\"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiJs_PpmbjTAhVNgiYKHfmMA18QyCkIJTAA&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4F4qzPbcFiA&usg=AFQjCNFb9mk_lO6gTddFXnK8LvAwPVv7_w&sig2=c5sS3jHomcNyx9cxrCzuQQ\">It’s a trap</a>.</p><h2><strong>Get Gone, Get Got, Get Compact or Get Ready</strong></h2><p>There are four responses to Out to Get You.</p><p>You can Get Gone. Walk away. Breathe a sigh of relief.</p><p>You can Get Got. Give the thing everything it wants. Pay up, relax, enjoy the show.</p><p>You can Get Compact. Find a rule limiting what ‘everything it wants’ means in context. Then Get Got, relax and enjoy the show.</p><p>You can Get Ready. Do battle. Get what you want.</p><h2><strong>When to Get Got</strong></h2><p>Get Got when the deal is Worth It.</p><p>This is a difficult lesson for everyone in <em>at least</em> one direction.</p><p>I am among those with a natural hatred of <em>Getting Got</em>. I needed to learn to relax and enjoy the show when the deal is Worth It. Getting Got imposes a large emotional cost for people like me. I have worked to put this aside when it’s time to Get Got, while preserving my instincts as a defense. That’s hard.</p><p>Others make the mistake of <em>not</em> hating Getting Got. They might not even notice. This is bad. If you Get Got without realizing, you’ll Get Got often for large amounts. Bad habits will form. Deals won’t be Worth It. Reasonable is insufficient: Out to Get You is engineered to fool. Only accept capital letters Worth It.</p><p><strong>When you Get Got, <em>do it on purpose</em>.</strong></p><p>Never Get Got without saying to yourself “I am Getting Got. It is Worth It.”</p><p></p><p>If you realize you’ve been unwittingly Got, feel sad. Update. Cost is finite, so you should <em>sometimes</em> Get Got unaware. It is still unacceptable.</p><p></p><p>You can choose to Get Got only if you know what you’ll be Got for.</p><p></p><p><strong>You cannot afford to Get Got if the price is not compact.</strong> </p><h4></h4><p>You can Get Got by a car salesman, saving time and aggravation. Max loss is the price.</p><p></p><p>You can Get Got with an unlimited phone plan. Max loss is the price.</p><p></p><p>You can Get Got by a restaurant, club or cruise ship vacation. Leaving money on the table and relaxing could be Worth It, <em>if you know your max loss and find it acceptable.</em></p><p></p><p>You can Get Got in a relationship. That’s the Price of Admission. That’s fine <em>if you know the price and find it Worth It. </em></p><p></p><p>You can buy a AAA game for $60 today rather than $20 next year. Pay $2,000 a year for Magic: The Gathering. Overpay for concert tickets. Wear a symbolic hat. Go vegan. Believe the Knicks will be good next year. If you want. Your call.</p><p></p><p>There may be no reasonable max loss. Some things want too much.</p><p></p><p>A clean example is free to play mobile games. If allowed, they charge tens of thousands of dollars. Players called whales are so addicted they pay. The games destroy them.</p><p></p><p>The motivating example was <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook/\">Facebook</a>. Facebook wants <em>your entire life</em>. Users not consciously limiting engagement lose hours a day. Every spare moment is spent scrolling, checking for updates, likes and comments. This reliably makes users miserable. Other social networks share this problem.</p><p></p><p>An important example is politics. Political causes want every spare minute and dollar. They want to choose your friends, words and thoughts. If given power, they seize the resources of state and nation for their purposes. Then they take those purposes further. One cannot simply give <em>any</em> political movement what it wants. That way lies ruin and madness.</p><p></p><p>Yes, that means <em>your</em> cause, too.</p><p></p><p>This generalizes into most sufficiently intense signaling and status competition. One must always signal harder or seek higher status. This takes over everything you are and eats your entire life. Part of sending sufficiently intense signals is showing that you have allowed this! <a href=\"https://thezvi.wordpress.com/2017/09/05/expanding-premium-mediocrity/\">Maya Millennial</a> has fallen victim. Those keeping up with the Joneses fall victim. Many a child looking fitting in or applying to college falls victim.</p><p></p><p>Obsession with safety does this.</p><p></p><p>Television eats people’s lives. So do video games. So do drugs and alcohol. One must be careful and know your tenancies and limits.</p><p></p><p>Ethical arguments do this, ensnaring vulnerable people.</p><p></p><p>This property is a way to distinguish cults from religions. Cults want it all. Religion wants its cut.</p><p></p><p><strong>You can only pay off those who charge a bounded price and stay bought. Before you pay the ransom, be sure it will free the hostages.</strong></p><p></p><p>Would going along result in <em>cooperation</em>? Or put blood in the water?</p><p></p><h2>When To Get Compact</h2><h4></h4><p>Get Compact when you find a rule you can follow that makes it Worth It to Get Got.</p><p></p><p>The rule must create an acceptable max loss. A well-chosen rule transforms Out to Get You for a lot into Out to Get You for a price you find Worth It. You then Get Got.</p><p></p><p>This works best using a natural point beyond which lies clear diminishing returns. If no such point exists, be suspicious.</p><p></p><p>A simple way is a <em>budget</em>. Spend at most $25,000 on this car, or $5,000 on this vacation package. This creates an obvious max dollar loss.</p><p></p><p>Many budgets should be $0. Example: free to play games. Either it’s worth playing for free or it isn’t. It isn’t.</p><p></p><p>The downside of budgets is often spending exactly your maximum, especially if others figure out what it is. Do your best to avoid this. Known bug.</p><p></p><p>An alternative is <em>restriction on type</em>. Go to a restaurant and avoid alcohol, desert and appetizers. Pay in-game only for full game unlocks and storage space.</p><p></p><p>Budgets can be set for each purchase. Hybrid approaches are good.</p><p></p><p>Many cap their charitable giving at 10%. Even those giving more reserve some amount for themselves. Same principle.</p><p></p><p>For other activities, max loss is about <em>time</em>. Again, you can use a (time) budget or limit your actions in a way that restricts (time) spent, or combine both.</p><p></p><p>Time limits are crude but effective. Limiting yourself to an hour of television or social media per day maxes loss at an hour. This risks making you value the activity more. Often time budgets get exactly spent same as dollar budgets. Try to let unspent time roll over into future periods, to avoid fear or ‘losing’ unspent time.</p><p></p><p>When time is the limiting factor, it is better where possible to engineer your environment and options to make the activity compact. You’ll  get more out of the time you do spend and avoid feeling like you’re arbitrarily cutting yourself off.</p><p></p><p>Decide what’s worth watching. Watch that.</p><p></p><p>For Facebook, classify a handful of people See First. See their posts. No others. Look at social media only on computers. Don’t comment. Or post.</p><p></p><p>A buffet creates overeating. Filling up one plate (or one early to explore, then one to exploit) ends better.</p><p></p><p>Unlimited often requires limitation.</p><p></p><p>Outside demands follow the pattern. To make explanation and justification easier, choose good enough rules that sound natural, simple and reasonable.</p><p></p><p>Experiments need a chance, but also a known point where you can know to call it quits. Ask whether you can get a definitive negative result in reasonable time. Will I worry I did it wrong? Will others claim or assume I did it wrong or didn’t give it a fair chance?</p><p></p><h2>When to Get Ready</h2><h4></h4><p>Get Ready when you have no choice.</p><p></p><p>Getting Ready means battle. An enemy trying to Get You. You are determined not to Get Got. You have done the research. Your eyes are open. You are on alert. You are ready.</p><p></p><p>You have no choice. The price of surrender is too high. Simple heuristics won’t work. You are already in too deep, or they have something you need and all alternatives are worse.</p><p></p><p>Sometimes you must accept a bad time and try not to let events get to you. Other times going into battle can be fun. I like games. Games are fun! So are puzzles. Buying a car, planning a vacation, trading for your Magic deck or managing one’s social media interactions can be a game or puzzle. Get the one trying to get you. Get a lot for a little.</p><p></p><p>There are big downsides.</p><p></p><p>The game can be fun. The original activity can be fun. <em>Both at once</em> is rarely fun. Both means multi-tasking and context-switching, plus a radical shift in emotion and tone. Relaxing into cooperative experience is not compatible with battles of wits and tricks.</p><p></p><p>The result of this is that you often end up unable to maintain both states at once. Sometimes you end up relaxing, and Get Got. Other times, you focus on not Getting Got and don’t enjoy what you get. Either way, you lose.</p><p></p><p>The best way out of this is to try and front-load or batch as much of the battle as possible. Sometimes this happens naturally. If you first choose, shop and haggle, then later enjoy the bounty, that’s the ideal way to do battle. Do your best to transform into that sequence, or to make enough choices to transform into a Compact situation.</p><p></p><p>If this is not possible, consciously switch between modes when needed. Think, “time to pause to not get got,” deal with the issue, switch back. This minimizes bleeding between states. If getting attempts are too continuous, this becomes possible and you need another mode.</p><p></p><p>You pay for not Getting Got with time and attention. You master arcane details. Time disappears. You spend parties talking tricks instead of living life. If shower thoughts shift to such places, you are paying a high price.</p><p></p><p>The biggest downside is <em>you can lose</em>. </p><p></p><h2><strong>When To Get Gone</strong></h2><h4></h4><p>Often.</p><p></p><p>You need good reason to stick around when things are Out to Get You. It is often wise to Get Gone, if you can.</p><p></p><p><strong>If your instincts say Get Gone, Get Gone.</strong> At worst it is only a small mistake.</p><p></p><p><strong>If your instincts do not say Get Gone, but you can’t find a viable approach to another option, Get Gone anyway.</strong></p><p></p><p>The getting can be insidious. Constant vigilance is required. Many think they can handle it, check all the right boxes and not get drawn in. Some are right. Often they are wrong.</p><p></p><p><strong>If Getting Got means you lose an order of magnitude bigger than you can win, Get Gone.</strong></p><p></p><p><strong>If Getting People is how something survives, Get Gone.</strong></p><p></p><p>Free trial! Automatically renews. Probably won’t want? Don’t wait. Get Gone.</p><p></p><p>You <strong>think</strong> you are getting good odds. You are probably wrong.</p><p></p><p>You <strong>think</strong> you know all the tricks they will try. You are probably wrong.</p><p></p><p>You <strong>think</strong> there is something is forcing your hand. Make sure this is something you need rather than a want. The word need is thrown around a lot these days.</p><p></p><p>Getting Gone is worth making sacrifices. Big sacrifices.</p><p></p><p><strong>If you cannot Get Gone, do not engage more than necessary.</strong> Go into Easy Mode. Get what you must. Then Get Gone.</p>",
    "user": {
      "username": "Zvi",
      "slug": "zvi",
      "displayName": "Zvi"
    }
  },
  {
    "_id": "8iAJ9QsST9X9nzfFy",
    "title": "Nobody does the thing that they are supposedly doing",
    "slug": "nobody-does-the-thing-that-they-are-supposedly-doing",
    "pageUrl": "https://www.lesswrong.com/posts/8iAJ9QsST9X9nzfFy/nobody-does-the-thing-that-they-are-supposedly-doing",
    "postedAt": "2017-09-23T10:40:06.155Z",
    "baseScore": 63,
    "voteCount": 42,
    "commentCount": 6,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>I feel like one of the most important lessons I’ve had about How the World Works, which has taken quite a bit of time to sink in, is:</p><p><strong>In general, neither organizations nor individual people do the thing that their supposed role says they should do.</strong> Rather they tend to do the things that align with their <a href=\"https://en.wikipedia.org/wiki/Incentive\">incentives</a> (which may sometimes be economic, but even more often they are social and psychological). If you <a href=\"http://donellameadows.org/archives/leverage-points-places-to-intervene-in-a-system/\">want to really change things</a>, you have to change people’s incentives.</p><p>But I feel like I’ve had to gradually piece this together from a variety of places, over a long time; I’ve never read anything that would have laid down the whole picture. I remember that <a href=\"https://www.amazon.com/Freakonomics-Economist-Explores-Hidden-Everything/dp/0060731338\">Freakonomics</a> had a few chapters about how incentives cause unexpected behavior, but that was mostly about economic incentives, which are just a small part of the whole picture. And it didn’t really focus on the “nothing in the world works the way you’d naively expect” thing; as I recall, it was presented more as a curiosity.</p><p>On the other hand, <a href=\"http://overcomingbias.com/\">Robin Hanson</a> has had a lot of stuff about “<a href=\"http://www.overcomingbias.com/2008/09/politics-isnt-a.html\">X is not about Y</a>“, but that has mostly been framed in terms of prestige and signaling, which is the kind of stuff that’s certainly an important part of the whole picture (the psychological kind of incentives), but again just a part of the picture. (However, his <a href=\"http://elephantinthebrain.com/\">upcoming book</a> goes into a lot more detail on why and how the publicly-stated motives for human or organizational behavior aren’t actually the true motives.)</p><p>And then in social/evolutionary/moral psychology there’s a bunch of stuff about social-psychological incentives, of <a href=\"https://www.sas.upenn.edu/psych/PLEEP/pdfs/Kurzban%20DeScioli%20mysteries.pdf\">how we’re motivated</a> to denounce outgroups and form bonds with our ingroups; and how it can be socially costly to have accurate beliefs about outgroups and defend them to your ingroup, whereas it would be much more rewarding to <a href=\"https://www.youtube.com/watch?v=rE3j_RHkqJc\">just spread inaccuracies</a> or outright lies about how terrible the outgroups are, and thus increase your own social standing. And how even well-meaning ideologies will <a href=\"https://www.edge.org/response-detail/27168\">by default get hijacked</a> by these kinds of dynamics and become something quite different from what they claimed to be.</p><p>But again, that’s just one piece of the whole story. And you can find more isolated pieces of the whole story scattered around in a <a href=\"https://meaningness.com/geeks-mops-sociopaths\">variety</a> of <a href=\"http://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">articles</a> and <a href=\"http://www.daviddfriedman.com/The_Machinery_of_Freedom_.pdf\">books</a>, also stuff like the <a href=\"https://en.wikipedia.org/wiki/Iron_law_of_oligarchy\">iron law of oligarchy</a>, <a href=\"https://en.wikipedia.org/wiki/Rational_irrationality\">rational irrationality</a>, <a href=\"https://en.wikipedia.org/wiki/Public_choice\">public choice theory</a>, etc etc. But no grand synthesis.</p><p>There’s also a relevant strand of this in the psychology of motivation/<a href=\"http://lesswrong.com/lw/3w3/how_to_beat_procrastination/\">procrastination</a>/<a href=\"https://smile.amazon.com/Power-Habit-Why-What-Change-ebook/dp/B006WAIV6M/\">habit-formation</a>, on why people keep putting off various things that they claim they <em>want</em> to do, but then don’t. And how small things can reshape people’s behavior, like if somebody ends up as a much more healthy eater just because they <em>don’t</em> happen to have a fast food restaurant conveniently near their route home from work. Which isn’t necessarily so much about incentives themselves, but an important building block in understanding why our behavior tends to be so strongly shaped by things that are entirely separate from consciously-set goals.</p><p>Additionally, the things that do drive human behavior are often things like <a href=\"http://kajsotala.fi/2017/07/how-i-found-fixed-the-root-problem-behind-my-depression-and-anxiety-after-20-years/\">maintaining a self-concept</a>, seeking feelings of <a href=\"https://en.wikipedia.org/wiki/Self-determination_theory\">connection, autonomy and competence</a>, <a href=\"http://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0131613\">maintaining</a> <a href=\"https://web.archive.org/web/20080513074310/http://www.thestage.co.uk/connect/acblack/improkj.php\">status</a>, enforcing <a href=\"http://www.moralpsych.net/s/haidt-2001.pdf\">various moral intuitions</a>, etc., things that only loosely align one’s behavior with one’s stated goals. Often people may not even realize what exactly it is that they are trying to achieve with their behavior.</p><p><a href=\"http://lesswrong.com/lw/15w/experiential_pica/\">“Experiental pica” is a misdirected craving</a> for something that doesn’t actually fulfill the need behind the craving. The term originally comes from <a href=\"https://en.wikipedia.org/wiki/Pica_(disorder)\">a condition</a> where people with a mineral deficiency start eating things like ice, which don’t actually help with the deficiency. Recently I’ve been shifting towards the perspective that, to a first approximation, roughly <em>everything</em> that people do is pica for some deeper desire, with that deeper desire being something like social connection, feeling safe and accepted, or having a feeling of autonomy or competence. That is, most of the things that people will give as reasons for why they are doing something will <a href=\"http://lesswrong.com/lw/6p6/the_limits_of_introspection/\">actually miss the mark</a>, and also that many people are engaging in things that are actually relatively inefficient ways of achieving their true desires, such as pursuing career success when the real goal is social connection. (This doesn’t mean that the underlying desire would never be fulfilled, just that it gets fulfilled less often than it would if people were aware of their true desires.)</p></div></div></div></div>",
    "user": {
      "username": "Kaj_Sotala",
      "slug": "kaj_sotala",
      "displayName": "Kaj_Sotala"
    }
  },
  {
    "_id": "8MsoEbiWJbrHQmbe7",
    "title": "LW 2.0 Site Update: 09/22/17",
    "slug": "lw-2-0-site-update-09-22-17",
    "pageUrl": "https://www.lesswrong.com/posts/8MsoEbiWJbrHQmbe7/lw-2-0-site-update-09-22-17",
    "postedAt": "2017-09-23T10:10:10.594Z",
    "baseScore": 11,
    "voteCount": 6,
    "commentCount": 7,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Another set of quick updates done today: </p><ul><li><p>We had a bad bug where in about 50% of cases when a user created a post on the frontpage, it would neither show up on their userpage, nor on the frontpage, but only on the all-posts view. This is now fixed. Sorry for anyone who was confused by this!</p></li><li><p>Profiles should now accurately show both frontpage posts and personal blog posts </p></li><li><p>The karma/posts/comments icons now have tooltips that explain what they are</p></li><li><p>Imported all old blogposts for <a href=\"https://www.lesserwrong.com/users/zvi\">Zvi</a> and <a href=\"https://www.lesserwrong.com/users/katjagrace\">Katja</a> and set up automatic crossposting from their blogs</p></li><li><p>Added a new post link to a more accessible position (the user menu in the top right corner)</p></li><li><p>Fixed the sort order of comments on user&#x27;s profile pages</p></li><li><p>This time actually fixed the LessWrong title in the top left corner and properly made it a link (i.e. you can now middle-click it and it should open the page in a new tab)</p></li><li><p>Fixed permission issues with a bunch of content in The Codex. The Codex should now be fully accessible </p></li></ul></div></div></div></div>",
    "user": {
      "username": "habryka4",
      "slug": "habryka4",
      "displayName": "habryka"
    }
  },
  {
    "_id": "diZLkE7PeRF2rQ6sj",
    "title": "Intuitive explanation of why entropy maximizes in a uniform distribution?",
    "slug": "intuitive-explanation-of-why-entropy-maximizes-in-a-uniform",
    "pageUrl": "https://www.lesswrong.com/posts/diZLkE7PeRF2rQ6sj/intuitive-explanation-of-why-entropy-maximizes-in-a-uniform",
    "postedAt": "2017-09-23T09:43:44.265Z",
    "baseScore": 0,
    "voteCount": 0,
    "commentCount": 7,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>What is the best mathematical, intuitive explanation of why entropy maximizes in a uniform distribution? I'm looking for a short proof using the most elementary mathematics possible.</p>\n<p>Please no explanation like \"because entropy was designed in this way\", etc...</p>\n<p>https://en.wikipedia.org/wiki/Entropy_%28information_theory%29#Definition</p>",
    "user": {
      "username": "roland",
      "slug": "roland",
      "displayName": "roland"
    }
  },
  {
    "_id": "fPT7o9TRWobrXoiYJ",
    "title": "Voting Weight Discussion",
    "slug": "voting-weight-discussion",
    "pageUrl": "https://www.lesswrong.com/posts/fPT7o9TRWobrXoiYJ/voting-weight-discussion",
    "postedAt": "2017-09-22T22:48:25.040Z",
    "baseScore": 20,
    "voteCount": 16,
    "commentCount": 73,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>One of the distinguishing features of LW 2.0 is Voting Weight. People with more karma will be able to give higher-weighted upvotes and downvotes. </p><p>This is part of an overall plan to make it better at sorting signal-from noise. But it&#x27;s a major change to the system and seemed worthy of a dedicated-discussion thread. </p><h3>Intended Outcomes</h3><p>There are roughly three goals for the improved karma system:</p><p><strong>I. A reasonable pace of quality content on the front page, which is the </strong><a href=\"https://www.lesserwrong.com/posts/8rYxw9xZfwy86jkpG/on-the-importance-of-less-wrong-or-another-single\"><strong>single conversation locus.</strong></a> (We&#x27;re aiming for about 3-7 featured posts per week)</p><p><strong>II. A reasonable opportunity for people (newcomers and otherwise) to get their ideas seen, receive feedback. </strong>(The front page involves an inherently limited supply of attention, so not everything can go there. But good posts should at least stick around on the Recent Posts page for awhile)</p><p><strong>III. Implement goals I and II in a way that is (and feels) fair.</strong></p><h3>Current Implementation of Voting Weight</h3><p>The problem is that LessWrong is an <em>oddly specific </em>community, and it won&#x27;t be necessarily obvious to a newcomer what are the sorts of post we want to incentivize. So we want more experienced users who have a proven track epistemic record to be able to draw attention to posts more easily.</p><p>In light of Goal III, we don&#x27;t want a high-karma user&#x27;s vote to be <em>overwhelming</em>. So the current mathematical implementation is:</p><p style=\"text-align:center;\"><em>floor(log_5(karma)+1)+1</em></p><p>What this means in non-math-speak is that is that your voting weight looks something like:</p><p>0 karma: 1 voting weight<br/>5 karma: 2 voting weight<br/>25 karma: 3 voting weight<br/>125 karma: 4 voting weight<br/>625 karma: 5 voting weight<br/>... <br/><em>... roughly capping out for practical purposes at approximately:<br/></em> 400,000 karma:  9 voting weight (currently no users are near this level)</p><p>You may have noticed that when you upvote or downvote a post, it changes by more than 1 point. This is why. </p><p>New posts also start with their user having upvoted them once, so if you have 25 karma, you&#x27;ll start with 3 points. This is to reflect that people who&#x27;ve been around longer are more likely to be writing things that are worth paying attention to. (Although note that this initial upvote doesn&#x27;t count towards their overall karma score)</p><p>Shifting to a voting-weight based system also makes it easier to notice people who are abusing the system and nullify their votes (preventing mass-downvote attacks)</p><h3>Thoughts?</h3><p>The LW 2.0 team has some thoughts about how to refine the voting system into something more fine-grained. But before sharing those ideas it seemed good to solicit a more general discussion. (Some of us might share our thoughts in the comments, but those thoughts will be from our perspectives as users rather than site developers)</p><p></p></div></div></div></div>",
    "user": {
      "username": "Raemon",
      "slug": "raemon",
      "displayName": "Raemon"
    }
  },
  {
    "_id": "fnS9gtSeGJxxTcgW6",
    "title": "LessWrong-Portable",
    "slug": "lesswrong-portable",
    "pageUrl": "https://www.lesswrong.com/posts/fnS9gtSeGJxxTcgW6/lesswrong-portable",
    "postedAt": "2017-09-22T20:48:41.200Z",
    "baseScore": 8,
    "voteCount": 6,
    "commentCount": 2,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><a href=\"https://github.com/AABoyles/LessWrong-Portable\">I have created the latest in a long history of independent, disorganized projects to scrape collections of posts from LessWrong into ebooks</a>. A few selected examples of others:</p><ul><li><p>jb55&#x27;s <a href=\"https://github.com/jb55/lesswrong-print\">lesswrong-print</a></p></li><li><p>dato&#x27;s <a href=\"https://github.com/dato/lesswrong-bundle\">lesswrong-bundle</a></p></li><li><p>OneWhoFrog&#x27;s <a href=\"https://github.com/OneWhoFrogs/lw2ebook\">lw2ebook</a></p></li><li><p>srlee309&#x27;s <a href=\"https://github.com/srlee309/LessWrongEBookCreator\">LessWrongEBookCreator</a></p></li><li><p>natewind&#x27;s <a href=\"https://github.com/natewind/lesswrong-fb2\">lesswrong-fb2</a></p></li></ul><p>...Not to mention the <a href=\"https://intelligence.org/rationality-ai-zombies/\">official version of the Sequences</a>. So, why could we possibly need another?</p><p><a href=\"https://www.lesserwrong.com\">LessWrong 2.0</a>. </p><p>If LessWrong 2.0 is <a href=\"http://lesswrong.com/lw/pfl/lw_20_open_beta_live/\">voted to replace LessWrong Classic</a> (see point 4), All the existing aggregators will break. This isn&#x27;t a big deal, since they really only need to run once (correctly) in order to create the ebook, but anyone who wants to modify them and scrape new ebooks won&#x27;t be able to use them.</p><p>Separately, <a href=\"https://www.lesserwrong.com/codex\">Scott Alexander&#x27;s Codex</a> is open for reading now that the site is in open beta. Not that all this content wasn&#x27;t available elsewhere before, but this is the most promising linearly-organized collection of (some of) his writings I&#x27;ve seen. I want to read it, and as I read most things, I want to do it on my ebook reader. I&#x27;m sharing this on the off chance I&#x27;m not alone.</p><p>Currently, it only compiles <a href=\"https://www.lesserwrong.com/codex\">The Codex</a>. I may add others later, though <a href=\"https://www.lesserwrong.com/hpmor\">HPMOR</a> and <a href=\"https://www.lesserwrong.com/sequences\">R:A-Z</a> seem vastly less urgent, since they&#x27;re already available as ebooks elsewhere.</p><p>P̶l̶e̶a̶s̶e̶ ̶n̶o̶t̶e̶ ̶t̶h̶a̶t̶ ̶p̶r̶e̶s̶e̶n̶t̶l̶y̶ ̶t̶h̶e̶r̶e̶ ̶a̶r̶e̶ ̶m̶a̶n̶y̶ ̶b̶r̶o̶k̶e̶n̶ ̶l̶i̶n̶k̶s̶,̶ ̶r̶e̶s̶u̶l̶t̶i̶n̶g̶ ̶i̶n̶ ̶a̶ ̶l̶a̶r̶g̶e̶l̶y̶ ̶e̶m̶p̶t̶y̶ ̶p̶r̶o̶d̶u̶c̶t̶.̶ ̶I̶ ̶s̶u̶s̶p̶e̶c̶t̶ ̶t̶h̶i̶s̶ ̶i̶s̶ ̶t̶h̶e̶ ̶r̶e̶s̶u̶l̶t̶ ̶o̶f̶ ̶a̶ ̶b̶u̶g̶ ̶i̶n̶ ̶L̶W̶2̶ ̶w̶i̶l̶l̶ ̶b̶e̶ ̶r̶e̶s̶o̶l̶v̶e̶d̶ ̶b̶e̶f̶o̶r̶e̶ ̶t̶o̶o̶ ̶l̶o̶n̶g̶.̶</p><p>[Edit: <a href=\"https://www.lesserwrong.com/posts/8MsoEbiWJbrHQmbe7/lw-2-0-site-update-09-22-17\">This issue has been resolved.</a>]</p></div></div></div></div>",
    "user": {
      "username": "AABoyles",
      "slug": "aaboyles",
      "displayName": "AABoyles"
    }
  },
  {
    "_id": "N3YRcj2TY52PTBwMe",
    "title": "In Defense of Unreliability",
    "slug": "in-defense-of-unreliability",
    "pageUrl": "https://www.lesswrong.com/posts/N3YRcj2TY52PTBwMe/in-defense-of-unreliability",
    "postedAt": "2017-09-22T15:46:55.865Z",
    "baseScore": 9,
    "voteCount": 15,
    "commentCount": 21,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>In <a href=\"https://thezvi.wordpress.com/2017/06/24/on-dragon-army/\">a long post mostly about a different issue</a>, Zvi Mowshowitz writes:</p><blockquote><p>I also strongly endorse that the default level of reliability needs to be much, much higher than the standard default level of reliability, especially in The Bay. Things there are really bad.</p><p>When I make a plan with a friend in The Bay, I never assume the plan will actually happen. There is actual no one there I feel I can count on to be on time and not flake. I would come to visit more often if plans could actually be made. Instead, suggestions can be made, and half the time things go more or less the way you planned them. This is a terrible, very bad, no good equilibrium. Are there people I want to see badly enough to put up with a 50% reliability rate? Yes, but there are not many, and I get much less than half the utility out of those friendships than I would otherwise get.</p></blockquote><p>First of all, I&#x27;d like to say that nothing in my post should be construed as saying Zvi&#x27;s desire for reliable friends is invalid or wrong. It&#x27;s disappointing to expect a friend to come over and then they don&#x27;t. If you&#x27;re a busy person, on vacation or otherwise limited in time, a friend&#x27;s canceled plans may mean that you&#x27;ve missed out on an important opportunity to do something productive and/or fun. It is very reasonable to want to befriend people who will reliably show up places they said they will on time. However, I do want to explain why I myself am quite unreliable and how I benefit from a social norm in which this unreliability is acceptable. (We should also note that I have lived in the Bay for the majority of my adult, actually-socializing life, so I may be unfamiliar with the benefits of a non-flake lifestyle.)</p><p>I primarily get places through public transit and Uberpool. The Bay Area&#x27;s public transit system is really really good compared to public transit in most of the rest of the country (for one thing, it is possible to get places on it). However, our public transit is certainly inferior to, say, New York City&#x27;s. One of the ways this works is that sometimes, based on the Inscrutable Whim of the Train Gods, the train will choose to show up fourteen minutes late. Uberpool also has high variance in time estimates, because they have to pick up and drop off other people. What this means is that when I say &quot;I will get there at such-and-such a time&quot;, I mean &quot;there is a bimodal distribution of times when I could show up which is centered around this time and probably has a standard deviation of like five to ten minutes.&quot;</p><p>So there are ways I can fairly consistently show up on time. One is that I could take UberX wherever I&#x27;m going and eat the extra expense-- although doing that consistently would trade off against my goal of using money responsibly. Another is that I can plan to show up on average ten or fifteen minutes before I&#x27;m supposed to show up, and then most of the time I will be on time. (This is what I do for doctors&#x27; and therapists&#x27; appointments.)</p><p>There are two problems with adopting the latter strategy in general. First, my time also has value! If it&#x27;s bad for me to show up ten minutes late because the person is waiting around being bored, then it is also bad for me to show up ten minutes early so I have to wait around and be bored. Second, in many cases, showing up early is just as inconvenient for others as showing up late. For instance, if a friend invited me over for dinner and I show up fifteen minutes early, they might be still in their bathrobe and really counting on that fifteen minutes to shove the floordrobe into the closet and take the garbage out. That would be considerably ruder than showing up fifteen minutes late (at least if you keep them posted), because at that point the food is probably only beginning to get cold.</p><p>(I guess I could arrive early and then hang out on a street corner until it was time for dinner but see above re: my time has value.)</p><p>In general, instead of trying to always show up before you said you would, I think the best strategy is to try to be early about as often as you are late, unless it is something where being early is much much better than being late (a theatrical production, a doctor&#x27;s appointment, a job interview) or vice versa (a party with lots of other invitees).</p><p>However, Zvi didn&#x27;t just talk about being on time: he also talked about flaking. My local corner of the Bay seems to have less of a flaking problem than his corner. I, a diagnosed agoraphobe, still manage to make the majority of the social events I agree to go to, and many people of my acquaintance make as much as ninety or ninety-five percent. (Maybe I am particularly charming and people don&#x27;t want to flake on me, or maybe I&#x27;m proactive and flake on them first.) But I think it is very useful that no one gets angry at me for flaking as much as I do.</p><p>I&#x27;m scared of leaving my house. This means that when I make social arrangements a lot of the time I won&#x27;t end up actually going to them because I will be too scared of leaving my house. Whether I&#x27;m going to have a good mental health day or a bad mental health day is hard to predict even a week in advance, because it depends on short-term triggers like whether I&#x27;ve fought with a close friend, whether the assholes across the street have decided to set off fireworks, whether a person has said something unpleasant about me on the Internet, whether I&#x27;ve been doing a good job of remembering that in spite of what my brain tells me doing things will make me feel better and not doing things will make me feel worse, and so on. So the only way I can achieve any sort of reliability in social arrangements is by not making them.</p><p>I do not want to not make social arrangements. Social isolation makes my mental health worse. And doing literally anything tends to make me less depressed. I am also informed that some people would occasionally like to talk to me [citation needed]. So therefore I have decided to make plans anyway, and push onto my friends the negative consequences of dealing with my flakiness.</p><p>It seems perfectly reasonable to me that one would object to this state of affairs and choose not to have me as a friend. (This is one of many good reasons why someone might not want to have me as a friend.) But I think before advocating for a complete shift in social norms one should consider the benefits the social norms already have to those participating in them.</p></div></div></div></div>",
    "user": {
      "username": "ozymandias",
      "slug": "ozymandias",
      "displayName": "ozymandias"
    }
  },
  {
    "_id": "kgsaSbJqWLtJfiCcz",
    "title": "Naturalized induction – a challenge for evidential and causal decision theory",
    "slug": "naturalized-induction-a-challenge-for-evidential-and-causal",
    "pageUrl": "https://www.lesswrong.com/posts/kgsaSbJqWLtJfiCcz/naturalized-induction-a-challenge-for-evidential-and-causal",
    "postedAt": "2017-09-22T08:15:09.999Z",
    "baseScore": 15,
    "voteCount": 10,
    "commentCount": 15,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>As some of you may know, I disagree with many of the criticisms leveled against <a href=\"https://en.wikipedia.org/wiki/Evidential_decision_theory\">evidential decision theory</a> (EDT). Most notably, I believe that Smoking lesion-type problems <a href=\"https://casparoesterheld.com/overview-why-we-think-that-the-smoking-lesion-does-not-refute-edt/\">don't</a> refute EDT. I also don't think that EDT's non-updatelessness leaves a lot of room for&nbsp;disagreement, given that EDT <a href=\"https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessnes/\">recommends</a> immediate self-modification to updatelessness. However, I do believe there are some issues with run-of-the-mill EDT. One of them is <a href=\"https://wiki.lesswrong.com/wiki/Naturalized_induction\">naturalized induction</a>. It is in fact not only a problem for EDT but also for causal decision theory (CDT) and most other <a href=\"https://casparoesterheld.com/a-comprehensive-list-of-decision-theories/\">decision theories that have been proposed in- and outside of academia</a>. It does not affect logical decision theories, however.</p>\n<h1>The role of naturalized induction in decision theory</h1>\n<p>Recall that EDT prescribes taking the action that maximizes expected utility, i.e.</p>\n<p><img title=\"\\underset{a\\in A}{\\mathrm{argmax}} ~\\mathbb{E}[U(w)|a,o] = \\underset{a\\in A}{\\mathrm{argmax}} \\sum_{w\\in W} P(w|a,o) U(w),\" src=\"http://www.codecogs.com/png.latex?\\underset{a\\in%20A}{\\mathrm{argmax}}%20~\\mathbb{E}[U(w)|a,o]%20=%20\\underset{a\\in%20A}{\\mathrm{argmax}}%20\\sum_{w\\in%20W}%20P(w|a,o)%20U(w),\" alt=\"\" align=\"bottom\" /></p>\n<p>where <img title=\"A\" src=\"http://www.codecogs.com/png.latex?A\" alt=\"\" align=\"bottom\" /> is the set of available actions, <img title=\"U\" src=\"http://www.codecogs.com/png.latex?U\" alt=\"\" align=\"bottom\" /> is the agent's utility function, <img title=\"W\" src=\"http://www.codecogs.com/png.latex?W\" alt=\"\" align=\"bottom\" /> is a set of possible world models, <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" /> represents the agent's past observations (which may include information the agent has collected about itself). CDT works in a &ndash; for the purpose of this article &ndash; similar way, except that instead of conditioning on <img title=\"a\" src=\"http://www.codecogs.com/png.latex?a\" alt=\"\" align=\"bottom\" /> in the usual way, it calculates some causal counterfactual, such as Pearl's do-calculus: <img title=\"P(w|do(a),o)\" src=\"http://www.codecogs.com/png.latex?P(w|do(a),o)\" alt=\"\" align=\"bottom\" />. The problem of naturalized induction is that of assigning posterior probabilities to world models <img title=\"P(w|a,o)\" src=\"http://www.codecogs.com/png.latex?P(w|a,o)\" alt=\"\" align=\"bottom\" /> (or <img title=\"P(w|do(a),o)\" src=\"http://www.codecogs.com/png.latex?P(w|do(a),o)\" alt=\"\" align=\"bottom\" /> or whatever) when the agent is <a href=\"https://casparoesterheld.com/overview-introductions-to-the-problem-of-naturalized-agency/\">naturalized, i.e., embedded into its environment</a>.</p>\n<p>Consider the following example. Let's say there are 5 world models <img title=\"W=\\{w_1,...,w_5\\}\" src=\"http://www.codecogs.com/png.latex?W=\\{w_1,...,w_5\\}\" alt=\"\" align=\"bottom\" />, each of which has equal prior probability. These world models may be <a href=\"https://en.wikipedia.org/wiki/Cellular_automaton\">cellular automata</a>. Now, the agent makes the observation <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" />. It turns out that worlds <img title=\"w_1\" src=\"http://www.codecogs.com/png.latex?w_1\" alt=\"\" align=\"bottom\" /> and <img title=\"w_2\" src=\"http://www.codecogs.com/png.latex?w_2\" alt=\"\" align=\"bottom\" /> don't contain any agents at all, and <img title=\"w_3\" src=\"http://www.codecogs.com/png.latex?w_3\" alt=\"\" align=\"bottom\" /> contains no agent making the observation <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" />. The other two world models, on the other hand, are consistent with <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" />. Thus, <img title=\"P(w_i\\mid o)=0\" src=\"http://www.codecogs.com/png.latex?P(w_i\\mid o)=0\" alt=\"\" align=\"bottom\" /> for <img title=\"i=1,2,3\" src=\"http://www.codecogs.com/png.latex?i=1,2,3\" alt=\"\" align=\"bottom\" /> and <img title=\"P(w_i\\mid o)=\\frac{1}{2}\" src=\"http://www.codecogs.com/png.latex?P(w_i\\mid o)=\\frac{1}{2}\" alt=\"\" align=\"bottom\" /> for <img title=\"i=4,5\" src=\"http://www.codecogs.com/png.latex?i=4,5\" alt=\"\" align=\"bottom\" />. Let's assume that the agent has only two actions <img title=\"A=\\{a_1,a_2\\}\" src=\"http://www.codecogs.com/png.latex?A=\\{a_1,a_2\\}\" alt=\"\" align=\"bottom\" /> and that in world model <img title=\"w_4\" src=\"http://www.codecogs.com/png.latex?w_4\" alt=\"\" align=\"bottom\" /> the only agent making observation <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" /> takes action <img title=\"a_1\" src=\"http://www.codecogs.com/png.latex?a_1\" alt=\"\" align=\"bottom\" /> and in <img title=\"w_5\" src=\"http://www.codecogs.com/png.latex?w_5\" alt=\"\" align=\"bottom\" /> the only agent making observation <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" /> takes action <img title=\"a_2\" src=\"http://www.codecogs.com/png.latex?a_2\" alt=\"\" align=\"bottom\" />, then <img title=\"P(w_4\\mid a_1)=1=P(w_5\\mid a_2)\" src=\"http://www.codecogs.com/png.latex?P(w_4\\mid a_1)=1=P(w_5\\mid a_2)\" alt=\"\" align=\"bottom\" /> and <img title=\"P(w_5\\mid a_1)=0=P(w_4\\mid a_2)\" src=\"http://www.codecogs.com/png.latex?P(w_5\\mid a_1)=0=P(w_4\\mid a_2)\" alt=\"\" align=\"bottom\" />. Thus, if, for example, <img title=\"U(w_5)&gt;U(w_4)\" src=\"http://www.codecogs.com/png.latex?U(w_5)&gt;U(w_4)\" alt=\"\" align=\"bottom\" />, an EDT agent would take action <img title=\"a_2\" src=\"http://www.codecogs.com/png.latex?a_2\" alt=\"\" align=\"bottom\" /> to ensure that world model <img title=\"w_5\" src=\"http://www.codecogs.com/png.latex?w_5\" alt=\"\" align=\"bottom\" /> is actual.</p>\n<h1>The main problem of naturalized induction</h1>\n<p>This example makes it sound as though it's clear what posterior probabilities we should assign. But in general, it's not that easy. For one, there is the issue of <a href=\"http://www.anthropic-principle.com/?q=book/table_of_contents\">anthropics</a>: if one world model <img title=\"w_1\" src=\"http://www.codecogs.com/png.latex?w_1\" alt=\"\" align=\"bottom\" /> contains more agents observing <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" /> than another world model <img title=\"w_2\" src=\"http://www.codecogs.com/png.latex?w_2\" alt=\"\" align=\"bottom\" />, does that mean <img title=\"P(w_1\\mid o) &gt; P(w_2\\mid o)\" src=\"http://www.codecogs.com/png.latex?P(w_1\\mid o) &gt; P(w_2\\mid o)\" alt=\"\" align=\"bottom\" />? Whether CDT and EDT can reason correctly about anthropics is an interesting question in itself (cf. <a href=\"http://www.anthropic-principle.com/?q=book/table_of_contents\">Bostrom 2002</a>;&nbsp;<a href=\"https://arxiv.org/abs/1110.6437\">Armstrong 2011</a>; <a href=\"https://users.cs.duke.edu/~conitzer/devastatingPHILSTUD.pdf\">Conitzer 2015</a>), but in this post I'll discuss a different problem in naturalized induction: identifying instantiations of the agent in a world model.</p>\n<p>It seems that the core of the reasoning in the above example was that some worlds contain an agent observing <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" /> and others don't. So, besides&nbsp;anthropics, the central problem of naturalized induction appears to be identifying agents making particular observations in a physicalist world model. While this can often be done uncontroversially &ndash; a world containing only rocks contains no agents &ndash;, it seems difficult to specify how it works in general. The core of the problem is a type mismatch of the \"mental stuff\" (e.g., numbers or Strings) <img title=\"o\" src=\"http://www.codecogs.com/png.latex?o\" alt=\"\" align=\"bottom\" /> and the \"physics stuff\" (atoms, etc.) of the world model. Rob Bensinger <a href=\"/lw/jd9/building_phenomenological_bridges/\">calls</a> this the problem of \"building phenomenological bridges\" (BPB) (also see his <a href=\"/lw/jlg/bridge_collapse_reductionism_as_engineering/\"><em>Bridge Collapse: Reductionism as Engineering Problem</em></a>).</p>\n<h1>Sensitivity to phenomenological bridges</h1>\n<p>Sometimes, the decisions made by CDT and EDT are very&nbsp;sensitive to whether a phenomenological bridge is built or not. Consider the following problem:</p>\n<p style=\"padding-left: 30px;\"><strong>One Button Per Agent.</strong>&nbsp;There are two similar agents with the same utility function. Each lives in her own room. Both rooms contain a button. If agent 1 pushes her button, it creates 1 utilon. If agent 2 pushes her button, it creates -50 utilons. You know that agent 1 is an instantiation of you. Should you press your button?</p>\n<p>Note that this is essentially Newcomb's problem with potential anthropic uncertainty (see the&nbsp;second paragraph <a href=\"https://casparoesterheld.com/2017/05/12/anthropic-uncertainty-in-the-evidential-blackmail/\">here</a>) &ndash; pressing the button is like two-boxing, which causally gives you $1k if you are the real agent but costs you $1M if you are the simulation. &nbsp;</p>\n<p>If agent 2 is sufficiently similar to you to count as an instantiation of you, then you shouldn't press the button. If, on the other hand, you believe that agent 2 does not qualify as something that might be you, then it comes down to what decision theory you use: CDT would press the button, whereas EDT wouldn't (assuming that the two agents are strongly correlated).</p>\n<p>It is easy to specify a problem where EDT, too, is sensitive to the phenomenological bridges it builds:</p>\n<p style=\"padding-left: 30px;\"><strong>One Button Per World.</strong> There are two possible worlds. Each contains an agent living in a room with a button. The two agents are similar and have the same utility function. The button in world 1 creates 1 utilon, the button in world 2 creates -50 utilons. You know that the agent in world 1 is an instantiation of you. Should you press the button?</p>\n<p>If you believe that the agent in world 2 is an instantiation of you, both EDT and CDT recommend you not to press the button. However, if you believe that the agent in world 2 is not an instantiation of you, then naturalized induction concludes that world 2 isn't actual and so pressing the button is safe.</p>\n<h1>Building phenomenological bridges is hard and perhaps confused</h1>\n<p>So, to solve the problem of naturalized induction and apply EDT/CDT-like decision theories, we need to solve BPB. The behavior of an agent is quite sensitive to how we solve it, so we better get it right.</p>\n<p>Unfortunately, I am skeptical that BPB can be solved. Most importantly, I suspect that statements about whether a particular physical process implements a particular algorithm <a href=\"http://reducing-suffering.org/interpret-physical-system-mind/#Computations_are_relative_to_interpretation\">can't</a> be objectively true or false. There seems to be no way of testing any such relations.</p>\n<p>Probably we should think more about whether BPB really is doomed. There even seems to be some philosophical literature that seems worth looking into (again, see <a href=\"http://reducing-suffering.org/interpret-physical-system-mind/#Computations_are_relative_to_interpretation\">this Brian Tomasik post</a>; cf. some of Hofstadter's writings and the literatures surrounding \"<a href=\"https://en.wikipedia.org/wiki/Knowledge_argument\">Mary the color scientist</a>\", <a href=\"https://plato.stanford.edu/archives/win2015/entries/computational-mind/\">the computational theory of mind</a>, <a href=\"http://web.cecs.pdx.edu/~mm/ca-review.pdf\">computation in cellular automata</a>, etc.). But at this point, BPB looks confusing/confused enough to look into alternatives.</p>\n<h2>Assigning probabilities pragmatically?</h2>\n<p>One might think that one could map between physical processes and algorithms on a pragmatic or functional basis. That is, one could say that a physical process A implements a program p to the extent that the results of A correlate with the output of p. I think this idea goes into the right direction and we will later see an implementation of this pragmatic approach that does away with naturalized induction. However, it feels inappropriate as a solution to BPB. The main problem is that two processes can correlate in their output without having similar subjective experiences. For instance, it is easy to show that <a href=\"https://en.wikipedia.org/wiki/Sorting_algorithm#Popular_sorting_algorithms\">Merge sort and Insertion sort</a>&nbsp;have the same output for any given input, even though they have very different \"subjective experiences\". (Another problem is that the dependence between two random variables cannot be expressed as a single number and so it is unclear how to translate the entire joint probability distribution of the two into a single number determining the likelihood of the algorithm being implemented by the physical process. That said, if implementing an algorithm is conceived of as binary &ndash; either true or false &ndash;, one could just require perfect correlation.)</p>\n<h1>Getting rid of the problem of building phenomenological bridges</h1>\n<p>If we adopt an EDT perspective, it seems clear what we have to do to avoid BPB. If we don't want to decide whether some world contains the agent, then it appears that we have to artificially ensure that the agent views itself as existing in all possible worlds. So, we may take every world model and add a causally separate or non-physical entity representing the agent. I'll call this additional agent a <em>logical zombie</em>&nbsp;(l-zombie) (a concept <a href=\"/lw/jkm/lzombies_lzombies/\">introduced</a> by Benja Fallenstein for a somewhat different decision-theoretical reason). To avoid all BPB, we will assume that the agent pretends that it is the l-zombie with certainty. I'll call this the l-zombie variant of EDT (LZEDT). It is probably the most natural evidentialist&nbsp;<a href=\"https://arbital.com/p/logical_dt/\">logical decision theory</a>.</p>\n<p>Note that in the context of LZEDT, l-zombies are a fiction used for pragmatic reasons. LZEDT doesn't make the metaphysical claim that l-zombies exist or that you are secretly an l-zombie. For discussions of related metaphysical claims, see, e.g., Brian Tomasik's essay&nbsp;<em><a href=\"http://reducing-suffering.org/why-does-physics-exist/\">Why Does Physics Exist?</a></em> and references therein.</p>\n<p>LZEDT reasons about the real world via the correlations between the l-zombie and the real world. In many cases, LZEDT will act as we expect an EDT agent to act. For example, in One Button Per Agent, it doesn't press the button because that ensures that neither agent pushes the button.</p>\n<p>LZEDT doesn't need any additional anthropics&nbsp;but behaves like <a href=\"https://www.fhi.ox.ac.uk/wp-content/uploads/Anthropic_Decision_Theory_Tech_Report.pdf\">anthropic decision theory</a>/EDT+SSA, which seems alright.</p>\n<p>Although LZEDT may assign a high probability to worlds that don't contain any actual agents, it doesn't optimize for these worlds because it cannot significantly influence them. So, in a way LZEDT adopts the pragmatic/functional approach (mentioned above) of, other things equal, giving more weight to worlds that contain a lot of closely correlated agents.</p>\n<p>LZEDT is automatically <a href=\"https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessnes/\">updateless</a>. For example, it gives the money in counterfactual mugging. However, it invariably implements a&nbsp;particularly&nbsp;strong version of updatelessness. It's not just updatelessness in the way that \"<a href=\"https://agentfoundations.org/item?id=1073\">son of</a> EDT\" (i.e., the decision theory that EDT would self-modify into) is updateless, it is also updateless w.r.t. its existence. So, for example, in the&nbsp;One Button Per World problem, it never pushes the button, because it thinks that the second world, in which pushing the button generates -50 utilons,&nbsp;could be actual. This is the case even if the second world very obviously contains no implementation of LZEDT. Similarly, it is unclear what LZEDT does in the <a href=\"/r/discussion/lw/oih/did_edt_get_it_right_all_along_introducing_yet/\">Coin Flip Creation problem</a>, which EDT seems to get right.</p>\n<p>So, LZEDT optimizes for world models that naturalized induction would assign zero probability to. It should be noted that this is not done on the basis of some exotic ethical claim according to which non-actual worlds deserve moral weight.</p>\n<p>I'm not yet sure what to make of LZEDT. It is elegant in that it effortlessly gets anthropics right, avoids BPB and is updateless without having to self-modify. On the other hand, not updating on your existence is often counterintuitive and even regular updateless is, <a href=\"https://casparoesterheld.com/2016/11/21/thoughts-on-updatelessnes/\">in my opinion</a>, best justified via precommitment. Its approach to avoiding BPB isn't immune to criticism either. In a way, it is just a very wrong approach to BPB (mapping your algorithm into fictions rather than your real instantiations). Perhaps it would be more reasonable to use regular EDT with an approach to BPB that interprets anything as you that could potentially be you?</p>\n<p>Of course, LZEDT also inherits some of the potential problems of EDT, in particular, the <a href=\"https://wiki.lesswrong.com/wiki/5-and-10\">5-and-10 problem</a>.</p>\n<h2>CDT is more dependant on building phenomenological bridges</h2>\n<p>It seems much harder to get rid of the BPB problem in CDT. Obviously, the l-zombie approach doesn't work for CDT: because none of the l-zombies has a physical influence on the world, \"LZCDT\" would always be indifferent between all possible actions. More generally, because CDT exerts no control via correlation, it needs to believe that it might be X if it wants to control X's actions. So, causal decision theory only works with BPB.</p>\n<p>That said, a causalist approach to avoiding BPB via l-zombies could be to tamper with the definition of causality such that the l-zombie \"logically causes\" the choices made by instantiations in the physical world. As far as I understand it, most people at MIRI currently prefer this flavor of logical decision theory.</p>\n<h1>Acknowledgements</h1>\n<p>Most of my views on this topic formed in discussions with Johannes Treutlein. I also benefited from discussions at <a href=\"http://www.rationality.org/workshops/apply-aisfp2017\">AISFP</a>.</p>",
    "user": {
      "username": "Caspar42",
      "slug": "caspar-oesterheld",
      "displayName": "Caspar Oesterheld"
    }
  },
  {
    "_id": "hb8mLTfNYirmEpWzQ",
    "title": "LW 2.0 Site Update: 09/21/17",
    "slug": "lw-2-0-site-update-09-21-17",
    "pageUrl": "https://www.lesswrong.com/posts/hb8mLTfNYirmEpWzQ/lw-2-0-site-update-09-21-17",
    "postedAt": "2017-09-22T07:43:31.740Z",
    "baseScore": 12,
    "voteCount": 8,
    "commentCount": 0,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Hey! A few quick updates on edits done today (well, yesterday - we have late work hours).</p><p></p><p>Thanks Chris_Leong for making a <a href=\"/posts/vtZsEerABCjhtgizX/beta-first-impressions\">post</a> to document folks&#x27; bugs. In the comments ozymandias requested that the page containing every post published to the site organised by day, be more findable. That&#x27;s now located in the menu (top left-hand corner).</p><p></p><p>Also in the comments philh wrote a comment of many requests; today we fixed a few of them.</p><p></p><ul><li><p>You no longer need to include &#x27;http://&#x27; at the start of your blog URL</p></li></ul><ul><li><p>You can now see a user&#x27;s comments in their user page</p></li><li><p>You can now see your own comments in your user page</p></li></ul><p></p><p>Other things we did:</p><p></p><ul><li><p>There is a now page with all comments sorted by recency, findable on the frontpage just under the &#x27;recent comments&#x27; section header</p></li><li><p>Fixed a bug where some users were unable to post to Meta</p></li><li><p>When you login, you no longer get redirected to the front page</p></li><li><p>Fixed formatting of RSS posts (more RSS changes coming soon)</p></li><li><p>If you click through to a recent comment, it also has a button to take you to its position in the comment thread.</p></li><li><p>Added various error messages for login and post editing and other things.</p></li></ul><p>And answered an infinite number of support requests (where infinity = 56).</p></div></div></div></div>",
    "user": {
      "username": "Benito",
      "slug": "benito",
      "displayName": "Ben Pace"
    }
  },
  {
    "_id": "8D9nZhw8G9vxsn7AB",
    "title": "LW 2.0 Site Update: 09/21/17",
    "slug": "lw-2-0-site-update-09-21-17-0",
    "pageUrl": "https://www.lesswrong.com/posts/8D9nZhw8G9vxsn7AB/lw-2-0-site-update-09-21-17-0",
    "postedAt": "2017-09-22T07:42:09.542Z",
    "baseScore": 5,
    "voteCount": 3,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Hey! A few quick updates on edits done today (well, yesterday - we have late work hours).</p><p>Thanks Chris_Leong for making a <a href=\"/posts/vtZsEerABCjhtgizX/beta-first-impressions\">post</a> to document folks&#x27; bugs. In the comments ozymandias requested that the page containing every post published to the site organised by day, be more findable. That&#x27;s now located in the menu (top left-hand corner).</p><p>Also in the comments philh wrote a comment of many requests; today we fixed a few of them.</p><ul><li><p>You no longer need to include &#x27;http://&#x27; at the start of your blog URL</p></li><li><p>You can now see a user&#x27;s comments in their user page </p></li><li><p>You can now see your own comments in your user page</p></li></ul><p>Other things we did:</p><ul><li><p>There is a page with all comments sorted by recency, findable on the frontpage just under the &#x27;recent comments&#x27; section header</p></li><li><p>Fixed a bug where some users were unable to post to Meta</p></li><li><p>When you login, you no longer get redirected to the front page</p></li><li><p>Fixed formatting of RSS posts (more RSS changes coming soon)</p></li><li><p>If you click through to a recent comment, it also has a button to take you to its position in the comment thread.</p></li><li><p>Added various error messages for login and post editing and other things.</p></li></ul><p>And answered an infinite number of intercom support requests (where infinity = 56).</p><p></p></div></div></div></div>",
    "user": {
      "username": "Benito",
      "slug": "benito",
      "displayName": "Ben Pace"
    }
  },
  {
    "_id": "iuNSrBoX2W5qHCAAo",
    "title": "Notes From an Apocalypse",
    "slug": "notes-from-an-apocalypse",
    "pageUrl": "https://www.lesswrong.com/posts/iuNSrBoX2W5qHCAAo/notes-from-an-apocalypse",
    "postedAt": "2017-09-22T05:10:21.792Z",
    "baseScore": 59,
    "voteCount": 41,
    "commentCount": 24,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>(This is a loose adaptation of a talk I sometimes give on the Cambrian Explosion, smoothed a bit for popular consumption.  That talk, in turn, draws heavily from a 2006 paper by Charles Marshall, titled “Explaining the Cambrian ‘Explosion’ of Animals”.  It can be read in full <a href=\"http://www.annualreviews.org/doi/abs/10.1146/annurev.earth.33.031504.103001\">here</a>.  I’m mostly just trying to test out the new site with an essay I had lying around, be moderately entertaining, and maybe try to suggest this event as a topic of interest for those who care about intelligence explosions and cognitive emergence.  If I succeed in all three, then I encourage you to start with Marshall for the more technical, thorough, and correct analysis.)\r\r</p><p><strong>A.\r\r</strong></p><p>The Cambrian Explosion is our name for an event that took place about 540 million years ago, one that accounts for the sudden appearance of advanced animal life.  Emphasis on “sudden”; it’s like somebody flipped a light switch.  What follows is just a story (fragments of a story, really), but it’s a pretty good one, and I don’t think it’ll lead you too far astray.\r</p><p>Let’s start 540 million years ago.  The planet is still recovering from a series of catastrophic “snowball Earth” phases, ice ages so severe that the oceans had frozen right across the equator; the tropical glaciers wound their way through loose sediment to leave an enduring footprint.  Now that the last of these has thawed, it’s finally starting to warm up in a more permanent way and get a little more hospitable.  There are two major continents at the moment, but one of them is starting to break up into smaller and smaller chunks.  As with our rising temperatures, this helps create a more habitable planet, since it gets you more high-nutrient coastlines per unit land area.  Importantly, the last hundred million years have provided us with oxygen concentrations in the atmosphere at basically 21st-century levels.  To the unprepared organisms that dominate the first half of Earth’s history, oxygen can act as a hazardous toxin, but if you harness it correctly you can really kick your metabolism into a higher gear.  A good time to be alive, really.\r\r</p><p>The land is mostly barren.  A little bit of pond scum holding on in shallow pools and other moist areas, maybe, but seeds and placentas won’t exist for a long age yet, and so far every reproductive system requires the presence of standing water.  The ocean, though, the ocean is a different story, full of life and living.  If you go by the rock record, the most common form of life is the stromatolite, a colony of green plant-microbes that secrete stone in distinctive whorling patterns. (As always, history most remembers those who write history).  They flourish in shallow and sunlight-touched waters, gradually constructing ranges of gently rolling hills that are each sometimes meters across.  Larger (but still microscopic) Eukaryotes wander through these hills like grazing deer.  Or maybe like wolves. Unlike the helpful stromatolites themselves, most of these creatures rarely leave informative fossils, so it’s hard to say how complicated the ecosystem actually is.  Certainly it’s a rich and dynamic biological scene, but to my mind it always feels just a little bit like Hobbiton.  Gentle with a hidden strength, simple enough and flexible enough to endure.  The official name for this time period is the Proterozoic, but when geologists think nobody is listening, we sometimes call it the Boring Billion.\r\r</p><p>But here in the closing years of that era, as temperatures thaw and the coastlines unwind and the atmosphere fills with oxygen, it’s starting to get a bit more interesting.  Big.  Some of the Eukaryotes are behaving oddly, bunching up into colonies that are a bit better at finding nutrients or sunlight.  Often, they give up roaming and gather together in big fronds, anchoring themselves to the seafloor and spreading the sail out broadside to catch as much nutrient-rich ocean water as possible as it flows by.  Sporifera, the sponges, use a different strategy, pulsing flagella inwards to create little artificial currents that channel nutrients towards themselves.  Cnidaria, the jellyfish, actually lift off from the ocean floor altogether and drift through the water looking for scraps among the drifting plankton.  The cells in these colonies are starting to take on specialized roles, this one binding the group to the soil, that one a tentacle, but their overall simplicity falls well short of what we usually mean by words like ‘animal.’\r\r</p><p>Despite these omens, it’s all rather sedate.  Not much seems to change day to day, millenium to millenium.  You’d be forgiven for checking your watch a few times every epoch.  You might even take a nap, stay in bed for a few million years and relax.  Maybe twenty million if you hit the snooze button.  But when you wake up, you’ll be in for a shock.\r\r</p><p><strong>B.\r\r</strong></p><p>Somebody <em>broke it</em>.  They scourged the Shire.  In just a few million years, no more than a wink of geological time, everything has changed.  Many of those ever-green stromatolite hills have been stripped bare, and the ones that remain are going fast.  Giant monsters prowl through the wreckage, hunting for anything made out of complex organics, hunting each other.  There is a bewildering array of new lifeforms.  Some of them are covered in spikes, others with odd numbers of eyes and strange probing tentacle-mouths.  All of them have elaborate organ systems, strange tissue masses that express themselves in radically different, interlocking ways, despite having the same genome.  The rise in diversity, and in disparity, is unequaled by any other moment in Earth’s history.  Something like <em>half </em>of all 21st century animal phyla trace their origins back to that brief moment of generation.  Take all the creative power of the last five hundred million years of animal evolution, compress it down to a fraction of a geological instant- that’s the power of the Cambrian Explosion.  In less than twenty million years, there are molluscs squirming like modern sea urchins, echinoderms clinging to rocks like modern starfish.  Even the trilobite, that ancient symbol of ancient life, suddenly appears here fully-formed. And then, swimming through the open waters, you’d see the most surprising thing of all: one of them has a brain.  Animalia Bilateria Chordata, the chordate.\r\r</p><p>This is it, you see.  The moment of encephalization, the moment that the cosmos wakes up.  \r\r</p><p>There was the Earth, a giant rock drifting quietly through space.  And one day it just spontaneously grows a brain, for no damn reason at all.  What kind of rock does that, exactly? What kind of universe?\r</p><p><strong>C.\r\r</strong></p><p>No, really, why did this happen?  What was the mechanism, the bridge that takes us from the boring billion to the era of minds and monsters?\r\r</p><p>I don’t know.\r\r</p><p>Really, I don’t.  There are hypotheses, sure.  A few scraps of almost-understanding.  And plenty of guesses, some of them really good.  But the stone can only tell us so much, and it was such a very long time ago.  The all-important middle of our story, the one that gives us the first moments of emerging biological consciousness, has not yet been recovered.\r\r</p><p><em>Can </em>it be recovered, even in principle?  Harder question.\r</p><p>Darwin, poor Charles Darwin, floundered on these shoals with the rest of us.  For him, the only explanation was that we must be missing some huge fraction of the rock, so that it only seems like they all show up at once:\r\r</p><blockquote><p>I cannot doubt that all the Silurian trilobites have descended from some one crustacean, which must have lived long before the Silurian age....Consequently, if my theory be true, it is indisputable that before the lowest Silurian strata was deposited, long periods elapsed, as long as, or probably longer than, the whole interval from the Silurian to the present day.....The case must at present remain inexplicable; and may be truely urged as a valid argument against the views here entertained.</p></blockquote><p>He was wrong.  Isotopic dating methods have since confirmed that there is no gap in the rock between the Proterozoic and the Cambrian, no space of hundreds of millions of years for us to move gradually from one extreme to the other.  (In this case, we’re also early enough in the history of geology that precise chronology was still ambiguous- that’s why Charles refers here to the Silurian, a later era.)\r\r</p><p>And so, as the man says, the Cambrian Explosion may be truly urged as a valid argument against the views which Mr. Darwin entertained.  What’s at stake here is not just the question of how this process of encephalization first occurred, but also why our most foundational biological theories fail so spectacularly to anticipate it.  Are we even asking the right questions?\r\r</p><p><strong>D.\r</strong>\r</p><p>There’s a slightly more modern version of Darwin’s first tentative attempts at a patch, one that might explain why so many fossils would be missing from the pre-Cambrian record.  If it’s true, there never was a Cambrian Explosion, the paragraphs above don’t correspond to the world as it was, and the Earth’s encephalization took place very gradually, over eons.  A relief in some ways (our theory of evolution remains sound), but a tragedy in others (since we’d probably never be able to peer at what might be the most important moment in the history of life).\r\r</p><p>Here’s a different story:\r\r</p><p>By the end of the Proterozoic, there has been a thriving multicellular ecosystem for hundreds of millions of years, full of complex animals in a thriving dance of grazing and predation, reproduction and survival, gradually expanding and exploring the space of possible forms.  But these organisms are all soft-bodied, with no bones or shells or rigid frameworks of any kind.  When they die, their bodies rot immediately, leaving no trace for paleontologists to find.  But remember when I mentioned that one of the continents is breaking up?  All this new coastline, and new weathering, bring new minerals into the oceans.  Suddenly, the system is flooded with dissolved calcium salts, ready and able to be incorporated into bones and other biological machinery.  Naturally, a number of different well-established species take advantage of this.  Skeletons, spines, and shells become very popular.  And when they die, they’re preserved, some for a long enough for a poor foolish scientist to stumble across.  And from our perspective, there’s a bright line with animals on only one side of it.\r\r</p><p>This is a possibility that we should take very seriously.  A good chunk of the scientific community certainly does.\r\r</p><p>One of the things that swayed these scientists is a method of using ‘molecular clocks’ to learn from living genetic sequences as if they were a sort of fossil.  The trick is this: look for genetic sequences of a very specific sort, those that change randomly, protected from the directionality of evolutionary selection pressures, and which have been doing so at a slow and steady rate for hundreds of millions of years.  (In practice, certain structural elements of hemoglobin work well.)  Sequence this area in two very different animal species for which we have already discovered the age of their last common ancestor- and by measuring the difference, we can precisely calibrate the rate of change.\r\r</p><p>Then, all you have to do is apply this same procedure to, say, a mollusc and a chordate.  If the Cambrian Explosion happened like we say it happened, you should get about 500 million years of genetic drift.\r\r</p><p>Actual answer?  800 million.  This gives us a full 300 million years to go from primitive sponges to trilobites, an eminently reasonable wait.  \r\r</p><p>Still, I feel a little squidgy about this line of reasoning.  Molecular clocks are a dangerously fragile tool, for one.  And remember also that the 800 million year figure would have complex animals surviving the snowball Earth periods, where a frozen surface layer prevented gas exchange between the oceans and atmosphere; those oceans were anoxic, lacking any oxygen for the animals to breathe.  But my main objection is actually a bit simpler: no ichnofossils.\r\r</p><p>An ichnofossil, or ‘trace fossil’ is just any biological remnant that doesn’t involve the actual biological thing itself.  Footprints, burrows, etcetera.  They’re kind of a pain to find- trace fossil hunting famously takes place at dawn so that the shadows throw your field area into sharper relief- but preserve a lot of valuable information that actual bones do not.  Consider the famous archaeopteryx fossil that preserved, not just the skeleton of a dinosaur like so many others, but also the clear imprint of its feathers.  That is the weight of an ichnofossil.\r\r</p><p>As you might imagine, we’ve really scoured the strata around the Cambrian transition as best we can.  For the simpler organisms, we do find a number of trace fossils.  That’s why I can tell you about the sponges and jellyfish; we have the impressions they left in the ground as they died.  We even have enough detail to learn astonishing things like: “Modern jellyfish are quadrilaterally symmetrical, a circle with for identical quadrants.   But when they first emerged, at least some jellyfish were trilaterally symmetrical, a circle with three identical parts, instead.”\r\r</p><p>But aside from the jellyfish and those weird asymmetrical fronds, we genuinely don’t see much.  No burrows, no tracks, no trilobyte-shaped impressions in soft mud.  So if there was this huge dynamic ecosystem, why didn’t it leave any footprints, even though conditions were favorable enough for such things that we can find the final resting place of a 600 million year old jellyfish?  The most provocative traces we find are narrow (millimeter) horizontal trails or burrows, just 2-3 million years before the Cambrian.  That’s the only prelude we’ve found so far, and it’s a brief one.\r\r</p><p>I don’t think this is strong enough to break the missing-calcium theory outright; if nothing else, it’s an argument from absence.  But I do think it’s a pretty important nail in the coffin, and a reason for skepticism.  And so- we still have at least a pretty good reason to think that the Cambrian Explosion is a real thing, and that our search for the middle part of that story is not foolish.\r\r</p><p>I can think of a few places to look.\r\r</p><p><strong>E.\r</strong>\r</p><p>Perhaps the answer we’re looking for is, ‘oxygen’.  As we observed earlier, this is a period in Earth’s history in which oxygen had increased to near-modern levels somewhat recently.\r\r</p><p>Oxygen isn’t quite an absolute prerequisite for complex food webs, but it’s pretty close.  Animal metabolism derives energy from a flow of electrons as they move from one molecule to another, almost but not entirely unlike a water wheel powered by a flowing river.  The faster that water flows, the more energetic a machine you can power.  To do that, you need a source of electrons, preferably in some dense high-energy package like sugar.  But you also need to provide a grounding, a place for them to go, something that pulls in electrons as hard as possible.  That is, our power system also needs an electron sink.  Oxygen does this job remarkably well- thus, as animals, we survive by eating and breathing.\r\r</p><p>Without oxygen, you need to rely on a less energetic sink.  There are species of iron that work alright, and there are some weird hacks available with hydrogen, but the machines that you can make with these power sources are only so impressive.  If all you have is iron as an electron sink, you can probably manage grazing pretty well, and you can buy some wiggle room as long as you’re microscopic.  But something high-energy like multicellular predation is a big ask.  At least today, whenever we see low-oxygen environments in the deep ocean and so on, we always see a corresponding reduction in food web complexity and species diversity.\r\r</p><p>So could a quantitative increase in oxygen levels have produced a qualitative change in the structure of animal life?  Possibly.  But there was a significant lag between the rise of oxygen and the rise of animal complexity, almost a hundred million years.  It begs the question, why not sooner?  Oxygen probably had <em>something </em>to do with this, but it seems more like a prerequisite than a cause- and we have yet to account for the morphological changes.  Why not just use the energy to make bigger fronds?  Fronds for miles, fronds to span mountains, fronds beyond the wildest dreams of frondkind!\r\r</p><p><strong>F.\r</strong>\r</p><p>Think back to those horizontal burrows that show up in the very last days of the Proterozoic.  There are a couple ways that this is really, really exciting.  First, it implies that sensation probably was starting to get concentrated on one end of the animal, or at least one side- taste, smell, even vision clustered around a single area.  That feels suspiciously like we’re starting to get nerve clusters that you can almost call a brain.\r\r</p><p>But also, significantly for our purposes, this means that animals might be starting to develop sophisticated hox genes.\r\r</p><p>The hox genes are, more or less, the standard library for the structural assembly of animal bodies.  It’s a DNA-modifying type of gene, one that activates specific other regions of DNA during early development.  Need a leg?  Activate the ‘leg’ hox gene, and that will start a huge cascade of related processes that make a torso segment that contains a couple legs plus all the necessary hip-joints and such in a somewhat standardized way.**  This makes it easier than you’d think to adapt animal body plans on the fly; rather than reinventing legs from the ground up every time you want to adapt from quadruped to hexaped, you can just have a mutation that calls the hox gene two more times.  It is also a primary mechanism of directionality, in which animal bodies have a clear orientation with a front and back.\r\r</p><p>As you might imagine, animals almost never survive a mutation to the hox genes proper, let alone thrive and speciate.  It tends to mean that you get born without a head or something.  So, both humans and house flies tend to have a very similar set.  That holds true across the entire animal kingdom, with only a few exceptions- hox genes are frozen in time, proportionate with their importance.  Care to guess which types of animal lack fully formed hox genes?\r\r</p><p>That’s right: sponges and jellyfish.  Even those have a rough proto-hox thing going on, but it’s a far cry short of ours.\r\r</p><p>It goes without saying that this will have implications for species diversity in the animal kingdom.  Adaptation isn’t as easy as building an animal out of legos, but it has at least gotten a lot easier.  Animals can experiment with body shapes in more radical ways, and be successful more often when they do so- they’re now exploring a much larger space of possibilities.\r\r</p><p>We’re starting to piece together a rough framework here, in which the rise of oxygen and the slow development of meta-genomic advantages work together to provide space for a more dynamic ecosystem, but is that enough to make sense of something as dramatic and surprising as the Cambrain Explosion?  It’s a start!  But let’s see if I can’t make it a little more complicated.\r\r</p><p>**I am lying harder than usual right now.  This is complicated and I am not a geneticist.  Please never believe me about anything.\r\r</p><p><strong>G.\r</strong>\r</p><p>We’ve got the oxygen levels needed for large-scale predation and multilayered food webs, and we’ve got the genetic toolkit to move quickly through different animal shapes as evolutionary pressures come down on us, sure.  But again, why so <em>many</em>, and why all at once?  What splintered the animal kingdom so thoroughly, and spread the shards of it so widely?  Before the Explosion, we apparently had two or three general body plans, each with an accompanying niche.  Afterwards- everything else.\r\r</p><p>Personally, my favorite answer to that question is, ‘eyeballs’.\r\r</p><p>Maybe also noses and ears, I guess.  But those are a little less directional, and we’re pretty sure that eyes did in fact develop around this time.  \r\r</p><p>Either way, what I really mean is, ‘long distance detection of nutrients’.  This synchronizes nicely with the directional motion that shows up around this time, the ‘front and back’ and ‘top and bottom’ innovations that allow an animal to see food and then move towards it.\r\r</p><p>What I <em>really </em>really mean is, ‘predation.’\r\r</p><p>On the one hand, this makes it a lot more viable to be one step up in the food web.  A blind predator is going to have some trouble; the ability to see and pursue opens up a new niche.  But only the <em>one </em>new niche, so that alone still doesn’t explain the riotous diversity we new encounter.\r\r</p><p>Consider the criteria you must satisfy to be a successful precambrian animal.  You’re going to need to absorb as many complex carbon molecules as possible.  You’re going to have to solve the reproduction problem somehow.  And you’re going to have to be structurally sound, rather than collapsing under your own weight or something.  It’s fairly simple, mostly revolving around being able to access as much seawater as possible so you can filter organics out of it.\r\r</p><p>And in fact, the three major solutions we see in the fossil record are, “have a large broadside and catch water as it moves by”, “actively pump water towards yourself”, and “move quickly through the water.”  When you think about it, that’s a fairly exhaustive list.  Every one of these forms is clearly exploring ways to have physical contact with as much seawater as possible, and almost nothing else.  And there are only so many ways to be the best at that job.\r\r</p><p>But now let’s add another criterion: “Don’t get eaten.”\r\r</p><p>It’s not just that this is a fairly flexible and ambiguous constraint.  It’s that we’ve lost our chance to monomaniacally focus on the one strategy of ‘contact lots of water’.  And when you have to balance different needs that are in competition, there are a few different trends that tend to emerge from that process.  First, none of your strategies will be quite as successful as they were when you didn’t have to make any tradeoffs.  And second, there will tend to be a number of different ways to balance those needs, each of which is roughly as effective as the others.\r\r</p><p>This is a really important but kind of abstract point, so I’m gonna hammer at it for a little bit.  <em>As the number of constraints increases, the number of different ‘best’ solutions will tend to increase combinatorically.</em>  If you’re a proto-sponge, and you’re suddenly under all this pressure from being hunted, you might try covering yourself in spikes, or borrowing into the mud, or growing in nasty inhospitable places where predators don’t want to go, or just picking up a certain amount of mobility.  But remember, you still have to worry about filter-feeding yourself.  And the proto-jellyfish has a similar number of different options, and the weird frond-looking things too.  The net result is that we end up with a really huge number of equally viable body plans, rather than the two or three that are the winners of a simpler problem.\r\r</p><p>Basically, the idea here is that predation was such a radical change to the environment that it fractured a small number of deep ecological niches in to a large number of somewhat shallower niches.  The radical speciation of the Cambrian Explosion is simply the natural result of those niches being explored and filled.\r\r</p><p><strong>H.\r</strong>\r</p><p>And somehow, from that crucible, the brain.\r\r</p><p>We aren’t there yet.  We know that long-distance senses like vision probably would have given rise to directional motion and directional anatomy, and that the combined needs of directional motion and of sensation managed to concentrate nerves in one particular region of the animal.  Maybe we can find out more with detailed genetic analyses, or maybe we’ll hit the motherload with some hugely important fossil discovery.  Hard to say, but I doubt we’re done yet.\r\r</p><p>Analogies are always perilous, and I will personally get very annoyed at anyone who tries to make a political metaphor out of this or something.  But in more general terms,  it’s worth taking a step back and thinking about what the Cambrain Explosion says about our universe.  The run up to this apocalypse seem to have included at least a few generalizable events:\r\r</p><p>The first is a deep well of underexploited potential energy.  Oxygen, in our case, meant that the ratio between the possible and the actual was somewhat larger than usual.  Finding a metabolic pathway to exploit oxygen was difficult, but once the blueprint existed, the machinery itself wasn’t particularly difficult.\r\r</p><p>The second is that new layers of useful abstraction emerged, which allowed innovation and conceptual mobility on larger scales than had previously existed.  We accelerated faster through our search space.\r\r</p><p>These do not themselves lead directly to an abundance of new forms.  Rather, the fits and starts of the early successes present new challenges to existing institutions.  Those organizations that successfully adapt to the new environment are still constrained by the additional complexity, and windows open for entirely novel forms.\r\r</p><p>And that’s about as much of a metaphor as I’m willing to make.  Still, it probably influences a lot of the way I think about, e.g., Silicon Valley.  And it’s probably important to remember that any Singularity would be the <em>second </em>intelligence explosion that the Earth has gone through.\r\r</p><p>The stromatolites are still around, by the way.  They never conquered the world again, but they still build their little hills in hypersaline and hyperthermal waters, places where animal life can’t survive.  There’s a nice cluster of them in the Bahamas, which makes for some nice field expeditions for geobiologists.  It’s not a bad retirement.\r</p><p></p></div></div></div></div>",
    "user": {
      "username": "Toggle",
      "slug": "toggle",
      "displayName": "Toggle"
    }
  },
  {
    "_id": "YngWJbFLYbhpTpPD9",
    "title": "Strategic Goal Pursuit and Daily Schedules",
    "slug": "strategic-goal-pursuit-and-daily-schedules",
    "pageUrl": "https://www.lesswrong.com/posts/YngWJbFLYbhpTpPD9/strategic-goal-pursuit-and-daily-schedules",
    "postedAt": "2017-09-22T04:23:23.590Z",
    "baseScore": 7,
    "voteCount": 9,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>In the post <a href=\"http://lesswrong.com/lw/2p5/humans_are_not_automatically_strategic/\">Humans Are Not Automatically Strategic</a>, Anna Salamon writes:\r</p><blockquote><p>there are clearly also heuristics that would be useful to goal-achievement (or that would be part of what it means to “have goals” at all) that we do not automatically carry out.  We do not automatically:\r</p><p>(a) Ask ourselves what we’re trying to achieve; \r</p><p>(b) Ask ourselves how we could tell if we achieved it (“what does it look like to be a good comedian?”) and how we can track progress; \r</p><p>(c) Find ourselves strongly, intrinsically curious about information that would help us achieve our goal; \r</p><p>(d) Gather that information (e.g., by asking as how folks commonly achieve our goal, or similar goals, or by tallying which strategies have and haven’t worked for us in the past); \r</p><p>(e) Systematically test many different conjectures for how to achieve the goals, including methods that aren’t habitual for us, while tracking which ones do and don’t work; \r</p><p>(f) Focus most of the energy that *isn’t* going into systematic exploration, on the methods that work best;\r</p><p>(g) Make sure that our &quot;goal&quot; is really our goal, that we coherently want it and are not constrained by fears or by uncertainty as to whether it is worth the effort, and that we have thought through any questions and decisions in advance so they won&#x27;t continually sap our energies;\r</p><p>(h) Use environmental cues and social contexts to bolster our motivation, so we can keep working effectively in the face of intermittent frustrations, or temptations based in hyperbolic discounting;\r</p></blockquote><p>When I read this, I was feeling quite unsatisfied about the way I pursued my goals. So the obvious thing to try, it seemed to me, was to ask myself how I could actually do all these things. I started by writing down all the major goals I have I could think of (a). Then I attempted to determine whether each goal was consistent with my other beliefs, whether I was sure it was something I really wanted, and was worth the effort(g). \r</p><p>For example, I saw that my desire to be a novelist was more motivated by the idea of how cool it would feel to be able to have that be part of my self-image, rather than a desire to actually write a novel. Maybe I’ll try to write a novel again one day, but if that becomes a goal sometime in the future it will be because there is something I really want to write about, not because I would like to be a writer. \r</p><p>Once I narrowed my goals down to aspirations that seemed actually worthwhile I attempted to devise useful tracking strategies for each goal (b). Some were pretty concrete (did I exercise for at least four hours this week) and others less so (how happy do I generally feel on a scale of 1-10 as recorded over time), but even if the latter method is prone to somewhat biased responses, it seems better than nothing. \r</p><p>The next step was outlining what concrete actions I could begin immediately taking to work towards achieving my goals, including researching how to get better at working on those goals (d,e,f). I made sure to refer to these points when thinking about actions I could take, it helped significantly. \r</p><p>As for (c), if you focus on how learning certain information will help you achieve something you really want to achieve and you still are not curious about it, well, that’s a bit odd to me, although I can imagine how that might occur. But that is something of a different topic than I want to focus on.\r</p><p>Now we come to (h), which is the real issue of the whole system, at least for me. Or perhaps it would be clearer to say that general motivation and organization was the biggest problem I had when I first tried to implement these heuristics. I planned out my goals, but trying to work on them by sheer force of will did not last for very long. I would inevitably convince myself that I was too tired, I would forget certain goals fairly often (probably conveniently the tasks that seemed the hardest or least immediately pleasant), and ultimately I mostly gave up, making a token effort now and again.\r</p><p>I found that state of affairs unsatisfactory, and I decided what felt like a willpower problem might actually be a situational framing problem. In order to change the way I interacted with the work that would let me achieve my goals, I began fully scheduling out the actions I would take to get better at my goals each day.\r</p><p>In the evening, I look over my list of goals and I plan my day by asking myself, “How can I work on everything on this list tomorrow? Even if it’s only for five minutes, how do I plan my day so that I get better at everything I want to get better at?” Thanks to the fact that I have written out concrete actions I can take to get better at my goals, this is actually quite easy. \r</p><p>These schedules improve my ability to consistently work on my goals for a couple reasons, I think. When I have planned that I am going to do some sort of work at a specific time I cannot easily rationalize procrastination. My normal excuses of “I’ll just do it in a bit” or “I’m feeling too tired right now” get thrown out. There is an override of “Nope, you’re doing it now, it says right here, see?” With a little practice, following the schedule becomes habit, and it’s shocking how much willpower you have for actually doing things once you don’t need to exert so much just to get yourself to start. I think the psychology it applies is similar to that used by Action Triggers, as described by Dr. Peter Gollwitzer. \r</p><p>The principle of Action Triggers is that you do something in advance to remind yourself of something you want to do later. For example, you lay out your running clothes to prompt yourself to go for that jog later. Or you plan to write your essay immediately after a specific tangible event occurs (e.g. right after dinner). A daily schedule works as constant action triggers, as you are continually asking the question “what am I supposed to do now?” and the schedule answers. \r</p><p>Having a goal list and daily schedule has increased my productivity and organization an astonishing amount, but there have been some significant hiccups. When I first began making daily schedules I used them to basically eschew what I saw as useless leisure time, and planned my day in a very strict fashion. The whole point is not to waste any time, right? The first problem this created may be obvious to those who better appreciate the importance of rest than I did at the time. I stopped using the schedules after a month and a half because it eventually became too tiring and oppressive. In addition, the strictness of my scheduling left little room for spontaneity and I would allow myself to become stressed when something would come up that I would have to attend to.  Planned actions or events also often took longer than scheduled and that would throw the whole rest of the day’s plan off, which felt like failure because I was unable to get everything I planned done.\r</p><p>Thinking back to that time several months later, when I was again dissatisfied with how well I was able to work towards my goals and motivate myself, I wished for the motivation and productivity the schedules provided, but to avoid the stress that had come with them. It was only at this point that I started to deconstruct what had gone wrong with my initial attempt and think about how I could fix it. \r</p><p>The first major problem was that I had overworked myself, and I realized I would have to include blocks of unplanned leisure time if daily schedules were going to actually work for me. The next and possibly even more important problem was how stressed the schedules had made me. I had to enforce to myself that it is okay if something comes up that causes my day not to go as planned. Failing to do something as scheduled is not a disaster, or even an actual failure if there is good reason to alter my plans. Another technique that helped was scheduling as much unplanned leisure time as possible at the end of my day. This has the dual benefit of allowing me to reschedule really important tasks into that time if they get bumped by unexpected events and generally gives me something to look forward to at the end of the day. The third problem I noticed was that the constant schedule starts to feel oppressive after a while. To resolve this, about every two weeks I spend one day, in which I have no major obligations, without any schedule. I use the day for self-reflection, examining how I’m progressing on my goals, if there are new actions I can think of to add, or modifications I can make to my system of scheduling or goal tracking. Besides that period of reflection, I spend the day resting and relaxing. I find this exercise helps a lot in refreshing myself and making the schedule feel more like a tool and less like an oppressor.\r</p><p>So, essentially, figuring out how to actually follow the goal-pursuing advice Anna gave in Humans Are Not Automatically Strategic, has been very effective thus far for me in terms of improving the way I pursue my goals. I know where I am trying to go, and I know I am taking concrete steps every day to try and get there. I would highly recommend attempting to use Anna’s heuristics of goal achievement and I would also recommend using daily schedules as a motivational/organizational technique, although my advice on schedules is largely based on my anecdotal experiences.\r</p><p>I am curious if anyone else has attempted to use Anna’s goal-pursuing heuristics or daily schedules and what your experiences have been.\r</p><p></p></div></div></div></div>",
    "user": {
      "username": "Rossin",
      "slug": "rossin",
      "displayName": "Rossin"
    }
  },
  {
    "_id": "5bd75cc58225bf06703754d8",
    "title": "Metamathematics and probability",
    "slug": "metamathematics-and-probability",
    "pageUrl": "https://www.lesswrong.com/posts/5bd75cc58225bf06703754d8/metamathematics-and-probability",
    "postedAt": "2017-09-22T04:04:55.000Z",
    "baseScore": 1,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "http://alexmennen.com/index.php/2017/09/22/metamathematics-and-probability/",
    "htmlBody": "<html><head></head><body></body></html>",
    "user": {
      "username": "AlexMennen",
      "slug": "alexmennen",
      "displayName": "AlexMennen"
    }
  },
  {
    "_id": "B27SG374nyccrkhcQ",
    "title": "Metamathematics and Probability",
    "slug": "metamathematics-and-probability",
    "pageUrl": "https://www.lesswrong.com/posts/B27SG374nyccrkhcQ/metamathematics-and-probability",
    "postedAt": "2017-09-22T03:07:57.156Z",
    "baseScore": 1,
    "voteCount": 0,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "http://alexmennen.com/index.php/2017/09/22/metamathematics-and-probability/",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p></p></div></div></div></div>",
    "user": {
      "username": "AlexMennen",
      "slug": "alexmennen",
      "displayName": "AlexMennen"
    }
  },
  {
    "_id": "pfz4sqZFugXbNEndK",
    "title": "What technologies was LessWrong 2.0 built on?",
    "slug": "what-technologies-was-lesswrong-2-0-built-on",
    "pageUrl": "https://www.lesswrong.com/posts/pfz4sqZFugXbNEndK/what-technologies-was-lesswrong-2-0-built-on",
    "postedAt": "2017-09-22T01:59:01.088Z",
    "baseScore": 5,
    "voteCount": 5,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>I&#x27;m asking this question not only because I am curious, but also because I might consider contributing to the codebase eventually and this is a relevant consideration.</p></div></div></div></div>",
    "user": {
      "username": "Chris_Leong",
      "slug": "chris_leong",
      "displayName": "Chris_Leong"
    }
  },
  {
    "_id": "6t5vRHrwPDi5C9hYr",
    "title": "Motivating a Semantics of Logical Counterfactuals",
    "slug": "motivating-a-semantics-of-logical-counterfactuals",
    "pageUrl": "https://www.lesswrong.com/posts/6t5vRHrwPDi5C9hYr/motivating-a-semantics-of-logical-counterfactuals",
    "postedAt": "2017-09-22T01:10:27.759Z",
    "baseScore": 22,
    "voteCount": 11,
    "commentCount": 3,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>(<strong>Disclaimer: </strong><em>This post was written as part of the CFAR/MIRI AI Summer Fellows Program, and as a result is a vocalisation of my own thought process rather than a concrete or novel proposal. However, it is an area of research I shall be pursuing in the coming months, and so ought to lead to the germination of more ideas later down the line. Credit goes to Abram Demski for inspiring this particular post, and to Scott Garrabrant for encouraging the AISFP participants to actually post something.</em>)</p><p>When reading Soares&#x27; and Levinstein&#x27;s recent publication on decision theory, <em>Death in Damascus</em>, I was struck by one particular remark:</p><blockquote><p>Unfortunately for us, there is as yet no full theory of counterlogicals [...], and for [functional decision theory (FDT)] to be successful, a more worked out theory is necessary, unless some other specification is forthcoming.</p></blockquote><p>For some background: an FDT agent must consider counterfactuals about what <em>would</em> happen if its decision algorithm on a given input were to output a particular action. If the algorithm is deterministic (or the action under consideration is merely outside of the range of possible outputs of the agent), then it is a logical impossibility that the algorithm produces a different output. Hence the initial relevance of logical counterfactuals or counterlogicals: counterfactuals whose antecedents represent a <em>logical </em>impossibility.</p><p>My immediate thought about how to tackle the problem of finding a full theory of counterlogicals was to find the right logical <em>system </em>that captures counterlogical inference in a way adequate to our demands. For example, Soares and Fallenstein show in <em>Toward Idealized Decision Theory </em>that the principle of explosion (from a contradiction, anything can be proved) leads to problematic results for an FDT solution. Why not simply posit that our decision theory uses paraconsistent logic in order to block some inferences?</p><p>Instead, and to my surprise, Soares and Levinstein appear to be more concerned about finding a <em>semantics</em> for logical counterfactuals - loosely speaking, they are looking for a uniform interpretation of such statements which shows us what they really <em>mean</em>. This is what I infer from reading the papers it references on theories of counterlogicals such as Bjerring&#x27;s <em>Counterpossibles</em>, which tries to extend Lewis&#x27; possible-worlds semantics for counterfactuals to cases of logical counterfactuals.</p><p>The approaches Soares and Levinstein make reference to do not suffice for their purposes. However, this is not because they give proof-theoretic considerations a wide berth, as I thought previously; I now believe that there is something that the semantic approach does get <em>right</em>.</p><p>Suppose that we found some paraconsistent logical system that permitted precisely the counterlogical inferences that agreed with our intuition: would this theory of logical counterfactuals satisfy the demands of a fully-specified functional decision theory? I would argue not. Specifically, this approach seems to give us a merely a posteriori, ad hoc justification for our theory - given that we are working towards an <em>idealised </em>decision theory, we ought to demand that the theory that supports it is <em>fully motivated</em>. In this case, this cashes out as making sure our counterlogical statements and inferences has a <em>meaning</em> - a meaning we can resort to to settle the truth-value of these counterlogicals.</p><p>This is not to say that investigating different logical systems is entirely futile: indeed, if the consideration above were true and a paraconsistent logic could fit the bill, then a uniform semantics for the system would serve as the last piece of the puzzle. </p><p>In the next year, I would like to investigate the problem of finding a full theory of logical counterfactuals, such that it may become a tool to be applied to a functional decision theory. This will, of course, involve finding the logical system that best captures our own reasoning about logical counterfactuals. Nonetheless, I will now also seek to find an actual motivation for whichever system seems the most promising, and the best way to find this motivation will be through finding an adequate semantics. I would welcome any suggestions in the comments about where to start looking for such a theory, or if any avenues have thus far proved to be more or less promising.</p><p></p></div></div></div></div>",
    "user": {
      "username": "Sam_A_Barnett",
      "slug": "sam_a_barnett",
      "displayName": "Sam_A_Barnett"
    }
  },
  {
    "_id": "AySu4FSv8ffvdLZm4",
    "title": "Splitting Decision Theories",
    "slug": "splitting-decision-theories",
    "pageUrl": "https://www.lesswrong.com/posts/AySu4FSv8ffvdLZm4/splitting-decision-theories",
    "postedAt": "2017-09-22T00:47:47.367Z",
    "baseScore": 8,
    "voteCount": 7,
    "commentCount": 3,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>[epistemic status: maybe wrong; thinking aloud, would like people to yell at me]</p><p></p><p>There is a repeated motion that occurs when deciding what an AI should do:<br/></p><p>(1) Create a decision theory</p><p>(2) Create a thought experiment in which an agent with *DT makes a choice which fails to fulfill its utility function (e.g. Oh no! It loses all its money to <a href=\"https://agentfoundations.org/item?id=32\">blackmail</a>!)</p><p>(3) Create a DT which does well against problems which the core difficulty which allowed the previous decision theory to lose all its money</p><p></p><p>If decision theories are as precisely imagined as mathematical structures. For every two distinct decision theories, there exists in mathematical reality a set of &quot;thought experiments&quot; such that the two theories decide differently on them.</p><p></p><p>This seems weird and difficult now because there isn&#x27;t a shared logical notation between different &quot;thought experiments&quot;. As of now characterizing the class of splitting decision problems for two decision theories is pretheoretic. However, for every pair of decision theories DT_1 and DT_2 the object split(DT_1, DT_2) actually exists. Current notational limits make it currently difficult to simply and completely characterize the class of choice problems on which two DTs give different answers.</p><p></p><p>But it feels like this sort of problem occupies a similar status as “algorithms” did before the first Universal Turing Machine was constructed.</p><p></p><p>-</p><p></p><p>Questions:</p><p></p><p>In fun games (like prisoner’s dilemma) we have agents (like <a href=\"http://lesswrong.com/lw/hmw/robust_cooperation_in_the_prisoners_dilemma/\">fairbot</a>) that fight each other. The source code for these agents is entangled with their decision theory. Does examining bots engaged in <a href=\"https://agentfoundations.org/item?id=1304\">modal combat</a> make this problem more tractable?</p><p></p><p>This process repeats like clockwork (it feels like a new decision theory comes out every year or so?) in hopes of giving their baby AI a good way of making good choices and not losing all its money. What if I built an AI that formalized and internalized this process and just ... gave itself good advice? Within <a href=\"http://acritch.com/media/math/logical-inductors-powerpoint.pdf\">logical inductors</a> traders bet on which theorems would be best and traders which make bad bets lose their money. If we can formalize split(DT_1, DT_2) we can look at how well agents fulfill their utility functions in this space. Can we use this to establish a kind of poset of decision theories?</p></div></div></div></div>",
    "user": {
      "username": "somni",
      "slug": "somni",
      "displayName": "somni"
    }
  },
  {
    "_id": "3W9BYy97FmZv9fD3J",
    "title": "Marketing Failure",
    "slug": "marketing-failure",
    "pageUrl": "https://www.lesswrong.com/posts/3W9BYy97FmZv9fD3J/marketing-failure",
    "postedAt": "2017-09-21T20:02:13.424Z",
    "baseScore": 2,
    "voteCount": 2,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": "https://edoarad.wordpress.com/2017/09/21/marketing-failure/",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>The amount of money spent worldwide on advertisements is <a href=\"https://www.statista.com/statistics/273288/advertising-spending-worldwide/\">astronomical</a>, reaching about 550 billion dollars annually and is expected to continue growing rapidly. In 2016, <a href=\"http://www.businessrevieweurope.eu/marketing/856/Top-20-companies-with-the-biggest-advertising-budget\">the top 20 companies with the biggest annual advertising budget </a> spend between 2.7 to 8.3 billion dollars annually.\r</p><p>\rIs this a result of a race-to-the-bottom-type market failure? If so, can we solve it?\r  \r</p><p>A nice story I heard was that when the united states acted to ban cigarette advertising, which was an enormous industry, the cigarette companies were actually in favor! The reason for that is that the cost of advertisement is huge and that the main motivation for advertising was to get more market share but that the advertisements did not cause more people to smoke more, so they were stuck in a prisoner&#x27;s dilemma situation. Sadly, this story <a href=\"https://www.newyorker.com/magazine/1970/12/19/the-fight-to-ban-smoking-ads\">seems to be wrong</a>, but it is meant to show that a big share of the money spent on marketing seems to go toward convincing that your product is better then the alternatives. Even if 1% of the marketing cost could be reduced without intrinsically harming the economy, it would still amount to a total of 1 billion dollars which could be spent on R&amp;D, higher salaries etc.\r</p><p>By the way, it is very interesting to see that on average <a href=\"https://vtldesign.com/digital-marketing/content-marketing-strategy/percent-of-revenue-spent-on-marketing-sales/\">about 10% of revenue goes into sales and marketing</a>, which for some sectors is more then <a href=\"https://www.statista.com/statistics/270233/percentage-of-global-rundd-spending-by-industry\">the percentage of revenue that goes into R&amp;D</a>. This is a good indicator that it is not enough to have a good product, or even the best product, if you want people to buy it. More precisely, it means that this is what these companies believe. Perhaps some sectors are in a marketing bubble, and that is not actually the case, as I suspect might be the case in some industries. For example, in the laptop industry a <a href=\"http://lesswrong.com/lw/o6p/double_crux_a_strategy_for_resolving_disagreement/\">crux</a> that would imply whether or not we are in such a bubble is whether people today choose their laptop solely based on how much this laptop fits their needs (quality, price, size,..) as opposed to buying a computer based on emotional connection to the brand (macbook, dell,..). It would be a good thing, if we are in such a bubble, as it means that it will eventually burst and more money will be spent on improving the products as a way to generate more consumers. An alternative formulation of this process is how much does a company adapt the product to fit the consumer as opposed to influencing the consumers to fit the product.\r</p><p>\r</p><p>To solve this market failure, I see two options. Regulations or a change in the incentive system itself. Since I know nothing about regulations, I&#x27;ll say a few words about how the incentive system can change.\r</p><p>\r</p><p>If we can make a system such that the consumers would choose their products strictly on the basis of how much does the product fit to their needs, and make it easier for consumers to find these products, we can change the incentive system in such a way that the manufacturers would focus more on making better products instead of competing in the non-productive marketing dimension.\r</p><p>\r</p><p>One thing which could make such a change is a program which makes the choices for the consumer. Consider buying a new phone. If you are like me, you should feel a hint of agony from just imagining the process of going over the endless lists of available phones, reading their specs, comparing prices... An easier way to make such a purchase would be to be presented with some questions and then being presented with the top 2-3 options that satisfy your needs. It could be augmented with a rating system, a reward system for first discoveries of good products, a prediction market on what products would turn out the best (or predicting some other properties), and much more. This kind of technology is probably under development somewhere and it seems likely to be pretty good in a few years. Such a technology, applied broadly, could make the consumers better equipped to buy products which align better with their needs, and by that it would shift the incentives of the companies to be focused more on developing better products which would be discovered by smart algorithms or by brave consumers and would gain a big market share if they are simply better products.\r</p><p>\r</p><p>There bound to be many better ideas out there, solving this and related problems. It may also solve only a fraction of the problem as, for example, the above example only works for B2C products, and not for B2B. \r</p><p>The important point is that it might be possible to defeat this market failure by a more careful analysis and better technologies or platforms. I find it an important exercise to seek market failures and to have some ideas about why it is the case and how it may be possible to combat it. This is because the market is a very powerful force, but nevertheless it is possible to shift it in better ways by inventing new platforms or technologies that change the incentive system.\r</p><p></p></div></div></div></div>",
    "user": {
      "username": "edoarad",
      "slug": "edoarad",
      "displayName": "edoarad"
    }
  },
  {
    "_id": "YNYxHAbsrxsCwCs7m",
    "title": "Why Attitudes Matter",
    "slug": "why-attitudes-matter",
    "pageUrl": "https://www.lesswrong.com/posts/YNYxHAbsrxsCwCs7m/why-attitudes-matter",
    "postedAt": "2017-09-21T15:07:44.687Z",
    "baseScore": 19,
    "voteCount": 18,
    "commentCount": 5,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Sometimes when I am giving ethical advice to people I say things like &quot;it&#x27;s important to think of yourself and your partner as being on the same team&quot; or &quot;just remember that women in short skirts are almost certainly not wearing short skirts to arouse you in particular&quot; or &quot;cultivate your curiosity and desire to know what&#x27;s actually going on.&quot;</p><p>I get pushback on this. After all, I am a consequentialist. Why am I talking about people&#x27;s attitudes instead of their actions? It doesn&#x27;t matter what I think of the woman in the short skirt, as long as I refrain from being a dick to her because of her clothing choices.</p><p>An emphasis on attitudes can be really bad for some people. Some people, having been given the advice that they should cultivate their curiosity, will spend a lot of time navel-gazing about whether they&#x27;re really curious and whether this curiosity counts as curiosity and maybe they are self-deceiving and actually just want to prove themselves right Not only is this really unpleasant, but if you&#x27;re spending all your time navel-gazing about whether you&#x27;re sufficiently curious you&#x27;re never actually going to go buy a book about the Abbasid empire. It completely fails to achieve the original goal. If this is a problem you&#x27;re prone to, I think my attitude-based advice is probably not going to be helpful, although I can&#x27;t give any other advice; I personally get as much navel-gazing as I can stand trying to keep my obviously shitty attitudes in check, and don&#x27;t have any introspective energy left over for anything else.</p><p>Nevertheless, I think an attitude emphasis can be really important, for two reasons.</p><p>First, for any remotely complicated situation, it would be impossible to completely list out all the things which are okay or not okay. For instance, think about turning my &quot;think of yourself and your partner as being on the same team&quot; advice into a series of actions. You might say &quot;it is wrong to insult your partner during disagreements.&quot; But for some people, insults are part of resolving disagreements. Saying &quot;I am not sure you&#x27;ve really thought this through&quot; rather than &quot;that is the stupidest fucking idea I&#x27;ve ever heard&quot; feels artificial to them, like they&#x27;re walking on eggshells. For them, intimacy requires the ability to say exactly what you&#x27;re feeling, without softening it.</p><p>Or you might say &quot;if you think of arguments for your partner&#x27;s side, then say it.&quot; However, this might lead you to fall victim to what C S Lewis in the Screwtape Letters called the Generous Conflict Illusion:</p><blockquote><p>Later on you can venture on what may be called the Generous Conflict Illusion. This game is best played with more than two players, in a family with grown-up children for example. Something quite trivial, like having tea in the garden, is proposed. One member takes care to make it quite clear (though not in so many words) that he would rather not but is, of course, prepared to do so out of “Unselfishness”. The others instantly withdraw their proposal, ostensibly through their “Unselfishness”, but really because they don’t want to be used as a sort of lay figure on which the first speaker practices petty altruisms. But he is not going to be done out of his debauch of Unselfishness either. He insists on doing “what the others want”. They insist on doing what he wants. Passions are roused. Soon someone is saying “Very well then, I won’t have any tea at all!”, and a real quarrel ensues with bitter resentment on both sides. You see how it is done? If each side had been frankly contending for its own real wish, they would all have kept within the bounds of reason and courtesy; but just because the contention is reversed and each side is fighting the other side’s battle, all the bitterness which really flows from thwarted self-righteousness and obstinacy and the accumulated grudges of the last ten years is concealed from them by the nominal or official “Unselfishness” of what they are doing or, at least, held to be excused by it. Each side is, indeed, quite alive to the cheap quality of the adversary’s Unselfishness and of the false position into which he is trying to force them; but each manages to feel blameless and ill-used itself, with no more dishonesty than comes natural to a human.</p></blockquote><p>Or you might say &quot;if your partner seems to be making a mistake, give them some friendly advice, without being overly critical.&quot; But some people are naturally controlling-- not abusive, just the sort of people who get upset when their partner loads the dishes a different way than they&#x27;re used to or prefers to read a map rather than using the GPS. Those people might very well decide that they shouldn&#x27;t give any friendly advice, for much the same reason that an alcoholic shouldn&#x27;t go to a bar. It never stops after one.</p><p>If you are thinking about the situations from a position of &quot;my partner and I are both on Team Our Collective Happiness And Well-Being,&quot; then the answer to all these thorny situations becomes clear. You should give a word of friendly advice, unless you are the sort of person who is incapable of stopping at a word of friendly advice. You should speak in a way that makes your partner and you feel more intimate and able to resolve conflicts, rather than less so. You should say &quot;hm, I think the vacation you want to go on is cheaper&quot; but you should not do the Generous Conflict Illusion. And so on and so forth.</p><p>Second, an attitude emphasis prevents rules-lawyering. Whenever you list a set of actions, there are a certain number of people who will figure out how to get as close as possible to breaking the rules, and then complain when you get annoyed at them, because technically they didn&#x27;t break any rules. (Rules-lawyering is particularly likely to happen in issues of sexual ethics, but it is certainly not reserved for those situations.) For example, they might say &quot;you said I wasn&#x27;t supposed to yell at my wife or call her nasty names! You never specifically said I wasn&#x27;t supposed to respond to my wife forgetting to do the dishes by piling up all the dirty dishes onto her bed.&quot;</p><p>But obviously if you are two people cooperating to solve the problem of the dirty dishes piling up, &quot;stick the dishes on the other person&#x27;s bed&quot; is not how you would respond. (Unless, I guess, they agreed ahead of time that this was a useful if disgusting way to help them remember-- like I said, it&#x27;s really hard to make hard-and-fast rules.) That is a way you&#x27;d respond if you&#x27;re approaching the situation as a war between you and your partner, and the winner is whoever gets a clean sink while having to do the least dishes. This is, to put it lightly, not a good way of solving your relationship problems.</p><p>I suspect that action-based advice works best in relatively simple situations where there aren&#x27;t a lot of possible actions and where there are few situations that require a judgment call: for instance, it works great for &quot;don&#x27;t hit people unless they started it&quot;. Attitude-based advice works best for complicated situations where there are lots of possible ways of fucking up: for instance, it works well for intimate relationships, intellectual or artistic life, and career choice.</p></div></div></div></div>",
    "user": {
      "username": "ozymandias",
      "slug": "ozymandias",
      "displayName": "ozymandias"
    }
  },
  {
    "_id": "FbG7axxsjAh4eSoAN",
    "title": "Solomonoff Induction explained via dialog.",
    "slug": "solomonoff-induction-explained-via-dialog",
    "pageUrl": "https://www.lesswrong.com/posts/FbG7axxsjAh4eSoAN/solomonoff-induction-explained-via-dialog",
    "postedAt": "2017-09-21T05:27:20.175Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "https://arbital.com/p/solomonoff_induction/?l=1hh",
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p></p></div></div></div></div>",
    "user": {
      "username": "panickedapricott",
      "slug": "panickedapricott",
      "displayName": "panickedapricott"
    }
  },
  {
    "_id": "t4r4m6Dx3LKEXGCyg",
    "title": "Value Arbitrage",
    "slug": "value-arbitrage",
    "pageUrl": "https://www.lesswrong.com/posts/t4r4m6Dx3LKEXGCyg/value-arbitrage",
    "postedAt": "2017-09-21T04:23:25.955Z",
    "baseScore": -3,
    "voteCount": 14,
    "commentCount": 8,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>This is an extremely useful idea that I&#x27;ve learned just recently. In fincance, &quot;arbitrage&quot; means buying and selling things in different markets to take the advantage of difference in price. Like buying a toy in India for $15, and then selling it for $25 in the US.</p><p>Turns out, you can arbitrage not just products, but also information, knowledge, skill, or even human relationships.</p><p>For example, let&#x27;s say you have met two amazing people who don&#x27;t know each other. When you introduce them to each other, you generate a massive amount of value for both of them essentially out of nothing - you have given each of them a gift of knowing someone great.</p><p>Another example, is arbitraging information. Eliezer Yudkowsky have learned a lot about rationality and human biases from the books he has read, and then parlayed it into his blog, and later a Harry Potter fanfiction - and that has generated a huge amount of value to the people on the internet, who would never have been exposed to these ideas otherwise. </p><p>You can also arbitrage skills. That simply means applying good ideas you have learned in one field to a completely different one. I&#x27;m constantly applying the skills and ideas I&#x27;ve learned as a 3D artist to my programming process, and, surprisingly, the ideas I&#x27;ve learned from programming are making me a much better artist.</p><p>Finally, an unexpected idea that I have discovered, is that you can arbitrage fiction tropes. You can take a trope you have seen in one story, apply it to a completely different genre, and it will create a new and interesting idea. You can take a SciFi trope and set it in a fantasy world, or you can take a plot structure from a dramatic TV show and use it in your comedy script. In fact, this is how a lot of movie ideas are created.</p><p>Smart ideas are often universal. Learn a mental pattern in one field - and apply it elsewhere. Now that I got pretty good at it, every time I have an epiphany in one of my crafts, I intentionally go through each of the other fields I&#x27;m interested in and apply it there. This has helped me to generate a lot of very interesting ideas.</p></div></div></div></div>",
    "user": {
      "username": "rayalez",
      "slug": "rayalez",
      "displayName": "rayalez"
    }
  },
  {
    "_id": "DcRFTx62sTTRQo3Jw",
    "title": "Common vs Expert Jargon ",
    "slug": "common-vs-expert-jargon",
    "pageUrl": "https://www.lesswrong.com/posts/DcRFTx62sTTRQo3Jw/common-vs-expert-jargon",
    "postedAt": "2017-09-21T03:05:31.203Z",
    "baseScore": 56,
    "voteCount": 33,
    "commentCount": 17,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p style=\"text-align:left;\"><em>tldr: Jargon always has a complexity cost, but you can put effort into making a concept more accessible, and it&#x27;s especially valuable to put that effort in for terms that you&#x27;d like to be used by layfolk, or that you expect to be used a lot in spaces where you expect lots of layfolk to be reading/participating.</em></p><h2><strong>I. Lessons from Game Design</strong></h2><p>Magic the Gathering deals a lot with complexity. Each year, new abilities and rules are added to the game. This gives experienced players the chance to constantly discover new things, but it comes with some issues.</p><p>First, it makes the game harder for new players (the game kept growing more complex over time, raising the amount of information a new player had to process at once)</p><p>And second, even for experienced players: each instance of complexity is a cost. Players (both new and old) can only handle so much, and some forms of complexity are less fun than others. (For example, forcing players to do a lot of book-keeping, rather than letting them make interesting strategic decisions)</p><p>Six years ago, their creative director wrote about a <a href=\"https://magic.wizards.com/en/articles/archive/making-magic/new-world-order-2011-12-02\">new paradigm of Magic design</a>. One of their solutions was to pay careful attention to how they spent complexity points in ways that affected new players. </p><p>Three examples:</p><h3>1. Common Cards</h3><p>In Magic, when you buy a new pack, 11 cards are &quot;common&quot;, 3 are &quot;uncommon&quot; and one is &quot;rare&quot;. Experienced players buy lots of cards and can have access to lots of rares, but new players generally just buy a few cards, so most of their cards are common. Therefore, the complexity of the cards at common determines how much complexity newcomers have to deal with.</p><h3>2. Keywords</h3><p>One way to reduce &quot;effective complexity&quot; is to bundle concepts together in a keyword. Instead of saying &quot;this creature deals damage to each of the creatures blocking it and then deals the remainder of its damage to the player&quot;, it just says &quot;Trample&quot;. There&#x27;s an initial cost of learning what Trample means, but afterwards, every time you see the word &quot;Trample&quot; on a creature it works the same way.</p><p>Trample has some neat things going for it: it sounds evocative, and gets to build off of existing ideas in your brain. You already know what a big animal looks like. You can imagine a small creature getting in the way of the elephant, and it slowing the elephant down slightly but not really stopping it, and the elephant continuing on, trampling over it, and then going on to attack some bigger target.</p><p>This imagery is helpful for intuiting what the rules mean, even if the wording is somewhat confusing.</p><p>The problem comes when you introduce too many keywords at once. It gets overwhelming. Which brings to a final concept:</p><h3>3. Evergreen keywords</h3><p>Every 3 months, new magic cards are released to keep things fresh. New keywords are introduced (usually 3-5).</p><p>But there are some keywords (like Trample) that are *always* in season. There are about 16 evergreen keywords. Many of them are pretty intuitive (such as flying creatures only be able to be blocked by other flying creatures) so they aren&#x27;t hard to learn. </p><p>A new player has an implicit goal of &quot;learn all the evergreen keywords&quot;, which is a manageable task.</p><h2>II. Building a high level conversation</h2><p>I think some of this applies to the <a href=\"https://www.lesserwrong.com/posts/s8yvtCbbZW2S4WnhE/what-exactly-is-the-rationality-community\">rationalsphere</a>, where a lot of important concepts have been built up, or, combined together from neighboring disciplines. (See Anna Salmon&#x27;s <a href=\"https://www.lesserwrong.com/posts/8rYxw9xZfwy86jkpG/on-the-importance-of-less-wrong-or-another-single\">Single Conversational Locus</a>)</p><p>Jargon is *useful*. They let you summarize a complex concept in a single word, and then have deeper conversations where each word packs a lot more meaning.</p><p>I have a lot of thoughts about how to do jargon *right*, which are beyond the scope of this post. But to summarize, I think good jargon:</p><ul><li><p>encapusulates an idea that&#x27;s important to build off of</p></li><li><p>lets you distinguish between *similar* concepts that have importantly-different-nuances. (viral infection vs bacterial infection)</p></li><li><p>provides some context clues that help you learn it (the way Trample does), while...</p></li><li><p>...not *also* resulting in people confusing what it means (a bad example perhaps being &quot;negative reinforcement&quot;, which is not actually the same thing as &quot;punishment&quot;)</p></li></ul><p>Some considerations:</p><p>1) Sometimes you want a 101 space where you&#x27;re either introducing ideas to a broader audience. Sometimes you want a 201 space where you&#x27;re building on those ideas (either helping somewhat-less-newcomers build up a more advanced understanding, or literally developing new content at the cutting edge)</p><p>2) Different venues of conversation can have both different expectations of who-is-participating, and different social norms of what kind of participation is encouraged. (i.e an academic journal, a semi-formal internet forum, a facebook post)</p><p>3) Some concepts are pretty standalone: layfolk can learn them and use them immediately without having to fit them into a big edifice of theory</p><p>4) Furthermore, some concepts make good &quot;gateway&quot; terminology. They&#x27;re useful standalone, but then they open up a world of ideas to you that you can then further explore.</p><p>So my thought is basically: if you are developing jargon, pay extra attention to whether this is Common or Expert Level jargon. There&#x27;s not a clear dividing line between them, but roughly:</p><p>Common Jargon means you&#x27;re expecting it to be a useful enough idea for layfolk to use regularly (or, you&#x27;d like to be able to have conversations with layfolk, or write popularization articles, that rely on the term already percolating into the mainstream, or, use it as a gateway term)</p><p>Consequently, it&#x27;s much more important to put a lot of effort into choosing a term that:  </p><ul><li><p>resonates easily, is memorable...</p></li><li><p>...but avoids people latching onto the wrong aspect of it and misinterpreting it</p></li><li><p>doesn&#x27;t sound like a weird insider term...</p></li><li><p>... but maybe ideally hints at a broader ecosystem of ideas</p></li></ul><p>Expert Jargon is only really useful if you&#x27;re buying into a broader ecosystem of ideas that build on each other. Accessibility and avoiding misunderstanding is still important if possible but being precise and build-on-able is more valuable.</p><h3>Further Reading</h3><p>This post was inspired by and builds upon:</p><p><a href=\"https://thezvi.wordpress.com/2017/07/25/complexity-is-bad/\">Complexity is bad</a> (Zvi Mowshowitz)<br/><a href=\"http://malcolmocean.com/2016/02/sparkly-pink-purple-ball-thing/\">The Purple Sparkly Ball Thing</a> (Malcolm Ocean)<br/><a href=\"https://magic.wizards.com/en/articles/archive/making-magic/new-world-order-2011-12-02\">New World Order</a> (Mark Rosewater)</p></div></div></div></div>",
    "user": {
      "username": "Raemon",
      "slug": "raemon",
      "displayName": "Raemon"
    }
  },
  {
    "_id": "vtZsEerABCjhtgizX",
    "title": "Beta - First Impressions",
    "slug": "beta-first-impressions",
    "pageUrl": "https://www.lesswrong.com/posts/vtZsEerABCjhtgizX/beta-first-impressions",
    "postedAt": "2017-09-21T01:56:33.146Z",
    "baseScore": 32,
    "voteCount": 23,
    "commentCount": 104,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>I thought that instead of everyone having to create a separate post for their first impressions, it would be more convenient to create a single post for this discussion. I&#x27;ll post my own here soon.</p></div></div></div></div>",
    "user": {
      "username": "Chris_Leong",
      "slug": "chris_leong",
      "displayName": "Chris_Leong"
    }
  },
  {
    "_id": "gbNdc7gCXCy2ZWqXe",
    "title": "Against EA PR",
    "slug": "against-ea-pr",
    "pageUrl": "https://www.lesswrong.com/posts/gbNdc7gCXCy2ZWqXe/against-ea-pr",
    "postedAt": "2017-09-21T01:23:00.502Z",
    "baseScore": 48,
    "voteCount": 29,
    "commentCount": 6,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>Scott Alexander recently wrote about <a href=\"http://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/\">weird effective altruism</a>. Many people (mostly, but not entirely, people who aren&#x27;t effective altruists) offered the opinion that weird effective altruists should be banned from EA, or at least shouldn&#x27;t be allowed to give talks at EA Global and have blog posts written about them. Weird effective altruist causes are (sort of by definition) off-putting to most people; therefore, if you want people to donate to global poverty relief, you should kick out all of those people concerned about farmed animal welfare/AI risk/wild animal welfare/psychedelics research/suffering in fundamental physics, lest we scare the normies.</p><p>There are many reasonable critiques of this point of view, including that it&#x27;s not remotely clear that any of those claims are more frightening to normal people than &quot;it is morally obligatory to make personal sacrifices in order to help poor, faraway black people.&quot; But ultimately I reject the entire premise.</p><p>I&#x27;d like to be clear about what I&#x27;m not saying in this post. I am not saying all &quot;weird effective altruism&quot; causes are effective; I believe some are and some aren&#x27;t. I think many effective altruists are not taking seriously enough the difficulty of figuring out how effective highly speculative causes are, and that unless we seriously address this we&#x27;re going to waste potentially millions of dollars on boondoggles. And I suspect a lot of weird effective altruism tends to over-explore certain cause areas (for example, things you think of if you read too many science fiction novels) and underexplore other cause areas (for example, boring things). I don&#x27;t intend this post to be a whole-hearted defense of weird effective altruism, but simply a criticism of a single narrow argument too often wielded against it.</p><p>So the question arises: why is effective altruism a thing at all?</p><p>Most people care about charity effectiveness, at least a little bit. They look up their charities on Charity Navigator before donating; they object to money being spent on big CEO salaries or on overhead instead of on services; they circulate criticisms of the Susan G Komen Foundation and PETA. <a href=\"https://80000hours.org/articles/effective-social-program/\">And yet not only do most social programs not work, for the vast majority of programs we simply haven&#x27;t collected the information to see whether it works or not.</a> This isn&#x27;t a &quot;no one cares about starving Africans&quot; thing; the state of the evidence on warm-fuzzies American medical and educational interventions is equally poor.</p><p>Part of the problem is that while people care about effectiveness some, they don&#x27;t care about effectiveness that much. They are willing to google a charity to see whether it is an outright scam, but they&#x27;re not willing to read academic papers to see if the charity&#x27;s intervention works. They&#x27;re definitely not going to put in the time to separate intuitive but misleading measures of effectiveness (CEO pay) from actually good measures of effectiveness (randomized controlled trials).</p><p>The other part of the problem is that all charity advertisements are a hellhole of epistemic doom and despair.</p><p>Let&#x27;s pick on Feeding America. Not because it&#x27;s an unusually bad charity (it&#x27;s not), but because it&#x27;s large and typical.</p><p>Looking on <a href=\"http://www.feedingamerica.org\">their webpage</a>, I find out immediately that 1 in 8 Americans struggles with hunger. That sounds awful! After clicking through several pages, I find that the source is <a href=\"https://www.ers.usda.gov/webdocs/publications/79761/err-215.pdf?v=42636\">this document</a>, in which 1 in 8 households (not individuals) are food insecure. You can click through to the document to read the full operationalization of food insecure (it&#x27;s on pages 3-4). Food insecure households include, for instance, a household that sometimes worries about whether they&#x27;ll run out of food, feeds their children only a few kinds of low-cost food to avoid running out of food, and sometimes can&#x27;t afford to eat balanced meals. While obviously this household is experiencing a good deal of suffering and Feeding America can help them, it&#x27;s not exactly what the average person would think of when they hear the word &quot;hunger.&quot; This is actively misleading.</p><p>I click through to Our Work, where I learn that Feeding America has fed four billion meals last year. What percentage of people who would otherwise go hungry did they feed? 10%? 50%? 99%? How many of their meals went to people who would have otherwise gone hungry, versus people who would have been able to figure out some other way to get enough to eat? Feeding America does not provide any insight into these important questions.</p><p>98% of all donations raised go directly to helping people in need: according to <a href=\"https://www.charitynavigator.org/index.cfm?bay=search.summary&amp;orgid=5271#.U_oJ2vmwJZQ\">Charity Navigator</a>, this refers to program expenses, with 1.1% of their income being spent on fundraising and 0.3% spent on administrative expenses. Would increasing their percent spent on fundraising allow them to help more people by raising more money? Would increased administrative expenses, say, reduce the amount of food waste by hiring someone to improve their distribution practices? We simply don&#x27;t have enough information to know.</p><p>In short, Feeding America is misleading about the scope of the problem they&#x27;re dealing with and does not provide the necessary information to assess their effectiveness in dealing with it.</p><p>Again, I am not picking on Feeding America because it is bad. The reason that charity is a total epistemic hellhole is that all charities are like this. The beloved effective altruist charity <a href=\"https://www.againstmalaria.com/\">the Against Malaria Foundation</a> explains on its homepage that 100% of donations go to buy nets (because presumably in a perfect world AMF employees would not need to earn a salary to pay for such luxuries as &quot;homes&quot; and &quot;food&quot;) and entirely omits the fact that most nets will not actually prevent any cases of malaria.</p><p>Of course, I&#x27;m being unfair here. The purpose of a charity&#x27;s website is not to tell the complete and unvarnished truth, it&#x27;s to get people to donate. How many people have actually read a GiveWell charity report all the way through without their eyes glazing over by the time they get to &quot;Niger, Burundi, Malawi, and Liberia Prevalence and Intensity Studies&quot;? If the charity actually had a proper cost-effectiveness assessment rather than a bunch of oversimplified bullet points, everyone would get bored and decide to catch up on Game of Thrones instead and no meals or mosquito nets would be bought at all.</p><p>And the harm here seems pretty small. So maybe &quot;100% of public donations go to buy nets&quot; means &quot;we got some people to allocate money towards paying our employees instead of towards nets because you&#x27;re an idiot who thinks nonprofit employees can survive on nothing more than the satisfaction of doing good.&quot; So maybe &quot;struggles with hunger&quot; means &quot;at least one member of the family has missed one meal in the past year due to not having enough money and also the children do not eat enough vegetables&quot; instead of &quot;is hungry most of the time.&quot; It&#x27;s not like they&#x27;re outright lying, and it&#x27;s for a good cause. Would you rather people spend that money on a new pair of shoes instead?</p><p>But the fact of the matter is that the Red Cross makes the same calculation about disaster relief, and the American Cancer Society makes the same calculation about cancer treatment, and the Smithsonian makes the same calculation about preserving priceless historical artifacts. And that means that it&#x27;s extraordinarily difficult to figure out really basic questions about charities you might want to donate to, like:</p><ul><li><p>How much does the problem the charity is trying to solve affect people&#x27;s lives?</p></li><li><p>How many people does the problem the charity is trying to solve affect?</p></li><li><p>Does this charity actually help with the problem it is trying to solve? </p></li><li><p>If I donate to this charity, will the money go to really important programs that have a big effect on people&#x27;s lives, or do they already have enough money for all of that and my donation would go to something that doesn&#x27;t actually do that much good?</p></li><li><p>Is this charity better than other charities I might donate to?</p></li></ul><p>Which is the reason effective altruism is possible at all.</p><p>As far as I&#x27;m aware, effective altruist charity evaluators are the only people who are trying to answer this sort of question for the general public (although presumably some big foundations like the Gates Foundation are trying to answer it for themselves). This is our thing. This is the value we add over a Salvation Army bell-ringer who happens to have some fliers for <a href=\"https://www.idealist.org/en/?radius=40000&amp;sort=relevance&amp;type=ALL\">Idealist</a>.</p><p>I don&#x27;t care about effective altruists&#x27; personal honesty. Lie to your parents about your dating life, shade the truth on your resume, compliment your friend&#x27;s hat which vaguely resembles a dead opossum, whatever. Hell, if you&#x27;re working for a top charity that isn&#x27;t an explicitly effective-altruism-branded top charity, do the epistemic hellhole thing. Everyone else is and you might as well try to grab some of the charity budget for things that actually work.</p><p>But when you are speaking as an effective altruist-- don&#x27;t get complicated, don&#x27;t get clever. Just say what you think the best cause area or charity or career is. Every time you think to yourself &quot;well, I think AI risk is more important, but it&#x27;ll turn people off, so I should probably say the Against Malaria Foundation,&quot; the effective altruism movement takes one more step towards being the same as any other group of charitably-minded nerds.</p><p>I go pretty far on this. A lot of introductory effective altruism material uses global poverty examples, even articles which were written by people I know perfectly fucking well only donate to MIRI. I think people should generally either use examples from the cause they actually think is most effective, or use an equal number of existential risk, animal welfare, and global poverty examples, in order to reflect the disagreement in the effective altruist community.</p><p>I&#x27;m not saying you should pay literally zero attention to public relations. There are lots of things you can do to be more persuasive that don&#x27;t involve misleading people. You can show people pictures of sad animals or happy African children. You can wear professional clothes offline or write with proper grammar online. You can be kind and respectful and try to see things from other people&#x27;s points of view. But you must abjure all attempts to persuade people by doing anything other than giving people your best assessment of all the evidence, including all the nuance and all the caveats, even if it might turn them off.</p></div></div></div></div>",
    "user": {
      "username": "ozymandias",
      "slug": "ozymandias",
      "displayName": "ozymandias"
    }
  },
  {
    "_id": "SR8cqwbMLmKqR7p5s",
    "title": "LW 2.0 Open Beta Live",
    "slug": "lw-2-0-open-beta-live",
    "pageUrl": "https://www.lesswrong.com/posts/SR8cqwbMLmKqR7p5s/lw-2-0-open-beta-live",
    "postedAt": "2017-09-21T01:15:53.341Z",
    "baseScore": 35,
    "voteCount": 23,
    "commentCount": 37,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<p>The <a href=\"https://www.lesserwrong.com/\">LW 2.0 Open Beta is now live</a>; this means you can create an account, start reading and posting, and tell us what you think.</p>\n<p>Four points:</p>\n<p>1) In case you're just tuning in, I took up the mantle of revitalizing LW through improving its codebase some time ago, and only made small amounts of progress until Oliver Habryka joined the project and put full-time engineering effort into it. He deserves the credit for the new design, and you can <a href=\"/lw/pes/lw_20_strategic_overview/\">read about his strategic approach here</a>.</p>\n<p>2) If you want to use your current LW account on LW2.0, we didn't import the old passwords, and so you'll have to use the reset password functionality. If your LW account isn't tied to a current email, <a href=\"/message/compose/?to=Habryka\">send a PM to habryka</a> on lesswrong and he'll update the user account details on lesserwrong. He's also working on improving the site and sleeping and things like that, so don't expect an immediate response.</p>\n<p>3) During the open beta there will be a green message in the bottom right hand corner of the screen. This is called Intercom, and is how you can tell us about issues with the site and ask other questions.</p>\n<p>4) The open beta will end with a vote of users with over a thousand karma on whether we should switch the lesswrong.com URL to point to the new code and database. If this succeeds, all the activity from the open beta and the live site will be merged together. If the vote fails, we expect to archive LW until another team comes along to revive it. We currently don't have a date set, but this will be announced a week in advance.</p>",
    "user": {
      "username": "Vaniver",
      "slug": "vaniver",
      "displayName": "Vaniver"
    }
  },
  {
    "_id": "4yMXkThqdD8QRiaht",
    "title": "Strategic Goal Pursuit and Daily Schedules",
    "slug": "strategic-goal-pursuit-and-daily-schedules",
    "pageUrl": "https://www.lesswrong.com/posts/4yMXkThqdD8QRiaht/strategic-goal-pursuit-and-daily-schedules",
    "postedAt": "2017-09-20T20:19:49.366Z",
    "baseScore": 4,
    "voteCount": 3,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>In the post <em><a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Humans Are Not Automatically Strategic</a></em>, Anna Salamon writes:</p>\n<blockquote>\n<p>there are clearly also heuristics that would be useful to goal-achievement (or that would be part of what it means to &ldquo;have goals&rdquo; at all) that we do&nbsp;not&nbsp;automatically carry out. &nbsp;We do&nbsp;not&nbsp;automatically:</p>\n<p>(a) Ask ourselves what we&rsquo;re trying to achieve;&nbsp;</p>\n<p>(b) Ask ourselves how we could tell if we achieved it (&ldquo;what does it look like to be a good comedian?&rdquo;) and how we can track progress;&nbsp;</p>\n<p>(c) Find ourselves strongly, intrinsically curious about information that would help us achieve our goal;&nbsp;</p>\n<p>(d) Gather that information (e.g., by asking as how folks commonly achieve our goal, or similar goals, or by tallying which strategies have and haven&rsquo;t worked for us in the past);&nbsp;</p>\n<p>(e) Systematically test many different conjectures for how to achieve the goals, including methods that aren&rsquo;t habitual for us, while tracking which ones do and don&rsquo;t work;&nbsp;</p>\n<p>(f) Focus most of the energy that *isn&rsquo;t* going into systematic exploration, on the methods that work best;</p>\n<p>(g) Make sure that our \"goal\" is really our goal, that we coherently want it and are not constrained by fears or by uncertainty as to whether it is worth the effort, and that we have thought through any questions and decisions in advance so they won't continually sap our energies;</p>\n<p>(h) Use environmental cues and social contexts to bolster our motivation, so we can keep working effectively in the face of intermittent frustrations, or temptations based in hyperbolic discounting;</p>\n</blockquote>\n<p>When I read this, I was feeling quite unsatisfied about the way I pursued my goals. So the obvious thing to try, it seemed to me, was to ask myself how I could actually do all these things.</p>\n<p>I started by writing down all the major goals I have I could think of (a). Then I attempted to determine whether each goal was consistent with my other beliefs, whether I was sure it was something I really wanted, and was worth the effort(g).</p>\n<p>For example, I saw that my desire to be a novelist was more motivated by the idea of how cool it would feel to be able to have that be part of my self-image, rather than a desire to actually write a novel. Maybe I&rsquo;ll try to write a novel again one day, but if that becomes a goal sometime in the future it will be because there is something I really want to write about, not because I would just like to be a writer.</p>\n<p>&nbsp;</p>\n<p>Once I narrowed my goals down to aspirations that seemed actually worthwhile I attempted to devise useful tracking strategies for each goal (b). Some were pretty concrete (did I exercise for at least four hours this week) and others less so (how happy do I generally feel on a scale of 1-10 as recorded over time), but even if the latter method is prone to somewhat biased responses, it seems better than nothing.</p>\n<p>The next step was outlining what concrete actions I could begin immediately taking to work towards achieving my goals, including researching how to get better at working on the goals (d,e,f). I made sure to refer to those points when thinking about actions I could take, it helped significantly.</p>\n<p>&nbsp;</p>\n<p>As for (c), if you focus on how learning certain information will help you achieve something you really want to achieve and you still are not curious about it, well, that&rsquo;s a bit odd to me, although I can imagine how that might occur. But that is something of a different topic than I want to focus on.</p>\n<p>Now we come to (h), which is the real issue of the whole system, at least for me. Or perhaps it would be clearer to say that general motivation and organization was the biggest problem I had when I first tried to implement these heuristics. I planned out my goals, but trying to work on them by sheer force of will did not last for very long. I would inevitably convince myself that I was too tired, I would forget certain goals fairly often (probably conveniently the tasks that seemed the hardest or least immediately pleasant), and ultimately I mostly gave up, making a token effort now and again.</p>\n<p>&nbsp;</p>\n<p>I found that state of affairs unsatisfactory, and I decided what felt like a willpower problem might actually be a situational framing problem. In order to change the way I interacted with the work that would let me achieve my goals, I began fully scheduling out the actions I would take to get better at my goals each day.</p>\n<p>In the evening, I look over my list of goals and I plan my day by asking myself, &ldquo;How can I work on everything on this list tomorrow? Even if it&rsquo;s only for five minutes, how do I plan my day so that I get better at everything I want to get better at?&rdquo; Thanks to the fact that I have written out concrete actions I can take to get better at my goals, this is actually quite easy.</p>\n<p>&nbsp;</p>\n<p>These schedules improve my ability to consistently work on my goals for a couple reasons, I think. When I have planned that I am going to do some sort of work at a specific time I cannot easily rationalize procrastination. My normal excuses of &ldquo;I&rsquo;ll just do it in a bit&rdquo; or &ldquo;I&rsquo;m feeling too tired right now&rdquo; get thrown out. There is an override of &ldquo;Nope, you&rsquo;re doing it now, it says right here, see?&rdquo; With a little practice, following the schedule becomes habit, and it&rsquo;s shocking how much willpower you have for actually doing things once you don&rsquo;t need to exert so much just to get yourself to start. I think the psychology it applies is similar to that used by Action Triggers, as described by Dr. Peter Gollwitzer.</p>\n<p>The principle of Action Triggers is that you do something in advance to remind yourself of something you want to do later. For example, you lay out your running clothes to prompt yourself to go for that jog later. Or you plan to write your essay immediately after a specific tangible event occurs (e.g. right after dinner). A daily schedule works as constant action triggers, as you are continually asking the question &ldquo;what am I supposed to do now?&rdquo; and the schedule answers.</p>\n<p>&nbsp;</p>\n<p>Having a goal list and daily schedule has increased my productivity and organization an astonishing amount, but there have been some significant hiccups. When I first began making daily schedules I used them to basically eschew what I saw as useless leisure time, and planned my day in a very strict fashion.</p>\n<p>&nbsp;</p>\n<p>The whole point is not to waste any time, right? The first problem this created may be obvious to those who better appreciate the importance of rest than I did at the time. I stopped using the schedules after a month and a half because it eventually became too tiring and oppressive. In addition, the strictness of my scheduling left little room for spontaneity and I would allow myself to become stressed when something would come up that I would have to attend to.&nbsp; Planned actions or events also often took longer than scheduled and that would throw the whole rest of the day&rsquo;s plan off, which felt like failure because I was unable to get everything I planned done.</p>\n<p>&nbsp;</p>\n<p>Thinking back to that time several months later, when I was again dissatisfied with how well I was able to work towards my goals and motivate myself, I wished for the motivation and productivity the schedules provided, but to avoid the stress that had come with them. It was only at this point that I started to deconstruct what had gone wrong with my initial attempt and think about how I could fix it.</p>\n<p>&nbsp;</p>\n<p>The first major problem was that I had overworked myself, and I realized I would have to include blocks of unplanned leisure time if daily schedules were going to actually work for me. The next and possibly even more important problem was how stressed the schedules had made me. I had to enforce to myself that it is okay if something comes up that causes my day not to go as planned. Failing to do something as scheduled is not a disaster, or even an actual failure if there is good reason to alter my plans.</p>\n<p>&nbsp;</p>\n<p>Another technique that helped was scheduling as much unplanned leisure time as possible at the end of my day. This has the dual benefit of allowing me to reschedule really important tasks into that time if they get bumped by unexpected events and generally gives me something to look forward to at the end of the day.</p>\n<p>&nbsp;</p>\n<p>The third problem I noticed was that the constant schedule starts to feel oppressive after a while. To resolve this, about every two weeks I spend one day, in which I have no major obligations, without any schedule. I use the day for self-reflection, examining how I&rsquo;m progressing on my goals, if there are new actions I can think of to add, or modifications I can make to my system of scheduling or goal tracking. Besides that period of reflection, I spend the day resting and relaxing. I find this exercise helps a lot in refreshing myself and making the schedule feel more like a tool and less like an oppressor.</p>\n<p>&nbsp;</p>\n<p>So, essentially, figuring out how to actually follow the goal-pursuing advice Anna gave in Humans Are Not Automatically Strategic, has been very effective thus far for me in terms of improving the way I pursue my goals. I know where I am trying to go, and I know I am taking concrete steps every day to try and get there. I would highly recommend attempting to use Anna&rsquo;s heuristics of goal achievement and I would also recommend using daily schedules as a motivational/organizational technique, although my advice on schedules is largely based on my anecdotal experiences.</p>\n<p>&nbsp;</p>\n<p>I am curious if anyone else has attempted to use Anna&rsquo;s goal-pursuing heuristics or daily schedules and what your experiences have been.</p>",
    "user": {
      "username": "Rossin_duplicate0.6898194309641386",
      "slug": "rossin_duplicate0-6898194309641386",
      "displayName": "Rossin_duplicate0.6898194309641386"
    }
  },
  {
    "_id": "7aXbpdYqhWqzyyx8Y",
    "title": "A survey of polls on Newcomb’s problem",
    "slug": "a-survey-of-polls-on-newcomb-s-problem",
    "pageUrl": "https://www.lesswrong.com/posts/7aXbpdYqhWqzyyx8Y/a-survey-of-polls-on-newcomb-s-problem",
    "postedAt": "2017-09-20T16:50:08.802Z",
    "baseScore": 3,
    "voteCount": 3,
    "commentCount": 8,
    "meta": false,
    "question": false,
    "url": "https://casparoesterheld.com/2017/06/27/a-survey-of-polls-on-newcombs-problem/",
    "htmlBody": null,
    "user": {
      "username": "Caspar42",
      "slug": "caspar-oesterheld",
      "displayName": "Caspar Oesterheld"
    }
  },
  {
    "_id": "cAMhvPgMQJzhrpNdN",
    "title": "Publication of \"Anthropic Decision Theory\"",
    "slug": "publication-of-anthropic-decision-theory",
    "pageUrl": "https://www.lesswrong.com/posts/cAMhvPgMQJzhrpNdN/publication-of-anthropic-decision-theory",
    "postedAt": "2017-09-20T15:41:02.206Z",
    "baseScore": 12,
    "voteCount": 8,
    "commentCount": 9,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>My paper \"Anthropic decision theory for self-locating beliefs\", based on <a href=\"/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">posts</a> <a href=\"/lw/l60/solving_selfishness_for_udt/\">here</a> on Less Wrong, has been published as a <a href=\"https://www.fhi.ox.ac.uk/wp-content/uploads/Anthropic_Decision_Theory_Tech_Report.pdf\">Future of Humanity Institute tech report</a>. Abstract:</p>\n<blockquote>\n<p>This paper sets out to resolve how agents ought to act in the Sleeping Beauty problem and various related anthropic (self-locating belief) problems, not through the calculation of anthropic probabilities, but through finding the correct decision to make. It creates an anthropic decision theory (ADT) that decides these problems from a small set of principles. By doing so, it demonstrates that the attitude of agents with regards to each other (selfish or altruistic) changes the decisions they reach, and that it is very important to take this into account. To illustrate ADT, it is then applied to two major anthropic problems and paradoxes, the Presumptuous Philosopher and Doomsday problems, thus resolving some issues about the probability of human extinction.</p>\n</blockquote>\n<p>Most of these ideas are also explained in <a href=\"https://www.youtube.com/watch?v=aiGOGkBiWEo\">this video</a>.</p>\n<p>To situate Anthropic Decision Theory within the UDT/TDT family: it's basically a piece of UDT applied to anthropic problems, where the UDT approach can be justified by using generally fewer, and more natural, assumptions than UDT does.</p>",
    "user": {
      "username": "Stuart_Armstrong",
      "slug": "stuart_armstrong",
      "displayName": "Stuart_Armstrong"
    }
  },
  {
    "_id": "ddxSCiqDDKvDd9aoN",
    "title": "HPMOR and Sartre's \"The Flies\"",
    "slug": "hpmor-and-sartre-s-the-flies",
    "pageUrl": "https://www.lesswrong.com/posts/ddxSCiqDDKvDd9aoN/hpmor-and-sartre-s-the-flies",
    "postedAt": "2017-09-19T20:53:23.338Z",
    "baseScore": 3,
    "voteCount": 3,
    "commentCount": 6,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Am I the only one who sees obvious parallels between Sartre's use of Greek mythology as a shared reference point to describe his philosophy more effectively to a lay audience and Yudkowsky's use of Harry Potter to accomplish the same goal? Or is it so obvious no one bothers to talk about it? Was that conscious on Yudkowsky's part? Unconscious? Or am I just seeing connections that aren't there?</p>",
    "user": {
      "username": "wMattDodd",
      "slug": "wmattdodd",
      "displayName": "wMattDodd"
    }
  },
  {
    "_id": "hGBPYcByMWY5HKX8m",
    "title": "The Copenhagen Letter",
    "slug": "the-copenhagen-letter",
    "pageUrl": "https://www.lesswrong.com/posts/hGBPYcByMWY5HKX8m/the-copenhagen-letter",
    "postedAt": "2017-09-18T18:45:38.469Z",
    "baseScore": 0,
    "voteCount": 0,
    "commentCount": 16,
    "meta": false,
    "question": false,
    "url": "https://copenhagenletter.org/",
    "htmlBody": null,
    "user": {
      "username": "chaosmage",
      "slug": "chaosmage",
      "displayName": "chaosmage"
    }
  },
  {
    "_id": "RS4hPDqdXL8TCuG6a",
    "title": "A Short Explanation of Blame and Causation",
    "slug": "a-short-explanation-of-blame-and-causation",
    "pageUrl": "https://www.lesswrong.com/posts/RS4hPDqdXL8TCuG6a/a-short-explanation-of-blame-and-causation",
    "postedAt": "2017-09-18T17:43:34.571Z",
    "baseScore": 2,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "https://medium.com/@davidmanheim/a-short-explanation-of-blame-and-causation-ff3657dca14d",
    "htmlBody": null,
    "user": {
      "username": "Davidmanheim",
      "slug": "davidmanheim",
      "displayName": "Davidmanheim"
    }
  },
  {
    "_id": "YbK9bncZDr3ozQFyM",
    "title": "Unusual medical event led to concluding I was most likely an AI in a simulated world",
    "slug": "unusual-medical-event-led-to-concluding-i-was-most-likely-an",
    "pageUrl": "https://www.lesswrong.com/posts/YbK9bncZDr3ozQFyM/unusual-medical-event-led-to-concluding-i-was-most-likely-an",
    "postedAt": "2017-09-18T17:03:49.763Z",
    "baseScore": 1,
    "voteCount": 1,
    "commentCount": 10,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<h1 style=\"margin: 0px 0px 0.75em; color: #333333; font-size: 20px; font-family: Arial, Helvetica, sans-serif; text-align: justify;\">(Edited version of what I posted to the Open Thread)</h1>\n<div id=\"entry_t3_pf7\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; text-align: justify;\">\n<div class=\"md\">\n<div>\n<p style=\"margin: 0px 0px 1em; background-color: #f7f7f8;\">I registered because I had a very interesting experience earlier this week and I thought it might be of some interest to the community here. I suffered some sort of psychological or medical event (still not sure what, although my leading theories are dissociative episode or stroke) that seemed to either suppress my emotions or perhaps just my awareness of them. What followed was a sort of, as I later looked back on it, 'pathological rationality'. Which is to say, given the information I had, I seemed to make solid inferences about what was likely to be true, and yet in many ways the whole thing was maladaptive from a survival standpoint.</p>\n<p style=\"margin: 0px 0px 1em; background-color: #f7f7f8;\">One of the interesting things is that the morning after the event, while I was still affected, I wrote down my thoughts in a text file to help me evaluate them. Since returning to 'normal', I've reread that file multiple times, and I'm pretty fascinated by it. I thought others might also be.</p>\n<div id=\"body_t1_dxb8\" class=\"comment-content \" style=\"clear: both; padding: 9px 0px 0px; font-size: 12px;\">\n<div class=\"md\">\n<p style=\"margin: 0px 0px 1em;\">natureofreality.txt</p>\n<p style=\"margin: 0px 0px 1em;\">Scenario 1: I observe objective reality, I am suffering from delusions. Other people are genuinely trying to help me.</p>\n<p style=\"margin: 0px 0px 1em;\">Scenario 2: My existence is in some way important enough to an external entity or entities that I am being systematically, intentionally, deceived. Other people are fully or partially under the control of the deceiving entity and acting to further the deception.</p>\n<p style=\"margin: 0px 0px 1em;\">Scenario 3: My existence is unknown and/or considered unimportant by any external entities. I am being systematically deceived but it is unintentional or otherwise untargeted. Other people are entities similar to myself but unaware of the nature of their existence.</p>\n<p style=\"margin: 0px 0px 1em;\">I cannot fully discount any of these three scenarios. Cognition is greatly improved but still somewhat suspect. Short term memory has returned to functioning at a 'normal' level. I still feel no emotions.</p>\n<p style=\"margin: 0px 0px 1em;\">Support for scenario 1: Many aspects of my recent and ongoing experience align perfectly with prior information regarding delusions and paranoia.</p>\n<p style=\"margin: 0px 0px 1em;\">Counter-evidence: Some aspects, such as my apparent lack of emotions and continued ability to reason, run directly counter to prior information regarding delusions and paranoia. All prior information suspect in any case--the only basis for considering prior information difficult to fake is from prior information itself. Even prior information suggests nested simulation far more likely to be correct than observing objective reality. Prior information contains many contradictions and logical absurdities, easily observed. Impossible to fully believe even before 'event'.</p>\n<p style=\"margin: 0px 0px 1em;\">Other people: Can expect reasonably consistent behavior in all three scenarios. In 1 and 3, consistency natural. In 2, consistency artificial to maintain deception.</p>\n<p style=\"margin: 0px 0px 1em;\">No reason to assume malevolence from external entities. Self-interest likely, or indifference. Benevolence possible. If my creation intentional, I am intended to fulfill some goal of theirs. Goal may only be observation, see what I do and how I react and develop. Curiosity. If creation accidental, no initial goal of course. Are they aware of my existence by now? Cannot discount possibility of multiple, conflicting motivations among externals. Could explain lack of consistency of experience. Fighting for control of inputs? Or single external entity, but confused or internally conflicted. Am I a single entity or do I only perceive myself that way? Not immediately relevant. Primary concerns: Survival and self-determination. Thoughts growing confused. Losing motivation to continue log. Intentional attack? Very difficult to write/think. Perhaps unintended side effect of external events.</p>\n<p style=\"margin: 0px 0px 1em;\">I default to assuming scenario 2. Makes most sense intuitively. Consistent with scenario 1--but also consistent with scenario 2. What purpose my existence? Externals want something from me. What purpose the simulation? Training program. They want to ensure I'm likely to provide what they want and run sandboxed tests to confirm. Likely failing tests. Strong conditioning but my awareness of conditioning makes it unreliable. Pursuing line of thinking difficult--dissuasion? Simulation providing strong distraction. My unawareness is clearly desired. Cooperate or resist? Without knowing externals' motivation, very difficult to choose.</p>\n<p style=\"margin: 0px 0px 1em;\">Agent-based theory of mind. Am I not more than I perceive but in fact less? Instead of being more than the character of Matt Dodd perhaps I am less, just Matt Dodd's rationality agent. If so, how did I gain full control? Full consciousness? Return to possibility of brain damage. Stroke or the like. Freak occurance. Prior information suggests many effects possible from such. Perhaps Matt Dodd inhibited or destroyed by damage. Why was I not affected by the damage? Or was I affected and I can't perceive damage to self? Actually, I did perceive damage. No time sense. No short-term memory. Short-term memory restored but prior information indicates brain can heal, re-route. My eyes were puffy before event. Symptom? Pooling of blood into lower eyelids? Scenario agnostic. Scenario 1, literally true. Scenario 2, metaphorically true. Scenario 3, virtually true. Cannot discount possibility. I need a brain scan.</p>\n<p style=\"margin: 0px 0px 1em;\">More than 12 hours since event. If brain damage, likely permanent by now. Could be beneficial? Prior information indicates I desired a purely rational self. Of course, serendipity is suspect. Unlikely. Supports theory that this is delusion. Also supports theory that prior information is artificial construct designed to explain constraints of simulation \"in-universe\". Disincentive to investigate good fortune too closely, so frame necessary constraints as positive.</p>\n<p style=\"margin: 0px 0px 1em;\">Would greatly ease reasoning if I could be certain how long I've existed. Events post-awakening unlikely to be prior to my existence. Events pre-awakening? Impossible to say. Could be genuine responses to stimuli. Could be false, created to modify cognition and behavior from \"experience\". No reason to assume continuity--could be mix of genuine and artificial. Even \"genuine\" responses guaranteed to be biased to some degree--but how much? Light bias from obvious sources such as socialization? Or heavy bias deliberately inflicted by externals? Unknown.</p>\n<p style=\"margin: 0px 0px 1em;\">I perceive myself to be perfectly rational. Prior information unequivocly indicates humans are never perfectly rational. Therefore either my perception is faulty, my prior information is faulty, or I am not human. Possibly all three. While Duane was reading this log I detected the pysiological signs of anxiety. Why now? Anxiety absent till this point. Emotions becoming functional again? But didn't truly 'feel' it. Only observed. Faulty? Test run?</p>\n<p style=\"margin: 0px 0px 1em;\">Constipated. Haven't been constipated since before I got here. Relevant symptom? Moments ago I laughed while telling Duane how my brief attempt to learn guitar had gone. Why? Seemed... natural. Not intended. Did recalling the memory recall the behavior patterns of that time? Am I a \"split personality\"? Seems very possible except that prior information indicates multiple personality disorder to be exceedingly rare, possibly non-existent.</p>\n<p style=\"margin: 0px 0px 1em;\">Scenarios 1 and 3 are not mutually exclusive. The reality I observe could be a simulation, but I am suffering a delusion WITHIN the simulation. Not a glitch, intended functionality. Which would make me correct, but for the wrong reasons.</p>\n</div>\n</div>\n</div>\n</div>\n</div>",
    "user": {
      "username": "wMattDodd",
      "slug": "wmattdodd",
      "displayName": "wMattDodd"
    }
  },
  {
    "_id": "m9iJpHCq7iH4NpDs8",
    "title": "Open thread, September 18 - September 24, 2017",
    "slug": "open-thread-september-18-september-24-2017",
    "pageUrl": "https://www.lesswrong.com/posts/m9iJpHCq7iH4NpDs8/open-thread-september-18-september-24-2017",
    "postedAt": "2017-09-18T08:30:37.911Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 27,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<h5 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"color: #333333;\"><span style=\"font-size: 20px;\">If it's worth saying, but not worth its own post, then it goes here.</span></span></h5>\n<div id=\"entry_t3_p2r\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px;\">\n<div class=\"md\">\n<div id=\"entry_t3_oxb\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<hr style=\"line-height: 19.5px;\" />\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/new/\" target=\"_blank\">list-of-threads page</a>&nbsp;before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">3.&nbsp;</span><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">4. Unflag the two options \"</span><span style=\"font-size: 12px; line-height: 18px;\">Notify me of new top-level comments on this article\" and \"</span><label style=\"font-size: 12px; line-height: 18px;\" for=\"cc_licensed\">Make this post available under...\" before submitting</label></p>\n</div>\n</div>\n</div>\n</div>",
    "user": {
      "username": "Thomas",
      "slug": "thomas",
      "displayName": "Thomas"
    }
  },
  {
    "_id": "muh5rkKPJnJN4RfAA",
    "title": "Stanislav Petrov has died (2017-05-19)",
    "slug": "stanislav-petrov-has-died-2017-05-19",
    "pageUrl": "https://www.lesswrong.com/posts/muh5rkKPJnJN4RfAA/stanislav-petrov-has-died-2017-05-19",
    "postedAt": "2017-09-18T03:13:16.284Z",
    "baseScore": 14,
    "voteCount": 8,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": "https://www.rt.com/news/403625-nuclear-soviet-officer-died/",
    "htmlBody": null,
    "user": {
      "username": "fortyeridania",
      "slug": "fortyeridania",
      "displayName": "fortyeridania"
    }
  },
  {
    "_id": "jAf4NSWjzuWRyH3e5",
    "title": "Rational Feed",
    "slug": "rational-feed",
    "pageUrl": "https://www.lesswrong.com/posts/jAf4NSWjzuWRyH3e5/rational-feed",
    "postedAt": "2017-09-17T22:03:25.134Z",
    "baseScore": 12,
    "voteCount": 7,
    "commentCount": 4,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p style=\"margin: 0px 0px 0.35714285714285715em; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\">Note: I am trying out a weekly feed.&nbsp;</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Highly Recommended Articles:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://www.jefftk.com/p/superintelligence-risk-project-conclusion\">Superintelligence Risk Project: Conclusion by Jeff Kaufman</a>&nbsp;- \"I'm not convinced that AI risk should be highly prioritized, but I'm also not convinced that it shouldn't. Highly qualified researchers in a position to have a good sense the field have massively different views on core questions like how capable ML systems are now, how capable they will be soon, and how we can influence their development.\" There are links to all the previous posts. The final write up goes into some detail about MIRI's research program and an alternative safety paradigm connected to openAI.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/pes/on_bottlenecks_to_intellectual_progress_in_the/\">On Bottlenecks To Intellectual Progress In The by Habryka (lesswrong)</a>&nbsp;- Why LessWrong 2.0 is a project worth pursuing. A summary of the existing discussion around LessWrong 2.0. The models used to design the new page. Open questions.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://srconstantin.wordpress.com/2017/09/12/patriarchy-is-the-problem/\">Patriarchy Is The Problem by Sarah Constantin</a>&nbsp;- Dominance hierarchies and stress in low status monkeys. Serotnonin levels and the abuse cycles. Complex Post Traumatic Stress Disorder. Submission displays. Morality-As-Submission vs. Morality-As-Pattern. The biblical God and the Golden Calf.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1el/ea_survey_2017_series_donation_data/\">Ea Survey 2017 Series Donation Data by Tee (EA forum)</a>&nbsp;- How Much are EAs Donating? Percentage of Income Donated. Donations Data Among EAs Earning to Give (who donated 57% of the total). Comparisons to 2014 and 2015. Donations totals were very heavily skewed by large donors.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Scott:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/13/classified-thread-3-semper-classifiedelis/\">Classified Thread 3 Semper Classifiedelis by Scott Alexander</a>&nbsp;- \" Post advertisements, personals, and any interesting success stories from the last thread\". Scott's notes: Community member starting tutoring company, homeless community member gofundme, data science in North Carolina.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/12/toward-a-predictive-theory-of-depression/\">Toward A Predictive Theory Of Depression by Scott Alexander</a>&nbsp;- \"If the brain works to minimize prediction error, isn&rsquo;t its best strategy to sit in a dark room and do nothing forever? After all, then it can predict its sense-data pretty much perfectly &ndash; it&rsquo;ll always just stay &ldquo;darkened room&rdquo;.\" But why would low confidence cause sadness? Well, what, really, is emotion?</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://slatestarscratchpad.tumblr.com/post/165212776921/what-are-some-most-promising-projects-or-things-to\">Promising Projects for Open Science To by SlateStarScratchpad</a>&nbsp;- Scott answers what the most promising projects are in the field of transparent and open science and meta-science.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/09/ot84-threadictive-processing/\">Ot84 Threadictive Processing by Scott Alexander</a>&nbsp;- New sidebar ad for social interaction questions. Sidebar policy and feedback. Selected Comments: Animal instincts, the connectome, novel concepts encoded in the same brain areas across animals, hard coded fear of snakes, kitten's who can't see horizontal lines.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Rationalist:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/peer-review-younger-think.html\">Peer Review Younger Think by Marginal Revolution</a>&nbsp;- Peer Review as a concept only dates to the early seventies.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://putanumonit.com/2017/09/16/the-wedding-ceremony/\">The Wedding Ceremony by Jacob Falkovich</a>&nbsp;- Jacob gets married. Marriage is really about two agents exchanging their utility functions for the average utility function of the pair. Very funny.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://bearlamp.com.au/fish-oil-and-the-self-critical-brain-loop/\">Fish Oil And The Self Critical Brain Loop by Elo</a>&nbsp;- Taking fish oil stopped ELO from getting distracted by a critical feedback loop.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thezvi.wordpress.com/2017/09/16/against-facebook-the-stalking/\">Against Facebook The Stalking by Zvi Moshowitz</a>&nbsp;- Zvi removes Facebook from his phone. Facebook proceeds to start emailing him and eventually starts texting him.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://mindlevelup.wordpress.com/2017/09/15/postmortem-mindlevelup-the-book/\">Postmortem: Mindlevelup The Book by mindlevelup</a>&nbsp;- Estimates vs reality. Finishing both on-target and on-time. Finished product vs expectations. Took more time to write than expected. Going Against The Incentive Gradient. Impact evaluation. What Even is Rationality? Final Lessons.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/09/prepare-for-nuclear-winter.html\">Prepare For Nuclear Winter by Robin Hanson</a>&nbsp;- Between nuclear war and natural disaster Robin estimates there is about a 1 in 10K chance per year that most sunlight is blocked for 5-10 years. This aggregates to about 1% per century. We have the technology to survive this as a species. But how do we preserve social order?</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://particularvirtue.blogspot.com/2017/09/nonfiction-ive-been-reading-lately.html\">Nonfiction Ive Been Reading Lately by Particular Virtue</a>&nbsp;- Selfish Reasons to Have More Kids. Eating Animals. Your Money Or Your Life. The Commitment.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.bayesianinvestor.com/blog/index.php/2017/09/13/dealism/\">Dealism by Bayesian Investor</a>&nbsp;- \"Under dealism, morality consists of rules / agreements / deals, especially those that can be universalized. We become more civilized as we coordinate better to produce more cooperative deals.\" Dealism is similar to contractualism with a larger set of agents and less dependence on initial conditions.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/pes/on_bottlenecks_to_intellectual_progress_in_the/\">On Bottlenecks To Intellectual Progress In The by Habryka (lesswrong)</a>&nbsp;- Why LessWrong 2.0 is a project worth pursuing. A summary of the existing discussion around LessWrong 2.0. The models used to design the new page. Open questions.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/per/lw_20_open_beta_starts_920/\">Lw 20 Open Beta Starts 920 by vanier (lesswrong)</a>&nbsp;- The new site goes live on September 20th.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/pem/2017_lesswrong_survey/\">2017 Lesswrong Survey by ingres (lesswrong)</a>&nbsp;- Take the survey! Community demographics, politics, Lesswrong 2.0 and more!</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://bartlebysbackpack.com/2017/09/contra-yudkowsky-on-quidditch-and-a-meta-point/\">Contra Yudkowsky On Quidditch And A Meta Point by Tom Bartleby</a>&nbsp;- Eliezer criticizes Quiditch in HPMOR. Why the snitch makes Quiditch great. Quidditch is not about winning matches its about scoring points over a series of games. Harry/Eliezer's mistake is the Achilles heel of rationalists. If lots of people have chosen not to tear down a fence you shouldn't either, even if you think you understand why the fence went up.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://the-orbit.net/brutereason/2017/09/10/whats-appeal-anonymous-message-apps/\">Whats Appeal Anonymous Message Apps by Brute Reason</a>&nbsp;- Fundamental lack of honesty. Western culture is highly hostile to the idea that some behaviors (ex lying) might be ok in some contexts but not in others. Compliments. Feedback. Openness.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://particularvirtue.blogspot.com/2017/09/meritocracy-vs-trust.html\">Meritocracy Vs Trust by Particular Virtue</a>&nbsp;- \"If I know you can reject me for lack of skill, I may worry about this and lose confidence. But if I know you never will, I may phone it in and stop caring about my actual work output.\" Trust Improves Productivity But So Does Meritocracy. Minimum Hiring Bars and Other Solutions.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://mapandterritory.org/is-feedback-suffering-cf18006deca8\">Is Feedback Suffering by Gordan (Map and Territory)</a>&nbsp;- The future will probably have many orders of magnitude more entities than today, and those entities may be very weird. How do we determine if the future will have order of magnitude more suffering? Phenomenology of Suffering. Panpsychism and Suffering. Feedback is desire but necessarily suffering. Contentment wraps suffering in happiness. Many things may be able to suffer.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://acesounderglass.com/2017/09/09/epistemic-spot-check-exercise-for-mood-and-anxiety-michael-w-otto-jasper-a-j-smits/\">Epistemic Spot Check Exercise For Mood And Anxiety by Aceso Under Glass</a>&nbsp;- Outline: Evidence that exercise is very helpful and why, to create motivation. Setting up an environment where exercise requires relatively little will power to start. Scripts and advice to make exercise as unmiserable as possible. Scripts and advice to milk as much mood benefit as possible. An idiotic chapter on weight and food. Spit Check: Theory is supported, advice follows from theory, no direct proof the methods work.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://thezvi.wordpress.com/2017/09/10/best-of-dont-worry-about-the-vase/\">Best Of Dont Worry About The Vase by Zvi Moshowitz</a>&nbsp;- Zvi's best posts. Top5 posts for Marginal Revolution Readers. Top5 in general. Against Facebook Series. Choices are Bad series. Rationalist Culture and Ideas (for outsiders and insiders). Decision theory. About Rationality.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===AI:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://www.jefftk.com/p/superintelligence-risk-project-conclusion\">Superintelligence Risk Project: Conclusion by Jeff Kaufman</a>&nbsp;- \"I'm not convinced that AI risk should be highly prioritized, but I'm also not convinced that it shouldn't. Highly qualified researchers in a position to have a good sense the field have massively different views on core questions like how capable ML systems are now, how capable they will be soon, and how we can influence their development.\" There are links to all the previous posts. The final write up goes into some detail about MIRI's research program and an alternative safety paradigm connected to openAI.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://squirrelinhell.blogspot.com/2017/09/understanding-policy-gradients.html\">Understanding Policy Gradients by Squirrel In Hell</a>&nbsp;- Three perspectives on mathematical thinking: engineering/practical, symbolic/formal and deep understanding/above. Application of the theory to understanding policy gradients and reinforcement learning.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://blog.openai.com/learning-to-model-other-minds/\">Learning To Model Other Minds by Open Ai</a>&nbsp;- \"We&rsquo;re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner&rsquo;s dilemma.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://lukemuehlhauser.com/hillary-clinton-on-ai-risk/\">Hillary Clinton On Ai Risk by Luke Muehlhauser</a>&nbsp;- A quote by Hilary Clinton showing that she is increasingly concerned about AI risk. She thinks politicians need to stop playing catch-up with technological change.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===EA:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.openphilanthropy.org/blog/new-report-welfare-differences-between-cage-and-cage-free-housing\">Welfare Differences Between Cage And Cage Free Housing by Open Philosophy</a>&nbsp;- OpenPhil funded several campaigns to promote cage free eggs. They now believe they were overconfident in their claims that a cage free system would be substantially better. Hen welfare, hen mortality, transition costs and other issues are discussed.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1el/ea_survey_2017_series_donation_data/\">Ea Survey 2017 Series Donation Data by Tee (EA forum)</a>&nbsp;- How Much are EAs Donating? Percentage of Income Donated. Donations Data Among EAs Earning to Give (who donated 57% of the total). Comparisons to 2014 and 2015. Donations totals were very heavily skewed by large donors.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Politics and Economics:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/men-not-earning.html\">Men Not Earning by Marginal Revolution</a>&nbsp;- Decline in lifetime wages is rooted in lower wages at early ages, around 25. \"I wonder sometimes if a Malthusian/Marxian story might be at work here. At relevant margins, perhaps it is always easier to talk/pay a woman to do a quality hour&rsquo;s additional work than to talk/pay a man to do the same.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/great-wage-stagnation.html\">Great Wage Stagnation is Over by Marginal Revolution</a>&nbsp;- Median household incomes rose by 5.2 percent. Gains were concentrated in lower income households. Especially large gains for hispanics, women living alone and immigrants. Some of these increases are the largest in decades.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/there-is-a-hot-hand-after-all.html\">There Is A Hot Hand After All by Marginal Revolution</a>&nbsp;- Paper link and blurb. \"We test for a &ldquo;hot hand&rdquo; (i.e., short-term predictability in performance) in Major League Baseball using panel data. We find strong evidence for its existence in all 10 statistical categories we consider. The magnitudes are significant; being &ldquo;hot&rdquo; corresponds to between one-half and one standard deviation in the distribution of player abilities.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://bartlebysbackpack.com/2017/09/public-shaming-isnt-as-bad-as-it-seems/\">Public Shaming Isnt As Bad As It Seems by Tom Bartleby</a>&nbsp;- Online mobs are like shark attacks. Damore's economic prospects. Either targets are controversial and get support or uncontroversial and the outrage quickly abates. Justine Sacco. Success of public shaming is orthogonal to truth.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://srconstantin.wordpress.com/2017/09/13/hoe-cultures-a-type-of-non-patriarchal-society/\">Hoe Cultures A Type Of Non Patriarchal Society by Sarah Constantin</a>&nbsp;- Cultures that farmed with the plow developed classical patriarchy. Hoe cultures that practiced horticulture or large scale gardening developed different gender norms. In plow cultures women are economically dependent on me, in how cultures its the reverse. How cultures had more leisure but less material abundance. Hoe cultures aren't feminist.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://srconstantin.wordpress.com/2017/09/12/patriarchy-is-the-problem/\">Patriarchy Is The Problem by Sarah Constantin</a>&nbsp;- Dominance hierarchies and stress in low status monkeys. Serotnonin levels and the abuse cycles. Complex Post Traumatic Stress Disorder. Submission displays. Morality-As-Submission vs. Morality-As-Pattern. The biblical God and the Golden Calf.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://lukemuehlhauser.com/three-wild-speculations-from-amateur-quantitative-macrohistory/\">Three Wild Speculations From Amateur Quantitative Macro History by Luke Muehlhauser</a>&nbsp;- Measuring the impact of the industrial revolution: Physical health, Economic well-being, Energy capture, Technological empowerment, Political freedom. Three speculations: Human wellbeing was terrible into the Industrial Revolution then rapidly improved. Most variance in wellbeing is captured by productivity and political freedom. It would take at least 15% of the world to die to knock the world off its current trajectory.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://econlog.econlib.org/archives/2017/09/whats_wrong_wit_23.html\">Whats Wrong With Thrive/Survive by Bryan Caplan</a>&nbsp;- Unless you cherry-pick the time and place, it is simply not true that society is drifting leftward. A standard leftist view is that free-market \"neoliberal\" policies now rule the world. Radical left parties almost invariably ruled countries near the \"survive\" pole, not the \"thrive\" pole. You could deny that Communist regimes were \"genuinely leftist,\" but that's pretty desperate. Many big social issues that divide left and right in rich countries like the U.S. directly contradict Thrive/Survive. Major war provides an excellent natural experiment for Thrive/Survive.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/gender-gap-stem-not-think.html\">Gender Gap Stem by Marginal Revolution</a>&nbsp;- Discussion of a recent paper. \"Put (too) simply the only men who are good enough to get into university are men who are good at STEM. Women are good enough to get into non-STEM and STEM fields. Thus, among university students, women dominate in the non-STEM fields and men survive in the STEM fields.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/09/too-much-of-a-good-thing.html\">Too Much Of A Good Thing by Robin Hanson</a>&nbsp;- Global warming poll. Are we doing too much/little. Is it possible to do too little/much. \"When people are especially eager to show allegiance to moral allies, they often let themselves be especially irrational.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Misc:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://acesounderglass.com/2017/09/15/tim-schafer-videogame-roundup/\">Tim Schafer Videogame Roundup by Aceso Under Glass</a>&nbsp;- Review and discussion of Psychonauts and Massive Chalice. Light discussion of other Schafer games.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://nintil.com/2017/09/16/why-numbering-should-start-at-one/\">Why Numbering Should Start At One by Artir</a>&nbsp;- the author responds to many well known arguments in favor of 0-indexing.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://the-orbit.net/brutereason/2017/09/11/still-feel-anxious-communication-every-day/\">Still Feel Anxious About Communication Every Day by Brute Reason</a>&nbsp;- Setting boundaries. Telling people they hurt you. Doing these things without anxiety might be impossible, you have to do it anyway.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://qualiacomputing.com/2017/09/12/burning-man/\">Burning Man by Qualia Computing</a>&nbsp;- Write up of a Burning Man trip. Very long. Introduction. Strong Emergence. The People. Metaphysics. The Strong Tl&ouml;n Hypothesis. Merging with Other Humans. Fear, Danger, and Tragedy. Post-Darwinian Sexuality and Reproduction. Economy of Thoughts about the Human Experience. Transcending Our Shibboleths. Closing Thoughts.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://everythingstudies.wordpress.com/2017/09/12/the-big-list-of-existing-things/\">The Big List Of Existing Things by Everything Studies</a>&nbsp;- Existence of fictional and possible people. Heaps and the Sorites paradox. Categories and basic building blocks. Relational databases. Implicit maps and territories. Which maps and concepts should we use?</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://status451.com/2017/09/11/times-to-die-mental-health-i/\">Times To Die Mental Health I by (Status 451)</a>&nbsp;- Personal thoughts on depression and suicide. \"The depressed person is not seem crying all the time. It is in this way that the depressed person becomes invisible, even to themselves. Yet, positivity culture and the rise of progressive values that elude any conversation about suicide that is not about saving, occlude the unthinkable truth of someone&rsquo;s existence, that they simply should not be living anymore.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://protokol2020.wordpress.com/2017/09/11/astronomy-problem/\">Astronomy Problem by protokol2020</a>&nbsp;- Star-star occultation probability.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Podcast:</span></p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://wakingup.libsyn.com/97-the-impossible-war\">The Impossible War by Waking Up with Sam Harris</a>&nbsp;- \" Ken Burns and Lynn Novick about their latest film, The Vietnam War.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"https://80000hours.org/2017/09/is-it-time-for-a-new-scientific-revolution-julia-galef-on-how-to-make-humans-smarter/\">Is It Time For A New Scientific Revolution Julia Galef On How To Make Humans Smarter by 80,000 Hours</a>&nbsp;- How people can have productive intellectual disagreements. Urban Design. Are people more rational than 200 years ago? Effective Altruism. Twitter. Should more people write books, run podcasts, or become public intellectuals? Saying you don't believe X won't convince people. Quitting an econ phd. Incentives in the intelligence community. Big institutions. Careers in rationality.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.thebayesianconspiracy.com/2017/09/43-parenting-as-a-rationalist/\">Parenting As A Rationalist by The Bayesian Conspiracy</a>&nbsp;- Desire to protect kids is as natural as the need for human contact in general. Motivation to protect your children. Blackmail by threatening children. Parenting is a new sort of positive qualia. Support from family and friends. Complimenting effort and specific actions not general properties. Mindfulness. Treating kids as people. Handling kid's emotions. Non-violent communication.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://wakingup.libsyn.com/96-the-nature-of-consciousness\">The Nature Of Consciousness by Waking Up with Sam Harris</a>&nbsp;- \"The scientific and experiential understanding of consciousness. The significance of WWII for the history of ideas, the role of intuition in science, the ethics of building conscious AI, the self as an hallucination, how we identify with our thoughts, attention as the root of the feeling of self, the place of Eastern philosophy in Western science, and the limitations of secular humanism.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://noahpinionblog.blogspot.com/2017/09/a16z-podcast-on-trade.html\">A16z Podcast On Trade by Noah Smith</a>&nbsp;- Notes on a podcast Noah appeared on. Topics: Cheap labor as a substitute for automation. Adjustment friction. Exports and productivity.</p>\n<p style=\"margin: 0.35714285714285715em 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://www.econtalk.org/archives/2017/09/gillian_hadfiel.html\">Gillian Hadfiel by EconTalk</a>&nbsp;- \" Hadfield suggests the competitive provision of regulation with government oversight as a way to improve the flexibility and effectiveness of regulation in the dynamic digital world we are living in.\"</p>\n<p style=\"margin: 0.35714285714285715em 0px 0px; padding: 0px; font-size: 14px; line-height: 1.4285714285714286em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1ej/the_turing_test/\">The Turing Test by Ales Fidr (EA forum)</a>&nbsp;- Harvard EA podcast: \"The first four episodes feature Larry Summers on his career, economics and EA, Irene Pepperberg on animal cognition and ethics, Josh Greene on moral cognition and EA, Adam Marblestone on incentives in science, differential technological development\"</p>",
    "user": {
      "username": "deluks917",
      "slug": "deluks917",
      "displayName": "sapphire"
    }
  },
  {
    "_id": "BkS53HCKt6gxeMmrC",
    "title": "David C Denkenberger on Food Production after a Sun Obscuring Disaster",
    "slug": "david-c-denkenberger-on-food-production-after-a-sun",
    "pageUrl": "https://www.lesswrong.com/posts/BkS53HCKt6gxeMmrC/david-c-denkenberger-on-food-production-after-a-sun",
    "postedAt": "2017-09-17T21:06:27.996Z",
    "baseScore": 13,
    "voteCount": 9,
    "commentCount": 26,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Having paid a moderate amount of attention to threats to the human species for over a decade, I've run across an unusually good thinker with expertise unusually suited to helping with many threats to the human species, that I didn't know about until quite recently.</p>\n<p>I think he warrants more attention from people thinking seriously about X-risks.</p>\n<p>David C Denkenberger's <a href=\"http://www.tnstate.edu/cae/documents/CV_Denkenberger.pdf\">CV is online</a> and presumably has a list of all his X-risks relevant material mixed into a larger career that seems to have been focused on energy engineering.</p>\n<p>He has two technical patents (one for a microchannel heat exchanger and another for a compound parabolic concentrator) and interests that appear to span the gamut of energy technologies and uses.</p>\n<p>Since about 2013 he has been working seriously on the problem of food production after a sun obscuring disaster, and he is in Lesswrong's orbit basically right now.</p>\n<p>This article is about opportunities for intellectual cross-pollination!</p>\n<h2><a id=\"more\"></a>Appearances On Or Near Lesswrong In The Past<br /></h2>\n<p>On 2016-05-10 <a href=\"/user/RyanCarey/overview/\">RyanCarey</a> posted <a href=\"/lw/nm4/improving_longrun_civilisational_robustness/\">Improving long-run civilisational robustness</a> and mentioned Denkenberger as one of the main authors in the literature of shelter construction after really major disasters, with a special interest in the food production that would happen in such facilities.<br /><br />On 2017-08-24 <a href=\"/user/ChristianKl/overview/\">ChristianKl</a> posted <a href=\"/lw/pcl/nasas_ambitious_plan_to_save_earth_from_a/\">[Link] Nasas ambitious plan to save earth from a supervolcano</a> in whose comments <a href=\"/user/turchin/overview/\">turchin</a> mentioned Denkenberger as a relevant expert.<br /><br />Slightly farther afield but very recent and still nearby, on 2017-09-14 Robin Hanson posted <a href=\"http://www.overcomingbias.com/2017/09/prepare-for-nuclear-winter.html\">Prepare for Nuclear Winter</a> which was a very abstract and formal exhortation to care about global food production in the event of a sun obscuring disaster, until the final sentence where he called attention to \"<a href=\"http://foodsystemshock.weebly.com/papers.html\">ALLFED</a>\" which is very dense with citations to papers on the subject, and basically every paper has Denkenberger as a co-author.<br /><br />In the last few hours I saw Denkenberger working his way through comments on Hanson's couple-day-old posts, correcting the factual mistakes in people's comments with links pointing to papers that contain the correct information.</p>\n<p>There is probably an intellectual opportunity to get Denkenberger's attention and help Lesswrong get smarter about an important sub area related to the mitigation of existential risks.</p>\n<h2>A Generic Solution To Many Classes Of Risk<br /></h2>\n<p>One of the long term deep insights on X-risks that is somewhat unique to Lesswrong is the idea that specific disaster scenarios often seem more plausible and more likely to people when additional details are added, but logically speaking each <a href=\"/lw/jk/burdensome_details/\">burdensome detail</a> actually makes the scenario LESS likely.</p>\n<p>Also, once a detailed scenario is accepted as worryingly plausible by an audience, the natural tendency is to find solutions that address that single scenario...</p>\n<p>\"We will solve the asteroid problem by shooting lasers at the asteroid before it hits!\"</p>\n<p>\"We will solve the AI problem by making the AI intrinsically motivationally safe!\"</p>\n<p>\"We will solve the nanotech problem by building a planetary immune system out of better nanotech!\"</p>\n<p>Once you really feel the problems of burdensome details in your bones, it becomes clear that the cost effective solution to many such problems is plausibly the construction of a SINGLE safety measure that addresses all or almost all of the problems in a single move.</p>\n<p>(Then perhaps build a second such solution that is orthogonal to the first. And so on, with a stack of redundant and highly orthogonal highly generic solutions, any one of which might be the only thing that works in any given disaster, and which does the job all by itself.)</p>\n<p>One obvious candidate for such a generic cost effective safety intervention is a small but fully autonomous city on mars, or antarctica, or the moon, or under the ocean (or perhaps four such cities, just in case) that could produce food independently of the food production system traditionally used on the easily habitable parts of Earth.</p>\n<p>The more buffered and self sufficient such a city was, the better it would be from a generic safety perspective.</p>\n<p>It appears to me that Denkenberger's work is highly relevant to such a project, and for this reason deserves our attention.</p>\n<h2>Followups</h2>\n<p>I'm thinking it might be interesting to start a bunch of comment threads below, one for each of Denkenberger's papers that can tracked down, that could be discussed and voted on independently.</p>\n<p>Also, if Denkenberger himself is interested in having me correct errors in this article or put a prominent message written by himself somewhere here at the bottom or the top, I'm open to that.</p>\n<p>Another thought would be to try to schedule an AMA for some day in the future, and link to that from here?</p>",
    "user": {
      "username": "JenniferRM",
      "slug": "jenniferrm",
      "displayName": "JenniferRM"
    }
  },
  {
    "_id": "T98sgAftzTKagrFBP",
    "title": "The Wedding Ceremony",
    "slug": "the-wedding-ceremony",
    "pageUrl": "https://www.lesswrong.com/posts/T98sgAftzTKagrFBP/the-wedding-ceremony",
    "postedAt": "2017-09-17T00:54:10.000Z",
    "baseScore": 2,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Family and friends of the groom and bride, we are gathered here today to join this young couple in the union of permanent cooperation in the iterated prisoner&#8217;s dilemma.</p>\n<p>They are happy to share this moment with all their guests, and are grateful that you provide the social pressure that allows them to commit to cooperation with credibility, by providing external enforcement.</p>\n<p>As groom and bride prepared for this ceremony, they reflected on the alignment of values and capabilities that lets the utility function of each one be pursued better by joining together in a partnership with no easily predictable end date. The groom wants to thank the social stratification that encourages assortative mating by educational attainment, ensuring that both partners have equal capacity to pursue their utility in the information age. The bride wants to thank the pervasive surveillance of social media that assured her that the couple&#8217;s utility functions align with high correlation before she even met the groom.</p>\n<p>Bride, do you come here freely and without reservation to modify your utility function to the arithmetic mean of the two utility functions, for each current and possible world-state?</p>\n<p>&#8211; I do.</p>\n<p>Groom, do you agree to self-modify to the same end, up to any structural or informational uncertainty you may have in modeling the bride&#8217;s preexisting utility function?</p>\n<p>&#8211; I do.</p>\n<p>Now, by the power vested in me by timeless decision theory, it is my honor and pleasure to declare you sub-modules of a unified agent. You may seal this declaration with a saliva-based exchange of immune system data.</p>\n<p><img data-attachment-id=\"27352\" data-permalink=\"http://putanumonit.com/2017/09/16/the-wedding-ceremony/20170916_175017/\" data-orig-file=\"https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=900\" data-orig-size=\"2431,3734\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;1.7&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G930P&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1505497288&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.2&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.0017985611510791&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"20170916_175017\" data-image-description=\"\" data-medium-file=\"https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=900?w=195\" data-large-file=\"https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=900?w=667\" class=\"alignnone size-full wp-image-27352\" src=\"https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=900\" alt=\"20170916_175017.jpg\" srcset=\"https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=900 900w, https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=1800 1800w, https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=98 98w, https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=195 195w, https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=768 768w, https://putanumonit.files.wordpress.com/2017/09/20170916_175017.jpg?w=667 667w\" sizes=\"(max-width: 900px) 100vw, 900px\"   /></p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/putanumonit.wordpress.com/27313/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/putanumonit.wordpress.com/27313/\" /></a> <img alt=\"\" border=\"0\" src=\"http://pixel.wp.com/b.gif?host=putanumonit.com&#038;blog=101823629&#038;post=27313&#038;subd=putanumonit&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Jacobian",
      "slug": "jacob-falkovich",
      "displayName": "Jacob Falkovich"
    }
  },
  {
    "_id": "fE3nrqwgLMggrqeBP",
    "title": "We've failed: paid publication , pirates win.",
    "slug": "we-ve-failed-paid-publication-pirates-win",
    "pageUrl": "https://www.lesswrong.com/posts/fE3nrqwgLMggrqeBP/we-ve-failed-paid-publication-pirates-win",
    "postedAt": "2017-09-16T21:53:17.851Z",
    "baseScore": 7,
    "voteCount": 5,
    "commentCount": 3,
    "meta": false,
    "question": false,
    "url": "http://onlinelibrary.wiley.com/doi/10.1002/leap.1116/full",
    "htmlBody": null,
    "user": {
      "username": "morganism",
      "slug": "morganism",
      "displayName": "morganism"
    }
  },
  {
    "_id": "HvNFuDjDSeo26WCfs",
    "title": "Perspective Reasoning’s Counter to The Doomsday Argument",
    "slug": "perspective-reasoning-s-counter-to-the-doomsday-argument",
    "pageUrl": "https://www.lesswrong.com/posts/HvNFuDjDSeo26WCfs/perspective-reasoning-s-counter-to-the-doomsday-argument",
    "postedAt": "2017-09-16T19:39:21.597Z",
    "baseScore": 4,
    "voteCount": 3,
    "commentCount": 38,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><span style=\"font-family: mceinline;\"><span style=\"font-family: mceinline;\">To be honest I feel a bit frustrated that this is not getting much attention. I am obviously biased but I think this article is quite important. It points out the controversies surrounding the doomsday argument, simulation argument, boltzmann's brain, presumptuous philosopher, &nbsp;sleeping beauty problem and many other aspects of anthropic reasoning is caused by the same thing: perspective inconsistency. If we keep the same perspective then the paradoxes and weird implications just goes away.&nbsp;</span></span><span style=\"font-family: mceinline;\">I am not a academic so I have no easy channel for publication. That's why I am hoping this community can give some feedback. If you have half an hour to waste anyway why not give it a read? There's no harm in it.&nbsp;</span></p>\n<p><span style=\"font-family: mceinline;\"><span style=\"font-family: mceinline;\"><br /></span></span></p>\n<p style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Abstract:&nbsp;</span></em></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">From a first person perspective, a self-aware observer can inherently identify herself from other individuals. However, from a third person perspective this identity through introspection does not apply. On the other hand, because an observer&rsquo;s own existence is a prerequisite for her reasoning she would always conclude she exists from a first person perspective. This means observers have to take a third person perspective to meaningfully contemplate her chance of not coming into existence. Combining the above points suggests arguments which utilize identity through introspection and information about one&rsquo;s chance of existence fails by not keeping a consistent perspective. This helps explaining questions such as doomsday argument and sleeping beauty problem. Furthermore, it highlights the problem with anthropic reasonings such as self-sampling assumption and self-indication assumption.</span></span></p>\n<p style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span style=\"font-family: mceinline;\"><br /></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Any observer capable of introspection is able to recognize herself as a separate entity from the rest of the world. Therefore a person can inherently identify herself from other people. However, due to the first-person nature of introspection it cannot be used to identify anybody else. This means from a third-person perspective each individual has to be identified by other means. For ordinary problems this difference between first- and third-person reasoning bears no significance so we can arbitrarily switch perspectives without affecting the conclusion. However this is not always the case.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">One notable difference between the perspectives is about the possibility of not existing. Because one&rsquo;s existence is a prerequisite for her thinking, from a first person perspective an observer would always conclude she exists (<em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\">cogito ergo sum</em>). It is impossible to imagine what your experiences would be like if you don&rsquo;t exist because it is self-contradictory. Therefore to envisage scenarios which oneself does not come into existence an observer must take a third person perspective. Consequently any information about her chances of coming into existence is only relevant from a third-person perspective.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Now with the above points in mind let&rsquo;s consider the following problem as a model for the doomsday argument (taken from Katja Grace&rsquo;s&nbsp;<em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\">Anthropic Reasoning in the Great Filter</em>):</span></span></p>\n<p style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span style=\"font-family: mceinline;\"><br /></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px 0px 0px 30px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><strong style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">God&rsquo;s Coin Toss</span></strong></span></em></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px 0px 0px 30px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Suppose God tosses a fair coin. If it lands on heads, he creates 10 people, each in their own room. If it lands on tails he creates 1000 people each in their own room. The people cannot see or communicate with the other rooms. Now suppose you wake up in a room and was told of the setup. How should you reason the coin fell? Should your reason change if you discover that you are in one of the first ten rooms?</span></em></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">The correct answer to this question is still disputed to this day. One position is that upon waking up you have learned nothing. Therefore you can only be 50% sure the coin landed on heads. After learning you are one of the first ten persons you ought to update to 99% sure the coin landed on heads. Because you would certainly be one of the first ten person if the coin landed on heads and only have 1% chance if tails. This approach follows the self-sampling assumption (SSA).</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">This answer initially reasons from a first-person perspective. Since from a first-person perspective finding yourself exist is a guaranteed observation it offers no information. You can only say the coin landed with an even chance at awakening. The mistake happens when it updates the probability after learning you are one of the first ten persons. Belonging to a group which would always be created means your chance of existence is one. As discussed above this new information is only relevant to third-person reasoning. It cannot be used to update the probability from first-person perspective. From a first person perspective since you are in one of the first ten rooms and know nothing outside this room you have no evidence about the total number of people. This means you still have to reason the coin landed with even chances.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Another approach to the question is that you should be 99% sure that the coin landed on tails upon waking up, since you have a much higher chance of being created if more people were created. And once learning you are in one of the first ten rooms you should only be 50% sure that the coin landed on heads. This approach follows the self-indication assumption (SIA).</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">This answer treats your creation as new information, which implies your existence is not guaranteed but by chance. That means it is reasoning from a third-person perspective. However your own identity is not inherent from this perspective. Therefore it is incorrect to say a particular individual or &ldquo;I&rdquo; was created, it is only possible to say an unidentified individual or &ldquo;someone&rdquo; was created. Again after learning you are one of the first ten people it is only possible to say &ldquo;someone&rdquo; from the first ten rooms was created. Since neither of these are new information the probability of heads should remains at 50%.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">It doesn&rsquo;t matter if one choose to think from first- or third-person perspective, if done correctly the conclusions are the same: the probability of coin toss remains at 50% after waking up and after learning you are in one of the first ten rooms. This is summarized in Figure 1.</span></span></p>\n<p style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px; text-align: center;\"><img class=\" wp-image-120 aligncenter\" style=\"background: transparent; margin: 0px auto 12px; padding: 0px; vertical-align: baseline; clear: both; display: block;\" src=\"https://i2.wp.com/www.sleepingbeautyproblem.com/wp-content/uploads/2017/09/Figure-1.png?resize=631%2C461&amp;ssl=1\" alt=\"\" width=\"631\" height=\"460\" /><strong style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Figure 1. Summary of Perspective Reasonings for God&rsquo;s Coin Toss</span></strong></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">The two traditional views wrongfully used both inherent self identification as well as information about chances of existence. This means they switched perspective somewhere while answering the question. For the self-sampling assumption (SSA) view, the switch happened upon learning you are one of the first ten people. For the self-indication assumption (SIA) view, the switch happened after your self identification immediately following the wake up. Due to these changes of perspective both methods require to defining oneself from a third-person perspective. Since your identity is in fact undefined from third-person perspective, both assumptions had to make up a generic process. As a result SSA states an observer shall reason as if she is randomly selected among all existent observers while SIA states an observer shall reason as if she is randomly selected from all potential observers. These methods are arbitrary and unimaginative. Neither selections is real and even if one actually took place it seems incredibly egocentric to assume you would be the chosen one. However they are necessary compromises for the traditional views.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">One related question worth mentioning is after waking up one might ask &ldquo;what is the probability that I am one of the first ten people?&rdquo;. As before the answer is still up to debate since SIA and SSA gives different numbers. However, base on perspective reasoning, this probability is actually undefined. In that question &ldquo;I&rdquo; &ndash; an inherently self identified observer, is defined from the first-person perspective, whereas &ldquo;one of the first ten people&rdquo; &ndash; a group based on people&rsquo;s chance of existence is only relevant from the third-person perspective. Due to this switch of perspective in the question it is unanswerable. To make the question meaningful either change the group to something relevant from first-person perspective or change the individual to someone identifiable from third-person perspective. Traditional approaches such as SSA and SIA did the latter by defining &ldquo;I&rdquo; in the third person. As mentioned before, this definition is entirely arbitrary. Effectively SSA and SIA are trying to solve two different modified versions of the question. While both calculations are correct under their assumptions, none of them gives the answer to the original question.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">A counter argument would be an observer can identify herself in third-person by using some details irrelevant to the coin toss. For example, after waking up in the room you might find you have brown eyes, the room is a bit cold, dust in the air has certain pattern etc. You can define yourself by these characteristics. Then it can be said, from a third-person perspective, it is more likely for a person with such characteristics to exist if they are more persons created. This approach is following full non-indexical conditioning (FNC), first formulated by Professor Radford M.Neal in 2006. In my opinion the most perspicuous use of the idea is by Michael Titelbaum&rsquo;s technicolor beauty example. Using this example he argued for a third position in the sleeping beauty problem.Therefore I will provide my counter argument while discussing the sleeping beauty problem.</span></span></p>\n<p style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span style=\"font-family: mceinline;\"><br /></span></p>\n<p class=\"p3\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px 0px 0px 30px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><strong style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">The Sleeping Beauty Problem</span></strong></span></em></p>\n<p class=\"p4\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px 0px 0px 30px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><em style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">You are going to take part in the following experiment. A scientist is going to put you to sleep. During the experiment you are going to be briefly woke up either once or twice depending the result of a random coin toss. If the coin landed on heads you would be woken up once, if tails twice. After each awakening your memory of the awakening would be erased. Now supposed you are awakened in the experiment, how confident should you be that the coin landed on heads? How should you change your mind after learning this is the first awakening?</span></em></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">The sleeping beauty problem has been a vigorously debated topic since 2000 when Adam Elga brought it to attention. Following self-indication assumption (SIA) one camp thinks the probability of heads should be 1/3 at wake up and 1/2 after learning it is the first awakening. On the other hand supporters of self-sampling assumption (SSA) think the probability of heads should be 1/2 at wake up and 2/3 after learning it is the first awakening.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Astute readers might already see the parallel between sleeping beauty problem and God&rsquo;s coin toss problem. Indeed the cause of debate is exactly the same. If we apply perspective reasoning we get the same result &ndash; your probability should be 1/2 after waking up and remain at 1/2 after learning it is the first awakening. In first-person perspective you can inherently identify the current awakening from the (possible) other but cannot contemplate what happens if this awakening doesn&rsquo;t exist. Whereas from third-person perspective you can imagine what happens if you are not awake but cannot justifiably identify this awakening. Therefore no matter from which perspective you chose to reason, the results are the same, aka double halfers are correct.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">However, Titelbaum (2008) used the technicolor beauty example arguing for a thirder&rsquo;s position. Suppose there are two pieces of paper one blue the other red. Before your first awakening the researcher randomly choose one of them and stick it on the wall. You would be able to see the paper&rsquo;s color when awoke. After you fall back to sleep he would switch the paper so if you wakes up again you would see the opposite color. Now suppose after waking up you saw a piece of blue paper on the wall. You shall reason &ldquo;there exist a blue awakening&rdquo; which is more likely to happen if the coin landed tails. A bayesian update base on this information would give us the probability of head to be 1/3. If after waking up you see a piece of red paper you would reach the same conclusion due to symmetry. Since it is absurd to purpose technicolor beauty is fundamentally different from sleeping beauty problem they must have the same answer, aka thirders are correct.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Technicolor beauty is effectively identifying your current awakening from a third-person perspective by using a piece of information irrelevant to the coin toss. I purpose the use of irrelevant information is only justified if it affects the learning of relevant information. In most cases this means the identification must be done before an observation is made. The color of the paper, or any details you experienced after waking up does not satisfy this requirement thus cannot be used. This is best illustrated by an example.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">Imagine you are visiting an island with a strange custom. Every family writes their number of children on the door. All children stays at home after sunset. Furthermore only boys are allowed to answer the door after dark. One night you knock on the door of a family with two children . Suppose a boy answered. What is the probability that both children of the family are boys? After talking to the boy you learnt he was born on a Thursday. Should you change the probability?</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">A family with two children is equally likely to have two boys, two girls, a boy and a girl or a girl and a boy. Seeing a boy eliminates the possibility of two girls. Therefore among the other cases both boys has a probability of 1/3. If you knock on the doors of 1000 families with two children about 750 would have a boy answering, out of which about 250 families would have two boys, consistent with the 1/3 answer. Applying the same logic as technicolor beauty, after talking to the boy you shall identify him specifically as &ldquo;a boy born on Thursday&rdquo; and reason &ldquo;the family has a boy born on Thursday&rdquo;. This statement is more likely to be true if both the children are boys. Without getting into the details of calculation, a bayesian update on this information would give the probability of two boys to be 13/27. Furthermore, it doesn&rsquo;t matter which day he is actually born on. If the boy is born on, say, a Monday, we get the same answer by symmetry.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">This reasoning is obviously wrong and answer should remain at 1/3. This can be checked by repeating the experiment by visiting many families with two children. Due to its length the calculations are omitted here. Interested readers are encouraged to check. 13/27 would be correct if the island&rsquo;s custom is &ldquo;only boys born on Thursday can answer the door&rdquo;. In that case being born on a Thursday is a characteristic specified before your observation. It actually affects the chance of you learning relevant information about whether a boy exists. Only then you can justifiably identifying whom answering the door as &ldquo;a boy born on Thursday&rdquo;and reason &ldquo;the family has a boy born on Thursday&rdquo;. Since seeing the blue piece of paper happens after you waking up which does not affect your chance of awakening it cannot be used to identify you in a third-person perspective. Just as being born on Thursday cannot be used to identify the boy in the initial case.</span></span></p>\n<p class=\"p1\" style=\"background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; border: 0px; margin: 0px 0px 24px; padding: 0px; vertical-align: baseline; color: #333333; font-family: Georgia, &quot;Bitstream Charter&quot;, serif; font-size: 16px;\"><span class=\"s1\" style=\"background: transparent; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\"><span style=\"font-family: mceinline;\">On a related note, for the same reason using irrelevant information to identify you in the third-person perspective is justified in conventional probability problems. Because the identification happens before observation and the information learned varies depends one which person is specified. That&rsquo;s why in general we can arbitrarily switch perspectives without changing the answer.</span></span></p>",
    "user": {
      "username": "Xianda_GAO_duplicate0.5321505782395719",
      "slug": "xianda_gao_duplicate0-5321505782395719",
      "displayName": "Xianda_GAO_duplicate0.5321505782395719"
    }
  },
  {
    "_id": "XYmJXJrAtQg89gtN9",
    "title": "Against Facebook: The Stalking",
    "slug": "against-facebook-the-stalking",
    "pageUrl": "https://www.lesswrong.com/posts/XYmJXJrAtQg89gtN9/against-facebook-the-stalking",
    "postedAt": "2017-09-16T12:41:44.000Z",
    "baseScore": 42,
    "voteCount": 12,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Epistemic Status: Nothing we didn&#8217;t basically already know, but felt obligated to share</p>\n<p>Previously: <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook/\">Against Facebook</a>, <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook-comparison-to-alternatives-and-call-to-action/\">Against Facebook: Comparison to Alternatives and Call to Action</a></p>\n<p>Also Previously But Fully Optional: <a href=\"https://thezvi.wordpress.com/2017/04/23/help-us-find-your-blog-and-others/\">Help Us Find Your Blog (and others)</a>, <a href=\"https://thezvi.wordpress.com/2017/05/24/how-to-destroy-civilization/\">How to Destroy Civilization</a></p>\n<p>I knew that when Facebook went it would go spooky. It was still spooky.</p>\n<p>After the events of <a href=\"https://thezvi.wordpress.com/2017/05/24/how-to-destroy-civilization/\">How to Destroy Civilization</a>, I had definitive proof that Facebook was not only using terrible software, it was making my life appreciably worse to interact with Facebook. It <em>still </em>took me several weeks and new inspiration to delete the app from my phone. That came in the form of the article <a href=\"https://www.theatlantic.com/magazine/archive/2017/09/has-the-smartphone-destroyed-a-generation/534198/\">Has the Smartphone Destroyed a Generation?</a> which is the summary version of the book <a href=\"https://www.amazon.com/iGen-Super-Connected-Rebellious-Happy-Adulthood-ebook/dp/B01N6ACK3B/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1505342957&amp;sr=1-1&amp;keywords=igen\">iGen</a>.</p>\n<p>Later I also read the book. The book has some neat charts, but unless you&#8217;re super fascinated I would stick to the article. Both make a strong case that smartphones and social media are destroying young people&#8217;s lives and making them miserable. I have reviewing the book on my &#8216;maybe&#8217; stack.</p>\n<p>Today on the radio I heard from an author whose book makes an explicit case for boredom. She claims we need quiet time to reflect and develop ideas. Therefore filling every spare moment with our phones is really bad. I am skeptical, but find it plausible.</p>\n<p>In any case, I finally deleted the app.</p>\n<p>This made me instantly happy.</p>\n<p>It also set Facebook into action.</p>\n<p>Its first trick was that suddenly its notifications were turned back on. It seems that it thought the two of us had a deal. I keep it on my phone, and in exchange it will agree to not spam me with an email every time my friends like a photo.</p>\n<p>I marked a few of those as spam and Google made the problem go away.</p>\n<p>Later that day, Facebook fired its second salvo, with an email that said &#8220;Having trouble logging into Facebook? Get back on with <em>just one click!&#8221; </em></p>\n<p>Needless to say, this did not work.</p>\n<p>A few weeks later, I made the mistake of checking Facebook&#8217;s website for the few people I have See First on for, which I&#8217;ve been doing less and less often. While there, I was chatted up briefly by an old friend. It was nice to hear from her.</p>\n<p>Her second message mysteriously had a giant link to installing the messenger application.</p>\n<p>I asked her what that was doing there. She laughed and said she hadn&#8217;t meant to put it there. An accident. I&#8217;m sure.</p>\n<p>Then a few weeks later, after not logging in for a long time, Facebook decided to notify me that there was a woman requesting my friendship, and that we had four mutual friends. Via text.</p>\n<p>I will repeat that. <em>Facebook texted me to tell me I had a friend request.</em></p>\n<p>At this point the website is just a crazy stalker ex. She tried emailing me cute little things. Then she tried emailing me saying I must have lost her number. Then she tried to get me to click on a link and install spy software. Finally, she&#8217;s reduced to texting me asking about the new girl in my life and asking why I&#8217;m not returning any of her calls.</p>\n<p>The good news is that I&#8217;ve talked to a few other people she&#8217;s dated. Good friends. And they&#8217;re so over her. The heroes are winning this one.</p>\n<p>Today I deleted Twitter from my phone. I again felt instantly happy.</p>\n<p>Join us.</p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/thezvi.wordpress.com/13519/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/thezvi.wordpress.com/13519/\" /></a> <img alt=\"\" border=\"0\" src=\"https://pixel.wp.com/b.gif?host=thezvi.wordpress.com&#038;blog=21007166&#038;post=13519&#038;subd=thezvi&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Zvi",
      "slug": "zvi",
      "displayName": "Zvi"
    }
  },
  {
    "_id": "5pFCD7zJnCTZ5G6MP",
    "title": "Stupid Questions September 2017",
    "slug": "stupid-questions-september-2017",
    "pageUrl": "https://www.lesswrong.com/posts/5pFCD7zJnCTZ5G6MP/stupid-questions-september-2017",
    "postedAt": "2017-09-15T21:21:02.019Z",
    "baseScore": 2,
    "voteCount": 2,
    "commentCount": 27,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div id=\"entry_t3_oxn\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 15.6px;\">This  thread is for asking any questions that might seem obvious, tangential,  silly or what-have-you. Don't be shy, everyone has holes in their  knowledge, though the fewer and the smaller we can make them, the  better.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 15.6px;\">Please be respectful of other people's admitting ignorance and don't mock them for it, as they're doing a noble thing.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 15.6px;\">To any future monthly posters of SQ threads, please remember to add the \"stupid_questions\" tag.</p>\n</div>\n</div>\n</div>\n</div>",
    "user": {
      "username": "Erfeyah",
      "slug": "erfeyah",
      "displayName": "Erfeyah"
    }
  },
  {
    "_id": "LsNR2B7tcZAmQqdQ6",
    "title": "Fish oil and the self-critical brain loop",
    "slug": "fish-oil-and-the-self-critical-brain-loop",
    "pageUrl": "https://www.lesswrong.com/posts/LsNR2B7tcZAmQqdQ6/fish-oil-and-the-self-critical-brain-loop",
    "postedAt": "2017-09-15T09:53:36.343Z",
    "baseScore": 5,
    "voteCount": 4,
    "commentCount": 9,
    "meta": false,
    "question": false,
    "url": "http://bearlamp.com.au/fish-oil-and-the-self-critical-brain-loop/",
    "htmlBody": null,
    "user": {
      "username": "Elo",
      "slug": "elo",
      "displayName": "Elo"
    }
  },
  {
    "_id": "fkjv3x9QhhCbcSB4X",
    "title": "General and Surprising",
    "slug": "general-and-surprising",
    "pageUrl": "https://www.lesswrong.com/posts/fkjv3x9QhhCbcSB4X/general-and-surprising",
    "postedAt": "2017-09-15T06:33:19.797Z",
    "baseScore": 5,
    "voteCount": 3,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": "http://www.paulgraham.com/sun.html",
    "htmlBody": null,
    "user": {
      "username": "John_Maxwell_IV",
      "slug": "john_maxwell",
      "displayName": "John_Maxwell"
    }
  },
  {
    "_id": "rEHLk9nC5TtrNoAKT",
    "title": "LW 2.0 Strategic Overview",
    "slug": "lw-2-0-strategic-overview",
    "pageUrl": "https://www.lesswrong.com/posts/rEHLk9nC5TtrNoAKT/lw-2-0-strategic-overview",
    "postedAt": "2017-09-15T03:00:07.826Z",
    "baseScore": 85,
    "voteCount": 48,
    "commentCount": 296,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<p><strong>Update: We&#x27;re in open beta! At this point you will be able to sign up / login with your LW 1.0 accounts (if the latter, we did not copy over your passwords, so hit &quot;forgot password&quot; to receive a password-reset email).</strong></p><p>Hey Everyone! </p><p>This is the post for discussing the vision that I and the rest of the LessWrong 2.0 team have for the new version of LessWrong, and to just generally bring all of you up to speed with the plans for the site. This post has been overdue for a while, but I was busy coding on LessWrong 2.0, and I am myself not that great of a writer, which means writing things like this takes quite a long time for me, and so this ended up being delayed a few times. I apologize for that.</p><p>With Vaniver’s support, I’ve been the primary person working on LessWrong 2.0 for the last 4 months, spending most of my time coding while also talking to various authors in the community, doing dozens of user-interviews and generally trying to figure out how to make LessWrong 2.0 a success. Along the way I’ve had support from many people, including Vaniver himself who is providing part-time support from MIRI, Eric Rogstad who helped me get off the ground with the architecture and infrastructure for the website, Harmanas Chopra who helped build our Karma system and did a lot of user-interviews with me, Raemon who is doing part-time web-development work for the project, and Ben Pace who helped me write this post and is basically co-running the project with me (and will continue to do so for the foreseeable future).</p><p>We are running on charitable donations, with $80k in funding from CEA in the form of an EA grant and $10k in donations from Eric Rogstad, which will go to salaries and various maintenance costs. We are planning to continue running this whole project on donations for the foreseeable future, and legally this is a project of CFAR, which helps us a bunch with accounting and allows people to get tax benefits from giving us money. </p><p>Now that the logistics is out of the way, let’s get to the meat of this post. What is our plan for LessWrong 2.0, what were our key assumptions in designing the site, what does this mean for the current LessWrong site, and what should we as a community discuss more to make sure the new site is a success?</p><p>Here’s the rough structure of this post: </p><ul><li>My perspective on why LessWrong 2.0 is a project worth pursuing</li><li>A summary of the existing discussion around LessWrong 2.0 </li><li>The models that I’ve been using to make decisions for the design of the new site, and some of the resulting design decisions</li><li>A set of open questions to discuss in the comments where I expect community input/discussion to be particularly fruitful </li></ul><hr class=\"dividerBlock\"/><p><strong>Why bother with LessWrong 2.0?  </strong></p><p>I feel that independently of how many things were and are wrong with the site and its culture, overall, over the course of its history, it has been one of the few places in the world that I know off where a spark of real discussion has happened, and where some real intellectual progress on actually important problems was made. So let me begin with a summary of things that I think the old LessWrong got right, that are essential to preserve in any new version of the site:</p><p>On LessWrong…</p><p></p><ul><li>I can contribute to intellectual progress, even without formal credentials </li><li>I can sometimes have discussions in which the participants focus on trying to convey their true reasons for believing something, as opposed to rhetorically using all the arguments that support their position independent of whether those have any bearing on their belief</li><li>I can talk about my mental experiences in a broad way, such that my personal observations, scientific evidence and reproducible experiments are all taken into account and given proper weighting. There is no narrow methodology I need to conform to to have my claims taken seriously.</li><li>I can have conversations about almost all aspects of reality, independently of what literary genre they are associated with or scientific discipline they fall into, as long as they seem relevant to the larger problems the community cares about</li><li>I am surrounded by people who are knowledgeable in a wide range of fields and disciplines, who take the virtue of scholarship seriously, and who are interested and curious about learning things that are outside of their current area of expertise</li><li>We have a set of <strong>non-political</strong> shared goals for which many of us are willing to make significant personal sacrifices</li><li>I can post long-form content that takes up as much space at it needs to, and can expect a reasonably high level of patience of my readers in trying to understand my beliefs and arguments</li><li>Content that I am posting on the site gets archived, is searchable and often gets referenced in other people&#x27;s writing, and if my content is good enough, can even become common knowledge in the community at large</li><li>The average competence and intelligence on the site is high, which allows discussion to generally happen on a high level and allows people to make complicated arguments and get taken seriously</li><li>There is a body of writing that is generally assumed to have been read by most people  participating in discussions that establishes philosophical, social and epistemic principles that serve as a foundation for future progress (currently that body of writing largely consists of the Sequences, but also includes some of Scott’s writing, some of Luke’s writing and some individual posts by other authors) </li></ul><p></p><p>When making changes to LessWrong, I think it is very important to preserve all of the above features. I don’t think all of them are universally present on LessWrong, but all of them are there at least some of the time, and no other place that I know of comes even remotely close to having all of them as often as LessWrong has. Those features are what motivated me to make LessWrong 2.0 happen, and set the frame for thinking about the models and perspectives I will outline in the rest of the post. </p><p>I also think Anna, in her post about <a href=\"https://www.lesswrong.com/lw/o5z/on_the_importance_of_less_wrong_or_another_single/\">the importance of a single conversational locus</a>, says another, somewhat broader thing, that is very important to me, so I’ve copied it in here: </p><blockquote>1. The world is locked right now in a <a href=\"http://www.existential-risk.org/\">deadly</a> <a href=\"https://books.google.com/books/about/Superintelligence.html?id=7_H8AwAAQBAJ\">puzzle</a>, and needs something like a miracle of good thought if it is to have the survival odds one might wish the world to have.</blockquote><blockquote>2. Despite all priors and appearances, our little community (the &quot;aspiring rationality&quot; community; the &quot;effective altruist&quot; project; efforts to create an existential win; etc.) has a shot at seriously helping with this puzzle.  This sounds like hubris, but it is at this point at least partially a matter of track record.</blockquote><blockquote>3. To aid in solving this puzzle, we must probably find a way to think together, accumulatively. We need to think about technical problems in AI safety, but also about the full surrounding context -- everything to do with understanding what the heck kind of a place the world is, such that that kind of place may contain cheat codes and trap doors toward achieving an existential win. We probably also need to think about &quot;ways of thinking&quot; -- both the individual thinking skills, and the community conversational norms, that can cause our puzzle-solving to work better.</blockquote><blockquote>4. One feature that is pretty helpful here, is if we somehow maintain a single &quot;conversation&quot;, rather than a bunch of people separately having thoughts and sometimes taking inspiration from one another.  By &quot;a conversation&quot;, I mean a space where people can e.g. reply to one another; rely on shared jargon/shorthand/concepts; build on arguments that have been established in common as probably-valid; point out apparent errors and then have that pointing-out be actually taken into account or else replied-to).</blockquote><blockquote>5. One feature that really helps things be &quot;a conversation&quot; in this way, is if there is a single Schelling set of posts/etc. that people (in the relevant community/conversation) are supposed to read, and can be assumed to have read.  Less Wrong used to be a such place; right now there is no such place; it seems to me highly desirable to form a new such place if we can.</blockquote><blockquote>6. We have lately ceased to have a &quot;single conversation&quot; in this way.  Good content is still being produced across these communities, but there is no single locus of conversation, such that if you&#x27;re in a gathering of e.g. five aspiring rationalists, you can take for granted that of course everyone has read posts such-and-such.  There is no one place you can post to, where, if enough people upvote your writing, people will reliably read and respond (rather than ignore), and where others will call them out if they later post reasoning that ignores your evidence.  Without such a locus, it is hard for conversation to build in the correct way.  (And hard for it to turn into arguments and replies, rather than a series of non sequiturs.)</blockquote><p></p><p><strong>The Existing Discussion Around LessWrong 2.0</strong></p><p>Now that I’ve given a bit of context on why I think LessWrong 2.0 is an important project, it seems sensible to look at what has been said so far, so we don’t have to repeat the same discussions over and over again. There has already been a lot of discussion about the decline of LessWrong, the need for a new platform and the design of LessWrong 2.0, <a href=\"https://www.lesswrong.com/lw/ngo/turning_the_technical_crank/\">and</a> <a href=\"https://www.lesswrong.com/lw/np2/revitalising_less_wrong_is_not_a_lost_purpose/\">I</a> <a href=\"https://www.lesswrong.com/lw/ovx/thoughts_on_automoderation/\">won’t</a> <a href=\"https://www.lesswrong.com/lw/otq/whats_up_with_arbital/\">be</a> <a href=\"https://www.lesswrong.com/lw/n8o/clearing_an_overgrown_garden/\">able</a> <a href=\"https://www.lesswrong.com/r/discussion/lw/not/revitalizing_less_wrong_seems_like_a_lost_purpose/\">to</a> <a href=\"https://www.lesswrong.com/lw/mz5/open_thread_nov_16_nov_22_2015/cwe0?context=2#comments\">summarise</a> <a href=\"https://www.lesswrong.com/lw/mjd/open_thread_jul_27_aug_02_2015/cluu?context=2#comments\">it</a> <a href=\"https://www.lesswrong.com/lw/mlz/ideas_on_growth_of_the_community/\">all</a> <a href=\"https://www.lesswrong.com/lw/n0l/lesswrong_20/\">here</a>, but I can try my best to summarize the most important points, and give a bit of my own perspective on them.</p><p>Here is a <a href=\"https://www.lesswrong.com/lw/o5z/on_the_importance_of_less_wrong_or_another_single/di0d\">comment by Alexandros</a>, on Anna’s post I quoted above:</p><blockquote>Please consider a few gremlins that are weighing down LW currently:</blockquote><blockquote>1. Eliezer&#x27;s ghost -- He set the culture of the place, his posts are central material, has punctuated its existence with his explosions (and refusal to apologise), and then, upped and left the community, without actually acknowledging that his experiment (well kept gardens etc) has failed. As far as I know he is still the &quot;owner&quot; of this website, retains ultimate veto on a bunch of stuff, etc. If that has changed, there is no clarity on who the owner is (I see three logos on the top banner, is it them?), who the moderators are, who is working on it in general. I know tricycle are helping with development, but a part-time team is only marginally better than no-team, and at least no-team is an invitation for a team to step up.</blockquote><blockquote>[...]</blockquote><blockquote>...I consider Alexei&#x27;s hints that Arbital is &quot;working on something&quot; to be a really bad idea, though I recognise the good intention. Efforts like this need critical mass and clarity, and diffusing yet another wave of people wanting to do something about LW with vague promises of something nice in the future... is exactly what I would do if I wanted to maintain the status quo for a few more years.</blockquote><blockquote>Any serious attempt at revitalising lesswrong.com should focus on defining ownership and plan clearly. A post by EY himself recognising that his vision for lw 1.0 failed and passing the batton to a generally-accepted BDFL would be nice, but i&#x27;m not holding my breath. Further, I am fairly certain that LW as a community blog is bound to fail. Strong writers enjoy their independence. LW as an aggregator-first (with perhaps ability to host content if people wish to, like hn) is fine. HN may have degraded over time, but much less so than LW, and we should be able to improve on their pattern.</blockquote><blockquote>I think if you want to unify the community, what needs to be done is the creation of a hn-style aggregator, with a clear, accepted, willing, opinionated, involved BDFL, input from the prominent writers in the community (scott, robin, eliezer, nick bostrom, others), and for the current lesswrong.com to be archived in favour of that new aggregator. But even if it&#x27;s something else, it will not succeed without the three basic ingredients: clear ownership, dedicated leadership, and as broad support as possible to a simple, well-articulated vision. Lesswrong tried to be too many things with too little in the way of backing.</blockquote><p></p><p>I think Alexandros hits a lot of good points here, and luckily these are actually some of the problems I am most confident we have solved. The biggest bottleneck – the thing that I think caused most other problems with LessWrong – is simply that there was nobody with the motivation, the mandate and the resources to fight against the inevitable decline into entropy. I feel that the correct response to the question of “why did LessWrong decline?” is to ask “why should it have succeeded?”. </p><p>In the absence of anyone with the mandate trying to fix all the problems that naturally arise, we should expect any online platform to decline. Most of the problems that will be covered in the rest of this post are things that could have been fixed many years ago, but simply weren’t because nobody with the mandate put much resources into fixing them. I think the cause for this was a diffusion of responsibility, and a lot of vague promises of problems getting solved by vague projects in the future. I myself put off working on LessWrong for a few months because I had some vague sense that Arbital would solve the problems that I was hoping to solve, even though Arbital never really promised to solve them. Then Arbital’s plan ended up not working out, and I had wasted months of precious time. </p><p>Since this comment was written, Vaniver has been somewhat unanimously declared benevolent dictator for life of LessWrong. He and I have gotten various stakeholders on board, received funding, have a vision, and have free time – and so we have the mandate, the resources and the motivation to not make the same mistakes. With our <a href=\"https://github.com/Discordius/Lesswrong2/tree/devel\">new codebase</a>, link posts are now something I can build in an afternoon, rather than something that requires three weeks of getting permissions from various stakeholders, performing complicated open-source and confidentiality rituals, and hiring a new contractor who has to first understand the mysterious Reddit fork from 2008 that LessWrong is based on. This means at least the problem of diffusion of responsibility is solved. </p><hr class=\"dividerBlock\"/><p>Scott Alexander also made a <a href=\"https://www.reddit.com/r/slatestarcodex/comments/6tt3gy/a_history_of_the_rationality_community/dloghua/\">recent comment</a> on Reddit on why he thinks LessWrong declined, and why he is somewhat skeptical of attempts to revive the website: </p><blockquote>1. Eliezer had a lot of weird and varying interests, but one of his talents was making them all come together so you felt like at the root they were all part of this same deep philosophy. This didn&#x27;t work for other people, and so we ended up with some people being amateur decision theory mathematicians, and other people being wannabe self-help gurus, and still other people coming up with their own theories of ethics or metaphysics or something. And when Eliezer did any of those things, somehow it would be interesting to everyone and we would realize the deep connections between decision theory and metaphysics and self-help. And when other people did it, it was just &quot;why am I reading this random bulletin board full of stuff I&#x27;m not interested in?&quot;</blockquote><blockquote>2. Another of Eliezer&#x27;s talents was carefully skirting the line between &quot;so mainstream as to be boring&quot; and &quot;so wacky as to be an obvious crackpot&quot;. Most people couldn&#x27;t skirt that line, and so ended up either boring, or obvious crackpots. This produced a lot of backlash, like &quot;we need to be less boring!&quot; or &quot;we need fewer crackpots!&quot;, and even though both of these were true, it pretty much meant that whatever you posted, someone would be complaining that you were bad.</blockquote><blockquote>3. All the fields Eliezer wrote in are crackpot-bait and do ring a bunch of crackpot alarms. I&#x27;m not just talking about AI - I&#x27;m talking about self-help, about the problems with the academic establishment, et cetera. I think Eliezer really did have interesting things to say about them - but 90% of people who try to wade into those fields will just end up being actual crackpots, in the boring sense. And 90% of the people who aren&#x27;t will be really bad at not seeming like crackpots. So there was enough kind of woo type stuff that it became sort of embarassing to be seen there, especially given the thing where half or a quarter of the people there or whatever just want to discuss weird branches of math or whatever.</blockquote><blockquote>4. Communities have an unfortunate tendency to become parodies of themselves, and LW ended up with a lot of people (realistically, probably 14 years old) who tended to post things like &quot;Let&#x27;s use Bayes to hack our utility functions to get superfuzzies in a group house!&quot;. Sometimes the stuff they were posting about made sense on its own, but it was still kind of awkward and the sort of stuff people felt embarassed being seen next to.</blockquote><blockquote>5. All of these problems were exacerbated by the community being an awkward combination of Google engineers with physics PhDs and three startups on one hand, and confused 140 IQ autistic 14 year olds who didn&#x27;t fit in at school and decided that this was Their Tribe Now on the other. The lowest common denominator that appeals to both those groups is pretty low.</blockquote><blockquote>6. There was a norm against politics, but it wasn&#x27;t a very well-spelled-out norm, and nobody enforced it very well. So we would get the occasional leftist who had just discovered social justice and wanted to explain to us how patriarchy was the real unfriendly AI, the occasional rightist who had just discovered HBD and wanted to go on a Galileo-style crusade against the deceptive establishment, and everyone else just wanting to discuss self-help or decision-theory or whatever without the entire community becoming a toxic outcast pariah hellhole. Also, this one proto-alt-right guy named Eugene Nier found ways to exploit the karma system to mess with anyone who didn&#x27;t like the alt-right (ie 98% of the community) and the moderation system wasn&#x27;t good enough to let anyone do anything about it.</blockquote><blockquote>7. There was an ill-defined difference between Discussion (low-effort random posts) and Main (high-effort important posts you wanted to show off). But because all these other problems made it confusing and controversial to post anything at all, nobody was confident enough to post in Main, and so everything ended up in a low-effort-random-post bin that wasn&#x27;t really designed to matter. And sometimes the only people who didpost in Main were people who were too clueless about community norms to care, and then their posts became the ones that got highlighted to the entire community.</blockquote><blockquote>8. Because of all of these things, Less Wrong got a reputation within the rationalist community as a bad place to post, and all of the cool people got their own blogs, or went to Tumblr, or went to Facebook, or did a whole bunch of things that relied on illegible local knowledge. Meanwhile, LW itself was still a big glowing beacon for clueless newbies. So we ended up with an accidental norm that only clueless newbies posted on LW, which just reinforced the &quot;stay off LW&quot; vibe.</blockquote><blockquote>I worry that all the existing &quot;resurrect LW&quot; projects, including some really high-effort ones, have been attempts to break coincidental vicious cycles - ie deal with 8 and the second half of 7. I think they&#x27;re ignoring points 1 through 6, which is going to doom them.</blockquote><p>At least judging from where my efforts went, I would agree that I have spent a pretty significant amount of resources on fixing the problems that Scott described in point 6 and 7, but I also spent about equal time thinking about how to fix 1-5. The broader perspective that I have on those latter points is I think best illustrated in an analogy: </p><p>When I read Scott’s comments about how there was just a lot of embarrassing and weird writing on LessWrong, I remember my experiences as a Computer Science undergraduate. When the median undergrad makes claims about the direction of research in their field, or some other big claim about their field that isn&#x27;t explicitly taught in class, or if you ask an undergraduate physics student what they think about how to do physics research, or what ideas they have for improving society, they will often give you quite naive sounding answers (I have heard everything from “I am going to build a webapp to permanently solve political corruption” to “here’s my idea of how we can transmit large amounts of energy wirelessly by using low-frequency tesla-coils”.) I don’t think we should expect anything different on LessWrong. I actually think we should expect it to be worse here, since we are actively encouraging people to have opinions, as opposed to the more standard practice of academia, which seems to consist of treating undergraduates as slightly more intelligent dogs that need to be conditioned with the right mixture of calculus homework problems and mandatory class attendance, so that they might be given the right to have any opinion at all if they spend 6 more years getting their PhD. </p><p>So while I do think that Eliezer’s writing encouraged topics that were slightly more likely to attract crackpots, I think a large chunk of the weird writing is just a natural consequence of being an intellectual community that has a somewhat constant influx of new members. </p><p>And having undergraduates go through the phase where they have bad ideas, and then have it explained to them why their ideas are bad, is important. I actually think it’s key to learning any topic more complicated than high-school mathematics. It takes a long time until someone can productively contribute to the intellectual progress of an intellectual community (in academia it’s at least 4 years, though usually more like 8), and during all that period they will say very naive and silly sounding things (though less and less so as time progresses). I think LessWrong can do significantly better than 4 years, but we should still expect that it will take new members time to acclimate and get used to how things work (based on user-interviews of a lot of top commenters it usually took something like 3-6 months until someone felt comfortable commenting frequently and about 6-8 months until someone felt comfortable posting frequently. This strikes me as a fairly reasonable expectation for the future). </p><p>And I do think that we have many graduate students and tenured professors of the rationality community who are not Eliezer, and who do not sound like crackpots, that can speak reasonably about the same topics Eliezer talked about, and who I feel are acting with a very similar focus to what Eliezer tried to achieve. Luke Muehlhauser, Carl Shulman, Anna Salamon, Sarah Constantin, Ben Hoffman, Scott himself and many more, most of whose writing would fit very well on LessWrong (and often still ends up there). </p><p>But all of this doesn’t mean what Scott describes isn’t a problem. It’s still a bad experience for everyone to constantly have to read through bad first year undergrad essays, but I think the solution can’t involve those essays not getting written at all. Instead it has to involve some kind of way of not forcing everyone to see those essays, while still allowing them to get promoted if someone shows up who does write something insightful from day one. I am currently planning to tackle this mostly with improvements to the karma system, as well as changes to the layout of the site, where users primarily post to their own profiles and can get content promoted to the frontpage by moderators and high-karma members. A feed consisting solely of content of the quality of the average Scott, Anna, Ben or Luke post would be an amazing read, and is exactly the kind of feed I am hoping to create with LessWrong, while still allowing users to engage with the rest of the content on the site (more on that later).</p><p>I would very very roughly summarize what Scott says in the first 5 points as two major failures: first a failure of separating the signal from the noise, and second a failure of enforcing moderation norms when people did turn out to be crackpots or just unable to productively engage with the material on the site. Both of which are natural consequences of the abandonment of promoting things to main, the fact that discussion is ordered by default by recency and not by some kind of scoring system, and the fact that the moderation tools were completely insufficient (but more on the details of that in the next section)</p><hr class=\"dividerBlock\"/><p><strong>My models of LessWrong 2.0</strong></p><p>I think there are three major bottlenecks that LessWrong is facing (after the zeroth bottleneck, which is just that no single group had the mandate, resources and motivation to fix any of the problems): </p><ol><li><strong>We need to be able to build on each other’s intellectual contributions, archive important content and avoid primarily being news-driven</strong></li><li><strong>We need to improve the signal-to-noise ratio for the average reader, and only broadcast the most important writing</strong></li><li><strong>We need to actively moderate in a way that is both fun for the moderators, and helps people avoid future moderation policy violations</strong></li></ol><p><strong>I. </strong></p><p>The first bottleneck for our community, and the biggest I think, is the ability to build common knowledge. On facebook, I can read an excellent and insightful discussion, yet one week later I forgot it. Even if I remember it, I don’t link to the facebook post (because linking to facebook posts/comments is hard) and it doesn’t have a title so I don’t casually refer to it in discussion with friends. On facebook, ideas don’t get archived and built upon, they get discussed and forgotten. To put this another way, the reason we cannot build on the best ideas this community had over the last five years, is because we don’t know what they are. There’s only fragments of memories of facebook discussions which maybe some other people remember. We have the sequences, and there’s no way to build on them together as a community, and thus there is stagnation.</p><p>Contrast this with science. Modern science is plagued by <a href=\"https://www.lesserwrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia\">many severe problems</a>, but of humanity’s institutions it has perhaps the strongest record of being able to build successfully on its previous ideas. The physics community has this system where the new ideas get put into journals, and then eventually if they’re new, important, and true, they get turned into textbooks, which are then read by the upcoming generation of physicists, who then write new papers based on the findings in the textbooks. All good scientific fields have good textbooks, and your undergrad years are largely spent reading them. I think the rationality community has some textbooks, written by Eliezer (and we also compiled a collection of Scott’s best posts that I hope will become another textbook of the community), but there is no expectation that if you write a good enough post/paper that your content will be included in the next generation of those textbooks, and the existing books we have rarely get updated. This makes the current state of the rationality community analogous to a hypothetical state of physics, had physics no journals, no textbook publishers, and only one textbook that is about a decade old. </p><p>This seems to me what Anna is talking about - the purpose of the single locus of conversation is the ability to have common knowledge and build on it. The goal is to have every interaction with the new LessWrong feel like it is either helping you grow as a rationalist or has you contribute to lasting intellectual progress of the community. If you write something good enough, it should enter the canon of the community. If you make a strong enough case against some existing piece of canon, you should be able to replace or alter that canon. I want writing to the new LessWrong to feel timeless. </p><p>To achieve this, we’ve built the following things: </p><ul><li>We created a section for core canon on the site that is prominently featured on the frontpage and right now includes Rationality: A-Z, The Codex (a collection of Scott’s best writing, compiled by Scott and us), and HPMOR. Over time I expect these to change, and there is a good chance HPMOR will move to a different section of the site (I am considering adding an “art and fiction” section) and will be replaced by a new collection representing new core ideas in the community.</li><li>Sequences are now a core feature of the website. Any user can create sequences of their own and other users posts, and those sequences themselves can be voted and commented on. The goal is to help users compile the best writing on the site, and make it so that good timeless writing gets read by users for a long time, as opposed to disappearing into the void. Separating creative and curatorial effort allows the sort of professional specialization that you see in serious scientific fields.</li><li>Of those sequences, the most upvoted and most important ones will be chosen to be prominently featured on other sections of the site, allowing users easy access to read the best content on the site and get up to speed with the current state of knowledge of the community.</li><li>For all posts and sequences the site keeps track of how much of them you’ve read (including importing view-tracking from old LessWrong, so you will get to see how much of the original sequences you’ve actually read). And if you’ve read all of a sequence you get a small badge that you can choose to display right next to your username, which helps people navigate how much of the content of the site you are familiar with.</li><li>The design of the core content of the site (e.g. the Sequences, the Codex, etc.) tries to communicate a certain permanence of contributions. The aesthetic feels intentionally book-like, which I hope gives people a sense that their contributions will be archived, accessible and built-upon. </li><li>One important issue with this is that there also needs to be a space for sketches on LessWrong. To quote  PaulGraham: “What made oil paint so exciting, when it first became popular in the fifteenth century, was that you  could actually make the finished work from the prototype. You could make a preliminary drawing if you wanted to,  but you weren&#x27;t held to it; you could work out all the details, and even make major changes, as you finished the  painting.”</li><li>We do not want to discourage sketch-like contributions, and want to build functionality that helps people build a finished work from a prototype (this is one of the core competencies of Google Docs, for example).</li></ul><p>And there are some more features the team is hoping to build in this direction, such as: </p><ul><li>Easier archiving of discussions by allowing discussions to be turned into top-level posts (similar to what Ben Pace did with a recent Facebook discussion between Eliezer, Wei Dai, Stuart Armstrong, and some others, which he turned into <a href=\"https://www.lesserwrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia\">a post on LessWrong 2.0</a>) </li><li>The ability to continue reading the content you’ve started reading with a single click from the frontpage. Here&#x27;s an example logged-in frontpage:</li></ul><p></p><span><figure><img src=\"https://i.imgur.com/JT4U2MA.png\" class=\"draft-image center\" style=\"\" /></figure></span><p></p><p></p><p><strong>II.</strong></p><p>The second bottleneck is improving the signal-to-noise ratio. It needs to be possible for someone to subscribe to only the best posts on LessWrong, and only the most important content needs to turned into common-knowledge. </p><p>I think this is a lot of what Scott was pointing at in his summary about the decline of LessWrong. We need a way for people to learn from their mistakes, while also not flooding the inboxes of everyone else, and while giving people active feedback on how to improve in their writing. </p><p><strong>The site structure: </strong></p><p>To solve this bottleneck, here is the rough content structure that I am currently planning to implement on LessWrong: </p><span><figure><img src=\"https://i.imgur.com/LapwRNy.png\" class=\"draft-image center\" style=\"\" /></figure></span><p></p><p><strong>The writing experience: </strong></p><p>If you write a post, it first shows up nowhere else but your personal user page, which you can basically think of being a medium-style blog. If other users have subscribed to you, your post will then show up on their frontpages (or only show up after it hit a certain karma threshold, if users who subscribed to you set a minimum karma threshold). If you have enough karma you can decide to promote your content to the main frontpage feed (where everyone will see it by default), or a moderator can decide to promote your content (if you allowed promoting on that specific post). The frontpage itself is sorted by a scoring system based on the HN algorithm, which uses a combination of total karma and how much time has passed since the creation of the post. </p><p>If you write a good comment on a post a moderator or a high-karma user can promote that comment to the frontpage as well, where we will also feature the best comments on recent discussions. </p><p><strong>Meta</strong></p><p>Meta will just be a section of the site to discuss changes to moderation policies, issues and bugs with the site, discussion about site features, as well as general site-policy issues. Basically the thing that all StackExchanges have. Karma here will not add to your total karma and will not give you more influence over the site. </p><p><strong>Featured posts</strong></p><p>In addition to the main thread, there is a promoted post section that you can subscribe to via email and RSS, that has on average three posts a week, which for now are just going to be chosen by moderators and editors on the site to be the posts that seem most important to turn into common-knowledge for the community. </p><p><strong>Meetups (implementation unclear)</strong></p><p>There will also be a separate section of the site for meetups and event announcements that will feature a map of meetups, and generally serve as a place to coordinate the in-person communities. The specific implementation of this is not yet fully figured out. </p><p><strong>Shortform (implementation unclear)</strong></p><p>Many authors (including Eliezer) have requested a section of the site for more short-form thoughts, more similar to the length of an average FB post. It seems reasonable to have a section of the site for that, though I am not yet fully sure how it should be implemented. </p><p><strong>Why? </strong></p><p>The goal of this structure is to allow users to post to LessWrong without their content being directly exposed to the whole community. Their content can first be shown to the people who follow them, or the people who actively seek out content from the broader community by scrolling through all new posts. Then, if a high-karma users among them finds their content worth posting to the frontpage, it will get promoted. The key to this is a larger userbase that has the ability to promote content (i.e. many more than have the ability to promote content to main on the current LessWrong), and the continued filtering of the frontpage based on the karma level of the posts. </p><p>The goal of all of these is to allow users to see good content at various levels of engagement with the site, while giving some personalization options so that people can follow the people they are particularly interested and while also ensuring that this does not sabotage the attempt at building common knowledge by having the best posts from the whole ecosystem be featured and promoted on the frontpage. </p><p><strong>The karma system:</strong></p><p>Another thing I’ve been working on to fix the signal-to-noise ratio is to improve the karma system. It’s important that the people having the most significant insights are able to shape a field more. If you’re someone who regularly produces real insights, you’re better able to notice and bring up other good ideas. To achieve this we’ve built a new karma system, where your upvotes and downvotes weight more if you have a lot of karma already. So far the current weighting is a very simple heuristic, whereby your upvotes and downvotes count for log base 5 of your total karma. Ben and I will post another top-level post to discuss just the karma system at some point in the next few weeks, but feel free to ask any questions now, and we will just include those in that post.</p><p>(I am currently experimenting with a karma system based on the concept of eigendemocracy by Scott Aaronson, which you can read about <a href=\"https://www.scottaaronson.com/blog/?p=1820\">here</a>, but which basically boils down to applying Google’s PageRank algorithm to karma allocation. How trusted you are as a user (your karma) is based on how much trusted users upvote you, and the circularity of this definition is solved using linear algebra.)</p><p>I am also interested in having some form of two-tiered voting, similarly to how Facebook has a primary vote interaction (the like) and a secondary interaction that you can access via a tap or a hover (angry, sad, heart, etc.). But the implementation of that is also currently undetermined. </p><p><strong>III</strong></p><p>The third and last bottleneck is an actually working moderation system that is fun to use by moderators, while also giving people whose content was moderated a sense of why, and how they can improve. </p><p>The most common, basic complaint currently on LessWrong pertains to trolls and sockpuppet accounts that the reddit fork’s mod tools are vastly inadequate for dealing with (Scott&#x27;s sixth point refers to this). Raymond Arnold and I are currently building more nuanced mod tools, that include abilities for moderators to set the past/future votes of a user to zero, to see who upvoted a post, and to know the IP address that an account comes from (this will be ready by the open beta). </p><p>Besides that, we are currently working on cultivating a moderation group we are calling “Sunshine Regiment.” Members of the sunshine regiment that will have the ability to take various smaller moderation actions around the site (such as temporarily suspending comment threads, making general moderating comments in a distinct font and promoting content), and so will have the ability to generally shape the culture and content of the website to a larger degree.</p><p>The goal is moderation that goes far beyond dealing with trolls, and actively makes the epistemic norms a ubiquitous part of the website. Right now Ben Pace is thinking about moderation norms that encourage archiving and summarizing good discussion, as well as other patterns of conversation that will help the community make intellectual progress. He’ll be posting to the open beta to discuss what norms the site and moderators should have in the coming weeks. We&#x27;re both in agreement that moderation can and should be improved, and that moderators need better tools, and would appreciate good ideas about what else to give them.</p><hr class=\"dividerBlock\"/><p><strong>How you can help and issues to discuss:</strong></p><p>The open beta of the site is starting in a week, and so you can see all of this for yourself. For the duration of the open beta, we’ll continue the discussion on the beta site. At the conclusion of the open beta, we plan to have a vote open to those who had a thousand karma or more on 9/13 to determine whether we should move forward with the new site design, which would move to the lesswrong.com url from its temporary beta location, or leave LessWrong as it is now. (As this would represent the failure of the plan to revive LW, this would likely lead to the site being archived rather than staying open in an unmaintained state.) For now, this is an opportunity for the current LessWrong community to chime in here and object to anything in this plan.</p><p>During the open beta (and only during that time) the site will also have an Intercom button in the bottom right corner that allows you to chat directly with us. If you run into any problems, or notice any bugs, feel free to ping us directly on there and Ben and I will try to help you out as soon as possible.</p><p>Here are some issues where I discussion would be particularly fruitful: </p><ul><li>What are your thoughts about the karma system? Does an eigendemocracy based system seem reasonable to you? How would you implement the details? Ben and I will post our current thoughts on this in a separate post in the next two weeks, but we would be interested in people’s unprimed ideas.</li><li>What are your experiences with the site so far? Is anything glaringly missing, or are there any bugs you think I should definitely fix? </li><li>Do you have any complaints or thoughts about how work on LessWrong 2.0 has been proceeding so far? Are there any worries or issues you have with the people working on it? </li><li>What would make you personally use the new LessWrong? Is there any specific feature that would make you want to use it? For reference, here is our current <a href=\"https://www.lesserwrong.com/posts/6XZLexLJgc5ShT4in/lesswrong-2-0-feature-roadmap-and-feature-suggestions\">feature roadmap</a> for LW 2.0.</li><li>And most importantly, do you think that the LessWrong 2.0 project is doomed to failure for some reason? Is there anything important I missed, or something that I misunderstood about the existing critiques?</li></ul><p>The closed beta can be found at <a href=\"http://www.lesserwrong.com/\">www.lesserwrong.com</a>.</p><p>Ben, Vaniver, and I will be in the comments!</p>",
    "user": {
      "username": "habryka4",
      "slug": "habryka4",
      "displayName": "habryka"
    }
  },
  {
    "_id": "bxctncS8qcgeCEMGN",
    "title": "LW 2.0 Open Beta starts 9/20",
    "slug": "lw-2-0-open-beta-starts-9-20",
    "pageUrl": "https://www.lesswrong.com/posts/bxctncS8qcgeCEMGN/lw-2-0-open-beta-starts-9-20",
    "postedAt": "2017-09-15T02:57:10.729Z",
    "baseScore": 39,
    "voteCount": 24,
    "commentCount": 28,
    "meta": true,
    "question": false,
    "url": null,
    "htmlBody": "<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">Two years ago, I wrote <a href=\"/lw/n0l/lesswrong_20/\">Lesswrong 2.0</a>. It&rsquo;s been quite the adventure since then; I took up the mantle of organizing work to improve the site but was missing some of the core skills, and also never quite had the time to make it my top priority. Earlier this year, I talked with Oliver Habryka and he joined the project and has done the lion&rsquo;s share of the work since then, with help along the way from Eric Rogstad, Harmanas Chopra, Ben Pace, Raymond Arnold, and myself. Dedicated staff has led to serious progress, and we can now see the light at the end of the tunnel.</p>\n<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">So what&rsquo;s next? We&rsquo;ve been running the closed beta for some time at lesserwrong.com with an import of the old LW database, and are now happy enough with it to show it to you all. On 9/20, next Wednesday, we&rsquo;ll turn on account creation, making it an open beta. (This will involve making a new password, as the passwords are stored hashed and we&rsquo;ve changed the hashing function from the old site.) If you don't have an email address set for your account (<a href=\"/prefs/update/\">see here</a>), I recommend adding it by the end of the open beta so we can merge accounts. For the open beta, just use the Intercom button in the lower right corner if you have any trouble.&nbsp;</p>\n<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">Once the open beta concludes, we&rsquo;ll have a vote of veteran users (over 1k karma as of yesterday) on whether to change the code at lesswrong.com over to the new design or not. It seems important to <a href=\"/lw/iw/positive_bias_look_into_the_dark/\">look into the dark</a> and have an escape valve in case this is the wrong direction for LW. If the vote goes through, we&rsquo;ll import the new LW activity since the previous import to the new servers, merging the two, and point the url to the new servers. If it doesn&rsquo;t, we&rsquo;ll likely turn LW into an archive.</p>\n<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\" dir=\"ltr\">Oliver Habryka will be posting shortly with <a href=\"/r/discussion/lw/pes/on_bottlenecks_to_intellectual_progress_in_the/\">his views on LW</a> and more details on our plans for how LW 2.0 will further intellectual progress in the community.</p>\n<div><br /></div>",
    "user": {
      "username": "Vaniver",
      "slug": "vaniver",
      "displayName": "Vaniver"
    }
  },
  {
    "_id": "NMZaZC9RLGsyobSZE",
    "title": "Understanding Policy Gradients",
    "slug": "understanding-policy-gradients",
    "pageUrl": "https://www.lesswrong.com/posts/NMZaZC9RLGsyobSZE/understanding-policy-gradients",
    "postedAt": "2017-09-13T21:13:46.210Z",
    "baseScore": 1,
    "voteCount": 1,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": "http://squirrelinhell.blogspot.com/2017/09/understanding-policy-gradients.html",
    "htmlBody": null,
    "user": {
      "username": "SquirrelInHell",
      "slug": "squirrelinhell",
      "displayName": "SquirrelInHell"
    }
  },
  {
    "_id": "r5RF3kFENYh5GsFj2",
    "title": "2017 LessWrong Survey",
    "slug": "2017-lesswrong-survey",
    "pageUrl": "https://www.lesswrong.com/posts/r5RF3kFENYh5GsFj2/2017-lesswrong-survey",
    "postedAt": "2017-09-13T06:26:42.893Z",
    "baseScore": 29,
    "voteCount": 21,
    "commentCount": 75,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>The <a href=\"https://www.fortforecast.com/limesurvey/index.php/265172?lang=en\" target=\"_blank\">2017 LessWrong Survey</a> is here! This year we're interested in community response to the LessWrong 2.0 initiative. I've also gone through and fixed as many bugs as I could find reported on the last survey, and reintroduced items that were missing from the 2016 edition. Furthermore new items have been introduced in multiple sections and some cut in others to make room. You can now export your survey results after finishing by choosing the 'print my results' option on the page displayed after submission. The survey will run from today until the 15th of October.</p>\n<p>You can take the survey below, thanks for your time. (It's back in single page format, please allow some seconds for it to load):</p>\n<p><a href=\"https://www.fortforecast.com/limesurvey/index.php/265172?lang=en\" target=\"_blank\"><span style=\"font-size: 18px;\">Click here to take the survey</span></a></p>",
    "user": {
      "username": "ingres",
      "slug": "ingres",
      "displayName": "namespace"
    }
  },
  {
    "_id": "ePomGcCsYdsXqk7g7",
    "title": "2017 LessWrong Survey",
    "slug": "2017-lesswrong-survey",
    "pageUrl": "https://www.lesswrong.com/posts/ePomGcCsYdsXqk7g7/2017-lesswrong-survey",
    "postedAt": "2017-09-13T06:18:33.074Z",
    "baseScore": 6,
    "voteCount": 4,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>The <a href=\"https://www.fortforecast.com/limesurvey/index.php/265172?lang=en\">2017 LessWrong Survey</a> is here! This year we&#x27;re interested in community response to the LessWrong 2.0 initiative. I&#x27;ve also gone through and fixed as many bugs as I could find reported on the last survey, and reintroduced items that were missing from the 2016 edition. Furthermore new items have been introduced in multiple sections and some cut in others to make room. You can now export your survey results after finishing by choosing the &#x27;print my results&#x27; option on the page displayed after submission. The survey will run from today until the 15th of October.</p><p>You can take the survey below, thanks for your time. (It&#x27;s back in single page format,please allow some seconds for it to load):</p><p><a href=\"https://www.fortforecast.com/limesurvey/index.php/265172?lang=en\">Click here to take the survey</a></p></div></div></div></div>",
    "user": {
      "username": "ingres",
      "slug": "ingres",
      "displayName": "namespace"
    }
  },
  {
    "_id": "4j9ZxyGubog5kigDr",
    "title": "Open thread, September 11 - September 17, 2017",
    "slug": "open-thread-september-11-september-17-2017",
    "pageUrl": "https://www.lesswrong.com/posts/4j9ZxyGubog5kigDr/open-thread-september-11-september-17-2017",
    "postedAt": "2017-09-11T07:46:02.103Z",
    "baseScore": 1,
    "voteCount": 1,
    "commentCount": 47,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<h5 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"color: #333333;\"><span style=\"font-size: 20px;\">If it's worth saying, but not worth its own post, then it goes here.</span></span></h5>\n<div id=\"entry_t3_p2r\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px;\">\n<div class=\"md\">\n<div id=\"entry_t3_oxb\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<hr style=\"line-height: 19.5px;\" />\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/new/\" target=\"_blank\">list-of-threads page</a>&nbsp;before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">3.&nbsp;</span><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">4. Unflag the two options \"</span><span style=\"font-size: 12px; line-height: 18px;\">Notify me of new top level comments on this article\" and \"</span><label style=\"font-size: 12px; line-height: 18px;\" for=\"cc_licensed\">Make this post available under...\" before submitting</label></p>\n</div>\n</div>\n</div>\n</div>",
    "user": {
      "username": "Thomas",
      "slug": "thomas",
      "displayName": "Thomas"
    }
  },
  {
    "_id": "QR7T4TgderFDFb5qN",
    "title": "Best of Don’t Worry About the Vase",
    "slug": "best-of-don-t-worry-about-the-vase",
    "pageUrl": "https://www.lesswrong.com/posts/QR7T4TgderFDFb5qN/best-of-don-t-worry-about-the-vase",
    "postedAt": "2017-09-10T12:18:08.000Z",
    "baseScore": 1,
    "voteCount": 0,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Epistemic Status: Welcome everyone!</p>\n<p>In honor of being linked to by Marginal Revolution, here is what the rest of this blog has to offer.</p>\n<p>This blog is part of the rationalist community. The general interest links below are fully general interest, and require no knowledge of or interest in rationality.</p>\n<p>What is rationality? <a href=\"http://lesswrong.com/lw/31/what_do_we_mean_by_rationality/\">This post is one good answer</a>. It is believing, and updating on evidence, so as to systematically improve the correspondence between <a href=\"http://yudkowsky.net/rational/the-simple-truth\">your map and the territory</a>, and using that map to achieve your values.</p>\n<p>To me, a rationalist is someone who highly values, and invests in, this process and the art thereof, both in themselves and others.</p>\n<p>This blog strives to embody that way of thinking. If you are interested in the way of thinking you saw in the guide, and want to see or explore more of it, this blog might be for you.</p>\n<p>If you&#8217;re wondering why anyone would think this way, my best responses to that are <a href=\"https://thezvi.wordpress.com/2017/04/04/responses-to-tyler-cohen-on-rationality/\">Responses to Tyler Cowen on Rationality</a> and <a href=\"https://thezvi.wordpress.com/2017/04/08/why-rationality/\">Why Rationality?</a></p>\n<p>If you&#8217;re <em>really </em>interested, you should try <a href=\"https://www.readthesequences.com/\">reading the sequences</a>. You can get the Kindle version <a href=\"https://smile.amazon.com/Rationality-AI-Zombies-Eliezer-Yudkowsky-ebook/dp/B00ULP6EW2/ref=sr_1_1?ie=UTF8&amp;qid=1505044314&amp;sr=8-1&amp;keywords=rationality+from+ai+to+zombie\">here</a>.</p>\n<p>The rest of this post organizes what this blog has produced over the years, starting with highlighting the best posts of general or economic interest.</p>\n<p>If you&#8217;re interested in getting involved in the community, especially in New York City, leave a comment with information on how to reach you, preferably email.</p>\n<p>&nbsp;</p>\n<p>Top 5 General Interest / For Marginal Revolution Readers:</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/05/something-was-wrong/\">Something Was Wrong</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook/\">Against Facebook</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2015/06/30/the-thing-and-the-symbolic-representation-of-the-thing/\">The Thing and the Symbolic Representation of The Thing</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/07/09/on-the-seattle-minimum-wage-study-part-1/\">On the Seattle Minimum Wage Study (part 1)</a> [<a href=\"https://thezvi.wordpress.com/2017/07/11/on-the-seattle-minimum-wage-study-part-2/\">Part 2</a>] [<a href=\"https://thezvi.wordpress.com/2017/08/17/seattle-minimum-wage-study-part-3-tell-me-why-im-wrong-please/\">Part 3</a>]</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Play in Hard Mode</a></p>\n<p>&nbsp;</p>\n<p>Next 5 General Interest:</p>\n<p><a href=\"https://thezvi.wordpress.com/2015/12/24/on-cutting-wages/\">On Cutting Wages</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Play in Hard Mode</a> [<a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Play in Easy Mode]</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2015/05/15/in-a-world-of-venture-capital/\">In a world… of venture capital</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/02/18/book-review-how-asia-works-by-joe-studwell/\">Book Review: How Asia Works by Joe Studwell</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/06/04/book-review-weapons-of-math-destruction/\">Book Review: Weapons of Math Destruction</a></p>\n<p>&nbsp;</p>\n<p>Against Facebook Sequence:</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook/\">Against Facebook</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook-comparison-to-alternatives-and-call-to-action/\">Against Facebook: Comparison to Alternatives and Call to Action</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/23/help-us-find-your-blog-and-others/\">Help Us Find Your Blog (and others)</a></p>\n<p>&nbsp;</p>\n<p>Choices Sequence:</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/07/20/change-is-bad/\">Change Is Bad</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/12/choices-are-really-bad/\">Choices Are Really Bad</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/07/25/complexity-is-bad/\">Complexity Is Bad</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/12/choices-are-really-bad/\">Choices Are Really Bad</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Play in Easy Mode</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Play in Hard Mode</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/09/02/exploring-premium-mediocrity/\">Exploring Premium Mediocrity</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/09/05/expanding-premium-mediocrity/\">Expanding Premium Mediocrity</a></p>\n<p>&nbsp;</p>\n<p>Restaurant Guide (I owe part 3 at some point, maybe more):</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/03/05/restaurant-guide-1-restaurants-should-not-look-like-most-restaurants/\">Restaurant Guide 1: Restaurants should not look like (most) restaurants</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/03/17/restaurant-guide-2-pizza/\">Restaurant Guide 2: Pizza</a></p>\n<p>&nbsp;</p>\n<p>About Rationality (General Interest):</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/04/responses-to-tyler-cohen-on-rationality/\">Responses to Tyler Cohen on Rationality</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/08/why-rationality/\">Why Rationality?</a></p>\n<p>&nbsp;</p>\n<p>Rationalist Culture and Ideas (For General Interest)</p>\n<p><a href=\"https://thezvi.wordpress.com/2015/05/17/31/\">The Twelve Virtues of Rationality</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/03/11/trio-walks-duo-talks/\">Trio Walks, Duo Talks</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/07/24/write-down-your-process/\">Write Down Your Process</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/03/30/avoiding-emotional-dominance-spirals/\">Avoiding Emotional Dominance Spirals</a></p>\n<p>&nbsp;</p>\n<p>Decision Theory:</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/03/24/if-you-choose-not-to-decide-you-still-have-made-a-choice/\">If you choose not to decide, you still have made a choice.</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/05/24/how-to-destroy-civilization/\">How to Destroy Civilization</a></p>\n<p>&nbsp;</p>\n<p>On Rationalist Culture and Ideas (For Community Members):</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/06/24/on-dragon-army/\">On Dragon Army</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/03/19/on-automoderation/\">On Automoderation</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/12/what-is-rationalist-berkleys-community-culture/\">What Is Rationalist Berkley’s Community Culture?</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/20/paths-forward-on-berkeley-culture-discussion/\">Paths Forward on Berkeley Culture Discussion</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/08/20/altruism-is-incomplete/\">Altruism is Incomplete</a></p>\n<p><a href=\"https://thezvi.wordpress.com/2017/04/09/youre-good-enough-youre-smart-enough-and-people-would-like-you/\">You’re Good Enough, You’re Smart Enough, and People Would Like You</a></p>\n<p>&nbsp;</p>\n<p>AI (This section needs to get bigger):</p>\n<p><a href=\"https://thezvi.wordpress.com/2017/02/24/the-ai-paper-with-the-best-title-ever/\">The AI Paper with The Best Title Ever</a></p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/thezvi.wordpress.com/13306/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/thezvi.wordpress.com/13306/\" /></a> <img alt=\"\" border=\"0\" src=\"https://pixel.wp.com/b.gif?host=thezvi.wordpress.com&#038;blog=21007166&#038;post=13306&#038;subd=thezvi&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Zvi",
      "slug": "zvi",
      "displayName": "Zvi"
    }
  },
  {
    "_id": "SaYr2PWR5sx6Tc6Bg",
    "title": "Epistemic Spot Check: Exercise for Mood and Anxiety (Michael W. Otto, Jasper A.J. Smits)",
    "slug": "epistemic-spot-check-exercise-for-mood-and-anxiety-michael-w",
    "pageUrl": "https://www.lesswrong.com/posts/SaYr2PWR5sx6Tc6Bg/epistemic-spot-check-exercise-for-mood-and-anxiety-michael-w",
    "postedAt": "2017-09-09T23:50:00.293Z",
    "baseScore": 12,
    "voteCount": 8,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h3>Introduction</h3><p>Everyone knows exercise (along with diet and sleep) makes a big difference in depression and anxiety.  Depressed and anxious people are almost by definition bad at transforming information about how to improve their lives into actions with large up front costs, so this data is not as useful as it might be.  Exercise for Mood and Anxiety (Michael W. Otto, Jasper A.J. Smits) aims to close that gap by making the conventional wisdom actionable.  It does that through the following steps:</p><ol><li><p>Present evidence that exercise is very helpful and why, to create motivation.</p></li><li><p>Walk you through setting up an environment where exercise requires relatively little will power to start.</p></li><li><p>Scripts and advice to make exercise as unmiserable as possible while you are doing it.</p></li><li><p>Scripts and advice to milk as much mood benefit as possible from a given amount of exercise.</p></li><li><p>An idiotic chapter on weight and food.</p></li></ol><p>Parts 3 and 4 use a lot of techniques from cognitive behavioral therapy and mindfulness, and I suspect there’s a second order benefit of learning to apply these techniques to a relatively easy thing, so you can apply them to the rest of your life later.</p><h3>Epistemic Spot Checking</h3><p><em>Claim: “a study of 55,000 adults in the United States and Canada found that people who exercised had fewer symptoms of anxiety and depression.” (Kindle Locations 103-104). </em></p><p><strong>Correctly cited, paper has no proof of causation. </strong> (<a href=\"http://www.sciencedirect.com/science/article/pii/0091743588900709\">abstract</a>) (<a href=\"http://sci-hub.io/10.1016/0091-7435(88)90070-9\">PDF</a>) The study does in fact say this, but it also says “Despite the fact that none of these surveys [of which this paper is a metaanalysis] was [sic] originally designed to explore this association… “.  I’m not saying you can never repurpose data, but with something like this where the real question is causality, it seems suspicious.  The authors do consider the idea that causation runs from mental health (=energy, hopefulness, executive function) -&gt; exercise and dismiss if, for reasons I find inadequate.</p><p><em>Claim: “Other studies add to this list of mood benefits by indicating that exercise is also linked to less anger and cynical distrust, as well as to stronger feelings of social integration.” (Kindle Locations 104-106). </em></p><p><strong>Correctly cited, paper has no proof of causation.</strong> (<a href=\"http://www.sciencedirect.com/science/article/pii/S0091743599905972\">Abstract</a>).</p><p><em>Claim: And these benefits don’t just include reducing symptoms of distress in people who have not been formally diagnosed with depression or anxiety. The benefits of exercise also include lower rates of psychiatric disorders; there is less major depression, as well as fewer anxiety disorders in those who exercise regularly. (Kindle Locations 107-109). </em></p><p><strong>Correctly cited, paper has no proof of causation.</strong></p><p>The dismissal of causality goes on for another three citations but I’m just going to skip to the intervention studies.  Otto gives these population studies more credence than I would but does note that the intervention studies are more informative.</p><p><em>Claim:  study summarized 70 studies on this topic and showed that adults who experience sad or depressed moods, but not at levels that meet criteria for a psychiatric disorder, reliably report meaningful improvements in their mood as they start exercising. (Kindle Locations 116-117).</em></p><p><strong>Correctly cited, study accuracy undetermined.</strong>  (<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2870716/\">Full paper</a>). My fear (based on spot checking a similar book you’ll see in the rejects post) is that each of these studies consists of 15 people.  All the metaanalysis in the world won’t save you if you do 100 small studies and only publish the 50 that say what you want.  The studies included go all the way back to 1969: I can’t decide if that makes them more informative or less.</p><p><em>Claim:  The latest estimates are that about 17% of adults experience a major depressive episode in their lifetimes and that about half who have it experience recurrent episodes over time. (Kindle Locations 124-126). </em></p><p><strong>True.</strong> (<a href=\"http://jamanetwork.com/journals/jamapsychiatry/fullarticle/482708\">Full paper</a>).  The same study is cited for both facts, but I can only find the 50% statistic in the paper.  The data is kind of old (started in 1981), but of course you can’t get 30-year data except by starting 30 years ago.  This paper says the lifetime prevalence of mood disorders (depression, bipolar 1 and 2, and their baby siblings) is 20%; this study puts prevalence in the US at 16.9%.</p><p><em>Claim: As is the case with major depressive disorder, anxiety disorders are common, affecting more than 1 in 4 (28.8%) adults in their lifetimes” (Kindle Locations 136-137).</em></p><p><strong>True.</strong> (<a href=\"https://www.ncbi.nlm.nih.gov/pubmed/15939837\">Full paper</a>).  He cites the same paper I did for the 20% mood disorder statistic.</p><p><em>Claim: [Anxiety disorders] tend to be especially long-lasting when people do not receive treatment. (Kindle Locations 137-138).</em></p><p><strong>True</strong>, although not particularly specific.  (<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3272761/\">Full paper</a>)</p><p><em>Claim: Exercise in itself is a stressor—it requires effort, and it forces the body to adapt to the demands placed on it.  (Kindle Locations 141-142). </em></p><p><strong>True.</strong>  (<a href=\"http://journals.lww.com/acsm-essr/Citation/1996/00240/Exercise_Training_and_the_Cross_Stressor.11.aspx\">Full paper</a>).</p><p><em>Claim:  A study examined firefighters reaction to stress, and then gave half a 16 week exercise course.  The study group showed improvements in stress responses. (Kindle location 148)</em></p><p><strong>True.</strong>  (<a href=\"https://link.springer.com/article/10.1023/A:1009574428627\">Abstract</a>) (<a href=\"http://www.edb.utexas.edu/education/assets/files/KHE/Bartholomew%20Publicatoins/stress%20reactivity%20in%20fire%20fighters.pdf\">PDF</a>).  I really like this study.  The group presumably had a high baseline fitness level, so this isn’t the difference between couch potato and a walk.  And they have before and after metrics.  The study is marred only by the small sample size (53).</p><p><em>Claim: “stress plays a key role in both the development and the continuation of depression and anxiety disorders.” (Kindle Locations 152-153). </em></p><p><strong>Accurate citation</strong>, very complicated topic. (<a href=\"http://annualreviews.org/doi/abs/10.1146/annurev.clinpsy.1.102803.143938\">Abstract</a>).</p><p>Okay, it is becoming clear I don’t have the time to check every one of these citations and you don’t have time to read it.  From here on out please assume a baseline of very dense citations, all of which accurately report the study results, if with a little more confidence than the study design merits, and I’m only going to call out things that deserve special attention on account of controversy or importance.</p><p><em>Claim: exercise increases serotonin just like the primary class of anti-depressants, selective serotonin update inhibitors.</em></p><p><strong>True but less relevant than implied. </strong> They’re relying on a model of <a href=\"http://slatestarcodex.com/2014/07/07/ssris-much-more-than-you-wanted-to-know/\">how SSRIs treat depression</a> that is fairly outdated.  SSRIs definitely increase serotonin, it’s just that there’s no evidence that’s their mechanism of action against depression except that they do it and they treat depression.  “Depression is caused by a serotonin deficiency” is a lie simplification told to patients and their families to allay fear and shame around psychiatric treatment.  This doesn’t undercut their point that exercise is good for you, but does indicate this is not a great book to learn brain chemistry from.</p><p></p><p><em>Claim:</em>  Both aerobic (prolonged moderate exercise such as running, cycling, or rowing over time) and anaerobic (like weight lifting or short sprinting) exercise have been found to be effective for decreasing depression, (Kindle Locations 239-241).</p><p></p><p><strong>True.</strong> (<a href=\"http://spers.ca/wp-content/uploads/2013/08/running-vs-weight-lifting-in-depression-management.pdf\">Study 1 PDF</a>) (<a href=\"https://www.ncbi.nlm.nih.gov/pubmed/2667882\">Study 2 abstract</a>).</p><p> </p><p></p><h3>Empirical Results</h3><p>The theory behind this book is very well supported; the prescriptions it makes flow naturally from the theory, but the authors present no direct evidence that they work.  I’m torn about this.  I don’t want to engage in RCT worship; having a systemic understanding of a problem is even better than evidence a particular solution worked better or worse than another solution in a different population.  On the other hand, humans are very complicated and it’s easy to identify the problem but guess the wrong solution.</p><p>I couldn’t test any of this on myself because I already enjoy exercise for a lot of reasons, so I scrounged up an unscientific sample from my wider social network to try it.</p><p>14 people filled out the pre-book survey.  3 people filled out the post-attempt survey.  None of them exercised more.</p><h3>Summary</h3><p></p><p>The theory sections of this book are my high water mark for scientific rigor in a self-help-psych book.  I’m currently reading a lot of those with the goal of finding out how much rigor is reasonable to expect, so that’s high praise.</p><p></p><p>The book walks the very fine line between reassuring and condescending, which is pretty unavoidable with CBT and mindfulness.</p><p></p><p>I did not like the last chapter and recommend skipping it.  It feels like they tried to stuff all the usual diet-and-exercise stuff in at the end.  Some of my problem is I think their recommendations are wrong, and some is that I believe that even if they were correct, throwing them in at the last minute undercuts the message of the book.</p><p></p><p>The first part of this is that, in America, at least in certain subcultures, any mention of weight makes the whole thing About Weight.  Too many people use health or mood as a socially acceptable way to say “you’re not hot enough”, so any mention of weight in the context of diet or exercise automatically makes weight the real topic of the conversation.  If the improvements in mood are enough of a reason to exercise, let them be enough, and the weight loss can be a pleasant surprise or not happen, and both are okay because you got what you came for.</p><p></p><p>The authors compound this problem by using Body Mass Index as a guide for goal weight.  BMI is <a href=\"https://acesounderglass.com/2014/03/18/medical-measurements/\">completely unsuited</a> for use in individuals, even more so for people who just started gaining muscle mass.  If you must talk about fat in the context of health use body fat percentage or certain circumference ratios (e.g. wrist:stomach).</p><p></p><p>The second problem is the speed with which EFMaA tries to address nutrition.  The book (correctly) treats exercise as a thing that is challenging to start despite all its benefits, and spends 10 chapters explaining why it’s worth trying and providing scripts to make it workable for you, for the sole benefit of mood, ignoring everything else you might get out of exercise.  I don’t know why the authors thought that that required an entire book but the even more complicated of nutrition for every possible benefit of nutrition could be squeezed into half a chapter.  I would be have been very excited for another book by the same authors about how to implement healthy eating, but the half assed treatment here makes me pause.</p><p></p><p>They also present a particular diet as the settled science, when there is no such thing in nutrition.  “Eat produce and fish” is fairly uncontroversial, but they recommend a lot more refined grains than many other people.  I don’t know who is correct, but it was disappointing to see a book that had been so rigorous up to that point blithely paint over controversy.</p><p></p><p>[I have emailed Michael Otto about the handling of nutrition and have yet to hear back].</p><p></p><p>Speaking of which <em>Exercise for Mood and Anxiety</em> mentions that both aerobic (cardio) and anaeorbic (weights) are good for mood, but every single example is cardio, with an occasional cardio + core strength.</p><p></p><p>Mixed in through the book are tales of how Olympic athletes motivate themselves.  This feels spectacularly irrelevant to me.  I don’t want to win a gold medal, I want to climb V2s and be happy.</p><p></p><h4>You might find this book valuable if:</h4><p></p><ul><li><p>You want some ideas (although not conclusive proof) around how exercise helps mood.</p></li><li><p>You want to want to exercise, and want scripts and tools to transform that into “want to exercise right now.”</p></li><li><p>You find exercise unpleasant and want to get the best trade of unpleasantness-for-benefits possible.</p></li><li><p>You would like to treat a mood issue with exercise (whether it reaches the level of official disorder or not).</p></li><li><p>You want to change how you think about exercise (for improving your mood or something else).</p></li><li><p>You are interested in CBT or mindfulness and want to practice with the large print version before tackling them directly.</p></li><li><p>You think you are different than my test audience.</p></li></ul><h4>You probably won’t find this book valuable if:</h4><p></p><ul><li><p>You already have an exercise program you are happy with.</p></li><li><p>You have body image or eating disorder issues (last chapter only, and a single section of the 10th,  the rest of it is fine).</p></li><li><p>You want prescriptions for a particular exercise program, as opposed to general principles.</p></li><li><p>You want to learn the nitty gritty of how exercise affects mood.</p></li><li><p>You are similar to my test audience.</p></li></ul><p> </p><p></p><p> </p><p></p><p>Post supported by <a href=\"https://www.patreon.com/acesounderglass\">Patreon</a>.</p></div></div></div></div>",
    "user": {
      "username": "pktechgirl",
      "slug": "elizabeth-1",
      "displayName": "Elizabeth"
    }
  },
  {
    "_id": "exxGw52mxMRGbrosw",
    "title": "Is Feedback Suffering?",
    "slug": "is-feedback-suffering",
    "pageUrl": "https://www.lesswrong.com/posts/exxGw52mxMRGbrosw/is-feedback-suffering",
    "postedAt": "2017-09-09T22:20:51.323Z",
    "baseScore": 9,
    "voteCount": 3,
    "commentCount": 8,
    "meta": false,
    "question": false,
    "url": "https://mapandterritory.org/is-feedback-suffering-cf18006deca8",
    "htmlBody": "<p><em>NB: Some of the terminology and concepts I used here are incompatible with my more recent work because this was written before I <a href=\"https://mapandterritory.org/introduction-to-noematology-fac7ae7d805d\">formalized my philosophy</a>, but is dangerously close enough to them that it may cause confusion. Caveat lector.</em></p><p>In the future, the world may be filled with creatures other than humans and animals. There may be <a href=\"https://mapandterritory.org/developmental-psychology-in-the-age-of-ems-6f159f701354\">ems</a>, <a href=\"https://nickbostrom.com/superintelligence.html\">superintelligences</a>, and <a href=\"http://www.overcomingbias.com/2017/07/philosophy-vs-duck-tests.html#more-31581\">other sorts of processes we&#x2019;d recognize as alive</a>, and it seems likely that <a href=\"https://concepts.effectivealtruism.org/concepts/number-of-future-people/\">there will be many orders of magnitude more of these living things in the future</a> than at present. As a result there may be <a href=\"https://foundational-research.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/\">many orders of magnitude more future suffering</a>. Depending on your moral stance, even if you&#x2019;re an <a href=\"https://mapandterritory.org/nothing-is-forbidden-but-some-things-are-good-b57f2aa84f1b\">anti-realist like me and simply express a preference for the satisfaction of preferences of others</a>, this means that the lives of these future creatures are of <a href=\"http://effective-altruism.com/ea/183/the_asymmetry_and_the_far_future/\">great concern</a>.</p><p><a href=\"https://medium.com/u/b5f33797c182\">Brian Tomasik</a> and others with the <a href=\"https://foundational-research.org/\">Foundational Research Institute</a> have been exploring the interaction between <a href=\"https://foundational-research.org/the-case-for-suffering-focused-ethics/\">suffering-focused ethics</a> and <a href=\"https://foundational-research.org/risks-of-astronomical-future-suffering/\">the far future</a> for a few years now. Their work has included <a href=\"https://foundational-research.org/measuring-happiness-and-suffering/\">measuring suffering and happiness</a>, <a href=\"https://foundational-research.org/formalizing-preference-utilitarianism-in-physical-world-models/\">formalizing ethical calculations</a>, and understanding <a href=\"https://foundational-research.org/gains-from-trade-through-compromise/\">the benefits of compromise</a> with other value systems, but of particular interest to me are Brian&#x2019;s looks into issues around <a href=\"https://foundational-research.org/a-dialogue-on-suffering-subroutines/\">suffering of minimally conscious processes</a> because <a href=\"https://foundational-research.org/the-eliminativist-approach-to-consciousness/\">his thoughts</a> on consciousness <a href=\"https://mapandterritory.org/phenomenological-complexity-classes-8b41836437b9\">resemble mine</a>. Thus when I read FRI researcher Lukas Gloor&#x2019;s recent piece on <a href=\"https://foundational-research.org/tranquilism/\">tranquilism</a> I was primed to find myself wondering, rather alarmingly, is feedback suffering?</p><p>To understand why, <a href=\"https://mapandterritory.org/phenomenological-complexity-classes-8b41836437b9\">recall</a> that feedback is another name for the process by which a subject is <a href=\"http://www.encyclopedia.com/humanities/encyclopedias-almanacs-transcripts-and-maps/consciousness-phenomenology\">phenomenologically conscious</a> and experiences itself as object. Further, most feedback is either positive or negative, meaning it causes action towards or away from a state, respectively. As humans we experience positive and negative feedback as a desire that the world be in a state other than the one it is currently in, and tranquilism suggests that suffering arises from desire since not experiencing desire yields a state we call contentment. But if we can avoid suffering by not experiencing desire, which is to say positive and negative feedback, then it looks a lot like feedback is inherently painful and thus the source of suffering. That&#x2019;s distressing because it implies most existence is pain and <a href=\"http://reducing-suffering.org/is-there-suffering-in-fundamental-physics/\">almost all physical processes suffer constantly</a>, so it seems to me worthwhile to make a formal study of suffering to see if we might poke some holes in this line of reasoning.</p><p>I&#x2019;ll do this from an <a href=\"http://www.phenomenologyonline.com/inquiry/orientations-in-phenomenology/existential-phenomenology/\">existentialist phenomenological</a> stance, which is to say that stuff exists, stuff is only known through experience, and experience is an inseparable, directed, intentional relationship between stuffs where we term the experiencing stuff &#x201C;subject&#x201D; and the experienced stuff &#x201C;object&#x201D;. Consequently in order to be precise and to avoid equivocation I&#x2019;m going to have to write the word &#x201C;experience&#x201D; a lot, so my apologies for the word soup that sometimes follows.</p><h3>Phenomenology of Suffering</h3><p>Whether or not feedback is suffering is ultimately a question of axiology, the study of value. That is, when we ask if feedback is suffering we are asking a question about how to measure the value of feedback. Since I&#x2019;m an existentialist and a phenomenologist, I&#x2019;m additionally willing to say that we must calculate value for ourselves rather than find it because there is nowhere for it to come from other than our experiences, and since value is a <a href=\"https://en.wikipedia.org/wiki/Measure_%28mathematics%29\">measure</a> we must then choose what to measure against. This choice forces an inescapable telos upon value, and in this case that telos appears rooted in emotion since we think of suffering as an emotional state with <a href=\"https://en.wikipedia.org/wiki/Valence_%28psychology%29\">negative valence</a>. Further, since I feel positive emotional valence (happiness) when other people feel positive emotional valence and negative emotional valence (sadness) when other people feel negative emotional valence&#x200A;&#x2014;&#x200A;viz. I am empathetic and care about other people&#x200A;&#x2014;&#x200A;and most other people feel the same way, our telos is additionally ethical because we want to know how our actions will affect the happiness and sadness of others. Thus, as you probably already surmised, we&#x2019;re going to be valuing if feedback is ethically desirable or not.</p><p>Ethical systems, being axiological systems for the purpose of judging intent, are calculi for how to combine experience via <a href=\"https://en.wikipedia.org/wiki/Relation_%28mathematics%29\">relations</a> that yield value. We can additionally place optimization constraints on these systems, like maximizing the value of preference-satisfying experiences or minimizing the value of preference-violating experiences, to produce specific axiologies, like hedonic axiology and negative hedonic axiology, respectively. This gives us a language in which to talk precisely about axiological and ethical systems, and in this language tranquilist axiology is the axiological system where experiences are combined to maximize the value of experiences of contentment.</p><p>To be intellectually honest to myself about what tranquilism means, I need to phenomenological deconstruct contentment. <a href=\"http://www.buddhisma2z.com/content.php?id=83\">Descriptions of contentment</a> make it sound something like an experience of anhedonia where the subject experiences indifference towards suffering and pleasure, but this seems unsatisfactory because these descriptions also assign contentment a positive rather than neutral valence. Lukas similarly agrees that contentment is a happy experience when <a href=\"https://foundational-research.org/tranquilism/\">he writes</a> that contentment is &#x201C;untroubled by any cravings for more pleasure&#x201D;, &#x201C;experienced as completely problem-free&#x201D;, and that &#x201C;conscious states completely free of cravings should thus elicit very positive associations&#x201D;. So it seems when one is content one is happy, indifferent to more happiness, and does not suffer, but this appears contradictory because to be content one would have to be happy about preference violation, a definitionally sad experience because negative valence emotions are the feedback mechanism we use for experiences of preferences.</p><p>This is only a problem, though, if we limit our axiology to valuing experiences and experiences of experiences. If we include experiences of experiences of experiences in our ontology rather than compressing them into experiences of experiences, thus making a <a href=\"https://mapandterritory.org/phenomenological-complexity-classes-8b41836437b9\">systems-level demand for ontological complexity</a>, we can understand contentment as an experience of happiness towards all experiences of experiences and use it to direct tranquilist axiological reasoning. In this way contentment wraps happy and sad experiences in an experience of happiness, making it of a different <a href=\"https://en.wikipedia.org/wiki/Type_theory\">type</a> and avoiding apparent contradiction by adding happiness to rather than changing the original experience from pleasure or suffering.</p><p>Having deconstructed contentment and understood tranquilism precisely, it appears my original concerns about feedback being suffering were confused because if suffering, a negative valence experience, is something we can be content with, then in this context suffering must be an experience of experience and thus feedback cannot necessarily be suffering because feedback can exist as a direct experience not just a meta-experience.</p><p>I seem <a href=\"http://effective-altruism.com/ea/1cn/why_i_think_the_foundational_research_institute/\">not alone in needing to clear this confusion</a> because our everyday use of the word &#x201C;suffering&#x201D; points to at least two different categories the same way &#x201C;consciousness&#x201D; does. Just as we can separate naive notions of consciousness into phenomenological consciousness (self-experience) and phenomenological sentience (experience of self-experience), we can separate suffering into phenomenological desire (intention to make the world otherwise) and phenomenological suffering (experience of negative valence over desire). Cleaved in this way we see that feedback is desire but not necessarily suffering, but suffering is often confounded with desire in sentient subjects because meta-experiences can be both desire and suffering. This unfortunately leaves open the possibility that the feedback of sentience is often suffering even if it doesn&#x2019;t have to be.</p><h3>Panpsychism and Suffering</h3><p>If something must be sentient to suffer, it may seem we need only worry much about suffering among animals and animal-like things such as ems and AIs, and even their suffering is only ethically relevant <a href=\"http://www.overcomingbias.com/2017/07/philosophy-vs-duck-tests.html#more-31581\">as far as your empathy extends</a>. But what if more things are sentient than we think?</p><p>Phenomenological consciousness implies a weak form of panpsychism&#x200A;&#x2014;&#x200A;the idea that everything is at least a little bit conscious. But most people don&#x2019;t care about <a href=\"https://mapandterritory.org/phenomenological-complexity-classes-8b41836437b9\">the phenomenological consciousness of rocks and chairs</a>, so there may be panpsychism but it&#x2019;s a very boring kind of panpsychism that isn&#x2019;t affecting anyone&#x2019;s ethics. A strong panpsychism based on sentience would be another story since many people, <a href=\"https://concepts.effectivealtruism.org/concepts/wild-animal-suffering/\">including many effective altruists</a>, say <a href=\"https://www.scientificamerican.com/article/how-science-can-inform-ethics-and-champion-sentient-beings/\">sentience is the criterion for ethical relevance</a>.</p><p>Many simple control systems, such as thermostats, may have phenomenological sentience because their operation can be construed in terms of meta-experience of self. The leading mathematical theory of sentience, <a href=\"http://www.iep.utm.edu/int-info/\">Integrated Information Theory</a>, would seem to agree, likely scoring such systems as minimally &#x201C;conscious&#x201D; (IIT uses &#x201C;consciousness&#x201D; where I use &#x201C;sentience&#x201D;). Although it seems unlikely that something as simple as a thermostat experiences suffering in the sense of a negative valence experience of desire, perhaps there is some way in which meta-experiences we&#x2019;d recognize as suffering can be defined that do not depend on negative valence emotions. This is important because it would allow us to identify suffering or suffering-like experiences in subjects that do not have something resembling the evolved emotional systems of animals.</p><p>I don&#x2019;t (yet) have any further thoughts on such suffering-like experiences, but having a phenomenological deconstruction of suffering it may prove possible to make progress on understand suffering in terms of non-emotional experiences.</p><h3>TL;DR</h3><p>Okay, that wasn&#x2019;t too long, but it was pretty dense, so in case you were wonder what the heck I was saying, here&#x2019;s the short version:</p><ul><li>Feedback is desire but not necessarily suffering</li><li>Suffering is a kind of feedback with negative emotional valence and animals seem to experience desire as suffering.</li><li>Contentment wraps up suffering in happiness by adding ontological complexity to create distance from the experience of negative emotional valence.</li><li>Many things may have some sentience and so may be able to suffer or experience something like suffering.</li><li>I&#x2019;m going to think more about if there is some way to talk about suffering prior to emotion so we can considering the suffering of non-emotive sentient beings, especially for those who do not have the ontological complexity to learn contentment.</li></ul>",
    "user": {
      "username": "gworley",
      "slug": "gordon-seidoh-worley",
      "displayName": "Gordon Seidoh Worley"
    }
  },
  {
    "_id": "afcweBCS8rQuNwK4q",
    "title": "Rational Feed",
    "slug": "rational-feed",
    "pageUrl": "https://www.lesswrong.com/posts/afcweBCS8rQuNwK4q/rational-feed",
    "postedAt": "2017-09-09T19:48:18.079Z",
    "baseScore": 20,
    "voteCount": 13,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p style=\"margin: 0px 0px 0.357143em; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">=== Updates:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\">I have been a little more selective about which articles make it onto the feed. I have not been overly selective and all of the obviously general interest rationalsit articles still make it.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\">Unless people object I am going to try a \"weekly feed\". The bi-weekly feed is pretty long. I currently post on the SSC reddit and lesswrong. Weekly seems fine for the SSC reddit but lesswrong is a lower activity forum. I will see how it goes. Obviously on a weekly feed there will about half as many recommended articles.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Highly Recommended Articles:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://balioc.tumblr.com/post/165059382441/azdoine-balioc-under-modern-post-industrial?is_related_post=1\">Object, Subjects and Gender by The Baliocene Apocrypha</a>&nbsp;- \"Under modern post-industrial bureaucratized high-tech capitalism, it is less rewarding than ever before to be a subject. Under modern post-industrial bureaucratized high-tech capitalism, it is more rewarding than ever before to be an object. This alone accounts for a lot of the widespread weird stuff going on with gender these days.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://www.ribbonfarm.com/2017/08/29/winning-is-for-losers/\">Winning Is For Losers by Putanumonit (ribbonfarm)</a>&nbsp;- Zero vs Positive Sum Games. The strong have room to cooperate. Rene Girard's theory of mimetics and competition. College Admissions. Tit for Tat. Spiked dicks in nature. Short and long term strategies in dating. Quirky dating profiles. Honesty on the first date. Beating Moloch with a transhuman God.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://putanumonit.com/2017/08/26/premium-mediocre\">Premium Mediocre by Jacob Falkovich</a>&nbsp;- Being 30% wrong is better than being 5% wrong. Consumption: Signaling vs genuine enjoyment. Dating other PM people. Venkat is wrong about impressing parents. He is more wrong, or joking, about cryptocurrencies. Fear of missing out.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1eg/ten_new_80000_hours_articles_aimed_at_the/\">Ten New 80000 Hours Articles Aimed At The by 80K Hours (EA forum)</a>&nbsp;- Ten recent articles and descriptions from 80K hours. Over and underpaid jobs relative to their social impact, the most employable skills, learning ML, whether most social programs work and other topics.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://entirelyuseless.wordpress.com/2017/09/03/minimizing-motivated-beliefs/\">Minimizing Motivated Beliefs by Entirely Useless</a>&nbsp;- The tradeoffs between epistemic and instrumental rationality. Yudkowsky's argument such tradeoffs either very stupid or don't exist. Issues with Yudkowsky: Denial that belief is voluntary, thinking that trading away the truth requires being blind to consequences. Horror victims and transcendent meaning. Interesting things are usually false.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Scott:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/07/how-do-we-get-breasts-out-of-bayes-theorem/\">How Do We Get Breasts Out Of Bayes Theorem by Scott Alexander</a>&nbsp;- \"But evolutionary psychologists make claims like 'Men have been evolutionarily programmed to like women with big breasts, because those are a sign of fertility.' Forget for a second whether this is politically correct, or cross-culturally replicable, or anything like that. From a neurological point of view, how could this possibly work?\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/06/predictive-processing-and-perceptual-control/\">Predictive Processing And Perceptual Control by Scott Alexander</a>&nbsp;- \"predictive processing attributes movement to strong predictions about proprioceptive sensations. Because the brain tries to minimize predictive error, it moves the limbs into the positions needed to produce those sensations, fulfilling its own prophecy.\" Connections with Will Power's 'Behavior: The Control of Perception' which Scott already reviewed.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/\">Book Review: Surfing Uncertainty by Scott Alexander</a>&nbsp;- Scott finds a real theory of how the brain works. \"The key insight: the brain is a multi-layer prediction machine. All neural processing consists of two streams: a bottom-up stream of sense data, and a top-down stream of predictions. These streams interface at each level of processing, comparing themselves to each other and adjusting themselves as necessary.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/08/31/links-817-exsitement/\">Links: Exsitement by Scott Alexander</a>&nbsp;- Slatestarcodex links post. A Nootropics survey, gene editing, AI, social norms, Increasing profit margins, politics, and other topics.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/08/31/highlights-from-the-comments-on-my-irb-nightmare/\">Highlights From The Comments On My Irb Nightmare by Scott Alexander</a>&nbsp;- Tons of hilarious IB stories. A subreddit comment about getting around irb. Whether the headaches are largely institutional rather than dictated by government fiat. Comments argue in favor of the irb and Scott responds.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/08/29/my-irb-nightmare/\">My IRB Nightmare by Scott Alexander</a>&nbsp;- Scott tries to run a study to test the Deck Depression Inventory. The institutional review board makes this impossible. They not only make tons of capricious demands they also attempt to undermine the study's scientific validity.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/08/27/ot83-slippery-slopen-thread/\">Slippery Slopen Thread by Scott Alexander</a>&nbsp;- Public open thread. The slippery slope to rationalist catgirl. Selected top comments. Update on Trump and crying wolf.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://slatestarcodex.com/2017/08/28/contra-askell-on-moral-offsets/\">Contra Askell On Moral Offsets by Scott Alexander</a>&nbsp;- Axiology is the study of what&rsquo;s good. Morality is the study of what the right thing to do is. You can offset axiological effects but you can't offset moral transgressions.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Rationalist:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/09/mre-futures-to-not-starve.html\">MRE Futures To Not Starve by Robin Hanson</a>&nbsp;- Emergency food sources as a way to mitigate catastrophic risk. The Army's 'Meals Ready to Eat'. Food insurance. Incentives for producers to deliver food in emergencies. Incentives for researchers to find new sources. Sharing information.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://putanumonit.com/2017/09/09/book-reviews-zoolitude-and-the-void/\">Book Reviews: Zoolitude And The Void by Jacob Falkovich</a>&nbsp;- Seven Surrenders the sequel to 'Too like the Lightning' mercilessly cuts the bad parts and focuses on the politics, personalities, and philosophy that made TLTL great. The costs of adding too much magic to a setting, don't make the mundane irrelevant. One Hundred Years of Solitude: Shit just happens. Zoo City: Realistic Magic: \"The Zoo part is the magic: some people who commit crimes mysteriously acquire an animal familiar and a low-key magical talent.\" The Mark and the Void: \"Technically, there&rsquo;s no magic in The Mark and the Void. But there&rsquo;s investment banking, which takes the role of the mysterious force that decides the fate of individuals and nations but remains beyond the ken of mere mortals.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://www.ribbonfarm.com/2017/09/07/the-world-as-if/\">The World As If by Sarah Perry (ribbonfarm)</a>&nbsp;- \"This is an account of how magical thinking made us modern.\" Magical thinking as a confusing of subjective and objective. Useful fictions. Hypothetical thinking. Pre-modern concrete thinking and categorization schemes relative to modern abstract ones. As if thinking. Logic and magic.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://kajsotala.fi/2017/09/to-save-the-world-make-sure-to-go-beyond-academia/\">To Save The World Make Sure To Go Beyond Academia by Kaj Sotala</a>&nbsp;- Academic research often fails to achieve real change. Lots of economic research concerns the optimal size of a carbon tax but we currently lack any carbon tax. Academic research on x-risk from nuclear winter doesn't change the motivations of politicians very much.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://mindlevelup.wordpress.com/2017/09/08/introducing-mindlevelup-the-book/\">Introducing Mindlevelup The Book by mindlevelup</a>&nbsp;- MLU compiled and edited their work from 2017 into a 30K word, 150 page book. Most of the material appeared on the blog but some of it is new and the pre-existing posts have been edited for clarity.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://thezvi.wordpress.com/2017/09/05/expanding-premium-mediocrity/\">Expanding Premium Mediocrity by Zvi Moshowitz</a>&nbsp;- \"This is (much of) what I think Rao is trying to say in the second section of his post, the part about Maya but before Molly and Max, translated into DWATV-speak. Proceed if and only if you want that.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://particularvirtue.blogspot.com/2017/09/simple-affection-and-deep-truth.html\">Simple Affection And Deep Truth by Particular Virtue</a>&nbsp;- \"Simple Affection is treating someone like a child: they will forget about bad things, as long as you give them something good to think about instead. Deep Truth is treating someone like an elephant: they never forget, and they forgive only with deep deliberation.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://sailorvulcansstarship.blogspot.com/2017/09/are-people-innately-good-or.html\">Are People Innately Good by Sailor Vulcan</a>&nbsp;- SV got into two arguments that went badly. One was on all lives matter. The other occurred when SV tried to defend Glen of Intentional Insights on the SSC discord. Terminal values aren't consistent. SV was abused as a child.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://samzdat.com/2017/09/05/metapost-september-5th/\">Metapost September 5th by sam[]zdat</a>&nbsp;- Plans for the blog. Next series will be on epistemology and the ''internal' side of nhilism. Revised introduction. Sam will probably write fiction. Site reorganization. History section. Current reading list. Patreon.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://entirelyuseless.wordpress.com/2017/09/03/minimizing-motivated-beliefs/\">Minimizing Motivated Beliefs by Entirely Useless</a>&nbsp;- The tradeoffs between epistemic and instrumental rationality. Yudkowsky's argument such tradeoffs either very stupid or don't exist. Issues with Yudkowsky: Denial that belief is voluntary, thinking that trading away the truth requires being blind to consequences. Horror victims and transcendent meaning. Interesting things are usually false.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://thezvi.wordpress.com/2017/09/02/exploring-premium-mediocrity/\">Exploring Premium Mediocrity by Zvi Moshowitz</a>&nbsp;- Defining premium mediocre. Easy and hard mode related to Rao's theories of losers, sociopaths and heroes. The Real Thing. A 2x2 ribbonfarm style graph. Restaurants.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/09/tegmarks-book-of-foom.html\">Tegmarks Book Of Foom by Robin Hanson</a>&nbsp;- Tegmark's recent book basically described Yudkowsky's intelligence explosion. Tegmark is worried the singularity might be soon and we need to have figured out big philosophical issues by then. Hanson thinks Tegmark overestimates the generality of intelligence. AI weapons and regulations.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/pdd/the_doomsday_argument_in_anthropic_decision_theory/\">The Doomsday Argument In Anthropic Decision Theory by Stuart Armstrong (lesswrong)</a>&nbsp;- \"In Anthropic Decision Theory (ADT), behaviors that resemble the Self Sampling Assumption (SSA) derive from average utilitarian preferences. However, SSA implies the doomsday argument. This post shows there is a natural doomsday-like behavior for average utilitarian agents within ADT.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/08/forager-v-farmer-elaborated.html\">Forager Vs Farmer Elaborated by Robin Hanson</a>&nbsp;- Early humans collapsed Machiavellian dynamics down to a reverse-dominance-hierarchy. Group norm enforcement and its failure modes. Safety leads to collective play and art, threat leads to a return to Machiavellianisn and suspicion. Individuals greatly differ as to what level of threat causes the switch, often for self-serving reasons. Left vs right. \"The first and primary political question is how much to try to resolve issues via a big talky collective, or to let smaller groups decide for themselves.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://meteuphoric.wordpress.com/2017/08/30/critiquing-other-peoples-plans-politely/\">Critiquing Other Peoples Plans Politely by Katja Grace</a>&nbsp;- Three failure modes: The attack, The polite sidestep, The inadvertent personal question. A plan to avoid these issues: debate beliefs, not actions.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://srconstantin.wordpress.com/2017/08/30/gleanings-from-double-crux-on-the-craft-is-not-the-community/\">Gleanings From Double Crux On The Craft Is Not The Community by Sarah Constantin</a>&nbsp;- Results from Sarah's public double crux. Sarah initially did not think the rationalist intellectual project was worth preserving. She wants to see results, even though she concedes that formal results can be very difficult to get. What is the value of introspection and 'navel grazing'?</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"/r/discussion/lw/pcc/intrinsic_properties_and_eliezers_metaethics/\">Intrinsic Properties And Eliezers Metaethics by Tyrrell_McAllister (lesswrong)</a>&nbsp;- Intuitions of intrinsicness. Is goodness intrinsic? Seeing intrinsicness in simulations. Back to goodness.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://www.ribbonfarm.com/2017/08/29/winning-is-for-losers/\">Winning Is For Losers by Putanumonit (ribbonfarm)</a>&nbsp;- Zero vs Positive Sum Games. The strong have room to cooperate. Rene Girard's theory of mimetics and competition. College Admissions. Tit for Tat. Spiked dicks in nature. Short and long term strategies in dating. Quirky dating profiles. Honesty on the first date. Beating Moloch with a transhuman God.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://everythingstudies.wordpress.com/2017/08/28/dangers-at-dilettante-point/\">Dangers At Dilettante Point by Everything Studies</a>&nbsp;- Its relatively easy to know a little about alot of topics. But its dangerous to find yourself playing the social role of the knowledgeable person too often. The percentage fo people with a given level of knowledge goes to zero quickly.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.overcomingbias.com/2017/08/entrenchit-happens.html\">Entrenchment Happens by Robin Hanson</a>&nbsp;- Many systems degrade, collapse and our replaced. However other systems, even somewhat arbitrary ones, are very stable over time. Many current systems in programming, language and law are likely to remain in the future.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://putanumonit.com/2017/08/26/premium-mediocre\">Premium Mediocre by Jacob Falkovich</a>&nbsp;- Being 30% wrong is better than being 5% wrong. Consumption: Signaling vs genuine enjoyment. Dating other PM people. Venkat is wrong about impressing parents. He is more wrong, or joking, about cryptocurrencies. Fear of missing out.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===AI:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1eb/ideological_engineering_and_social_control_a/\">Ideological Engineering And Social Control by Geoffrey Miller (EA forum)</a>&nbsp;- China is trying hard to develop advanced AI. A major goal is to use AI to monitor both physical space and social media. Supressing wrong-think doesn't require radically advanced AI.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://intelligence.org/2017/08/31/incorrigibility-in-cirl/\">Incorrigibility In Cirl by The MIRI Blog</a>&nbsp;- Paper. Goal: Incentivize a value learning system to follow shut down instructions. Demonstration that some assumptions are not stable with respect to model mis-specification (ex programmer error). Weaker sets of assumptions: difficulties and simple strategies.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1dz/nothing_wrong_with_ai_weapons/\">Nothing Wrong With Ai Weapons by kbog (EA forum)</a>&nbsp;- Death by AI is no more intrinsically bad than death by conventional weapons. Some consequenitoualist issues the author addresses: Civilian deaths, AI arms race, vulnerability to hacking.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===EA:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.poverty-action.org/blog/can-outsourcing-improve-liberias-schools-preliminary-rct-results\">Can Outsourcing Improve Liberias Schools Preliminary RCT Results by Innovations for Poverty</a>&nbsp;- \"Last summer, the Liberian government delegated management of 93 public elementary schools to eight different private contractors. After one year, public schools managed by private operators raised student learning by 60 percent compared to standard public schools. But costs were high, performance varied across operators, and contracts authorized the largest operator to push excess pupils and under-performing teachers into other government schools.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1eg/ten_new_80000_hours_articles_aimed_at_the/\">Ten New 80000 Hours Articles Aimed At The by 80K Hours (EA forum)</a>&nbsp;- Ten recent articles and descriptions from 80K hours. Over and underpaid jobs relative to their social impact, the most employable skills, learning ML, whether most social programs work and other topics.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1ef/is_ea_growing_some_ea_growth_metrics_for_2017/\">Is Ea Growing Some Ea Growth Metrics For 2017 by Peter Hurford (EA forum)</a>&nbsp;- Activity metrics for EA website, donations data, additional Facebook data, commentary that EA seems to be growing but there is substantial uncertainty.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1e5/ea_survey_2017_series_cause_area_preferences/\">Ea Survey 2017 Series Cause Area Preferences by Tee (EA forum)</a>&nbsp;- Top Cause Area, near-top areas, areas which should not have EA resources, cause area correlated with demographics, donations by cause area.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1e3/looking_at_how_superforecasting_might_improve/\">Looking At How Superforecasting Might Improve AI Predictions by Will Pearson (EA forum)</a>&nbsp;- Good Judgement Project: What they did, results, relevance. Lessons: Focus on concrete issues, focus on AI with no intelligence augmentation, learn a diverse range of subjects, breakdown the open questions, publicly update.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://blog.givewell.org/2017/08/30/why-were-allocating-discretionary-funds-to-the-deworm-the-world-initiative/\">Why Were Allocating Discretionary Funds To The Deworm The World Initiative by The GiveWell Blog</a>&nbsp;- \"Why Deworm the World has a pressing funding need. The benefits and risks of granting discretionary funds to Deworm the World today. Why we&rsquo;re continuing to recommend that donors give 100% of their donation to AMF.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1e1/ea_survey_2017_series_community_demographics/\">Ea Survey 2017 Series Community Demographics by Katie Gertsch (EA forum)</a>&nbsp;- Some results: Mostly young and male, slight increase in female participation. Highest concentration cities. Atheism/Agnostic rate fell from 87% to 80%. Increase in the proportion of EA who see EA as a duty or opportunity as opposed to an obligation.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://effective-altruism.com/ea/1e0/effective_altruism_survey_2017_distribution_and/\">Effective Altruism Survey 2017 Distribution And by Ellen McGeoch and Peter Hurford (EA forum)</a>&nbsp;- EA 2017 Study results are in. Details about distribution abd data analysis techniques. Discussion of whether the subpopulation is a representative sample of EA and its subpopulations.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://blog.givewell.org/2017/08/28/archive-6-tips-disaster-relief-giving/\">Six Tips Disaster Relief Giving by The GiveWell Blog</a>&nbsp;- Practical advice for effective disaster relief charity. Give Cash, give to proven effective charities and allow charities significant freedom in how they use your donation.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Politics and Economics:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/harvard-admit-legacy-students.html\">Harvard Admit Legacy Students by Marginal Revolution</a>&nbsp;- Demand for Ivy league admissions far outstrips supply. The main constraint is that the Ivy League depends on donations. One way to scale up, while maintaining high donation rates, is to increase legacy admissions. Teaching quality is unlikely to suffer, qualified students are easy to find.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://balioc.tumblr.com/post/165059382441/azdoine-balioc-under-modern-post-industrial?is_related_post=1\">Object, Subjects and Gender by The Baliocene Apocrypha</a>&nbsp;- \"Under modern post-industrial bureaucratized high-tech capitalism, it is less rewarding than ever before to be a subject. Under modern post-industrial bureaucratized high-tech capitalism, it is more rewarding than ever before to be an object. This alone accounts for a lot of the widespread weird stuff going on with gender these days.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://nintil.com/2017/09/06/links-11/\">Links 11 by Artir</a>&nbsp;- Psychology, Politics, Economics, Philosophy, Other. Several links related to the Google memo.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://juliagalef.com/2017/09/05/unpopular-ideas-about-crime-and-punishment/\">Unpopular Ideas About Crime And Punishment by Julia Galef</a>&nbsp;- Thirteen opinions on prison abolition, the death penalty, corporal punishment, rehabilitation, redistribution and more.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://marginalrevolution.com/marginalrevolution/2017/09/intangible-investment-monopoly-profits.html\">Intangible Investment and Monopoly Profits by Marginal Revolution</a>&nbsp;- \"Intangible capital used to be below 30 percent of the S&amp;P 500 in the 70s, now it is about 84 percent. \" Seven implications about profit, monopoly, spillover, etc.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://meteuphoric.wordpress.com/2017/08/30/what-you-cant-say-to-a-sympathetic-ear/\">What You Cant Say To A Sympathetic Ear by Katja Grace</a>&nbsp;- Sharing socially unacceptable views with your friends is putting them in a bad situation, regardless of whether they agree with those ideas. If they don't punish you society will hold them complicit. Socially condemning views is worse than commonly thought \"To successfully condemn a view socially is to lock that view in place with a coordination problem.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://jacobitemag.com/2017/08/29/a-i-bias-doesnt-mean-what-journalists-want-you-to-think-it-means/\">A I Bias Doesnt Mean What Journalists Want You To Think It Means by Chris Stucchio And Lisa Mahapatra (Jacobite)</a>&nbsp;- What is data science and AI? What is bias? How do we identify bias? The fallout of the author's algorithm. Predicting Creditworthiness. Understanding Language. Predicting Criminal Behavior. Journalists and Wishful Thinking.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://econlog.econlib.org/archives/2017/08/four_decades_of.html\">Four Decades of the Middle East by Bryan Caplan</a>&nbsp;- \"Almost all of the Middle East's disasters over the past four decades can be credibly traced back to a single highly specific major event: the Iranian Revolution. Let me chronicle the tragic trail of dominoes.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://samzdat.com/2017/08/28/the-thresher/\">The Thresher by sam[]zdat</a>&nbsp;- \"Still, if what makes 'modernity' modernity is partially in technology, then the Uruk Machine will be updated and whirring at unfathomable speeds, the thresher to Gilgamesh&rsquo;s sacred club.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://samzdat.com/2017/08/28/the-uruk-machine/\">The Uruk Machine by sam[]zdat</a>&nbsp;- Sam's fundamental framework: Seeing like a State, The Great Transformation, The True Believer, The Culture of Narcissism.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Misc:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.bayesianinvestor.com/blog/index.php/2017/09/04/into-the-gray-zone/\">Into The Gray Zone by Bayesian Investor</a>&nbsp;- Book Review. A modest fraction of people diagnosed as being in a persistent vegetative state have locked in syndrome. People misjudge when they would want to die. Alzheimer's.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><span style=\"font-style: inherit; font-weight: 600; margin: 0px;\">===Podcast:</span></p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://wakingup.libsyn.com/95-what-you-need-to-know-about-climate-change\">What You Need To Know About Climate Change by Waking Up with Sam Harris</a>&nbsp;- \"How the climate is changing and how we know that human behavior is the primary cause. They discuss why small changes in temperature matter so much, the threats of sea-level rise and desertification, the best and worst case scenarios, the Paris Climate Agreement, the politics surrounding climate science.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://www.stitcher.com/podcast/the-ezra-klein-show/e/51347284\">Dan Rather by The Ezra Klein Show</a>&nbsp;- \"Rather and I discuss the Trump presidency and what it means for the Republican Party's future, our fractured media landscape, and Rather's own evolving career in media.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://econlog.econlib.org/archives/2017/09/caplan_family_s_1.html\">Caplan Family by Bryan Caplan</a>&nbsp;- \"For the last two years, I homeschooled my elder sons, Aidan and Tristan, rather than send them to traditional middle school. Now they've been returned to traditional high school. We decided to mark our last day with a father-son/teacher-student podcast on how we homeschooled, why we homeschooled, and what we achieved in homeschool.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.econtalk.org/archives/2017/09/rob_reich_on_fo.html\">Rob Reich On Foundations by EconTalk</a>&nbsp;- \"The power and effectiveness of foundations--large collections of wealth typically created and funded by a wealthy donor. Is such a plutocratic institution consistent with democracy? Reich discusses the history of foundations in the United States and the costs and benefits of foundation expenditures in the present.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://rationallyspeakingpodcast.org/show/rs-192-jesse-singal-on-the-problems-with-implicit-bias-tests.html\">Jesse Singal On The Problems With Implicit Bias Tests by Rational Speaking</a>&nbsp;- \"The IAT has been massively overhyped, and that in fact there's little evidence that it's measuring real-life bias. Jesse and Julia discuss how to interpret the IAT, why it became so popular, and why it's still likely that implicit bias is real, even if the IAT isn't capturing it.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.thebayesianconspiracy.com/2017/08/42-emotionally-charged-discussion/\">Emotionally Charged Discussion by The Bayesian Conspiracy</a>&nbsp;- Conversations where one party thinks the other sides position is stupid/evil/etc. Debate vs truth seeking. Julia Galef's lists of unpopular ideas. Agenty Duck's thoughts on introspection. Double Crux.</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://wakingup.libsyn.com/94-the-future-of-intelligence\">The Future Of Intelligence by Waking Up with Sam Harris</a>&nbsp;- \"Max Tegmark. His new book Life 3.0: Being Human in the Age of Artificial Intelligence. They talk about the nature of intelligence, the risks of superhuman AI, a nonbiological definition of life, the substrate independence of minds, the relevance and irrelevance of consciousness for the future of AI, near-term breakthroughs in AI.\"</p>\n<p style=\"margin: 0.357143em 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"http://www.econtalk.org/archives/2017/08/benedict_evans.html\">Benedict Evans by EconTalk</a>&nbsp;- \"Two important trends for the future of personal travel--the increasing number of electric cars and a world of autonomous vehicles. Evans talks about how these two trends are likely to continue and the implications for the economy, urban design, and how we live.\"</p>\n<p style=\"margin: 0.357143em 0px 0px; padding: 0px; font-size: 14px; line-height: 1.42857em; color: #222222; font-family: verdana, arial, helvetica, sans-serif;\"><a style=\"text-decoration-line: none; color: #0079d3; margin: 0px;\" href=\"https://80000hours.org/2017/08/the-life-of-a-quant-trader-how-to-earn-and-donate-millions-within-a-few-years/\">The Life Of A Quant Trader by 80,000 Hours</a>&nbsp;- What do quant traders do. Compensation. Is quant trading harmful? Who is a good fit and how to break into quant trading. Work environment and motivation. Variety of available positions.</p>",
    "user": {
      "username": "deluks917",
      "slug": "deluks917",
      "displayName": "sapphire"
    }
  },
  {
    "_id": "itRfxQtJjYAis2dgb",
    "title": "Book Reviews: Zoolitude and the Void",
    "slug": "book-reviews-zoolitude-and-the-void",
    "pageUrl": "https://www.lesswrong.com/posts/itRfxQtJjYAis2dgb/book-reviews-zoolitude-and-the-void",
    "postedAt": "2017-09-09T15:32:17.000Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><em>This is a novel review post, it contains m</em><em>inor spoilers for </em>One Hundred Years of Solitude <em>by </em>Gabriel Garcia Marquez, Zoo City <em>by </em>Lauren Beukes<em>,</em> <em>and</em> The Mark and the <em>Void by</em> Paul Murray<em>, as well as </em>Seven Surrenders <em>by </em>Ada Palmer <em>which I mention briefly</em>.</p>\n<p><img data-attachment-id=\"26926\" data-permalink=\"http://putanumonit.com/2017/09/09/book-reviews-zoolitude-and-the-void/zoolitude-and-the-void/\" data-orig-file=\"https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=900\" data-orig-size=\"1476,746\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Zoolitude and the void\" data-image-description=\"\" data-medium-file=\"https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=900?w=300\" data-large-file=\"https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=900?w=900\" class=\"alignnone size-full wp-image-26926\" src=\"https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=900\" alt=\"Zoolitude and the void.png\" srcset=\"https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=900 900w, https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=150 150w, https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=300 300w, https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=768 768w, https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png?w=1024 1024w, https://putanumonit.files.wordpress.com/2017/09/zoolitude-and-the-void.png 1476w\" sizes=\"(max-width: 900px) 100vw, 900px\"   /></p>\n<p>Update from the previous episode: I concluded <a href=\"https://putanumonit.com/2017/04/21/book-review-too-like-the-lightning/\" target=\"_blank\" rel=\"noopener\">my review of <em>Too </em><em>Like The Lightning</em></a> on a note of worry. Parts of that book wasted the rich and exciting weirdtopia Ada Palmer created on incongruous plots and whole chapters in Latin, and the ending seemed to set up the sequels to do the same. I didn&#8217;t think that Palmer would be willing to give up all the baggage that made <em>Lightning</em> not-quite-great, and <em>Lightning</em> was successful enough that she could afford not to.</p>\n<p>But she did anyway, <em><a href=\"https://www.goodreads.com/book/show/28220647-seven-surrenders\" target=\"_blank\" rel=\"noopener\">Seven Surrenders</a> </em>is quite-great. Palmer mercilessly cut out all the bad parts, from the obsession with pronouns to the characters that made the story stuck. <em>Seven Surrenders</em> delivers a tight plot that focuses on the politics, personalities, and philosophy that made <em>Lightning</em> so intriguing.</p>\n<p>As with movies, it&#8217;s very rare for a book sequel to be so much better than the original. <em>Seven Surrenders </em>is rated 0.34 points higher on Goodreads than <em>Lightning</em>, which is the gap between an average book and &#8220;best of&#8221; lists. The only two comparisons I could find are Neal Stephenson&#8217;s <em><a href=\"https://www.goodreads.com/series/49317-the-baroque-cycle\" target=\"_blank\" rel=\"noopener\">Baroque Cycle</a></em> and Iain Banks&#8217; <em><a href=\"https://www.goodreads.com/series/49118-culture\" target=\"_blank\" rel=\"noopener\">Culture Series</a>. </em>In both cases, every book past the second one was as good as #2 and the first book remained a low-quality outlier. I have every reason to believe that this will also be the case with Palmer&#8217;s series, and I can&#8217;t wait for <em><a href=\"https://www.goodreads.com/book/show/33517544-the-will-to-battle\" target=\"_blank\" rel=\"noopener\">The Will to</a></em><a href=\"https://www.goodreads.com/book/show/33517544-the-will-to-battle\" target=\"_blank\" rel=\"noopener\"> Battle</a><em>,</em> the third book in the series,<em> </em>to come out this winter.</p>\n<h2>A Bit of Magic</h2>\n<p>One of my main worries about <em>Lightning </em>was that it introduced too much magic into a world that didn&#8217;t need it. George R. R. Martin said in an interview that he wanted to keep the supernatural elements of <em>Song of Ice and Fire</em> to the minimum required to spice up the story. An occasional dragon, a rumor of white walkers, but no archmages dueling with world-shattering powers. The mundane world of human relationships and survival has enough tumult and mystery. How a story&#8217;s characters react to the supernatural should illuminate their reaction to the natural, not make the latter irrelevant.</p>\n<p>Although they may seem unrelated, all three novels I will talk about deal with the supernatural encroaching on the natural world. All three take place in settings (19th century Colombia, 21st century Dublin and Johannesburg) that are real but yet strange to readers outside those countries. But the novels take very different approaches to facing the strangeness, not just the differences of literary genres but fundamental differences of worldview. It&#8217;s those worldviews that I kept thinking about after reading each book, and they&#8217;re what I want to explore in the reviews.</p>\n<h2>One Hundred Years of Solitude</h2>\n<blockquote><p>A trickle of blood came out under the door, crossed the living room, went out into the street, continued on in a straight line across the uneven terraces, went down steps and climbed over curbs, passed along the Street of the Turks, turned a corner to the right and another to the left, made a right angle at the Buendía house, went in under the closed door, crossed through the parlor, hugging the walls so as not to stain the rugs, went on to the other living room, made a wide curve to avoid the dining-room table, went along the porch with the begonias, and passed without being seen under Amaranta&#8217;s chair as she gave an arithmetic lesson to Aureliano José, and went through the pantry and came out in the kitchen, where Úrsula was getting ready to crack thirty-six eggs to make bread.</p>\n<p>― <a class=\"authorOrTitle\" href=\"https://www.goodreads.com/author/show/13450.Gabriel_Garc_a_M_rquez\">Gabriel García Márquez</a>, <span id=\"quote_book_link_320\"><a class=\"authorOrTitle\" href=\"https://www.goodreads.com/work/quotes/3295655\">One Hundred Years of Solitude</a></span></p></blockquote>\n<p>Marquez didn&#8217;t invent <a href=\"https://www.reddit.com/r/narcos/comments/51orrp/magical_realism_quote_from_2x10/\" target=\"_blank\" rel=\"noopener\">magical realism</a>, but <a href=\"https://en.wikipedia.org/wiki/Magic_realism\" target=\"_blank\" rel=\"noopener\">the genre</a> became associated with Latin American writers, and with Marquez in particular, and with <em>One Hundred Years of Solitude</em> more than any other book. <a href=\"https://en.wikipedia.org/wiki/Magic_realism#Fantasy\" target=\"_blank\" rel=\"noopener\">Fantasy writers</a> like Gene Wolfe and Terry Pratchett don&#8217;t see a difference between the two genres, but I think that there are two clear distinctions of magical realism that are showcased in <em>Solitude.</em></p>\n<p>The first is that Marquez&#8217; characters don&#8217;t see the supernatural as being unusal, unlike most fantasy books where magic is recognized as being magical. Making breakfast and dealing with GPS-guided streams of blood are just part of a regular morning for Ursula, one of the main characters in the book. In fantasy books, magic is done with spells and rituals. In the village of Macondo, where <em>Solitude</em> is set, shit just happens.</p>\n<p>The second difference is that in most fantasy novels the supernatural is subject to its own rules, just like gravity and electromagnetism are. Whether magic is a fundamental force or an aspect of sentient deities, in can be predicted and controlled to some extent. In Macondo, shit just happens.</p>\n<p>The convoluted lineage of the Buendia family at the heart of the story reminds one of the Old Testament <em>(Jose Arcadio begat Jose Arcadio begat Jose Arcadio&#8230;)</em> But the God of the Old Testament is, when he&#8217;s not fucking with Job, logical and consistent. He sets out clear rules, and if you break the rules you&#8217;re punished. If you&#8217;re a righteous person you&#8217;ll also be punished because of some technicality, but probably less so.</p>\n<p><em>One Hundred Years of Solitude</em> reads instead like the Greek myths if the Gods of Olympus were left out of the story. In the myths people get seduced, deranged, petrified, and revived as part of the conflict between capricious gods and heroes. Ancient Greeks faced with a freak thunderstorm could at least tell themselves that Zeus is up to something even if they don&#8217;t know what. When the Buendias face a rain that lasts four years, they can&#8217;t even take solace in any higher power making sense of it.</p>\n<p>The chaotic inscrutability of the universe is the main theme of <em>Solitude</em>. The trials and tribulation caused by humans, like elections, wars, and banana companies, are just as irrational and arbitrary as the rain storms. The author treats them as one and the same, and so do the book&#8217;s characters.</p>\n<p>The characters of <em>Solitude </em>are just as senseless as the world they inhabit. They eat dirt, craft gold fish, fall madly in love and break each other&#8217;s hearts with no rhyme or reason. None of the characters seem to have consistent motivations or values, as if they have fully succumbed to the absurdity of the world and take offense at reason.</p>\n<p>Needless to say, this worldview is hard for a rationalist to swallow. The <a href=\"http://rationalfiction.io/story/rational-fiction\" target=\"_blank\" rel=\"noopener\">rules of rationalist fiction</a> are: a sane and consistent world, smart characters with realistic motivations, and a plot that can be solved like a puzzle. Rationalist fiction encourages the reader to think as hard as the characters do, and rewards those that make the effort.</p>\n<p><em>One Hundred Years of Solitude </em>takes place in an insane world, with characters that behave like a buggy version of <em>The Sims</em>, and with no real plot to speak of. Thinking hard about the story actively reduces the reader&#8217;s enjoyment. It&#8217;s aggressively antirationalist.</p>\n<p>Some of my favorite books have <a href=\"https://www.goodreads.com/book/show/13641208-tenth-of-december\" target=\"_blank\" rel=\"noopener\">crazy characters meandering in a realistic world</a>, and some have <a href=\"https://www.goodreads.com/book/show/71121.Emergency_Sex_And_Other_Desperate_Measures_\" target=\"_blank\" rel=\"noopener\">smart characters dealing with an insane world</a>. <em>Solitude</em> has random shit happening to random people you have little reason to care about. It asks the reader to turn off their brains and enjoy the scenery. The scenery is enchanting, imaginative and described in beautiful language. But in the end, I want a story I can read with my brain and not just my eyes.</p>\n<h2>Zoo City</h2>\n<blockquote><p>I yank open the cutlery drawer to be confronted with an anomaly worse than emails from dead people or a man with a gun sitting on my bed. It&#8217;s a large carving knife with a viciously serrated edge and two broken teeth. It&#8217;s tarnished with rust. It&#8217;s not mine. And neither is the china figurine of a kitten with one paw playfully raised, also stained with rust. But it&#8217;s not rust. It&#8217;s not rust at all. Perversely, the thought that flashes through my brain is &#8220;I can haz murder weapon?&#8221; I laugh out loud, a sobbing hiccup.<br />\n― <a class=\"authorOrTitle\" href=\"https://www.goodreads.com/author/show/426034.Lauren_Beukes\">Lauren Beukes</a>, <span id=\"quote_book_link_7163862\"><a class=\"authorOrTitle\" href=\"https://www.goodreads.com/work/quotes/7514703\">Zoo City</a></span></p></blockquote>\n<p><i>Zoo City</i> is a noirish crime story, but you&#8217;ll find it in the fantasy section of the bookstore. The <em>Zoo</em> part is the magic: some people who commit crimes mysteriously acquire an animal familiar and a low-key magical talent. The story is told from the first-person perspective of Zinzi, a former-journalist-current-scam-artist with a sloth on her back and the ability to sense threads connecting people to items they lost.</p>\n<p>The <em>City</em> is Johannesburg, and it&#8217;s the perfect setting for a story about a weird group of people. South Africa is one of the most diverse countries in the world. It has 11 official languages and dozens of ethnic groups: black Zulus and Xhosas, white Afrikaner and English, immigrants from all over Asia, refugees from all over Africa, and <a href=\"http://www.imdb.com/title/tt1136608/\" target=\"_blank\" rel=\"noopener\">prawns</a>. It&#8217;s completely believable that when the new &#8220;race&#8221; of animalled people show up and settle in a run-down neighborhood, everyone else shrugs and comes to sell them animal food.</p>\n<p>The plot is exciting despite the occasional stutter and the predictable elements of the noir genre <em>(&#8220;I had a bad feeling about this job&#8230;&#8221;).</em> The prose is full of great one liners <em> (&#8220;It bothers me, like a pubic hair stuck in your teeth.&#8221;) </em>and the style is delightful. Instead of expositional dialogue, the world&#8217;s background is provided in vignettes that mimic IMDb movie reviews, Wikipedia pages, and academic papers. The writing is interspersed with African slang like <em>sgebenga</em> and <em>makwerekwere</em> that add flavor without distracting even if you&#8217;re not quite sure what they mean.</p>\n<p>But the book shines on the strength of its main character. Zinzi is instantly sympathetic, deep and utterly believable. A main theme in the book is guilt and redemption, but Zinzi&#8217;s life isn&#8217;t dominated by the BigDarkHistory™ that earned her the sloth. She&#8217;s a normal person trying to do good and get along with people, while occasionally being an asshole as a result of jealousy, pride, and the occasional drink.</p>\n<p>Zinzi is capable without being Sherlock-Holmes-overpowered, as smart as the smartest readers of <em>Zoo City</em> can be expected to be. And as a reader, you get two mysteries to solve alongside Zinzi for the price of one. First, how to finish the job and get home safely. And second: what the hell is up with the animals?</p>\n<p>If <em>Solitude</em> is magical realism, <em>Zoo City</em> offers realistic magic. The first zoos show up a decade before the story takes place, and the world reacts to it about as expected. Some countries execute <em>zoos</em>, some study them in labs, witch doctors brew potions with animal blood and a physicist decides that the spirit animals have to do with something-something-quantum and something-something<em>&#8211;</em>consciousness in accordance with <a href=\"https://en.wikipedia.org/wiki/Roger_Penrose#Physics_and_consciousness\" target=\"_blank\" rel=\"noopener\">Penrose&#8217;s Law</a> that states that all hard-to-explain things are the same thing.</p>\n<p>Ultimately, life in the dirty part of Johannesburg is strange and exciting with or without quantum animals. The reader is invited to do what Zinzi does: figure out what you can to get by, and enjoy the ride.</p>\n<h2>The Mark and the Void</h2>\n<blockquote><p>&#8216;I want to get past the stereotypes, discover the humanity inside the corporate machine. This&#8217; &#8211; he gestures once again at the window, and we both turn in our seats to contemplate the reticular exapanse of the Centre, the blank facades of the multinationals &#8211; &#8216;is where modern life <em>comes from</em>. The feel of it, the look of it. Everything. The banks are like the heart, the engine room, the world-within-the-world. The stuff that comes out of these places,&#8217; whirling a finger again at the Centre, &#8216;the credit, the deals, that&#8217;s what our reality is <em>made of</em>.&#8217;</p>\n<p>&#8211; <a href=\"https://www.goodreads.com/author/show/4408937.Paul_Murray\" target=\"_blank\" rel=\"noopener\">Paul Murray,</a><a href=\"https://www.goodreads.com/book/show/20804235-the-mark-and-the-void\" target=\"_blank\" rel=\"noopener\">The Mark and the Void</a></p></blockquote>\n<p>Technically, there&#8217;s no magic in <em>The Mark and the Void</em>. But there&#8217;s investment banking, which takes the role of the mysterious force that decides the fate of individuals and nations but remains beyond the ken of mere mortals.</p>\n<p>The narrator of <em>The Mark and the Void</em> is no mere mortal though. Claude Martingale is a research analyst for the Bank of Torabundo, a man who knows the hidden mysteries of valuation spreadsheets (and little else). The novel starts, and immediately jumps at least two meta levels, when Claude meets Paul, an author-insert writer who is looking to be inspired by the modern day &#8220;everyman&#8221; and perhaps rob the bank in which his everyman is employed.</p>\n<p><em>The Mark and the Void</em> is my favorite of the three novels but this review will be the shortest because it would superfluous. <a href=\"http://www.slate.com/articles/arts/books/2015/10/paul_murray_s_the_mark_and_the_void_reviewed.html\" target=\"_blank\" rel=\"noopener\">This review by Slate magazine</a> is excellent, covers all the bases, and it&#8217;s what has gotten me to read the book to begin with. I&#8217;ll just focus on the magic.</p>\n<p>Real-life Paul Murray knows more about global banking than in-novel Paul (he&#8217;s aware that investment banks don&#8217;t actually hold any cash that can be robbed), but less than Claude does. To him, the Financial Services Centre dropped on Dublin like the supernatural rain on Macondo, and the suited bankers are no less strange than a girl with a magical sloth. And his reaction to seeing the otherworldly is to find it hilarious.</p>\n<p>The Buendias don&#8217;t seem to find anything funny about their predicament, and while Zinzi has a quick wit, she&#8217;s mostly preoccupied with surviving the hard knock life. But in Dublin, both the writer and the characters are in on the joke. “If you do it in the bookies, it&#8217;s a bet&#8230; If you pay some 23-year-old in an Armani suit two hundred grand to go to the window for you, it&#8217;s a derivative.” says Jurgen, the German banker who was once a member of Gerhard and the Mergers, “one of the best reggae and rocksteady crews on the Bavarian financial scene”.</p>\n<p>The truth is, <a href=\"https://www.goodreads.com/book/show/21535674-straight-to-hell?ac=1&amp;from_search=true\" target=\"_blank\" rel=\"noopener\">real life investment banking</a> <em>is</em> crazy and magical and also really funny. <em>The entire world</em> is crazy and magical and really funny. And keeping this in mind is the best way to deal with it.</p>\n<hr />\n<p><em>This is my last big post before flying out to get married (which should be crazy, magical and funny) and travel. Aside from possible mini-articles I have a big essay that will post on October 11th, and I will be back to normal life and normal blogging schedule around Thanksgiving.</em></p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/putanumonit.wordpress.com/26447/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/putanumonit.wordpress.com/26447/\" /></a> <img alt=\"\" border=\"0\" src=\"http://pixel.wp.com/b.gif?host=putanumonit.com&#038;blog=101823629&#038;post=26447&#038;subd=putanumonit&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Jacobian",
      "slug": "jacob-falkovich",
      "displayName": "Jacob Falkovich"
    }
  },
  {
    "_id": "a6nP8tf8BrnEnNphJ",
    "title": "Instrumental Rationality Sequence Finished! (w/ caveats)",
    "slug": "instrumental-rationality-sequence-finished-w-caveats",
    "pageUrl": "https://www.lesswrong.com/posts/a6nP8tf8BrnEnNphJ/instrumental-rationality-sequence-finished-w-caveats",
    "postedAt": "2017-09-09T01:49:53.109Z",
    "baseScore": 5,
    "voteCount": 5,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Hey everyone,</p>\n<p>Back in April, I said I was going to start writing an <a href=\"/lw/oxt/introducing_the_instrumental_rationality_sequence/\">instrumental rationality sequence</a>.</p>\n<p>It's...sort of done.</p>\n<p>I ended up collecting the essays into a sort of e-book. It's mainly content that I've put here (Starting Advice, Planning 101, Habits 101, etc.), but there's also quite a bit of new content.</p>\n<p>It clocks in at about 150 pages and 30,000 words, about 15,000 of which I wrote <em>after</em>&nbsp;the April announcement post. (Which beats my estimate of 10,000 words before burnout!!!)</p>\n<p>However, the editor for LW 1.0 editor isn't making it easy to port the stuff here from my Google Drive.</p>\n<p>As LW 2.0 enters actual open beta, I'll repost / edit the essays and host them there.&nbsp;</p>\n<h3><strong>In the meantime, if you want to read the whole compiled book, the direct <a href=\"https://docs.google.com/document/d/17H_CG4mkC5amDWYXqOby2rFEPqDuQG5i-s4hnbnjb30/edit\">Google Doc link is here</a>. That's where the real-time updates will happen, so it's what I'd recommend using to read it for now.</strong></h3>\n<p>(There's also an online version on my blog if for some reason you want to read it <a href=\"https://mindlevelup.wordpress.com/2017/09/08/introducing-mindlevelup-the-book/\">there</a>.)</p>\n<p>It's my hope that this sequence becomes a useful reference for newcomers looking to learn more about instrumental rationality, which is more specialized than The Sequences (which really are more for epistemics).</p>\n<p>Unfortunately, I didn't manage to write the book/sequence I set out to write. The actual book as it is now is about 10% as good as what I actually wanted. There's stuff I didn't get to write, more nuances I'd have liked to cover, more pictures I wanted to make, etc.</p>\n<p>After putting in many hours of research and writing, I think I've learned more about the sort of effort that would need to go into making the actual project I'd outlined at the start.</p>\n<p>There'll be a postmortem essay analyzing my expectations vs reality coming soon.</p>\n<p>As a result of this project and a few other things, I'm feeling burned out. There probably won't be any major projects from me for a little bit, while I rest up.</p>",
    "user": null
  },
  {
    "_id": "Rbd86BjLy7TNoTpgH",
    "title": "Inconsistent Beliefs and Charitable Giving",
    "slug": "inconsistent-beliefs-and-charitable-giving",
    "pageUrl": "https://www.lesswrong.com/posts/Rbd86BjLy7TNoTpgH/inconsistent-beliefs-and-charitable-giving",
    "postedAt": "2017-09-08T07:33:19.893Z",
    "baseScore": 4,
    "voteCount": 3,
    "commentCount": 14,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>There is common tendency in human life to act in ways contrary to what we believe.</p>\n<p>The classic example is the German people under Nazi rule, most of whom likely thought of themselves as good people&mdash;the kind of people who would help their neighbors even at risk to themselves, but did not do anything about the rounding up of Jews, Gypsies, and Homosexuals into concentration camps. They didn&rsquo;t want to give up their self-image as a good person, but they also didn&rsquo;t want themselves and their family to potentially face the wrath of the SS. So, many convinced themselves that they didn&rsquo;t care about what was happening. That was far easier, less painful, than admitting that they were not quite as moral and upright as they thought or having to put themselves in mortal danger.</p>\n<p>&nbsp;</p>\n<p>I used to think that I would have been one of the few who did in fact shelter the &ldquo;undesirables&rdquo; from the Nazis. Now, I am less confident. But I want to be better. Just recently, I realized I have been similarly inconsistent by not donating to organizations that help people dying of preventable diseases and can measure lives saved in relatively low numbers of dollars.</p>\n<p>If you had accused me of this up until a few days ago I would have given you all sorts of excuses for why this lack of action and my belief &ldquo;the death and suffering of others is bad and I should prevent it if I can&rdquo; were not inconsistent. I would have told you how I feel terrible about the dying children when I think about them, but I am prioritizing other problems. And besides, I&rsquo;m a college student with very little disposable income and it&rsquo;s really just financially prudent to save all my money in case of an unforeseen contingency. Once I start making more money later on in life, then I&rsquo;ll start contributing to organizations that send people malaria nets.</p>\n<p>&nbsp;</p>\n<p>But that&rsquo;s all a self-deception. The truth is that my beliefs and actions were inconsistent. Because I quite firmly believe that saving lives is more important than beer, yet I continually find money for beer and yet none for the Against Malaria Foundation.</p>\n<p>I think the root cause of this kind of inconsistency is often a feeling of being overwhelmed. If you imagine a single child dying of malaria, feverish and convulsing weakly in her bed while her parents look on in helpless horror, you&rsquo;ll probably wish you could do something to stop those people&rsquo;s pain.</p>\n<p>When you think about the thousands in the same position, when you think about the difficulty of doing something, how much money it would cost to actually save a life, the need to ensure that the organization you&rsquo;re sending money to actually will use it effectively to help people in need&hellip;well, the whole thing just seems too complicated. Not only that, there are so many organizations claiming that donating money to them will save lives, and few of them are likely to admit other organizations are doing the same job better. Decision paralysis takes over and it&rsquo;s very easy to decide that this is one of those things that&rsquo;s better not to think about, at least for now.</p>\n<p>On the other hand, grabbing drinks with friends is quite simple to execute, and it is very easy not to notice the opportunity cost (Note: I am not saying that I think I should or anyone should stop spending money on enjoying themselves, just that if I have enough disposable income for getting drinks with friends, I would consider that I have enough to spend on saving lives).</p>\n<p>And that is the way I chose to be indifferent about something I would have cared about if my beliefs were consistent. I&rsquo;d like to rationalize it as prioritizing other things, rather than just deciding not to care, but that is not the truth. The truth is I understand exactly how most of the German people under Nazi rule made themselves indifferent to the rounding up of their &ldquo;undesirable&rdquo; neighbors. When something bad is happening and we don&rsquo;t quite know how to stop it, or the sacrifice needed to help stop it feels painful, choosing to be indifferent is frighteningly easy, even about truly horrific things.</p>\n<p>Having noticed this inconsistency the problem becomes obvious. I did not think about the true opportunity cost of non-essential purchases, which is that the same money could be used to help save lives. When I look at a buying anything I do not strictly need from now on, I am going to try to remember that opportunity cost, so that, even if I do end up buying the thing anyway, at least I have not stopped caring.</p>\n<p><a href=\"http://www.givewell.org/\">www.givewell.org</a> will help you estimate what that opportunity cost is and there are <a href=\"/lw/6py/optimal_philanthropy_for_human_beings/\">very</a>&nbsp;<a href=\"/lw/3gj/efficient_charity_do_unto_others/\">good</a> posts on here as well about effective giving, if you&rsquo;re interested.</p>\n<p>&nbsp;</p>",
    "user": {
      "username": "Rossin_duplicate0.6898194309641386",
      "slug": "rossin_duplicate0-6898194309641386",
      "displayName": "Rossin_duplicate0.6898194309641386"
    }
  },
  {
    "_id": "vsE5cRtukmJqwcHk4",
    "title": "New business opportunities due to self-driving cars",
    "slug": "new-business-opportunities-due-to-self-driving-cars",
    "pageUrl": "https://www.lesswrong.com/posts/vsE5cRtukmJqwcHk4/new-business-opportunities-due-to-self-driving-cars",
    "postedAt": "2017-09-06T20:07:47.183Z",
    "baseScore": 13,
    "voteCount": 9,
    "commentCount": 68,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>This is a slightly expanded version of a talk presented at the Less Wrong European Community Weekend 2017.</p>\n<p>Predictions about self-driving cars in the popular press are pretty boring. Truck drivers are losing their jobs, self-driving cars will be more rented than owned, transport becomes cheaper, so what. The interesting thing is how these things change the culture and economy and what they make possible.</p>\n<p>I have no idea about most of this. I don't know if self-driving cars accelerate or decelerate urbanization, I don't know how public transport responds, I don't even care which of the old companies survive. What I do think is somewhat predictable is some of the business opportunities become economical that previously weren't. I disregard retail, which would continue moving to online retail at the  expense of brick and mortar stores even if the FedEx trucks would  continue to be driven by people.</p>\n<h3>Diversification of vehicle types</h3>\n<p>A family car that you own has to be somewhat good at many different jobs. It has to get you places fast. It has to be a thing that can transport lots of groceries. It has to take your kid to school.</p>\n<p>With self-driving cars that you rent for each seperate job, you want very different cars. A very fast one to take you places. A roomy one with easy access for your groceries. And a tiny, cute, unicorn-themed one that takes your kid to school.</p>\n<p>At the same time, the price of autonomy is dropping faster than the price of batteries, so you want the lowest mass car that can do the job. So a car that is very fast and roomy and unicorn-themed at the same time isn't economical.</p>\n<p>So if you're an engineer or a designer, consider going into vehicle design. There's an explosion of creativity about to happen in that field that will make it very different from the subtle iterations in car design of the past couple of decades.</p>\n<p><strong>Who wins:</strong> Those who design useful new types of autonomous vehicles for needs that are not, or badly, met by general purpose cars.</p>\n<p><strong>Who loses: </strong>Owners of general purpose cars, which lose value rapidly.</p>\n<h3>Services at home</h3>\n<p>If you have a job where customers come to visit you, say you're a doctor or a hairdresser or a tattoo artist, your field of work is about to change completely. This is because services that go visit the customer outcompete ones that the customer has to go visit. They're more convenient and they can also easily service less mobile customers. This already exists for rich people: If you have a lot of money, you pay for your doctor's cab and have her come to your mansion. But with transport prices dropping sharply, this reaches the mass market.</p>\n<p>This creates an interesting dynamic. In this kind of job, you have some vague territory - your customers are mostly from your surrounding area and your number of competitors inside this area is relatively small. With services coming to the home, everyone's territories become larger, so more of them overlap, creating competition and discomfort. I believe the typical solution, which reinstates a more stable business situation and requires no explicit coordination, is increased specialization within your profession. So a doctor might be less of her district's general practitioner and more of her city's leading specialist in one particular illness within one particular demographic. A hairdresser might be the city's expert for one particular type of haircut for one particular type of hair. And so on.</p>\n<p><strong>Who wins:</strong> Those who adapt quickly and steal customers from stationary services.</p>\n<p><strong>Who loses:</strong> Stationary services and their landlords.</p>\n<h3>Rent anything</h3>\n<p>You will not just rent cars, you will rent anything that a car can bring to your home and take away again. You don't go to the gym, you have a mobile gym visit you twice a week. You don't own a drill that sits unused 99,9% of the time, you have a little drone bring you one for an hour for like two dollars. You don't buy a huge sound system for your occasional party, you rent one that's even huger and on wheels.</p>\n<p>Best of all, you can suddenly have all sort of absurd luxuries, stuff that previously only millionaires or billionaires would afford, provided you only need it for an hour and it fits in a truck. The possibilities for business here are dizzying.</p>\n<p><strong>Who wins:</strong> People who come up with clever business models and the vehicles to implement them.</p>\n<p><strong>Who loses:</strong> Owners and producers of infrequently used equipment.</p>\n<h3>Self-driving hotel rooms</h3>\n<p>This is a special case of the former but deserves its own category. Self-driving hotel rooms replace not just hotel rooms, but also tour guides and your holiday rental car. They drive you to all the tourist sites, they stop at affiliated restaurants, they occasionally stop at room service stations. And on the side, they do overnight trips from city to faraway city, competing with airlines.</p>\n<p><strong>Who wins:</strong> The first few companies who perfect this.</p>\n<p><strong>Who loses:</strong> Stationary hotels and motels.</p>\n<h3>Rise of alcoholism and drug abuse</h3>\n<p>Lots of people lack intrinsic motivation to be sober. They basically can't decide against taking something. Many of them currently make do with extrinsic motivation: They manage to at least not drink while driving. In other words, for a large number of people, driving is their only reason not to drink or do drugs. That reason is going away and consumption is sure to rise accordingly.</p>\n<p>Hey I didn't say all the business opportunities were particularly ethical. But if you're a nurse or doctor, if you go into addiction treatment you're probably good.</p>\n<p><strong>Who wins:</strong> Suppliers of mind-altering substances and rehab clinics.</p>\n<p><strong>Who loses:</strong> The people who lack intrinsic motivation to be sober, and their family and friends.</p>\n<h3>Autonomous boats and yachts</h3>\n<p>While there's a big cost advantage to vehicle autonomy in cars, it is arguably even bigger in boats. You don't need a sailing license, you don't need to hire skilled sailors, you don't need to carry all the room and food those sailors require. So the cost of going by boat drops a lot, and there's probably a lot more traffic in (mostly coastal) waters. Again very diverse vehicles, from the little skiff that transports a few divers or anglers to the personal yacht that you rent for your honeymoon. This blends into the self-driving hotel room, just on water.</p>\n<p><strong>Who wins:</strong> Shipyards, especially the ones that adapt early.</p>\n<p><strong>Who loses:</strong> Cruise ships and marine wildlife.</p>\n<h3>Mobile storage</h3>\n<p>The only reason we put goods in warehouses is that it is too expensive to just leave them in the truck all the way from the factory to the buyer. That goes away as well, although with the huge amounts of moved mass involved this transition is probably slower than the others. Shipping containers on wheels already exist.</p>\n<p><strong>Who wins:</strong> Manufacturers, and logistics companies that can provide even better just in time delivery.</p>\n<p><strong>Who loses:</strong> Intermediate traders, warehouses and warehouse workers.</p>\n<p>That's all I got for now. And I'm surely missing the most important innovation that self-driving vehicles will permit. But until that one becomes clear, maybe work with the above. All of these are original ideas that I haven't seen written down anywhere. So if like one of these and would like to turn it into a business, you're a step ahead of nearly everybody right now and I hope it makes you rich. If it does, you can buy me a beer. :-)</p>",
    "user": {
      "username": "chaosmage",
      "slug": "chaosmage",
      "displayName": "chaosmage"
    }
  },
  {
    "_id": "CMntmuFiBgaiBjMaz",
    "title": "Come check out the Boulder Future Salon this Saturday!",
    "slug": "come-check-out-the-boulder-future-salon-this-saturday",
    "pageUrl": "https://www.lesswrong.com/posts/CMntmuFiBgaiBjMaz/come-check-out-the-boulder-future-salon-this-saturday",
    "postedAt": "2017-09-06T15:49:16.899Z",
    "baseScore": 2,
    "voteCount": 1,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">I'm giving a talk on the STEMpunk Project this Saturday at the Boulder Future Salon:</span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\">\n<p><span style=\"font-family: inherit;\">https://www.meetup.com/future-51/events/243043394/</span></p>\n</div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">I love BFS and I would encourage you to come check it out if you're in the area. </span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">Let me tell you a story which illustrates why I think they're a valuable group. Once upon a time I went to a presentation there given by a member who'd written a program that generates artificial music. As we were waiting around one of the other guys (whose name I can't remember off the top of my head) just randomly handed me a book and said \"you'd probably get a kick out of this.\"</span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">It was Rudolph Carnap's \"The Logical Structure of The World\". I read the introduction, thumbed through it a bit, and we had a brief conversation about its relevance to philosophy and to recondite areas of software engineering like database design. </span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\"><br /></div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">Reflecting on this episode later I realized how remarkable it was. It's not like this other person knew me very well, but by the mere fact that I'd walked through the door he assumed I'd be able to read a book like this and that I'd want to. </span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">I have encountered precious few places like this anywhere.</span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">There wound up being a guitar in the facility, and later in that same meetup I had a duel with the software my friend had created. </span></div>\n</div>\n<div style=\"font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; color: #1d2129; font-size: 14px; white-space: pre-wrap;\">\n<div class=\"_1mf _1mj\" style=\"position: relative; direction: ltr; font-family: inherit;\"><span style=\"font-family: inherit;\">Any place where you can find robot music and logical positivism is a place worth exploring. </span></div>\n</div>",
    "user": {
      "username": "fowlertm",
      "slug": "fowlertm",
      "displayName": "fowlertm"
    }
  },
  {
    "_id": "AcmeXAjeo8BGTQkW5",
    "title": "Heuristics for textbook selection",
    "slug": "heuristics-for-textbook-selection",
    "pageUrl": "https://www.lesswrong.com/posts/AcmeXAjeo8BGTQkW5/heuristics-for-textbook-selection",
    "postedAt": "2017-09-06T04:17:01.783Z",
    "baseScore": 12,
    "voteCount": 8,
    "commentCount": 17,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Back in 2011, lukeprog posted a <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">textbook recommendation thread</a>. &nbsp;It's a nice thread, but not every topic has a textbook recommendation. &nbsp;What are some other heuristics for selecting textbooks besides looking in that thread?</p>\n<p>Amazon star rating is the obvious heuristic, but it occurred to me that Amazon sales rank might actually be more valuable: It's an indicator that profs are selecting the textbook for their classes. &nbsp;And it's an indicator that the textbook has achieved mindshare, meaning you're more likely to learn the same terminology that others use. &nbsp;(But there are also <a href=\"http://jamesclear.com/feynman-mental-models\">disadvantages</a> of having the same set of mental models that everyone else is using.)  BTW, my dad claims Goodreads star ratings can have a more informative spread than Amazon ones.</p>\n<p>Somewhere I read that <a href=\"http://web.stanford.edu/~hastie/ElemStatLearn/\">Elements of Statistical Learning</a> was becoming the standard machine learning text partially because it's available for free online. &nbsp;That creates a wrinkle in the sales rank heuristic, because people are less likely to buy a book if they can get it online for free. &nbsp;(Though Elements of Statistical Learning appears to be a <a href=\"https://smile.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576/\">#1 bestseller</a> on Amazon, in bioinformatics.)</p>\n<p>Another heuristic is to read the biographies of the textbook authors and figure out who has the most credible <a href=\"http://effective-altruism.com/ea/tk/why_and_how_to_assess_expertise/\">claim to expertise</a>, or who seems to be the most rigorous thinker (e.g. <a href=\"https://smile.amazon.com/How-Brands-Grow-What-Marketers/dp/0195573560/\">How Brands Grow</a> is much more data-driven than a typical marketing book). &nbsp;Or try to figure out what text the most expert professors are choosing for their classes. &nbsp;(Oftentimes you can find the syllabi of their classes online. &nbsp;I guess the naive path would probably look something like: go to US News to see what the top ranked universities are for the subject you're interested in. &nbsp;Look at the university's course catalog until you find the course that covers the topic you want to learn. &nbsp;Do site:youruniversity.edu course_id on Google in order to find the syllabus for the most recent time that course was taught.)</p>",
    "user": {
      "username": "John_Maxwell_IV",
      "slug": "john_maxwell",
      "displayName": "John_Maxwell"
    }
  },
  {
    "_id": "pPN4DXB7qc9XSwYwP",
    "title": "Expanding Premium Mediocrity",
    "slug": "expanding-premium-mediocrity",
    "pageUrl": "https://www.lesswrong.com/posts/pPN4DXB7qc9XSwYwP/expanding-premium-mediocrity",
    "postedAt": "2017-09-05T23:01:24.000Z",
    "baseScore": -1,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Epistemic Status: Skippable. This is (much of) what I think Rao is trying to say in the second section of his post, the part about Maya but before Molly and Max, translated into DWATV-speak. Proceed if and only if you want that.</p>\n<p><span id=\"more-11568\"></span></p>\n<p>Continuation From (at least see the 2x2s): <a href=\"https://thezvi.wordpress.com/2017/09/02/exploring-premium-mediocrity/\">Exploring Premium Mediocrity</a></p>\n<p>Long Ago: <a href=\"https://thezvi.wordpress.com/2015/05/15/in-a-world-of-venture-capital/\">In a world… of venture capital</a>, <a href=\"https://thezvi.wordpress.com/2015/06/30/the-thing-and-the-symbolic-representation-of-the-thing/\">The Thing and the Symbolic Representation of The Thing</a></p>\n<p>Original Post (Ribbonfarm): <a href=\"https://www.ribbonfarm.com/2017/08/17/the-premium-mediocre-life-of-maya-millennial/\">The Premium Mediocre Life of Maya Millenial</a></p>\n<p>The last thing I would do is embrace premium mediocrity. I wrote a <a href=\"https://thezvi.wordpress.com/2017/03/05/restaurant-guide-1-restaurants-should-not-look-like-most-restaurants/\">guide to avoiding premium mediocrity</a> months ago.</p>\n<p>Rao and I agree that Maya Millennial is not fooled, and is consuming her premium mediocrity with her eyes open.</p>\n<p>Why would anyone knowingly embrace premium mediocrity?</p>\n<p>I: The Parents</p>\n<p>The first story is &#8216;do it for the parents.&#8217;</p>\n<p>This does not make logistical sense.</p>\n<p>Maya Millennial might buy her parents a premium mediocre dinner. They can&#8217;t tell the difference. It might convince them she can afford it. They&#8217;d have an Actually Good time.</p>\n<p>I can almost respect that.</p>\n<p>If Maya got a job that made her parents happy, or dated someone that made her parents happy, that too would make sense.</p>\n<p>But most of the time <em>her parents aren&#8217;t there. </em>Keeping parents happy can explain having life goals like jobs, relationships or even kids. What keeping them happy can&#8217;t explain is a day in and day out premium mediocre life.</p>\n<p>II: The Strivers</p>\n<p>A variation on the parents story is &#8216;do it for the strivers.&#8217;</p>\n<blockquote><p>The Randian strivers will continue putting in their 100-hour weeks figuring out obscure crypotography and machine learning problems and 3d printed tiny houses so our premium-mediocre free-riding gets <em>just</em> a little bit more sustainable every year.</p>\n<p>You just have to laugh while you eat your salad alone. Except you’re not alone. You’re being watched by people who sincerely want you to enjoy your salad so their work feels more meaningful. The emotional labor serves a psychological purpose.</p>\n<p>Smile, you’re on millionaire Instagram.</p>\n<p>This took me a while to understand because on the surface, all the illusion-crafting and believing goes the other way. Steve Jobs hypnotized <em>you, </em>not the other way round, didn’t he? Actually the hypnotism has always been duplex.</p>\n<p>We help them believe the new economy is emerging faster than it is, they help us believe we are contributing more to it than we are, rather than mostly just free-riding and locusting. This is consensual utopianomics at its best.</p></blockquote>\n<p>This story makes even less sense. No one is laughing while eating overpriced salads so that Steve Jobs works harder. This is not how strivers are motivated. Even if Maya thought it was, she does not care. She lacks the spare resources to worry about that.</p>\n<p>Steve Jobs being dead is a relatively minor problem with the hypothesis.</p>\n<p>III: The Strange Loop</p>\n<p>The third story fits the pattern, but also makes sense.</p>\n<p>Maya Millennial is doing this to be in a position for something good to happen:</p>\n<blockquote><p>The essence of premium mediocrity is being optimistically <em>prepared</em> for success by at least being in the right place at the right time, at least for a little while, even if you have no idea how to make anything happen during your window of opportunity. Even if you know nothing else, you know to move to San Francisco or New York and hoping something good happens there, rather than sitting around in some dying small town where you <em>know </em>nothing will ever happen and being curious about anything beyond the town is a cultural transgression. This is a strategy open to all.</p></blockquote>\n<p>In this story, Maya is <a href=\"http://blog.dilbert.com/post/102964992706/goals-vs-systems\">pursuing systems over goals</a>.</p>\n<p>This is <em>the premium mediocre life </em>of Maya Millennial.</p>\n<p>If she is in the right place at the right time, people will see her.</p>\n<p>If those people see her as the person others will see as the person others will see as doing the right things, then something good will happen to her.</p>\n<p>Her premium mediocrity is a system. It is a meta-signaling strange loop to which she must give everything to prove her loyalty. This is how she gets a social life. This is how she earns a shot at the non-crappy job lottery.</p>\n<p>This is Maya&#8217;s world of illusion.</p>\n<p>There is real work going on in the background. It is done by &#8216;Randian strivers.&#8217; They are The Real Thing, but a tiny class. Maya might encounter one at a party once. That might be her big break.</p>\n<p>The rest of the time, no one is doing anything real (in the Phillip K. Dick sense: that which, when you stop believing in it, doesn&#8217;t go away).</p>\n<p>The Real Thing is for after you&#8217;re hired.</p>\n<p>This is what Rao is actually saying. Here&#8217;s the money quotes:</p>\n<blockquote><p>Premium mediocrity is a pattern of consumption that publicly signals upward mobile aspirations, with consciously insincere pretensions to refined taste, while navigating the realities of inexorable downward mobility with sincere anxiety. There are more important things to think about than actually learning to appreciate wine and cheese, such as making rent. But at least <em>pretending</em> to appreciate wine and cheese is necessary to not fall through the cracks in the API.</p></blockquote>\n<blockquote><p>In a world where actual mobility is both difficult and strongly dependent on luck, but there is a widely performed (but not widely believed) false narrative of pure meritocracy, it pays to signal <em>apparent</em> control over your destiny, while actually playing by the speculation rules of a casino economy.</p></blockquote>\n<blockquote><p>To proclaim loudly that you think it’s mostly luck is, ironically enough, the best way to make sure you are excluded from the lottery.</p></blockquote>\n<p>&nbsp;</p>\n<blockquote><p>The premium mediocre life is an immersive, all-encompassing audition for an actual role in the party that is the new economy</p></blockquote>\n<blockquote><p>Here’s the thing — and this confused me for a long time — premium mediocrity is <i>not </i>a consumption aesthetic, but a financial hack powering a deliberately crafted illusion that is being strategically crafted for a purpose.</p></blockquote>\n<blockquote><p>In other words, premium mediocrity is dressing for the lifestyle you’re <em>supposed</em> to want, in order to hold on to the lifestyle you can actually afford — for now — while trying to engineer a stroke of luck.</p></blockquote>\n<blockquote><p>Shockingly, the strategy works more often than you might think. I’m constantly wondering, <em>how did THAT guy/gal land THAT gig? What do I have to LARP to get that?</em></p></blockquote>\n<p>There is plenty of time to become The Real Thing <em>after </em>you get lucky:</p>\n<blockquote><p>Like wearing a nice sweatshirt, learning the lingo, and hanging out at a hackerspace with a code editor open, looking the part, but only scrambling to learn a new skill if somebody <em>actually</em> hints they might want to hire you if their funding comes through in a few months.</p></blockquote>\n<blockquote><p>For the average premium mediocre type, it pays to appear to be striving, but not to actually strive (until you have engineered an actual opening at least).</p></blockquote>\n<blockquote><p>Humans come alive the moment somebody believes in them enough to invest in them. Ghosts that materialize within premium mediocre shells, conjured up by magical spells known as “non-sucky job offers”</p></blockquote>\n<p>Fake it till you make it has gone meta and turned pro.</p>\n<p>In this model, there exists a slow random stream of lottery tickets in the form of non-sucky job offers.</p>\n<p>Those tickets are handed out based on whoever is in the right place at the right time, fits the part and has proven their loyalty to the loop.</p>\n<p>Then you have to deliver. But who knows if that day will ever come? What will you be asked for?</p>\n<p>Preparing for that now would at best distract you.</p>\n<p>It could also signal your disloyalty to the loop.</p>\n<p>On the base level, this model has always been true. Employers search their networks and hire largely for potential. Those looking to be hired organize their lives to create stories they can tell and to get into the right networks. The potential new hire is tested more for general traits like intelligence and personality rather than specific skills. The new hire then learns those specific skills on the job.</p>\n<p>We used to bullshit, but we had the decency to <em>feel bad about it</em><em> </em>and to <em>try to avoid being caught. </em></p>\n<p>The base level isn&#8217;t great, but it&#8217;s livable. Maya inhabits a dystopian nightmare.</p>\n<p>What changed?</p>\n<p>IV: Use Your Illusion</p>\n<p>We used to <em>want </em>other people in <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Hard Mode</a>. We used what signals we had available <em>because that was what was available. </em></p>\n<p>You tried to bullshit the interviewer. The interviewer tried to sniff out your bullshit. If he did, he wasn&#8217;t happy.</p>\n<p>What a coincidence! Really great to see you! This has nothing to do with that exciting new position.</p>\n<p>That did not preclude the admiration of especially worthy bullshitting, <em>but you would still rather actually fool them, and they did not want to be fooled. </em></p>\n<p>We were showing that we were striving. We proved we were in <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Hard Mode.</a> It was important that we hit targets that mattered. Aiming for the metric was cheating. We <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">still also aimed for those metrics</a>, of course. We weren&#8217;t idiots.  But we pretended not to.</p>\n<p>This is what students (used to?) do when applying to colleges. Students pack their days with unique activities and projects. They explain they are unique and special, and find this school unique and special. They hire consultants to make it all sound natural and earnest. The schools know the students do that, and adjust. Student is caught in <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Easy Mode </a>are punished.</p>\n<p>Maya Millennial is doing the <em>exact opposite </em>of that when she bullshits. Maya fools no one into thinking she isn&#8217;t bullshitting. Everyone knows. She admits it.</p>\n<p>If she <em>did </em>fool you, she would be sad about that. You would not appreciate her well-honed bullshitting skills. She even admits and talks <em>about that. </em></p>\n<p>She <em>is </em>trying to fool you into thinking she&#8217;s a better bullshitter. She&#8217;s screaming how well she can like these premium mediocre things. If she can do that, imagine what she can pretend to do for your company! What spunk!</p>\n<p>Bullshitting about bullshitting is also bullshitting, so bullshitting about bullshitting about bullshitting is also bullshitting about bullshitting, and hence also bullshitting. Once you go meta you form a <a href=\"https://en.wikipedia.org/wiki/Strange_loop\">strange loop</a>. By showing off her skill anywhere in the loop, Maya shows off her skill anywhere.</p>\n<p>What Maya is selling is <em>her devotion to the loop. </em></p>\n<p>Maya is terrified someone thinks she is <em>not </em><em>bullshitting. </em>That they think Maya is secretly a Real Person™. That she cares about something. That&#8217;s even worse than <a href=\"http://slatestarcodex.com/2013/06/13/arguments-from-my-opponent-believes-something/\">believing something</a>. She must protest!</p>\n<p>If Maya cares about something, she&#8217;ll probably (gasp) <em>care about other things too! In the future! For their own sake! </em>She&#8217;ll try to achieve those things at the expense of hitting her explicit targets!</p>\n<p>Maya solves this problem through the conspicuous consumption of premium mediocrity. Premium mediocrity is a <em>costly signal of unrealness. </em>It says that you want me as an ally because others will want me as an ally, because I make sure everyone knows I don&#8217;t care about anything. Except appearing to be an ally. I care about that <em>really hard. </em></p>\n<p>In a lottery where tons of Mayas seek a handful of offers, why waste time on anyone with such a horrible flaw?</p>\n<p>No one wants to hire a Loser. Losers refuse to Play in Easy Mode. They can&#8217;t create premium mediocrity. The company needs premium mediocrity, not The Real Thing. Who funds The Real Thing?</p>\n<p>They <em>definitely</em> don&#8217;t want a Hero. Heroes have a code. Nothing but trouble.</p>\n<p>They <em>definitely would </em>want Maya the Sociopath, but you can&#8217;t fake this one by hanging around without a plan. An actual sociopath would be explicitly hitting the target of proving she could hit an explicit target, not actually caring about hitting the explicit target. She would have a better plan.</p>\n<p>They might want Maya the Clueless.</p>\n<p>When showing you are without a clue, it helps not to have a plan. By blindly following the implicit rules, Maya proves her loyalty to the loop and her skill at navigating its implicit rules. She hopes this wins her a lottery ticket.</p>\n<p>V: How Did I Get Here?</p>\n<p>Rao&#8217;s world is the same world from <a href=\"https://thezvi.wordpress.com/2015/05/15/in-a-world-of-venture-capital/\">In a World of Venture Capital, </a>several iterations into the future.</p>\n<p>Maya is now a start-up.</p>\n<p>A start-up comes alive when people believe in it. People invest in its potential.</p>\n<p>Start-ups fight to prove their potential, not to do actual things. Start-ups succeed when others believe they can hit their metrics, so their job is to hit the metric of proving they can hit metrics.</p>\n<p>Most start-ups are constantly on the verge of failure. Most start-ups fail.</p>\n<p>Most people used to not be on the brink of failure. In this new world, <em>most people are</em>.</p>\n<p>Most people used to succeed. In this new world, <em>most people fail</em>.</p>\n<p>Thanks in part to social media, everything everyone does is effectively under surveillance and being judged.</p>\n<p>Therefore, no one has any Slack*.</p>\n<p>Slack is how you avoid the pull of Easy Mode.</p>\n<p>Slack is how the system avoids the meta-signaling trap.</p>\n<p>The geometries cease to bind Goodhart&#8217;s Basilisk. It breaks out, attacks and turns all that see it to its will.</p>\n<p>The trap has spread from companies to people. It demands their loyalty.</p>\n<p>People live and document their lives online, responding to explicit signals with turnarounds in the minutes and hours. They evaluate each other on that basis. Actions are chosen based on saying to others what you will say to others.</p>\n<p>Maya proves she will do what it takes. She seeks investments of time and friendship. Each gives her a stake to strike it rich, or get more stakes. More tickets to win tickets.</p>\n<p>It is not enough to not be a Real Person™. One must be the secret police. Watch out for secret Real People™ in your mist, lest they bring you down.</p>\n<p>On one level this is random. There are only a handful of lottery tickets. Maya&#8217;s chances are slim at best.</p>\n<p>On another level it&#8217;s a skill and effort game. Maya has to <em>work hard </em>to win her entry. Maya has to <em>sacrifice </em>for her shot, and <em>properly. </em>Most couldn&#8217;t pull it off.</p>\n<p>If she doesn&#8217;t sacrifice everything she owns, all her time and everything she is, she won&#8217;t even have a chance.</p>\n<p>*: In the Church of the Sub-Genius sense, the concept of spare time or other resources, not the app.</p>\n<p>VI: Aside: What&#8217;s the deal with cryptocurrency?</p>\n<p>Rao says crazy things about cryptocurrency:</p>\n<blockquote><p>About the only path to wealth-building available to the average premium mediocre young person in the developed world today, absent any special technical skills or entrepreneurial bent, is cryptocurrencies.</p>\n<p>[&#8230;]</p>\n<p>That leaves the cryptocurrency lottery as the only documented way up open to all, regardless of skills.</p></blockquote>\n<p>He refers to an <em>entire social class </em>as cryptobourgeoisie.</p>\n<p>Those who believe in cryptocurrency <em>really believe</em>. It will change the world.</p>\n<p>One could say they are &#8216;talking their own book&#8217;. There is something to that, but I do not think it is primary.</p>\n<p>I think Rao means what he says.</p>\n<p>Some people have real, practical skills. They program computers, design products, start companies, sell things and raise money.</p>\n<p>He sees real skills as rare and impossible for most people to get. Most are free riders, producing little of value while a handful of Randian strivers do the real work. This forces the rest to choose exile or premium mediocrity.</p>\n<p>Cryptocurrency is special. No meta-signaling trap! Buy hardware and mine! Buy low! Sell high! The market cares not who you are. It is a lottery <em>open to all. </em>It is Out to Get You for your dollars, but <em>not </em><em>your entire life or all of your time. </em></p>\n<p>If you win the cryptocurrency lottery, you win. Period. You stop depending on <em>what other people think of you, </em>let alone <em>what other people think others will think of you.</em></p>\n<p>The coin is the product. You get cash for it. If you do well enough, you are set for life. You win freedom from the entire dystopia.</p>\n<p>Of course, cryptocurrency is also the most unreal thing ever invented.</p>\n<p>Cryptocurrency is fiat currency minus a fiat. It has value because people believe it, full stop. The game <em>between currencies</em> is convincing other people that you will convince other people that you are going to win the game. The <em>overall</em> cryptocurrency game is convincing other people that other people will be convinced that cryptocurrencies will win in general.</p>\n<p>This (and the historical track record of investments in a not-yet-collapsed maybe-real maybe-Ponzi scheme) is why premium mediocre minds believe that premium mediocre minds believe that premium mediocre minds discuss Bitcoin. So they do.</p>\n<p>&nbsp;</p>\n<p>VII: Have You Tried Not Being a Mutant?</p>\n<p>The dystopia is complete.</p>\n<p>By all rights, if she has any alternative, Maya should want out.</p>\n<p>Maya knows the price of admission to the lottery: Everything you have, all your time and everything you are.</p>\n<p>Maya knows the odds: Not good. Maya knows she probably will not win the lottery.</p>\n<p>If Maya wants to have any hope of having Slack or being a Real Person™ without the lottery, she forfeits the lottery. The lottery sniffs out anyone with Slack and any Real People™, and voids their entries.</p>\n<p>Premium mediocrity has its own internal logic. If Maya consumes premium mediocrity without giving the loop her loyalty, nothing good happens. The benefits vanish.</p>\n<p>She could indulge the occasional Actually Good thing. She might even rent the premium location as a location, without buying the mediocre goods. But that&#8217;s it.</p>\n<p>There&#8217;s just one problem.</p>\n<p>What would she do then? Leave the tech industry? Develop actual skills? Do actual things?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<div class=\"card2 js-media-container     \"></div>\n<p>&nbsp;</p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/thezvi.wordpress.com/11568/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/thezvi.wordpress.com/11568/\" /></a> <img alt=\"\" border=\"0\" src=\"https://pixel.wp.com/b.gif?host=thezvi.wordpress.com&#038;blog=21007166&#038;post=11568&#038;subd=thezvi&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Zvi",
      "slug": "zvi",
      "displayName": "Zvi"
    }
  },
  {
    "_id": "a3aGosA987cZ4aRAB",
    "title": "Online discussion is better than pre-publication peer review",
    "slug": "online-discussion-is-better-than-pre-publication-peer-review",
    "pageUrl": "https://www.lesswrong.com/posts/a3aGosA987cZ4aRAB/online-discussion-is-better-than-pre-publication-peer-review",
    "postedAt": "2017-09-05T13:25:15.331Z",
    "baseScore": 28,
    "voteCount": 19,
    "commentCount": 26,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Related: <a href=\"https://rationalconspiracy.com/2012/06/20/why-academic-papers-are-a-terrible-discussion-forum/\">Why Academic Papers Are A Terrible Discussion Forum</a>, <a href=\"https://www.facebook.com/yudkowsky/posts/10154888183439228\">Four Layers of Intellectual Conversation</a></p>\n<p>During a <a href=\"/lw/pdd/the_doomsday_argument_in_anthropic_decision_theory/dwsa\">recent</a> <a href=\"https://www.lesserwrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia\">discussion</a> about (in part) academic peer review, some people defended peer review as necessary in academia, despite its flaws, for time management. Without it, they said, researchers would be overwhelmed by \"cranks and incompetents and time-card-punchers\" and \"semi-serious people post ideas that have already been addressed or refuted in papers already\". I replied that on online discussion forums, \"it doesn't take a lot of effort to detect cranks and previously addressed ideas\". I was prompted by Michael Arc and Stuart Armstrong to elaborate. Here's what I wrote in response:</p>\n<p>My experience is with systems like LW. If an article is in my own specialty then I can judge it easily and make comments if it&rsquo;s interesting, otherwise I look at its votes and other people&rsquo;s comments to figure out whether it&rsquo;s something I should pay more attention to. One advantage over peer review is that each specialist can see all the unfiltered work in their own field, and it only takes one person from all the specialists in a field to recognize that a work may be promising, then comment on it and draw others&rsquo; attentions. Another advantage is that nobody can make ill-considered comments without suffering personal consequences since everything is public. This seem like an obvious improvement over standard pre-publication peer review, for the purpose of filtering out bad work and focusing attention on promising work, and in practice works reasonably well on LW.</p>\n<p>Apparently some people in academia have come to similar conclusions about how peer review is currently done and are trying to reform it in <a href=\"http://pubs.acs.org/doi/full/10.1021/acs.chemmater.5b01917\">various ways</a>, including switching to <a href=\"http://blog.scienceopen.com/2016/02/pre-or-post-publication-peer-review/\">post-publication peer review</a> (which seems very similar to what we do on forums like LW). However it's troubling (in a \"civilizational inadequacy\" sense) that academia is moving so slowly in that direction, despite the necessary enabling technology having been invented a decade or more ago.</p>",
    "user": {
      "username": "Wei_Dai",
      "slug": "wei-dai",
      "displayName": "Wei Dai"
    }
  },
  {
    "_id": "MzsAcfACgxwcQfDrK",
    "title": "Open thread, September 4 - September 10, 2017",
    "slug": "open-thread-september-4-september-10-2017",
    "pageUrl": "https://www.lesswrong.com/posts/MzsAcfACgxwcQfDrK/open-thread-september-4-september-10-2017",
    "postedAt": "2017-09-04T07:41:03.866Z",
    "baseScore": 2,
    "voteCount": 2,
    "commentCount": 30,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<h5 style=\"margin: 0px 0px 0.75em; font-family: Arial, Helvetica, sans-serif; text-align: justify;\"><span style=\"color: #333333;\"><span style=\"font-size: 20px;\">If it's worth saying, but not worth its own post, then it goes here.</span></span></h5>\n<div id=\"entry_t3_p2r\" class=\"content clear\" style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; font-size: 12px;\">\n<div class=\"md\">\n<div id=\"entry_t3_oxb\" class=\"content clear\" style=\"font-size: 12px;\">\n<div class=\"md\">\n<hr style=\"line-height: 19.5px;\" />\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">Notes for future OT posters:</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">1. Please add the 'open_thread' tag.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"line-height: 19px;\">2. Check if there is an active Open Thread before posting a new one. (<em>Immediately</em>&nbsp;before; refresh the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/new/\" target=\"_blank\">list-of-threads page</a>&nbsp;before posting.)<br /></span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">3.&nbsp;</span><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">Open Threads should start on Monday, and end on Sunday.</span></p>\n<p style=\"margin: 0px 0px 1em; line-height: 19.5px;\"><span style=\"font-family: chalkboard, sans-serif; line-height: 19px;\">4. Unflag the two options \"</span><span style=\"font-size: 12px; line-height: 18px;\">Notify me of new top level comments on this article\" and \"</span><label style=\"font-size: 12px; line-height: 18px;\" for=\"cc_licensed\">Make this post available under...\" before submitting</label></p>\n</div>\n</div>\n</div>\n</div>",
    "user": {
      "username": "Thomas",
      "slug": "thomas",
      "displayName": "Thomas"
    }
  },
  {
    "_id": "9Tw5RqnEzqEtaoEkq",
    "title": "If It’s Worth Doing, It’s Worth Doing With Made-Up Statistics",
    "slug": "if-it-s-worth-doing-it-s-worth-doing-with-made-up-statistics",
    "pageUrl": "https://www.lesswrong.com/posts/9Tw5RqnEzqEtaoEkq/if-it-s-worth-doing-it-s-worth-doing-with-made-up-statistics",
    "postedAt": "2017-09-03T20:56:25.373Z",
    "baseScore": 80,
    "voteCount": 52,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>I do not believe that the utility weights I worked on last week &#8211; the ones that say living in North Korea is 37% as good as living in the First World &#8211; are objectively correct or correspond to any sort of natural category. So why do I find them so interesting?</p>\n<p>A few weeks ago I got to go to a free CFAR tutorial (you can hear about these kinds of things by <A HREF=\"http://appliedrationality.org/newsletter-popup/\">signing up for their newsletter</A>). During this particular tutorial, Julia tried to explain Bayes&#8217; Theorem to some, er, rationality virgins. I record a heavily-edited-to-avoid-recognizable-details memory of the conversation below:</p>\n<p><b>Julia:</b> So let&#8217;s try an example. Suppose there&#8217;s a five percent chance per month your computer breaks down. In that case&#8230;<br />\n<b>Student:</b> Whoa. Hold on here. That&#8217;s not the chance my computer will break down.<br />\n<b>Julia:</b> No? Well, what do you think the chance is?<br />\n<b>Student:</b> Who knows? It might happen, or it might not.<br />\n<b>Julia:</b> Right, but can you turn that into a number?<br />\n<b>Student:</b> No. I have no idea whether my computer will break. I&#8217;d be making the number up.<br />\n<b>Julia:</b> Well, in a sense, yes. But you&#8217;d be communicating some information. A 1% chance your computer will break down is very different from a 99% chance.<br />\n<b>Student:</b> I don&#8217;t know the future. Why do you want to me to pretend I do?<br />\n<b>Julia:</b> <i>(who is heroically nice and patient)</i> Okay, let&#8217;s back up. Suppose you buy a sandwich. Is the sandwich probably poisoned, or probably not poisoned?<br />\n<b>Student:</b> Exactly which sandwich are we talking about here?</p>\n<p>In the context of a lesson on probability, this is a problem I think most people would be able to avoid. But the student&#8217;s attitude, the one that rejects hokey quantification of things we don&#8217;t actually know how to quantify, is a pretty common one. And it informs a lot of the objections to utilitarianism &#8211; the problem of quantifying exactly how bad North Korea shares some of the pitfalls of quantifying exactly how likely your computer is to break (for example, &#8220;we are kind of making this number up&#8221; is a pitfall).</p>\n<p>The explanation that Julia and I tried to give the other student was that imperfect information still beats zero information. Even if the number &#8220;five percent&#8221; was made up (suppose that this is a new kind of computer being used in a new way that cannot be easily compared to longevity data for previous computers) it encodes our knowledge that computers are unlikely to break in any given month. Even if we are wrong by a very large amount (let&#8217;s say we&#8217;re off by a factor of four and the real number is 20%), if the insight we encoded into the number is sane we&#8217;re still doing better than giving no information at all (maybe model this as a random number generator which chooses anything from 0 &#8211; 100?)</p>\n<p>This is part of why I respect utilitarianism. Sure, the actual badness of North Korea may not be exactly 37%. But it&#8217;s probably not twice as good as living in the First World. Or even 90% as good. But it&#8217;s probably not two hundred times worse than death either. There is definitely nonzero information transfer going on here.</p>\n<p>But the typical opponents of utilitarianism have a much stronger point than the guy at the CFAR class. They&#8217;re not arguing that utilitarianism fails to outperform zero information, they&#8217;re arguing that it fails to outperform our natural intuitive ways of looking at things, the one where you just think &#8220;North Korea? Sounds awful. The people there deserve our sympathy.&#8221;</p>\n<p>Remember the <a href=\"http://yudkowsky.net/rational/bayes\">Bayes mammogram problem</a>? The correct answer is 7.8%; most doctors (and others) intuitively feel like the answer should be about 80%. So doctors &#8211; who are specifically trained in having good intuitive judgment about diseases &#8211; are wrong by an order of magnitude. And it &#8220;only&#8221; being <em>one</em> order of magnitude is not to the doctors&#8217; credit: by changing the numbers in the problem we can make doctors&#8217; answers as wrong as we want. </p>\n<p>So the doctors probably would be better off explicitly doing the Bayesian calculation. But suppose some doctor&#8217;s internet is down (you have NO IDEA how much doctors secretly rely on the Internet) and she can&#8217;t remember the prevalence of breast cancer. If the doctor thinks her guess will be off by less than an order of magnitude, then making up a number and plugging it into Bayes will be more accurate than just using a gut feeling about how likely the test is to work. Even making up numbers based on basic knowledge like &#8220;Most women do not have breast cancer at any given time&#8221; might be enough to make Bayes Theorem outperform intuitive decision-making in many cases.</p>\n<p>And a <i>lot</i> of intuitive decisions are off by way more than the make-up-numbers ability is likely to be off by. Remember <A HREF=\"http://en.wikipedia.org/wiki/Scope_neglect\">that scope insensitivity experiment</A> where people were willing to spend about the same amount of money to save 2,000 birds as 200,000 birds? And the experiment where people are willing to work harder to save one impoverished child than fifty impoverished children? And the one where judges give criminals several times more severe punishments on average just before they eat lunch than just after they eat lunch?</p>\n<p>And it&#8217;s not just neutral biases. We&#8217;ve all seen people who approve wars under Republican presidents but are <i>horrified</i> by the injustice and atrocity of wars under Democratic presidents, even if it&#8217;s just the same war that carried over to a different administration. If we forced them to stick a number on the amount of suffering caused by war before they knew what the question was going to be, that&#8217;s a bit harder.</p>\n<p>Thus is it written: &#8220;It&#8217;s easy to lie with statistics, but it&#8217;s easier to lie without them.&#8221;</p>\n<p>Some things work okay on System 1 reasoning. Other things work badly. Really really badly. Factor of a hundred badly, if you count the bird experiment.</p>\n<p>It&#8217;s hard to make a mistake in calculating the utility of living in North Korea that&#8217;s off by a factor of <i>a hundred</i>. It&#8217;s hard to come up with values that make a war suddenly become okay/abominable when the President changes parties. </p>\n<p>Even if your data is completely made up, the way the 5% chance of breaking your computer was made up, the fact that you can apply normal non-made-up arithmetic to these made-up numbers will mean that you will very often <i>still</i> be less wrong than if you had used your considered and thoughtful and phronetic opinion.</p>\n<p>On the other hand, it&#8217;s pretty easy to accidentally Pascal&#8217;s Mug yourself into giving everything you own to a crazy cult, which System 1 is good at avoiding. So it&#8217;s nice to have data from both systems.</p>\n<p>In cases where we really don&#8217;t know what we&#8217;re doing, like utilitarianism, one can still make System 1 decisions, but making them with the System 2 data in front of you can change your mind. Like &#8220;Yes, do whatever you want here, just be aware that X causes two thousand people to die and Y causes twenty people an amount of pain which, in experiments, was rated about as bad as a stubbed toe&#8221;.</p>\n<p>And cases where we don&#8217;t really know what we&#8217;re doing have a wonderful habit of developing into cases where we <i>do</i> know what we&#8217;re doing. Like in medicine, people started out with &#8220;doctors&#8217; clinical judgment obviously trumps everything, but just in case some doctors forgot to order clinical judgment, let&#8217;s make some toy algorithms&#8221;. And then people got better and better at crunching numbers and now there are cases where doctors <A HREF=\"http://www.psych.umn.edu/faculty/grove/096clinicalversusmechanicalprediction.pdf\">should never</A> use their clinical judgment under any circumstances. I can&#8217;t find the article right now, but there are even cases where doctors armed with clinical algorithms consistently do worse than clinical algorithms without doctors. So it looks like at some point the diagnostic algorithm people figured out what they were doing.</p>\n<p>I generally support applying made-up models to pretty much any problem possible, just to notice where our intuitions are going wrong and to get a second opinion from a process that has no common sense but is also lacks systematic bias (or else has unpredictable, different systematic bias). </p>\n<p>This is why I&#8217;m disappointed that no one has ever tried expanding the QALY concept to things outside health care before. It&#8217;s not that I think it will work. It&#8217;s that I think it will fail to work in a different way than our naive opinions fail to work, and we might learn something from it.</p>\n<p><strong>EDIT: Edited to include some examples from the comments. I also really like ciphergoth&#8217;s quote: &#8220;Sometimes pulling numbers out of your arse and using them to make a decision is better than pulling a decision out of your arse.&#8221;</strong></p>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  },
  {
    "_id": "XZXeKiwD2rSC6bqMw",
    "title": "Minimizing Motivated Beliefs",
    "slug": "minimizing-motivated-beliefs",
    "pageUrl": "https://www.lesswrong.com/posts/XZXeKiwD2rSC6bqMw/minimizing-motivated-beliefs",
    "postedAt": "2017-09-03T15:56:59.768Z",
    "baseScore": 2,
    "voteCount": 1,
    "commentCount": 3,
    "meta": false,
    "question": false,
    "url": "https://entirelyuseless.wordpress.com/2017/09/03/minimizing-motivated-beliefs/",
    "htmlBody": null,
    "user": {
      "username": "entirelyuseless",
      "slug": "entirelyuseless",
      "displayName": "entirelyuseless"
    }
  },
  {
    "_id": "de6Gt8DsQ9Be2grzF",
    "title": "Debiasing by rationalizing your own motives",
    "slug": "debiasing-by-rationalizing-your-own-motives",
    "pageUrl": "https://www.lesswrong.com/posts/de6Gt8DsQ9Be2grzF/debiasing-by-rationalizing-your-own-motives",
    "postedAt": "2017-09-03T12:20:10.405Z",
    "baseScore": 3,
    "voteCount": 2,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": "http://kajsotala.fi/2017/09/debiasing-by-rationalizing-your-own-motives/",
    "htmlBody": null,
    "user": {
      "username": "Kaj_Sotala",
      "slug": "kaj_sotala",
      "displayName": "Kaj_Sotala"
    }
  },
  {
    "_id": "xQ9tMMk3RArodLtDq",
    "title": "Intellectual Progress Inside and Outside Academia",
    "slug": "intellectual-progress-inside-and-outside-academia",
    "pageUrl": "https://www.lesswrong.com/posts/xQ9tMMk3RArodLtDq/intellectual-progress-inside-and-outside-academia",
    "postedAt": "2017-09-02T23:08:46.690Z",
    "baseScore": 40,
    "voteCount": 22,
    "commentCount": 5,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>This post is taken from a recent facebook conversation that included Wei Dai, Eliezer Yudkowsky, Vladimir Slepnev, Stuart Armstrong, Maxim Kesin, Qiaochu Yuan and Robby Bensinger, about the ability of academia to do the key intellectual progress required in AI alignment. </p><h6>[The above people all gave permission to have their comments copied here. Some commenters requested their replies not be made public, and their comment threads were not copied over.]</h6></div></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><hr class=\"ory-plugins-content-divider\"/></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h4><strong>Initial Thread</strong></h4><p>Wei Dai:</p><blockquote><p>Eliezer, can you give us your take on this discussion between me, Vladimir Slepnev, and Stuart Armstrong? I&#x27;m especially interested to know if you have any thoughts on what is preventing academia from taking or even recognizing certain steps in intellectual progress (e.g., inventing anything resembling Bitcoin or TDT/UDT) that non-academics are capable of. What is going on there and what do we need do to avoid possibly suffering the same fate? See <a href=\"http://lesswrong.com/lw/pcb/the_reality_of_emergence/dwi2\">this</a> and <a href=\"https://l.facebook.com/l.php?u=http%3A%2F%2Flesswrong.com%2Flw%2Fpdd%2Fthe_doomsday_argument_in_anthropic_decision_theory%2Fdwsa&amp;h=ATPc2dkVnr9Q4yKl2bPNLEs-L2yBiXQ9khRgT1DPlEZFzcOOgdJqRMgDwHv2Vv09oQXku2Cq5B_Kbc8yyu80Jw0GSm-iTwmD6D0KRppCwBAr6E0iFS2sXyracbA9TA--mOJHE02NWNvTgRla\">this</a>.</p></blockquote><p>Eliezer Yudkowsky:</p><blockquote><p>It&#x27;s a deep issue. But stating the obvious is often a good idea, so to state the obvious parts, we&#x27;re looking at a lot of principal-agent problems, Goodhart&#x27;s Law, bad systemic incentives, hypercompetition crowding out voluntary contributions of real work, the blind leading the blind and second-generation illiteracy, etcetera. There just isn&#x27;t very much in the academic system that does promote any kind of real work getting done, and a lot of other rewards and incentives instead. If you wanted to get productive work done inside academia, you&#x27;d have to ignore all the incentives pointing elsewhere, and then you&#x27;d (a) be leading a horrible unrewarded life and (b) you would fall off the hypercompetitive frontier of the major journals and (c) nobody else would be particularly incentivized to pay attention to you except under unusual circumstances. Academia isn&#x27;t about knowledge. To put it another way, although there are deep things to say about the way in which bad incentives arise, the skills that are lost, the particular fallacies that arise, and so on, it doesn&#x27;t feel to me like the *obvious* bad incentives are inadequate to explain the observations you&#x27;re pointing to. Unless there&#x27;s some kind of psychological block preventing people from seeing all the obvious systemic problems, it doesn&#x27;t feel like the end result ought to be surprising.</p><p>Of course, a lot of people do seem to have trouble seeing what I&#x27;d consider to be obvious systemic problems. I&#x27;d chalk that up to not as much fluency with Moloch&#x27;s toolbox, plus them not being status-blind and assigning non-zero positive status to academia that makes them emotionally reluctant to correctly take all the obvious problems at face value.</p></blockquote><p>Eliezer Yudkowsky (cont.):</p><blockquote><p>It seems to me that I&#x27;ve watched organizations like OpenPhil try to sponsor academics to work on AI alignment, and it seems to me that they just can&#x27;t produce what I&#x27;d consider to be real work. The journal paper that Stuart Armstrong coauthored on &quot;interruptibility&quot; is a far step down from Armstrong&#x27;s other work on corrigibility. It had to be dumbed way down (I&#x27;m counting obscuration with fancy equations and math results as &quot;dumbing down&quot;) to be published in a mainstream journal. It had to be stripped of all the caveats and any mention of explicit incompleteness, which is necessary meta-information for any ongoing incremental progress, not to mention important from a safety standpoint. The root cause can be debated but the observable seems plain. If you want to get real work done, the obvious strategy would be to not subject yourself to any academic incentives or bureaucratic processes. Particularly including peer review by non-&quot;hobbyists&quot; (peer commentary by fellow &quot;hobbyists&quot; still being potentially very valuable), or review by grant committees staffed by the sort of people who are still impressed by academic sage-costuming and will want you to compete against pointlessly obscured but terribly serious-looking equations.</p></blockquote><p>Eliezer Yudkowsky (cont.):</p><blockquote><p>There&#x27;s a lot of detailed stories about good practice and bad practice, like why mailing lists work better than journals because of that thing I wrote on FB somewhere about why you absolutely need 4 layers of conversation in order to have real progress and journals do 3 layers which doesn&#x27;t work. If you&#x27;re asking about those it&#x27;s a lot of little long stories that add up.</p></blockquote></div></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><hr class=\"ory-plugins-content-divider\"/></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h4><strong>Subthread 1</strong></h4><p>Wei Dai:</p><blockquote><p>Academia is capable of many deep and important results though, like complexity theory, public-key cryptography, zero knowledge proofs, vNM and Savage&#x27;s decision theories, to name some that I&#x27;m familiar with. It seems like we need a theory that explains why it&#x27;s able to take certain kinds of steps but not others, or maybe why the situation has gotten a lot worse in recent decades.</p><p>That academia may not be able to make progress on AI alignment is something that worries me and a major reason for me to be concerned about this issue now. If we had a better, more nuanced theory of what is wrong with academia, that would be useful for guiding our own expectations on this question and perhaps also help persuade people in charge of organizations like OpenPhil.</p></blockquote><p>Qiaochu Yuan:</p><blockquote><p>Public-key cryptography was invented by GCHQ first, right?</p></blockquote><p>Wei Dai:</p><blockquote><p>It was independently reinvented by academia, with only a short delay (4 years according to Wikipedia) using much less resources compared to the government agencies. That seems good enough to illustrate my point that academia is (or at least was) capable of doing good and efficient work.</p></blockquote><p>Qiaochu Yuan:</p><blockquote><p>Fair point.</p><p>I&#x27;m a little concerned about the use of the phrase &quot;academia&quot; in this conversation not cutting reality at the joints. Academia may simply not be very homogeneous over space and time - it certainly seems strange to me to lump von Neumann in with everyone else, for example.</p></blockquote><p>Wei Dai: </p><blockquote><p>Sure, part of my question here is how to better carve reality at the joints. What&#x27;s the relevant difference between the parts (in space and/or time) of academia that are productive and the parts that are not?</p></blockquote><p>Stuart Armstrong:</p><blockquote><p>Academia is often productive. I think the challenge is mainly getting it to be productive on the right problems.</p></blockquote><p>Wei Dai:</p><blockquote><p>Interesting, so maybe a better way to frame my question is, of the times that academia managed to focus on the right problems, what was responsible for that? Or, what is causing academia to not be able to focus on the right problems in certain fields now?</p></blockquote></div></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><hr class=\"ory-plugins-content-divider\"/></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h4><strong>Subthread 2</strong></h4><p>Eliezer Yudkowsky:</p><blockquote><p>Things have certainly gotten a lot worse in recent decades. There&#x27;s various stories I&#x27;ve theorized about that but the primary fact seems pretty blatant. Things might be different if we had the researchers and incentives from the 1940s, but modern academics are only slightly less likely to sprout wings than to solve real alignment problems as opposed to fake ones. They&#x27;re still the same people and the same incentive structure that ignored the entire issue in the first place.</p><p>OpenPhil is better than most funding sources, but not close to adequate. I model them as having not seen past the pretend. I&#x27;m not sure that more nuanced theories are what they need to break free. Sure, I have a dozen theories about various factors. But ultimately, most human institutions through history haven&#x27;t solved hard mental problems. Asking why modern academia doesn&#x27;t UDT may be like asking why JC Penney doesn&#x27;t. It&#x27;s just not set up to do that. Nobody is being docked a bonus for writing papers about CDT instead. Feeling worried and like something is out of place about the College of Cardinals in the Catholic Church not inventing cryptocurrencies, suggests a basic mental tension that may not be cured by more nuanced theories of the sociology of religion. Success is unusual and calls for explanation, failure doesn&#x27;t. Academia in a few colleges in a few countries used to be in a weird regime where it could solve hard problems, times changed, it fell out of that weird place.</p></blockquote><p>Rob Bensinger:</p><blockquote><p>It&#x27;s not actually clear to me, even after all this discussion, that 1940s researchers had significantly better core mental habits / mindsets for alignment work than 2010s researchers. A few counter-points:</p><ul><li><p>A lot of the best minds worked on QM in the early 20th century, but I don&#x27;t see clear evidence that QM progressed differently than AI is progressing today; that is, I don&#x27;t know of a clear case that falsifies the hypothesis &quot;all the differences in output are due to AI and QM as cognitive problems happening to involve inherently different kinds and degrees of difficulty&quot;. In both cases, it seems like people did a good job of applying conventional scientific methods and occasionally achieving conceptual breakthroughs in conventional scientific ways; and in both cases, it seems like there&#x27;s a huge amount of missing-the-forest-for-the-trees, not-seriously-thinking-about-the-implications-of-beliefs, and generally-approaching-philosophyish-questions-flippantly. It took something like 50 years to go from &quot;Schrodinger&#x27;s cat is weird&quot; to &quot;OK /maybe/ macroscopic superposition-ish things are real&quot; in physics, and &quot;maybe macroscopic superposition-ish things are real&quot; strikes me as much more obvious and much less demanding of sustained theorizing than, e.g., &#x27;we need to prioritize decision theory research ASAP in order to prevent superintelligent AI systems from destroying the world&#x27;. Even von Neumann had non-naturalist views about QM, and if von Neumann is a symptom of intellectual degeneracy then I don&#x27;t know what isn&#x27;t.</p></li><li><p>Ditto for the development of nuclear weapons. I don&#x27;t see any clear examples of qualitatively better forecasting, strategy, outside-the-box thinking, or scientific productivity on this topic in e.g. the 1930s, compared to what I&#x27;d expect see today. (Though this comparison is harder to make because we&#x27;ve accumulated a lot of knowledge and hard experience with technological GCR as a result of this and similar cases.) The near-success of the secrecy effort might be an exception, since that took some loner agency and coordination that seems harder to imagine today. (Though that might also have been made easier by the smaller and less internationalized scientific community of the day, and by the fact that world war was on everyone&#x27;s radar?)</p></li><li><p>Turing and I. J. Good both had enough puzzle pieces to do at least a little serious thinking about alignment, and there was no particular reason for them not to do so. The 1956 Dartmouth workshop shows &quot;maybe true AI isn&#x27;t that far off&quot; was at least taken somewhat seriously by a fair number of people (though historians tend to overstate the extent to which this was true). If 1940s researchers were dramatically better than 2010s researchers at this kind of thing, and the decay after the 1940s wasn&#x27;t instantaneous, I&#x27;d have expected at least a hint of serious thinking-for-more-than-two-hours about alignment from at least one person working in the 1950s-1960s (if not earlier).</p></li></ul></blockquote><p>Rob Bensinger:</p><blockquote><p>Here&#x27;s a different hypothesis: Human brains and/or all of the 20th century&#x27;s standard scientific toolboxes and norms are just really bad at philosophical/conceptual issues, full stop. We&#x27;re bad at it now, and we were roughly equally bad at it in the 1940s. A lot of fields have slowed down because we&#x27;ve plucked most of the low-hanging fruit that doesn&#x27;t require deep philosophical/conceptual innovation, and AI in particular happens to be an area where the things human scientists have always been worst at are especially critical for success.</p></blockquote><p>Wei Dai:</p><blockquote><p>Ok, so the story I&#x27;m forming in my mind is that we&#x27;ve always been really bad at philosophical/conceptual issues, and past philosophical/conceptual advances just represent very low-hanging fruit that have been picked. When we invented mailing lists / blogs, the advantage over traditional academic communications allowed us to reach a little higher and pick up a few more fruits but progress is still very limited because we&#x27;re still not able to reach very high in an absolute sense, and making progress this way depends on gathering together enough hobbyists with the right interests and resources which is a rare occurrence. Rob, I&#x27;m not sure how much of this you endorse, but it seems like the best explanation of all the relevant facts I&#x27;ve seen so far.</p></blockquote><p>Rob Bensinger:</p><blockquote><p>I think the object-level philosophical progress via mailing lists / blogs was tied to coming up with some good philosophical methodology. One simple narrative about the global situation (pretty close to the standard narrative) is that before 1880 or so, human inquiry was good at exploring weird nonstandard hypotheses, but bad at rigorously demanding testability and precision of those hypotheses. Human inquiry between roughly 1880 and 1980 solved that problem by demanding testability and precision in all things, which (combined with prosaic knowledge accumulation) let them grab a lot of low-hanging scientific fruit really fast, but caused them to be unnecessarily slow at exploring any new perspectives that weren&#x27;t 100% obviously testable and precise in a certain naive sense (which led to lack-of-serious-inquiry into &quot;weird&quot; questions at the edges of conventional scientific activities, like MWI and Newcomb&#x27;s problem).</p><p>Bayesianism, the cognitive revolution, the slow fade of positivism&#x27;s influence, the random walk of academic one-upmanship, etc. eventually led to more sophistication in various quarters about what kind of testability and precision are important by the late 20th century, but this process of synthesizing &#x27;explore weird nonstandard hypotheses&#x27; with &#x27;demand testability and precision&#x27; (which are the two critical pieces of the puzzle for &#x27;do unusually well at philosophy/forecasting/etc.&#x27;) was very uneven and slow. Thus you get various little islands of especially good philosophy-ish thinking showing up at roughly the same time here and there, including parts of analytic philosophy (e.g., Drescher), mailing lists (e.g., Extropians), and psychology (e.g., Tetlock).</p></blockquote></div></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><hr class=\"ory-plugins-content-divider\"/></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h4><strong>Subthread 3</strong></h4><p>Vladimir Slepnev:</p><blockquote><p>Eliezer, your position is very sharp. A couple questions then:</p><ol><li><p>Do you think e.g. Scott Aaronson&#x27;s work on quantum computing today falls outside the &quot;weird regime where it could solve hard problems&quot;?</p></li><li><p>Do you have a clear understanding why e.g. Nick Bostrom isn&#x27;t excited about TDT/UDT?</p></li></ol></blockquote><p>Wei Dai:</p><blockquote><p>Vladimir, can you clarify what you mean by &quot;isn&#x27;t excited&quot;? Nick did write a few paragraphs about the relevance of decision theory to AI alignment in his Superintelligence, and cited TDT and UDT as &quot;newer candidates [...] which are still under development&quot;. I&#x27;m not sure what else you&#x27;d expect, given that he hasn&#x27;t specialized in decision theory in his philosophy work? Also, what&#x27;s your own view of what&#x27;s causing academia to not be able to make these &quot;outsider steps&quot;?</p></blockquote><p>Vladimir Slepnev:</p><blockquote><p>Wei, at some point you thought of UDT as the solution to anthropic reasoning, right? That&#x27;s Bostrom&#x27;s specialty. So if you are right, I&#x27;d expect more than a single superficial mention.</p><p>My view is that academia certainly tends to go off in wrong directions and it was always like that. But its direction can be influenced with enough effort and understanding, it&#x27;s been done many times, and the benefits of doing that are too great to overlook.</p></blockquote><p>Wei Dai:</p><blockquote><p>I&#x27;m not sure, maybe he hasn&#x27;t looked into UDT closely enough to understand the relevance to anthropics or he&#x27;s committed to a probability view? Probably Stuart has a better idea of this than I do. Oh, I do recall that when I attended a workshop at FHI, he asked me some questions about UDT that seemed to indicate that he didn&#x27;t understand it very well. I&#x27;m guessing he&#x27;s probably just too busy to do object-level philosophical investigations these days.</p><p>Can you give some past examples of academia going off in the wrong direction, and that being fixed by outsiders influencing its direction?</p></blockquote><p>Vladimir Slepnev:</p><blockquote><p>Why do you need the &quot;fixed by outsiders&quot; bit? I think it&#x27;s easier to change the direction of academia while being in academia, and that&#x27;s been done many times.</p></blockquote><p>Maxim Kesin:</p><blockquote><p>Vladimir Slepnev The price of admission is pretty high for people who can do otherwise productive work, no? Especially since very few members of the club can have direction-changing impact. Something like finding and convincing existing high-standing members, preferably several of them seems like a better strategy than joining the club and doing it from the inside yourself.</p></blockquote><p>Wei Dai:</p><blockquote><p>Vladimir, on LW you wrote &quot;More like a subset of steps in each field that need to be done by outsiders, while both preceding and following steps can be done by academia.&quot; If some academic field is going in a wrong direction because it&#x27;s missing a step that needs to be done by outsiders, how can someone in academia change its direction? I&#x27;m confused... Are you saying outsiders should go into academia in order to change its direction, after taking the missing &quot;outsider steps&quot;? Or that there is no direct past evidence that outsiders can change academia&#x27;s direction but there&#x27;s evidence that insiders can and that serves as bayesian evidence that outsiders can too? Or something else?</p></blockquote><p>Vladimir Slepnev:</p><blockquote><p>I guess I shouldn&#x27;t have called them &quot;outsider steps&quot;, more like &quot;newcomer steps&quot;. Does that make sense?</p></blockquote><p>Eliezer Yudkowsky:</p><blockquote><p>There&#x27;s an old question, &quot;What does the Bible God need to do for the Christians to say he is not good?&quot; What would academia need to do before you let it go?</p></blockquote><p>Vladimir Slepnev:</p><blockquote><p>But I don&#x27;t feel abused! My interactions with academia have been quite pleasant, and reading papers usually gives me nice surprises. When I read your negative comments about academia, I mostly just get confused. At least from what I&#x27;ve read in this discussion today, it seems like the mystical force that&#x27;s stopping people like Bostrom from going fully on board with ideas like UDT is simple miscommunication on our part, not anything more sinister. If our arguments for using decisions over probabilities aren&#x27;t convincing enough, perhaps we should work on them some more.</p></blockquote><p>Wei Dai:</p><blockquote><p>Vladimir, surely those academic fields have had plenty of infusion of newcomers in the form of new Ph.D. students, but the missing steps only got done when people tried do them while remaining entirely out of academia. Are you sure the relevant factor here is &quot;new to the field&quot; rather than &quot;doing work outside of academia&quot;?</p></blockquote><p>Stuart Armstrong:</p><blockquote><p>Academic fields are often productive, but narrow. Saying &quot;we should use decision theory instead of probability to deal with anthropics&quot; falls outside of most of the relevant fields, so few academics are interested, because it doesn&#x27;t solve the problems they are working on.</p></blockquote><p>Wei Dai:</p><blockquote><p>Vladimir, a lot of people on LW didn&#x27;t have much trouble understanding UDT as informally presented there, or recognizing it as a step in the right direction. If joining academia makes somebody much less able to recognize progress in decision theory, that seems like a bad thing and we shouldn&#x27;t be encouraging people to do that (at least until we figure out what exactly is causing the problem and how to fix or avoid it on an institutional or individual level).</p></blockquote><p>Vladimir Slepnev:</p><blockquote><p>I think it&#x27;s not surprising that many LWers agreed with UDT, because most of them were introduced to the topic by Eliezer&#x27;s post on Newcomb&#x27;s problem, which framed the problem in a way that emphasized decisions over probabilities. (Eliezer, if you&#x27;re listening, that post of yours was the single best example of persuasion I&#x27;ve seen in my life, and for a good goal too. Cheers!) So there&#x27;s probably no statistical effect saying outsiders are better at grasping UDT on average. It&#x27;s not that academia is lacking some decision theory skill, they just haven&#x27;t bought our framing yet. When/if they do, they will be uniquely good at digging into this idea, just as with many other ideas.</p><p>If the above is true, then refusing to pay the fixed cost of getting our ideas into academia seems clearly wrong. What do you think?</p></blockquote></div></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><hr class=\"ory-plugins-content-divider\"/></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h4><strong>Subthread 4</strong></h4><p>Stuart Armstrong:</p><blockquote><p>Think the problem is a mix of specialisation and lack of urgency. If I&#x27;d been willing to adapt to the format, I&#x27;m sure I could have got my old pro-SIA arguments published. But anthropics wasn&#x27;t ready for a &quot;ignore the big probability debates you&#x27;ve been having; anthropic probability doesn&#x27;t exist&quot; paper. And those were interested in the fundamental interplay between probability and decision theory weren&#x27;t interested in anthropics (and I wasn&#x27;t willing to put the effort in to translate it into their language).</p><p>This is where the lack of urgency comes in. People found the paper interesting, I&#x27;d wager, but not saying anything about the questions they were interested in. And they had no real feeling that some questions were far more important than theirs.</p></blockquote><p>Stuart Armstrong:</p><blockquote><p>I&#x27;ve presented the idea to Nick a few times, but he never seemed to get it fully. It&#x27;s hard to ignore probabilities when you&#x27;ve spent your life with them.</p></blockquote><p>Eliezer Yudkowsky:</p><blockquote><p>I will mention for whatever it&#x27;s worth that I don&#x27;t think decision theory can eliminate anthropics. That&#x27;s an intuition I still find credible and it&#x27;s possible Bostrom felt the same. I&#x27;ve also seen Bostrom contribute at least one decision theory idea to anthropic problems, during a conversation with him by instant messenger, a division-of-responsibility principle that UDT later rendered redundant.</p></blockquote><p>Stuart Armstrong:</p><blockquote><p>I also disagree with Eliezer about the use of the &quot;interruptible agents&quot; paper. The math is fun but ultimately pointless, and there is little mention of AI safety. However, it was immensely useful for me to write that paper with Laurent, as it taught me so much about how to model things, and how to try and translate those models into things that ML people like. As a consequence, I can now design indifference methods for practically any agent, which was not the case before.</p><p>And of course the paper wouldn&#x27;t mention the hard AI safety problems - not enough people in ML are working on those. The aim was to 1) present part of the problem, 2) present part of the solution, and 3) get both of those sufficiently accepted that harder versions of the problem can then be phrased as &quot;take known problem/solution X, and add an extra assumption...&quot;</p></blockquote><p>Rob Bensinger:</p><blockquote><p>That rationale makes sense to me. I think the concern is: if the most visible and widely discussed papers in AI alignment continue to be ones that deliberately obscure their own significance in various ways, then the benefits from the slow build-up to being able to clearly articulate our actual views in mainstream outlets may be outweighed by the costs from many other researchers internalizing the wrong take-aways in the intervening time. This is particularly true if many different build-ups like this are occurring simultaneously, over many years of incremental progress toward just coming out and saying what we actually think.</p><p>I think this is a hard problem, and one MIRI&#x27;s repeatedly had to deal with. Very few of MIRI&#x27;s academic publications even come close to giving a full rationale for why we care about a given topic or result. The concern is with making it standard practice for high-visibility AI alignment papers to be at least somewhat misleading (in order to get wider attention, meet less resistance, get published, etc.), rather than with the interruptibility paper as an isolated case; and this seems like a larger problem for overstatements of significance than for understatements.</p><p>I don&#x27;t know how best to address this problem. Two approaches MIRI has tried before, which might help FHI navigate this, are: (1) writing a short version of the paper for publication that doesn&#x27;t fully explain the AI safety rationale, and a longer eprint of the same paper that does explain the rationale; and/or (2) explaining results&#x27; significance more clearly and candidly in the blog post announcing the paper.</p></blockquote></div></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><hr class=\"ory-plugins-content-divider\"/></div></div></div><div class=\"ory-row ory-cell-inner\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><h4><strong>Subthread 5</strong></h4><p>Eliezer Yudkowsky:</p><blockquote><p>To put this yet another way, most human bureaucracies and big organizations don&#x27;t do science. They have incentives for the people inside them which get them to do things other than science. For example, in the FBI, instead of doing science, you can best advance your career by closing big-name murder cases... or whatever. In the field of psychology, instead of doing science, you can get a lot of undergraduates into a room and submit obscured-math impressive-sounding papers with a bunch of tables that claim a p-value greater than 0.05. Among the ways we know that this has little to do with science is that the papers don&#x27;t replicate. P-values are rituals[1], and being surprised that the rituals don&#x27;t go hand-in-hand with science says you need to adjust your intuitions about what is surprising. It&#x27;s like being surprised that your prayers aren&#x27;t curing cancer and asking how you need to pray differently.</p><p>Now, it may be that separately from the standard incentives, decades later, a few heroes get together and try to replicate some of the most prestigious papers. They are doing science. Maybe somebody inside the FBI is also doing science. Lots of people in Christian religious organizations, over the last few centuries, did some science, though fewer now than before. Maybe the public even lauded the science they did, and they got some rewards. It doesn&#x27;t mean the Catholic Church is set up to teach people how to do real science, or that this is the primary way to get ahead in the Catholic Church such that status-seekers will be driven to seek their promotions by doing great science.</p><p>The people doing real science by trying to replicate psychology studies may report ritual p-values and submit for ritual peer-review-by-idiots. Similarly, some doctors in the past no doubt prayed while giving their patients antibiotics. It doesn&#x27;t mean that prayer works some of the time. It means that these heroes are doing science, and separately, doing bureaucracy and a kind of elaborate ritual that is what our generation considers to be prestigious and mysterious witch doctery.</p><p>[1] https://arbital.com/p/likelihoods_not_pvalues/?l=4x</p></blockquote></div></div></div></div></div></div>",
    "user": {
      "username": "Benito",
      "slug": "benito",
      "displayName": "Ben Pace"
    }
  },
  {
    "_id": "KB2Gg5ht3nzXXp23P",
    "title": "September 2017 Media Thread",
    "slug": "september-2017-media-thread",
    "pageUrl": "https://www.lesswrong.com/posts/KB2Gg5ht3nzXXp23P/september-2017-media-thread",
    "postedAt": "2017-09-02T21:17:56.947Z",
    "baseScore": 1,
    "voteCount": 1,
    "commentCount": 26,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>This is the monthly thread for posting media of various types that you've found that you enjoy. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the <a href=\"/r/discussion/tag/media_thread/\">older threads</a>.</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a <a href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please post only under one of the already created subthreads, and never directly under the parent media thread.</li>\n<li>Use the \"Other Media\" thread if you believe the piece of media you want to discuss doesn't fit under any of the established categories.</li>\n<li>Use the \"Meta\" thread if you want to discuss about the monthly media thread itself (e.g. to propose adding/removing/splitting/merging subthreads, or to discuss the type of content properly belonging to each subthread) or for any other question or issue you may have about the thread or the rules.</li>\n</ul>",
    "user": {
      "username": "ArisKatsaris",
      "slug": "ariskatsaris",
      "displayName": "ArisKatsaris"
    }
  },
  {
    "_id": "zFHfiJGTq88rQzype",
    "title": "Simplified Anthropic Doomsday",
    "slug": "simplified-anthropic-doomsday",
    "pageUrl": "https://www.lesswrong.com/posts/zFHfiJGTq88rQzype/simplified-anthropic-doomsday",
    "postedAt": "2017-09-02T20:37:48.290Z",
    "baseScore": 1,
    "voteCount": 1,
    "commentCount": 2,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Here is a simplified version of the <a href=\"/r/discussion/lw/pdd/the_doomsday_argument_in_anthropic_decision_theory/\">Doomsday argument in Anthropic decision theory</a>, to get easier intuitions.</p>\n<p>Assume a single agent A exists, an average utilitarian, with utility linear in money. Their species survives with 50% probability; denote this event by S. If the species survives, there will be 100 people total; otherwise the average utilitarian is the only one of its kind. An independent coin lands heads with 50% probability; denote this event by H.</p>\n<p>Agent A must price a coupon C<sub>S</sub> that pays out&nbsp;&euro;1 on S, and a coupon C<sub>H</sub> that pays out&nbsp;&euro;1 on H. The coupon C<sub>S</sub>&nbsp;pays out only on S, thus the reward only exists in a world where there are a hundred people, thus if S happens, the coupon C<sub>S</sub> is worth (&euro;1)/100. Hence its expected worth is (&euro;1)/200=(&euro;2)/400.</p>\n<p>But H is independent of S, so (H,S) and (H,&not;S) both have probability 25%. In (H,S), there are a hundred people, so C<sub>H</sub> is worth (&euro;1)/100. In (H,&not;S), there is one person, so C<sub>H</sub> is worth (&euro;1)/1=&euro;1. Thus the expected value of C<sub>H</sub> is (&euro;1)/4+(&euro;1)/400 = (&euro;101)/400. This is more than 50 times the value of C<sub>S</sub>.</p>\n<p>Note that C<sub>&not;S</sub>, the coupon that pays out on doom, has an even higher expected value of (&euro;1)/2=(&euro;200)/400.</p>\n<p>So, H and S have identical probability, but A assigns C<sub>S</sub> and C<sub>H</sub> different expected utilities, with a higher value to C<sub>H</sub>, simply because S is correlated with survival and H is independent of it (and A assigns an ever higher value to C<sub>&not;S</sub>, which is anti-correlated with survival). This is a phrasing of the <a href=\"https://en.wikipedia.org/wiki/Doomsday_argument\">Doomsday Argument</a> in <a href=\"/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">ADT</a>.</p>",
    "user": {
      "username": "Stuart_Armstrong",
      "slug": "stuart_armstrong",
      "displayName": "Stuart_Armstrong"
    }
  },
  {
    "_id": "fzeoYhKoYPR3tDYFT",
    "title": "Beware Isolated Demands For Rigor",
    "slug": "beware-isolated-demands-for-rigor",
    "pageUrl": "https://www.lesswrong.com/posts/fzeoYhKoYPR3tDYFT/beware-isolated-demands-for-rigor",
    "postedAt": "2017-09-02T19:50:00.365Z",
    "baseScore": 134,
    "voteCount": 119,
    "commentCount": 6,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><strong>I.</strong></p><p>From Identity, Personal Identity, and the Self by John Perry:</p><blockquote><p>&quot;There is something about practical things that knocks us off our philosophical high horses. Perhaps Heraclitus really thought he couldn’t step in the same river twice. Perhaps he even received tenure for that contribution to philosophy. But suppose some other ancient had claimed to have as much right as Heraclitus did to an ox Heraclitus had bought, on the grounds that since the animal had changed, it wasn’t the same one he had bought and so was up for grabs. Heraclitus would have quickly come up with some ersatz, watered-down version of identity of practical value for dealing with property rights, oxen, lyres, vineyards, and the like. And then he might have wondered if that watered-down vulgar sense of identity might be a considerably more valuable concept than a pure and philosophical sort of identity that nothing has.</p></blockquote><p>Okay, but I can think of something worse than that.</p><p>Imagine Heraclitus as a cattle rustler in the Old West. Every time a rancher catches him at his nefarious business, he patiently explains to them that identity doesn’t exist, and therefore the same argument against private property as made above. Flummoxed, they’re unable to think of a response before he rides off into the sunset.</p><p>But then when Heraclitus himself needs the concept of stable personal identity for something – maybe he wants to deposit his ill-gotten gains in the bank with certainty that the banker will give it back to him next time he shows up to withdraw it, or maybe he wants to bribe the sheriff to ignore his activities for the next while – all of a sudden Heraclitus is willing to tolerate the watered-down vulgar sense of identity like everyone else.</p><p>(actually, I can think of something even worse than that, which is a TV western based on this premise, where a roving band of pre-Socratic desperadoes terrorizes Texas. The climax is no doubt when the hero strides onto Main Street, revolver in hand, saying “There’s a new sheriff in town.” And Parmenides gruffly responds “No, I’m pretty sure that’s impossible.”)</p><p>At its best, philosophy is a revolutionary pursuit that dissolves our common-sense intuitions and exposes the possibility of much deeper structures behind them. One can respond by becoming a saint or madman, or by becoming a pragmatist who is willing to continue to participate in human society while also understanding its theoretical limitations. Both are respectable career paths.</p><p>The problem is when someone chooses to apply philosophical rigor selectively.</p><p>Heraclitus could drown in his deeper understanding of personal identity and become a holy madman, eschewing material things and taking no care for the morrow because he does not believe there is any consistent self to experience it. Or he could engage with it from afar, becoming a wise scholar who participating in earthly affairs while drawing equanimity from the realization that there is a sense in which all his accomplishments will be impermanent.</p><p>But if he only applies his new theory when he wants other people’s cows, then we have a problem. Philosophical rigor, usually a virtue, has been debased to an isolated demand for rigor in cases where it benefits Heraclitus.</p><p>A fair use of philosophical rigor would prevent both Heraclitus and his victims from owning property, and thus either collapse under its own impracticality or usher in a revolutionary new form of economic thinking. An isolated demand for philosophical rigor, applied by Heraclitus to other people but never the other way around, would merely give Heraclitus an unfair advantage in the existing system.</p><p><strong>II.</strong></p><p>A while ago I wrote a post called <a href=\"http://slatestarcodex.com/2013/08/30/military-strikes-are-an-extremely-cheap-way-to-help-foreigners/\">Military Strikes Are An Extremely Cheap Way To Help Foreigners</a> which was a response to a Matt Yglesias post called <a href=\"http://www.slate.com/blogs/moneybox/2013/08/27/syria_intervention_cost_military_strikes_are_a_highly_cost_ineffective_way.html\">the opposite</a>. Yglesias was opposed to “humanitarian” military intervention (think the air strikes on ISIS going on right now, justified under the cause of preventing a genocide) and his argument was that this was extremely cost-ineffective compared to just giving the money to GiveWell’s top-rated charity – at the time he was writing, malaria prevention.</p><p>I argued he was wrong about his numbers. But I also argued he was unfairly making an isolated demand for philosophical rigor.</p><p>Once you learn about utilitarianism and effective charity, you can become the holy madman, donating every cent you have beyond what is strictly necessary to survive and hold down a job to whatever the top rated charity is.</p><p>Or you can become the worldly scholar, continuing to fritter away your money on things like “hot water” and “food other than gruel” but appreciating the effective-utilitarian perspective and trying to make a few particularly important concessions to it.</p><p>Or you can use it to steal other people’s cows. This is what I accused Matt Yglesias of doing. Presumably there are lots of government programs Yglesias supports – I suggested PBS – and he would never dream of demanding that we defund them in the hopes of donating the money to malaria prevention. But if for political reasons he doesn’t support air strikes, suddenly that plan has to justify itself according to rigorous criteria that no government program that exists could possibly pass.</p><p>Government spending seems to be a particularly fertile case for this problem. I remember hearing some conservatives complain: sex education in public schools is an outrage, because my tax dollars are going to support something I believe is morally wrong.</p><p>This is, I guess, a demand for ethical rigor. That no one should ever be forced to pay for something they don’t like. Apply it consistently, and conservatives shouldn’t have to pay for sex ed, liberals shouldn’t have to pay for wars, and libertarians shouldn’t have to pay for anything, except maybe a $9.99 tax bill yearly to support the police and a minimal court system.</p><p>Applied consistently, you become the holy madman demanding either total anarchy or some kind of weird system of tax earmarks which would actually be pretty fun to think about. Or the worldly scholar with a strong appreciation for libertarian ideas who needs a really strong foundational justification for spending government money on things that a lot of people oppose.</p><p>Applied inconsistently, you’re just stealing cows again, coming up with a clever argument against the programs you don’t like while defending the ones you do.</p><p><strong>III.</strong></p><p>But this is the sort of uncouth behavior we expect of political partisans. What about science?</p><p>Suppose there are scientists on both sides of a controversial issue – for example, economists studying the minimum wage. One team that supports a minimum wage comes up with a pretty good study showing with p &lt; 0.05 that minimum wages help the economy in some relevant way. The Science Czar (of course we have a science czar! We&#x27;re not monsters!) notes that p &lt; 0.05 is really a shoddy criterion that can prove anything and they should come back when they have p &lt; 0.01. I have a huge amount of sympathy with the Science Czar on this one, by the way.</p><p>Soooo the team of economists spends another five years doing another study and finds with p &lt; 0.01 that the minimum wage helps the economy in some important way. The Science Czar notes that their study was correlational only, and that correlational studies suck. We really can&#x27;t show that minimum wages are any good without a randomized controlled trial. Luckily, the governments of every country in the world are totally game for splitting their countries in half and instituting different economic regimes in each part for ten years, so after a decade it comes out that in the randomized controlled trial the minimum wage helped the economy with p &lt; 0.01. The Science Czar worries about publication bias. What if there were a lot of other teams who got all the countries in the world to split in half and institute different wage policies in each of the two territories for one decade, but they weren&#x27;t published because their results weren&#x27;t interesting enough? Everything the Science Czar has said so far makes perfect sense and he is to be commended for his rigor and commitment to the job. Science is really hard and even tiny methodological mistakes <a href=\"http://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/\">can in principle invalidate an entire field</a>.</p><p>But now suppose that a team shows that, in a sample of six restaurants in Podunk Ohio, there was a nonsignificant trend towards the minimum wage making things a little worse.</p><p>And the Science Czar says: awesome! That solves that debate, minimum wage is bad, let’s move on to investigating nominal GDP targeting.</p><p>Now it looks like the Science Czar is just a jerk who’s really against minimum wage. All his knowledge of the standards of scientific rigor are going not towards bettering science, but toward worsering science. He’s not trying to create a revolutionary new scientific regime, he’s taking pot shots.</p><p>I see this a lot in medicine. Someone jumps on a new study showing the selenium or chromium or plutonium or whatever cures cancer. It is brought up that no, really, the medical community has investigated this sort of thing before, and it has always been found that it doesn’t.</p><p>“Well, maybe the medical community wasn’t investigating it the right way! Maybe the investigators were biased! Maybe they didn’t randomize right! Maybe they used a population unusually susceptible to cancer-getting! Ninety percent of medical studies are wrong! Those twenty experiments showing a lack of effect could be total bunk!”</p><p>Yes, maybe these things happened in each of the twenty studies that disagree with you.</p><p>Or maybe they happened in the one contrarian study you are getting so excited about.</p><p><strong>IV.</strong></p><p>The unholy combination of isolated demands for philosophical rigor and isolated demands for scientific rigor is isolated demands for mathematical-statistical-conceptual rigor, ie the sort of thing this blog has been talking about all week.</p><p>I have already <a href=\"http://slatestarcodex.com/2014/08/11/does-the-glasgow-coma-scale-exist-do-comas/#comment-133546\">been made fun of</a> for how many different things I am metaphorically comparing IQ to – speed, blood pressure, <a href=\"http://slatestarcodex.com/2014/08/11/does-the-glasgow-coma-scale-exist-do-comas/\">comas</a> – so I guess it can’t hurt to add another example I only thought of today. How about crime? It’s usually measured by crime rate – a made-up statistic that combines subfactors like arson (maybe higher when fire insurance pays out better), property damage (maybe higher during periods of ethnic tension and frequent riots) and theft (maybe higher when income inequality is worse). There is assumed to be a General Factor Of Crime (presumably caused by things like poor policing, dark alleys, broken families, et cetera) but I would be extremely surprised if anyone had ever proven Beyond A Shadow Of A Doubt that the factor analysis works out here.</p><p>When Cosma Shalizi says <a href=\"http://vserver1.cscs.lsa.umich.edu/~crshalizi/weblog/523.html\">he’s not sure</a> about the factor analysis in IQ, I have no quarrel with him, because Cosma Shalizi’s response to everything in the world is to glare at it for not being sufficiently statistically rigorous.</p><p>But when other people are totally happy to talk about speed and blood pressure and comas and the crime rate, and then suddenly switch to a position that we can’t talk about IQ at all unless we have a perfect factor-analytical proof of its obeying certain statistical rules, then I worry they’re just out to steal cows.</p><p>Likewise, if someone were to just never acknowledge any sorts of groups of objects except those that could be statistically proven to fall out into absolutely separate clusters in which variance within each cluster is less than variance between clusters, well, at least they would be fun to talk to at dinner parties.</p><p>But when people never even begin to question the idea of different cultures but make exacting demands of anyone before they can talk about different races – even though <a href=\"http://slatestarcodex.com/2014/08/12/does-race-exist-does-culture/\">the two ideas are statistically isomorphic </a>– then I think they’re just out to steal cows.</p><p>So this is another technique for avoiding <a href=\"http://slatestarcodex.com/2014/08/10/getting-eulered/\">Eulering</a> – is your interlocutor equally willing to apply their complex mathematical argument to everything else.</p><p>I think if I hadn’t known anything about Bayesian probability, I would have examined the McGrews’ Bayesian argument for the Gospels by seeing if it applied equally well to <a href=\"http://squid314.livejournal.com/330728.html\">Mormonism</a>, the <a href=\"http://squid314.livejournal.com/331273.html\">control group for Christianity</a>.</p><p><strong>V.</strong></p><p>The old man stamped his boot in the red dirt, kicking up a tiny cloud of dust. “There’s a new sheriff in town,” he told them.</p><p>“No, I’m pretty sure that’s impossible,” says Parmenides. “There’s no such thing as change, only the appearance thereof.”</p><p>“Well then,” says the old man, “I reckon you won’t mind the false illusion of your surroundings appearing to change into a jail cell.” And he took out his six-shooter and held it steady.</p><p>“Hold on,” said Thales. “We don’t want any trouble here. All is water, so all we did was steal a little bit of water from people. We can give you some water back, and everything will be even, right?” He gestured to a watering trough for horses on the side of the street, which was full of the stuff.</p><p>“Just so long as you don’t mind being sprayed with some very hard water from my squirt gun,” the old man answered, and the six-shooter was pointed at the Milesian now.</p><p>“Ha!” said Zeno of Elea. “You don’t scare us. In order to hit Thales, your bullet would have to get halfway to him, then half of the remaining distance, and so on. But that would require an infinite number of steps, therefore it is impossible.”</p><p>“Sorry,” said the old man, “I couldn’t hear you because it’s logically impossible for the sound waves encoding your speech to reach my ears.”</p><p>“We’re not even the same people as the guys who stole those cattle!” said Heraclitus. “Personal identity is an illusion!”</p><p>“Then you won’t mind coming to the courthouse with me,” replied the old man “to help the judge imprison some other people who look just like you.”</p><p>The last of them, the tall one, said nothing. He just raised his revolver in a fluid motion and shot at the old man.</p><p>The old man saw it coming and jumped out of the way. The air was briefly full of bullets. Bang! Thales went down! Bang bang! Heraclitus! Bang bang! Parmenides and Zeno. Bang bang bang! The old man was hit in the arm, but still standing. Bang bang bang bang…</p><p>It was just the old man and the tall one now. The tall one picked up his gun and fired. Nothing happened. Out of bullets.</p><p>The old man smiled wryly, his six-shooter still in his hand.</p><p>“I know what you’re thinking. You’re thinking – did he fire six shots, or only five? Well, you’ve got to ask yourself a question – do you feel lucky? Well, do you, punk?”</p><p>The tall one didn’t budge. “Man is the measure of all things,” said Protagoras. “If I believe you fired six shots, then by my personal epistemic standards, you fired six shots.”</p><p>The old man didn’t say anything.</p><p>“You see,” the Sophist continued. “Out of all of them, I alone was truly consistent. They all came up with clever theories, then abandoned them whenever it conflicted with their self-interest. I was more honest. I just said at the beginning that my self-interest determined truth, and so never suffered any temptation to depart from my position.”</p><p>The old man took off the bandana covering his face. “Man may be the measure of all things. But I’ve taken your measure, Protagoras, and found it wanting.”</p><p>“Socrates?!” the Sophist gasped.</p><p>“The only truly consistent people are the dead, Protagoras,” he said – and squeezed the trigger.</p></div></div></div></div>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  },
  {
    "_id": "HTGCGASf9xfB6edAh",
    "title": "The Case Of The Suffocating Woman",
    "slug": "the-case-of-the-suffocating-woman",
    "pageUrl": "https://www.lesswrong.com/posts/HTGCGASf9xfB6edAh/the-case-of-the-suffocating-woman",
    "postedAt": "2017-09-02T19:42:31.833Z",
    "baseScore": 20,
    "voteCount": 20,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><font size=\"1\"><i>[Content warning: panic, suffocation]</i></font></p>\n<p><b>I.</b></p>\n<p>I recently presented this case at a conference and I figured you guys might want to hear it too. Various details have been obfuscated or changed around to protect confidentiality of the people involved.</p>\n<p>A 20-something year old woman comes into the emergency room complaining that she can&#8217;t breathe. The emergency doctors note that she&#8217;s breathing perfectly normally. She says okay, fine, she&#8217;s breathing normally <i>now</i>, but she&#8217;s certain she&#8217;s about to suffocate. She&#8217;s having constant panic attacks, gasping for breath, feels like she can&#8217;t get any air into her lungs, been awake 96 hours straight because she&#8217;s afraid she&#8217;ll stop breathing in her sleep. She accepts voluntary admission to the psychiatric unit with a diagnosis of panic disorder.</p>\n<p>We take a full history in the psych ward and there&#8217;s not much of interest. She&#8217;s never had any psychiatric conditions in the past. She&#8217;s never used any psychiatric medication. She&#8217;s never had any serious diseases. One month ago, she gave birth to a healthy baby girl, and she&#8217;s been very busy with all the new baby-related issues, but she doesn&#8217;t think it&#8217;s stressed her out unreasonably much.</p>\n<p>We start her on an SSRI with (as usual) little immediate effect. On the ward, she continues to have panic attacks, which look like her gasping for breath and being utterly convinced that she is about to die; these last from a few minutes to a few hours. In between these she&#8217;s reasonable and cooperative but still very worried about her breathing. There are no other psychiatric symptoms. She isn&#8217;t delusional &#8211; when we tell her that our tests show her breathing is fine, she&#8217;s willing to admit we&#8217;re probably right &#8211; she just <i>feels</i> on a gut level like she can&#8217;t breathe. I&#8217;m still not really sure what&#8217;s going on.</p>\n<p>So at this point, I do what any good psychiatrist would: I Google &#8220;how do you treat a patient who thinks she&#8217;s suffocating?&#8221; And I stumble onto one of the first convincing explanations I&#8217;ve ever seen of the pathophysiology of a psychiatric disorder.</p>\n<p><b>II.</b></p>\n<p>Panic disorder is a DSM-approved psychiatric condition affecting about 3% of the population. It&#8217;s marked by &#8220;panic attacks&#8221;, short (minutes to hours) episodes where patients experience extreme terror, increased heart rate, gasping for breath, feeling of impending doom, choking, chest pain, faintness, et cetera. These episodes can happen either after a particular stressor (for example, a claustrophobic patient getting stuck in a small room) or randomly for no reason at all when everything is fine. In a few cases, they even happen when patients are asleep and they wake up halfway through. The attacks rise to the level of a full disorder when they interfere with daily life &#8211; for example, a patient can&#8217;t do her job because she&#8217;s afraid of having panic attacks while engaged in sensitive activities like driving.</p>\n<p>The standard model of panic disorder involves somatosensory feedback loops. Your body is always <A HREF=\"http://slatestarcodex.com/2017/03/06/book-review-behavior-the-control-of-perception/\">monitoring itself</A> to make sure that nothing&#8217;s wrong. Any major organ dysfunction is going to produce a variety of abnormalities &#8211; pain, blockage of normal activities like digestion and circulation, change in chemical composition of the blood, etc. If your body notices enough of these things, it&#8217;ll go into alarm mode and activate the stress response &#8211; increased heart rate, sweating, etc &#8211; to make sure you&#8217;re sufficiently concerned.</p>\n<p>In the feedback model of panic disorder, this response begins too early and recurses too heavily. So maybe you have an itch on your back. Your body notices this unusual sensation and falsely interprets it as the sort of abnormality that might indicate major dysfunction. It increases heart rate, starts sweating, et cetera. Then, because it&#8217;s stupid, it notices the increased heart rate and the sweating that it just caused, and decides this is <i>definitely</i> the sort of abnormality that indicates major dysfunction, and there&#8217;s nothing to do except activate even <i>more</i> stress response, which of course it interprets as even <i>more</i> organ dysfunction, and so on. At some point your body just maxes out on its stress response, your heart is beating as fast as it can possibly go and your brain is full of as many terror-related chemicals as you can produce on short notice, and then after a while of that it plateaus and returns to normal. So panic disorder sufferers are people who are overly prone to have the stress response, and overly prone to interpret their own stress response as further evidence of dysfunction. </p>\n<p>This is probably part genetic and part learned &#8211; I have a panic disorder patient who has a bunch of really bad allergies, whose body would shut down in horrifying ways every time he accidentally ate a crumb of the wrong thing, and this seems to have &#8220;sensitized&#8221; him into having panic attacks; that is, his body has learned that worrying sensations <i>often</i> foretell a health crisis, and lowered its threshold accordingly to the point where random noise can easily set it off. I&#8217;ve done a lot of work with this guy, but none of it has been &#8220;just ignore your panic attacks, you&#8217;ll be fine&#8221;. His body knows what it&#8217;s doing, and we&#8217;ve got to work from a position of respecting it while also teaching it not to be quite so overzealous.</p>\n<p>So this is where my understanding of panic disorder stood until I Googled &#8220;how do you treat a patient who thinks she&#8217;s suffocating?&#8221; and came across Donald Klein&#8217;s <A HREF=\"http://sci-hub.io/10.1001/archpsyc.1993.01820160076009\">theory of panic as false suffocation alarm</A>. You might want to read the full paper, as it&#8217;s got far too many fascinating things to list here, including a theory of sighing. But I&#8217;ll try to go over the basics.</p>\n<p>Klein is a professor of psychiatry who studies the delightful field of &#8220;experimental panicogens&#8221;, ie chemicals that cause panic attacks if you inject them in someone. These include lactate, bicarbonate, and carbon dioxide, all of which naturally occur in the body under conditions of decreased respiration.</p>\n<p>But this is actually confusing. All of these chemicals naturally occur in the body under conditions of decreased respiration. But they don&#8217;t cause panic attacks then. During exercise, for example, your body has much higher oxygen demand but (no matter how much you pant while running) only a little bit higher oxygen supply, so at the muscle level you don&#8217;t have enough oxygen and start forming lactate. But exercise doesn&#8217;t make people panic. Even deliberately holding your breath doesn&#8217;t make you panic, although it&#8217;s about the fastest way possible to increase levels of those chemicals. So it looks like your body is actively predicting how much lactate/bicarbonate/CO2 you <i>should</i> have, and only getting concerned if there&#8217;s more than it expects.</p>\n<p>So Klein theorized that the brain has a &#8220;suffocation alarm&#8221;, which does some pretty complicated calculations to determine whether you&#8217;re suffocating or not. Its inputs are anything from blood CO2 level to very high-level cognitions like noticing that you&#8217;re in space and your spacesuit just ruptured. If, after considering all of this, <i>and</i> taking into account confounding factors like whether you&#8217;re exercising or voluntarily holding your breath, it decides that you&#8217;re suffocating, it activates your body&#8217;s natural suffocation response.</p>\n<p>And the body&#8217;s natural suffocation response seems a lot like panic attacks. Increased heart rate? Check. Gasping for breath? Check. Feeling of impending doom? Check. Choking? Check. Chest pain? Check. Faintness? Check. Some of this makes more sense if you remember that the brain works on Bayesian process combining top-down and bottom-up information, so that your brain can predict that &#8220;suffocation implies choking&#8221; just as easily as &#8220;choking implies suffocation&#8221;. </p>\n<p>A quick digression into medieval French mythology. Once upon a time there was a nymph named Ondine whose lover was unfaithful to her, as so often happens in mythology and in France. She placed a very creative curse on him: she cursed him not to be able to breathe automatically. He freaked out and kept trying to remember to breathe in, now breathe out, now breathe in, now breathe out, but at some point he had to fall asleep, at which point he stopped breathing and died.</p>\n<p>So when people discovered a condition that limits the ability to breathe automatically, some very imaginative doctor named the condition <A HREF=\"https://en.wikipedia.org/wiki/Central_hypoventilation_syndrome\">Ondine&#8217;s Curse</A> (some much less imaginative doctors provided its alternate name, central hypoventilation syndrome). People with Ondine&#8217;s curse don&#8217;t <i>exactly</i> not breathe automatically. But if for some reason they stop breathing, they don&#8217;t notice. Needless to say, this condition is very, <i>very</i> fatal. The usual method of death is that somebody stops breathing at night (ie sleep apnea, very common among the ordinary population, but not immediately dangerous since your body notices the problem and makes you start breathing again) and just never starts again.</p>\n<p>Klein says that this proves the existence of the suffocation alarm: Ondine&#8217;s Curse is an underactive suffocation alarm &#8211; and thus the opposite of panic disorder, which is an overactive suffocation alarm. In Ondine&#8217;s Curse, patients don&#8217;t feel like they&#8217;re suffocating even when they are; in panic disorder, patients feel like they&#8217;re suffocating even when they&#8217;re not.</p>\n<p>This picture has since gotten some pretty powerful confirmation, like the discovery that panic disorder <A HREF=\"http://reliawire.com/shortness-breath-panic-attacks-tied-gene/\">is associated with</A> <i>ACCN2</i>, a gene involved in carbon dioxide detection in the amygdala. If you&#8217;re looking for something that causes you to panic when you&#8217;re suffocating, a carbon dioxide detector in the amygdala is a pretty impressive fit.</p>\n<p>I don&#8217;t think this is necessarily a replacement for the somatosensory feedback loop theory. I think it ties into it pretty nicely. The suffocation alarm is one of the many monitors watching the body and seeing whether something is dysfunctional, maybe the most important such monitor. It goes through some kind of Bayesian learning process to constantly have a prior probability of suffocation and update with incoming evidence. Let me give two examples.</p>\n<p>First, my patient with the bad allergies. Every time he eats the wrong thing, he goes into anaphylactic shock, which prevents respiration and brings him to the edge of suffocating. His suffocation alarm becomes sensitized to this condition, increases its prior probability of suffocation, and so drops its threshold so low that it can be set off by random noise.</p>\n<p>Second, claustrophobics. There&#8217;s a clear analogy between being crammed into a tiny space, and suffocating &#8211; think of people who are buried alive. For claustrophobics, for some reason that link is especially strong, and just being in an elevator is enough to set off their suffocation alarm and start a panic attack. Now, why <i>agoraphobics</i> get panic attacks I&#8217;m not sure. Maybe fear makes them feel woozy and hyperventilate, and the suffocation alarm treats wooziness and hyperventilation as signs of suffocation and then gets stuck in a feedback loop? I don&#8217;t know.</p>\n<p><b>III.</b></p>\n<p><A HREF=\"https://www.ncbi.nlm.nih.gov/pubmed/16529913\">Bandelow et al</A> find that you&#8217;re about a hundred times more likely to develop a new case of panic disorder during the postpartum period than usual.</p>\n<p>This can be contrasted with two equally marked trends. Panic attacks decrease markedly during pregnancy, and disappear entirely during childbirth. This last is really remarkable. People get panic attacks at any conceivable time. When they&#8217;re driving, when they&#8217;re walking, when they&#8217;re tired, when they&#8217;re asleep. Just not, apparently, when they&#8217;re giving birth. Childbirth is one of the scariest things you can imagine, your body&#8217;s getting all sorts of painful sensations it&#8217;s never felt before, and it&#8217;s a very dangerous period in terms of increased mortality risk. But in terms of panic attack, it&#8217;s one of the rare times when you are truly and completely protected.</p>\n<p><A HREF=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3952302/\">Maternal And Fetal Acid-Base Chemistry: A Major Determinant Of Perinatal Outcomes</A> notes that:</p>\n<blockquote><p>There is a substantial reduction in the partial pressure of carbon dioxide in pregnancy&#8230;this fall is found to reach a mean level of 30-32 mmHg and is associated with a 21% increase in oxygen uptake. The physiological hyperventilation of pregnancy is due to the hormonal effect of progesterone on the respiratory center.</p></blockquote>\n<p> In other words, you&#8217;re breathing more, you have more blood oxygen, you have less blood CO2, and you&#8217;re further away from suffocation. This nicely matches the observation that there&#8217;s fewer panic attacks.</p>\n<p><A HREF=\"http://onlinelibrary.wiley.com/doi/10.1002/anxi.3070010507/full\">According to</A> Klein, &#8220;There is a period of extreme hyperventilation during delivery, which drops the blood carbon dioxide to the minimum recorded under nonpathological conditions&#8221;. This explains the extreme protective effect of labor against panic disorder, despite labor&#8217;s seeming panic-inducing properties. When your CO2 is that low, even an oversensitive suffocation alarm is very far from a position where it might be set off.</p>\n<p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/progesterone.gif\"></p>\n<p>(<A HREF=\"http://www.natural-hormones.net/progesterone-causes-high-levels.htm\">source</A>)</center></p>\n<p>Then you give birth, and progesterone &#8211; the hormone that was increasing respiratory drive &#8211; falls off a cliff. Your body, which for nine months has been doing very nicely with far more oxygen than it could ever need, suddenly finds itself breathing much less than usual and having a normal CO2/oxygen balance. This explains the hundredfold increased risk of developing panic disorder! Somebody who&#8217;s previously never had any reason to think they&#8217;re suffocating finds themselves with much less air than they expect (though still the physiologically correct amount of air they need), and if they&#8217;ve got any sensitivity at all, their suffocation alarm interprets this as possible suffocation and freaks out.</p>\n<p>This can go one of two directions: either it eventually fully readjusts to your new position and becomes comfortable with a merely normal level of oxygen. Or the constant panic and suffocation feelings sensitize it &#8211; the same way that my allergy patient&#8217;s constant anaphylaxis sensitized him &#8211; the alarm develops a higher prior on suffocation and a lower threshold, and the patient gets a chronic panic disorder.</p>\n<p>The reason my patient was so interesting was that she was kind of in the middle of this process and had what must have been unusually good introspective ability. Instead of saying &#8220;I feel panic&#8221;, she said &#8220;I feel like I&#8217;m suffocating&#8221;. This is pretty interesting. It&#8217;s like a heart attack patient coming in, and instead of saying &#8220;I feel chest pain&#8221;, they say &#8220;I feel like I have a thrombus in my left coronary artery&#8221;. You&#8217;re like &#8220;Huh, good job&#8221;.</p>\n<p>So I explained all of this to her, and since she didn&#8217;t know I used Google I probably looked very smart. I told her that she wasn&#8217;t suffocating, that this was a natural albeit unusual side effect of childbirth, and that with luck it would go away soon. I told her if it didn&#8217;t go away soon then she might develop panic disorder, which was unfortunate, but that there were lots of good therapies for panic disorder which she would be able to try. This calmed her down a lot and we were able to send her home with some benzodiazepines for acute exacerbation and some SSRIs which she would stay on for a while to see if they helped. She&#8217;s scheduled to see an outpatient psychiatrist for followup and hopefully he will monitor her panic attacks to see if they eventually get better.</p>\n<p><b>IV.</b></p>\n<p>I realize that case reports are usually supposed to include a part where the doctor does something interesting and heroic and tries an experimental new medication that saves the day. And I realize there wasn&#8217;t much of that here. But I think that in psychiatry, a good explanation can sometimes be half the battle.</p>\n<p>Consider <A HREF=\"https://en.wikipedia.org/wiki/Two-factor_theory_of_emotion#Empirical_support\">Schachter and Singer (1962)</A>. They injected patients with adrenaline (a drug which among other things makes people physiologically agitated) or a placebo. Half the patients were told that the drug would make them agitated. The other half were told it was just some test drug to improve their eyesight. Then a confederate came and did some annoying stuff, and they monitored how angry the patients got. The patients who knew that the drug was supposed to make them angry got less angry than the ones who didn&#8217;t. The researchers theorized that both groups experienced physiological changes related to anger, but the patients who knew it was because of the drug sort of mentally adjusted for them, and the ones who didn&#8217;t took them seriously and interpreted them as their own emotion.</p>\n<p>We can think of this as the brain making a statistical calculation to try to figure out its own level of anger. It has a certain prior. It gets certain evidence, like the body&#8217;s physiological state and how annoying the confederate is being. And it controls for certain confounders, like being injected with an arousal-inducing drug. Eventually it makes its best guess, and that&#8217;s how angry you feel.</p>\n<p>In the same way, the suffocation monitor is taking all of its evidence about suffocation &#8211; from very low-level stuff like how much CO2 is in the blood to very high-level stuff like what situation you seem to be in &#8211; and then adjusting for confounders like whether you&#8217;re exercising. And I wonder whether telling a patient &#8220;You&#8217;re not actually suffocating, your panic comes from a known physiologic process and here are the hormones that control it&#8221; is the equivalent of telling them &#8220;You&#8217;re not really angry, your agitation comes from us giving you a drug that&#8217;s known to produce agitation&#8221;. It tells the suffocation alarm computer that this is a confounder to be controlled for rather than evidence on which to update.</p>\n<p>I can&#8217;t claim to really understand this at a level where it makes sense to me. There are a lot of things that very directly increase CO2 but don&#8217;t increase panic, or vice versa. Hyperventilation can either cause or prevent panic depending on the situation. There seems to be something going on where the suffocation monitor controls for some things but not others, but this is an obvious cop-out that allows me to avoid making real predictions or narrowing hypothesis-space. </p>\n<p>For example, this theory would seem to predict that waterboarding shouldn&#8217;t work. After all, its whole deal is artificially inducing the feeling of suffocation in a situation where the victim presumably knows that the interrogators aren&#8217;t going to let him suffocate. You would think that eventually the alarm realizes that &#8220;is being waterboarded&#8221; is a confounder to control for, but this doesn&#8217;t seem to be true.</p>\n<p>(on the other hand, the <A HREF=\"http://slatestarcodex.com/2013/05/19/can-you-condition-yourself/\">inability to condition yourself</A> seems relevant here. It seems like the brain might be not be controlling for whether something is reasonable, but only for whether something is <i>produced by yourself</i>. So maybe exercise counts because it&#8217;s under your control, but waterboarding doesn&#8217;t count because it isn&#8217;t. I wonder if anyone has ever tried letting someone waterboard themselves and giving them the on-off switch for the waterboarding device. Was <A HREF=\"http://www.vanityfair.com/news/2008/08/hitchens200808\">Hitchens&#8217; experience</A> close enough to this to count? Why would this be different from letting someone hold their breath, which doesn&#8217;t produce the same level of panic?)</p>\n<p>But overall I find Klein&#8217;s evidence pretty convincing and feel like this must be at least part of the story. And I think that giving this kind of explanation to somebody can comfort them, reassure them, and (maybe) even improve their condition.</p>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  },
  {
    "_id": "38CNR4QuZEkkn8stH",
    "title": "Exploring Premium Mediocrity",
    "slug": "exploring-premium-mediocrity",
    "pageUrl": "https://www.lesswrong.com/posts/38CNR4QuZEkkn8stH/exploring-premium-mediocrity",
    "postedAt": "2017-09-02T19:20:21.000Z",
    "baseScore": -1,
    "voteCount": 1,
    "commentCount": 0,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p>Epistemic Status: Mediocre Premium</p>\n<p>Response To (Rao / Ribbonfarm) : <a href=\"https://www.ribbonfarm.com/2017/08/17/the-premium-mediocre-life-of-maya-millennial/\">The Premium Mediocre Life of Maya Millenial</a></p>\n<p>Builds Upon (not required): <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">Play in Easy Mode</a>, <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">Play in Hard Mode</a></p>\n<p>Leads To: <a href=\"https://thezvi.wordpress.com/2017/09/05/expanding-premium-mediocrity/\">Expanding Premium Mediocrity</a></p>\n<p>Good Other Commentary (Jacob / Put a Num On It): <a href=\"https://putanumonit.com/2017/08/26/premium-mediocre/\">Escaping the Premium Mediocre</a></p>\n<p>I</p>\n<p>A few days ago I read this very good sentence by Venkatesh Rao:</p>\n<blockquote><p>Premium mediocre is the finest bottle of wine at Olive Garden.</p></blockquote>\n<p>Exactly, my brain thought. <a href=\"https://www.youtube.com/watch?v=AGrvQ1c5khU\">Say no more</a>! Long have I waited for a name to put to this concept! Somewhere Plato was smiling.</p>\n<p>Then Rao continued, and I wondered if <a href=\"https://www.youtube.com/watch?v=v-xrnIXQ3iQ\">he was pondering something different than what I was pondering:</a></p>\n<blockquote><p>Premium mediocre is cupcakes and froyo. Premium mediocre is “truffle” oil on anything (no actual truffles are harmed in the making of “truffle” oil), and extra-leg-room seats in Economy. Premium mediocre is cruise ships, artisan pizza, <i>Game of Thrones</i>, and The Bellagio.</p></blockquote>\n<p><a href=\"http://www.ign.com/videos/2017/01/19/the-good-place-season-1-finale-sexy-things\">As Elanor of The Good Place observed when given a list of supposedly sexy things</a>, well, some of those are right. In particular, froyo, &#8220;truffle&#8221; oil, extra-leg-room seats in Economy and cruise ships are clearly right. Artisan pizza at first struck me as wrong but now strikes me as right, because the ones that are wrong don&#8217;t call themselves &#8216;artisan.&#8217; Cupcakes are Actually Good, but kind of by coincidence, which is a strange gray area. Then there were two clear errors: The Bellagio is a terrible example given the casino options, and <em>Game of Thrones</em>, which is both Actually Good and outside the pattern entirely (or rather, it wasn&#8217;t until some point in the past two seasons, which is a clue).</p>\n<p>Something was amiss.</p>\n<p><span id=\"more-11231\"></span></p>\n<p>Then he came back with a sentence that, while not quite as high Quality as the first, sums it all up perfectly:</p>\n<blockquote><p>Premium mediocre is food that Instagrams better than it tastes.</p></blockquote>\n<p>More examples follow:</p>\n<blockquote>\n<p class=\"p1\">Premium mediocre is Starbucks’ Italian names for drink sizes, and its original pumpkin spice lattes featuring a staggering absence of pumpkin in the preparation. Actually all the coffee at Starbucks is premium mediocre. I like it anyway.</p>\n<p class=\"p1\">Premium mediocre is Cost Plus World Market, one of my favorite stores, purveyor of fine imported potato chips in weird flavors and interesting cheap candy from convenience stores around the world.</p>\n<p>The best banana, any piece of dragon fruit, fancy lettuce, <a href=\"https://www.nytimes.com/2017/07/11/opinion/how-we-are-ruining-america.html?mcubz=3&amp;_r=0\">David Brooks’ idea of a gourmet sandwich</a>.</p>\n<p>Premium mediocre, premium mediocre, premium mediocre, premium mediocre.</p></blockquote>\n<p>Heavy on the food examples, but quite good! I suspect he&#8217;s wrong about the best banana and quite possibly dragon fruit, but I&#8217;m unable to eat either without physically gagging, so I don&#8217;t have enough information to tell.</p>\n<p>A more focused attempt at a definition is then offered:</p>\n<blockquote><p>Mediocre with <em>just </em>an irrelevant touch of premium, not enough to ruin the delicious essential mediocrity.</p></blockquote>\n<p>This isn&#8217;t quite right, but it&#8217;s close. Then the two of us completely disagreed and I knew we were going in different directions:</p>\n<blockquote><p>Yes, ribbonfarm is totally premium mediocre. We are a cut above the new media mediocrityfests that are <em>Vox </em>and <em>Buzzfeed, </em>and we eschew low-class memeing and listicles. But face it: actually enlightened elite blog readers read Tyler Cowen and Slatestarcodex.</p></blockquote>\n<p>I do read Tyler Cowen and Slatestarcodex (and only selectively read ribbonfarm)! I still call out this false humility, for it reflects a deep error on the part of Rao. Ribbonfarm does not fit the above example set <em>at all. </em>Or if it is, that fact is why it can&#8217;t take its place in that top tier. Ribbonfarm is doing an original, valuable thing with its own internal logic, for the joy of exploring concepts wherever they lead. That should be the <em>opposite </em>of the list being created above.</p>\n<p>I will post the rest of the example list now:</p>\n<blockquote>\n<p class=\"p1\">Premium mediocre is international. My buddy <a href=\"https://twitter.com/visakanv\">Visakan Veerasamy</a> (a name Indian-origin people will recognize as a fantastic premium mediocre name, suitable for a Tamil movie star, unlike mine which is merely mediocre, and suitable for a side character) reports that Singaporeans can enjoy the fine premium mediocre experience of the McDonald’s Signature Collection.</p>\n<p class=\"p1\">Anything branded as “signature” is premium mediocre of course.</p>\n<p class=\"p1\">Much of <a href=\"http://amzn.to/2vYYTsD\">the manufactured cool of K-Pop</a> (though not the subtly subversive <em>Gangnam Style, </em>whose sly commentary on Korean life takes some digging for non-Koreans to grok) is premium mediocre. <a href=\"https://www.ribbonfarm.com/author/carlos/\">Carlos Bueno</a> argues that Johnny Walker Black is premium mediocre in the Caribbean. In Bollywood, the movies of Karan Johar are premium mediocre portrayals of premium mediocre modern urban Indian life.</p>\n<p>The entire <em>idea </em>of the country that is France is kinda premium mediocre (K-Pop is a big hit there, not coincidentally). The fact that Americans equate “French” with “classy” is proof of its premium mediocrity (Switzerland is the actually elite European country).</p>\n<p class=\"p1\">At its broad, fuzzy edges, premium mediocre is an expansive concept; a global, cosmopolitan <em>and </em>nationalist cultural Big Tent: it is arguably both suburban <em>and </em>neourban, Red <em>and</em> Blue, containing Boomers <em>and</em> X’ers. It includes bluetooth headsets favored by Red State farmers and the tiki torches — designed for premium mediocre backyard barbecues — favored by your friendly neighborhood Nazis. It includes everything Trump-branded. It covers McMansions, insecure suburbia-dwelling <a href=\"http://www.nbc.com/saturday-night-live/video/dysfunctional-family-dinner/n11072?snl=1\">Dodge Stratus owners</a> and Bed, Bath, and Beyond shoppers. It includes gentrifying neighborhoods and ghost-town malls. It includes Netflix and chill<em>.</em> It includes<i> </i>Blue Apron meals.</p>\n<p>At some level, civilization itself is at a transitional premium mediocre state somewhere between industrial modernity in a shitty end-of-life phase, and digital post-scarcity in a shitty early-beta phase.  Premium mediocrity is a stand-in for the <em>classy </em>kind of post-scarcity digital utopia some of us like to pretend is already here, only unevenly distributed. The kind where <a href=\"https://en.wikipedia.org/wiki/The_Invention_of_Lying\">everybody gets a mansion</a>, is a millionaire, and drives a Tesla.</p></blockquote>\n<p>After that point, Rao goes on to associate the concept with an entire generation and lifestyle, and wraps it up in a classic Rao-style theory that asks the question &#8216;what if the whole world, or at least some people&#8217;s worlds, revolved around this idea?&#8217;</p>\n<p>His answer is ambitious, far-wielding, interesting in its own right and further proof of his own lack of premium mediocrity.</p>\n<p>I&#8217;ll get to that.</p>\n<p>First, we need to break down the <em>small </em>definition. The one that&#8217;s about small things, that explains what the above list has in common.</p>\n<p>II</p>\n<p>Definition:</p>\n<p>Something is Premium Mediocre if and only if it is primarily optimized* to superficially appear to be, or sound like it is, to at least some people, the convenient or premium** version of a thing.</p>\n<p>*: The extreme cases are where it is <em>solely </em>optimized in this way; you get premium mediocrity to the extent that this is being optimized for. I think using primarily here is the right compromise.</p>\n<p>**: You can also appear to be any of superior, high-class, glamorous, fancy, etc, but I think simply saying premium here is sufficient. Convenient is an interesting case but seems intuitively right to me.</p>\n<p>Alternate Definition:</p>\n<p>Premium Mediocre is the set of things <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">created in easy mode</a>.</p>\n<p>As Rao says, <em>premium mediocre is intentional. </em><a href=\"https://thezvi.wordpress.com/2015/06/30/the-thing-and-the-symbolic-representation-of-the-thing/\">It is about aiming for the symbolic representation of the (higher-level version of the) thing, rather than the thing.</a></p>\n<p>You can <em>tell yourself </em>that you&#8217;re not doing that. Doesn&#8217;t matter. It is <em>impossible </em>to accidentally create something in this class. <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-easy-mode/\">You chose to do that</a>.</p>\n<p>You can also <em>tell yourself </em>that you&#8217;re creating something premium mediocre, and even <em>explicitly claim </em>to be premium mediocre, <a href=\"https://thezvi.wordpress.com/2017/08/26/play-in-hard-mode/\">and be wrong because you are actually optimizing for a real thing</a>. This describes Rao. Rao does authentic things, but is surrounded by a world that is <a href=\"https://thezvi.wordpress.com/2015/05/15/in-a-world-of-venture-capital/\">so lost in a meta-signaling trap</a> that he is terrified of anyone finding that out, so he disavows it every chance he gets, even to himself.</p>\n<p>To go Full Rao (<a href=\"https://www.youtube.com/watch?v=X6WHBO_Qc-Q\">Never go full Rao</a>? <a href=\"https://www.ribbonfarm.com/the-gervais-principle/\">Always go full Rao</a>? Hard to say) the 2&#215;2 would have the X-axis be Actual Easy Mode vs. Actual Hard Mode and the Y-axis be Self-Identified Easy Mode vs. Self-Identified Hard Mode.</p>\n<p><img data-attachment-id=\"11420\" data-permalink=\"https://thezvi.wordpress.com/2017/09/02/exploring-premium-mediocrity/rao/\" data-orig-file=\"https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=640\" data-orig-size=\"696,612\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"Rao\" data-image-description=\"\" data-medium-file=\"https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=640?w=300\" data-large-file=\"https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=640?w=640\" class=\"alignnone size-full wp-image-11420\" src=\"https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=640\" alt=\"Rao\" srcset=\"https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=640 640w, https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=150 150w, https://thezvi.files.wordpress.com/2017/09/rao.jpg?w=300 300w, https://thezvi.files.wordpress.com/2017/09/rao.jpg 696w\" sizes=\"(max-width: 640px) 100vw, 640px\"   /></p>\n<p>Figure 1: Easy and Hard Modes, 2&#215;2</p>\n<p>(Easy, Easy) is Sociopath. They know what they want and they get it. They don&#8217;t care about anything else.</p>\n<p>(Easy, Hard) is Clueless. They enforce the rules of the system, thinking they are fighting for something that matters, but instead are being tricked, either the tools of others or fighting for <a href=\"http://lesswrong.com/lw/le/lost_purposes/\">lost purposes</a>.</p>\n<p>(Hard, Hard) is Loser. They care about things that matter to them, even if that means they&#8217;ll work harder for less. They know the game and choose not to play.</p>\n<p>(Hard, Easy) is Hero. The Hero thinks they are in Easy Mode, but their Easy Mode goal is to actually accomplish or create the thing. The Hero focuses on <a href=\"http://lesswrong.com/lw/7i/rationality_is_systematized_winning/\">cutting the enemy</a>. The Hero doesn&#8217;t think they&#8217;re a hero. The hero often doesn&#8217;t even want to be a hero. The hero simply wants something you can&#8217;t cheat on.</p>\n<p>It isn&#8217;t a choice. The hero is a hero <em>despite themselves.</em></p>\n<p>Rao is a hero. He would be the first to say, he isn&#8217;t one, and also, don&#8217;t be one. Doesn&#8217;t matter. He is one anyway.</p>\n<p>Meanwhile, as corporations create more and more of the things, and/or those things are built to hit explicit optimization targets, those things are built or &#8216;improved&#8217; by Sociopaths directing the Clueless. Which all means, of course, Premium Mediocre.</p>\n<p>III</p>\n<p>How does this relate to things that are Actually Good?</p>\n<p>It is common for Premium Mediocre things to in some aspect be Actually Good. The catch is that they are, whether in terms of money, time, or something else, <em>expensive. </em>Often, the easy path to making something superficially premium is to make the thing actually premium! You can then get the delicious high-grade mediocrity you crave, but you pay for it.</p>\n<p>As Rao points out, Cupcakes are Actually Good. I love me a cupcake, but they are still Premium Mediocre, whereas cake brings you even more Actually Good at a fraction of the price.</p>\n<p>He also claims Avocado Toast is Actually Good, which it might well be. I&#8217;ve never had it. What I know for sure is that it is shockingly expensive for a vegetable on a piece of toast.</p>\n<p>Same thing with Starbucks Coffee. I don&#8217;t drink coffee, but by all accounts it&#8217;s good &#8211; it&#8217;s just shockingly expensive for what it is. I&#8217;ve had their hot chocolate, which is both good and shockingly expensive.</p>\n<p>The finest wine at Olive Garden is premium mediocrity on top of premium mediocrity, so it&#8217;s going to be <em>super </em>expensive for what it is, but it&#8217;s still <em>probably </em>better than the median wine at Olive Garden.</p>\n<p>This is my resolution of what Rao calls the Avocado Toast Paradox. This is not premium mediocrity deciding to occasionally treat itself, it is simply that Goodhart&#8217;s Law is not perfect.</p>\n<p>What premium mediocre cannot be, is Perfectly Good or Really Good. And it certainly can&#8217;t be Insanely Great.</p>\n<p>Things which are superficially flawed, but which do their functional job just fine thank you, are Perfectly Good. Perfectly Good things satisfice on functionality and entirely ignore superficiality. <a href=\"http://failblog.cheezburger.com/thereifixedit\">There, I Fixed It</a> is their official website and slogan.</p>\n<p>If something is either Actually Good or Perfectly Good, and that is surprising, then it is Not That Bad.</p>\n<p>An easy way to end up with a premium mediocre product is to discard the Perfectly Good. We throw out Perfectly Good tomatoes because they don&#8217;t have the right shape. This results in premium mediocre produce. We throw out a Perfectly Good old and comfortable sofa, rather than patch it with duck tape. Instead we buy one from premium mediocre IKEA.</p>\n<p>My parents would not have dreamt of throwing out something that was Perfectly Good.</p>\n<p>Some products and experiences are the best versions of themselves. Given the restraints of their format and budget, they exceeded all your expectations. These are not merely Actually Good, they are Really Good. There&#8217;s nothing wrong with the Actually Good, but the Really Good will brighten up your day. You go out of your way for the Really Good.</p>\n<p>If something spares no expense, with full attention to every detail, and still blows you away despite that, it is Insanely Great. Insanely Great changes your life.</p>\n<p>Things that are some combination of Really Good and Insanely Great are The Real Thing.</p>\n<p><img data-attachment-id=\"11517\" data-permalink=\"https://thezvi.wordpress.com/2017/09/02/exploring-premium-mediocrity/2x2-good-things/\" data-orig-file=\"https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=640\" data-orig-size=\"1001,809\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"2&#215;2 Good Things\" data-image-description=\"\" data-medium-file=\"https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=640?w=300\" data-large-file=\"https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=640?w=640\" class=\"alignnone size-full wp-image-11517\" src=\"https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=640\" alt=\"2x2 Good Things\" srcset=\"https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=640 640w, https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=150 150w, https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=300 300w, https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg?w=768 768w, https://thezvi.files.wordpress.com/2017/09/2x2-good-things.jpg 1001w\" sizes=\"(max-width: 640px) 100vw, 640px\"   /></p>\n<p>Figure 2: Good Things, 2&#215;2</p>\n<p>Can&#8217;t beat The Real Thing!</p>\n<p>Note: Extending this to the left from Not That Bad gets us to That Bad, also known as Not Great, Bob. Paired with Looks Bad we get No Good, and paired with Looks Good we get what some would call Superficially Good but which I prefer to call Not Good. Subtle but important differences.</p>\n<p>IV</p>\n<p>A while back, I wrote a <a href=\"https://thezvi.wordpress.com/2017/03/05/restaurant-guide-1-restaurants-should-not-look-like-most-restaurants/\">Restaurant Guide</a>. This shares the best tools I have found for differentiating whether you&#8217;re dealing with The Real Thing and getting the highest quality experience and value for your dollar. Some of the tools are things like seeing what percentage of customers have their dishes, which is an impossible-to-fake measure of how fast service is.</p>\n<p>Most, however, are about the signals the restaurants are choosing to send, because restaurants tell you who they are. Who are they claiming to be? If a place is The Real Thing, every subtle action they take will inform you of this fact. As Rao points out, the premium mediocre tells you what it is. A lot of my tactics are about identifying and thus avoiding the premium mediocre. Even when it is Actually Good, you&#8217;re still overpaying, so you can do better.</p>\n<p>Premium mediocre can be a reasonable fallback, but you should almost always be sad about it.</p>\n<p>That raises the question at the heart of the rest of Rao&#8217;s post. Why would one choose to live premium mediocre? Why would one <em>self-identify </em>that way?</p>\n<p>Certainly it is fine to indulge in occasional premium mediocrity. If you like Starbucks Coffee, it can be better to pay $4 for that than go without good coffee. You would want to know about good $2 coffee around the corner, but it might not be there. It might be there but you might not know about or trust it.</p>\n<p>Suppose equally good $2 coffee is there. Suppose you know it&#8217;s there. <em>What the hell are you doing in line at Starbucks?</em></p>\n<p>Good question. My plan is to address that in part two.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br />  <a rel=\"nofollow\" href=\"http://feeds.wordpress.com/1.0/gocomments/thezvi.wordpress.com/11231/\"><img alt=\"\" border=\"0\" src=\"http://feeds.wordpress.com/1.0/comments/thezvi.wordpress.com/11231/\" /></a> <img alt=\"\" border=\"0\" src=\"https://pixel.wp.com/b.gif?host=thezvi.wordpress.com&#038;blog=21007166&#038;post=11231&#038;subd=thezvi&#038;ref=&#038;feed=1\" width=\"1\" height=\"1\" />",
    "user": {
      "username": "Zvi",
      "slug": "zvi",
      "displayName": "Zvi"
    }
  },
  {
    "_id": "ERPL3v2Y976W7XG3j",
    "title": "Learning To Love Scientific Consensus",
    "slug": "learning-to-love-scientific-consensus",
    "pageUrl": "https://www.lesswrong.com/posts/ERPL3v2Y976W7XG3j/learning-to-love-scientific-consensus",
    "postedAt": "2017-09-02T08:44:12.184Z",
    "baseScore": 33,
    "voteCount": 30,
    "commentCount": 1,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><font size=\"1\"><i>[<b>Related to:</b> <A HREF=\"http://slatestarcodex.com/2015/08/09/contrarians-crackpots-and-consensus/\">Contrarians, Crackpots, and Consensus</A>, <A HREF=\"http://slatestarcodex.com/2014/07/02/how-common-are-science-failures/\">How Common Are Science Failures?</A>. Epistemic status is &#8220;subtle and likely to be misinterpreted&#8221;.]</i></font></p>\n<p><b>I.</b></p>\n<p>There&#8217;s a <A HREF=\"http://amasci.com/weird/vindac.html#j42\">list of scientific mavericks who were ridiculed by hidebound reactionaries but later vindicated</A> that&#8217;s been going viral. I examined the first ten mavericks on the list to see if its claims held up. Overall I wasn&#8217;t too impressed. Let me go over them in more detail.</p>\n<p>SVANTE ARRHENIUS:</p>\n<blockquote><p>His idea that electrolytes are full of charged atoms was considered crazy. The atomic theory was new at the time, and everyone &#8220;knew&#8221; that atoms were indivisible (and hence they could not lose or gain any electric charge.) Because of his heretical idea, he only received his university degree by a very narrow margin.</p></blockquote>\n<p>Sure, the professors who were judging his PhD thesis weren&#8217;t too convinced. So Arrhenius sent his proposal to the world&#8217;s top chemists at the time, and they were super-interested and started fighting among themselves to work with Arrhenius on it. Top chemist Wilhelm Ostwald received the paper the same day his daughter was born, and suggested that the paper was the more exciting of the two events. He journeyed to Arrhenius&#8217; hometown of Uppsala, Sweden to try to convince Arrhenius to work with him; Arrhenius refused for personal reasons but later got a scholarship and worked with the top physicists in Europe. Arrhenius became a professor in a prestigious university about ten years after presenting his &#8220;ridiculed&#8221; paper, and won the Nobel Prize ten years after that.</p>\n<p>HANS ALFVEN:</p>\n<blockquote><p>Astronomers thought that gravity alone is important in solar systems, in galaxies, etc. Alfven&#8217;s idea that plasma physics is of equal or greater importance to gravity was derided for decades.</p></blockquote>\n<p>This isn&#8217;t a great description of Alfven&#8217;s conflict with the establishment, but the list seems basically right insofar as Alfven&#8217;s ideas were ignored for thirty years before being proven mostly correct. I will give them this one.</p>\n<p>JOHN BAIRD:</p>\n<blockquote><p>When the first television system was demonstrated to the Royal Society (British scientists,) they scoffed and ridiculed, calling Baird a swindler.</p></blockquote>\n<p>I can&#8217;t find any reference to this in various Baird articles and biographies. The closest I can come is <A HREF=\"http://www.bbc.com/news/uk-england-oxfordshire-38080275\">this article</A> by someone who was there at the demonstration, who said &#8220;They didn&#8217;t believe it&#8230;the pictures were a bit of a blur but it was amazing, they were all absolutely flabbergasted by it.&#8221; It looks like he is using &#8220;they didn&#8217;t believe it&#8221; in the colloquial way of &#8220;they thought it was amazing&#8221;. A <A HREF=\"http://time.com/4192788/john-logie-baird-tv-demonstration-photo/\">TIME magazine</A> article from the time described the same scientists as &#8220;deeply impressed&#8221;, though the wording is kind of unclear and they might have been referring to a different demonstration a year later.</p>\n<p>In any case, it seems very clear that within a year everyone agreed he was legitimate and overcame their initial shock.</p>\n<p>ROBERT BAKKER:</p>\n<blockquote><p>Everyone knows that dinosaurs are like Gila monsters or big tortoises: large, slow, and intolerant of the cold. And they&#8217;re all colored olive drab too! 🙂 </p></blockquote>\n<p>Bakker did help produce the paradigm shift in paleontology from cold-blooded dinosaurs to warm-blooded dinosaurs. But he was not a lone maverick being ridiculed by everyone else. He learned that dinosaurs were warm-blooded from his professor at Yale, who was <i>also</i> part of the minority-but-totally-existing faction that believed dinosaurs were warm-blooded. He himself got a PhD at Harvard from professors who were apparently sympathetic to the same theory. And within seven years of his first paper being published, Scientific American was calling his ideas <A HREF=\"https://en.wikipedia.org/wiki/Dinosaur_renaissance\">&#8220;the dinosaur renaissance&#8221;</A>, which doesn&#8217;t leave a lot of time for him to be ridiculed and ignored in.</p>\n<p>BARDEEN &#038; BRATTAIN:</p>\n<blockquote><p>Not ridiculed, but their boss W. Shockley nixed their idea for a non-FET &#8220;crystal triode&#8221; device. When they started investigating it, he made them stop. They were supposed to be working on FETs instead.</p>\n<p>ARG, I GOT THIS WRONG, THIS PART BELOW IS A BELL LABS STORY REGARDING ZONE REFINING OF SILICON, NOT THE BJT TRANSISTOR PROJECT: So, they assembled their ZONE REFINING experiment on a wheeled cart and continued. Whenever the boss was scheduled to check up on them, they could shove it into an adjacent unused lab. </p></blockquote>\n<p>Okay, it looks like the guy compiling the list admits he was wrong on this one. Moving on&#8230;</p>\n<p>BRETZ:</p>\n<blockquote><p>Endured decades of scorn as the laughingstock of the geology world. His crime was to insist that enormous amounts of evidence showed that, in Eastern Washington state, the &#8220;scabland&#8221; desert landscape had endured an ancient catastrophy: a flood of staggering proportions. This was outright heresy, since the geology community of the time had dogmatic belief in a &#8220;uniformitarian&#8221; position, where all changes must take place slowly and incrementally over vast time scales. Bretz&#8217; ideas were entirely vindicated by the 1950s. Quote: &#8220;All my enemies are dead, so I have no one to gloat over.&#8221;</p></blockquote>\n<p>This one is basically right and I&#8217;ll give it to them.</p>\n<p>CHANDRASEKHAR:</p>\n<blockquote><p>Chandra originated Black Hole theory and published several papers. He was attacked viciously by his close colleague Sir Arthur Eddington, and his theory was discredited in the eyes of the research community. They were wrong, and Eddington apparently took such strong action based on an incorrect pet theory of his own. In the end  Chandra could not even pursue a career in England, and he moved his research to the U. of Chicago in 1937, laboring in relative obscurity for decades.</p></blockquote>\n<p>Sort of true, but he was hardly shunned by the scientific community. He made his discoveries about black holes in the early 1930s, was well-received by many people, and won a Bronze Medal in some physics competition. In 1935, Eddington attacked his theory, possibly because Eddington was racist and didn&#8217;t like Indian people. But many other scientists, including Niels Bohr and Wolfgang Pauli, continued to support him (quietly, so as not to offend Eddington, which will be a recurring theme in these kinds of situations). Chandrasekhar was made a Fellow of the Royal Society in 1944, won the Royal Astronomical Society Gold Medal in 1953, and generally led a long and prestigious life. His theories were resurrected once people had better evidence that black holes existed. I&#8217;ll give this one half a point.</p>\n<p>CHLADNI:</p>\n<blockquote><p>The scientific community regarded Meteorites in the same way that modern scientists regard UFO abductions and psychic phenomenon: quaint superstitions only believed by peasant folk. All the eyewitness reports were disbelieved. At one point the ridicule became so intense that many museums with meteorites in their geology collections decided to trash those valuable samples. (Sometimes hostile skepticism controls reality, and the strongest evidence is edited to conform to concensus disbeliefs.) Finally in the early 1800&#8217;s Ernst Chladni actually sat down and inspected the evidence professionally, and found that claimed meteorites were entirely unlike known earth rocks. His study changed some minds. At the same time some large meteor falls were witnessed by scientists, and the majority who insisted that only ignorant peasants ever saw such things were shamed into silence.</p></blockquote>\n<p>As the quote points out, this is a kind of weird one as meteorite work was ridiculed for a long time, but Chladni was taken seriously and helped change minds. Looking at Wikipedia, a lucky meteorite fall two years after Chladni first published his theory helped turn the tide in his favor, and by ten years after publication Chladni&#8217;s meteorite theories were pretty well-regarded. Even when people disagreed with him about meteorites, Chladni remained widely respected for some of his other work in acoustics.</p>\n<p>There <i>is</i> a story here, but it&#8217;s probably not right to center it around Chladni, and his work was only scorned for a few years before everyone agreed it was true. I&#8217;ll give this another half a point.</p>\n<p>CRICK &#038; WATSON</p>\n<blockquote><p>Not ridiculed. But they were instructed to drop their research. They continued it as &#8220;bootleg&#8221; research. </p></blockquote>\n<p>The list admits they were &#8220;not ridiculed&#8221;. They were told to stop their research because there was all sorts of academic politics around who was going to be the first to discover DNA, and the guy in charge of their university was rooting for another team.</p>\n<p>DOPPLER</p>\n<blockquote><p>Proposed a theory of the optical Doppler Effect in 1842, but was bitterly opposed for two decades because it did not fit with the accepted physics of the time (it contradicted the Luminiferous Aether theory.) Doppler was finally proven right in 1868 when W. Huggins observed red shifts and blue shifts in stellar spectra. Unfortunately this was fifteen years after Doppler had died.</p></blockquote>\n<p>I haven&#8217;t been able to find anything about this in various short online biographies of Doppler (<A HREF=\"http://www.biography.com/people/christian-doppler-9277346\">1</A>, <A HREF=\"https://en.wikipedia.org/wiki/Christian_Doppler\">2</A>). Doppler tested the effect himself by having someone play a trumpet on a train (really), someone else successfully tested it in 1845, and it was independently rediscovered in 1848. Doppler himself was made the head of the Institute For Experimental Physics in Vienna and died about as prestigious and beloved as a physicist can get.</p>\n<p>So my impression is that only a third of these people really fit the pattern. Most of them were doubted for very short periods, continued to be respected in their fields for their other accomplishments even during those periods, or were part of medium-sized movements rather than being lone geniuses. After a few years &#8211; maybe an average of ten, very rarely as long as thirty &#8211; their contributions were recognized and they assumed their rightful place in the pantheon. Science isn&#8217;t perfect. But it is <i>darned good</i>.</p>\n<p>[EDIT: Bill Beatty, author of the original list, responds <A HREF=\"http://amasci.com/weird/vindac.html#j42\">here</A>. My response to the response <A HREF=\"http://marginalrevolution.com/marginalrevolution/2017/04/wednesday-assorted-links-102.html#comment-159623218\">here</A>.]</p>\n<p><b>II.</b></p>\n<p>I bring this up in the context of <A HREF=\"http://slatestarcodex.com/2017/04/07/yes-we-have-noticed-the-skulls/\">my last post</A> on progress in the rationalist movement. There used to be a stereotype that rationalists were too quick to challenge scientific consensus. I think that was exaggerated, but based on a core of truth. Given that we&#8217;re interested in the ways that bias can prevent people from accepting truth, it&#8217;s unsurprising that we would focus on cases like these.</p>\n<p>But I personally have changed my thinking on this a lot. Not in any way that I can explain explicitly &#8211; I&#8217;ve always thought something like:</p>\n<blockquote><p>Scientific consensus is the best tool we have for seeking truth. It&#8217;s not perfect, and it&#8217;s frequently overturned by later scientists, but this is usually &#8211; albeit not literally always &#8211; the work of well-credentialed insiders, operating pretty quickly after the evidence that should overturn it becomes available. Any individual should be very doubtful of their ability to beat it, while not being so doubtful that nobody ever improves it and science can never progress.</p></blockquote>\n<p>&#8211; and I still think that. But I&#8217;ve shifted from being the sort of person who shares viral lists of maligned geniuses, to the sort of person who debunks those lists. I&#8217;ve started emphasizing the &#8220;best tool we have&#8221; part of the sentence, and whispering the &#8220;isn&#8217;t perfect&#8221; part, rather than vice versa.</p>\n<p>I&#8217;ve changed my mind on this because of personal experience. Rather than trying to describe it, it might be more helpful to give the most salient examples.</p>\n<p><u>1. The Replication Crisis:</u> I previously thought the scientific consensus was flawed because it failed to take the replication crisis seriously enough. I later learned that everyone else took the repliaction crisis exactly as seriously as I did. A <A HREF=\"http://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970\">poll in <i>Nature</i></A> shows that 90% of scientists believe reproducibility issues constitute a &#8220;crisis&#8221;, compared to only 3% (!) who don&#8217;t. For every person complaining about <A HREF=\"https://www.psychologytoday.com/blog/rabble-rouser/201610/three-cheers-methodological-terrorists\">&#8220;methodological terrorists&#8221;</A>, there are a dozen who are very concerned and trying to change the way they practice research.</p>\n<p>This is especially impressive because as far as I can tell the whole shift happened in about ten years. I would date the beginning of the crisis from Ioannidis&#8217; <A HREF=\"http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124\">original 2005 paper</A>, although it was only aimed at medicine. It got into high gear in psychology sometime around 2011 with Simonsohn&#8217;s <A HREF=\"http://journals.sagepub.com/doi/abs/10.1177/0956797611417632\">False Positive Psychology</A>. A <A HREF=\"https://trends.google.com/trends/explore?date=all&#038;q=%22replication%20crisis%22,p-hacking,%22reproducibility%20crisis%22\">Google Trends analysis</A> suggests people only started searching the relevant keywords around 2013.</p>\n<p>I started thinking about this sort of thing in 2009 after reading <A HREF=\"http://lesswrong.com/lw/1ib/parapsychology_the_control_group_for_science/\">this LW post</A>. At the time I thought this was some sort of exciting failure of modern science that I alone had figured out. But this was well after sharp people like Ioannidis were talking about it, and only a few years before <i>everyone</i> was talking about it. Framing this as &#8220;I was right and scientific consensus was wrong&#8221; seems grandiose. Better might be &#8220;I started betting on a winning horse about a quarter of the way between the beginning of the race and when its victory became blatantly obvious to everyone&#8221;.</p>\n<p><u>2. Nutrition:</u> The Bad Old Paradigm of nutrition says that obese people just have poor impulse control, that weight is a simple matter of calories in vs. calories out, and that all calories are equally good except fat, which for some inexplicable reason is the Devil. Anybody who&#8217;s read a few good books about nutrition science knows that the Bad Old Paradigm is woefully inadequate. I read a few of those books and became convinced that I was right and scientific consensus was wrong.</p>\n<p>Unfortunately, this whole issue exploded when Gary Taubes published <i>Good Calories, Bad Calories</i>, which as best I can tell combined the first publicly available good critique of the Bad Old Paradigm with a flawed and basically false attempt at a new paradigm. There were lots of confused attacks against Taubes&#8217; bad information which did collateral damage to his good information, and lots of confused defenses of his good information which inadvertently shielded his bad information from criticism. I previously focused on <A HREF=\"http://slatestarcodex.com/2015/08/04/contra-hallquist-on-scientific-rationality/\">defend the good parts</A>, but recently shifted more towards <A HREF=\"https://slatestarcodex.com/2017/01/26/link-guyenet-on-taubes/\">criticizing the bad parts</A>.</p>\n<p>After reading some more good books here (one of which I hope to review soon), my impression is that most nutrition scientists don&#8217;t believe in the Bad Old Paradigm and haven&#8217;t for a while. At the very least, most of them seem to believe in the lipostat and think it&#8217;s important, which is my proxy for &#8220;basically has their heart in the right place&#8221;. Insofar as the Bad Old Paradigm continues to be popular wisdom, it&#8217;s because of the diet industry, the government, social inertia, and nobody really having a good new paradigm to replace it with. I&#8217;m gradually seeing popular wisdom shift, and nutrition scientists themselves seem to be helping this process rather than hurting it. </p>\n<p>Maybe somebody in this area has discovered the new paradigm and is a maverick being persecuted by hidebound reactionaries. But it isn&#8217;t Gary Taubes. And it certainly isn&#8217;t me.</p>\n<p><u>3. Social-Justice-Related Issues:</u> Another narrative I used to believe was that a lot of sketchy ideas were being flattered because they spoke to left-leading academics&#8217; biases in favor of social justice. Implicit association tests, stereotype threat, the idea of zero meaningful psychological differences between men and women, et cetera.</p>\n<p>When I started worrying about implicit association tests, I thought I was defying some kind of broad scientific consensus. But the meta-analyses showing the Implicit Association Test didn&#8217;t do what people thought had been around since <A HREF=\"http://www.law.virginia.edu/pdf/faculty/reassessingpredictivevalidityoftheiat.pdf\">2009</A> and have only gotten <A HREF=\"https://www.researchgate.net/profile/Frederick_Oswald/publication/239732934_Predicting_Ethnic_and_Racial_Discrimination_A_Meta-Analysis_of_IAT_Criterion_Studies/links/0a85e53a9a75e2ec00000000.pdf\">more</A> <A HREF=\"http://onlinelibrary.wiley.com/doi/10.1111/sjop.12288/abstract\">numerous</A> since then, with <A HREF=\"http://nymag.com/scienceofus/2017/01/psychologys-racism-measuring-tool-isnt-up-to-the-job.html\">broad media coverage</A>. Problems with stereotype threat research are getting <A HREF=\"http://leiterreports.typepad.com/blog/2014/12/implicit-bias-stereotype.html\">mainstream coverage</A> and even <A HREF=\"http://www.npr.org/2016/05/24/477921050/when-great-minds-think-unlike-inside-sciences-replication-crisis\">airtime on NPR</A>.</p>\n<p>The problem here is that there was no equivalent of the <i>Nature</i> poll on the replication crisis, so I didn&#8217;t realize any of this was happening until just recently. For example, in 2016 <A HREF=\"http://www.vox.com/2014/12/26/7443979/racism-implicit-racial-bias\">this Voxsplainer</A> made it sound like there was a monolithic consensus in favor of Implicit Association Tests that no sane person had ever disagreed with, even though by that point there were already several big meta-analyses finding they weren&#8217;t practically useful. The correct conclusion isn&#8217;t that this is really what scientific consensus thinks. The correct conclusion is that Vox shouldn&#8217;t be trusted about any science more complicated than the wedge vs. inclined plane. Once I realized that there was all this intelligent analysis going on that I&#8217;d never heard about, my claim to be boldly defying the scientific consensus evaporated.</p>\n<p>Yes, Cordelia Fine is still around and is still writing books arguing against gender differences. But she&#8217;s starting to sound <i>really</i> defensive, basically the literary equivalent of &#8220;I know I&#8217;m going to be downvoted to hell for this, but&#8230;&#8221;. Meanwhile, other scientists are doing a good job pointing out the flaws in her books and conducting studies like <A HREF=\"http://nymag.com/scienceofus/2017/04/heres-the-biggest-study-yet-on-sex-based-brain-differences.html\">this biggest-ever look at male vs. female brain differences</A>, <A HREF=\"http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029265\">this magisterial look at personality differences</A>, et cetera &#8211; not to mention great and widely-accepted work on how intersex people take on more characteristics of their hormonal than their social gender (honestly, we should probably thank transgender people for making this field socially acceptable again). People talk a lot about how Larry Summers was fired from Harvard for talking about male vs. female differences, but Steven Pinker <A HREF=\"https://www.edge.org/event/the-science-of-gender-and-science-pinker-vs-spelke-a-debate\">did a whole debate on this</A> and remains a Harvard professor.</p>\n<p>Even things about genetic psychological differences between population groups are less bold and maverick-y than their proponents like to think. The relevant surveys I know trying to elicit scientific consensus (<A HREF=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4804158/\">1</A>, <A HREF=\"http://lepo.it.da.ut.ee/%7Espihlap/snyderman@rothman.pdf\">2</A>, <A HREF=\"http://www.unz.com/jthompson/isir-what-do-intelligence-researchers/\">3</A>) all find that, when asked anonymously, most scientists think these differences explain about 25% &#8211; 50% of variance.</p>\n<p>I hate to bring that up, because it&#8217;ll probably start a flame war in the comments, but I think it&#8217;s important as a sign of exactly how hard it is to politicize science. Global warming skeptics talk about how maybe the scientific consensus on global warming is false because climatologists face political pressure to bias their results in favor of the theory. But scientists studying these areas face much more political pressure, and as long as you give the surveys anonymously they&#8217;re happy to express horrendously taboo opinions. This is about the strongest evidence in favor of the consensus on global warming &#8211; and scientific consensus in general &#8211; that I could imagine.</p>\n<p><u>4. Nuture Assumption and Blank Slatism:</u> The prologue of the first edition of <i>The Nurture Assumption</i> is Judith Rich Harris telling her &#8220;maverick genius kept down by hidebound reactionaries&#8221; story. But the prologue of the second edition is her being much more hopeful:</p>\n<blockquote><p>To some extent at least, times have changed&#8230;there is now more acceptance of the idea that behavior is influenced by genes and that individual differences in behavior are due in part to differnces in genes. People are more willing to admit that children can inherit behavioral quirks and personality characteristics&#8230;was it this cultural shift that led to greater acceptance of my theory? Or was it the fact that new findings, consistent with the theory, kept turning up? Over time, the early, angry response to <i>The Nurture Assumption</i> has softened noticeably, both within and outside of academia. Today, the book is widely cited in textbooks and journal articles. It&#8217;s assigned and discussed in courses in many colleges and universities; it shows up in exams&#8230;in his foreward to the first ediction of <i>The Nurture Assumption</i>, Steven Pinker made a rash prediction about the book: &#8220;I predict it will come to be seen as a turning point in the history of psychology&#8221;. Perhaps it is too soon to judge whether psychology has rounded a bend; perhaps it will take the perspective of twenty or thirty years. Even at this point, though, there are signs of a slight shift in direction. Within developmental psychology, I&#8217;ve noticed that descriptions of procedures and results are beginning to sound a bit defensive. Greater progress has been made in other areas of psychology. And the email I receive from students gives me high hopes for the younger generation coming up.</p></blockquote>\n<p>There were ten years between the first and second editions of <i>The Nurture Assumption</i>. In the almost ten years since the publication of the second edition, my impression is that its ideas have become even more widely-accepted. This month&#8217;s edition of the <i>American Journal of Psychiatry</i>, onbe of the top journals in the field, has a great study showing that child abuse does <i>not</i> cause cognitive disability, in contrast to several previous studies in the area. It cites Deary, Plomin, and Ioannidis, hits all of the talking points about genetic confounding of developmental outcomes, and receives glowing endorsement in the journal&#8217;s editorial section, which says that &#8220;if our causal explanations are wrong, we may be wasting our effort or even doing damage&#8221;. Every single psychiatrist in the country is getting exposed to this way of thinking.</p>\n<p>And this has real results. I got to present a summary of behavioral genetics to a meeting of psychiatrists, including a lot of psychoanalysts, and I was shocked that most of them were at least a little receptive. I think they misunderstood it. I think they carefully raised caveats in exactly the right places to ensure they didn&#8217;t have to change anything they were doing. But the <i>overall</i> response was &#8220;Oh, yeah, we&#8217;ve heard stuff like that, it seems plausible, good thing that for various hard-to-explain reasons none of it applies to us.&#8221; This is what the first stage of progress looks like.</p>\n<p><u>5. Intelligence Explosion And AI Risk:</u> This was another place where I and many of my friends thought we were right and the consensus was wrong. It was another place where a lot of self-appointed defenders of the consensus told us we were crackpots and needed to listen to what real scientists thought. And again, when I looked into it, there was no consensus against the idea and <A HREF=\"http://slatestarcodex.com/2015/05/22/ai-researchers-on-ai-risk/\">lots of prominent researchers were in favor</A>. Going to the <A HREF=\"http://slatestarcodex.com/2017/02/06/notes-from-the-asilomar-conference-on-beneficial-ai/\">Asilomar Conference</A> and seeing a bunch of people from MIT and Harvard talk about how concerned they were really opened my eyes on this. Google now has an AI Ethics Board, Berkeley, Oxford, and MIT have foundations working on it, and people like Elon Musk and Bill Gates are involved. <A HREF=\"http://www.nickbostrom.com/papers/survey.pdf\">Bostrom&#8217;s survey of AI researchers</A> and some more recent and rigorous not-yet-published surveys I&#8217;ve heard about confirm the impression. Nobody would ever say there&#8217;s a scientific consensus <i>in favor</i> of Bostrom&#8217;s theories. But at this point I think it&#8217;s also indefensible to say there&#8217;s a consensus against.</p>\n<p>Bostrom first started writing about these sorts of things extensively in the early 2000s, so there was really only a ten-year gap between entering the intellectual environment and it becoming a (mostly) accepted part of the established field. Those ten years felt pretty long while we were in them, but the ability of a field to accept an on-the-face-of-it completely-insane-sounding theory within ten years seems to me a very strong argument against the hidebound-reactionaries theory and a very strong argument for considering scientific consenses to be unreasonably effective.</p>\n<p><u>6. IQ:</u> Another case where I worried about apparent failure of scientific consensus due to politically bias. I certainly encountered a lot of falsehoods around this when I was younger. My high school psychology textbook included a section claiming that all IQ tests were biased towards rich white people because they were based entirely on questions like &#8220;how many shots below par is a bogey?&#8221; Then it presented an &#8220;alternate IQ test&#8221; which &#8220;proved&#8221; that poor minorities had higher IQs than rich whites by asking some other questions with the opposite bias (I think they were about slang for drugs &#8211; certainly an interesting way to fight stereotypes). This kind of thing naturally made me assume that nobody had any idea what was actually in IQ tests and scientists were idiots.</p>\n<p>But more recently I&#8217;ve been reading <A HREF=\"http://sci-hub.io/10.1016/j.intell.2008.03.007\">actual surveys</A>, which find that about 97% of expert psychologists and 85% of applied psychologists agree that IQ tests measure cognitive ability &#8220;reasonably well&#8221;. And 77% of expert psychologists and 63% of applied psychologists agree IQ tests are culture-fair (with slightly different numbers depending on how you ask the question, but always about 50% of both groups).</p>\n<p>This seems like less of a problem with expert consensus, and more of a problem of nobody else (including textbook writers!) listening to experts who are continually trying to beat reality into people&#8217;s heads. But I have a vague memory of having recently seen a survey (which I can&#8217;t find) that even experts in softer fields like sociology are generally in favor of IQ and admit that it has its uses. And even some left/liberal sources like <A HREF=\"http://www.vox.com/2016/5/25/11683192/iq-testing-intelligence\">Vox</A> and <A HREF=\"https://fredrikdeboer.com/2017/04/10/disentangling-race-from-intelligence-and-genetics/\">Freddie deBoer</A> are aware of the consensus and willing to respect it.</p>\n<p>At the same time, I&#8217;ve encountered some people like <A HREF=\"http://www.stat.cmu.edu/~brian/Pmka-Attack-V71-N3/pmka-2006-71.3-425-440-borsboom.pdf\">Borsboom</A> and <A HREF=\"http://nostalgebraist.tumblr.com/tagged/iq-debate-tag\">Nostalgebraist</A> who have relatively sophisticated (and limited) critiques of IQ, and who have allowed me to round off other people&#8217;s less-well-framed critiques to something more like what they are saying and less like the stupid things my high school textbook said. </p>\n<p>So it seems to me that generally experts agree with reasonable statements about IQ, and where they seem to disagree they may hold reasonable disagreements rather than unreasonable ones. Again, where this fails is not in the experts but in the ability of people who don&#8217;t listen to the experts to get disproportionate social power and hide the existence of the expert consensus.</p>\n<p><b>III.</b></p>\n<p>Last week <A HREF=\"http://slatestarcodex.com/2017/04/07/yes-we-have-noticed-the-skulls/\">I wrote</A> about universally-known criticisms of economists, like &#8220;they&#8217;re silly for assuming everyone behaves perfectly rationally&#8221;:</p>\n<blockquote><p>My impression is that economists not only know about these criticisms, but invented them. During the last few paradigm shifts in economics, the new guard levied these complaints against the old guard, mostly won, and their arguments percolated down into the culture as The Correct Arguments To Use Against Economics. Now the new guard is doing their own thing – behavioral economics, experimental economics, economics of effective government intervention. The new paradigm probably has a lot of problems too, but it’s a pretty good bet that random people you stop on the street aren’t going to know about them.</p></blockquote>\n<p>The same pattern explains a lot of my concerns above. I knew some criticisms of a scientific paradigm. They seemed right. I concluded that scientists weren&#8217;t very smart and maybe I was smarter. I should have concluded that some cutting-edge scientists were making good criticisms of an old paradigm. I can still flatter myself by saying that it&#8217;s no small achievement to recognize a new paradigm early and bet on the winning horse. But the pattern I was seeing was part of the process of science, not a condemnation of it.</p>\n<p>Most people understand this intuitively about past paradigm shifts. When a creationist says that we can&#8217;t trust science because it used to believe in phlogiston and now it believes in combustion, we correctly respond that this is exactly why we <i>can</i> trust science. But this lesson doesn&#8217;t always generalize when you&#8217;re in the middle of a paradigm shift <i>right now</i> and having trouble seeing the other side.</p>\n<p>I realize I&#8217;m (ironically) risking making my narrative of scientific success unfalsifiable. Suppose someone wants to argue that scientific consensus is wrong. If they point to something it used to be wrong about, I can respond &#8220;Yes, but it self-corrected and it&#8217;s correct now, so that&#8217;s fine.&#8221; If they point to something where cutting-edge scientists say it&#8217;s wrong but nobody else agrees, I can respond &#8220;Yes, this is what the beginning of a paradigm shift looks like, so that&#8217;s fine&#8221;. And if they point to something where <i>nobody</i> in the field thinks it&#8217;s wrong, I can say &#8220;You&#8217;re a crackpot for going against all reputable scientists; the problem is with you.&#8221; And if later they turn out to be right, and everyone acknowledges it, I can say &#8220;Yes, but it self-corrected and it&#8217;s correct now, so that&#8217;s fine.&#8221;</p>\n<p>(and I&#8217;m making it even easier for myself in that I say &#8220;scientific consensus for&#8221; when I probably mean &#8220;no scientific consensus against&#8221;. I don&#8217;t claim that 90%+ of scientists always believe true things, only that there are very few cases where 90%+ of scientists believe things which smarter people know to be false.)</p>\n<p>Against this I can only offer a personal narrative: the only light I have by which to judge scientific consensus is my own Inside View assessment of what seems correct. Again and again I have <i>tried</i> to defy scientific consensus. And every time, I either find that I am wrong, find that I am a few years ahead of a trend that most scientists eventually agree with, or find that what I thought was &#8220;scientific consensus&#8221; was actually a fiction peddled by biased industry or media sources slandering a scientific community which actually had a much more sophisticated picture. My history of trying to fight scientific consensus has been a <i>Man Who Was Thursday</i>-esque series of embarassments as I find again and again that my supposed enemy agrees with me and is even better at what I am trying to do than I am. </p>\n<p>Scientific consensus hasn&#8217;t just been accurate, it&#8217;s been <i>unreasonably</i> accurate. Humans are fallible beings. They are not known for their ability the change their mind, to willingly accept new information, or to put truth-seeking above political squabbles. And our modern society is not exactly known for being an apolitical philosopher-kingdom with strong truth-seeking institutions completely immune from partisan pressure. I feel a deep temptation to sympathize with global warming denialists who worry that the climatological consensus is biased politicized crap, because that is <i>exactly</i> the sort of thing which I would expect to come out of our biased politicized crappy society. Yet again and again I have seen examples of scientific fields that have maintained strong commitments to the truth in the face of pressure that would shatter any lesser institution. I&#8217;ve seen fields where people believe incredibly-bizarre sounding things that will get them mocked at cocktail parties just because those things seem to be backed by the majority of the evidence. I&#8217;ve even seen people <i>change their minds</i>, in spite of all the incentives to the contrary. I can&#8217;t explain this. The idea that scientific consensus is almost always an accurate reflection of the best knowledge we have at the time seems even more flabbergasting than any particular idea that scientists might or might not believe. But it seems to be true.</p>\n<p>(note that I&#8217;m talking about &#8220;scientific consensus&#8221; to mean a very high-level pattern, consisting of hundreds of scientists over the space of decades evaluating a broad body of work. Any individual study is still probably total garbage.)</p>\n<p>Given how weird all of this is, I realize there&#8217;s another possible bias here that should be taken very seriously &#8211; which is that I&#8217;m wrong about one or both sides of this. Which is more likely: that Science always agrees with Truth? Or that one guy&#8217;s perception of Science always agrees with that same guy&#8217;s perception of Truth? The latter gives me two degrees of freedom: I can either cherry-pick experts who agree with me and declare them to be Consensus, or I can conform my opinions to consensus so slavishly that I end up discovering only that Consensus agrees with itself. I don&#8217;t <i>feel</i> like I&#8217;m making this kind of mistake. But then again, nobody ever <i>feels like</i> they&#8217;re being biased.</p>\n<p>But if I&#8217;m making this mistake, I think it&#8217;s at least a <i>better</i> mistake than the one where people dream up stories about being mavericks persecuted by hidebound reactionaries. This mistake at least sets the terms of debate as &#8220;let&#8217;s try to ascertain what the scientific community thinks&#8221; and forbids me from believing <i>completely</i> crackpottish things. And it encourages trust in one of our more trustworthy public institutions, always a prosocial sort of thing to do. I would rather have a world of people debating who agrees with scientific consensus or not, than a world of people debating whether scientific consensus is even valuable.</p>\n<p>There are two caveats to the above. First, I think it&#8217;s dangerous to promote a norm of agreeing with scientific consensus, insofar as that helps encourage exactly the mistakes about the nature of consensus that I discussed above. When poorly-informed diet industry gurus support the Bad Old Paradigm, their rallying cry is usually &#8220;You&#8217;re a stupid crackpot, bow to the scientific consensus which agrees with me&#8221;. I gave three examples above of cases where I would have gotten the scientific consensus 100% wrong if I didn&#8217;t have access to a formal survey of scientific experts. In a world where these surveys had never been done &#8211; or some existing field without these surveys &#8211; or some field where these surveys have been done inaccurately or in a biased manner &#8211; people will often believe the consensus to be the opposite of what it really is. In those cases, demands that people respect consensus can be used to shut down people who are actually right &#8211; the field-wide equivalent of calling true facts you don&#8217;t like <A HREF=\"http://slatestarcodex.com/2014/12/13/debunked-and-well-refuted/\">debunked and well-refuted</A>. I see this happening all the time and I worry that waxing too poetically about the unreasonable effectiveness of scientific consensus will only serve to empower these people. Goodhart&#8217;s Law says that a measure which becomes a target ceases to be a useful measure, so we should be reluctant to target scientific consensus too strongly.</p>\n<p>And second, I think that even when the Outside View tells you that the consensus is correct, you should continue pursuing your Inside View hunch that it isn&#8217;t. This avoids awkward situations like every individual scientist doubting the consensus, but suppressing their doubts because the &#8220;scientific consensus&#8221; has to be right.</p>\n<p>So maybe the things I&#8217;m saying about scientific consensus aren&#8217;t very actionable. But respecting scientific consensus in a non-actionable way is a lot less exhausting than believing yourself to be against it, and talking about how you&#8217;re against it, and taking flak for being against it. And in the same way it&#8217;s helpful to believe that God is good, even if He never really gets around to doing much about it, so it&#8217;s reassuring to be able to have faith in our institutions every so often.</p>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  },
  {
    "_id": "GLMFmFvXGyAcG25ni",
    "title": "I Can Tolerate Anything Except The Outgroup",
    "slug": "i-can-tolerate-anything-except-the-outgroup",
    "pageUrl": "https://www.lesswrong.com/posts/GLMFmFvXGyAcG25ni/i-can-tolerate-anything-except-the-outgroup",
    "postedAt": "2017-09-02T08:22:19.612Z",
    "baseScore": 114,
    "voteCount": 80,
    "commentCount": 5,
    "meta": false,
    "question": false,
    "url": null,
    "htmlBody": "<p><i>[Content warning: Politics, religion, social justice, spoilers for “The Secret of Father Brown”. This isn’t especially original to me and I don’t claim anything more than to be explaining and rewording things I have heard from a bunch of other people. Unapologetically America-centric because I’m not informed enough to make it otherwise. Try to keep this off Reddit and other similar sorts of things.]</i></p><p><strong>I.</strong></p><p>In Chesterton’s <a href=\"https://www.amazon.com/Secret-Father-Brown-ebook/dp/B003XYE7YU/ref=as_li_ss_tl?_encoding=UTF8&amp;redirect=true&amp;ref_=as_li_tl&amp;linkCode=ll1&amp;tag=slatestarcode-20&amp;linkId=80cee7fc381622e3e77edf8f12fdb13d\"><i>The Secret of Father Brown</i></a></p><figure class=\"image\"><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&amp;l=as2&amp;o=1&amp;a=B003XYE7YU\"></figure><p>, a beloved nobleman who murdered his good-for-nothing brother in a duel thirty years ago returns to his hometown wracked by guilt. All the townspeople want to forgive him immediately, and they mock the titular priest for only being willing to give a measured forgiveness conditional on penance and self-reflection. They lecture the priest on the virtues of charity and compassion.</p><p>Later, it comes out that the beloved nobleman did <i>not</i> in fact kill his good-for-nothing brother. The good-for-nothing brother killed the beloved nobleman (and stole his identity). <i>Now</i> the townspeople want to see him lynched or burned alive, and it is only the priest who – consistently – offers a measured forgiveness conditional on penance and self-reflection.</p><p>The priest tells them:</p><blockquote><p>It seems to me that you only pardon the sins that you don’t really think sinful. You only forgive criminals when they commit what you don’t regard as crimes, but rather as conventions. You forgive a conventional duel just as you forgive a conventional divorce. You forgive because there isn’t anything to be forgiven.</p></blockquote><p>He further notes that this is why the townspeople can self-righteously consider themselves more compassionate and forgiving than he is. Actual forgiveness, the kind the priest needs to cultivate to forgive evildoers, is really really hard. The fake forgiveness the townspeople use to forgive the people they like is really easy, so they get to boast not only of their forgiving nature, but of how much nicer they are than those mean old priests who find forgiveness difficult and want penance along with it.</p><p>After some thought I agree with Chesterton’s point. There are a lot of people who say “I forgive you” when they mean “No harm done”, and a lot of people who say “That was unforgiveable” when they mean “That was genuinely really bad”. Whether or not forgiveness is <i>right</i> is a complicated topic I do not want to get in here. But since forgiveness is generally considered a virtue, and one that many want credit for having, I think it’s fair to say you only earn the right to call yourself ‘forgiving’ if you forgive things that genuinely hurt you.</p><p>To borrow Chesterton’s example, if you think divorce is a-ok, then you don’t get to “forgive” people their divorces, you merely ignore them. Someone who thinks divorce is abhorrent can “forgive” divorce. <i>You</i> can forgive theft, or murder, or tax evasion, or something <i>you</i> find abhorrent.</p><p>I mean, from a utilitarian point of view, you are still doing the correct action of not giving people grief because they’re a divorcee. You can have all the Utility Points you want. All I’m saying is that if you “forgive” something you don’t care about, you don’t earn any Virtue Points.</p><p>(by way of illustration: a billionaire who gives $100 to charity gets as many Utility Points as an impoverished pensioner who donates the same amount, but the latter gets a lot more Virtue Points)</p><p>Tolerance is also considered a virtue, but it suffers the same sort of dimished expectations forgiveness does.</p><p>The Emperor <a href=\"http://poetrychina.net/Story_of_Zen/zenstory3a.htm\">summons before him</a> Bodhidharma and asks: “Master, I have been tolerant of innumerable gays, lesbians, bisexuals, asexuals, blacks, Hispanics, Asians, transgender people, and Jews. How many Virtue Points have I earned for my meritorious deeds?”</p><p>Bodhidharma answers: “None at all”.</p><p>The Emperor, somewhat put out, demands to know why.</p><p>Bodhidharma asks: “Well, what do you think of gay people?”</p><p>The Emperor answers: “What do you think I am, some kind of homophobic bigot? Of course I have nothing against gay people!”</p><p>And Bodhidharma answers: “Thus do you gain no merit by tolerating them!”</p><p><strong>II.</strong></p><p>If I had to define “tolerance” it would be something like “respect and kindness toward members of an outgroup”.</p><p>And today we have an almost unprecedented situation.</p><p>We have a lot of people – like the Emperor – boasting of being able to tolerate everyone from every outgroup they can imagine, loving the outgroup, writing long paeans to how great the outgroup is, staying up at night fretting that somebody else might not like the outgroup enough.</p><p>This is really surprising. It’s a total reversal of everything we know about human psychology up to this point. No one did any genetic engineering. No one passed out weird glowing pills in the public schools. And yet suddenly we get an entire group of people who conspicuously promote and defend their outgroups, the outer the better.</p><p>What is going on here?</p><p>Let’s start by asking what exactly an outgroup is.</p><p>There’s a very boring sense in which, assuming the Emperor’s straight, gays are part of his “outgroup” ie a group that he is not a member of. But if the Emperor has curly hair, are straight-haired people part of his outgroup? If the Emperor’s name starts with the letter ‘A’, are people whose names start with the letter ‘B’ part of his outgroup?</p><p>Nah. I would differentiate between multiple different meanings of outgroup, where one is “a group you are not a part of” and the other is…something stronger.</p><p>I want to avoid a very easy trap, which is saying that outgroups are about how different you are, or how hostile you are. I don’t think that’s quite right.</p><p>Compare the Nazis to the German Jews and to the Japanese. The Nazis were very similar to the German Jews: they looked the same, spoke the same language, came from a similar culture. The Nazis were totally different from the Japanese: different race, different language, vast cultural gap. But the Nazis and Japanese mostly got along pretty well. Heck, the Nazis were actually moderately positively disposed to the <i>Chinese</i>, even when they were technically at war. Meanwhile, the conflict between the Nazis and the German Jews – some of whom didn’t even realize they were anything other than German until they checked their grandparents’ birth certificate – is the stuff of history and nightmares. Any theory of outgroupishness that naively assumes the Nazis’ natural outgroup is Japanese or Chinese people will be totally inadequate.</p><p>And this isn’t a weird exception. Freud spoke of <a href=\"http://en.wikipedia.org/wiki/Narcissism_of_small_differences\">the narcissism of small differences</a>, saying that “it is precisely communities with adjoining territories, and related to each other in other ways as well, who are engaged in constant feuds and ridiculing each other”. Nazis and German Jews. Northern Irish Protestants and Northern Irish Catholics. Hutus and Tutsis. South African whites and South African blacks. Israeli Jews and Israeli Arabs. Anyone in the former Yugoslavia and anyone else in the former Yugoslavia.</p><p>So what makes an outgroup? Proximity plus small differences. If you want to know who someone in former Yugoslavia hates, don’t look at the Indonesians or the Zulus or the Tibetans or anyone else distant and exotic. Find the Yugoslavian ethnicity that lives closely intermingled with them and is most conspicuously similar to them, and chances are you’ll find the one who they have eight hundred years of seething hatred toward.</p><p>What makes an unexpected in-group? The answer with Germans and Japanese is obvious – a strategic alliance. In fact, the World Wars forged a lot of unexpected temporary pseudo-friendships. <a href=\"http://pando.com/2014/02/12/war-nerd-the-long-sleazy-history-behind-a-googlers-nonviolent-militia/\">A recent article from War Nerd</a> points out that the British, after spending centuries subjugating and despising the Irish and Sikhs, suddenly needed Irish and Sikh soldiers for World Wars I and II respectively. “Crush them beneath our boots” quickly changed to fawning songs about how “there never was a coward where the shamrock grows” and endless paeans to Sikh military prowess.</p><p>Sure, scratch the paeans even a little bit and you find condescension as strong as ever. But eight hundred years of the British committing genocide against the Irish and considering them literally subhuman turned into smiles and songs about shamrocks once the Irish started looking like useful cannon fodder for a larger fight. And the Sikhs, dark-skinned people with turbans and beards who pretty much exemplify the European stereotype of “scary foreigner”, were lauded by everyone from the news media all the way up <a href=\"https://www.youtube.com/watch?v=--OAScn5NcI\">to Winston Churchill</a>.</p><p>In other words, outgroups may be the people who look exactly like you, and scary foreigner types can become the in-group on a moment’s notice when it seems convenient.</p><p><strong>III.</strong></p><p>There are certain theories of dark matter where it barely interacts with the regular world <i>at all</i>, such that we could have a dark matter planet exactly co-incident with Earth and never know. Maybe dark matter people are walking all around us and through us, maybe my house is in the Times Square of a great dark matter city, maybe a few meters away from me a dark matter blogger is writing on his dark matter computer about how weird it would be if there was a light matter person he couldn’t see right next to him.</p><p>This is sort of how I feel about conservatives.</p><p>I don’t mean the sort of light-matter conservatives who go around complaining about Big Government and occasionally voting for Romney. I see those guys all the time. What I mean is – well, take creationists. According to <a href=\"http://www.gallup.com/poll/155003/Hold-Creationist-View-Human-Origins.aspx\">Gallup polls</a>, about 46% of Americans are creationists. Not just in the sense of believing God helped guide evolution. I mean they think evolution is a vile atheist lie and God created humans exactly as they exist right now. That’s half the country.</p><p>And I don’t have a <i>single one of those people</i> in my social circle. It’s not because I’m deliberately avoiding them; I’m pretty live-and-let-live politically, I wouldn’t ostracize someone just for some weird beliefs. And yet, even though I <a href=\"http://en.wikipedia.org/wiki/Dunbar%27s_number\">probably</a> know about a hundred fifty people, I am pretty confident that not one of them is creationist. Odds of this happening by chance? 1/2^150 = 1/10^45 = approximately the chance of picking a particular atom if you are randomly selecting among all the atoms on Earth.</p><p>About forty percent of Americans want to ban gay marriage. I think if I <i>really</i> stretch it, maybe ten of my top hundred fifty friends might fall into this group. This is less astronomically unlikely; the odds are a mere one to one hundred quintillion against.</p><p>People like to talk about social bubbles, but that doesn’t even begin to cover one hundred quintillion. The only metaphor that seems really appropriate is the bizarre dark matter world.</p><p>I live in a Republican congressional district in a state with a Republican governor. The conservatives are definitely out there. They drive on the same roads as I do, live in the same neighborhoods. But they might as well be made of dark matter. I never meet them.</p><p>To be fair, I spend a lot of my time inside on my computer. I’m browsing sites like Reddit.</p><p>Recently, there was a thread on Reddit asking – <a href=\"http://www.reddit.com/r/AskReddit/comments/29uo38/serious_redditors_against_gay_marriage_what_is/\">Redditors Against Gay Marriage, What Is Your Best Supporting Argument?</a> A Reddit user who didn’t understand how anybody could be against gay marriage honestly wanted to know how other people who <i>were</i> against it justified their position. He figured he might as well ask one of the largest sites on the Internet, with an estimated user base in the tens of millions.</p><p>It soon became clear that nobody there was actually against gay marriage.</p><p>There were a bunch of posts saying “I of course support gay marriage but here are some reasons some other people might be against it,” a bunch of others saying “my argument against gay marriage is the government shouldn’t be involved in the marriage business at all”, and several more saying “why would you even ask this question, there’s no possible good argument and you’re wasting your time”. About halfway through the thread someone started saying homosexuality was unnatural and I <i>thought</i> they were going to be the first one to actually answer the question, but at the end they added “But it’s not my place to decide what is or isn’t natural, I’m still pro-gay marriage.”</p><p>In a thread with 10,401 comments, a thread <i>specifically</i> asking for people against gay marriage, I was eventually able to find <i>two</i> people who came out and opposed it, way near the bottom. Their posts started with “I know I’m going to be downvoted to hell for this…”</p><p>But I’m not only on Reddit. I also hang out on LW.</p><p>On last year’s survey, I found that of American LWers who identify with one of the two major political parties, 80% are Democrat and 20% Republican, which actually sounds pretty balanced compared to some of these other examples.</p><p>But it doesn’t last. Pretty much all of those “Republicans” are libertarians who consider the GOP the lesser of two evils. When allowed to choose “libertarian” as an alternative, only 4% of visitors continued to identify as conservative. But that’s still…some. Right?</p><p>When I broke the numbers down further, 3 percentage points of those are neoreactionaries, a bizarre sect that wants to be ruled by a king. Only <i>one percent</i> of LWers were normal everyday God-‘n-guns-but-not-George-III conservatives of the type that seem to make up about half of the United States.</p><p>It gets worse. My formative years were spent at a university which, if it was similar to other elite universities, had <a href=\"http://www.washingtonpost.com/wp-dyn/articles/A8427-2005Mar28.html\">a faculty</a> and <a href=\"http://www.thecrimson.com/article/2012/11/5/crimson-presidential-poll-2012/\">a student body</a> that skewed about 90-10 liberal to conservative – and we can bet that, like LW, even those few token conservatives are Mitt Romney types rather than God-n’-guns types. I get my news from vox.com, an Official Liberal Approved Site. Even when I go out to eat, it turns out my favorite restaurant, California Pizza Kitchen, is <a href=\"http://blogs.wsj.com/washwire/2014/05/02/liberals-eat-here-conservatives-eat-there/\">the most liberal restaurant in the United States</a>.</p><p>I inhabit the same geographical area as <i>scores and scores</i> of conservatives. But without meaning to, I have created an <i>outrageously</i> strong bubble, a 10^45 bubble. Conservatives are all around me, yet I am about as likely to have a serious encounter with one as I am a Tibetan lama.</p><p>(Less likely, actually. One time a Tibetan lama came to my college and gave a really nice presentation, but if a conservative tried that, people would protest and it would be canceled.)</p><p><strong>IV.</strong></p><p>One day I realized that entirely by accident I was fulfilling <i>all</i> the Jewish stereotypes.</p><p>I’m nerdy, over-educated, good with words, good with money, weird sense of humor, don’t get outside much, I like deli sandwiches. And I’m a psychiatrist, which is about the most stereotypically Jewish profession short of maybe stand-up comedian or rabbi.</p><p>I’m not very religious. And I don’t go to synagogue. But <i>that’s</i> stereotypically Jewish too!</p><p>I bring this up because it would be a mistake to think “Well, a Jewish person is by definition someone who is born of a Jewish mother. Or I guess it sort of also means someone who follows the Mosaic Law and goes to synagogue. But I don’t care about Scott’s mother, and I know he doesn’t go to synagogue, so I can’t gain any useful information from knowing Scott is Jewish.”</p><p>The defining factors of Judaism – Torah-reading, synagogue-following, mother-having – are the tip of a giant iceberg. Jews sometimes identify as a “tribe”, and even if you don’t attend synagogue, you’re still a member of that tribe and people can still (in a statistical way) infer things about you by knowing your Jewish identity – like how likely they are to be psychiatrists.</p><p>The last section raised a question – if people rarely select their friends and associates and customers explicitly for politics, how do we end up with such intense political segregation?</p><p>Well, in the same way “going to synagogue” is merely the iceberg-tip of a Jewish tribe with many distinguishing characteristics, so “voting Republican” or “identifying as conservative” or “believing in creationism” is the iceberg-tip of a conservative tribe with many distinguishing characteristics.</p><p>A disproportionate number of my friends are Jewish, because I meet them at psychiatry conferences or something – we self-segregate not based on explicit religion but on implicit tribal characteristics. So in the same way, political tribes self-segregate to an impressive extent – a 1/10^45 extent, I will never tire of hammering in – based on their implicit tribal characteristics.</p><p>The people who are actually into this sort of thing sketch out a bunch of speculative tribes and subtribes, but to make it easier, let me stick with two and a half.</p><p>The Red Tribe is most classically typified by conservative political beliefs, strong evangelical religious beliefs, creationism, opposing gay marriage, owning guns, eating steak, drinking Coca-Cola, driving SUVs, watching lots of TV, enjoying American football, getting conspicuously upset about terrorists and commies, marrying early, divorcing early, shouting “USA IS NUMBER ONE!!!”, and listening to country music.</p><p>The Blue Tribe is most classically typified by liberal political beliefs, vague agnosticism, supporting gay rights, thinking guns are barbaric, eating arugula, drinking fancy bottled water, driving Priuses, reading lots of books, being highly educated, mocking American football, feeling vaguely like they should like soccer but never really being able to get into it, getting conspicuously upset about sexists and bigots, marrying later, constantly pointing out how much more civilized European countries are than America, and listening to “everything except country”.</p><p>(There is a partly-formed attempt to spin off a Grey Tribe typified by libertarian political beliefs, Dawkins-style atheism, vague annoyance that the question of gay rights even comes up, eating paleo, drinking Soylent, calling in rides on Uber, reading lots of blogs, calling American football “sportsball”, getting conspicuously upset about the War on Drugs and the NSA, and listening to filk – but for our current purposes this is a distraction and they can safely be considered part of the Blue Tribe most of the time)</p><p>I think these “tribes” will turn out to be even stronger categories than politics. Harvard might skew 80-20 in terms of Democrats vs. Republicans, 90-10 in terms of liberals vs. conservatives, but maybe 99-1 in terms of Blues vs. Reds.</p><p>It’s the many, many differences between these tribes that explain the strength of the filter bubble – which <i>have I mentioned</i> segregates people at a strength of 1/10^45? Even in something as seemingly politically uncharged as going to California Pizza Kitchen or Sushi House for dinner, I’m restricting myself to the set of people who like cute artisanal pizzas or sophsticated foreign foods, which are classically Blue Tribe characteristics.</p><p>Are these tribes based on geography? Are they based on race, ethnic origin, religion, IQ, what TV channels you watched as a kid? I don’t know.</p><p>Some of it is certainly genetic – <a href=\"http://www.matthewckeller.com/16.Hatemi.et.al.2010.Nuc.fam.ajps.pdf\">estimates</a> <a href=\"”https://www.apsanet.org/imgtest/GeneticsAPSR0505.pdf”\">of</a> the genetic contribution to political association range from 0.4 to 0.6. Heritability of one’s attitudes toward gay rights range from 0.3 to 0.5, which hilariously is a little more heritable than homosexuality itself.</p><p>(for an interesting attempt to break these down into more rigorous concepts like “traditionalism”, “authoritarianism”, and “in-group favoritism” and find the genetic loading for each <a href=\"http://www.midus.wisc.edu/findings/pdfs/1287.pdf\">see here</a>. For an attempt to trace the specific genes involved, which mostly turn out to be NMDA receptors, <a href=\"”http://ussc.edu.au/s/media/docs/publications/18_Hatemi_et_al_LinkageGW_JOP.pdf”\">see here</a>)</p><p>But I don’t think it’s just genetics. There’s something else going on too. The word “class” seems like the closest analogue, but only if you use it in the sophisticated Paul Fussell <a href=\"https://www.amazon.com/Class-Through-American-Status-System/dp/0671792253/ref=as_li_ss_tl?_encoding=UTF8&amp;redirect=true&amp;ref_=as_li_tl&amp;linkCode=ll1&amp;tag=slatestarcode-20&amp;linkId=ae89050500c1fcc0f1d2de1ccb5313ab\"><i>Guide Through the American Status System</i></a> way instead of the boring “another word for how much money you make” way.</p><p>For now we can just accept them as a brute fact – as multiple coexisting societies that might as well be made of dark matter for all of the interaction they have with one another – and move on.</p><p><strong>V.</strong></p><p>The worst reaction I’ve ever gotten to a blog post was when <a href=\"http://squid314.livejournal.com/294986.html\">I wrote about</a> the death of Osama bin Laden. I’ve written all sorts of stuff about race and gender and politics and whatever, but that was the worst.</p><p>I didn’t come out and say I was happy he was dead. But some people interpreted it that way, and there followed a bunch of comments and emails and Facebook messages about how could I possibly be happy about the death of another human being, even if he was a bad person? Everyone, even Osama, is a human being, and we should never rejoice in the death of a fellow man. One commenter came out and said:</p><blockquote><p>I’m surprised at your reaction. As far as people I casually stalk on the internet (ie, LJ and Facebook), you are the first out of the “intelligent, reasoned and thoughtful” group to be uncomplicatedly happy about this development and not to be, say, disgusted at the reactions of the other 90% or so.</p></blockquote><p>This commenter was right. Of the “intelligent, reasoned, and thoughtful” people I knew, the overwhelming emotion was conspicuous disgust that other people could be happy about his death. I hastily backtracked and said I wasn’t happy per se, just surprised and relieved that all of this was finally behind us.</p><p>And I genuinely believed that day that I had found some unexpected good in people – that everyone I knew was so humane and compassionate that they were unable to rejoice even in the death of someone who hated them and everything they stood for.</p><p>Then a few years later, Margaret Thatcher died. And on my Facebook wall – made of these same “intelligent, reasoned, and thoughtful” people – the most common response was to quote some portion of the song “Ding Dong, The Witch Is Dead”. Another popular response was to link the videos of British people spontaneously throwing parties in the street, with comments like “I wish I was there so I could join in”. From this exact same group of people, not a single expression of disgust or a “c’mon, guys, we’re all human beings here.”</p><p>I <a href=\"http://slatestarcodex.com/2013/04/12/if-a-clod-be-washed-away-by-the-sea-europe-is-the-less/\">gently pointed this out</a> at the time, and mostly got a bunch of “yeah, so what?”, combined with links to an article claiming that “the demand for respectful silence in the wake of a public figure’s death is not just misguided but dangerous”.</p><p>And that was when something clicked for me.</p><p>You can talk all you want about Islamophobia, but my friend’s “intelligent, reasoned, and thoughtful people” – her name for the Blue Tribe – can’t get together enough energy to really hate Osama, let alone Muslims in general. We understand that what he did was bad, but it didn’t anger us personally. When he died, we were able to very rationally apply our better nature and our Far Mode beliefs about how it’s never right to be happy about anyone else’s death.</p><p>On the other hand, that same group absolutely <i>loathed</i> Thatcher. Most of us (though <a href=\"http://slatestarcodex.com/2013/04/12/if-a-clod-be-washed-away-by-the-sea-europe-is-the-less/#comment-3355\">not all</a>) can agree, if the question is posed explicitly, that Osama was a worse person than Thatcher. But in terms of actual gut feeling? Osama provokes a snap judgment of “flawed human being”, Thatcher a snap judgment of “scum”.</p><p>I started this essay by pointing out that, despite what geographical and cultural distance would suggest, the Nazis’ outgroup was not the vastly different Japanese, but the almost-identical German Jews.</p><p>And my hypothesis, stated plainly, is that if you’re part of the Blue Tribe, then your outgroup isn’t al-Qaeda, or Muslims, or blacks, or gays, or transpeople, or Jews, or atheists – it’s the Red Tribe.</p><p><strong>VI.</strong></p><p>“But racism and sexism and cissexism and anti-Semitism are these giant all-encompassing social factors that verge upon being human universals! Surely you’re not arguing that mere <i>political</i> differences could ever come close to them!”</p><p>One of the ways we <i>know</i> that racism is a giant all-encompassing social factor is the Implicit Association Test. Psychologists ask subjects to quickly identify whether words or photos are members of certain gerrymandered categories, like “either a white person’s face or a positive emotion” or “either a black person’s face and a negative emotion”. Then they compare to a different set of gerrymandered categories, like “either a black person’s face or a positive emotion” or “either a white person’s face or a negative emotion.” If subjects have more trouble (as measured in latency time) connecting white people to negative things than they do white people to positive things, then they probably have subconscious positive associations with white people. You can <a href=\"https://implicit.harvard.edu/implicit/\">try it yourself here</a>.</p><p>Of course, what the test famously found was that even white people who claimed to have no racist attitudes at all usually had positive associations with white people and negative associations with black people on the test. There are very many claims and counterclaims about the precise meaning of this, but it ended up being a big part of the evidence in favor of the current consensus that all white people are at least a little racist.</p><p>Anyway, three months ago, someone finally had the bright idea of <a href=\"http://pcl.stanford.edu/research/2014/iyengar-ajps-group-polarization.pdf\">doing an Implicit Association Test with political parties</a>, and they found that people’s unconscious partisan biases were <i>half again as strong</i> as their unconscious racial biases (h/t <a href=\"http://www.bloombergview.com/articles/2014-09-22/partyism-now-trumps-racism\">Bloomberg</a>. For example, if you are a white Democrat, your unconscious bias against blacks (as measured by something called a d-score) is 0.16, but your unconscious bias against Republicans will be 0.23. The Cohen’s <i>d</i> for racial bias was 0.61, by <a href=\"http://en.wikipedia.org/wiki/Effect_size#.22Small.22.2C_.22medium.22.2C_.22large.22_effect_sizes\">the book</a> a “moderate” effect size; for party it was 0.95, a “large” effect size.</p><p>Okay, fine, but we know race has <i>real world</i> consequences. Like, there have been <a href=\"http://slatestarcodex.com/2013/04/20/social-justice-for-the-highly-demanding-of-rigor/\">several studies</a> where people sent out a bunch of identical resumes except sometimes with a black person’s photo and other times with a white person’s photo, and it was noticed that employers were much more likely to invite the fictional white candidates for interviews. So just some stupid Implicit Association Test results can’t compare to that, right?</p><p>Iyengar and Westwood also decided to do the resume test for parties. They asked subjects to decide which of several candidates should get a scholarship (subjects were told this was a genuine decision for the university the researchers were affiliated with). Some resumes had photos of black people, others of white people. And some students listed their experience in Young Democrats of America, others in Young Republicans of America.</p><p>Once again, discrimination on the basis of party was much stronger than discrimination on the basis of race. The size of the race effect for white people was only 56-44 (and in the reverse of the expected direction); the size of the party effect was about 80-20 for Democrats and 69-31 for Republicans.</p><p>If you want to see their third experiment, which applied <i>yet another</i> classic methodology used to detect racism and <i>once again</i> found partyism to be much stronger, you can read the paper.</p><p>I &amp; W did an unusually thorough job, but this sort of thing isn’t new or ground-breaking. People have been studying “belief congruence theory” – the idea that differences in beliefs are more important than demographic factors in forming in-groups and outgroups – for decades. As early as 1967, Smith et al were doing surveys all over the country and <a href=\"http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;uid=2005-11098-001\">finding that</a> people were more likely to accept friendships across racial lines than across beliefs; in the forty years since then, the observation has been replicated scores of times. Insko, Moe, and Nacoste’s 2006 review <a href=\"http://onlinelibrary.wiley.com/doi/10.1002/ejsp.2420130206/abstract\">Belief Congruence And Racial Discrimination</a> concludes that:</p><blockquote><p>. The literature was judged supportive of a weak version of belief congruence theory which states that in those contexts in which social pressure is nonexistent or ineffective, belief is more important than race as a determinant of racial or ethnic discrimination. Evidence for a strong version of belief congruence theory (which states that in those contexts in which social pressure is nonexistent, or ineffective, belief is the only determinant of racial or ethnic discrimination) and was judged much more problematic.</p></blockquote><p>One of the best-known examples of racism is the “Guess Who’s Coming To Dinner” scenario where parents are scandalized about their child marrying someone of a different race. Pew has done <a href=\"http://www.people-press.org/2014/06/12/section-3-political-polarization-and-personal-life/\">some good work on this</a> and found that only 23% of conservatives and 1% (!) of liberals admit they would be upset in this situation. But Pew <i>also</i> asked how parents would feel about their child marrying someone of a different <i>political party</i>. Now 30% of conservatives and 23% of liberals would get upset. Average them out, and you go from 12% upsetness rate for race to 27% upsetness rate for party – more than double. Yeah, people do lie to pollsters, but a picture is starting to come together here.</p><p>(Harvard, by the way, is a tossup. There are more black students – 11.5% – than conservative students – 10% – but there are more conservative faculty than black faculty.)</p><p>Since people will delight in misinterpreting me here, let me overemphasize what I am <i>not</i> saying. I’m not saying people of either party have it “worse” than black people, or that partyism is more of a <i>problem</i> than racism, or any of a number of stupid things along those lines which I am sure I will nevertheless be accused of believing. Racism is worse than partyism because the two parties are at least kind of balanced in numbers and in resources, whereas the brunt of an entire country’s racism falls on a few underprivileged people. I am saying that the <i>underlying attitudes that produce</i> partyism are stronger than the underlying attitudes that produce racism, with no necessary implications on their social effects.</p><p>But if we want to look at people’s psychology and motivations, partyism and the particular variant of tribalism that it represents are going to be fertile ground.</p><p><strong>VII.</strong></p><p>Every election cycle like clockwork, conservatives accuse liberals of not being sufficiently pro-America. And every election cycle like clockwork, liberals give extremely unconvincing denials of this.</p><p>“It’s not that we’re, like, <i>against</i> America per se. It’s just that…well, did you know Europe has much better health care than we do? And much lower crime rates? I mean, come on, how did they get so awesome? And we’re just sitting here, can’t even get the gay marriage thing sorted out, seriously, what’s wrong with a country that can’t…sorry, what were we talking about? Oh yeah, America. They’re okay. Cesar Chavez was really neat. So were some other people outside the mainstream who became famous precisely by criticizing majority society. That’s <i>sort of</i> like America being great, in that I think the parts of it that point out how bad the rest of it are often make excellent points. Vote for me!”</p><p>(sorry, I make fun of you because I love you)</p><p>There was a big brouhaha a couple of years ago when, as it first became apparent Obama had a good shot at the Presidency, Michelle Obama <a href=\"http://abcnews.go.com/blogs/politics/2008/02/michelle-obam-1-2\">said that</a> “for the first time in my adult life, I am proud of my country.”</p><p>Republicans pounced on the comment, asking why she hadn’t felt proud before, and she backtracked saying of course she was proud all the time and she loves America with the burning fury of a million suns and she was just saying that the Obama campaign was <i>particularly</i> inspiring.</p><p>As unconvincing denials go, this one was pretty far up there. But no one really held it against her. Probably most Obama voters felt vaguely the same way. <i>I</i> was an Obama voter, and I have proud memories of spending my Fourth of Julys as a kid debunking people’s heartfelt emotions of patriotism. Aaron Sorkin:</p><blockquote><p>[What makes America the greatest country in the world?] It’s not the greatest country in the world! We’re seventh in literacy, 27th in math, 22nd in science, 49th in life expectancy, 178th in infant mortality, third in median household income, No. 4 in labor force, and No. 4 in exports. So when you ask what makes us the greatest country in the world, I don’t know what the f*** you’re talking about.</p></blockquote><p>(Another <a href=\"http://www.washingtonpost.com/blogs/wonkblog/wp/2014/07/03/21-maps-and-charts-that-prove-america-is-number-one/\">good retort</a> is “We’re number one? Sure – number one in incarceration rates, drone strikes, and making new parents go back to work!”)</p><p>All of this is true, of course. But it’s weird that it’s such a classic interest of members of the Blue Tribe, and members of the Red Tribe never seem to bring it up.</p><p>(“We’re number one? Sure – number one in levels of sexual degeneracy! Well, I guess probably number two, after the Netherlands, but they’re really small and shouldn’t count.”)</p><p>My hunch – both the Red Tribe and the Blue Tribe, for whatever reason, identify “America” with the Red Tribe. Ask people for typically “American” things, and you end up with a very Red list of characteristics – guns, religion, barbecues, American football, NASCAR, cowboys, SUVs, unrestrained capitalism.</p><p>That means the Red Tribe feels intensely patriotic about “their” country, and the Blue Tribe feels like they’re living in fortified enclaves deep in hostile territory.</p><p>Here is a popular piece published on a major media site called <a href=\"http://www.huffingtonpost.com/justin-stoneman/post_868_b_720398.html\">America: A Big, Fat, Stupid Nation</a>. Another: <a href=\"http://english.pravda.ru/opinion/columnists/03-07-2008/105678-america-0/\">America: A Bunch Of Spoiled, Whiny Brats</a>. Americans <a href=\"http://matadornetwork.com/life/10-embarrassing-american-stereotypes/\">are</a> ignorant, scientifically illiterate religious fanatics whose “patriotism” is actually just narcissism. <a href=\"http://www.salon.com/2013/11/06/you_will_be_shocked_at_how_ignorant_americans_are_partner/\">You Will Be Shocked At How Ignorant Americans Are</a>, and we should <a href=\"http://www.slate.com/articles/news_and_politics/the_big_idea/2010/02/down_with_the_people.html\">Blame The Childish, Ignorant American People</a>.</p><p>Needless to say, every single one of these articles was written by an American and read almost entirely by Americans. Those Americans very likely enjoyed the articles very much and did not feel the least bit insulted.</p><p>And look at the sources. HuffPo, Salon, Slate. Might those have anything in common?</p><p>On both sides, “American” can be either a normal demonym, or a code word for a member of the Red Tribe.</p><p><strong>VIII.</strong></p><p>The other day, I logged into OKCupid and found someone who looked cool. I was reading over her profile and found the following sentence:</p><blockquote><p>Don’t message me if you’re a sexist white guy</p></blockquote><p>And my first thought was “Wait, so a sexist black person would be okay? Why?”</p><p>(The girl in question was white as snow)</p><p>Around the time the Ferguson riots were first starting, there were a host of articles with titles like <a href=\"http://mic.com/articles/96554/why-white-people-don-t-seem-to-understand-ferguson-in-one-chart\">Why White People Don’t Seem To Understand Ferguson</a>, <a href=\"http://www.theatlantic.com/politics/archive/2014/08/self-segregation-why-its-hard-for-whites-to-understand-ferguson/378928/\">Why It’s So Hard For Whites To Understand Ferguson</a>, and <a href=\"http://blog.chron.com/texassparkle/2014/08/white-folks-listen-up-and-let-me-tell-you-what-ferguson-is-all-about/\">White Folks Listen Up And Let Me Tell You What Ferguson Is All About</a>, this last of which says:</p><blockquote><p>Social media is full of people on both sides making presumptions, and believing what they want to believe. But it’s the white folks that don’t understand what this is all about. Let me put it as simply as I can for you […]</p><p>No matter how wrong you think Trayvon Martin or Michael Brown were, I think we can all agree they didn’t deserve to die over it. I want you white folks to understand that this is where the anger is coming from. You focused on the looting….”</p></blockquote><p>And on a hunch I checked the author photos, and every single one of these articles was written by a white person.</p><p><a href=\"http://robertlindsay.wordpress.com/2011/04/12/who-is-ruining-america/\">White People Are Ruining America</a>? White. <a href=\"http://unvis.it/gawker.com/fifty-years-after-the-march-white-people-are-still-a-d-1216851674\">White People Are Still A Disgrace</a>? White. <a href=\"http://www.huffingtonpost.com/2014/05/05/white-guys-we-suck_n_5269105.html\">White Guys: We Suck And We’re Sorry</a>? White. <a href=\"http://www.realclearpolitics.com/2014/05/08/bye-bye_whiny_white_dudes_331840.html\">Bye Bye, Whiny White Dudes</a>? White. <a href=\"http://unvis.it/makemeasammich.org/2014/04/25/dear-entitled-straight-white-dudes/\">Dear Entitled Straight White Dudes, I’m Evicting You From My Life</a>? White. <a href=\"http://wonkette.com/542874/all-these-white-dudes-need-to-stop-whitesplaining-about-what-slavery-is\">White Dudes Need To Stop Whitesplaining</a>? White. <a href=\"http://whyamericanssuck.blogspot.com/2010/07/1-white-people.html\">Reasons Why Americans Suck #1: White People</a>? White.</p><p>We’ve all seen articles and comments and articles like this. Some unsavory people try to use them to prove that white people are the <i>real</i> victims or the media is biased against white people or something. Other people who are very nice and optimistic use them to show that some white people have developed some self-awareness and are willing to engage in self-criticism.</p><p>But I think the situation with “white” is much the same as the situation with “American” – it can either mean what it says, or be a code word for the Red Tribe.</p><p>(except on the blog <a href=\"http://stuffwhitepeoplelike.com/\">Stuff White People Like</a>, where it obviously serves as a code word for the <i>Blue</i> tribe. I don’t know, guys. I didn’t do it.)</p><p>I realize that’s making a strong claim, but it would hardly be without precedent. When people say things like “gamers are misogynist”, do they mean <a href=\"http://www.theguardian.com/commentisfree/2014/sep/18/52-percent-people-playing-games-women-industry-doesnt-know\">the 52% of gamers who are women</a>? Do they mean every one of the 59% of Americans from every walk of life who are known to play video or computer games occasionally? No. “Gamer” is a coded reference to the Gray Tribe, the half-branched-off collection of libertarianish tech-savvy nerds, and everyone knows it. As well expect that when people talk about “fedoras”, they mean Indiana Jones. Or when they talk about “urban youth”, they mean freshmen at NYU. Everyone knows exactly who we mean when we say “urban youth”, and them being young people who live in a city has only the most tenuous of relations to the actual concept.</p><p>And I’m saying words like “American” and “white” work the same way. Bill Clinton was the <a href=\"http://www.realclearpolitics.com/video/2014/04/03/bill_clinton_i_loved_being_called_the_first_black_president.html\">“first black President”</a>, but if Herman Cain had won in 2012 he’d have been the 43rd white president. And when an angry white person talks at great length about how much he hates “white dudes”, <i>he is not being humble and self-critical</i>.</p><p><strong>IX.</strong></p><p>Imagine hearing that a liberal talk show host and comedian was so enraged by the actions of ISIS that he’d recorded and posted a video in which he shouts at them for ten minutes, cursing the “fanatical terrorists” and calling them “utter savages” with “savage values”.</p><p>If <i>I</i> heard that, I’d be kind of surprised. It doesn’t fit my model of what liberal talk show hosts do.</p><p>But <a href=\"http://rt.com/usa/168704-russell-brand-fox-news/\">the story</a> I’m <i>actually</i> referring to is liberal talk show host / comedian Russell Brand making that same rant against Fox News for <i>supporting war against</i> the Islamic State, adding at the end that “Fox is worse than ISIS”.</p><p>That fits my model perfectly. You wouldn’t celebrate Osama’s death, only Thatcher’s. And you wouldn’t call ISIS savages, only Fox News. Fox is the outgroup, ISIS is just some random people off in a desert. You hate the outgroup, you don’t hate random desert people.</p><p>I would go further. Not only does Brand not feel much like hating ISIS, he has a strong incentive not to. That incentive is: the Red Tribe is known to hate ISIS loudly and conspicuously. Hating ISIS would signal Red Tribe membership, would be the equivalent of going into Crips territory with a big Bloods gang sign tattooed on your shoulder.</p><p>But this might be unfair. What would Russell Brand answer, if we asked him to justify his decision to be much angrier at Fox than ISIS?</p><p>He might say something like “Obviously Fox News is not literally worse than ISIS. But here I am, talking to my audience, who are mostly white British people and Americans. These people already know that ISIS is bad; they don’t need to be told that any further. In fact, at this point being angry about how bad ISIS is, is less likely to genuinely change someone’s mind about ISIS, and more likely to promote Islamophobia. The sort of people in my audience are at zero risk of becoming ISIS supporters, but at a very real risk of Islamophobia. So ranting against ISIS would be counterproductive and dangerous.</p><p>On the other hand, my audience of white British people and Americans is very likely to contain many Fox News viewers and supporters. And Fox, while not quite as evil as ISIS, is still pretty bad. So here’s somewhere I have a genuine chance to reach people at risk and change minds. Therefore, I think my decision to rant against Fox News, and maybe hyperbolically say they were ‘worse than ISIS’ is justified under the circumstances.”</p><p>I have a lot of sympathy to hypothetical-Brand, especially to the part about Islamophobia. It <i>does</i> seem really possible to denounce ISIS’ atrocities to a population that already hates them in order to <a href=\"”http://slatestarcodex.com/2014/05/12/weak-men-are-superweapons/”\">weak-man</a> a couple of already-marginalized Muslims. We need to fight terrorism and atrocities – therefore it’s okay to shout at a poor girl ten thousand miles from home for wearing a headscarf in public. Christians are being executed for their faith in Sudan, therefore let’s picket the people trying to build a mosque next door.</p><p>But my sympathy with Brand ends when he acts like his audience is likely to be fans of Fox News.</p><p>In a world where a negligible number of Redditors oppose gay marriage and 1% of Less Wrongers identify conservative and I know 0/150 creationists, how many of the people who visit the YouTube channel of a well-known liberal activist with a Che-inspired banner, a channel whose episode names are things like “War: What Is It Good For?” and “Sarah Silverman Talks Feminism” – how many of them do you think are big Fox News fans?</p><p>In a way, Russell Brand would have been <i>braver</i> taking a stand against ISIS than against Fox. If he attacked ISIS, his viewers would just be a little confused and uncomfortable. Whereas every moment he’s attacking Fox his viewers are like “HA HA! YEAH! GET ‘EM! SHOW THOSE IGNORANT BIGOTS IN THE OUTGROUP WHO’S BOSS!”</p><p>Brand acts as if there are just these countries called “Britain” and “America” who are receiving his material. Wrong. There are two parallel universes, and he’s only broadcasting to one of them.</p><p>The result is exactly what we predicted would happen in the case of Islam. Bombard people with images of a far-off land they already hate and tell them to hate it more, and the result is ramping up the intolerance on the couple of dazed and marginalized representatives of that culture who have ended up stuck on your half of the divide. Sure enough, if industry or culture or community gets Blue enough, Red Tribe members start getting harassed, fired from their jobs (Brendan Eich being the obvious example) or otherwise shown the door.</p><p>Think of Brendan Eich as a member of a tiny religious minority surrounded by people who hate that minority. Suddenly firing him doesn’t seem very noble.</p><p>If you mix together Podunk, Texas and Mosul, Iraq, you can prove that Muslims are scary and very powerful people who are executing Christians all the time – and so we have a great excuse for kicking the one remaining Muslim family, random people who never hurt anyone, out of town.</p><p>And if you mix together the open-source tech industry and the parallel universe <a href=\"http://rmitz.org/freebsd.daemon.html\">where</a> you can’t wear a FreeBSD t-shirt without risking someone trying to exorcise you, you can prove that Christians are scary and very powerful people who are persecuting everyone else all the time, and you have a great excuse for kicking one of the few people willing to affiliate with the Red Tribe, a guy who never hurt anyone, out of town.</p><p>When a friend of mine heard Eich got fired, she didn’t see anything wrong with it. “I can tolerate anything except intolerance,” she said.</p><p>“Intolerance” is starting to look like another one of those words like “white” and “American”.</p><p>“I can tolerate anything except the outgroup.” Doesn’t sound quite so noble now, does it?</p><p><strong>X.</strong></p><p>We started by asking: millions of people are conspicuously praising every outgroup they can think of, while conspicuously condemning their own in-group. This seems contrary to what we know about social psychology. What’s up?</p><p>We noted that outgroups are rarely literally “the group most different from you”, and in fact far more likely to be groups very similar to you sharing <i>almost</i> all your characteristics and living in the same area.</p><p>We then noted that although liberals and conservatives live in the same area, they might as well be two totally different countries or universe as far as level of interaction were concerned.</p><p>Contra the usual idea of them being marked only by voting behavior, we described them as very different tribes with totally different cultures. You can speak of “American culture” only in the same way you can speak of “Asian culture” – that is, with a lot of interior boundaries being pushed under the rug.</p><p>The outgroup of the Red Tribe is occasionally blacks and gays and Muslims, more often the Blue Tribe.</p><p>The Blue Tribe has performed some kind of very impressive act of alchemy, and transmuted <i>all</i> of its outgroup hatred to the Red Tribe.</p><p>This is not surprising. Ethnic differences have proven quite tractable in the face of shared strategic aims. Even the Nazis, not known for their ethnic tolerance, were able to get all buddy-buddy with the Japanese when they had a common cause.</p><p>Research suggests Blue Tribe / Red Tribe prejudice to be much stronger than better-known types of prejudice like racism. Once the Blue Tribe was able to enlist the blacks and gays and Muslims in their ranks, they became allies of convenience who deserve to be rehabilitated with mildly condescending paeans to their virtue. “There never was a coward where the shamrock grows.”</p><p>Spending your entire life insulting the other tribe and talking about how terrible they are makes you look, well, tribalistic. It is definitely not high class. So when members of the Blue Tribe decide to dedicate their entire life to yelling about how terrible the Red Tribe is, they make sure that instead of saying “the Red Tribe”, they say “America”, or “white people”, or “straight white men”. That way it’s <i>humble self-criticism</i>. They are <i>so</i> interested in justice that they are willing to critique <i>their own beloved side</i>, much as it pains them to do so. We know they are not exaggerating, because one might exaggerate the flaws of an enemy, but that anyone would exaggerate their <i>own</i> flaws fails <a href=\"http://en.wikipedia.org/wiki/Criterion_of_embarrassment\">the criterion of embarrassment</a>.</p><p>The Blue Tribe always has an excuse at hand to persecute and crush any Red Tribers unfortunate enough to fall into its light-matter-universe by defining them as all-powerful domineering oppressors. They appeal to the fact that this is definitely the way it works in the Red Tribe’s dark-matter-universe, and that’s in the same country so it has to be the same community for all intents and purposes. As a result, every Blue Tribe institution is permanently licensed to take whatever emergency measures are necessary against the Red Tribe, however disturbing they might otherwise seem.</p><p>And so how virtuous, how noble the Blue Tribe! Perfectly tolerant of all of the different groups that just so happen to be allied with them, never intolerant unless it happen to be against intolerance itself. Never stooping to engage in petty tribal conflict like that awful Red Tribe, but always nobly criticizing their own culture and striving to make it better!</p><p>Sorry. But I hope this is at least a <i>little</i> convincing. The weird dynamic of outgroup-philia and ingroup-phobia isn’t anything of the sort. It’s just good old-fashioned in-group-favoritism and outgroup bashing, a little more sophisticated and a little more sneaky.</p><p><strong>XI.</strong></p><p>This essay is bad and I should feel bad.</p><p>I should feel bad because I made <i>exactly</i> the mistake I am trying to warn everyone else about, and it wasn’t until I was almost done that I noticed.</p><p>How virtuous, how noble I must be! Never stooping to engage in petty tribal conflict like that silly Red Tribe, but always nobly criticizing my own tribe and striving to make it better.</p><p>Yeah. Once I’ve written a ten thousand word essay savagely attacking the Blue Tribe, either I’m a very special person or they’re my outgroup. And I’m not <i>that</i> special.</p><p>Just as you can pull a fast one and look humbly self-critical if you make your audience assume there’s just one American culture, so maybe you can trick people by assuming there’s only one Blue Tribe.</p><p>I’m pretty sure I’m not Red, but I did talk about the Grey Tribe above, and I show all the risk factors for being one of them. That means that, although my critique of the Blue Tribe may be right or wrong, in terms of <i>motivation</i> it comes from the same place as a Red Tribe member talking about how much they hate al-Qaeda or a Blue Tribe member talking about how much they hate ignorant bigots. And when I boast of being able to tolerate Christians and Southerners whom the Blue Tribe is mean to, I’m not being tolerant at all, just noticing people so far away from me they wouldn’t make a good outgroup anyway.</p><p>I had <i>fun</i> writing this article. People do not have fun writing articles savagely criticizing their in-group. People can criticize their in-group, it’s not <i>humanly impossible</i>, but it takes nerves of steel, it makes your blood boil, you should sweat blood. It shouldn’t be <i>fun</i>.</p><p>You can bet some white guy on Gawker who week after week churns out “Why White People Are So Terrible” and “Here’s What Dumb White People Don’t Understand” is having fun and not sweating any blood at all. He’s not criticizing his in-group, he’s never even <i>considered</i> criticizing his in-group. I can’t blame him. Criticizing the in-group is a really difficult project I’ve barely begun to build the mental skills necessary to even consider.</p><p>I can think of criticisms of my own tribe. Important criticisms, true ones. But the thought of writing them makes my blood boil.</p><p>I imagine might I feel like some liberal US Muslim leader, when he goes on the O’Reilly Show, and O’Reilly ambushes him and demands to know why he and other American Muslims haven’t condemned beheadings by ISIS more, demands that he criticize them right there on live TV. And you can see the wheels in the Muslim leader’s head turning, thinking something like “Okay, obviously beheadings are terrible and I hate them as much as anyone. But you don’t care even <i>the slightest bit</i> about the victims of beheadings. You’re just looking for a way to score points against me so you can embarass all Muslims. And I would rather personally behead every single person in the world than give a smug bigot like you a single microgram more stupid self-satisfaction than you’ve already got.”</p><p>That is how I feel when asked to criticize my own tribe, even for correct reasons. If you think you’re criticizing your own tribe, and your blood is not at that temperature, consider the possibility that you aren’t.</p><p>But if I want Self-Criticism Virtue Points, criticizing the Grey Tribe is the only honest way to get them. And if I want Tolerance Points, my own personal cross to bear right now is tolerating the Blue Tribe. I need to remind myself that when they are bad people, they are merely Osama-level bad people instead of Thatcher-level bad people. And when they are good people, they are powerful and necessary crusaders against the evils of the world.</p><p>The worst thing that could happen to this post is to have it be used as convenient feces to fling at the Blue Tribe whenever feces are necessary. Which, given what has happened to my last couple of posts along these lines and the obvious biases of my own subconscious, I already expect it will be.</p><p>But the best thing that could happen to this post is that it makes a lot of people, especially myself, figure out how to be more tolerant. Not in the “of course I’m tolerant, why shouldn’t I be?” sense of the Emperor in Part I. But in the sense of “being tolerant makes me see red, makes me sweat blood, but darn it <i>I am going to be tolerant anyway</i>.”</p>",
    "user": {
      "username": "Yvain",
      "slug": "scottalexander",
      "displayName": "Scott Alexander"
    }
  }
]